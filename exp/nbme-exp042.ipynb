{"cells":[{"cell_type":"markdown","metadata":{"id":"uniform-bangkok"},"source":["## References"],"id":"uniform-bangkok"},{"cell_type":"markdown","metadata":{"id":"addressed-fitting"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"],"id":"addressed-fitting"},{"cell_type":"markdown","metadata":{"id":"concerned-services"},"source":["## Configurations"],"id":"concerned-services"},{"cell_type":"code","execution_count":null,"metadata":{"id":"smoking-english"},"outputs":[],"source":["EXP_NAME = \"nbme-exp042\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"],"id":"smoking-english"},{"cell_type":"code","execution_count":null,"metadata":{"id":"appropriate-carol"},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=2\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=5\n","    train_fold=[0, 1, 2, 3, 4]\n","    seed=71\n","    gradient_accumulation_steps=4\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"],"id":"appropriate-carol"},{"cell_type":"code","execution_count":null,"metadata":{"id":"amber-confidence"},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"],"id":"amber-confidence"},{"cell_type":"markdown","metadata":{"id":"integral-nutrition"},"source":["## Directory Settings"],"id":"integral-nutrition"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11207,"status":"ok","timestamp":1647352101940,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"synthetic-portfolio","outputId":"d5ef14bf-886b-4728-f599-41970ff4b735"},"outputs":[{"name":"stdout","output_type":"stream","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers\n","    !pip install sentencepiece\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"],"id":"synthetic-portfolio"},{"cell_type":"code","execution_count":null,"metadata":{"id":"communist-principle"},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"id":"communist-principle"},{"cell_type":"markdown","metadata":{"id":"integrated-tractor"},"source":["## Utilities"],"id":"integrated-tractor"},{"cell_type":"code","execution_count":null,"metadata":{"id":"statewide-methodology"},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"],"id":"statewide-methodology"},{"cell_type":"code","execution_count":null,"metadata":{"id":"alert-internet"},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"],"id":"alert-internet"},{"cell_type":"code","execution_count":null,"metadata":{"id":"packed-number"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"id":"packed-number"},{"cell_type":"code","execution_count":null,"metadata":{"id":"thousand-government"},"outputs":[],"source":["seed_everything()"],"id":"thousand-government"},{"cell_type":"markdown","metadata":{"id":"fluid-sympathy"},"source":["## Data Loading"],"id":"fluid-sympathy"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1647352107406,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"alive-dairy","outputId":"a7ca68f6-d531-4475-d262-c2e7c8281ba0"},"outputs":[{"data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"],"id":"alive-dairy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"warming-custom"},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"],"id":"warming-custom"},{"cell_type":"markdown","metadata":{"id":"three-founder"},"source":["## Preprocessing"],"id":"three-founder"},{"cell_type":"code","execution_count":null,"metadata":{"id":"utility-surface"},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"],"id":"utility-surface"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1647352107407,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"naval-mexican","outputId":"ecf9bc8f-6819-4b19-c9d8-775310d6f8a0"},"outputs":[{"data":{"text/plain":["((14300, 8), (5, 6))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"],"id":"naval-mexican"},{"cell_type":"code","execution_count":null,"metadata":{"id":"excellent-father"},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"],"id":"excellent-father"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1647352107897,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"multiple-making","outputId":"198b9f3d-6d64-479f-a500-6f70da3c8b3d"},"outputs":[{"data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"],"id":"multiple-making"},{"cell_type":"markdown","metadata":{"id":"concerned-wilson"},"source":["## CV split"],"id":"concerned-wilson"},{"cell_type":"code","execution_count":null,"metadata":{"id":"allied-oriental"},"outputs":[],"source":["def get_groupkfold(df, group_name):\n","    groups = df[group_name].unique()\n","\n","    kf = KFold(\n","        n_splits=CFG.n_fold,\n","        shuffle=True,\n","        random_state=CFG.seed,\n","    )\n","    folds_ids = []\n","    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n","        val_group = groups[val_group_idx]\n","        is_val = df[group_name].isin(val_group)\n","        val_idx = df[is_val].index\n","        df.loc[val_idx, \"fold\"] = int(i_fold)\n","\n","    df[\"fold\"] = df[\"fold\"].astype(int)\n","    return df"],"id":"allied-oriental"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1647352107897,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"victorian-replacement","outputId":"115dbcc5-f9e0-408c-832e-e9b5f36d9a18"},"outputs":[{"data":{"text/plain":["fold\n","0    2902\n","1    2894\n","2    2813\n","3    2791\n","4    2900\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["train = get_groupkfold(train, \"pn_num\")\n","display(train.groupby(\"fold\").size())"],"id":"victorian-replacement"},{"cell_type":"markdown","metadata":{"id":"indie-hands"},"source":["## Setup tokenizer"],"id":"indie-hands"},{"cell_type":"code","execution_count":null,"metadata":{"id":"placed-pavilion"},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\", trim_offsets=False)\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name, trim_offsets=False)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"],"id":"placed-pavilion"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1647352112782,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"abandoned-offer","outputId":"bfe77396-0396-4464-df6d-98b2da56f47d"},"outputs":[{"name":"stdout","output_type":"stream","text":["'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}],"source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"],"id":"abandoned-offer"},{"cell_type":"markdown","metadata":{"id":"secure-mattress"},"source":["## Create dataset"],"id":"secure-mattress"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["a068a967d95945cab627216b77c83cda","0bc0430a9bd34eb68fa8bfe9d67f816e","d121bf9ada4f4c128b16df1c1ac6cefe","0399a39c415444dc849bc2af68c994bc","ec3ae1c9fd86497c832e0f370c439a60","dcdee0f86ee44521ada35550f53cf8b4","2aafe85d44784db69061af1a3139e3fc","62b527b8654e48819e8987e042be0a61","3a325138c0d64b8e9d08db5250cf25e4","8820fa4608e8494fb1eb79aa2d92e62b","838177e0e1a44fa8acf383398d7989ae"]},"executionInfo":{"elapsed":36312,"status":"ok","timestamp":1647352149088,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"phantom-reverse","outputId":"2f45b30b-dbd5-4a19-b34d-e4c8fbac0100"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a068a967d95945cab627216b77c83cda","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"],"id":"phantom-reverse"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["b442b1c4458c49deb830c280d7f57b55","9c1c08f024594e2f8e62af5973101472","2b2f4c5b0da14c85b45872bb1d70e2f6","72a583da875e4453aaf69b0c395a27a9","283d3b0fa75a47c5b361e49d8fee8a0d","ff284eb9d326463dbcd0c13233604d01","0db5c6f7136546abbc3e6fd2b64e1935","789018951c5a44cab8e88c13aea8597b","1aba16da8f13419f92e351a0a63cce96","1abb815356f9446193fa316f1a76ffe8","72b2634c24434f3ab6a1f3c4f1645852"]},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1647352149089,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"helpful-obligation","outputId":"a964cf2c-71c6-4fea-bab3-050851a9cc82"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b442b1c4458c49deb830c280d7f57b55","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"],"id":"helpful-obligation"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1647352149091,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"happy-buyer","outputId":"fed29502-1aa8-48fe-ca64-0a44ad40de56"},"outputs":[{"name":"stdout","output_type":"stream","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"],"id":"happy-buyer"},{"cell_type":"code","execution_count":null,"metadata":{"id":"therapeutic-handy"},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"],"id":"therapeutic-handy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"handed-teens"},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"],"id":"handed-teens"},{"cell_type":"markdown","metadata":{"id":"familiar-football"},"source":["## Model"],"id":"familiar-football"},{"cell_type":"code","execution_count":null,"metadata":{"id":"prospective-flour"},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            #path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","        self.cnn1 = nn.Conv1d(self.model_config.hidden_size, 256, kernel_size=2, padding=\"same\")\n","        self.cnn2 = nn.Conv1d(256, 1, kernel_size=2, padding=\"same\")\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]   # [batch, seq_len, d_model]\n","        h = h.permute(0, 2, 1)   # [batch, d_model, seq_len]\n","        cnn_embeddings = F.relu(self.cnn1(h))\n","        cnn_embeddings = self.cnn2(cnn_embeddings)\n","        output, _ = torch.max(cnn_embeddings, 1)\n","        return output"],"id":"prospective-flour"},{"cell_type":"markdown","metadata":{"id":"domestic-prerequisite"},"source":["## Training"],"id":"domestic-prerequisite"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJcvpYFqbqaa"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class FocalLoss(nn.Module):\n","    \"\"\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65938\n","    \"\"\"\n","    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.logits = logits\n","        self.reduce = reduce\n","\n","    def forward(self, inputs, targets):\n","        if self.logits:\n","            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n","        else:\n","            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n","        pt = torch.exp(-BCE_loss)\n","        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n","\n","        if self.reduce:\n","            return torch.mean(F_loss)\n","        else:\n","            return F_loss"],"id":"TJcvpYFqbqaa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"sticky-blink"},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"],"id":"sticky-blink"},{"cell_type":"code","execution_count":null,"metadata":{"id":"medium-completion"},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"],"id":"medium-completion"},{"cell_type":"code","execution_count":null,"metadata":{"id":"excellent-eligibility"},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"],"id":"excellent-eligibility"},{"cell_type":"code","execution_count":null,"metadata":{"id":"subject-chapel"},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    #criterion = FocalLoss(reduce=False)\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"],"id":"subject-chapel"},{"cell_type":"markdown","metadata":{"id":"monetary-state"},"source":["## Main"],"id":"monetary-state"},{"cell_type":"code","execution_count":null,"metadata":{"id":"selected-maple"},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"],"id":"selected-maple"},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9fc820db4c20404ba98ee79396b5b363","3f191def88d74437900b7ce926e113ad","3a841058dd2147dfaf7dad9f5e83fc77","59e0df25eb5447a191edc8878f3d9447","707499c5a22a495f9cd814480c1009a1","a906a29299024c1e853d86bf147495b5","e11b0696ad3e4ae584530d42ac45b44b","f47b3673d6724f049090cde9038ff571","e79157a631a640f4af3377e9823f6493","6c896dcb5fb14a8997eb6e43a9c65d0e","b59c6338355e4a619dc2579039d172e5","335266df983d42e5ad63eecd50b18672","c02ecf6b54a747eb9db10ada1ed8b3c8","4a6c536580ef4d84bb46d14363fba24d","c08bef1dc00a4718a18583cf7b3f4795","e238f0dbdd504648a4bac20cc6c906b6","43d0dd24bbb74774acd32c10c4ceb229","c5333198d8424c7d855127266f2dc456","16997f093267472484f47e7e751f876f","9fa54cefe1414a8c90a4b50e48dce3a6","611387a35e8a4cc9b634b4b4730fc903","154aaf74cdb240748892b0dcf954199a","35696f212e1a40a99dc7b90f1d880aac","af76eee3a96e4509b9fb4e5d85bb5447","7d43de8fbfad43cc80fd928799af703b","0e53274a03de4c0cb17a50bb8cdd0456","66eeb3ee376548bfb139cd3b8395a1ff","844310b0f9974437b21be474a4f13221","e60c7cd8678d46f2a3ad00b3d32585da","30664846d2d441aeab45e6a2700f31ac","b7bbd07ed4734367ab6fbe3548c9d913","42eae6e871644489827fa7b1cdea551d","c944c0fe12564dae98134683fc5d0c2d","7170281bab5e4e50a7b33a19b56aee66","c6c6561965b044c19ee5419924422bc8","d9052c48c3ee4359a8d963be6fc7f98d","a89fcdeacc194a56917c2c2ccc3228c1","452d7d9bc5a94e96bd91b5b4dbec3760","b8eb96a8cd934659953a7a154a2732a2","bb2ffd8904854588b8fc53a8a4845860","b14372a025aa4d069474d8aab8499693","59f08270bf734b73b586ff9e3d98fa2a","3be8e07394d94ccba9de0a6db92674f8","85f364edbf79498fa60543d03a9895d1","d57377a103924888b18915e9080df51a","425ff7de89704088a80eb1e60790a108","3c437ba94dcd48dd8b9137571e47f4cf","217ef0160bc042f99a0954fb12760c33","06747c463e8346de93cd49b1426d1776","7e6fd51ccfa647efa31037168fbbb59f","507f7d66b75048a7bf791dc00d632978","c085f947e824413b97fe56be4775785c","04c8b1ad279d48d285d2e79357bb16fe","213e0af4ea0442f78a5e2f3620bcf8be","346ae89d47954f7eb8a0db84621de7fd","27d59314703f45b49d2449929c9fe6d0","9b648b6374274930b3f284e38bc3b1a0","ecfe056930a1409fa771fbfacfd5e657","ffa66c875f7147ebbc93545f3833decf","82494331726b4d00afdc0d74f03da57e","04d710e17b66405d936d87a73c1bf4d7","ecdfe18de07c486494a870c92da04a75","cf962fb724bd46a7a8d59fc484c51caf","572b08467e884783a75fe2f78a953c1d","2f316cabf2164a3389a687ea4744e3be","039f43676fcc468fbaeb92e98e3f912d"]},"id":"local-thesis","outputId":"3189037a-20d7-4def-f286-aeaa70447eb1","executionInfo":{"status":"ok","timestamp":1647392452114,"user_tz":-540,"elapsed":1094024,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5699] Elapsed 0m 0s (remain 79m 16s) Loss: 0.1875(0.1875) Grad: 50853.8555  LR: 0.000000  \n","Epoch: [1][100/5699] Elapsed 0m 24s (remain 22m 54s) Loss: 0.1870(0.3017) Grad: 55268.6914  LR: 0.000001  \n","Epoch: [1][200/5699] Elapsed 0m 48s (remain 22m 11s) Loss: 0.1773(0.2912) Grad: 53175.6367  LR: 0.000001  \n","Epoch: [1][300/5699] Elapsed 1m 14s (remain 22m 9s) Loss: 0.1625(0.2866) Grad: 51296.8945  LR: 0.000002  \n","Epoch: [1][400/5699] Elapsed 1m 38s (remain 21m 35s) Loss: 0.2373(0.2785) Grad: 80164.0859  LR: 0.000003  \n","Epoch: [1][500/5699] Elapsed 2m 2s (remain 21m 8s) Loss: 0.3450(0.2658) Grad: 133679.7969  LR: 0.000004  \n","Epoch: [1][600/5699] Elapsed 2m 26s (remain 20m 41s) Loss: 0.1620(0.2468) Grad: 77641.9688  LR: 0.000004  \n","Epoch: [1][700/5699] Elapsed 2m 50s (remain 20m 13s) Loss: 0.0813(0.2276) Grad: 40719.6914  LR: 0.000005  \n","Epoch: [1][800/5699] Elapsed 3m 14s (remain 19m 47s) Loss: 0.0120(0.2055) Grad: 7233.5752  LR: 0.000006  \n","Epoch: [1][900/5699] Elapsed 3m 38s (remain 19m 21s) Loss: 0.0102(0.1852) Grad: 521.9288  LR: 0.000006  \n","Epoch: [1][1000/5699] Elapsed 4m 2s (remain 18m 56s) Loss: 0.0256(0.1688) Grad: 3160.1633  LR: 0.000007  \n","Epoch: [1][1100/5699] Elapsed 4m 26s (remain 18m 32s) Loss: 0.0250(0.1552) Grad: 3682.5605  LR: 0.000008  \n","Epoch: [1][1200/5699] Elapsed 4m 50s (remain 18m 7s) Loss: 0.0220(0.1438) Grad: 2146.7866  LR: 0.000008  \n","Epoch: [1][1300/5699] Elapsed 5m 14s (remain 17m 43s) Loss: 0.0276(0.1343) Grad: 3814.2415  LR: 0.000009  \n","Epoch: [1][1400/5699] Elapsed 5m 38s (remain 17m 19s) Loss: 0.0114(0.1259) Grad: 11066.1348  LR: 0.000010  \n","Epoch: [1][1500/5699] Elapsed 6m 3s (remain 16m 55s) Loss: 0.0307(0.1186) Grad: 5655.3159  LR: 0.000011  \n","Epoch: [1][1600/5699] Elapsed 6m 27s (remain 16m 31s) Loss: 0.0013(0.1124) Grad: 1805.1021  LR: 0.000011  \n","Epoch: [1][1700/5699] Elapsed 6m 51s (remain 16m 6s) Loss: 0.0281(0.1067) Grad: 36351.5703  LR: 0.000012  \n","Epoch: [1][1800/5699] Elapsed 7m 15s (remain 15m 43s) Loss: 0.0038(0.1015) Grad: 5224.1602  LR: 0.000013  \n","Epoch: [1][1900/5699] Elapsed 7m 39s (remain 15m 18s) Loss: 0.0037(0.0968) Grad: 8479.6133  LR: 0.000013  \n","Epoch: [1][2000/5699] Elapsed 8m 4s (remain 14m 54s) Loss: 0.0038(0.0924) Grad: 5139.3828  LR: 0.000014  \n","Epoch: [1][2100/5699] Elapsed 8m 28s (remain 14m 30s) Loss: 0.0090(0.0886) Grad: 20184.8828  LR: 0.000015  \n","Epoch: [1][2200/5699] Elapsed 8m 52s (remain 14m 5s) Loss: 0.0260(0.0851) Grad: 71883.4219  LR: 0.000015  \n","Epoch: [1][2300/5699] Elapsed 9m 16s (remain 13m 41s) Loss: 0.0111(0.0818) Grad: 10219.6436  LR: 0.000016  \n","Epoch: [1][2400/5699] Elapsed 9m 40s (remain 13m 17s) Loss: 0.0139(0.0787) Grad: 52239.5078  LR: 0.000017  \n","Epoch: [1][2500/5699] Elapsed 10m 4s (remain 12m 52s) Loss: 0.0203(0.0759) Grad: 9310.7793  LR: 0.000018  \n","Epoch: [1][2600/5699] Elapsed 10m 28s (remain 12m 28s) Loss: 0.0015(0.0732) Grad: 1541.5209  LR: 0.000018  \n","Epoch: [1][2700/5699] Elapsed 10m 52s (remain 12m 4s) Loss: 0.0007(0.0708) Grad: 1003.3315  LR: 0.000019  \n","Epoch: [1][2800/5699] Elapsed 11m 16s (remain 11m 39s) Loss: 0.0052(0.0686) Grad: 6442.9185  LR: 0.000020  \n","Epoch: [1][2900/5699] Elapsed 11m 40s (remain 11m 15s) Loss: 0.0004(0.0665) Grad: 559.0829  LR: 0.000020  \n","Epoch: [1][3000/5699] Elapsed 12m 4s (remain 10m 51s) Loss: 0.0002(0.0645) Grad: 183.8769  LR: 0.000020  \n","Epoch: [1][3100/5699] Elapsed 12m 28s (remain 10m 27s) Loss: 0.0091(0.0626) Grad: 11376.7891  LR: 0.000020  \n","Epoch: [1][3200/5699] Elapsed 12m 52s (remain 10m 3s) Loss: 0.0001(0.0609) Grad: 117.0704  LR: 0.000020  \n","Epoch: [1][3300/5699] Elapsed 13m 16s (remain 9m 38s) Loss: 0.0014(0.0593) Grad: 11241.8770  LR: 0.000020  \n","Epoch: [1][3400/5699] Elapsed 13m 40s (remain 9m 14s) Loss: 0.0003(0.0577) Grad: 282.4328  LR: 0.000020  \n","Epoch: [1][3500/5699] Elapsed 14m 4s (remain 8m 50s) Loss: 0.0070(0.0562) Grad: 14746.8574  LR: 0.000019  \n","Epoch: [1][3600/5699] Elapsed 14m 28s (remain 8m 26s) Loss: 0.0049(0.0548) Grad: 15830.4414  LR: 0.000019  \n","Epoch: [1][3700/5699] Elapsed 14m 53s (remain 8m 2s) Loss: 0.0043(0.0536) Grad: 11754.1064  LR: 0.000019  \n","Epoch: [1][3800/5699] Elapsed 15m 17s (remain 7m 38s) Loss: 0.0159(0.0525) Grad: 17333.4375  LR: 0.000019  \n","Epoch: [1][3900/5699] Elapsed 15m 41s (remain 7m 14s) Loss: 0.0558(0.0513) Grad: 28240.9336  LR: 0.000019  \n","Epoch: [1][4000/5699] Elapsed 16m 6s (remain 6m 50s) Loss: 0.0044(0.0502) Grad: 5198.6016  LR: 0.000019  \n","Epoch: [1][4100/5699] Elapsed 16m 30s (remain 6m 25s) Loss: 0.0031(0.0491) Grad: 10967.1816  LR: 0.000019  \n","Epoch: [1][4200/5699] Elapsed 16m 54s (remain 6m 1s) Loss: 0.0037(0.0481) Grad: 4813.0786  LR: 0.000019  \n","Epoch: [1][4300/5699] Elapsed 17m 18s (remain 5m 37s) Loss: 0.0016(0.0472) Grad: 3187.3801  LR: 0.000019  \n","Epoch: [1][4400/5699] Elapsed 17m 42s (remain 5m 13s) Loss: 0.0006(0.0462) Grad: 5976.4619  LR: 0.000019  \n","Epoch: [1][4500/5699] Elapsed 18m 7s (remain 4m 49s) Loss: 0.0034(0.0453) Grad: 4936.2451  LR: 0.000019  \n","Epoch: [1][4600/5699] Elapsed 18m 31s (remain 4m 25s) Loss: 0.0083(0.0445) Grad: 17927.5703  LR: 0.000019  \n","Epoch: [1][4700/5699] Elapsed 18m 55s (remain 4m 1s) Loss: 0.0001(0.0436) Grad: 99.4770  LR: 0.000019  \n","Epoch: [1][4800/5699] Elapsed 19m 19s (remain 3m 36s) Loss: 0.0017(0.0428) Grad: 3265.9316  LR: 0.000018  \n","Epoch: [1][4900/5699] Elapsed 19m 43s (remain 3m 12s) Loss: 0.0015(0.0420) Grad: 1832.1921  LR: 0.000018  \n","Epoch: [1][5000/5699] Elapsed 20m 7s (remain 2m 48s) Loss: 0.0007(0.0413) Grad: 577.2554  LR: 0.000018  \n","Epoch: [1][5100/5699] Elapsed 20m 32s (remain 2m 24s) Loss: 0.0002(0.0406) Grad: 288.3051  LR: 0.000018  \n","Epoch: [1][5200/5699] Elapsed 20m 56s (remain 2m 0s) Loss: 0.0183(0.0399) Grad: 44096.7578  LR: 0.000018  \n","Epoch: [1][5300/5699] Elapsed 21m 20s (remain 1m 36s) Loss: 0.0036(0.0393) Grad: 8319.4980  LR: 0.000018  \n","Epoch: [1][5400/5699] Elapsed 21m 44s (remain 1m 11s) Loss: 0.0001(0.0386) Grad: 106.0967  LR: 0.000018  \n","Epoch: [1][5500/5699] Elapsed 22m 9s (remain 0m 47s) Loss: 0.0020(0.0380) Grad: 1573.9307  LR: 0.000018  \n","Epoch: [1][5600/5699] Elapsed 22m 33s (remain 0m 23s) Loss: 0.0182(0.0374) Grad: 18167.3008  LR: 0.000018  \n","Epoch: [1][5698/5699] Elapsed 22m 57s (remain 0m 0s) Loss: 0.0103(0.0369) Grad: 16378.6758  LR: 0.000018  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 11m 16s) Loss: 0.0003(0.0003) \n","EVAL: [100/1451] Elapsed 0m 12s (remain 2m 46s) Loss: 0.0394(0.0057) \n","EVAL: [200/1451] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0102(0.0048) \n","EVAL: [300/1451] Elapsed 0m 36s (remain 2m 18s) Loss: 0.0001(0.0050) \n","EVAL: [400/1451] Elapsed 0m 48s (remain 2m 6s) Loss: 0.0001(0.0048) \n","EVAL: [500/1451] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0003(0.0048) \n","EVAL: [600/1451] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0049) \n","EVAL: [700/1451] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0956(0.0055) \n","EVAL: [800/1451] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0166(0.0063) \n","EVAL: [900/1451] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0016(0.0062) \n","EVAL: [1000/1451] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0186(0.0061) \n","EVAL: [1100/1451] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0273(0.0060) \n","EVAL: [1200/1451] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0011(0.0058) \n","EVAL: [1300/1451] Elapsed 2m 36s (remain 0m 18s) Loss: 0.0020(0.0056) \n","EVAL: [1400/1451] Elapsed 2m 48s (remain 0m 6s) Loss: 0.0006(0.0055) \n","EVAL: [1450/1451] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0001(0.0054) \n","Epoch 1 - avg_train_loss: 0.0369  avg_val_loss: 0.0054  time: 1557s\n","Epoch 1 - Score: 0.8222\n","Epoch 1 - Save Best Score: 0.8222 Model\n","Epoch: [2][0/5699] Elapsed 0m 0s (remain 60m 1s) Loss: 0.0088(0.0088) Grad: 29386.3340  LR: 0.000018  \n","Epoch: [2][100/5699] Elapsed 0m 29s (remain 26m 58s) Loss: 0.0002(0.0052) Grad: 622.2739  LR: 0.000018  \n","Epoch: [2][200/5699] Elapsed 0m 54s (remain 24m 56s) Loss: 0.0040(0.0048) Grad: 23204.1582  LR: 0.000018  \n","Epoch: [2][300/5699] Elapsed 1m 19s (remain 23m 40s) Loss: 0.0040(0.0050) Grad: 51813.0430  LR: 0.000018  \n","Epoch: [2][400/5699] Elapsed 1m 43s (remain 22m 50s) Loss: 0.0004(0.0047) Grad: 2347.7178  LR: 0.000017  \n","Epoch: [2][500/5699] Elapsed 2m 8s (remain 22m 9s) Loss: 0.0002(0.0046) Grad: 959.8391  LR: 0.000017  \n","Epoch: [2][600/5699] Elapsed 2m 32s (remain 21m 34s) Loss: 0.0027(0.0047) Grad: 8932.4492  LR: 0.000017  \n","Epoch: [2][700/5699] Elapsed 2m 57s (remain 21m 2s) Loss: 0.0004(0.0045) Grad: 1246.0557  LR: 0.000017  \n","Epoch: [2][800/5699] Elapsed 3m 21s (remain 20m 31s) Loss: 0.0021(0.0045) Grad: 6544.1377  LR: 0.000017  \n","Epoch: [2][900/5699] Elapsed 3m 45s (remain 20m 1s) Loss: 0.0193(0.0045) Grad: 117636.0859  LR: 0.000017  \n","Epoch: [2][1000/5699] Elapsed 4m 9s (remain 19m 33s) Loss: 0.0012(0.0045) Grad: 9017.7246  LR: 0.000017  \n","Epoch: [2][1100/5699] Elapsed 4m 34s (remain 19m 7s) Loss: 0.0000(0.0044) Grad: 39.0516  LR: 0.000017  \n","Epoch: [2][1200/5699] Elapsed 4m 59s (remain 18m 41s) Loss: 0.0037(0.0045) Grad: 5996.8633  LR: 0.000017  \n","Epoch: [2][1300/5699] Elapsed 5m 24s (remain 18m 15s) Loss: 0.0001(0.0044) Grad: 250.4940  LR: 0.000017  \n","Epoch: [2][1400/5699] Elapsed 5m 48s (remain 17m 50s) Loss: 0.0008(0.0045) Grad: 3483.1680  LR: 0.000017  \n","Epoch: [2][1500/5699] Elapsed 6m 13s (remain 17m 24s) Loss: 0.0003(0.0045) Grad: 2343.1597  LR: 0.000017  \n","Epoch: [2][1600/5699] Elapsed 6m 37s (remain 16m 58s) Loss: 0.0000(0.0046) Grad: 83.1217  LR: 0.000017  \n","Epoch: [2][1700/5699] Elapsed 7m 2s (remain 16m 32s) Loss: 0.0001(0.0047) Grad: 266.3357  LR: 0.000016  \n","Epoch: [2][1800/5699] Elapsed 7m 26s (remain 16m 6s) Loss: 0.0004(0.0048) Grad: 2008.8275  LR: 0.000016  \n","Epoch: [2][1900/5699] Elapsed 7m 51s (remain 15m 41s) Loss: 0.0001(0.0047) Grad: 357.9521  LR: 0.000016  \n","Epoch: [2][2000/5699] Elapsed 8m 15s (remain 15m 15s) Loss: 0.0117(0.0047) Grad: 28930.6465  LR: 0.000016  \n","Epoch: [2][2100/5699] Elapsed 8m 40s (remain 14m 50s) Loss: 0.0000(0.0047) Grad: 73.3142  LR: 0.000016  \n","Epoch: [2][2200/5699] Elapsed 9m 4s (remain 14m 25s) Loss: 0.0011(0.0046) Grad: 6396.3726  LR: 0.000016  \n","Epoch: [2][2300/5699] Elapsed 9m 28s (remain 14m 0s) Loss: 0.0000(0.0046) Grad: 116.3863  LR: 0.000016  \n","Epoch: [2][2400/5699] Elapsed 9m 53s (remain 13m 34s) Loss: 0.0041(0.0045) Grad: 6314.6460  LR: 0.000016  \n","Epoch: [2][2500/5699] Elapsed 10m 17s (remain 13m 9s) Loss: 0.0011(0.0045) Grad: 2730.2217  LR: 0.000016  \n","Epoch: [2][2600/5699] Elapsed 10m 41s (remain 12m 44s) Loss: 0.0000(0.0045) Grad: 96.9127  LR: 0.000016  \n","Epoch: [2][2700/5699] Elapsed 11m 5s (remain 12m 18s) Loss: 0.0000(0.0045) Grad: 52.5617  LR: 0.000016  \n","Epoch: [2][2800/5699] Elapsed 11m 29s (remain 11m 53s) Loss: 0.0140(0.0045) Grad: 20964.0273  LR: 0.000016  \n","Epoch: [2][2900/5699] Elapsed 11m 54s (remain 11m 28s) Loss: 0.0000(0.0044) Grad: 40.4323  LR: 0.000016  \n","Epoch: [2][3000/5699] Elapsed 12m 18s (remain 11m 4s) Loss: 0.0003(0.0045) Grad: 1526.2919  LR: 0.000015  \n","Epoch: [2][3100/5699] Elapsed 12m 42s (remain 10m 39s) Loss: 0.0000(0.0045) Grad: 47.1010  LR: 0.000015  \n","Epoch: [2][3200/5699] Elapsed 13m 7s (remain 10m 14s) Loss: 0.0020(0.0045) Grad: 7773.6299  LR: 0.000015  \n","Epoch: [2][3300/5699] Elapsed 13m 31s (remain 9m 49s) Loss: 0.0103(0.0045) Grad: 22459.6270  LR: 0.000015  \n","Epoch: [2][3400/5699] Elapsed 13m 55s (remain 9m 24s) Loss: 0.0001(0.0045) Grad: 351.1918  LR: 0.000015  \n","Epoch: [2][3500/5699] Elapsed 14m 19s (remain 8m 59s) Loss: 0.0183(0.0045) Grad: 34226.1484  LR: 0.000015  \n","Epoch: [2][3600/5699] Elapsed 14m 43s (remain 8m 34s) Loss: 0.0057(0.0045) Grad: 7668.1138  LR: 0.000015  \n","Epoch: [2][3700/5699] Elapsed 15m 7s (remain 8m 10s) Loss: 0.0096(0.0045) Grad: 13815.4336  LR: 0.000015  \n","Epoch: [2][3800/5699] Elapsed 15m 32s (remain 7m 45s) Loss: 0.0436(0.0044) Grad: 148673.7500  LR: 0.000015  \n","Epoch: [2][3900/5699] Elapsed 15m 56s (remain 7m 20s) Loss: 0.0022(0.0044) Grad: 11133.6924  LR: 0.000015  \n","Epoch: [2][4000/5699] Elapsed 16m 20s (remain 6m 56s) Loss: 0.0001(0.0044) Grad: 124.9300  LR: 0.000015  \n","Epoch: [2][4100/5699] Elapsed 16m 44s (remain 6m 31s) Loss: 0.0008(0.0043) Grad: 4098.2544  LR: 0.000015  \n","Epoch: [2][4200/5699] Elapsed 17m 8s (remain 6m 6s) Loss: 0.0001(0.0044) Grad: 1310.1718  LR: 0.000015  \n","Epoch: [2][4300/5699] Elapsed 17m 32s (remain 5m 42s) Loss: 0.0004(0.0044) Grad: 5854.2124  LR: 0.000014  \n","Epoch: [2][4400/5699] Elapsed 17m 56s (remain 5m 17s) Loss: 0.0000(0.0044) Grad: 37.5313  LR: 0.000014  \n","Epoch: [2][4500/5699] Elapsed 18m 20s (remain 4m 53s) Loss: 0.0007(0.0044) Grad: 15714.3340  LR: 0.000014  \n","Epoch: [2][4600/5699] Elapsed 18m 45s (remain 4m 28s) Loss: 0.0047(0.0044) Grad: 14157.7021  LR: 0.000014  \n","Epoch: [2][4700/5699] Elapsed 19m 10s (remain 4m 4s) Loss: 0.0000(0.0044) Grad: 37.2841  LR: 0.000014  \n","Epoch: [2][4800/5699] Elapsed 19m 35s (remain 3m 39s) Loss: 0.0000(0.0044) Grad: 61.1854  LR: 0.000014  \n","Epoch: [2][4900/5699] Elapsed 19m 59s (remain 3m 15s) Loss: 0.0051(0.0044) Grad: 28479.6973  LR: 0.000014  \n","Epoch: [2][5000/5699] Elapsed 20m 24s (remain 2m 50s) Loss: 0.0000(0.0044) Grad: 18.9738  LR: 0.000014  \n","Epoch: [2][5100/5699] Elapsed 20m 48s (remain 2m 26s) Loss: 0.0017(0.0044) Grad: 10664.4561  LR: 0.000014  \n","Epoch: [2][5200/5699] Elapsed 21m 12s (remain 2m 1s) Loss: 0.0002(0.0044) Grad: 5191.5542  LR: 0.000014  \n","Epoch: [2][5300/5699] Elapsed 21m 37s (remain 1m 37s) Loss: 0.0132(0.0044) Grad: 36695.2305  LR: 0.000014  \n","Epoch: [2][5400/5699] Elapsed 22m 1s (remain 1m 12s) Loss: 0.0004(0.0044) Grad: 1586.5649  LR: 0.000014  \n","Epoch: [2][5500/5699] Elapsed 22m 26s (remain 0m 48s) Loss: 0.0000(0.0044) Grad: 35.9938  LR: 0.000013  \n","Epoch: [2][5600/5699] Elapsed 22m 49s (remain 0m 23s) Loss: 0.0024(0.0043) Grad: 4625.4014  LR: 0.000013  \n","Epoch: [2][5698/5699] Elapsed 23m 13s (remain 0m 0s) Loss: 0.0004(0.0043) Grad: 4155.8057  LR: 0.000013  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 9m 39s) Loss: 0.0001(0.0001) \n","EVAL: [100/1451] Elapsed 0m 12s (remain 2m 46s) Loss: 0.0400(0.0042) \n","EVAL: [200/1451] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0039(0.0036) \n","EVAL: [300/1451] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0000(0.0038) \n","EVAL: [400/1451] Elapsed 0m 48s (remain 2m 7s) Loss: 0.0000(0.0036) \n","EVAL: [500/1451] Elapsed 1m 0s (remain 1m 55s) Loss: 0.0000(0.0038) \n","EVAL: [600/1451] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0036) \n","EVAL: [700/1451] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0647(0.0042) \n","EVAL: [800/1451] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0083(0.0047) \n","EVAL: [900/1451] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0001(0.0049) \n","EVAL: [1000/1451] Elapsed 2m 1s (remain 0m 54s) Loss: 0.0204(0.0047) \n","EVAL: [1100/1451] Elapsed 2m 13s (remain 0m 42s) Loss: 0.0251(0.0046) \n","EVAL: [1200/1451] Elapsed 2m 25s (remain 0m 30s) Loss: 0.0062(0.0044) \n","EVAL: [1300/1451] Elapsed 2m 37s (remain 0m 18s) Loss: 0.0014(0.0043) \n","EVAL: [1400/1451] Elapsed 2m 49s (remain 0m 6s) Loss: 0.0008(0.0043) \n","EVAL: [1450/1451] Elapsed 2m 55s (remain 0m 0s) Loss: 0.0000(0.0042) \n","Epoch 2 - avg_train_loss: 0.0043  avg_val_loss: 0.0042  time: 1573s\n","Epoch 2 - Score: 0.8663\n","Epoch 2 - Save Best Score: 0.8663 Model\n","Epoch: [3][0/5699] Elapsed 0m 0s (remain 55m 13s) Loss: 0.0006(0.0006) Grad: 6148.2744  LR: 0.000013  \n","Epoch: [3][100/5699] Elapsed 0m 28s (remain 26m 11s) Loss: 0.0020(0.0041) Grad: 2487.9746  LR: 0.000013  \n","Epoch: [3][200/5699] Elapsed 0m 54s (remain 24m 47s) Loss: 0.0001(0.0029) Grad: 131.9110  LR: 0.000013  \n","Epoch: [3][300/5699] Elapsed 1m 18s (remain 23m 27s) Loss: 0.0001(0.0032) Grad: 648.7836  LR: 0.000013  \n","Epoch: [3][400/5699] Elapsed 1m 42s (remain 22m 33s) Loss: 0.0000(0.0035) Grad: 100.1703  LR: 0.000013  \n","Epoch: [3][500/5699] Elapsed 2m 6s (remain 21m 53s) Loss: 0.0001(0.0035) Grad: 319.4601  LR: 0.000013  \n","Epoch: [3][600/5699] Elapsed 2m 30s (remain 21m 18s) Loss: 0.0000(0.0035) Grad: 94.0460  LR: 0.000013  \n","Epoch: [3][700/5699] Elapsed 2m 55s (remain 20m 47s) Loss: 0.0006(0.0034) Grad: 4497.0029  LR: 0.000013  \n","Epoch: [3][800/5699] Elapsed 3m 19s (remain 20m 20s) Loss: 0.0002(0.0033) Grad: 1198.1947  LR: 0.000013  \n","Epoch: [3][900/5699] Elapsed 3m 44s (remain 19m 53s) Loss: 0.0073(0.0036) Grad: 20242.7129  LR: 0.000013  \n","Epoch: [3][1000/5699] Elapsed 4m 8s (remain 19m 25s) Loss: 0.0001(0.0036) Grad: 464.8263  LR: 0.000013  \n","Epoch: [3][1100/5699] Elapsed 4m 32s (remain 18m 58s) Loss: 0.0027(0.0037) Grad: 28233.5410  LR: 0.000012  \n","Epoch: [3][1200/5699] Elapsed 4m 56s (remain 18m 30s) Loss: 0.0007(0.0036) Grad: 2040.3634  LR: 0.000012  \n","Epoch: [3][1300/5699] Elapsed 5m 20s (remain 18m 3s) Loss: 0.0159(0.0036) Grad: 46196.4375  LR: 0.000012  \n","Epoch: [3][1400/5699] Elapsed 5m 44s (remain 17m 36s) Loss: 0.0031(0.0036) Grad: 4264.4009  LR: 0.000012  \n","Epoch: [3][1500/5699] Elapsed 6m 8s (remain 17m 10s) Loss: 0.0000(0.0035) Grad: 38.1399  LR: 0.000012  \n","Epoch: [3][1600/5699] Elapsed 6m 32s (remain 16m 44s) Loss: 0.0023(0.0035) Grad: 3014.7561  LR: 0.000012  \n","Epoch: [3][1700/5699] Elapsed 6m 56s (remain 16m 18s) Loss: 0.0000(0.0035) Grad: 39.6042  LR: 0.000012  \n","Epoch: [3][1800/5699] Elapsed 7m 20s (remain 15m 53s) Loss: 0.0001(0.0036) Grad: 495.7781  LR: 0.000012  \n","Epoch: [3][1900/5699] Elapsed 7m 44s (remain 15m 28s) Loss: 0.0466(0.0036) Grad: 95097.1719  LR: 0.000012  \n","Epoch: [3][2000/5699] Elapsed 8m 8s (remain 15m 2s) Loss: 0.0000(0.0036) Grad: 103.1233  LR: 0.000012  \n","Epoch: [3][2100/5699] Elapsed 8m 32s (remain 14m 37s) Loss: 0.0009(0.0037) Grad: 5584.3960  LR: 0.000012  \n","Epoch: [3][2200/5699] Elapsed 8m 56s (remain 14m 12s) Loss: 0.0000(0.0036) Grad: 20.2785  LR: 0.000012  \n","Epoch: [3][2300/5699] Elapsed 9m 20s (remain 13m 48s) Loss: 0.0057(0.0036) Grad: 50503.2812  LR: 0.000012  \n","Epoch: [3][2400/5699] Elapsed 9m 45s (remain 13m 23s) Loss: 0.0000(0.0036) Grad: 16.1586  LR: 0.000011  \n","Epoch: [3][2500/5699] Elapsed 10m 9s (remain 12m 58s) Loss: 0.0000(0.0036) Grad: 40.1411  LR: 0.000011  \n","Epoch: [3][2600/5699] Elapsed 10m 33s (remain 12m 34s) Loss: 0.0001(0.0036) Grad: 1628.5562  LR: 0.000011  \n","Epoch: [3][2700/5699] Elapsed 10m 57s (remain 12m 9s) Loss: 0.0000(0.0036) Grad: 58.2691  LR: 0.000011  \n","Epoch: [3][2800/5699] Elapsed 11m 21s (remain 11m 44s) Loss: 0.0001(0.0035) Grad: 531.9642  LR: 0.000011  \n","Epoch: [3][2900/5699] Elapsed 11m 45s (remain 11m 20s) Loss: 0.0005(0.0035) Grad: 10931.5049  LR: 0.000011  \n","Epoch: [3][3000/5699] Elapsed 12m 9s (remain 10m 55s) Loss: 0.0001(0.0035) Grad: 348.7240  LR: 0.000011  \n","Epoch: [3][3100/5699] Elapsed 12m 33s (remain 10m 31s) Loss: 0.0009(0.0035) Grad: 3069.4609  LR: 0.000011  \n","Epoch: [3][3200/5699] Elapsed 12m 57s (remain 10m 6s) Loss: 0.0000(0.0035) Grad: 43.6351  LR: 0.000011  \n","Epoch: [3][3300/5699] Elapsed 13m 21s (remain 9m 42s) Loss: 0.0000(0.0035) Grad: 32.0925  LR: 0.000011  \n","Epoch: [3][3400/5699] Elapsed 13m 45s (remain 9m 17s) Loss: 0.0016(0.0034) Grad: 15610.4971  LR: 0.000011  \n","Epoch: [3][3500/5699] Elapsed 14m 9s (remain 8m 53s) Loss: 0.0067(0.0034) Grad: 8743.1260  LR: 0.000011  \n","Epoch: [3][3600/5699] Elapsed 14m 33s (remain 8m 28s) Loss: 0.0001(0.0034) Grad: 428.9945  LR: 0.000011  \n","Epoch: [3][3700/5699] Elapsed 14m 57s (remain 8m 4s) Loss: 0.0191(0.0034) Grad: 39270.5000  LR: 0.000010  \n","Epoch: [3][3800/5699] Elapsed 15m 22s (remain 7m 40s) Loss: 0.0002(0.0034) Grad: 875.6772  LR: 0.000010  \n","Epoch: [3][3900/5699] Elapsed 15m 47s (remain 7m 16s) Loss: 0.0001(0.0034) Grad: 6244.8608  LR: 0.000010  \n","Epoch: [3][4000/5699] Elapsed 16m 12s (remain 6m 52s) Loss: 0.0000(0.0034) Grad: 17.7898  LR: 0.000010  \n","Epoch: [3][4100/5699] Elapsed 16m 36s (remain 6m 28s) Loss: 0.0086(0.0034) Grad: 13482.6064  LR: 0.000010  \n","Epoch: [3][4200/5699] Elapsed 17m 1s (remain 6m 4s) Loss: 0.0126(0.0034) Grad: 44634.4258  LR: 0.000010  \n","Epoch: [3][4300/5699] Elapsed 17m 25s (remain 5m 39s) Loss: 0.0014(0.0034) Grad: 7978.2905  LR: 0.000010  \n","Epoch: [3][4400/5699] Elapsed 17m 50s (remain 5m 15s) Loss: 0.0001(0.0034) Grad: 2230.1897  LR: 0.000010  \n","Epoch: [3][4500/5699] Elapsed 18m 14s (remain 4m 51s) Loss: 0.0132(0.0034) Grad: 9713.6426  LR: 0.000010  \n","Epoch: [3][4600/5699] Elapsed 18m 39s (remain 4m 27s) Loss: 0.0001(0.0034) Grad: 380.8178  LR: 0.000010  \n","Epoch: [3][4700/5699] Elapsed 19m 4s (remain 4m 2s) Loss: 0.0309(0.0034) Grad: 69019.5000  LR: 0.000010  \n","Epoch: [3][4800/5699] Elapsed 19m 28s (remain 3m 38s) Loss: 0.0000(0.0034) Grad: 44.4024  LR: 0.000010  \n","Epoch: [3][4900/5699] Elapsed 19m 52s (remain 3m 14s) Loss: 0.0005(0.0034) Grad: 6021.5088  LR: 0.000010  \n","Epoch: [3][5000/5699] Elapsed 20m 17s (remain 2m 49s) Loss: 0.0420(0.0034) Grad: 19142.8770  LR: 0.000009  \n","Epoch: [3][5100/5699] Elapsed 20m 41s (remain 2m 25s) Loss: 0.0000(0.0034) Grad: 59.5071  LR: 0.000009  \n","Epoch: [3][5200/5699] Elapsed 21m 5s (remain 2m 1s) Loss: 0.0001(0.0034) Grad: 724.7731  LR: 0.000009  \n","Epoch: [3][5300/5699] Elapsed 21m 29s (remain 1m 36s) Loss: 0.0104(0.0034) Grad: 124876.2578  LR: 0.000009  \n","Epoch: [3][5400/5699] Elapsed 21m 54s (remain 1m 12s) Loss: 0.0040(0.0034) Grad: 13362.9922  LR: 0.000009  \n","Epoch: [3][5500/5699] Elapsed 22m 18s (remain 0m 48s) Loss: 0.0000(0.0034) Grad: 45.5261  LR: 0.000009  \n","Epoch: [3][5600/5699] Elapsed 22m 42s (remain 0m 23s) Loss: 0.0001(0.0034) Grad: 307.5257  LR: 0.000009  \n","Epoch: [3][5698/5699] Elapsed 23m 6s (remain 0m 0s) Loss: 0.0000(0.0034) Grad: 1010.0786  LR: 0.000009  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 9m 31s) Loss: 0.0000(0.0000) \n","EVAL: [100/1451] Elapsed 0m 12s (remain 2m 45s) Loss: 0.0443(0.0048) \n","EVAL: [200/1451] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0054(0.0041) \n","EVAL: [300/1451] Elapsed 0m 36s (remain 2m 18s) Loss: 0.0000(0.0043) \n","EVAL: [400/1451] Elapsed 0m 48s (remain 2m 6s) Loss: 0.0000(0.0041) \n","EVAL: [500/1451] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0000(0.0044) \n","EVAL: [600/1451] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0041) \n","EVAL: [700/1451] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0812(0.0046) \n","EVAL: [800/1451] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0027(0.0053) \n","EVAL: [900/1451] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0000(0.0054) \n","EVAL: [1000/1451] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0205(0.0052) \n","EVAL: [1100/1451] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0340(0.0051) \n","EVAL: [1200/1451] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0078(0.0049) \n","EVAL: [1300/1451] Elapsed 2m 36s (remain 0m 18s) Loss: 0.0029(0.0049) \n","EVAL: [1400/1451] Elapsed 2m 48s (remain 0m 6s) Loss: 0.0012(0.0048) \n","EVAL: [1450/1451] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0048) \n","Epoch 3 - avg_train_loss: 0.0034  avg_val_loss: 0.0048  time: 1565s\n","Epoch 3 - Score: 0.8732\n","Epoch 3 - Save Best Score: 0.8732 Model\n","Epoch: [4][0/5699] Elapsed 0m 0s (remain 52m 9s) Loss: 0.0001(0.0001) Grad: 1043.5417  LR: 0.000009  \n","Epoch: [4][100/5699] Elapsed 0m 28s (remain 26m 13s) Loss: 0.0000(0.0024) Grad: 374.3969  LR: 0.000009  \n","Epoch: [4][200/5699] Elapsed 0m 53s (remain 24m 34s) Loss: 0.0015(0.0028) Grad: 3314.5837  LR: 0.000009  \n","Epoch: [4][300/5699] Elapsed 1m 17s (remain 23m 12s) Loss: 0.0004(0.0035) Grad: 5001.9229  LR: 0.000009  \n","Epoch: [4][400/5699] Elapsed 1m 41s (remain 22m 20s) Loss: 0.0002(0.0035) Grad: 1583.5814  LR: 0.000009  \n","Epoch: [4][500/5699] Elapsed 2m 5s (remain 21m 39s) Loss: 0.0034(0.0032) Grad: 5474.4492  LR: 0.000008  \n","Epoch: [4][600/5699] Elapsed 2m 29s (remain 21m 4s) Loss: 0.0061(0.0032) Grad: 6989.3086  LR: 0.000008  \n","Epoch: [4][700/5699] Elapsed 2m 52s (remain 20m 31s) Loss: 0.0000(0.0030) Grad: 46.4439  LR: 0.000008  \n","Epoch: [4][800/5699] Elapsed 3m 16s (remain 20m 0s) Loss: 0.0000(0.0029) Grad: 44.7138  LR: 0.000008  \n","Epoch: [4][900/5699] Elapsed 3m 40s (remain 19m 32s) Loss: 0.0000(0.0029) Grad: 22.3699  LR: 0.000008  \n","Epoch: [4][1000/5699] Elapsed 4m 3s (remain 19m 4s) Loss: 0.0000(0.0028) Grad: 49.5229  LR: 0.000008  \n","Epoch: [4][1100/5699] Elapsed 4m 27s (remain 18m 37s) Loss: 0.0000(0.0027) Grad: 215.6449  LR: 0.000008  \n","Epoch: [4][1200/5699] Elapsed 4m 51s (remain 18m 11s) Loss: 0.0000(0.0027) Grad: 29.2790  LR: 0.000008  \n","Epoch: [4][1300/5699] Elapsed 5m 15s (remain 17m 45s) Loss: 0.0127(0.0028) Grad: 27265.8535  LR: 0.000008  \n","Epoch: [4][1400/5699] Elapsed 5m 38s (remain 17m 19s) Loss: 0.0000(0.0028) Grad: 168.4196  LR: 0.000008  \n","Epoch: [4][1500/5699] Elapsed 6m 2s (remain 16m 54s) Loss: 0.0000(0.0028) Grad: 26.0272  LR: 0.000008  \n","Epoch: [4][1600/5699] Elapsed 6m 26s (remain 16m 29s) Loss: 0.0000(0.0028) Grad: 15.6259  LR: 0.000008  \n","Epoch: [4][1700/5699] Elapsed 6m 50s (remain 16m 3s) Loss: 0.0000(0.0028) Grad: 50.6472  LR: 0.000008  \n","Epoch: [4][1800/5699] Elapsed 7m 13s (remain 15m 38s) Loss: 0.0099(0.0028) Grad: 28436.4043  LR: 0.000007  \n","Epoch: [4][1900/5699] Elapsed 7m 37s (remain 15m 14s) Loss: 0.0001(0.0027) Grad: 294.0804  LR: 0.000007  \n","Epoch: [4][2000/5699] Elapsed 8m 1s (remain 14m 49s) Loss: 0.0000(0.0027) Grad: 43.6212  LR: 0.000007  \n","Epoch: [4][2100/5699] Elapsed 8m 25s (remain 14m 25s) Loss: 0.0057(0.0027) Grad: 16188.2002  LR: 0.000007  \n","Epoch: [4][2200/5699] Elapsed 8m 48s (remain 14m 0s) Loss: 0.0000(0.0027) Grad: 101.0026  LR: 0.000007  \n","Epoch: [4][2300/5699] Elapsed 9m 12s (remain 13m 36s) Loss: 0.0000(0.0028) Grad: 91.9962  LR: 0.000007  \n","Epoch: [4][2400/5699] Elapsed 9m 36s (remain 13m 11s) Loss: 0.0000(0.0027) Grad: 17.2915  LR: 0.000007  \n","Epoch: [4][2500/5699] Elapsed 10m 0s (remain 12m 47s) Loss: 0.0040(0.0029) Grad: 27733.4531  LR: 0.000007  \n","Epoch: [4][2600/5699] Elapsed 10m 24s (remain 12m 23s) Loss: 0.0067(0.0029) Grad: 9137.8682  LR: 0.000007  \n","Epoch: [4][2700/5699] Elapsed 10m 48s (remain 11m 59s) Loss: 0.0000(0.0029) Grad: 192.1588  LR: 0.000007  \n","Epoch: [4][2800/5699] Elapsed 11m 11s (remain 11m 35s) Loss: 0.0000(0.0029) Grad: 26.9240  LR: 0.000007  \n","Epoch: [4][2900/5699] Elapsed 11m 35s (remain 11m 11s) Loss: 0.0125(0.0029) Grad: 16823.4707  LR: 0.000007  \n","Epoch: [4][3000/5699] Elapsed 11m 59s (remain 10m 47s) Loss: 0.0016(0.0029) Grad: 4273.3823  LR: 0.000007  \n","Epoch: [4][3100/5699] Elapsed 12m 24s (remain 10m 23s) Loss: 0.0014(0.0028) Grad: 8396.4551  LR: 0.000006  \n","Epoch: [4][3200/5699] Elapsed 12m 48s (remain 9m 59s) Loss: 0.0005(0.0028) Grad: 5496.4492  LR: 0.000006  \n","Epoch: [4][3300/5699] Elapsed 13m 12s (remain 9m 35s) Loss: 0.0000(0.0028) Grad: 43.0937  LR: 0.000006  \n","Epoch: [4][3400/5699] Elapsed 13m 36s (remain 9m 11s) Loss: 0.0001(0.0028) Grad: 551.9372  LR: 0.000006  \n","Epoch: [4][3500/5699] Elapsed 14m 0s (remain 8m 47s) Loss: 0.0001(0.0029) Grad: 624.5699  LR: 0.000006  \n","Epoch: [4][3600/5699] Elapsed 14m 23s (remain 8m 23s) Loss: 0.0000(0.0028) Grad: 8.2470  LR: 0.000006  \n","Epoch: [4][3700/5699] Elapsed 14m 47s (remain 7m 59s) Loss: 0.0000(0.0028) Grad: 15.5113  LR: 0.000006  \n","Epoch: [4][3800/5699] Elapsed 15m 11s (remain 7m 35s) Loss: 0.0001(0.0028) Grad: 402.8243  LR: 0.000006  \n","Epoch: [4][3900/5699] Elapsed 15m 35s (remain 7m 11s) Loss: 0.0000(0.0028) Grad: 5.3038  LR: 0.000006  \n","Epoch: [4][4000/5699] Elapsed 15m 59s (remain 6m 47s) Loss: 0.0030(0.0028) Grad: 16024.7402  LR: 0.000006  \n","Epoch: [4][4100/5699] Elapsed 16m 23s (remain 6m 23s) Loss: 0.0000(0.0028) Grad: 93.5000  LR: 0.000006  \n","Epoch: [4][4200/5699] Elapsed 16m 47s (remain 5m 59s) Loss: 0.0002(0.0028) Grad: 970.2991  LR: 0.000006  \n","Epoch: [4][4300/5699] Elapsed 17m 11s (remain 5m 35s) Loss: 0.0000(0.0028) Grad: 21.3376  LR: 0.000006  \n","Epoch: [4][4400/5699] Elapsed 17m 35s (remain 5m 11s) Loss: 0.0028(0.0028) Grad: 66570.2266  LR: 0.000005  \n","Epoch: [4][4500/5699] Elapsed 17m 59s (remain 4m 47s) Loss: 0.0011(0.0028) Grad: 7399.9961  LR: 0.000005  \n","Epoch: [4][4600/5699] Elapsed 18m 23s (remain 4m 23s) Loss: 0.0050(0.0029) Grad: 19889.6328  LR: 0.000005  \n","Epoch: [4][4700/5699] Elapsed 18m 47s (remain 3m 59s) Loss: 0.0450(0.0029) Grad: 73748.7422  LR: 0.000005  \n","Epoch: [4][4800/5699] Elapsed 19m 11s (remain 3m 35s) Loss: 0.0000(0.0029) Grad: 106.3379  LR: 0.000005  \n","Epoch: [4][4900/5699] Elapsed 19m 35s (remain 3m 11s) Loss: 0.0000(0.0029) Grad: 18.9048  LR: 0.000005  \n","Epoch: [4][5000/5699] Elapsed 19m 59s (remain 2m 47s) Loss: 0.0000(0.0029) Grad: 9.3923  LR: 0.000005  \n","Epoch: [4][5100/5699] Elapsed 20m 23s (remain 2m 23s) Loss: 0.0000(0.0029) Grad: 13.1880  LR: 0.000005  \n","Epoch: [4][5200/5699] Elapsed 20m 47s (remain 1m 59s) Loss: 0.0000(0.0029) Grad: 22.0776  LR: 0.000005  \n","Epoch: [4][5300/5699] Elapsed 21m 11s (remain 1m 35s) Loss: 0.0000(0.0029) Grad: 7.2377  LR: 0.000005  \n","Epoch: [4][5400/5699] Elapsed 21m 35s (remain 1m 11s) Loss: 0.0004(0.0029) Grad: 1727.5444  LR: 0.000005  \n","Epoch: [4][5500/5699] Elapsed 21m 59s (remain 0m 47s) Loss: 0.0000(0.0029) Grad: 76.4332  LR: 0.000005  \n","Epoch: [4][5600/5699] Elapsed 22m 23s (remain 0m 23s) Loss: 0.0024(0.0029) Grad: 2131.3892  LR: 0.000005  \n","Epoch: [4][5698/5699] Elapsed 22m 46s (remain 0m 0s) Loss: 0.0000(0.0029) Grad: 1025.0046  LR: 0.000004  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 9m 37s) Loss: 0.0000(0.0000) \n","EVAL: [100/1451] Elapsed 0m 12s (remain 2m 45s) Loss: 0.0424(0.0057) \n","EVAL: [200/1451] Elapsed 0m 24s (remain 2m 30s) Loss: 0.0078(0.0048) \n","EVAL: [300/1451] Elapsed 0m 36s (remain 2m 18s) Loss: 0.0000(0.0047) \n","EVAL: [400/1451] Elapsed 0m 48s (remain 2m 6s) Loss: 0.0000(0.0045) \n","EVAL: [500/1451] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0001(0.0046) \n","EVAL: [600/1451] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0043) \n","EVAL: [700/1451] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0815(0.0048) \n","EVAL: [800/1451] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0035(0.0054) \n","EVAL: [900/1451] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0001(0.0057) \n","EVAL: [1000/1451] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0236(0.0054) \n","EVAL: [1100/1451] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0317(0.0053) \n","EVAL: [1200/1451] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0031(0.0051) \n","EVAL: [1300/1451] Elapsed 2m 36s (remain 0m 18s) Loss: 0.0018(0.0050) \n","EVAL: [1400/1451] Elapsed 2m 48s (remain 0m 6s) Loss: 0.0009(0.0049) \n","EVAL: [1450/1451] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0049) \n","Epoch 4 - avg_train_loss: 0.0029  avg_val_loss: 0.0049  time: 1545s\n","Epoch 4 - Score: 0.8761\n","Epoch 4 - Save Best Score: 0.8761 Model\n","Epoch: [5][0/5699] Elapsed 0m 0s (remain 54m 58s) Loss: 0.0000(0.0000) Grad: 1004.6412  LR: 0.000004  \n","Epoch: [5][100/5699] Elapsed 0m 28s (remain 26m 2s) Loss: 0.0002(0.0023) Grad: 840.6690  LR: 0.000004  \n","Epoch: [5][200/5699] Elapsed 0m 53s (remain 24m 30s) Loss: 0.0011(0.0025) Grad: 11807.5391  LR: 0.000004  \n","Epoch: [5][300/5699] Elapsed 1m 17s (remain 23m 14s) Loss: 0.0021(0.0027) Grad: 6944.9453  LR: 0.000004  \n","Epoch: [5][400/5699] Elapsed 1m 41s (remain 22m 24s) Loss: 0.0000(0.0025) Grad: 14.5431  LR: 0.000004  \n","Epoch: [5][500/5699] Elapsed 2m 5s (remain 21m 44s) Loss: 0.0000(0.0024) Grad: 3.5950  LR: 0.000004  \n","Epoch: [5][600/5699] Elapsed 2m 30s (remain 21m 12s) Loss: 0.0000(0.0024) Grad: 316.2021  LR: 0.000004  \n","Epoch: [5][700/5699] Elapsed 2m 54s (remain 20m 41s) Loss: 0.0001(0.0023) Grad: 2786.5298  LR: 0.000004  \n","Epoch: [5][800/5699] Elapsed 3m 18s (remain 20m 12s) Loss: 0.0005(0.0022) Grad: 4995.0913  LR: 0.000004  \n","Epoch: [5][900/5699] Elapsed 3m 42s (remain 19m 43s) Loss: 0.0001(0.0023) Grad: 326.7875  LR: 0.000004  \n","Epoch: [5][1000/5699] Elapsed 4m 6s (remain 19m 16s) Loss: 0.0000(0.0023) Grad: 9.1601  LR: 0.000004  \n","Epoch: [5][1100/5699] Elapsed 4m 30s (remain 18m 49s) Loss: 0.0106(0.0024) Grad: 72060.1797  LR: 0.000004  \n","Epoch: [5][1200/5699] Elapsed 4m 54s (remain 18m 22s) Loss: 0.0013(0.0023) Grad: 4077.4041  LR: 0.000004  \n","Epoch: [5][1300/5699] Elapsed 5m 18s (remain 17m 56s) Loss: 0.0000(0.0023) Grad: 115.8937  LR: 0.000003  \n","Epoch: [5][1400/5699] Elapsed 5m 42s (remain 17m 30s) Loss: 0.0000(0.0023) Grad: 11.4345  LR: 0.000003  \n","Epoch: [5][1500/5699] Elapsed 6m 6s (remain 17m 5s) Loss: 0.0000(0.0023) Grad: 261.3623  LR: 0.000003  \n","Epoch: [5][1600/5699] Elapsed 6m 30s (remain 16m 39s) Loss: 0.0063(0.0023) Grad: 4870.1348  LR: 0.000003  \n","Epoch: [5][1700/5699] Elapsed 6m 54s (remain 16m 14s) Loss: 0.0000(0.0022) Grad: 12.6202  LR: 0.000003  \n","Epoch: [5][1800/5699] Elapsed 7m 18s (remain 15m 49s) Loss: 0.0000(0.0022) Grad: 18.9905  LR: 0.000003  \n","Epoch: [5][1900/5699] Elapsed 7m 42s (remain 15m 24s) Loss: 0.0001(0.0022) Grad: 343.4515  LR: 0.000003  \n","Epoch: [5][2000/5699] Elapsed 8m 6s (remain 14m 59s) Loss: 0.0013(0.0022) Grad: 8455.6787  LR: 0.000003  \n","Epoch: [5][2100/5699] Elapsed 8m 30s (remain 14m 34s) Loss: 0.0000(0.0022) Grad: 30.4220  LR: 0.000003  \n","Epoch: [5][2200/5699] Elapsed 8m 55s (remain 14m 10s) Loss: 0.0007(0.0022) Grad: 6230.8765  LR: 0.000003  \n","Epoch: [5][2300/5699] Elapsed 9m 19s (remain 13m 45s) Loss: 0.0001(0.0022) Grad: 112.1725  LR: 0.000003  \n","Epoch: [5][2400/5699] Elapsed 9m 43s (remain 13m 20s) Loss: 0.0015(0.0023) Grad: 7437.2773  LR: 0.000003  \n","Epoch: [5][2500/5699] Elapsed 10m 7s (remain 12m 56s) Loss: 0.0000(0.0022) Grad: 12.0389  LR: 0.000002  \n","Epoch: [5][2600/5699] Elapsed 10m 31s (remain 12m 31s) Loss: 0.0000(0.0023) Grad: 24.5216  LR: 0.000002  \n","Epoch: [5][2700/5699] Elapsed 10m 55s (remain 12m 7s) Loss: 0.0001(0.0022) Grad: 190.8715  LR: 0.000002  \n","Epoch: [5][2800/5699] Elapsed 11m 19s (remain 11m 42s) Loss: 0.0022(0.0022) Grad: 15318.6240  LR: 0.000002  \n","Epoch: [5][2900/5699] Elapsed 11m 43s (remain 11m 18s) Loss: 0.0002(0.0022) Grad: 1151.8485  LR: 0.000002  \n","Epoch: [5][3000/5699] Elapsed 12m 7s (remain 10m 54s) Loss: 0.0000(0.0024) Grad: 19.4808  LR: 0.000002  \n","Epoch: [5][3100/5699] Elapsed 12m 31s (remain 10m 29s) Loss: 0.0000(0.0024) Grad: 86.9625  LR: 0.000002  \n","Epoch: [5][3200/5699] Elapsed 12m 55s (remain 10m 5s) Loss: 0.0000(0.0024) Grad: 37.3077  LR: 0.000002  \n","Epoch: [5][3300/5699] Elapsed 13m 19s (remain 9m 41s) Loss: 0.0076(0.0024) Grad: 34670.8789  LR: 0.000002  \n","Epoch: [5][3400/5699] Elapsed 13m 43s (remain 9m 16s) Loss: 0.0000(0.0024) Grad: 26.0922  LR: 0.000002  \n","Epoch: [5][3500/5699] Elapsed 14m 7s (remain 8m 52s) Loss: 0.0159(0.0024) Grad: 53226.1250  LR: 0.000002  \n","Epoch: [5][3600/5699] Elapsed 14m 32s (remain 8m 28s) Loss: 0.0000(0.0025) Grad: 31.0747  LR: 0.000002  \n","Epoch: [5][3700/5699] Elapsed 14m 56s (remain 8m 3s) Loss: 0.0001(0.0024) Grad: 270.8058  LR: 0.000002  \n","Epoch: [5][3800/5699] Elapsed 15m 20s (remain 7m 39s) Loss: 0.0107(0.0025) Grad: 59973.6016  LR: 0.000001  \n","Epoch: [5][3900/5699] Elapsed 15m 44s (remain 7m 15s) Loss: 0.0000(0.0025) Grad: 45.8636  LR: 0.000001  \n","Epoch: [5][4000/5699] Elapsed 16m 8s (remain 6m 50s) Loss: 0.0122(0.0025) Grad: 21945.2480  LR: 0.000001  \n","Epoch: [5][4100/5699] Elapsed 16m 32s (remain 6m 26s) Loss: 0.0002(0.0025) Grad: 2190.6755  LR: 0.000001  \n","Epoch: [5][4200/5699] Elapsed 16m 56s (remain 6m 2s) Loss: 0.0000(0.0025) Grad: 60.2319  LR: 0.000001  \n","Epoch: [5][4300/5699] Elapsed 17m 21s (remain 5m 38s) Loss: 0.0003(0.0025) Grad: 3177.6475  LR: 0.000001  \n","Epoch: [5][4400/5699] Elapsed 17m 45s (remain 5m 14s) Loss: 0.0030(0.0025) Grad: 17022.1992  LR: 0.000001  \n","Epoch: [5][4500/5699] Elapsed 18m 9s (remain 4m 50s) Loss: 0.0000(0.0025) Grad: 56.9972  LR: 0.000001  \n","Epoch: [5][4600/5699] Elapsed 18m 33s (remain 4m 25s) Loss: 0.0005(0.0024) Grad: 7135.5312  LR: 0.000001  \n","Epoch: [5][4700/5699] Elapsed 18m 57s (remain 4m 1s) Loss: 0.0000(0.0024) Grad: 15.8563  LR: 0.000001  \n","Epoch: [5][4800/5699] Elapsed 19m 21s (remain 3m 37s) Loss: 0.0000(0.0024) Grad: 8.7659  LR: 0.000001  \n","Epoch: [5][4900/5699] Elapsed 19m 45s (remain 3m 13s) Loss: 0.0000(0.0024) Grad: 57.7358  LR: 0.000001  \n","Epoch: [5][5000/5699] Elapsed 20m 9s (remain 2m 48s) Loss: 0.0001(0.0024) Grad: 675.7855  LR: 0.000001  \n","Epoch: [5][5100/5699] Elapsed 20m 33s (remain 2m 24s) Loss: 0.0001(0.0024) Grad: 260.4205  LR: 0.000000  \n","Epoch: [5][5200/5699] Elapsed 20m 57s (remain 2m 0s) Loss: 0.0079(0.0024) Grad: 6864.9575  LR: 0.000000  \n","Epoch: [5][5300/5699] Elapsed 21m 21s (remain 1m 36s) Loss: 0.0000(0.0025) Grad: 229.5800  LR: 0.000000  \n","Epoch: [5][5400/5699] Elapsed 21m 45s (remain 1m 12s) Loss: 0.0000(0.0025) Grad: 4.2555  LR: 0.000000  \n","Epoch: [5][5500/5699] Elapsed 22m 9s (remain 0m 47s) Loss: 0.0321(0.0024) Grad: 42945.1953  LR: 0.000000  \n","Epoch: [5][5600/5699] Elapsed 22m 33s (remain 0m 23s) Loss: 0.0000(0.0024) Grad: 524.0225  LR: 0.000000  \n","Epoch: [5][5698/5699] Elapsed 22m 57s (remain 0m 0s) Loss: 0.0000(0.0024) Grad: 1001.3297  LR: 0.000000  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 9m 22s) Loss: 0.0000(0.0000) \n","EVAL: [100/1451] Elapsed 0m 12s (remain 2m 45s) Loss: 0.0440(0.0056) \n","EVAL: [200/1451] Elapsed 0m 24s (remain 2m 30s) Loss: 0.0070(0.0047) \n","EVAL: [300/1451] Elapsed 0m 36s (remain 2m 17s) Loss: 0.0000(0.0048) \n","EVAL: [400/1451] Elapsed 0m 48s (remain 2m 6s) Loss: 0.0000(0.0045) \n","EVAL: [500/1451] Elapsed 1m 0s (remain 1m 53s) Loss: 0.0000(0.0047) \n","EVAL: [600/1451] Elapsed 1m 12s (remain 1m 41s) Loss: 0.0000(0.0043) \n","EVAL: [700/1451] Elapsed 1m 24s (remain 1m 29s) Loss: 0.0900(0.0047) \n","EVAL: [800/1451] Elapsed 1m 35s (remain 1m 17s) Loss: 0.0030(0.0054) \n","EVAL: [900/1451] Elapsed 1m 47s (remain 1m 5s) Loss: 0.0000(0.0057) \n","EVAL: [1000/1451] Elapsed 1m 59s (remain 0m 53s) Loss: 0.0277(0.0055) \n","EVAL: [1100/1451] Elapsed 2m 11s (remain 0m 41s) Loss: 0.0368(0.0054) \n","EVAL: [1200/1451] Elapsed 2m 23s (remain 0m 29s) Loss: 0.0030(0.0052) \n","EVAL: [1300/1451] Elapsed 2m 35s (remain 0m 17s) Loss: 0.0016(0.0051) \n","EVAL: [1400/1451] Elapsed 2m 47s (remain 0m 5s) Loss: 0.0014(0.0050) \n","EVAL: [1450/1451] Elapsed 2m 53s (remain 0m 0s) Loss: 0.0000(0.0050) \n","Epoch 5 - avg_train_loss: 0.0024  avg_val_loss: 0.0050  time: 1556s\n","Epoch 5 - Score: 0.8820\n","Epoch 5 - Save Best Score: 0.8820 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5703] Elapsed 0m 0s (remain 70m 24s) Loss: 0.5063(0.5063) Grad: 165383.0469  LR: 0.000000  \n","Epoch: [1][100/5703] Elapsed 0m 27s (remain 25m 30s) Loss: 0.1674(0.2514) Grad: 52010.3242  LR: 0.000001  \n","Epoch: [1][200/5703] Elapsed 0m 51s (remain 23m 37s) Loss: 0.3058(0.2661) Grad: 59101.8047  LR: 0.000001  \n","Epoch: [1][300/5703] Elapsed 1m 15s (remain 22m 38s) Loss: 0.2739(0.2566) Grad: 27384.0039  LR: 0.000002  \n","Epoch: [1][400/5703] Elapsed 1m 39s (remain 21m 58s) Loss: 0.1039(0.2403) Grad: 10248.3232  LR: 0.000003  \n","Epoch: [1][500/5703] Elapsed 2m 3s (remain 21m 26s) Loss: 0.1758(0.2203) Grad: 26207.1426  LR: 0.000004  \n","Epoch: [1][600/5703] Elapsed 2m 28s (remain 20m 57s) Loss: 0.0420(0.1951) Grad: 8997.8604  LR: 0.000004  \n","Epoch: [1][700/5703] Elapsed 2m 52s (remain 20m 31s) Loss: 0.0317(0.1705) Grad: 2169.2839  LR: 0.000005  \n","Epoch: [1][800/5703] Elapsed 3m 16s (remain 20m 4s) Loss: 0.0128(0.1518) Grad: 1819.0210  LR: 0.000006  \n","Epoch: [1][900/5703] Elapsed 3m 41s (remain 19m 38s) Loss: 0.0139(0.1372) Grad: 565.6723  LR: 0.000006  \n","Epoch: [1][1000/5703] Elapsed 4m 5s (remain 19m 12s) Loss: 0.0189(0.1254) Grad: 1073.4895  LR: 0.000007  \n","Epoch: [1][1100/5703] Elapsed 4m 29s (remain 18m 47s) Loss: 0.0082(0.1157) Grad: 1049.2574  LR: 0.000008  \n","Epoch: [1][1200/5703] Elapsed 4m 54s (remain 18m 22s) Loss: 0.0059(0.1074) Grad: 578.5864  LR: 0.000008  \n","Epoch: [1][1300/5703] Elapsed 5m 18s (remain 17m 57s) Loss: 0.0086(0.1001) Grad: 1178.3668  LR: 0.000009  \n","Epoch: [1][1400/5703] Elapsed 5m 42s (remain 17m 32s) Loss: 0.0071(0.0939) Grad: 3002.6721  LR: 0.000010  \n","Epoch: [1][1500/5703] Elapsed 6m 6s (remain 17m 7s) Loss: 0.0047(0.0882) Grad: 6774.0693  LR: 0.000011  \n","Epoch: [1][1600/5703] Elapsed 6m 31s (remain 16m 42s) Loss: 0.0018(0.0833) Grad: 557.1898  LR: 0.000011  \n","Epoch: [1][1700/5703] Elapsed 6m 55s (remain 16m 17s) Loss: 0.0031(0.0790) Grad: 1165.7894  LR: 0.000012  \n","Epoch: [1][1800/5703] Elapsed 7m 19s (remain 15m 52s) Loss: 0.0071(0.0751) Grad: 2758.9453  LR: 0.000013  \n","Epoch: [1][1900/5703] Elapsed 7m 43s (remain 15m 27s) Loss: 0.0003(0.0717) Grad: 435.6849  LR: 0.000013  \n","Epoch: [1][2000/5703] Elapsed 8m 7s (remain 15m 2s) Loss: 0.0047(0.0685) Grad: 3212.8020  LR: 0.000014  \n","Epoch: [1][2100/5703] Elapsed 8m 32s (remain 14m 37s) Loss: 0.0120(0.0657) Grad: 3622.2361  LR: 0.000015  \n","Epoch: [1][2200/5703] Elapsed 8m 56s (remain 14m 13s) Loss: 0.0135(0.0631) Grad: 8036.8657  LR: 0.000015  \n","Epoch: [1][2300/5703] Elapsed 9m 20s (remain 13m 48s) Loss: 0.0010(0.0606) Grad: 499.0972  LR: 0.000016  \n","Epoch: [1][2400/5703] Elapsed 9m 44s (remain 13m 24s) Loss: 0.0013(0.0584) Grad: 895.4147  LR: 0.000017  \n","Epoch: [1][2500/5703] Elapsed 10m 9s (remain 12m 59s) Loss: 0.0051(0.0563) Grad: 6682.8569  LR: 0.000018  \n","Epoch: [1][2600/5703] Elapsed 10m 33s (remain 12m 35s) Loss: 0.0068(0.0544) Grad: 1909.4733  LR: 0.000018  \n","Epoch: [1][2700/5703] Elapsed 10m 57s (remain 12m 10s) Loss: 0.0096(0.0526) Grad: 3195.5393  LR: 0.000019  \n","Epoch: [1][2800/5703] Elapsed 11m 21s (remain 11m 46s) Loss: 0.0001(0.0510) Grad: 61.3937  LR: 0.000020  \n","Epoch: [1][2900/5703] Elapsed 11m 46s (remain 11m 21s) Loss: 0.0121(0.0494) Grad: 4898.7188  LR: 0.000020  \n","Epoch: [1][3000/5703] Elapsed 12m 10s (remain 10m 57s) Loss: 0.0031(0.0480) Grad: 2860.7981  LR: 0.000020  \n","Epoch: [1][3100/5703] Elapsed 12m 34s (remain 10m 32s) Loss: 0.0024(0.0466) Grad: 3412.8965  LR: 0.000020  \n","Epoch: [1][3200/5703] Elapsed 12m 58s (remain 10m 8s) Loss: 0.0003(0.0454) Grad: 326.1258  LR: 0.000020  \n","Epoch: [1][3300/5703] Elapsed 13m 22s (remain 9m 44s) Loss: 0.0017(0.0442) Grad: 1002.9542  LR: 0.000020  \n","Epoch: [1][3400/5703] Elapsed 13m 47s (remain 9m 19s) Loss: 0.0005(0.0431) Grad: 1516.5187  LR: 0.000020  \n","Epoch: [1][3500/5703] Elapsed 14m 11s (remain 8m 55s) Loss: 0.0001(0.0420) Grad: 90.8141  LR: 0.000019  \n","Epoch: [1][3600/5703] Elapsed 14m 35s (remain 8m 31s) Loss: 0.0093(0.0410) Grad: 3814.9937  LR: 0.000019  \n","Epoch: [1][3700/5703] Elapsed 14m 59s (remain 8m 6s) Loss: 0.0043(0.0400) Grad: 2262.1404  LR: 0.000019  \n","Epoch: [1][3800/5703] Elapsed 15m 24s (remain 7m 42s) Loss: 0.0001(0.0391) Grad: 109.4466  LR: 0.000019  \n","Epoch: [1][3900/5703] Elapsed 15m 48s (remain 7m 18s) Loss: 0.0031(0.0382) Grad: 1870.6306  LR: 0.000019  \n","Epoch: [1][4000/5703] Elapsed 16m 12s (remain 6m 53s) Loss: 0.0010(0.0374) Grad: 709.7171  LR: 0.000019  \n","Epoch: [1][4100/5703] Elapsed 16m 37s (remain 6m 29s) Loss: 0.0052(0.0366) Grad: 6218.8276  LR: 0.000019  \n","Epoch: [1][4200/5703] Elapsed 17m 1s (remain 6m 5s) Loss: 0.0048(0.0358) Grad: 2675.9756  LR: 0.000019  \n","Epoch: [1][4300/5703] Elapsed 17m 25s (remain 5m 40s) Loss: 0.0075(0.0351) Grad: 48563.4062  LR: 0.000019  \n","Epoch: [1][4400/5703] Elapsed 17m 50s (remain 5m 16s) Loss: 0.0105(0.0344) Grad: 8399.0410  LR: 0.000019  \n","Epoch: [1][4500/5703] Elapsed 18m 14s (remain 4m 52s) Loss: 0.0000(0.0338) Grad: 32.0358  LR: 0.000019  \n","Epoch: [1][4600/5703] Elapsed 18m 38s (remain 4m 28s) Loss: 0.0011(0.0331) Grad: 1144.2487  LR: 0.000019  \n","Epoch: [1][4700/5703] Elapsed 19m 3s (remain 4m 3s) Loss: 0.0025(0.0325) Grad: 698.9832  LR: 0.000019  \n","Epoch: [1][4800/5703] Elapsed 19m 27s (remain 3m 39s) Loss: 0.0047(0.0319) Grad: 13408.1523  LR: 0.000018  \n","Epoch: [1][4900/5703] Elapsed 19m 52s (remain 3m 15s) Loss: 0.0099(0.0313) Grad: 5721.6494  LR: 0.000018  \n","Epoch: [1][5000/5703] Elapsed 20m 16s (remain 2m 50s) Loss: 0.0035(0.0308) Grad: 1711.5215  LR: 0.000018  \n","Epoch: [1][5100/5703] Elapsed 20m 40s (remain 2m 26s) Loss: 0.0036(0.0303) Grad: 5453.1929  LR: 0.000018  \n","Epoch: [1][5200/5703] Elapsed 21m 5s (remain 2m 2s) Loss: 0.0032(0.0298) Grad: 1359.7446  LR: 0.000018  \n","Epoch: [1][5300/5703] Elapsed 21m 29s (remain 1m 37s) Loss: 0.0003(0.0293) Grad: 415.3329  LR: 0.000018  \n","Epoch: [1][5400/5703] Elapsed 21m 54s (remain 1m 13s) Loss: 0.0015(0.0288) Grad: 1689.7844  LR: 0.000018  \n","Epoch: [1][5500/5703] Elapsed 22m 18s (remain 0m 49s) Loss: 0.0001(0.0283) Grad: 1100.7162  LR: 0.000018  \n","Epoch: [1][5600/5703] Elapsed 22m 42s (remain 0m 24s) Loss: 0.0058(0.0279) Grad: 1770.7991  LR: 0.000018  \n","Epoch: [1][5700/5703] Elapsed 23m 7s (remain 0m 0s) Loss: 0.0023(0.0275) Grad: 552.8029  LR: 0.000018  \n","Epoch: [1][5702/5703] Elapsed 23m 7s (remain 0m 0s) Loss: 0.0076(0.0275) Grad: 3064.2935  LR: 0.000018  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 10m 51s) Loss: 0.0001(0.0001) \n","EVAL: [100/1447] Elapsed 0m 12s (remain 2m 47s) Loss: 0.0021(0.0036) \n","EVAL: [200/1447] Elapsed 0m 24s (remain 2m 33s) Loss: 0.0047(0.0041) \n","EVAL: [300/1447] Elapsed 0m 36s (remain 2m 20s) Loss: 0.0098(0.0056) \n","EVAL: [400/1447] Elapsed 0m 49s (remain 2m 7s) Loss: 0.0000(0.0058) \n","EVAL: [500/1447] Elapsed 1m 1s (remain 1m 55s) Loss: 0.0003(0.0058) \n","EVAL: [600/1447] Elapsed 1m 13s (remain 1m 43s) Loss: 0.0000(0.0055) \n","EVAL: [700/1447] Elapsed 1m 25s (remain 1m 30s) Loss: 0.0001(0.0053) \n","EVAL: [800/1447] Elapsed 1m 37s (remain 1m 18s) Loss: 0.0000(0.0053) \n","EVAL: [900/1447] Elapsed 1m 49s (remain 1m 6s) Loss: 0.0199(0.0057) \n","EVAL: [1000/1447] Elapsed 2m 1s (remain 0m 54s) Loss: 0.0020(0.0059) \n","EVAL: [1100/1447] Elapsed 2m 13s (remain 0m 42s) Loss: 0.0193(0.0059) \n","EVAL: [1200/1447] Elapsed 2m 25s (remain 0m 29s) Loss: 0.0214(0.0058) \n","EVAL: [1300/1447] Elapsed 2m 37s (remain 0m 17s) Loss: 0.0000(0.0056) \n","EVAL: [1400/1447] Elapsed 2m 49s (remain 0m 5s) Loss: 0.0000(0.0053) \n","EVAL: [1446/1447] Elapsed 2m 55s (remain 0m 0s) Loss: 0.0001(0.0052) \n","Epoch 1 - avg_train_loss: 0.0275  avg_val_loss: 0.0052  time: 1568s\n","Epoch 1 - Score: 0.8413\n","Epoch 1 - Save Best Score: 0.8413 Model\n","Epoch: [2][0/5703] Elapsed 0m 0s (remain 60m 40s) Loss: 0.0000(0.0000) Grad: 995.4301  LR: 0.000018  \n","Epoch: [2][100/5703] Elapsed 0m 28s (remain 26m 41s) Loss: 0.0040(0.0042) Grad: 8781.4209  LR: 0.000018  \n","Epoch: [2][200/5703] Elapsed 0m 55s (remain 25m 8s) Loss: 0.0000(0.0036) Grad: 63.9467  LR: 0.000018  \n","Epoch: [2][300/5703] Elapsed 1m 19s (remain 23m 49s) Loss: 0.0014(0.0040) Grad: 3236.7930  LR: 0.000018  \n","Epoch: [2][400/5703] Elapsed 1m 44s (remain 22m 57s) Loss: 0.0010(0.0039) Grad: 6433.5347  LR: 0.000017  \n","Epoch: [2][500/5703] Elapsed 2m 8s (remain 22m 16s) Loss: 0.0023(0.0041) Grad: 3398.4397  LR: 0.000017  \n","Epoch: [2][600/5703] Elapsed 2m 33s (remain 21m 40s) Loss: 0.0016(0.0043) Grad: 2450.5488  LR: 0.000017  \n","Epoch: [2][700/5703] Elapsed 2m 57s (remain 21m 8s) Loss: 0.0001(0.0043) Grad: 136.1160  LR: 0.000017  \n","Epoch: [2][800/5703] Elapsed 3m 22s (remain 20m 39s) Loss: 0.0000(0.0042) Grad: 25.1238  LR: 0.000017  \n","Epoch: [2][900/5703] Elapsed 3m 47s (remain 20m 9s) Loss: 0.0002(0.0041) Grad: 2495.2036  LR: 0.000017  \n","Epoch: [2][1000/5703] Elapsed 4m 11s (remain 19m 41s) Loss: 0.0016(0.0044) Grad: 14258.5635  LR: 0.000017  \n","Epoch: [2][1100/5703] Elapsed 4m 36s (remain 19m 14s) Loss: 0.0000(0.0043) Grad: 38.4007  LR: 0.000017  \n","Epoch: [2][1200/5703] Elapsed 5m 0s (remain 18m 47s) Loss: 0.0000(0.0043) Grad: 52.9888  LR: 0.000017  \n","Epoch: [2][1300/5703] Elapsed 5m 25s (remain 18m 21s) Loss: 0.0000(0.0042) Grad: 20.3962  LR: 0.000017  \n","Epoch: [2][1400/5703] Elapsed 5m 50s (remain 17m 54s) Loss: 0.0032(0.0042) Grad: 4629.9180  LR: 0.000017  \n","Epoch: [2][1500/5703] Elapsed 6m 14s (remain 17m 28s) Loss: 0.0000(0.0041) Grad: 96.7024  LR: 0.000017  \n","Epoch: [2][1600/5703] Elapsed 6m 39s (remain 17m 2s) Loss: 0.0000(0.0040) Grad: 14.0089  LR: 0.000017  \n","Epoch: [2][1700/5703] Elapsed 7m 3s (remain 16m 36s) Loss: 0.0004(0.0040) Grad: 5554.1768  LR: 0.000016  \n","Epoch: [2][1800/5703] Elapsed 7m 28s (remain 16m 10s) Loss: 0.0009(0.0039) Grad: 9006.6670  LR: 0.000016  \n","Epoch: [2][1900/5703] Elapsed 7m 52s (remain 15m 44s) Loss: 0.0014(0.0040) Grad: 19915.1621  LR: 0.000016  \n","Epoch: [2][2000/5703] Elapsed 8m 16s (remain 15m 19s) Loss: 0.0001(0.0040) Grad: 144.0148  LR: 0.000016  \n","Epoch: [2][2100/5703] Elapsed 8m 41s (remain 14m 54s) Loss: 0.0055(0.0040) Grad: 7130.9238  LR: 0.000016  \n","Epoch: [2][2200/5703] Elapsed 9m 5s (remain 14m 28s) Loss: 0.0000(0.0039) Grad: 58.3768  LR: 0.000016  \n","Epoch: [2][2300/5703] Elapsed 9m 30s (remain 14m 3s) Loss: 0.0001(0.0039) Grad: 786.8982  LR: 0.000016  \n","Epoch: [2][2400/5703] Elapsed 9m 54s (remain 13m 38s) Loss: 0.0000(0.0039) Grad: 427.3071  LR: 0.000016  \n","Epoch: [2][2500/5703] Elapsed 10m 19s (remain 13m 12s) Loss: 0.0010(0.0039) Grad: 4935.4399  LR: 0.000016  \n","Epoch: [2][2600/5703] Elapsed 10m 43s (remain 12m 47s) Loss: 0.0017(0.0039) Grad: 7350.4482  LR: 0.000016  \n","Epoch: [2][2700/5703] Elapsed 11m 8s (remain 12m 22s) Loss: 0.0000(0.0039) Grad: 84.8325  LR: 0.000016  \n","Epoch: [2][2800/5703] Elapsed 11m 32s (remain 11m 57s) Loss: 0.0017(0.0039) Grad: 10241.1543  LR: 0.000016  \n","Epoch: [2][2900/5703] Elapsed 11m 57s (remain 11m 32s) Loss: 0.0115(0.0039) Grad: 39222.3750  LR: 0.000016  \n","Epoch: [2][3000/5703] Elapsed 12m 21s (remain 11m 7s) Loss: 0.0300(0.0039) Grad: 28304.8711  LR: 0.000015  \n","Epoch: [2][3100/5703] Elapsed 12m 45s (remain 10m 42s) Loss: 0.0000(0.0040) Grad: 33.8182  LR: 0.000015  \n","Epoch: [2][3200/5703] Elapsed 13m 10s (remain 10m 17s) Loss: 0.0041(0.0040) Grad: 30380.4922  LR: 0.000015  \n","Epoch: [2][3300/5703] Elapsed 13m 34s (remain 9m 52s) Loss: 0.0002(0.0041) Grad: 586.3026  LR: 0.000015  \n","Epoch: [2][3400/5703] Elapsed 13m 59s (remain 9m 28s) Loss: 0.0000(0.0041) Grad: 54.0519  LR: 0.000015  \n","Epoch: [2][3500/5703] Elapsed 14m 23s (remain 9m 3s) Loss: 0.0000(0.0041) Grad: 377.9645  LR: 0.000015  \n","Epoch: [2][3600/5703] Elapsed 14m 48s (remain 8m 38s) Loss: 0.0028(0.0041) Grad: 9568.9287  LR: 0.000015  \n","Epoch: [2][3700/5703] Elapsed 15m 12s (remain 8m 13s) Loss: 0.0383(0.0041) Grad: 26396.5156  LR: 0.000015  \n","Epoch: [2][3800/5703] Elapsed 15m 36s (remain 7m 48s) Loss: 0.0000(0.0041) Grad: 1463.3159  LR: 0.000015  \n","Epoch: [2][3900/5703] Elapsed 16m 1s (remain 7m 24s) Loss: 0.0003(0.0041) Grad: 1082.5588  LR: 0.000015  \n","Epoch: [2][4000/5703] Elapsed 16m 25s (remain 6m 59s) Loss: 0.0027(0.0041) Grad: 20482.3398  LR: 0.000015  \n","Epoch: [2][4100/5703] Elapsed 16m 50s (remain 6m 34s) Loss: 0.0006(0.0041) Grad: 2411.4177  LR: 0.000015  \n","Epoch: [2][4200/5703] Elapsed 17m 14s (remain 6m 9s) Loss: 0.0025(0.0041) Grad: 3711.9617  LR: 0.000015  \n","Epoch: [2][4300/5703] Elapsed 17m 38s (remain 5m 45s) Loss: 0.0000(0.0041) Grad: 9.4270  LR: 0.000014  \n","Epoch: [2][4400/5703] Elapsed 18m 3s (remain 5m 20s) Loss: 0.0029(0.0041) Grad: 4243.1631  LR: 0.000014  \n","Epoch: [2][4500/5703] Elapsed 18m 27s (remain 4m 55s) Loss: 0.0001(0.0041) Grad: 1545.7841  LR: 0.000014  \n","Epoch: [2][4600/5703] Elapsed 18m 51s (remain 4m 31s) Loss: 0.0003(0.0041) Grad: 1629.5039  LR: 0.000014  \n","Epoch: [2][4700/5703] Elapsed 19m 16s (remain 4m 6s) Loss: 0.0003(0.0041) Grad: 2927.7046  LR: 0.000014  \n","Epoch: [2][4800/5703] Elapsed 19m 40s (remain 3m 41s) Loss: 0.0001(0.0041) Grad: 257.4524  LR: 0.000014  \n","Epoch: [2][4900/5703] Elapsed 20m 4s (remain 3m 17s) Loss: 0.0000(0.0040) Grad: 13.3525  LR: 0.000014  \n","Epoch: [2][5000/5703] Elapsed 20m 29s (remain 2m 52s) Loss: 0.0000(0.0040) Grad: 41.5203  LR: 0.000014  \n","Epoch: [2][5100/5703] Elapsed 20m 53s (remain 2m 27s) Loss: 0.0018(0.0040) Grad: 4040.5693  LR: 0.000014  \n","Epoch: [2][5200/5703] Elapsed 21m 17s (remain 2m 3s) Loss: 0.0030(0.0040) Grad: 10244.7930  LR: 0.000014  \n","Epoch: [2][5300/5703] Elapsed 21m 42s (remain 1m 38s) Loss: 0.0000(0.0040) Grad: 92.7493  LR: 0.000014  \n","Epoch: [2][5400/5703] Elapsed 22m 6s (remain 1m 14s) Loss: 0.0000(0.0040) Grad: 69.8759  LR: 0.000014  \n","Epoch: [2][5500/5703] Elapsed 22m 30s (remain 0m 49s) Loss: 0.0007(0.0040) Grad: 4043.8582  LR: 0.000013  \n","Epoch: [2][5600/5703] Elapsed 22m 55s (remain 0m 25s) Loss: 0.0000(0.0040) Grad: 38.6093  LR: 0.000013  \n","Epoch: [2][5700/5703] Elapsed 23m 19s (remain 0m 0s) Loss: 0.0058(0.0040) Grad: 27925.2715  LR: 0.000013  \n","Epoch: [2][5702/5703] Elapsed 23m 19s (remain 0m 0s) Loss: 0.0002(0.0040) Grad: 1430.5844  LR: 0.000013  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 10m 7s) Loss: 0.0000(0.0000) \n","EVAL: [100/1447] Elapsed 0m 12s (remain 2m 46s) Loss: 0.0073(0.0031) \n","EVAL: [200/1447] Elapsed 0m 24s (remain 2m 32s) Loss: 0.0049(0.0035) \n","EVAL: [300/1447] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0101(0.0042) \n","EVAL: [400/1447] Elapsed 0m 48s (remain 2m 7s) Loss: 0.0000(0.0046) \n","EVAL: [500/1447] Elapsed 1m 0s (remain 1m 55s) Loss: 0.0000(0.0048) \n","EVAL: [600/1447] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0046) \n","EVAL: [700/1447] Elapsed 1m 25s (remain 1m 30s) Loss: 0.0000(0.0045) \n","EVAL: [800/1447] Elapsed 1m 37s (remain 1m 18s) Loss: 0.0000(0.0047) \n","EVAL: [900/1447] Elapsed 1m 49s (remain 1m 6s) Loss: 0.0240(0.0053) \n","EVAL: [1000/1447] Elapsed 2m 1s (remain 0m 54s) Loss: 0.0008(0.0054) \n","EVAL: [1100/1447] Elapsed 2m 13s (remain 0m 41s) Loss: 0.0021(0.0054) \n","EVAL: [1200/1447] Elapsed 2m 25s (remain 0m 29s) Loss: 0.0000(0.0053) \n","EVAL: [1300/1447] Elapsed 2m 37s (remain 0m 17s) Loss: 0.0000(0.0051) \n","EVAL: [1400/1447] Elapsed 2m 49s (remain 0m 5s) Loss: 0.0000(0.0048) \n","EVAL: [1446/1447] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0048) \n","Epoch 2 - avg_train_loss: 0.0040  avg_val_loss: 0.0048  time: 1579s\n","Epoch 2 - Score: 0.8693\n","Epoch 2 - Save Best Score: 0.8693 Model\n","Epoch: [3][0/5703] Elapsed 0m 0s (remain 57m 7s) Loss: 0.0050(0.0050) Grad: 9997.0127  LR: 0.000013  \n","Epoch: [3][100/5703] Elapsed 0m 28s (remain 25m 57s) Loss: 0.0098(0.0036) Grad: 17072.6191  LR: 0.000013  \n","Epoch: [3][200/5703] Elapsed 0m 54s (remain 24m 48s) Loss: 0.0007(0.0036) Grad: 1566.5051  LR: 0.000013  \n","Epoch: [3][300/5703] Elapsed 1m 18s (remain 23m 31s) Loss: 0.0065(0.0035) Grad: 22368.6230  LR: 0.000013  \n","Epoch: [3][400/5703] Elapsed 1m 42s (remain 22m 41s) Loss: 0.0000(0.0033) Grad: 108.2983  LR: 0.000013  \n","Epoch: [3][500/5703] Elapsed 2m 7s (remain 22m 0s) Loss: 0.0280(0.0034) Grad: 116045.3438  LR: 0.000013  \n","Epoch: [3][600/5703] Elapsed 2m 31s (remain 21m 26s) Loss: 0.0103(0.0032) Grad: 56023.9961  LR: 0.000013  \n","Epoch: [3][700/5703] Elapsed 2m 55s (remain 20m 53s) Loss: 0.0012(0.0031) Grad: 6732.4336  LR: 0.000013  \n","Epoch: [3][800/5703] Elapsed 3m 19s (remain 20m 23s) Loss: 0.0074(0.0031) Grad: 9014.3242  LR: 0.000013  \n","Epoch: [3][900/5703] Elapsed 3m 44s (remain 19m 55s) Loss: 0.0008(0.0033) Grad: 7622.1533  LR: 0.000013  \n","Epoch: [3][1000/5703] Elapsed 4m 8s (remain 19m 27s) Loss: 0.0000(0.0032) Grad: 86.4603  LR: 0.000013  \n","Epoch: [3][1100/5703] Elapsed 4m 32s (remain 19m 0s) Loss: 0.0000(0.0032) Grad: 22.0874  LR: 0.000012  \n","Epoch: [3][1200/5703] Elapsed 4m 57s (remain 18m 33s) Loss: 0.0000(0.0034) Grad: 108.9599  LR: 0.000012  \n","Epoch: [3][1300/5703] Elapsed 5m 21s (remain 18m 7s) Loss: 0.0076(0.0034) Grad: 12272.0996  LR: 0.000012  \n","Epoch: [3][1400/5703] Elapsed 5m 45s (remain 17m 41s) Loss: 0.0013(0.0033) Grad: 6338.2412  LR: 0.000012  \n","Epoch: [3][1500/5703] Elapsed 6m 9s (remain 17m 15s) Loss: 0.0051(0.0032) Grad: 17738.1309  LR: 0.000012  \n","Epoch: [3][1600/5703] Elapsed 6m 34s (remain 16m 50s) Loss: 0.0000(0.0032) Grad: 69.2173  LR: 0.000012  \n","Epoch: [3][1700/5703] Elapsed 6m 58s (remain 16m 24s) Loss: 0.0000(0.0032) Grad: 139.7569  LR: 0.000012  \n","Epoch: [3][1800/5703] Elapsed 7m 22s (remain 15m 59s) Loss: 0.0000(0.0032) Grad: 20.8107  LR: 0.000012  \n","Epoch: [3][1900/5703] Elapsed 7m 47s (remain 15m 34s) Loss: 0.0069(0.0033) Grad: 12151.9287  LR: 0.000012  \n","Epoch: [3][2000/5703] Elapsed 8m 11s (remain 15m 9s) Loss: 0.0000(0.0032) Grad: 23.1965  LR: 0.000012  \n","Epoch: [3][2100/5703] Elapsed 8m 35s (remain 14m 44s) Loss: 0.0026(0.0032) Grad: 24933.0312  LR: 0.000012  \n","Epoch: [3][2200/5703] Elapsed 9m 0s (remain 14m 19s) Loss: 0.0000(0.0032) Grad: 44.1335  LR: 0.000012  \n","Epoch: [3][2300/5703] Elapsed 9m 24s (remain 13m 54s) Loss: 0.0000(0.0032) Grad: 61.7433  LR: 0.000012  \n","Epoch: [3][2400/5703] Elapsed 9m 48s (remain 13m 29s) Loss: 0.0000(0.0033) Grad: 491.0946  LR: 0.000011  \n","Epoch: [3][2500/5703] Elapsed 10m 13s (remain 13m 4s) Loss: 0.0092(0.0033) Grad: 16864.2363  LR: 0.000011  \n","Epoch: [3][2600/5703] Elapsed 10m 37s (remain 12m 39s) Loss: 0.0004(0.0033) Grad: 3877.4124  LR: 0.000011  \n","Epoch: [3][2700/5703] Elapsed 11m 1s (remain 12m 15s) Loss: 0.0009(0.0033) Grad: 4169.7915  LR: 0.000011  \n","Epoch: [3][2800/5703] Elapsed 11m 25s (remain 11m 50s) Loss: 0.0000(0.0033) Grad: 69.7872  LR: 0.000011  \n","Epoch: [3][2900/5703] Elapsed 11m 49s (remain 11m 25s) Loss: 0.0000(0.0033) Grad: 9.2004  LR: 0.000011  \n","Epoch: [3][3000/5703] Elapsed 12m 14s (remain 11m 1s) Loss: 0.0019(0.0033) Grad: 5078.7969  LR: 0.000011  \n","Epoch: [3][3100/5703] Elapsed 12m 38s (remain 10m 36s) Loss: 0.0000(0.0033) Grad: 53.3493  LR: 0.000011  \n","Epoch: [3][3200/5703] Elapsed 13m 2s (remain 10m 11s) Loss: 0.0000(0.0033) Grad: 39.7617  LR: 0.000011  \n","Epoch: [3][3300/5703] Elapsed 13m 27s (remain 9m 47s) Loss: 0.0015(0.0033) Grad: 5036.5933  LR: 0.000011  \n","Epoch: [3][3400/5703] Elapsed 13m 51s (remain 9m 22s) Loss: 0.0002(0.0033) Grad: 2266.3220  LR: 0.000011  \n","Epoch: [3][3500/5703] Elapsed 14m 15s (remain 8m 58s) Loss: 0.0006(0.0033) Grad: 3985.7188  LR: 0.000011  \n","Epoch: [3][3600/5703] Elapsed 14m 39s (remain 8m 33s) Loss: 0.0002(0.0032) Grad: 871.2277  LR: 0.000011  \n","Epoch: [3][3700/5703] Elapsed 15m 4s (remain 8m 9s) Loss: 0.0000(0.0033) Grad: 27.9512  LR: 0.000010  \n","Epoch: [3][3800/5703] Elapsed 15m 28s (remain 7m 44s) Loss: 0.0000(0.0032) Grad: 106.2751  LR: 0.000010  \n","Epoch: [3][3900/5703] Elapsed 15m 52s (remain 7m 20s) Loss: 0.0062(0.0032) Grad: 6017.8960  LR: 0.000010  \n","Epoch: [3][4000/5703] Elapsed 16m 16s (remain 6m 55s) Loss: 0.0000(0.0033) Grad: 82.3209  LR: 0.000010  \n","Epoch: [3][4100/5703] Elapsed 16m 41s (remain 6m 31s) Loss: 0.0000(0.0033) Grad: 174.2325  LR: 0.000010  \n","Epoch: [3][4200/5703] Elapsed 17m 5s (remain 6m 6s) Loss: 0.0000(0.0032) Grad: 15.9591  LR: 0.000010  \n","Epoch: [3][4300/5703] Elapsed 17m 29s (remain 5m 42s) Loss: 0.0004(0.0032) Grad: 1881.3667  LR: 0.000010  \n","Epoch: [3][4400/5703] Elapsed 17m 53s (remain 5m 17s) Loss: 0.0131(0.0032) Grad: 36730.8203  LR: 0.000010  \n","Epoch: [3][4500/5703] Elapsed 18m 18s (remain 4m 53s) Loss: 0.0001(0.0032) Grad: 367.2306  LR: 0.000010  \n","Epoch: [3][4600/5703] Elapsed 18m 42s (remain 4m 28s) Loss: 0.0204(0.0032) Grad: 24922.2324  LR: 0.000010  \n","Epoch: [3][4700/5703] Elapsed 19m 6s (remain 4m 4s) Loss: 0.0007(0.0032) Grad: 5976.8462  LR: 0.000010  \n","Epoch: [3][4800/5703] Elapsed 19m 31s (remain 3m 40s) Loss: 0.0000(0.0032) Grad: 36.8343  LR: 0.000010  \n","Epoch: [3][4900/5703] Elapsed 19m 55s (remain 3m 15s) Loss: 0.0111(0.0032) Grad: 35877.9336  LR: 0.000010  \n","Epoch: [3][5000/5703] Elapsed 20m 19s (remain 2m 51s) Loss: 0.0005(0.0032) Grad: 4183.7339  LR: 0.000009  \n","Epoch: [3][5100/5703] Elapsed 20m 43s (remain 2m 26s) Loss: 0.0011(0.0032) Grad: 5351.0107  LR: 0.000009  \n","Epoch: [3][5200/5703] Elapsed 21m 8s (remain 2m 2s) Loss: 0.0000(0.0032) Grad: 64.8193  LR: 0.000009  \n","Epoch: [3][5300/5703] Elapsed 21m 32s (remain 1m 37s) Loss: 0.0008(0.0031) Grad: 6467.0342  LR: 0.000009  \n","Epoch: [3][5400/5703] Elapsed 21m 56s (remain 1m 13s) Loss: 0.0011(0.0031) Grad: 25894.9434  LR: 0.000009  \n","Epoch: [3][5500/5703] Elapsed 22m 20s (remain 0m 49s) Loss: 0.0000(0.0031) Grad: 8.0007  LR: 0.000009  \n","Epoch: [3][5600/5703] Elapsed 22m 45s (remain 0m 24s) Loss: 0.0001(0.0031) Grad: 1135.2084  LR: 0.000009  \n","Epoch: [3][5700/5703] Elapsed 23m 9s (remain 0m 0s) Loss: 0.0000(0.0031) Grad: 25.6155  LR: 0.000009  \n","Epoch: [3][5702/5703] Elapsed 23m 9s (remain 0m 0s) Loss: 0.0012(0.0031) Grad: 5123.3374  LR: 0.000009  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 9m 37s) Loss: 0.0000(0.0000) \n","EVAL: [100/1447] Elapsed 0m 12s (remain 2m 46s) Loss: 0.0074(0.0037) \n","EVAL: [200/1447] Elapsed 0m 24s (remain 2m 32s) Loss: 0.0019(0.0034) \n","EVAL: [300/1447] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0088(0.0047) \n","EVAL: [400/1447] Elapsed 0m 48s (remain 2m 7s) Loss: 0.0000(0.0050) \n","EVAL: [500/1447] Elapsed 1m 1s (remain 1m 55s) Loss: 0.0000(0.0050) \n","EVAL: [600/1447] Elapsed 1m 13s (remain 1m 42s) Loss: 0.0000(0.0047) \n","EVAL: [700/1447] Elapsed 1m 25s (remain 1m 30s) Loss: 0.0000(0.0045) \n","EVAL: [800/1447] Elapsed 1m 37s (remain 1m 18s) Loss: 0.0000(0.0047) \n","EVAL: [900/1447] Elapsed 1m 49s (remain 1m 6s) Loss: 0.0189(0.0052) \n","EVAL: [1000/1447] Elapsed 2m 1s (remain 0m 54s) Loss: 0.0010(0.0054) \n","EVAL: [1100/1447] Elapsed 2m 13s (remain 0m 41s) Loss: 0.0004(0.0054) \n","EVAL: [1200/1447] Elapsed 2m 25s (remain 0m 29s) Loss: 0.0000(0.0052) \n","EVAL: [1300/1447] Elapsed 2m 37s (remain 0m 17s) Loss: 0.0000(0.0050) \n","EVAL: [1400/1447] Elapsed 2m 49s (remain 0m 5s) Loss: 0.0000(0.0047) \n","EVAL: [1446/1447] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0046) \n","Epoch 3 - avg_train_loss: 0.0031  avg_val_loss: 0.0046  time: 1569s\n","Epoch 3 - Score: 0.8719\n","Epoch 3 - Save Best Score: 0.8719 Model\n","Epoch: [4][0/5703] Elapsed 0m 0s (remain 56m 24s) Loss: 0.0001(0.0001) Grad: 1088.1781  LR: 0.000009  \n","Epoch: [4][100/5703] Elapsed 0m 29s (remain 26m 51s) Loss: 0.0002(0.0021) Grad: 688.9764  LR: 0.000009  \n","Epoch: [4][200/5703] Elapsed 0m 54s (remain 24m 48s) Loss: 0.0001(0.0023) Grad: 184.9677  LR: 0.000009  \n","Epoch: [4][300/5703] Elapsed 1m 18s (remain 23m 33s) Loss: 0.0000(0.0021) Grad: 59.7447  LR: 0.000009  \n","Epoch: [4][400/5703] Elapsed 1m 43s (remain 22m 44s) Loss: 0.0007(0.0022) Grad: 2482.0186  LR: 0.000009  \n","Epoch: [4][500/5703] Elapsed 2m 7s (remain 22m 5s) Loss: 0.0001(0.0022) Grad: 702.4813  LR: 0.000008  \n","Epoch: [4][600/5703] Elapsed 2m 31s (remain 21m 29s) Loss: 0.0000(0.0023) Grad: 95.4328  LR: 0.000008  \n","Epoch: [4][700/5703] Elapsed 2m 56s (remain 20m 57s) Loss: 0.0000(0.0022) Grad: 12.8884  LR: 0.000008  \n","Epoch: [4][800/5703] Elapsed 3m 20s (remain 20m 27s) Loss: 0.0000(0.0022) Grad: 31.4955  LR: 0.000008  \n","Epoch: [4][900/5703] Elapsed 3m 44s (remain 19m 58s) Loss: 0.0000(0.0022) Grad: 6.8126  LR: 0.000008  \n","Epoch: [4][1000/5703] Elapsed 4m 9s (remain 19m 30s) Loss: 0.0000(0.0023) Grad: 10.6649  LR: 0.000008  \n","Epoch: [4][1100/5703] Elapsed 4m 33s (remain 19m 4s) Loss: 0.0034(0.0023) Grad: 6579.6206  LR: 0.000008  \n","Epoch: [4][1200/5703] Elapsed 4m 57s (remain 18m 36s) Loss: 0.0000(0.0024) Grad: 141.9139  LR: 0.000008  \n","Epoch: [4][1300/5703] Elapsed 5m 22s (remain 18m 10s) Loss: 0.0000(0.0025) Grad: 39.3034  LR: 0.000008  \n","Epoch: [4][1400/5703] Elapsed 5m 46s (remain 17m 44s) Loss: 0.0000(0.0025) Grad: 89.3855  LR: 0.000008  \n","Epoch: [4][1500/5703] Elapsed 6m 10s (remain 17m 18s) Loss: 0.0001(0.0025) Grad: 165.7470  LR: 0.000008  \n","Epoch: [4][1600/5703] Elapsed 6m 35s (remain 16m 52s) Loss: 0.0048(0.0026) Grad: 18860.8301  LR: 0.000008  \n","Epoch: [4][1700/5703] Elapsed 6m 59s (remain 16m 26s) Loss: 0.0001(0.0025) Grad: 272.4298  LR: 0.000008  \n","Epoch: [4][1800/5703] Elapsed 7m 23s (remain 16m 1s) Loss: 0.0040(0.0024) Grad: 16643.5215  LR: 0.000007  \n","Epoch: [4][1900/5703] Elapsed 7m 48s (remain 15m 36s) Loss: 0.0000(0.0025) Grad: 6.7021  LR: 0.000007  \n","Epoch: [4][2000/5703] Elapsed 8m 12s (remain 15m 10s) Loss: 0.0079(0.0025) Grad: 53162.0625  LR: 0.000007  \n","Epoch: [4][2100/5703] Elapsed 8m 36s (remain 14m 45s) Loss: 0.0013(0.0025) Grad: 8787.6709  LR: 0.000007  \n","Epoch: [4][2200/5703] Elapsed 9m 1s (remain 14m 20s) Loss: 0.0011(0.0025) Grad: 4126.2246  LR: 0.000007  \n","Epoch: [4][2300/5703] Elapsed 9m 25s (remain 13m 55s) Loss: 0.0000(0.0025) Grad: 143.4295  LR: 0.000007  \n","Epoch: [4][2400/5703] Elapsed 9m 49s (remain 13m 31s) Loss: 0.0077(0.0025) Grad: 8666.7383  LR: 0.000007  \n","Epoch: [4][2500/5703] Elapsed 10m 14s (remain 13m 6s) Loss: 0.0002(0.0025) Grad: 1573.9193  LR: 0.000007  \n","Epoch: [4][2600/5703] Elapsed 10m 38s (remain 12m 41s) Loss: 0.0069(0.0025) Grad: 23450.1934  LR: 0.000007  \n","Epoch: [4][2700/5703] Elapsed 11m 3s (remain 12m 16s) Loss: 0.0076(0.0025) Grad: 26848.7656  LR: 0.000007  \n","Epoch: [4][2800/5703] Elapsed 11m 27s (remain 11m 52s) Loss: 0.0000(0.0025) Grad: 16.2202  LR: 0.000007  \n","Epoch: [4][2900/5703] Elapsed 11m 51s (remain 11m 27s) Loss: 0.0000(0.0025) Grad: 105.6327  LR: 0.000007  \n","Epoch: [4][3000/5703] Elapsed 12m 15s (remain 11m 2s) Loss: 0.0001(0.0025) Grad: 960.8406  LR: 0.000007  \n","Epoch: [4][3100/5703] Elapsed 12m 40s (remain 10m 37s) Loss: 0.0000(0.0026) Grad: 11.2198  LR: 0.000006  \n","Epoch: [4][3200/5703] Elapsed 13m 4s (remain 10m 13s) Loss: 0.0000(0.0026) Grad: 5.0371  LR: 0.000006  \n","Epoch: [4][3300/5703] Elapsed 13m 28s (remain 9m 48s) Loss: 0.0045(0.0026) Grad: 15187.1396  LR: 0.000006  \n","Epoch: [4][3400/5703] Elapsed 13m 53s (remain 9m 24s) Loss: 0.0001(0.0027) Grad: 685.7784  LR: 0.000006  \n","Epoch: [4][3500/5703] Elapsed 14m 17s (remain 8m 59s) Loss: 0.0000(0.0027) Grad: 97.8356  LR: 0.000006  \n","Epoch: [4][3600/5703] Elapsed 14m 42s (remain 8m 34s) Loss: 0.0000(0.0027) Grad: 78.0168  LR: 0.000006  \n","Epoch: [4][3700/5703] Elapsed 15m 6s (remain 8m 10s) Loss: 0.0000(0.0027) Grad: 3.7883  LR: 0.000006  \n","Epoch: [4][3800/5703] Elapsed 15m 31s (remain 7m 45s) Loss: 0.0000(0.0026) Grad: 11.0594  LR: 0.000006  \n","Epoch: [4][3900/5703] Elapsed 15m 55s (remain 7m 21s) Loss: 0.0001(0.0026) Grad: 120.4729  LR: 0.000006  \n","Epoch: [4][4000/5703] Elapsed 16m 19s (remain 6m 56s) Loss: 0.0000(0.0026) Grad: 151.0262  LR: 0.000006  \n","Epoch: [4][4100/5703] Elapsed 16m 43s (remain 6m 32s) Loss: 0.0005(0.0026) Grad: 4119.9683  LR: 0.000006  \n","Epoch: [4][4200/5703] Elapsed 17m 8s (remain 6m 7s) Loss: 0.0041(0.0026) Grad: 11966.6807  LR: 0.000006  \n","Epoch: [4][4300/5703] Elapsed 17m 32s (remain 5m 43s) Loss: 0.0000(0.0026) Grad: 170.7529  LR: 0.000006  \n","Epoch: [4][4400/5703] Elapsed 17m 56s (remain 5m 18s) Loss: 0.0103(0.0026) Grad: 42955.9414  LR: 0.000005  \n","Epoch: [4][4500/5703] Elapsed 18m 21s (remain 4m 54s) Loss: 0.0001(0.0027) Grad: 196.1312  LR: 0.000005  \n","Epoch: [4][4600/5703] Elapsed 18m 45s (remain 4m 29s) Loss: 0.0000(0.0026) Grad: 119.2508  LR: 0.000005  \n","Epoch: [4][4700/5703] Elapsed 19m 9s (remain 4m 5s) Loss: 0.0000(0.0026) Grad: 179.5112  LR: 0.000005  \n","Epoch: [4][4800/5703] Elapsed 19m 34s (remain 3m 40s) Loss: 0.0031(0.0026) Grad: 8441.3916  LR: 0.000005  \n","Epoch: [4][4900/5703] Elapsed 19m 58s (remain 3m 16s) Loss: 0.0136(0.0026) Grad: 36005.8672  LR: 0.000005  \n","Epoch: [4][5000/5703] Elapsed 20m 22s (remain 2m 51s) Loss: 0.0037(0.0026) Grad: 12869.6484  LR: 0.000005  \n","Epoch: [4][5100/5703] Elapsed 20m 47s (remain 2m 27s) Loss: 0.0176(0.0026) Grad: 107136.5469  LR: 0.000005  \n","Epoch: [4][5200/5703] Elapsed 21m 11s (remain 2m 2s) Loss: 0.0000(0.0026) Grad: 401.0672  LR: 0.000005  \n","Epoch: [4][5300/5703] Elapsed 21m 35s (remain 1m 38s) Loss: 0.0000(0.0026) Grad: 4.9648  LR: 0.000005  \n","Epoch: [4][5400/5703] Elapsed 21m 59s (remain 1m 13s) Loss: 0.0005(0.0026) Grad: 8070.2925  LR: 0.000005  \n","Epoch: [4][5500/5703] Elapsed 22m 24s (remain 0m 49s) Loss: 0.0000(0.0026) Grad: 120.8871  LR: 0.000005  \n","Epoch: [4][5600/5703] Elapsed 22m 48s (remain 0m 24s) Loss: 0.0000(0.0026) Grad: 67.0222  LR: 0.000005  \n","Epoch: [4][5700/5703] Elapsed 23m 12s (remain 0m 0s) Loss: 0.0002(0.0026) Grad: 793.3770  LR: 0.000004  \n","Epoch: [4][5702/5703] Elapsed 23m 13s (remain 0m 0s) Loss: 0.0000(0.0026) Grad: 817.2604  LR: 0.000004  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 9m 53s) Loss: 0.0000(0.0000) \n","EVAL: [100/1447] Elapsed 0m 12s (remain 2m 46s) Loss: 0.0087(0.0038) \n","EVAL: [200/1447] Elapsed 0m 24s (remain 2m 32s) Loss: 0.0023(0.0036) \n","EVAL: [300/1447] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0101(0.0040) \n","EVAL: [400/1447] Elapsed 0m 48s (remain 2m 7s) Loss: 0.0000(0.0044) \n","EVAL: [500/1447] Elapsed 1m 0s (remain 1m 55s) Loss: 0.0000(0.0045) \n","EVAL: [600/1447] Elapsed 1m 13s (remain 1m 42s) Loss: 0.0000(0.0043) \n","EVAL: [700/1447] Elapsed 1m 25s (remain 1m 30s) Loss: 0.0000(0.0041) \n","EVAL: [800/1447] Elapsed 1m 37s (remain 1m 18s) Loss: 0.0000(0.0043) \n","EVAL: [900/1447] Elapsed 1m 49s (remain 1m 6s) Loss: 0.0207(0.0049) \n","EVAL: [1000/1447] Elapsed 2m 1s (remain 0m 54s) Loss: 0.0006(0.0050) \n","EVAL: [1100/1447] Elapsed 2m 13s (remain 0m 41s) Loss: 0.0003(0.0050) \n","EVAL: [1200/1447] Elapsed 2m 25s (remain 0m 29s) Loss: 0.0000(0.0047) \n","EVAL: [1300/1447] Elapsed 2m 37s (remain 0m 17s) Loss: 0.0000(0.0045) \n","EVAL: [1400/1447] Elapsed 2m 49s (remain 0m 5s) Loss: 0.0000(0.0043) \n","EVAL: [1446/1447] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0043) \n","Epoch 4 - avg_train_loss: 0.0026  avg_val_loss: 0.0043  time: 1572s\n","Epoch 4 - Score: 0.8867\n","Epoch 4 - Save Best Score: 0.8867 Model\n","Epoch: [5][0/5703] Elapsed 0m 0s (remain 56m 42s) Loss: 0.0000(0.0000) Grad: 819.4926  LR: 0.000004  \n","Epoch: [5][100/5703] Elapsed 0m 28s (remain 26m 26s) Loss: 0.0000(0.0023) Grad: 782.7213  LR: 0.000004  \n","Epoch: [5][200/5703] Elapsed 0m 54s (remain 24m 52s) Loss: 0.0000(0.0021) Grad: 54.3652  LR: 0.000004  \n","Epoch: [5][300/5703] Elapsed 1m 18s (remain 23m 35s) Loss: 0.0009(0.0019) Grad: 5238.3208  LR: 0.000004  \n","Epoch: [5][400/5703] Elapsed 1m 43s (remain 22m 45s) Loss: 0.0015(0.0018) Grad: 8372.7236  LR: 0.000004  \n","Epoch: [5][500/5703] Elapsed 2m 7s (remain 22m 5s) Loss: 0.0001(0.0019) Grad: 1004.4896  LR: 0.000004  \n","Epoch: [5][600/5703] Elapsed 2m 32s (remain 21m 32s) Loss: 0.0004(0.0020) Grad: 2001.2527  LR: 0.000004  \n","Epoch: [5][700/5703] Elapsed 2m 56s (remain 21m 0s) Loss: 0.0000(0.0019) Grad: 2.6501  LR: 0.000004  \n","Epoch: [5][800/5703] Elapsed 3m 20s (remain 20m 29s) Loss: 0.0000(0.0019) Grad: 105.9331  LR: 0.000004  \n","Epoch: [5][900/5703] Elapsed 3m 45s (remain 20m 1s) Loss: 0.0000(0.0019) Grad: 11.6405  LR: 0.000004  \n","Epoch: [5][1000/5703] Elapsed 4m 9s (remain 19m 32s) Loss: 0.0029(0.0019) Grad: 15240.9473  LR: 0.000004  \n","Epoch: [5][1100/5703] Elapsed 4m 34s (remain 19m 5s) Loss: 0.0007(0.0019) Grad: 4118.2012  LR: 0.000004  \n","Epoch: [5][1200/5703] Elapsed 4m 58s (remain 18m 38s) Loss: 0.0002(0.0020) Grad: 1298.9081  LR: 0.000004  \n","Epoch: [5][1300/5703] Elapsed 5m 22s (remain 18m 11s) Loss: 0.0000(0.0020) Grad: 36.5984  LR: 0.000003  \n","Epoch: [5][1400/5703] Elapsed 5m 46s (remain 17m 45s) Loss: 0.0000(0.0019) Grad: 88.8474  LR: 0.000003  \n","Epoch: [5][1500/5703] Elapsed 6m 11s (remain 17m 19s) Loss: 0.0006(0.0019) Grad: 4256.5918  LR: 0.000003  \n","Epoch: [5][1600/5703] Elapsed 6m 35s (remain 16m 53s) Loss: 0.0000(0.0020) Grad: 2.1485  LR: 0.000003  \n","Epoch: [5][1700/5703] Elapsed 6m 59s (remain 16m 27s) Loss: 0.0000(0.0020) Grad: 282.8831  LR: 0.000003  \n","Epoch: [5][1800/5703] Elapsed 7m 23s (remain 16m 1s) Loss: 0.0001(0.0020) Grad: 1334.3715  LR: 0.000003  \n","Epoch: [5][1900/5703] Elapsed 7m 48s (remain 15m 36s) Loss: 0.0016(0.0021) Grad: 6135.2905  LR: 0.000003  \n","Epoch: [5][2000/5703] Elapsed 8m 12s (remain 15m 11s) Loss: 0.0000(0.0021) Grad: 103.8230  LR: 0.000003  \n","Epoch: [5][2100/5703] Elapsed 8m 36s (remain 14m 45s) Loss: 0.0099(0.0021) Grad: 81312.0000  LR: 0.000003  \n","Epoch: [5][2200/5703] Elapsed 9m 0s (remain 14m 20s) Loss: 0.0189(0.0021) Grad: 85032.3750  LR: 0.000003  \n","Epoch: [5][2300/5703] Elapsed 9m 25s (remain 13m 55s) Loss: 0.0001(0.0021) Grad: 1569.2407  LR: 0.000003  \n","Epoch: [5][2400/5703] Elapsed 9m 49s (remain 13m 30s) Loss: 0.0027(0.0021) Grad: 1623.0844  LR: 0.000003  \n","Epoch: [5][2500/5703] Elapsed 10m 13s (remain 13m 5s) Loss: 0.0001(0.0021) Grad: 289.9116  LR: 0.000002  \n","Epoch: [5][2600/5703] Elapsed 10m 37s (remain 12m 40s) Loss: 0.0001(0.0021) Grad: 371.8671  LR: 0.000002  \n","Epoch: [5][2700/5703] Elapsed 11m 1s (remain 12m 15s) Loss: 0.0000(0.0021) Grad: 9.4535  LR: 0.000002  \n","Epoch: [5][2800/5703] Elapsed 11m 26s (remain 11m 50s) Loss: 0.0000(0.0022) Grad: 8.9442  LR: 0.000002  \n","Epoch: [5][2900/5703] Elapsed 11m 50s (remain 11m 26s) Loss: 0.0000(0.0021) Grad: 86.8516  LR: 0.000002  \n","Epoch: [5][3000/5703] Elapsed 12m 14s (remain 11m 1s) Loss: 0.0000(0.0021) Grad: 22.3228  LR: 0.000002  \n","Epoch: [5][3100/5703] Elapsed 12m 38s (remain 10m 36s) Loss: 0.0000(0.0021) Grad: 6.3759  LR: 0.000002  \n","Epoch: [5][3200/5703] Elapsed 13m 2s (remain 10m 11s) Loss: 0.0000(0.0021) Grad: 12.8723  LR: 0.000002  \n","Epoch: [5][3300/5703] Elapsed 13m 27s (remain 9m 47s) Loss: 0.0000(0.0021) Grad: 17.5699  LR: 0.000002  \n","Epoch: [5][3400/5703] Elapsed 13m 51s (remain 9m 22s) Loss: 0.0000(0.0021) Grad: 57.8172  LR: 0.000002  \n","Epoch: [5][3500/5703] Elapsed 14m 15s (remain 8m 57s) Loss: 0.0000(0.0021) Grad: 3.6784  LR: 0.000002  \n","Epoch: [5][3600/5703] Elapsed 14m 39s (remain 8m 33s) Loss: 0.0002(0.0021) Grad: 325.8224  LR: 0.000002  \n","Epoch: [5][3700/5703] Elapsed 15m 3s (remain 8m 8s) Loss: 0.0003(0.0020) Grad: 2005.7327  LR: 0.000002  \n","Epoch: [5][3800/5703] Elapsed 15m 27s (remain 7m 44s) Loss: 0.0004(0.0021) Grad: 872.8845  LR: 0.000001  \n","Epoch: [5][3900/5703] Elapsed 15m 52s (remain 7m 19s) Loss: 0.0036(0.0021) Grad: 8086.4868  LR: 0.000001  \n","Epoch: [5][4000/5703] Elapsed 16m 16s (remain 6m 55s) Loss: 0.0000(0.0021) Grad: 10.1390  LR: 0.000001  \n","Epoch: [5][4100/5703] Elapsed 16m 40s (remain 6m 30s) Loss: 0.0000(0.0021) Grad: 12.4883  LR: 0.000001  \n","Epoch: [5][4200/5703] Elapsed 17m 4s (remain 6m 6s) Loss: 0.0000(0.0021) Grad: 11.4927  LR: 0.000001  \n","Epoch: [5][4300/5703] Elapsed 17m 28s (remain 5m 41s) Loss: 0.0000(0.0021) Grad: 7.0416  LR: 0.000001  \n","Epoch: [5][4400/5703] Elapsed 17m 52s (remain 5m 17s) Loss: 0.0002(0.0021) Grad: 695.3354  LR: 0.000001  \n","Epoch: [5][4500/5703] Elapsed 18m 16s (remain 4m 52s) Loss: 0.0000(0.0021) Grad: 55.0278  LR: 0.000001  \n","Epoch: [5][4600/5703] Elapsed 18m 40s (remain 4m 28s) Loss: 0.0000(0.0021) Grad: 14.4430  LR: 0.000001  \n","Epoch: [5][4700/5703] Elapsed 19m 5s (remain 4m 4s) Loss: 0.0022(0.0021) Grad: 1582.5070  LR: 0.000001  \n","Epoch: [5][4800/5703] Elapsed 19m 29s (remain 3m 39s) Loss: 0.0345(0.0021) Grad: 28649.5332  LR: 0.000001  \n","Epoch: [5][4900/5703] Elapsed 19m 53s (remain 3m 15s) Loss: 0.0000(0.0021) Grad: 21.6785  LR: 0.000001  \n","Epoch: [5][5000/5703] Elapsed 20m 17s (remain 2m 50s) Loss: 0.0001(0.0021) Grad: 195.0869  LR: 0.000001  \n","Epoch: [5][5100/5703] Elapsed 20m 41s (remain 2m 26s) Loss: 0.0159(0.0021) Grad: 15578.8184  LR: 0.000000  \n","Epoch: [5][5200/5703] Elapsed 21m 5s (remain 2m 2s) Loss: 0.0000(0.0021) Grad: 15.6243  LR: 0.000000  \n","Epoch: [5][5300/5703] Elapsed 21m 29s (remain 1m 37s) Loss: 0.0000(0.0021) Grad: 15.1494  LR: 0.000000  \n","Epoch: [5][5400/5703] Elapsed 21m 54s (remain 1m 13s) Loss: 0.0000(0.0021) Grad: 11.0299  LR: 0.000000  \n","Epoch: [5][5500/5703] Elapsed 22m 18s (remain 0m 49s) Loss: 0.0000(0.0022) Grad: 13.1620  LR: 0.000000  \n","Epoch: [5][5600/5703] Elapsed 22m 42s (remain 0m 24s) Loss: 0.0002(0.0022) Grad: 1239.9036  LR: 0.000000  \n","Epoch: [5][5700/5703] Elapsed 23m 6s (remain 0m 0s) Loss: 0.0051(0.0021) Grad: 8744.2061  LR: 0.000000  \n","Epoch: [5][5702/5703] Elapsed 23m 6s (remain 0m 0s) Loss: 0.0000(0.0021) Grad: 999.7158  LR: 0.000000  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 9m 20s) Loss: 0.0001(0.0001) \n","EVAL: [100/1447] Elapsed 0m 12s (remain 2m 45s) Loss: 0.0092(0.0036) \n","EVAL: [200/1447] Elapsed 0m 24s (remain 2m 32s) Loss: 0.0028(0.0034) \n","EVAL: [300/1447] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0090(0.0040) \n","EVAL: [400/1447] Elapsed 0m 48s (remain 2m 7s) Loss: 0.0000(0.0044) \n","EVAL: [500/1447] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0000(0.0045) \n","EVAL: [600/1447] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0043) \n","EVAL: [700/1447] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0000(0.0041) \n","EVAL: [800/1447] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0000(0.0043) \n","EVAL: [900/1447] Elapsed 1m 49s (remain 1m 6s) Loss: 0.0210(0.0049) \n","EVAL: [1000/1447] Elapsed 2m 0s (remain 0m 53s) Loss: 0.0006(0.0051) \n","EVAL: [1100/1447] Elapsed 2m 13s (remain 0m 41s) Loss: 0.0005(0.0050) \n","EVAL: [1200/1447] Elapsed 2m 25s (remain 0m 29s) Loss: 0.0000(0.0048) \n","EVAL: [1300/1447] Elapsed 2m 37s (remain 0m 17s) Loss: 0.0000(0.0046) \n","EVAL: [1400/1447] Elapsed 2m 49s (remain 0m 5s) Loss: 0.0000(0.0044) \n","EVAL: [1446/1447] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0043) \n","Epoch 5 - avg_train_loss: 0.0021  avg_val_loss: 0.0043  time: 1566s\n","Epoch 5 - Score: 0.8852\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5743] Elapsed 0m 0s (remain 58m 47s) Loss: 0.3522(0.3522) Grad: 110467.3828  LR: 0.000000  \n","Epoch: [1][100/5743] Elapsed 0m 24s (remain 23m 2s) Loss: 0.3255(0.2878) Grad: 50313.4688  LR: 0.000001  \n","Epoch: [1][200/5743] Elapsed 0m 48s (remain 22m 29s) Loss: 0.1622(0.2728) Grad: 23674.2422  LR: 0.000001  \n","Epoch: [1][300/5743] Elapsed 1m 13s (remain 22m 2s) Loss: 0.2694(0.2692) Grad: 23077.9004  LR: 0.000002  \n","Epoch: [1][400/5743] Elapsed 1m 37s (remain 21m 35s) Loss: 0.1094(0.2536) Grad: 5318.5903  LR: 0.000003  \n","Epoch: [1][500/5743] Elapsed 2m 1s (remain 21m 10s) Loss: 0.1033(0.2289) Grad: 8529.4893  LR: 0.000003  \n","Epoch: [1][600/5743] Elapsed 2m 25s (remain 20m 47s) Loss: 0.0152(0.1992) Grad: 2375.7666  LR: 0.000004  \n","Epoch: [1][700/5743] Elapsed 2m 50s (remain 20m 23s) Loss: 0.0048(0.1741) Grad: 2114.6904  LR: 0.000005  \n","Epoch: [1][800/5743] Elapsed 3m 14s (remain 19m 58s) Loss: 0.0134(0.1551) Grad: 127.2086  LR: 0.000006  \n","Epoch: [1][900/5743] Elapsed 3m 38s (remain 19m 33s) Loss: 0.0158(0.1398) Grad: 371.5001  LR: 0.000006  \n","Epoch: [1][1000/5743] Elapsed 4m 2s (remain 19m 8s) Loss: 0.0127(0.1277) Grad: 643.4902  LR: 0.000007  \n","Epoch: [1][1100/5743] Elapsed 4m 26s (remain 18m 44s) Loss: 0.0114(0.1177) Grad: 1714.2454  LR: 0.000008  \n","Epoch: [1][1200/5743] Elapsed 4m 50s (remain 18m 20s) Loss: 0.0123(0.1093) Grad: 2323.4983  LR: 0.000008  \n","Epoch: [1][1300/5743] Elapsed 5m 15s (remain 17m 56s) Loss: 0.0043(0.1017) Grad: 1239.4060  LR: 0.000009  \n","Epoch: [1][1400/5743] Elapsed 5m 39s (remain 17m 32s) Loss: 0.0009(0.0952) Grad: 274.7113  LR: 0.000010  \n","Epoch: [1][1500/5743] Elapsed 6m 3s (remain 17m 7s) Loss: 0.0354(0.0894) Grad: 6310.8071  LR: 0.000010  \n","Epoch: [1][1600/5743] Elapsed 6m 27s (remain 16m 43s) Loss: 0.0009(0.0845) Grad: 351.7319  LR: 0.000011  \n","Epoch: [1][1700/5743] Elapsed 6m 52s (remain 16m 19s) Loss: 0.0091(0.0800) Grad: 4311.8315  LR: 0.000012  \n","Epoch: [1][1800/5743] Elapsed 7m 16s (remain 15m 54s) Loss: 0.0018(0.0760) Grad: 461.4533  LR: 0.000013  \n","Epoch: [1][1900/5743] Elapsed 7m 40s (remain 15m 30s) Loss: 0.0016(0.0724) Grad: 371.3974  LR: 0.000013  \n","Epoch: [1][2000/5743] Elapsed 8m 4s (remain 15m 6s) Loss: 0.0006(0.0692) Grad: 624.6112  LR: 0.000014  \n","Epoch: [1][2100/5743] Elapsed 8m 28s (remain 14m 41s) Loss: 0.0132(0.0662) Grad: 5376.3330  LR: 0.000015  \n","Epoch: [1][2200/5743] Elapsed 8m 52s (remain 14m 17s) Loss: 0.0050(0.0636) Grad: 595.2495  LR: 0.000015  \n","Epoch: [1][2300/5743] Elapsed 9m 17s (remain 13m 53s) Loss: 0.0002(0.0611) Grad: 112.3299  LR: 0.000016  \n","Epoch: [1][2400/5743] Elapsed 9m 41s (remain 13m 29s) Loss: 0.0017(0.0588) Grad: 489.6865  LR: 0.000017  \n","Epoch: [1][2500/5743] Elapsed 10m 5s (remain 13m 4s) Loss: 0.0032(0.0567) Grad: 1071.3779  LR: 0.000017  \n","Epoch: [1][2600/5743] Elapsed 10m 29s (remain 12m 40s) Loss: 0.0004(0.0548) Grad: 100.5273  LR: 0.000018  \n","Epoch: [1][2700/5743] Elapsed 10m 53s (remain 12m 16s) Loss: 0.0012(0.0530) Grad: 1307.1633  LR: 0.000019  \n","Epoch: [1][2800/5743] Elapsed 11m 18s (remain 11m 52s) Loss: 0.0016(0.0513) Grad: 268.0724  LR: 0.000020  \n","Epoch: [1][2900/5743] Elapsed 11m 42s (remain 11m 27s) Loss: 0.0005(0.0497) Grad: 114.4449  LR: 0.000020  \n","Epoch: [1][3000/5743] Elapsed 12m 6s (remain 11m 3s) Loss: 0.0004(0.0482) Grad: 212.7341  LR: 0.000020  \n","Epoch: [1][3100/5743] Elapsed 12m 30s (remain 10m 39s) Loss: 0.0224(0.0468) Grad: 8423.2217  LR: 0.000020  \n","Epoch: [1][3200/5743] Elapsed 12m 54s (remain 10m 15s) Loss: 0.0056(0.0455) Grad: 2510.1418  LR: 0.000020  \n","Epoch: [1][3300/5743] Elapsed 13m 18s (remain 9m 50s) Loss: 0.0000(0.0443) Grad: 28.5916  LR: 0.000020  \n","Epoch: [1][3400/5743] Elapsed 13m 42s (remain 9m 26s) Loss: 0.0029(0.0432) Grad: 568.5084  LR: 0.000020  \n","Epoch: [1][3500/5743] Elapsed 14m 6s (remain 9m 2s) Loss: 0.0097(0.0422) Grad: 3132.3511  LR: 0.000020  \n","Epoch: [1][3600/5743] Elapsed 14m 31s (remain 8m 38s) Loss: 0.0188(0.0412) Grad: 6038.9722  LR: 0.000019  \n","Epoch: [1][3700/5743] Elapsed 14m 55s (remain 8m 13s) Loss: 0.0208(0.0402) Grad: 1647.2957  LR: 0.000019  \n","Epoch: [1][3800/5743] Elapsed 15m 19s (remain 7m 49s) Loss: 0.0018(0.0392) Grad: 371.3403  LR: 0.000019  \n","Epoch: [1][3900/5743] Elapsed 15m 43s (remain 7m 25s) Loss: 0.0034(0.0383) Grad: 1872.2382  LR: 0.000019  \n","Epoch: [1][4000/5743] Elapsed 16m 7s (remain 7m 1s) Loss: 0.0004(0.0375) Grad: 68.6268  LR: 0.000019  \n","Epoch: [1][4100/5743] Elapsed 16m 32s (remain 6m 37s) Loss: 0.0275(0.0367) Grad: 6442.7031  LR: 0.000019  \n","Epoch: [1][4200/5743] Elapsed 16m 56s (remain 6m 13s) Loss: 0.0113(0.0359) Grad: 3045.4790  LR: 0.000019  \n","Epoch: [1][4300/5743] Elapsed 17m 20s (remain 5m 48s) Loss: 0.0001(0.0352) Grad: 36.9324  LR: 0.000019  \n","Epoch: [1][4400/5743] Elapsed 17m 44s (remain 5m 24s) Loss: 0.0036(0.0345) Grad: 1914.8209  LR: 0.000019  \n","Epoch: [1][4500/5743] Elapsed 18m 8s (remain 5m 0s) Loss: 0.0536(0.0339) Grad: 12991.1357  LR: 0.000019  \n","Epoch: [1][4600/5743] Elapsed 18m 32s (remain 4m 36s) Loss: 0.0046(0.0332) Grad: 1651.6139  LR: 0.000019  \n","Epoch: [1][4700/5743] Elapsed 18m 57s (remain 4m 12s) Loss: 0.0002(0.0326) Grad: 74.6112  LR: 0.000019  \n","Epoch: [1][4800/5743] Elapsed 19m 21s (remain 3m 47s) Loss: 0.0040(0.0320) Grad: 956.9886  LR: 0.000019  \n","Epoch: [1][4900/5743] Elapsed 19m 45s (remain 3m 23s) Loss: 0.0016(0.0314) Grad: 739.7721  LR: 0.000018  \n","Epoch: [1][5000/5743] Elapsed 20m 9s (remain 2m 59s) Loss: 0.0001(0.0309) Grad: 40.7898  LR: 0.000018  \n","Epoch: [1][5100/5743] Elapsed 20m 33s (remain 2m 35s) Loss: 0.0004(0.0303) Grad: 122.3009  LR: 0.000018  \n","Epoch: [1][5200/5743] Elapsed 20m 57s (remain 2m 11s) Loss: 0.0000(0.0298) Grad: 45.3998  LR: 0.000018  \n","Epoch: [1][5300/5743] Elapsed 21m 22s (remain 1m 46s) Loss: 0.0040(0.0293) Grad: 587.3419  LR: 0.000018  \n","Epoch: [1][5400/5743] Elapsed 21m 46s (remain 1m 22s) Loss: 0.0000(0.0289) Grad: 33.1643  LR: 0.000018  \n","Epoch: [1][5500/5743] Elapsed 22m 10s (remain 0m 58s) Loss: 0.0038(0.0284) Grad: 1957.9110  LR: 0.000018  \n","Epoch: [1][5600/5743] Elapsed 22m 34s (remain 0m 34s) Loss: 0.0042(0.0280) Grad: 898.2176  LR: 0.000018  \n","Epoch: [1][5700/5743] Elapsed 22m 58s (remain 0m 10s) Loss: 0.0012(0.0276) Grad: 278.5894  LR: 0.000018  \n","Epoch: [1][5742/5743] Elapsed 23m 8s (remain 0m 0s) Loss: 0.0003(0.0274) Grad: 1002.7850  LR: 0.000018  \n","EVAL: [0/1407] Elapsed 0m 0s (remain 10m 53s) Loss: 0.0002(0.0002) \n","EVAL: [100/1407] Elapsed 0m 12s (remain 2m 41s) Loss: 0.0002(0.0049) \n","EVAL: [200/1407] Elapsed 0m 24s (remain 2m 26s) Loss: 0.0014(0.0049) \n","EVAL: [300/1407] Elapsed 0m 36s (remain 2m 14s) Loss: 0.0017(0.0043) \n","EVAL: [400/1407] Elapsed 0m 48s (remain 2m 2s) Loss: 0.0000(0.0044) \n","EVAL: [500/1407] Elapsed 1m 0s (remain 1m 49s) Loss: 0.0049(0.0043) \n","EVAL: [600/1407] Elapsed 1m 12s (remain 1m 37s) Loss: 0.0007(0.0042) \n","EVAL: [700/1407] Elapsed 1m 24s (remain 1m 25s) Loss: 0.0148(0.0043) \n","EVAL: [800/1407] Elapsed 1m 36s (remain 1m 13s) Loss: 0.0075(0.0046) \n","EVAL: [900/1407] Elapsed 1m 48s (remain 1m 1s) Loss: 0.0000(0.0049) \n","EVAL: [1000/1407] Elapsed 2m 0s (remain 0m 49s) Loss: 0.0038(0.0048) \n","EVAL: [1100/1407] Elapsed 2m 12s (remain 0m 36s) Loss: 0.0263(0.0048) \n","EVAL: [1200/1407] Elapsed 2m 25s (remain 0m 24s) Loss: 0.0001(0.0048) \n","EVAL: [1300/1407] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0000(0.0047) \n","EVAL: [1400/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0045) \n","EVAL: [1406/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0045) \n","Epoch 1 - avg_train_loss: 0.0274  avg_val_loss: 0.0045  time: 1563s\n","Epoch 1 - Score: 0.8467\n","Epoch 1 - Save Best Score: 0.8467 Model\n","Epoch: [2][0/5743] Elapsed 0m 0s (remain 61m 26s) Loss: 0.0180(0.0180) Grad: 25130.7852  LR: 0.000018  \n","Epoch: [2][100/5743] Elapsed 0m 28s (remain 26m 7s) Loss: 0.0001(0.0027) Grad: 538.4601  LR: 0.000018  \n","Epoch: [2][200/5743] Elapsed 0m 54s (remain 24m 49s) Loss: 0.0003(0.0032) Grad: 1139.8209  LR: 0.000018  \n","Epoch: [2][300/5743] Elapsed 1m 18s (remain 23m 34s) Loss: 0.0000(0.0035) Grad: 73.7938  LR: 0.000018  \n","Epoch: [2][400/5743] Elapsed 1m 42s (remain 22m 45s) Loss: 0.0000(0.0033) Grad: 72.6415  LR: 0.000017  \n","Epoch: [2][500/5743] Elapsed 2m 6s (remain 22m 6s) Loss: 0.0039(0.0035) Grad: 14216.0732  LR: 0.000017  \n","Epoch: [2][600/5743] Elapsed 2m 30s (remain 21m 31s) Loss: 0.0001(0.0035) Grad: 567.3922  LR: 0.000017  \n","Epoch: [2][700/5743] Elapsed 2m 55s (remain 21m 0s) Loss: 0.0000(0.0038) Grad: 82.6476  LR: 0.000017  \n","Epoch: [2][800/5743] Elapsed 3m 19s (remain 20m 32s) Loss: 0.0010(0.0038) Grad: 7758.2256  LR: 0.000017  \n","Epoch: [2][900/5743] Elapsed 3m 43s (remain 20m 3s) Loss: 0.0017(0.0037) Grad: 18150.1094  LR: 0.000017  \n","Epoch: [2][1000/5743] Elapsed 4m 8s (remain 19m 35s) Loss: 0.0037(0.0037) Grad: 15393.1533  LR: 0.000017  \n","Epoch: [2][1100/5743] Elapsed 4m 32s (remain 19m 8s) Loss: 0.0418(0.0038) Grad: 41209.6719  LR: 0.000017  \n","Epoch: [2][1200/5743] Elapsed 4m 56s (remain 18m 41s) Loss: 0.0000(0.0037) Grad: 19.2460  LR: 0.000017  \n","Epoch: [2][1300/5743] Elapsed 5m 20s (remain 18m 14s) Loss: 0.0009(0.0038) Grad: 5321.7026  LR: 0.000017  \n","Epoch: [2][1400/5743] Elapsed 5m 44s (remain 17m 48s) Loss: 0.0107(0.0038) Grad: 18096.3418  LR: 0.000017  \n","Epoch: [2][1500/5743] Elapsed 6m 8s (remain 17m 22s) Loss: 0.0002(0.0037) Grad: 804.0021  LR: 0.000017  \n","Epoch: [2][1600/5743] Elapsed 6m 33s (remain 16m 57s) Loss: 0.0000(0.0037) Grad: 91.8517  LR: 0.000017  \n","Epoch: [2][1700/5743] Elapsed 6m 57s (remain 16m 31s) Loss: 0.0001(0.0037) Grad: 264.3683  LR: 0.000016  \n","Epoch: [2][1800/5743] Elapsed 7m 21s (remain 16m 6s) Loss: 0.0001(0.0037) Grad: 444.6758  LR: 0.000016  \n","Epoch: [2][1900/5743] Elapsed 7m 45s (remain 15m 41s) Loss: 0.0008(0.0036) Grad: 2577.0293  LR: 0.000016  \n","Epoch: [2][2000/5743] Elapsed 8m 10s (remain 15m 16s) Loss: 0.0024(0.0036) Grad: 2108.5093  LR: 0.000016  \n","Epoch: [2][2100/5743] Elapsed 8m 34s (remain 14m 52s) Loss: 0.0000(0.0037) Grad: 34.3749  LR: 0.000016  \n","Epoch: [2][2200/5743] Elapsed 8m 59s (remain 14m 28s) Loss: 0.0005(0.0037) Grad: 4885.8628  LR: 0.000016  \n","Epoch: [2][2300/5743] Elapsed 9m 24s (remain 14m 4s) Loss: 0.0003(0.0036) Grad: 1521.1141  LR: 0.000016  \n","Epoch: [2][2400/5743] Elapsed 9m 48s (remain 13m 39s) Loss: 0.0014(0.0036) Grad: 8245.5283  LR: 0.000016  \n","Epoch: [2][2500/5743] Elapsed 10m 12s (remain 13m 14s) Loss: 0.0008(0.0036) Grad: 2191.4673  LR: 0.000016  \n","Epoch: [2][2600/5743] Elapsed 10m 37s (remain 12m 49s) Loss: 0.0009(0.0036) Grad: 4257.1782  LR: 0.000016  \n","Epoch: [2][2700/5743] Elapsed 11m 1s (remain 12m 25s) Loss: 0.0000(0.0036) Grad: 293.8303  LR: 0.000016  \n","Epoch: [2][2800/5743] Elapsed 11m 25s (remain 12m 0s) Loss: 0.0000(0.0036) Grad: 43.8471  LR: 0.000016  \n","Epoch: [2][2900/5743] Elapsed 11m 50s (remain 11m 35s) Loss: 0.0000(0.0035) Grad: 18.7081  LR: 0.000016  \n","Epoch: [2][3000/5743] Elapsed 12m 14s (remain 11m 11s) Loss: 0.0054(0.0035) Grad: 18432.7402  LR: 0.000015  \n","Epoch: [2][3100/5743] Elapsed 12m 38s (remain 10m 46s) Loss: 0.0032(0.0035) Grad: 14679.9316  LR: 0.000015  \n","Epoch: [2][3200/5743] Elapsed 13m 3s (remain 10m 21s) Loss: 0.0009(0.0035) Grad: 5224.5005  LR: 0.000015  \n","Epoch: [2][3300/5743] Elapsed 13m 27s (remain 9m 57s) Loss: 0.0000(0.0035) Grad: 42.2089  LR: 0.000015  \n","Epoch: [2][3400/5743] Elapsed 13m 51s (remain 9m 32s) Loss: 0.0000(0.0035) Grad: 96.4720  LR: 0.000015  \n","Epoch: [2][3500/5743] Elapsed 14m 16s (remain 9m 8s) Loss: 0.0000(0.0035) Grad: 17.5245  LR: 0.000015  \n","Epoch: [2][3600/5743] Elapsed 14m 40s (remain 8m 43s) Loss: 0.0006(0.0035) Grad: 4012.9404  LR: 0.000015  \n","Epoch: [2][3700/5743] Elapsed 15m 4s (remain 8m 19s) Loss: 0.0013(0.0034) Grad: 6934.4019  LR: 0.000015  \n","Epoch: [2][3800/5743] Elapsed 15m 29s (remain 7m 54s) Loss: 0.0001(0.0035) Grad: 420.1849  LR: 0.000015  \n","Epoch: [2][3900/5743] Elapsed 15m 53s (remain 7m 30s) Loss: 0.0001(0.0035) Grad: 904.5406  LR: 0.000015  \n","Epoch: [2][4000/5743] Elapsed 16m 17s (remain 7m 5s) Loss: 0.0009(0.0035) Grad: 3370.3398  LR: 0.000015  \n","Epoch: [2][4100/5743] Elapsed 16m 42s (remain 6m 41s) Loss: 0.0002(0.0035) Grad: 1369.0894  LR: 0.000015  \n","Epoch: [2][4200/5743] Elapsed 17m 6s (remain 6m 16s) Loss: 0.0000(0.0034) Grad: 103.3106  LR: 0.000015  \n","Epoch: [2][4300/5743] Elapsed 17m 30s (remain 5m 52s) Loss: 0.0000(0.0034) Grad: 38.8130  LR: 0.000014  \n","Epoch: [2][4400/5743] Elapsed 17m 55s (remain 5m 27s) Loss: 0.0178(0.0035) Grad: 7885.7954  LR: 0.000014  \n","Epoch: [2][4500/5743] Elapsed 18m 19s (remain 5m 3s) Loss: 0.0019(0.0035) Grad: 15903.7217  LR: 0.000014  \n","Epoch: [2][4600/5743] Elapsed 18m 43s (remain 4m 38s) Loss: 0.0000(0.0035) Grad: 335.4640  LR: 0.000014  \n","Epoch: [2][4700/5743] Elapsed 19m 8s (remain 4m 14s) Loss: 0.0338(0.0035) Grad: 9456.7197  LR: 0.000014  \n","Epoch: [2][4800/5743] Elapsed 19m 32s (remain 3m 50s) Loss: 0.0000(0.0035) Grad: 113.2711  LR: 0.000014  \n","Epoch: [2][4900/5743] Elapsed 19m 56s (remain 3m 25s) Loss: 0.0005(0.0035) Grad: 3953.3787  LR: 0.000014  \n","Epoch: [2][5000/5743] Elapsed 20m 21s (remain 3m 1s) Loss: 0.0254(0.0035) Grad: 54943.1406  LR: 0.000014  \n","Epoch: [2][5100/5743] Elapsed 20m 45s (remain 2m 36s) Loss: 0.0004(0.0035) Grad: 2916.1938  LR: 0.000014  \n","Epoch: [2][5200/5743] Elapsed 21m 9s (remain 2m 12s) Loss: 0.0000(0.0035) Grad: 123.2616  LR: 0.000014  \n","Epoch: [2][5300/5743] Elapsed 21m 33s (remain 1m 47s) Loss: 0.0002(0.0035) Grad: 569.8438  LR: 0.000014  \n","Epoch: [2][5400/5743] Elapsed 21m 58s (remain 1m 23s) Loss: 0.0008(0.0035) Grad: 9293.3467  LR: 0.000014  \n","Epoch: [2][5500/5743] Elapsed 22m 22s (remain 0m 59s) Loss: 0.0000(0.0035) Grad: 42.2979  LR: 0.000014  \n","Epoch: [2][5600/5743] Elapsed 22m 46s (remain 0m 34s) Loss: 0.0000(0.0035) Grad: 26.3914  LR: 0.000013  \n","Epoch: [2][5700/5743] Elapsed 23m 10s (remain 0m 10s) Loss: 0.0015(0.0035) Grad: 11557.7236  LR: 0.000013  \n","Epoch: [2][5742/5743] Elapsed 23m 20s (remain 0m 0s) Loss: 0.0021(0.0035) Grad: 8308.4160  LR: 0.000013  \n","EVAL: [0/1407] Elapsed 0m 0s (remain 10m 28s) Loss: 0.0001(0.0001) \n","EVAL: [100/1407] Elapsed 0m 12s (remain 2m 40s) Loss: 0.0001(0.0039) \n","EVAL: [200/1407] Elapsed 0m 24s (remain 2m 26s) Loss: 0.0031(0.0047) \n","EVAL: [300/1407] Elapsed 0m 36s (remain 2m 14s) Loss: 0.0021(0.0041) \n","EVAL: [400/1407] Elapsed 0m 48s (remain 2m 2s) Loss: 0.0000(0.0040) \n","EVAL: [500/1407] Elapsed 1m 0s (remain 1m 49s) Loss: 0.0046(0.0041) \n","EVAL: [600/1407] Elapsed 1m 12s (remain 1m 37s) Loss: 0.0008(0.0039) \n","EVAL: [700/1407] Elapsed 1m 24s (remain 1m 25s) Loss: 0.0180(0.0040) \n","EVAL: [800/1407] Elapsed 1m 36s (remain 1m 13s) Loss: 0.0248(0.0046) \n","EVAL: [900/1407] Elapsed 1m 48s (remain 1m 1s) Loss: 0.0000(0.0050) \n","EVAL: [1000/1407] Elapsed 2m 0s (remain 0m 49s) Loss: 0.0000(0.0049) \n","EVAL: [1100/1407] Elapsed 2m 13s (remain 0m 36s) Loss: 0.0390(0.0049) \n","EVAL: [1200/1407] Elapsed 2m 25s (remain 0m 24s) Loss: 0.0001(0.0049) \n","EVAL: [1300/1407] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0000(0.0047) \n","EVAL: [1400/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0046) \n","EVAL: [1406/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0045) \n","Epoch 2 - avg_train_loss: 0.0035  avg_val_loss: 0.0045  time: 1575s\n","Epoch 2 - Score: 0.8626\n","Epoch 2 - Save Best Score: 0.8626 Model\n","Epoch: [3][0/5743] Elapsed 0m 0s (remain 55m 35s) Loss: 0.0002(0.0002) Grad: 1067.4196  LR: 0.000013  \n","Epoch: [3][100/5743] Elapsed 0m 28s (remain 26m 30s) Loss: 0.0002(0.0033) Grad: 659.6199  LR: 0.000013  \n","Epoch: [3][200/5743] Elapsed 0m 54s (remain 25m 3s) Loss: 0.0000(0.0027) Grad: 14.8205  LR: 0.000013  \n","Epoch: [3][300/5743] Elapsed 1m 18s (remain 23m 43s) Loss: 0.0000(0.0026) Grad: 16.1798  LR: 0.000013  \n","Epoch: [3][400/5743] Elapsed 1m 43s (remain 22m 52s) Loss: 0.0000(0.0028) Grad: 14.1394  LR: 0.000013  \n","Epoch: [3][500/5743] Elapsed 2m 7s (remain 22m 11s) Loss: 0.0000(0.0028) Grad: 14.6793  LR: 0.000013  \n","Epoch: [3][600/5743] Elapsed 2m 31s (remain 21m 36s) Loss: 0.0001(0.0027) Grad: 632.4421  LR: 0.000013  \n","Epoch: [3][700/5743] Elapsed 2m 55s (remain 21m 4s) Loss: 0.0000(0.0026) Grad: 47.0302  LR: 0.000013  \n","Epoch: [3][800/5743] Elapsed 3m 20s (remain 20m 34s) Loss: 0.0002(0.0029) Grad: 684.2684  LR: 0.000013  \n","Epoch: [3][900/5743] Elapsed 3m 44s (remain 20m 5s) Loss: 0.0031(0.0030) Grad: 3607.0535  LR: 0.000013  \n","Epoch: [3][1000/5743] Elapsed 4m 8s (remain 19m 37s) Loss: 0.0000(0.0031) Grad: 43.8917  LR: 0.000013  \n","Epoch: [3][1100/5743] Elapsed 4m 32s (remain 19m 10s) Loss: 0.0070(0.0030) Grad: 20797.4219  LR: 0.000012  \n","Epoch: [3][1200/5743] Elapsed 4m 57s (remain 18m 43s) Loss: 0.0001(0.0031) Grad: 278.3212  LR: 0.000012  \n","Epoch: [3][1300/5743] Elapsed 5m 21s (remain 18m 17s) Loss: 0.0004(0.0030) Grad: 1379.4617  LR: 0.000012  \n","Epoch: [3][1400/5743] Elapsed 5m 45s (remain 17m 50s) Loss: 0.0001(0.0030) Grad: 154.9360  LR: 0.000012  \n","Epoch: [3][1500/5743] Elapsed 6m 9s (remain 17m 24s) Loss: 0.0038(0.0029) Grad: 4478.1982  LR: 0.000012  \n","Epoch: [3][1600/5743] Elapsed 6m 34s (remain 16m 59s) Loss: 0.0000(0.0029) Grad: 10.3358  LR: 0.000012  \n","Epoch: [3][1700/5743] Elapsed 6m 58s (remain 16m 34s) Loss: 0.0001(0.0029) Grad: 503.1984  LR: 0.000012  \n","Epoch: [3][1800/5743] Elapsed 7m 22s (remain 16m 9s) Loss: 0.0002(0.0029) Grad: 715.3236  LR: 0.000012  \n","Epoch: [3][1900/5743] Elapsed 7m 47s (remain 15m 44s) Loss: 0.0007(0.0029) Grad: 2293.4487  LR: 0.000012  \n","Epoch: [3][2000/5743] Elapsed 8m 11s (remain 15m 18s) Loss: 0.0001(0.0030) Grad: 621.7363  LR: 0.000012  \n","Epoch: [3][2100/5743] Elapsed 8m 35s (remain 14m 53s) Loss: 0.0001(0.0029) Grad: 350.7739  LR: 0.000012  \n","Epoch: [3][2200/5743] Elapsed 8m 59s (remain 14m 28s) Loss: 0.0005(0.0030) Grad: 738.4132  LR: 0.000012  \n","Epoch: [3][2300/5743] Elapsed 9m 24s (remain 14m 3s) Loss: 0.0077(0.0030) Grad: 58624.3594  LR: 0.000012  \n","Epoch: [3][2400/5743] Elapsed 9m 48s (remain 13m 38s) Loss: 0.0007(0.0029) Grad: 4656.3945  LR: 0.000011  \n","Epoch: [3][2500/5743] Elapsed 10m 12s (remain 13m 13s) Loss: 0.0000(0.0029) Grad: 11.5955  LR: 0.000011  \n","Epoch: [3][2600/5743] Elapsed 10m 36s (remain 12m 49s) Loss: 0.0000(0.0029) Grad: 6.0136  LR: 0.000011  \n","Epoch: [3][2700/5743] Elapsed 11m 0s (remain 12m 24s) Loss: 0.0000(0.0029) Grad: 132.0177  LR: 0.000011  \n","Epoch: [3][2800/5743] Elapsed 11m 25s (remain 11m 59s) Loss: 0.0062(0.0029) Grad: 18923.2793  LR: 0.000011  \n","Epoch: [3][2900/5743] Elapsed 11m 49s (remain 11m 35s) Loss: 0.0001(0.0029) Grad: 152.9011  LR: 0.000011  \n","Epoch: [3][3000/5743] Elapsed 12m 13s (remain 11m 10s) Loss: 0.0000(0.0029) Grad: 23.7728  LR: 0.000011  \n","Epoch: [3][3100/5743] Elapsed 12m 38s (remain 10m 45s) Loss: 0.0173(0.0029) Grad: 5644.4463  LR: 0.000011  \n","Epoch: [3][3200/5743] Elapsed 13m 2s (remain 10m 21s) Loss: 0.0000(0.0028) Grad: 9.8399  LR: 0.000011  \n","Epoch: [3][3300/5743] Elapsed 13m 26s (remain 9m 56s) Loss: 0.0007(0.0028) Grad: 2729.6316  LR: 0.000011  \n","Epoch: [3][3400/5743] Elapsed 13m 50s (remain 9m 31s) Loss: 0.0001(0.0028) Grad: 190.0585  LR: 0.000011  \n","Epoch: [3][3500/5743] Elapsed 14m 14s (remain 9m 7s) Loss: 0.0001(0.0028) Grad: 134.0294  LR: 0.000011  \n","Epoch: [3][3600/5743] Elapsed 14m 39s (remain 8m 42s) Loss: 0.0001(0.0028) Grad: 69.2652  LR: 0.000011  \n","Epoch: [3][3700/5743] Elapsed 15m 3s (remain 8m 18s) Loss: 0.0000(0.0028) Grad: 25.5842  LR: 0.000010  \n","Epoch: [3][3800/5743] Elapsed 15m 27s (remain 7m 53s) Loss: 0.0001(0.0028) Grad: 246.6748  LR: 0.000010  \n","Epoch: [3][3900/5743] Elapsed 15m 51s (remain 7m 29s) Loss: 0.0002(0.0028) Grad: 456.2875  LR: 0.000010  \n","Epoch: [3][4000/5743] Elapsed 16m 15s (remain 7m 4s) Loss: 0.0028(0.0028) Grad: 6536.9443  LR: 0.000010  \n","Epoch: [3][4100/5743] Elapsed 16m 40s (remain 6m 40s) Loss: 0.0000(0.0028) Grad: 64.9651  LR: 0.000010  \n","Epoch: [3][4200/5743] Elapsed 17m 4s (remain 6m 16s) Loss: 0.0000(0.0028) Grad: 67.1088  LR: 0.000010  \n","Epoch: [3][4300/5743] Elapsed 17m 28s (remain 5m 51s) Loss: 0.0076(0.0028) Grad: 2551.4307  LR: 0.000010  \n","Epoch: [3][4400/5743] Elapsed 17m 53s (remain 5m 27s) Loss: 0.0000(0.0028) Grad: 15.3528  LR: 0.000010  \n","Epoch: [3][4500/5743] Elapsed 18m 17s (remain 5m 2s) Loss: 0.0001(0.0028) Grad: 78.2840  LR: 0.000010  \n","Epoch: [3][4600/5743] Elapsed 18m 41s (remain 4m 38s) Loss: 0.0001(0.0028) Grad: 108.8928  LR: 0.000010  \n","Epoch: [3][4700/5743] Elapsed 19m 5s (remain 4m 13s) Loss: 0.0000(0.0028) Grad: 848.3239  LR: 0.000010  \n","Epoch: [3][4800/5743] Elapsed 19m 29s (remain 3m 49s) Loss: 0.0000(0.0028) Grad: 14.6735  LR: 0.000010  \n","Epoch: [3][4900/5743] Elapsed 19m 53s (remain 3m 25s) Loss: 0.0010(0.0028) Grad: 1292.0961  LR: 0.000010  \n","Epoch: [3][5000/5743] Elapsed 20m 18s (remain 3m 0s) Loss: 0.0000(0.0028) Grad: 75.6228  LR: 0.000009  \n","Epoch: [3][5100/5743] Elapsed 20m 42s (remain 2m 36s) Loss: 0.0001(0.0028) Grad: 171.7361  LR: 0.000009  \n","Epoch: [3][5200/5743] Elapsed 21m 6s (remain 2m 11s) Loss: 0.0000(0.0028) Grad: 104.8017  LR: 0.000009  \n","Epoch: [3][5300/5743] Elapsed 21m 30s (remain 1m 47s) Loss: 0.0010(0.0028) Grad: 1395.4070  LR: 0.000009  \n","Epoch: [3][5400/5743] Elapsed 21m 54s (remain 1m 23s) Loss: 0.0015(0.0028) Grad: 3985.9695  LR: 0.000009  \n","Epoch: [3][5500/5743] Elapsed 22m 18s (remain 0m 58s) Loss: 0.0000(0.0028) Grad: 45.0033  LR: 0.000009  \n","Epoch: [3][5600/5743] Elapsed 22m 43s (remain 0m 34s) Loss: 0.0000(0.0028) Grad: 7.6019  LR: 0.000009  \n","Epoch: [3][5700/5743] Elapsed 23m 7s (remain 0m 10s) Loss: 0.0001(0.0028) Grad: 835.4563  LR: 0.000009  \n","Epoch: [3][5742/5743] Elapsed 23m 17s (remain 0m 0s) Loss: 0.0001(0.0028) Grad: 1001.9123  LR: 0.000009  \n","EVAL: [0/1407] Elapsed 0m 0s (remain 9m 55s) Loss: 0.0001(0.0001) \n","EVAL: [100/1407] Elapsed 0m 12s (remain 2m 41s) Loss: 0.0001(0.0042) \n","EVAL: [200/1407] Elapsed 0m 24s (remain 2m 26s) Loss: 0.0011(0.0047) \n","EVAL: [300/1407] Elapsed 0m 36s (remain 2m 14s) Loss: 0.0006(0.0040) \n","EVAL: [400/1407] Elapsed 0m 48s (remain 2m 1s) Loss: 0.0000(0.0041) \n","EVAL: [500/1407] Elapsed 1m 0s (remain 1m 49s) Loss: 0.0007(0.0039) \n","EVAL: [600/1407] Elapsed 1m 12s (remain 1m 37s) Loss: 0.0002(0.0037) \n","EVAL: [700/1407] Elapsed 1m 24s (remain 1m 25s) Loss: 0.0142(0.0036) \n","EVAL: [800/1407] Elapsed 1m 36s (remain 1m 13s) Loss: 0.0110(0.0041) \n","EVAL: [900/1407] Elapsed 1m 48s (remain 1m 1s) Loss: 0.0000(0.0044) \n","EVAL: [1000/1407] Elapsed 2m 1s (remain 0m 49s) Loss: 0.0000(0.0043) \n","EVAL: [1100/1407] Elapsed 2m 13s (remain 0m 36s) Loss: 0.0427(0.0045) \n","EVAL: [1200/1407] Elapsed 2m 25s (remain 0m 24s) Loss: 0.0000(0.0045) \n","EVAL: [1300/1407] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0000(0.0044) \n","EVAL: [1400/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0042) \n","EVAL: [1406/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0042) \n","Epoch 3 - avg_train_loss: 0.0028  avg_val_loss: 0.0042  time: 1572s\n","Epoch 3 - Score: 0.8697\n","Epoch 3 - Save Best Score: 0.8697 Model\n","Epoch: [4][0/5743] Elapsed 0m 0s (remain 56m 50s) Loss: 0.0013(0.0013) Grad: 3038.6584  LR: 0.000009  \n","Epoch: [4][100/5743] Elapsed 0m 29s (remain 27m 14s) Loss: 0.0040(0.0025) Grad: 3832.7520  LR: 0.000009  \n","Epoch: [4][200/5743] Elapsed 0m 54s (remain 24m 55s) Loss: 0.0000(0.0021) Grad: 13.8650  LR: 0.000009  \n","Epoch: [4][300/5743] Elapsed 1m 18s (remain 23m 38s) Loss: 0.0000(0.0027) Grad: 132.2292  LR: 0.000009  \n","Epoch: [4][400/5743] Elapsed 1m 42s (remain 22m 47s) Loss: 0.0000(0.0025) Grad: 7.9021  LR: 0.000009  \n","Epoch: [4][500/5743] Elapsed 2m 6s (remain 22m 6s) Loss: 0.0000(0.0022) Grad: 61.0069  LR: 0.000009  \n","Epoch: [4][600/5743] Elapsed 2m 30s (remain 21m 30s) Loss: 0.0002(0.0022) Grad: 640.8725  LR: 0.000008  \n","Epoch: [4][700/5743] Elapsed 2m 55s (remain 20m 58s) Loss: 0.0012(0.0022) Grad: 5162.1978  LR: 0.000008  \n","Epoch: [4][800/5743] Elapsed 3m 19s (remain 20m 29s) Loss: 0.0000(0.0022) Grad: 46.4707  LR: 0.000008  \n","Epoch: [4][900/5743] Elapsed 3m 43s (remain 20m 0s) Loss: 0.0000(0.0022) Grad: 7.5057  LR: 0.000008  \n","Epoch: [4][1000/5743] Elapsed 4m 7s (remain 19m 33s) Loss: 0.0000(0.0022) Grad: 19.0678  LR: 0.000008  \n","Epoch: [4][1100/5743] Elapsed 4m 32s (remain 19m 7s) Loss: 0.0003(0.0022) Grad: 4832.0654  LR: 0.000008  \n","Epoch: [4][1200/5743] Elapsed 4m 56s (remain 18m 40s) Loss: 0.0001(0.0021) Grad: 308.8330  LR: 0.000008  \n","Epoch: [4][1300/5743] Elapsed 5m 20s (remain 18m 13s) Loss: 0.0000(0.0022) Grad: 5.8763  LR: 0.000008  \n","Epoch: [4][1400/5743] Elapsed 5m 44s (remain 17m 47s) Loss: 0.0001(0.0021) Grad: 205.3762  LR: 0.000008  \n","Epoch: [4][1500/5743] Elapsed 6m 8s (remain 17m 21s) Loss: 0.0057(0.0022) Grad: 22354.3281  LR: 0.000008  \n","Epoch: [4][1600/5743] Elapsed 6m 32s (remain 16m 56s) Loss: 0.0046(0.0022) Grad: 74363.4531  LR: 0.000008  \n","Epoch: [4][1700/5743] Elapsed 6m 56s (remain 16m 30s) Loss: 0.0000(0.0021) Grad: 7.6705  LR: 0.000008  \n","Epoch: [4][1800/5743] Elapsed 7m 21s (remain 16m 5s) Loss: 0.0000(0.0022) Grad: 452.9641  LR: 0.000007  \n","Epoch: [4][1900/5743] Elapsed 7m 45s (remain 15m 40s) Loss: 0.0000(0.0022) Grad: 50.8763  LR: 0.000007  \n","Epoch: [4][2000/5743] Elapsed 8m 9s (remain 15m 15s) Loss: 0.0148(0.0022) Grad: 33539.0508  LR: 0.000007  \n","Epoch: [4][2100/5743] Elapsed 8m 33s (remain 14m 50s) Loss: 0.0000(0.0022) Grad: 7.3517  LR: 0.000007  \n","Epoch: [4][2200/5743] Elapsed 8m 57s (remain 14m 25s) Loss: 0.0050(0.0022) Grad: 15908.2764  LR: 0.000007  \n","Epoch: [4][2300/5743] Elapsed 9m 22s (remain 14m 0s) Loss: 0.0015(0.0022) Grad: 7460.7646  LR: 0.000007  \n","Epoch: [4][2400/5743] Elapsed 9m 46s (remain 13m 36s) Loss: 0.0001(0.0022) Grad: 377.1212  LR: 0.000007  \n","Epoch: [4][2500/5743] Elapsed 10m 10s (remain 13m 11s) Loss: 0.0000(0.0022) Grad: 60.9114  LR: 0.000007  \n","Epoch: [4][2600/5743] Elapsed 10m 34s (remain 12m 46s) Loss: 0.0000(0.0023) Grad: 130.0903  LR: 0.000007  \n","Epoch: [4][2700/5743] Elapsed 10m 58s (remain 12m 22s) Loss: 0.0000(0.0022) Grad: 25.3453  LR: 0.000007  \n","Epoch: [4][2800/5743] Elapsed 11m 23s (remain 11m 57s) Loss: 0.0000(0.0023) Grad: 17.1123  LR: 0.000007  \n","Epoch: [4][2900/5743] Elapsed 11m 47s (remain 11m 32s) Loss: 0.0000(0.0022) Grad: 15.9683  LR: 0.000007  \n","Epoch: [4][3000/5743] Elapsed 12m 11s (remain 11m 8s) Loss: 0.0406(0.0023) Grad: 22968.8301  LR: 0.000007  \n","Epoch: [4][3100/5743] Elapsed 12m 35s (remain 10m 43s) Loss: 0.0000(0.0022) Grad: 45.9466  LR: 0.000006  \n","Epoch: [4][3200/5743] Elapsed 12m 59s (remain 10m 19s) Loss: 0.0000(0.0022) Grad: 11.9710  LR: 0.000006  \n","Epoch: [4][3300/5743] Elapsed 13m 24s (remain 9m 54s) Loss: 0.0003(0.0023) Grad: 4099.8818  LR: 0.000006  \n","Epoch: [4][3400/5743] Elapsed 13m 48s (remain 9m 30s) Loss: 0.0002(0.0023) Grad: 1876.4341  LR: 0.000006  \n","Epoch: [4][3500/5743] Elapsed 14m 12s (remain 9m 5s) Loss: 0.0001(0.0022) Grad: 686.0372  LR: 0.000006  \n","Epoch: [4][3600/5743] Elapsed 14m 36s (remain 8m 41s) Loss: 0.0127(0.0023) Grad: 52565.0938  LR: 0.000006  \n","Epoch: [4][3700/5743] Elapsed 15m 0s (remain 8m 17s) Loss: 0.0021(0.0023) Grad: 13637.6211  LR: 0.000006  \n","Epoch: [4][3800/5743] Elapsed 15m 25s (remain 7m 52s) Loss: 0.0000(0.0023) Grad: 100.9552  LR: 0.000006  \n","Epoch: [4][3900/5743] Elapsed 15m 49s (remain 7m 28s) Loss: 0.0000(0.0023) Grad: 377.1543  LR: 0.000006  \n","Epoch: [4][4000/5743] Elapsed 16m 13s (remain 7m 3s) Loss: 0.0001(0.0023) Grad: 841.2525  LR: 0.000006  \n","Epoch: [4][4100/5743] Elapsed 16m 37s (remain 6m 39s) Loss: 0.0007(0.0023) Grad: 3600.3955  LR: 0.000006  \n","Epoch: [4][4200/5743] Elapsed 17m 2s (remain 6m 15s) Loss: 0.0001(0.0023) Grad: 257.3127  LR: 0.000006  \n","Epoch: [4][4300/5743] Elapsed 17m 26s (remain 5m 50s) Loss: 0.0031(0.0024) Grad: 21896.5039  LR: 0.000006  \n","Epoch: [4][4400/5743] Elapsed 17m 50s (remain 5m 26s) Loss: 0.0000(0.0024) Grad: 32.4527  LR: 0.000005  \n","Epoch: [4][4500/5743] Elapsed 18m 15s (remain 5m 2s) Loss: 0.0000(0.0023) Grad: 15.7055  LR: 0.000005  \n","Epoch: [4][4600/5743] Elapsed 18m 39s (remain 4m 37s) Loss: 0.0000(0.0023) Grad: 48.4389  LR: 0.000005  \n","Epoch: [4][4700/5743] Elapsed 19m 3s (remain 4m 13s) Loss: 0.0000(0.0023) Grad: 3.6668  LR: 0.000005  \n","Epoch: [4][4800/5743] Elapsed 19m 28s (remain 3m 49s) Loss: 0.0083(0.0024) Grad: 9064.9180  LR: 0.000005  \n","Epoch: [4][4900/5743] Elapsed 19m 52s (remain 3m 24s) Loss: 0.0000(0.0023) Grad: 6.2271  LR: 0.000005  \n","Epoch: [4][5000/5743] Elapsed 20m 16s (remain 3m 0s) Loss: 0.0072(0.0023) Grad: 20551.2363  LR: 0.000005  \n","Epoch: [4][5100/5743] Elapsed 20m 40s (remain 2m 36s) Loss: 0.0001(0.0024) Grad: 4773.8447  LR: 0.000005  \n","Epoch: [4][5200/5743] Elapsed 21m 4s (remain 2m 11s) Loss: 0.0000(0.0024) Grad: 23.3395  LR: 0.000005  \n","Epoch: [4][5300/5743] Elapsed 21m 29s (remain 1m 47s) Loss: 0.0000(0.0024) Grad: 54.7274  LR: 0.000005  \n","Epoch: [4][5400/5743] Elapsed 21m 53s (remain 1m 23s) Loss: 0.0000(0.0023) Grad: 11.3974  LR: 0.000005  \n","Epoch: [4][5500/5743] Elapsed 22m 17s (remain 0m 58s) Loss: 0.0004(0.0024) Grad: 6629.8618  LR: 0.000005  \n","Epoch: [4][5600/5743] Elapsed 22m 41s (remain 0m 34s) Loss: 0.0028(0.0024) Grad: 4467.2251  LR: 0.000005  \n","Epoch: [4][5700/5743] Elapsed 23m 5s (remain 0m 10s) Loss: 0.0000(0.0024) Grad: 68.2659  LR: 0.000004  \n","Epoch: [4][5742/5743] Elapsed 23m 15s (remain 0m 0s) Loss: 0.0141(0.0024) Grad: 47794.1133  LR: 0.000004  \n","EVAL: [0/1407] Elapsed 0m 0s (remain 9m 32s) Loss: 0.0000(0.0000) \n","EVAL: [100/1407] Elapsed 0m 12s (remain 2m 40s) Loss: 0.0001(0.0047) \n","EVAL: [200/1407] Elapsed 0m 24s (remain 2m 26s) Loss: 0.0012(0.0052) \n","EVAL: [300/1407] Elapsed 0m 36s (remain 2m 14s) Loss: 0.0004(0.0044) \n","EVAL: [400/1407] Elapsed 0m 48s (remain 2m 1s) Loss: 0.0000(0.0043) \n","EVAL: [500/1407] Elapsed 1m 0s (remain 1m 49s) Loss: 0.0017(0.0041) \n","EVAL: [600/1407] Elapsed 1m 12s (remain 1m 37s) Loss: 0.0001(0.0041) \n","EVAL: [700/1407] Elapsed 1m 24s (remain 1m 25s) Loss: 0.0186(0.0040) \n","EVAL: [800/1407] Elapsed 1m 36s (remain 1m 13s) Loss: 0.0127(0.0045) \n","EVAL: [900/1407] Elapsed 1m 48s (remain 1m 1s) Loss: 0.0000(0.0050) \n","EVAL: [1000/1407] Elapsed 2m 1s (remain 0m 49s) Loss: 0.0000(0.0050) \n","EVAL: [1100/1407] Elapsed 2m 13s (remain 0m 36s) Loss: 0.0419(0.0052) \n","EVAL: [1200/1407] Elapsed 2m 25s (remain 0m 24s) Loss: 0.0000(0.0051) \n","EVAL: [1300/1407] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0000(0.0050) \n","EVAL: [1400/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0048) \n","EVAL: [1406/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0048) \n","Epoch 4 - avg_train_loss: 0.0024  avg_val_loss: 0.0048  time: 1570s\n","Epoch 4 - Score: 0.8746\n","Epoch 4 - Save Best Score: 0.8746 Model\n","Epoch: [5][0/5743] Elapsed 0m 0s (remain 55m 8s) Loss: 0.0002(0.0002) Grad: 2740.8196  LR: 0.000004  \n","Epoch: [5][100/5743] Elapsed 0m 28s (remain 26m 33s) Loss: 0.0002(0.0019) Grad: 1403.0731  LR: 0.000004  \n","Epoch: [5][200/5743] Elapsed 0m 54s (remain 24m 54s) Loss: 0.0005(0.0017) Grad: 2318.1008  LR: 0.000004  \n","Epoch: [5][300/5743] Elapsed 1m 18s (remain 23m 37s) Loss: 0.0000(0.0017) Grad: 8.2456  LR: 0.000004  \n","Epoch: [5][400/5743] Elapsed 1m 42s (remain 22m 47s) Loss: 0.0016(0.0018) Grad: 2885.7297  LR: 0.000004  \n","Epoch: [5][500/5743] Elapsed 2m 6s (remain 22m 8s) Loss: 0.0000(0.0019) Grad: 635.4901  LR: 0.000004  \n","Epoch: [5][600/5743] Elapsed 2m 31s (remain 21m 36s) Loss: 0.0095(0.0019) Grad: 17323.8535  LR: 0.000004  \n","Epoch: [5][700/5743] Elapsed 2m 55s (remain 21m 4s) Loss: 0.0000(0.0019) Grad: 190.9422  LR: 0.000004  \n","Epoch: [5][800/5743] Elapsed 3m 19s (remain 20m 33s) Loss: 0.0000(0.0020) Grad: 87.6501  LR: 0.000004  \n","Epoch: [5][900/5743] Elapsed 3m 44s (remain 20m 4s) Loss: 0.0000(0.0020) Grad: 7.0604  LR: 0.000004  \n","Epoch: [5][1000/5743] Elapsed 4m 8s (remain 19m 36s) Loss: 0.0000(0.0022) Grad: 30.4423  LR: 0.000004  \n","Epoch: [5][1100/5743] Elapsed 4m 32s (remain 19m 9s) Loss: 0.0000(0.0021) Grad: 25.3308  LR: 0.000004  \n","Epoch: [5][1200/5743] Elapsed 4m 56s (remain 18m 42s) Loss: 0.0000(0.0021) Grad: 23.2850  LR: 0.000004  \n","Epoch: [5][1300/5743] Elapsed 5m 21s (remain 18m 16s) Loss: 0.0000(0.0021) Grad: 13.7777  LR: 0.000003  \n","Epoch: [5][1400/5743] Elapsed 5m 45s (remain 17m 49s) Loss: 0.0000(0.0021) Grad: 11.2256  LR: 0.000003  \n","Epoch: [5][1500/5743] Elapsed 6m 9s (remain 17m 23s) Loss: 0.0029(0.0021) Grad: 16940.9473  LR: 0.000003  \n","Epoch: [5][1600/5743] Elapsed 6m 33s (remain 16m 58s) Loss: 0.0000(0.0021) Grad: 3.8697  LR: 0.000003  \n","Epoch: [5][1700/5743] Elapsed 6m 57s (remain 16m 32s) Loss: 0.0000(0.0020) Grad: 4.1141  LR: 0.000003  \n","Epoch: [5][1800/5743] Elapsed 7m 21s (remain 16m 6s) Loss: 0.0000(0.0020) Grad: 7.1413  LR: 0.000003  \n","Epoch: [5][1900/5743] Elapsed 7m 45s (remain 15m 41s) Loss: 0.0000(0.0020) Grad: 4.2031  LR: 0.000003  \n","Epoch: [5][2000/5743] Elapsed 8m 10s (remain 15m 16s) Loss: 0.0000(0.0020) Grad: 14.7856  LR: 0.000003  \n","Epoch: [5][2100/5743] Elapsed 8m 34s (remain 14m 51s) Loss: 0.0000(0.0020) Grad: 230.2438  LR: 0.000003  \n","Epoch: [5][2200/5743] Elapsed 8m 58s (remain 14m 26s) Loss: 0.0000(0.0020) Grad: 52.5481  LR: 0.000003  \n","Epoch: [5][2300/5743] Elapsed 9m 22s (remain 14m 1s) Loss: 0.0049(0.0020) Grad: 3772.6685  LR: 0.000003  \n","Epoch: [5][2400/5743] Elapsed 9m 47s (remain 13m 37s) Loss: 0.0001(0.0020) Grad: 1764.3982  LR: 0.000003  \n","Epoch: [5][2500/5743] Elapsed 10m 11s (remain 13m 12s) Loss: 0.0307(0.0020) Grad: 27540.3711  LR: 0.000003  \n","Epoch: [5][2600/5743] Elapsed 10m 35s (remain 12m 47s) Loss: 0.0000(0.0020) Grad: 26.3702  LR: 0.000002  \n","Epoch: [5][2700/5743] Elapsed 11m 0s (remain 12m 23s) Loss: 0.0000(0.0020) Grad: 132.3085  LR: 0.000002  \n","Epoch: [5][2800/5743] Elapsed 11m 24s (remain 11m 59s) Loss: 0.0000(0.0019) Grad: 14.6466  LR: 0.000002  \n","Epoch: [5][2900/5743] Elapsed 11m 49s (remain 11m 35s) Loss: 0.0000(0.0019) Grad: 464.7120  LR: 0.000002  \n","Epoch: [5][3000/5743] Elapsed 12m 14s (remain 11m 10s) Loss: 0.0000(0.0020) Grad: 22.5999  LR: 0.000002  \n","Epoch: [5][3100/5743] Elapsed 12m 38s (remain 10m 46s) Loss: 0.0000(0.0019) Grad: 25.7849  LR: 0.000002  \n","Epoch: [5][3200/5743] Elapsed 13m 3s (remain 10m 22s) Loss: 0.0325(0.0020) Grad: 9482.1816  LR: 0.000002  \n","Epoch: [5][3300/5743] Elapsed 13m 27s (remain 9m 57s) Loss: 0.0009(0.0020) Grad: 12030.1719  LR: 0.000002  \n","Epoch: [5][3400/5743] Elapsed 13m 52s (remain 9m 33s) Loss: 0.0080(0.0020) Grad: 90891.2266  LR: 0.000002  \n","Epoch: [5][3500/5743] Elapsed 14m 17s (remain 9m 8s) Loss: 0.0000(0.0020) Grad: 7.1896  LR: 0.000002  \n","Epoch: [5][3600/5743] Elapsed 14m 41s (remain 8m 44s) Loss: 0.0002(0.0020) Grad: 3380.7058  LR: 0.000002  \n","Epoch: [5][3700/5743] Elapsed 15m 6s (remain 8m 20s) Loss: 0.0000(0.0020) Grad: 47.4518  LR: 0.000002  \n","Epoch: [5][3800/5743] Elapsed 15m 31s (remain 7m 55s) Loss: 0.0002(0.0019) Grad: 3807.4863  LR: 0.000002  \n","Epoch: [5][3900/5743] Elapsed 15m 56s (remain 7m 31s) Loss: 0.0036(0.0020) Grad: 16497.8496  LR: 0.000001  \n","Epoch: [5][4000/5743] Elapsed 16m 21s (remain 7m 7s) Loss: 0.0000(0.0021) Grad: 60.3427  LR: 0.000001  \n","Epoch: [5][4100/5743] Elapsed 16m 45s (remain 6m 42s) Loss: 0.0000(0.0020) Grad: 90.7728  LR: 0.000001  \n","Epoch: [5][4200/5743] Elapsed 17m 10s (remain 6m 18s) Loss: 0.0000(0.0020) Grad: 40.3714  LR: 0.000001  \n","Epoch: [5][4300/5743] Elapsed 17m 34s (remain 5m 53s) Loss: 0.0000(0.0020) Grad: 6.3318  LR: 0.000001  \n","Epoch: [5][4400/5743] Elapsed 17m 59s (remain 5m 29s) Loss: 0.0000(0.0020) Grad: 44.2341  LR: 0.000001  \n","Epoch: [5][4500/5743] Elapsed 18m 23s (remain 5m 4s) Loss: 0.0000(0.0020) Grad: 7.6126  LR: 0.000001  \n","Epoch: [5][4600/5743] Elapsed 18m 48s (remain 4m 40s) Loss: 0.0000(0.0020) Grad: 85.9200  LR: 0.000001  \n","Epoch: [5][4700/5743] Elapsed 19m 12s (remain 4m 15s) Loss: 0.0000(0.0020) Grad: 3.2487  LR: 0.000001  \n","Epoch: [5][4800/5743] Elapsed 19m 37s (remain 3m 50s) Loss: 0.0000(0.0020) Grad: 254.4857  LR: 0.000001  \n","Epoch: [5][4900/5743] Elapsed 20m 1s (remain 3m 26s) Loss: 0.0000(0.0020) Grad: 84.7247  LR: 0.000001  \n","Epoch: [5][5000/5743] Elapsed 20m 25s (remain 3m 1s) Loss: 0.0000(0.0020) Grad: 7.8390  LR: 0.000001  \n","Epoch: [5][5100/5743] Elapsed 20m 50s (remain 2m 37s) Loss: 0.0002(0.0020) Grad: 2221.8691  LR: 0.000000  \n","Epoch: [5][5200/5743] Elapsed 21m 14s (remain 2m 12s) Loss: 0.0624(0.0020) Grad: 115592.0859  LR: 0.000000  \n","Epoch: [5][5300/5743] Elapsed 21m 39s (remain 1m 48s) Loss: 0.0000(0.0020) Grad: 28.6847  LR: 0.000000  \n","Epoch: [5][5400/5743] Elapsed 22m 4s (remain 1m 23s) Loss: 0.0000(0.0020) Grad: 6.3374  LR: 0.000000  \n","Epoch: [5][5500/5743] Elapsed 22m 28s (remain 0m 59s) Loss: 0.0000(0.0020) Grad: 3.9180  LR: 0.000000  \n","Epoch: [5][5600/5743] Elapsed 22m 53s (remain 0m 34s) Loss: 0.0000(0.0020) Grad: 82.9692  LR: 0.000000  \n","Epoch: [5][5700/5743] Elapsed 23m 17s (remain 0m 10s) Loss: 0.0000(0.0020) Grad: 19.5728  LR: 0.000000  \n","Epoch: [5][5742/5743] Elapsed 23m 27s (remain 0m 0s) Loss: 0.0021(0.0020) Grad: 3389.8811  LR: 0.000000  \n","EVAL: [0/1407] Elapsed 0m 0s (remain 10m 8s) Loss: 0.0000(0.0000) \n","EVAL: [100/1407] Elapsed 0m 12s (remain 2m 41s) Loss: 0.0000(0.0046) \n","EVAL: [200/1407] Elapsed 0m 24s (remain 2m 27s) Loss: 0.0015(0.0054) \n","EVAL: [300/1407] Elapsed 0m 36s (remain 2m 14s) Loss: 0.0003(0.0046) \n","EVAL: [400/1407] Elapsed 0m 48s (remain 2m 2s) Loss: 0.0000(0.0047) \n","EVAL: [500/1407] Elapsed 1m 0s (remain 1m 49s) Loss: 0.0013(0.0044) \n","EVAL: [600/1407] Elapsed 1m 12s (remain 1m 37s) Loss: 0.0003(0.0043) \n","EVAL: [700/1407] Elapsed 1m 24s (remain 1m 25s) Loss: 0.0214(0.0042) \n","EVAL: [800/1407] Elapsed 1m 37s (remain 1m 13s) Loss: 0.0210(0.0048) \n","EVAL: [900/1407] Elapsed 1m 49s (remain 1m 1s) Loss: 0.0000(0.0053) \n","EVAL: [1000/1407] Elapsed 2m 1s (remain 0m 49s) Loss: 0.0000(0.0052) \n","EVAL: [1100/1407] Elapsed 2m 13s (remain 0m 37s) Loss: 0.0483(0.0055) \n","EVAL: [1200/1407] Elapsed 2m 25s (remain 0m 24s) Loss: 0.0000(0.0054) \n","EVAL: [1300/1407] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0000(0.0053) \n","EVAL: [1400/1407] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0000(0.0051) \n","EVAL: [1406/1407] Elapsed 2m 50s (remain 0m 0s) Loss: 0.0000(0.0051) \n","Epoch 5 - avg_train_loss: 0.0020  avg_val_loss: 0.0051  time: 1582s\n","Epoch 5 - Score: 0.8711\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5754] Elapsed 0m 0s (remain 70m 49s) Loss: 0.4964(0.4964) Grad: 165534.4688  LR: 0.000000  \n","Epoch: [1][100/5754] Elapsed 0m 25s (remain 23m 39s) Loss: 0.3487(0.2690) Grad: 118612.2344  LR: 0.000001  \n","Epoch: [1][200/5754] Elapsed 0m 49s (remain 22m 56s) Loss: 0.3092(0.2700) Grad: 105037.9297  LR: 0.000001  \n","Epoch: [1][300/5754] Elapsed 1m 14s (remain 22m 30s) Loss: 0.2684(0.2606) Grad: 47784.1289  LR: 0.000002  \n","Epoch: [1][400/5754] Elapsed 1m 39s (remain 22m 2s) Loss: 0.2520(0.2478) Grad: 51359.8438  LR: 0.000003  \n","Epoch: [1][500/5754] Elapsed 2m 3s (remain 21m 35s) Loss: 0.1792(0.2319) Grad: 42451.4375  LR: 0.000003  \n","Epoch: [1][600/5754] Elapsed 2m 28s (remain 21m 9s) Loss: 0.0451(0.2115) Grad: 7145.1289  LR: 0.000004  \n","Epoch: [1][700/5754] Elapsed 2m 52s (remain 20m 43s) Loss: 0.0157(0.1876) Grad: 3726.7222  LR: 0.000005  \n","Epoch: [1][800/5754] Elapsed 3m 16s (remain 20m 17s) Loss: 0.0034(0.1667) Grad: 1849.5742  LR: 0.000006  \n","Epoch: [1][900/5754] Elapsed 3m 41s (remain 19m 51s) Loss: 0.0117(0.1505) Grad: 2843.8501  LR: 0.000006  \n","Epoch: [1][1000/5754] Elapsed 4m 5s (remain 19m 26s) Loss: 0.0100(0.1373) Grad: 1346.0226  LR: 0.000007  \n","Epoch: [1][1100/5754] Elapsed 4m 30s (remain 19m 1s) Loss: 0.0249(0.1265) Grad: 1702.5947  LR: 0.000008  \n","Epoch: [1][1200/5754] Elapsed 4m 54s (remain 18m 36s) Loss: 0.0184(0.1177) Grad: 666.4717  LR: 0.000008  \n","Epoch: [1][1300/5754] Elapsed 5m 19s (remain 18m 12s) Loss: 0.0193(0.1102) Grad: 1357.0824  LR: 0.000009  \n","Epoch: [1][1400/5754] Elapsed 5m 43s (remain 17m 47s) Loss: 0.0289(0.1037) Grad: 3237.6309  LR: 0.000010  \n","Epoch: [1][1500/5754] Elapsed 6m 8s (remain 17m 22s) Loss: 0.0551(0.0978) Grad: 5261.6357  LR: 0.000010  \n","Epoch: [1][1600/5754] Elapsed 6m 32s (remain 16m 57s) Loss: 0.0712(0.0923) Grad: 8236.8818  LR: 0.000011  \n","Epoch: [1][1700/5754] Elapsed 6m 57s (remain 16m 33s) Loss: 0.0052(0.0877) Grad: 1797.9567  LR: 0.000012  \n","Epoch: [1][1800/5754] Elapsed 7m 21s (remain 16m 8s) Loss: 0.0028(0.0832) Grad: 1901.1240  LR: 0.000013  \n","Epoch: [1][1900/5754] Elapsed 7m 45s (remain 15m 44s) Loss: 0.0014(0.0793) Grad: 495.0470  LR: 0.000013  \n","Epoch: [1][2000/5754] Elapsed 8m 10s (remain 15m 19s) Loss: 0.0114(0.0758) Grad: 5708.8384  LR: 0.000014  \n","Epoch: [1][2100/5754] Elapsed 8m 34s (remain 14m 54s) Loss: 0.0445(0.0725) Grad: 14404.9639  LR: 0.000015  \n","Epoch: [1][2200/5754] Elapsed 8m 58s (remain 14m 29s) Loss: 0.0030(0.0696) Grad: 2329.3943  LR: 0.000015  \n","Epoch: [1][2300/5754] Elapsed 9m 22s (remain 14m 4s) Loss: 0.0014(0.0668) Grad: 1317.1858  LR: 0.000016  \n","Epoch: [1][2400/5754] Elapsed 9m 47s (remain 13m 39s) Loss: 0.0156(0.0644) Grad: 5039.2974  LR: 0.000017  \n","Epoch: [1][2500/5754] Elapsed 10m 11s (remain 13m 15s) Loss: 0.0014(0.0621) Grad: 936.2305  LR: 0.000017  \n","Epoch: [1][2600/5754] Elapsed 10m 35s (remain 12m 50s) Loss: 0.0097(0.0600) Grad: 3929.7898  LR: 0.000018  \n","Epoch: [1][2700/5754] Elapsed 10m 59s (remain 12m 25s) Loss: 0.0140(0.0580) Grad: 11563.1445  LR: 0.000019  \n","Epoch: [1][2800/5754] Elapsed 11m 24s (remain 12m 1s) Loss: 0.0030(0.0561) Grad: 29481.0723  LR: 0.000019  \n","Epoch: [1][2900/5754] Elapsed 11m 48s (remain 11m 36s) Loss: 0.0019(0.0544) Grad: 1117.1487  LR: 0.000020  \n","Epoch: [1][3000/5754] Elapsed 12m 12s (remain 11m 12s) Loss: 0.0012(0.0529) Grad: 1169.4167  LR: 0.000020  \n","Epoch: [1][3100/5754] Elapsed 12m 37s (remain 10m 47s) Loss: 0.0155(0.0513) Grad: 8034.7876  LR: 0.000020  \n","Epoch: [1][3200/5754] Elapsed 13m 1s (remain 10m 23s) Loss: 0.0009(0.0499) Grad: 707.6580  LR: 0.000020  \n","Epoch: [1][3300/5754] Elapsed 13m 25s (remain 9m 58s) Loss: 0.0031(0.0487) Grad: 2509.7852  LR: 0.000020  \n","Epoch: [1][3400/5754] Elapsed 13m 50s (remain 9m 34s) Loss: 0.0034(0.0474) Grad: 2566.3782  LR: 0.000020  \n","Epoch: [1][3500/5754] Elapsed 14m 14s (remain 9m 9s) Loss: 0.0028(0.0462) Grad: 3586.1616  LR: 0.000020  \n","Epoch: [1][3600/5754] Elapsed 14m 38s (remain 8m 45s) Loss: 0.0032(0.0451) Grad: 829.7496  LR: 0.000019  \n","Epoch: [1][3700/5754] Elapsed 15m 2s (remain 8m 20s) Loss: 0.0026(0.0441) Grad: 4310.1763  LR: 0.000019  \n","Epoch: [1][3800/5754] Elapsed 15m 27s (remain 7m 56s) Loss: 0.0016(0.0430) Grad: 1062.0513  LR: 0.000019  \n","Epoch: [1][3900/5754] Elapsed 15m 51s (remain 7m 31s) Loss: 0.0143(0.0420) Grad: 8800.3105  LR: 0.000019  \n","Epoch: [1][4000/5754] Elapsed 16m 15s (remain 7m 7s) Loss: 0.0005(0.0411) Grad: 2928.8159  LR: 0.000019  \n","Epoch: [1][4100/5754] Elapsed 16m 40s (remain 6m 43s) Loss: 0.0009(0.0402) Grad: 658.8488  LR: 0.000019  \n","Epoch: [1][4200/5754] Elapsed 17m 4s (remain 6m 18s) Loss: 0.0002(0.0394) Grad: 126.1455  LR: 0.000019  \n","Epoch: [1][4300/5754] Elapsed 17m 28s (remain 5m 54s) Loss: 0.0013(0.0387) Grad: 1803.8541  LR: 0.000019  \n","Epoch: [1][4400/5754] Elapsed 17m 53s (remain 5m 29s) Loss: 0.0001(0.0379) Grad: 84.7040  LR: 0.000019  \n","Epoch: [1][4500/5754] Elapsed 18m 17s (remain 5m 5s) Loss: 0.0000(0.0371) Grad: 34.4238  LR: 0.000019  \n","Epoch: [1][4600/5754] Elapsed 18m 41s (remain 4m 41s) Loss: 0.0026(0.0364) Grad: 1555.7394  LR: 0.000019  \n","Epoch: [1][4700/5754] Elapsed 19m 5s (remain 4m 16s) Loss: 0.0036(0.0358) Grad: 8858.8184  LR: 0.000019  \n","Epoch: [1][4800/5754] Elapsed 19m 30s (remain 3m 52s) Loss: 0.0020(0.0351) Grad: 1613.7404  LR: 0.000019  \n","Epoch: [1][4900/5754] Elapsed 19m 54s (remain 3m 27s) Loss: 0.0159(0.0345) Grad: 4621.8101  LR: 0.000018  \n","Epoch: [1][5000/5754] Elapsed 20m 18s (remain 3m 3s) Loss: 0.0020(0.0339) Grad: 726.5339  LR: 0.000018  \n","Epoch: [1][5100/5754] Elapsed 20m 42s (remain 2m 39s) Loss: 0.0125(0.0334) Grad: 6907.2148  LR: 0.000018  \n","Epoch: [1][5200/5754] Elapsed 21m 6s (remain 2m 14s) Loss: 0.0002(0.0328) Grad: 104.9039  LR: 0.000018  \n","Epoch: [1][5300/5754] Elapsed 21m 31s (remain 1m 50s) Loss: 0.0004(0.0323) Grad: 577.2276  LR: 0.000018  \n","Epoch: [1][5400/5754] Elapsed 21m 55s (remain 1m 25s) Loss: 0.0006(0.0317) Grad: 481.9662  LR: 0.000018  \n","Epoch: [1][5500/5754] Elapsed 22m 19s (remain 1m 1s) Loss: 0.0039(0.0312) Grad: 2724.9214  LR: 0.000018  \n","Epoch: [1][5600/5754] Elapsed 22m 43s (remain 0m 37s) Loss: 0.0015(0.0307) Grad: 903.1094  LR: 0.000018  \n","Epoch: [1][5700/5754] Elapsed 23m 8s (remain 0m 12s) Loss: 0.0000(0.0303) Grad: 13.4907  LR: 0.000018  \n","Epoch: [1][5753/5754] Elapsed 23m 20s (remain 0m 0s) Loss: 0.0001(0.0300) Grad: 767.2360  LR: 0.000018  \n","EVAL: [0/1396] Elapsed 0m 0s (remain 10m 51s) Loss: 0.0003(0.0003) \n","EVAL: [100/1396] Elapsed 0m 12s (remain 2m 41s) Loss: 0.0004(0.0032) \n","EVAL: [200/1396] Elapsed 0m 24s (remain 2m 25s) Loss: 0.0015(0.0030) \n","EVAL: [300/1396] Elapsed 0m 36s (remain 2m 12s) Loss: 0.0002(0.0033) \n","EVAL: [400/1396] Elapsed 0m 48s (remain 2m 0s) Loss: 0.0002(0.0043) \n","EVAL: [500/1396] Elapsed 1m 0s (remain 1m 48s) Loss: 0.0017(0.0043) \n","EVAL: [600/1396] Elapsed 1m 12s (remain 1m 36s) Loss: 0.0001(0.0041) \n","EVAL: [700/1396] Elapsed 1m 24s (remain 1m 23s) Loss: 0.0004(0.0040) \n","EVAL: [800/1396] Elapsed 1m 36s (remain 1m 11s) Loss: 0.0007(0.0047) \n","EVAL: [900/1396] Elapsed 1m 48s (remain 0m 59s) Loss: 0.0001(0.0049) \n","EVAL: [1000/1396] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0096(0.0047) \n","EVAL: [1100/1396] Elapsed 2m 13s (remain 0m 35s) Loss: 0.0076(0.0046) \n","EVAL: [1200/1396] Elapsed 2m 25s (remain 0m 23s) Loss: 0.0001(0.0045) \n","EVAL: [1300/1396] Elapsed 2m 37s (remain 0m 11s) Loss: 0.0003(0.0043) \n","EVAL: [1395/1396] Elapsed 2m 48s (remain 0m 0s) Loss: 0.0000(0.0043) \n","Epoch 1 - avg_train_loss: 0.0300  avg_val_loss: 0.0043  time: 1574s\n","Epoch 1 - Score: 0.8531\n","Epoch 1 - Save Best Score: 0.8531 Model\n","Epoch: [2][0/5754] Elapsed 0m 0s (remain 63m 50s) Loss: 0.0000(0.0000) Grad: 772.6686  LR: 0.000018  \n","Epoch: [2][100/5754] Elapsed 0m 27s (remain 26m 4s) Loss: 0.0017(0.0042) Grad: 12973.1836  LR: 0.000018  \n","Epoch: [2][200/5754] Elapsed 0m 54s (remain 25m 0s) Loss: 0.0041(0.0052) Grad: 12497.0127  LR: 0.000018  \n","Epoch: [2][300/5754] Elapsed 1m 18s (remain 23m 44s) Loss: 0.0027(0.0049) Grad: 8306.8281  LR: 0.000018  \n","Epoch: [2][400/5754] Elapsed 1m 42s (remain 22m 53s) Loss: 0.0000(0.0043) Grad: 47.7841  LR: 0.000017  \n","Epoch: [2][500/5754] Elapsed 2m 7s (remain 22m 14s) Loss: 0.0021(0.0041) Grad: 5737.9487  LR: 0.000017  \n","Epoch: [2][600/5754] Elapsed 2m 31s (remain 21m 39s) Loss: 0.0011(0.0040) Grad: 7227.4951  LR: 0.000017  \n","Epoch: [2][700/5754] Elapsed 2m 55s (remain 21m 7s) Loss: 0.0000(0.0041) Grad: 40.6957  LR: 0.000017  \n","Epoch: [2][800/5754] Elapsed 3m 20s (remain 20m 39s) Loss: 0.0009(0.0041) Grad: 2867.5115  LR: 0.000017  \n","Epoch: [2][900/5754] Elapsed 3m 44s (remain 20m 10s) Loss: 0.0006(0.0040) Grad: 2098.1062  LR: 0.000017  \n","Epoch: [2][1000/5754] Elapsed 4m 9s (remain 19m 42s) Loss: 0.0001(0.0040) Grad: 170.1181  LR: 0.000017  \n","Epoch: [2][1100/5754] Elapsed 4m 33s (remain 19m 14s) Loss: 0.0026(0.0042) Grad: 7848.5806  LR: 0.000017  \n","Epoch: [2][1200/5754] Elapsed 4m 57s (remain 18m 47s) Loss: 0.0044(0.0041) Grad: 3131.9941  LR: 0.000017  \n","Epoch: [2][1300/5754] Elapsed 5m 21s (remain 18m 20s) Loss: 0.0001(0.0041) Grad: 2660.8467  LR: 0.000017  \n","Epoch: [2][1400/5754] Elapsed 5m 45s (remain 17m 54s) Loss: 0.0005(0.0041) Grad: 1888.2257  LR: 0.000017  \n","Epoch: [2][1500/5754] Elapsed 6m 10s (remain 17m 28s) Loss: 0.0000(0.0042) Grad: 309.0374  LR: 0.000017  \n","Epoch: [2][1600/5754] Elapsed 6m 34s (remain 17m 3s) Loss: 0.0028(0.0042) Grad: 4463.8228  LR: 0.000017  \n","Epoch: [2][1700/5754] Elapsed 6m 58s (remain 16m 37s) Loss: 0.0021(0.0042) Grad: 2437.2063  LR: 0.000016  \n","Epoch: [2][1800/5754] Elapsed 7m 22s (remain 16m 12s) Loss: 0.0007(0.0041) Grad: 1431.4269  LR: 0.000016  \n","Epoch: [2][1900/5754] Elapsed 7m 47s (remain 15m 46s) Loss: 0.0001(0.0042) Grad: 263.1537  LR: 0.000016  \n","Epoch: [2][2000/5754] Elapsed 8m 11s (remain 15m 21s) Loss: 0.0030(0.0041) Grad: 9153.6807  LR: 0.000016  \n","Epoch: [2][2100/5754] Elapsed 8m 35s (remain 14m 56s) Loss: 0.0190(0.0041) Grad: 38195.0352  LR: 0.000016  \n","Epoch: [2][2200/5754] Elapsed 9m 0s (remain 14m 31s) Loss: 0.0000(0.0040) Grad: 26.0178  LR: 0.000016  \n","Epoch: [2][2300/5754] Elapsed 9m 24s (remain 14m 6s) Loss: 0.0000(0.0040) Grad: 157.7569  LR: 0.000016  \n","Epoch: [2][2400/5754] Elapsed 9m 48s (remain 13m 42s) Loss: 0.0034(0.0040) Grad: 21742.8984  LR: 0.000016  \n","Epoch: [2][2500/5754] Elapsed 10m 13s (remain 13m 17s) Loss: 0.0026(0.0040) Grad: 5034.3218  LR: 0.000016  \n","Epoch: [2][2600/5754] Elapsed 10m 37s (remain 12m 52s) Loss: 0.0003(0.0040) Grad: 3499.4990  LR: 0.000016  \n","Epoch: [2][2700/5754] Elapsed 11m 1s (remain 12m 27s) Loss: 0.0000(0.0040) Grad: 128.2349  LR: 0.000016  \n","Epoch: [2][2800/5754] Elapsed 11m 25s (remain 12m 2s) Loss: 0.0026(0.0040) Grad: 2244.4470  LR: 0.000016  \n","Epoch: [2][2900/5754] Elapsed 11m 49s (remain 11m 38s) Loss: 0.0022(0.0040) Grad: 3431.2830  LR: 0.000016  \n","Epoch: [2][3000/5754] Elapsed 12m 14s (remain 11m 13s) Loss: 0.0042(0.0039) Grad: 7618.4248  LR: 0.000015  \n","Epoch: [2][3100/5754] Elapsed 12m 38s (remain 10m 48s) Loss: 0.0001(0.0039) Grad: 713.3105  LR: 0.000015  \n","Epoch: [2][3200/5754] Elapsed 13m 2s (remain 10m 24s) Loss: 0.0000(0.0039) Grad: 96.6663  LR: 0.000015  \n","Epoch: [2][3300/5754] Elapsed 13m 26s (remain 9m 59s) Loss: 0.0001(0.0039) Grad: 162.0851  LR: 0.000015  \n","Epoch: [2][3400/5754] Elapsed 13m 50s (remain 9m 34s) Loss: 0.0000(0.0039) Grad: 23.1682  LR: 0.000015  \n","Epoch: [2][3500/5754] Elapsed 14m 15s (remain 9m 10s) Loss: 0.0001(0.0039) Grad: 408.1383  LR: 0.000015  \n","Epoch: [2][3600/5754] Elapsed 14m 39s (remain 8m 45s) Loss: 0.0041(0.0039) Grad: 12444.6514  LR: 0.000015  \n","Epoch: [2][3700/5754] Elapsed 15m 3s (remain 8m 21s) Loss: 0.0008(0.0039) Grad: 8950.4922  LR: 0.000015  \n","Epoch: [2][3800/5754] Elapsed 15m 27s (remain 7m 56s) Loss: 0.0068(0.0039) Grad: 36922.3711  LR: 0.000015  \n","Epoch: [2][3900/5754] Elapsed 15m 52s (remain 7m 32s) Loss: 0.0014(0.0039) Grad: 9143.2051  LR: 0.000015  \n","Epoch: [2][4000/5754] Elapsed 16m 16s (remain 7m 7s) Loss: 0.0000(0.0039) Grad: 30.4170  LR: 0.000015  \n","Epoch: [2][4100/5754] Elapsed 16m 40s (remain 6m 43s) Loss: 0.0387(0.0039) Grad: 71126.3516  LR: 0.000015  \n","Epoch: [2][4200/5754] Elapsed 17m 4s (remain 6m 18s) Loss: 0.0017(0.0039) Grad: 11792.1494  LR: 0.000015  \n","Epoch: [2][4300/5754] Elapsed 17m 29s (remain 5m 54s) Loss: 0.0000(0.0039) Grad: 15.9222  LR: 0.000014  \n","Epoch: [2][4400/5754] Elapsed 17m 53s (remain 5m 29s) Loss: 0.0105(0.0039) Grad: 7274.1279  LR: 0.000014  \n","Epoch: [2][4500/5754] Elapsed 18m 17s (remain 5m 5s) Loss: 0.0001(0.0039) Grad: 265.6796  LR: 0.000014  \n","Epoch: [2][4600/5754] Elapsed 18m 41s (remain 4m 41s) Loss: 0.0001(0.0039) Grad: 89.7149  LR: 0.000014  \n","Epoch: [2][4700/5754] Elapsed 19m 5s (remain 4m 16s) Loss: 0.0001(0.0039) Grad: 258.2596  LR: 0.000014  \n","Epoch: [2][4800/5754] Elapsed 19m 30s (remain 3m 52s) Loss: 0.0001(0.0039) Grad: 115.1160  LR: 0.000014  \n","Epoch: [2][4900/5754] Elapsed 19m 54s (remain 3m 27s) Loss: 0.0011(0.0039) Grad: 2319.2324  LR: 0.000014  \n","Epoch: [2][5000/5754] Elapsed 20m 18s (remain 3m 3s) Loss: 0.0000(0.0039) Grad: 24.0497  LR: 0.000014  \n","Epoch: [2][5100/5754] Elapsed 20m 42s (remain 2m 39s) Loss: 0.0047(0.0039) Grad: 6456.8950  LR: 0.000014  \n","Epoch: [2][5200/5754] Elapsed 21m 7s (remain 2m 14s) Loss: 0.0000(0.0038) Grad: 74.7299  LR: 0.000014  \n","Epoch: [2][5300/5754] Elapsed 21m 31s (remain 1m 50s) Loss: 0.0000(0.0038) Grad: 74.7238  LR: 0.000014  \n","Epoch: [2][5400/5754] Elapsed 21m 55s (remain 1m 25s) Loss: 0.0045(0.0038) Grad: 12185.7705  LR: 0.000014  \n","Epoch: [2][5500/5754] Elapsed 22m 19s (remain 1m 1s) Loss: 0.0000(0.0038) Grad: 17.0012  LR: 0.000014  \n","Epoch: [2][5600/5754] Elapsed 22m 43s (remain 0m 37s) Loss: 0.0033(0.0038) Grad: 23998.6953  LR: 0.000013  \n","Epoch: [2][5700/5754] Elapsed 23m 8s (remain 0m 12s) Loss: 0.0000(0.0038) Grad: 15.3616  LR: 0.000013  \n","Epoch: [2][5753/5754] Elapsed 23m 20s (remain 0m 0s) Loss: 0.0418(0.0039) Grad: 134241.7969  LR: 0.000013  \n","EVAL: [0/1396] Elapsed 0m 0s (remain 9m 36s) Loss: 0.0002(0.0002) \n","EVAL: [100/1396] Elapsed 0m 12s (remain 2m 39s) Loss: 0.0002(0.0027) \n","EVAL: [200/1396] Elapsed 0m 24s (remain 2m 25s) Loss: 0.0012(0.0026) \n","EVAL: [300/1396] Elapsed 0m 36s (remain 2m 12s) Loss: 0.0001(0.0029) \n","EVAL: [400/1396] Elapsed 0m 48s (remain 2m 0s) Loss: 0.0001(0.0037) \n","EVAL: [500/1396] Elapsed 1m 0s (remain 1m 48s) Loss: 0.0003(0.0036) \n","EVAL: [600/1396] Elapsed 1m 12s (remain 1m 36s) Loss: 0.0000(0.0035) \n","EVAL: [700/1396] Elapsed 1m 24s (remain 1m 23s) Loss: 0.0051(0.0034) \n","EVAL: [800/1396] Elapsed 1m 36s (remain 1m 11s) Loss: 0.0008(0.0039) \n","EVAL: [900/1396] Elapsed 1m 48s (remain 0m 59s) Loss: 0.0000(0.0041) \n","EVAL: [1000/1396] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0029(0.0040) \n","EVAL: [1100/1396] Elapsed 2m 13s (remain 0m 35s) Loss: 0.0031(0.0039) \n","EVAL: [1200/1396] Elapsed 2m 25s (remain 0m 23s) Loss: 0.0000(0.0038) \n","EVAL: [1300/1396] Elapsed 2m 37s (remain 0m 11s) Loss: 0.0001(0.0038) \n","EVAL: [1395/1396] Elapsed 2m 48s (remain 0m 0s) Loss: 0.0000(0.0037) \n","Epoch 2 - avg_train_loss: 0.0039  avg_val_loss: 0.0037  time: 1573s\n","Epoch 2 - Score: 0.8763\n","Epoch 2 - Save Best Score: 0.8763 Model\n","Epoch: [3][0/5754] Elapsed 0m 0s (remain 62m 25s) Loss: 0.0000(0.0000) Grad: 1001.3102  LR: 0.000013  \n","Epoch: [3][100/5754] Elapsed 0m 29s (remain 27m 11s) Loss: 0.0000(0.0029) Grad: 175.0985  LR: 0.000013  \n","Epoch: [3][200/5754] Elapsed 0m 54s (remain 25m 15s) Loss: 0.0000(0.0031) Grad: 148.5732  LR: 0.000013  \n","Epoch: [3][300/5754] Elapsed 1m 19s (remain 23m 53s) Loss: 0.0000(0.0031) Grad: 11.6597  LR: 0.000013  \n","Epoch: [3][400/5754] Elapsed 1m 43s (remain 23m 1s) Loss: 0.0000(0.0033) Grad: 6.9771  LR: 0.000013  \n","Epoch: [3][500/5754] Elapsed 2m 7s (remain 22m 18s) Loss: 0.0021(0.0035) Grad: 16285.8564  LR: 0.000013  \n","Epoch: [3][600/5754] Elapsed 2m 32s (remain 21m 43s) Loss: 0.0000(0.0036) Grad: 9.9657  LR: 0.000013  \n","Epoch: [3][700/5754] Elapsed 2m 56s (remain 21m 9s) Loss: 0.0001(0.0037) Grad: 463.2340  LR: 0.000013  \n","Epoch: [3][800/5754] Elapsed 3m 20s (remain 20m 39s) Loss: 0.0011(0.0035) Grad: 8156.7666  LR: 0.000013  \n","Epoch: [3][900/5754] Elapsed 3m 44s (remain 20m 9s) Loss: 0.0001(0.0036) Grad: 185.0770  LR: 0.000013  \n","Epoch: [3][1000/5754] Elapsed 4m 8s (remain 19m 42s) Loss: 0.0019(0.0034) Grad: 5251.1602  LR: 0.000013  \n","Epoch: [3][1100/5754] Elapsed 4m 33s (remain 19m 14s) Loss: 0.0002(0.0034) Grad: 2585.9431  LR: 0.000012  \n","Epoch: [3][1200/5754] Elapsed 4m 57s (remain 18m 47s) Loss: 0.0000(0.0034) Grad: 53.7480  LR: 0.000012  \n","Epoch: [3][1300/5754] Elapsed 5m 21s (remain 18m 21s) Loss: 0.0000(0.0034) Grad: 17.1224  LR: 0.000012  \n","Epoch: [3][1400/5754] Elapsed 5m 45s (remain 17m 54s) Loss: 0.0035(0.0034) Grad: 5189.8608  LR: 0.000012  \n","Epoch: [3][1500/5754] Elapsed 6m 10s (remain 17m 28s) Loss: 0.0063(0.0034) Grad: 16123.9424  LR: 0.000012  \n","Epoch: [3][1600/5754] Elapsed 6m 34s (remain 17m 3s) Loss: 0.0000(0.0034) Grad: 49.8291  LR: 0.000012  \n","Epoch: [3][1700/5754] Elapsed 6m 58s (remain 16m 37s) Loss: 0.0000(0.0033) Grad: 455.8813  LR: 0.000012  \n","Epoch: [3][1800/5754] Elapsed 7m 22s (remain 16m 11s) Loss: 0.0003(0.0033) Grad: 3479.0085  LR: 0.000012  \n","Epoch: [3][1900/5754] Elapsed 7m 46s (remain 15m 46s) Loss: 0.0001(0.0034) Grad: 344.6980  LR: 0.000012  \n","Epoch: [3][2000/5754] Elapsed 8m 11s (remain 15m 21s) Loss: 0.0006(0.0033) Grad: 6955.1421  LR: 0.000012  \n","Epoch: [3][2100/5754] Elapsed 8m 35s (remain 14m 55s) Loss: 0.0032(0.0033) Grad: 7093.9336  LR: 0.000012  \n","Epoch: [3][2200/5754] Elapsed 8m 59s (remain 14m 30s) Loss: 0.0005(0.0034) Grad: 1256.6163  LR: 0.000012  \n","Epoch: [3][2300/5754] Elapsed 9m 23s (remain 14m 5s) Loss: 0.0002(0.0033) Grad: 1148.3289  LR: 0.000012  \n","Epoch: [3][2400/5754] Elapsed 9m 47s (remain 13m 40s) Loss: 0.0027(0.0032) Grad: 7644.3389  LR: 0.000011  \n","Epoch: [3][2500/5754] Elapsed 10m 11s (remain 13m 15s) Loss: 0.0000(0.0032) Grad: 16.0589  LR: 0.000011  \n","Epoch: [3][2600/5754] Elapsed 10m 36s (remain 12m 51s) Loss: 0.0000(0.0033) Grad: 17.2715  LR: 0.000011  \n","Epoch: [3][2700/5754] Elapsed 11m 0s (remain 12m 26s) Loss: 0.0001(0.0033) Grad: 654.6019  LR: 0.000011  \n","Epoch: [3][2800/5754] Elapsed 11m 24s (remain 12m 1s) Loss: 0.0001(0.0033) Grad: 273.5566  LR: 0.000011  \n","Epoch: [3][2900/5754] Elapsed 11m 48s (remain 11m 36s) Loss: 0.0054(0.0033) Grad: 13288.8613  LR: 0.000011  \n","Epoch: [3][3000/5754] Elapsed 12m 12s (remain 11m 12s) Loss: 0.0020(0.0033) Grad: 7531.9536  LR: 0.000011  \n","Epoch: [3][3100/5754] Elapsed 12m 36s (remain 10m 47s) Loss: 0.0000(0.0033) Grad: 21.0648  LR: 0.000011  \n","Epoch: [3][3200/5754] Elapsed 13m 1s (remain 10m 22s) Loss: 0.0000(0.0033) Grad: 57.0585  LR: 0.000011  \n","Epoch: [3][3300/5754] Elapsed 13m 25s (remain 9m 58s) Loss: 0.0000(0.0033) Grad: 74.9185  LR: 0.000011  \n","Epoch: [3][3400/5754] Elapsed 13m 49s (remain 9m 33s) Loss: 0.0019(0.0033) Grad: 8153.9209  LR: 0.000011  \n","Epoch: [3][3500/5754] Elapsed 14m 13s (remain 9m 9s) Loss: 0.0001(0.0033) Grad: 1473.3171  LR: 0.000011  \n","Epoch: [3][3600/5754] Elapsed 14m 37s (remain 8m 44s) Loss: 0.0006(0.0033) Grad: 1494.3855  LR: 0.000011  \n","Epoch: [3][3700/5754] Elapsed 15m 1s (remain 8m 20s) Loss: 0.0021(0.0033) Grad: 8974.0029  LR: 0.000010  \n","Epoch: [3][3800/5754] Elapsed 15m 26s (remain 7m 55s) Loss: 0.0005(0.0032) Grad: 2463.7825  LR: 0.000010  \n","Epoch: [3][3900/5754] Elapsed 15m 50s (remain 7m 31s) Loss: 0.0000(0.0032) Grad: 136.4211  LR: 0.000010  \n","Epoch: [3][4000/5754] Elapsed 16m 14s (remain 7m 7s) Loss: 0.0000(0.0032) Grad: 212.4940  LR: 0.000010  \n","Epoch: [3][4100/5754] Elapsed 16m 38s (remain 6m 42s) Loss: 0.0000(0.0032) Grad: 12.3540  LR: 0.000010  \n","Epoch: [3][4200/5754] Elapsed 17m 2s (remain 6m 18s) Loss: 0.0011(0.0032) Grad: 5821.3389  LR: 0.000010  \n","Epoch: [3][4300/5754] Elapsed 17m 27s (remain 5m 53s) Loss: 0.1237(0.0032) Grad: 68106.2812  LR: 0.000010  \n","Epoch: [3][4400/5754] Elapsed 17m 51s (remain 5m 29s) Loss: 0.0001(0.0032) Grad: 387.7618  LR: 0.000010  \n","Epoch: [3][4500/5754] Elapsed 18m 15s (remain 5m 5s) Loss: 0.0000(0.0032) Grad: 92.6768  LR: 0.000010  \n","Epoch: [3][4600/5754] Elapsed 18m 40s (remain 4m 40s) Loss: 0.0023(0.0032) Grad: 2645.5471  LR: 0.000010  \n","Epoch: [3][4700/5754] Elapsed 19m 4s (remain 4m 16s) Loss: 0.0000(0.0032) Grad: 19.4840  LR: 0.000010  \n","Epoch: [3][4800/5754] Elapsed 19m 28s (remain 3m 51s) Loss: 0.0001(0.0032) Grad: 694.7372  LR: 0.000010  \n","Epoch: [3][4900/5754] Elapsed 19m 52s (remain 3m 27s) Loss: 0.0015(0.0032) Grad: 2501.1948  LR: 0.000010  \n","Epoch: [3][5000/5754] Elapsed 20m 16s (remain 3m 3s) Loss: 0.0000(0.0033) Grad: 132.1205  LR: 0.000009  \n","Epoch: [3][5100/5754] Elapsed 20m 41s (remain 2m 38s) Loss: 0.0001(0.0033) Grad: 804.9271  LR: 0.000009  \n","Epoch: [3][5200/5754] Elapsed 21m 5s (remain 2m 14s) Loss: 0.0018(0.0032) Grad: 4033.5410  LR: 0.000009  \n","Epoch: [3][5300/5754] Elapsed 21m 29s (remain 1m 50s) Loss: 0.0023(0.0032) Grad: 5774.2310  LR: 0.000009  \n","Epoch: [3][5400/5754] Elapsed 21m 53s (remain 1m 25s) Loss: 0.0025(0.0032) Grad: 2399.0647  LR: 0.000009  \n","Epoch: [3][5500/5754] Elapsed 22m 17s (remain 1m 1s) Loss: 0.0000(0.0032) Grad: 136.1410  LR: 0.000009  \n","Epoch: [3][5600/5754] Elapsed 22m 41s (remain 0m 37s) Loss: 0.0003(0.0033) Grad: 1476.2559  LR: 0.000009  \n","Epoch: [3][5700/5754] Elapsed 23m 5s (remain 0m 12s) Loss: 0.0001(0.0032) Grad: 339.2369  LR: 0.000009  \n","Epoch: [3][5753/5754] Elapsed 23m 18s (remain 0m 0s) Loss: 0.0000(0.0032) Grad: 338.0183  LR: 0.000009  \n","EVAL: [0/1396] Elapsed 0m 0s (remain 9m 36s) Loss: 0.0000(0.0000) \n","EVAL: [100/1396] Elapsed 0m 12s (remain 2m 39s) Loss: 0.0001(0.0035) \n","EVAL: [200/1396] Elapsed 0m 24s (remain 2m 25s) Loss: 0.0010(0.0029) \n","EVAL: [300/1396] Elapsed 0m 36s (remain 2m 12s) Loss: 0.0000(0.0032) \n","EVAL: [400/1396] Elapsed 0m 48s (remain 2m 0s) Loss: 0.0001(0.0041) \n","EVAL: [500/1396] Elapsed 1m 0s (remain 1m 47s) Loss: 0.0020(0.0040) \n","EVAL: [600/1396] Elapsed 1m 12s (remain 1m 35s) Loss: 0.0000(0.0038) \n","EVAL: [700/1396] Elapsed 1m 24s (remain 1m 23s) Loss: 0.0001(0.0036) \n","EVAL: [800/1396] Elapsed 1m 36s (remain 1m 11s) Loss: 0.0003(0.0041) \n","EVAL: [900/1396] Elapsed 1m 48s (remain 0m 59s) Loss: 0.0000(0.0043) \n","EVAL: [1000/1396] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0047(0.0042) \n","EVAL: [1100/1396] Elapsed 2m 12s (remain 0m 35s) Loss: 0.0039(0.0042) \n","EVAL: [1200/1396] Elapsed 2m 24s (remain 0m 23s) Loss: 0.0000(0.0040) \n","EVAL: [1300/1396] Elapsed 2m 37s (remain 0m 11s) Loss: 0.0000(0.0040) \n","EVAL: [1395/1396] Elapsed 2m 48s (remain 0m 0s) Loss: 0.0000(0.0039) \n","Epoch 3 - avg_train_loss: 0.0032  avg_val_loss: 0.0039  time: 1571s\n","Epoch 3 - Score: 0.8813\n","Epoch 3 - Save Best Score: 0.8813 Model\n","Epoch: [4][0/5754] Elapsed 0m 0s (remain 60m 54s) Loss: 0.0001(0.0001) Grad: 498.7793  LR: 0.000009  \n","Epoch: [4][100/5754] Elapsed 0m 30s (remain 28m 18s) Loss: 0.0042(0.0017) Grad: 20726.0332  LR: 0.000009  \n","Epoch: [4][200/5754] Elapsed 0m 55s (remain 25m 38s) Loss: 0.0001(0.0021) Grad: 694.1335  LR: 0.000009  \n","Epoch: [4][300/5754] Elapsed 1m 20s (remain 24m 10s) Loss: 0.0058(0.0023) Grad: 36955.3594  LR: 0.000009  \n","Epoch: [4][400/5754] Elapsed 1m 44s (remain 23m 14s) Loss: 0.0000(0.0027) Grad: 192.6804  LR: 0.000009  \n","Epoch: [4][500/5754] Elapsed 2m 8s (remain 22m 31s) Loss: 0.0039(0.0030) Grad: 8256.2275  LR: 0.000009  \n","Epoch: [4][600/5754] Elapsed 2m 33s (remain 21m 54s) Loss: 0.0006(0.0030) Grad: 2530.7500  LR: 0.000008  \n","Epoch: [4][700/5754] Elapsed 2m 57s (remain 21m 21s) Loss: 0.0000(0.0029) Grad: 32.2926  LR: 0.000008  \n","Epoch: [4][800/5754] Elapsed 3m 22s (remain 20m 50s) Loss: 0.0024(0.0029) Grad: 34094.0156  LR: 0.000008  \n","Epoch: [4][900/5754] Elapsed 3m 46s (remain 20m 21s) Loss: 0.0104(0.0028) Grad: 8393.2793  LR: 0.000008  \n","Epoch: [4][1000/5754] Elapsed 4m 11s (remain 19m 52s) Loss: 0.0006(0.0027) Grad: 18259.7754  LR: 0.000008  \n","Epoch: [4][1100/5754] Elapsed 4m 35s (remain 19m 25s) Loss: 0.0000(0.0027) Grad: 96.6144  LR: 0.000008  \n","Epoch: [4][1200/5754] Elapsed 5m 0s (remain 18m 58s) Loss: 0.0000(0.0028) Grad: 3.7319  LR: 0.000008  \n","Epoch: [4][1300/5754] Elapsed 5m 24s (remain 18m 30s) Loss: 0.0001(0.0028) Grad: 392.9023  LR: 0.000008  \n","Epoch: [4][1400/5754] Elapsed 5m 48s (remain 18m 3s) Loss: 0.0000(0.0028) Grad: 19.1602  LR: 0.000008  \n","Epoch: [4][1500/5754] Elapsed 6m 12s (remain 17m 36s) Loss: 0.0000(0.0029) Grad: 12.0155  LR: 0.000008  \n","Epoch: [4][1600/5754] Elapsed 6m 37s (remain 17m 10s) Loss: 0.0077(0.0030) Grad: 18708.5547  LR: 0.000008  \n","Epoch: [4][1700/5754] Elapsed 7m 1s (remain 16m 44s) Loss: 0.0000(0.0029) Grad: 29.8183  LR: 0.000008  \n","Epoch: [4][1800/5754] Elapsed 7m 25s (remain 16m 18s) Loss: 0.0000(0.0029) Grad: 87.8183  LR: 0.000007  \n","Epoch: [4][1900/5754] Elapsed 7m 49s (remain 15m 52s) Loss: 0.0000(0.0029) Grad: 17.5711  LR: 0.000007  \n","Epoch: [4][2000/5754] Elapsed 8m 14s (remain 15m 26s) Loss: 0.0002(0.0029) Grad: 3334.0532  LR: 0.000007  \n","Epoch: [4][2100/5754] Elapsed 8m 38s (remain 15m 1s) Loss: 0.0061(0.0028) Grad: 8827.6230  LR: 0.000007  \n","Epoch: [4][2200/5754] Elapsed 9m 2s (remain 14m 35s) Loss: 0.0016(0.0028) Grad: 7397.6211  LR: 0.000007  \n","Epoch: [4][2300/5754] Elapsed 9m 26s (remain 14m 10s) Loss: 0.0000(0.0028) Grad: 66.5390  LR: 0.000007  \n","Epoch: [4][2400/5754] Elapsed 9m 50s (remain 13m 45s) Loss: 0.0000(0.0028) Grad: 7.2962  LR: 0.000007  \n","Epoch: [4][2500/5754] Elapsed 10m 15s (remain 13m 20s) Loss: 0.0000(0.0028) Grad: 99.6376  LR: 0.000007  \n","Epoch: [4][2600/5754] Elapsed 10m 39s (remain 12m 55s) Loss: 0.0000(0.0027) Grad: 23.4443  LR: 0.000007  \n","Epoch: [4][2700/5754] Elapsed 11m 3s (remain 12m 30s) Loss: 0.0000(0.0027) Grad: 21.0457  LR: 0.000007  \n","Epoch: [4][2800/5754] Elapsed 11m 27s (remain 12m 5s) Loss: 0.0004(0.0027) Grad: 10229.8809  LR: 0.000007  \n","Epoch: [4][2900/5754] Elapsed 11m 52s (remain 11m 40s) Loss: 0.0227(0.0027) Grad: 16320.7891  LR: 0.000007  \n","Epoch: [4][3000/5754] Elapsed 12m 16s (remain 11m 15s) Loss: 0.0029(0.0027) Grad: 7244.4341  LR: 0.000007  \n","Epoch: [4][3100/5754] Elapsed 12m 40s (remain 10m 50s) Loss: 0.0000(0.0027) Grad: 6.2184  LR: 0.000006  \n","Epoch: [4][3200/5754] Elapsed 13m 4s (remain 10m 25s) Loss: 0.0000(0.0027) Grad: 8.3108  LR: 0.000006  \n","Epoch: [4][3300/5754] Elapsed 13m 29s (remain 10m 1s) Loss: 0.0000(0.0027) Grad: 71.0481  LR: 0.000006  \n","Epoch: [4][3400/5754] Elapsed 13m 53s (remain 9m 36s) Loss: 0.0001(0.0027) Grad: 401.0907  LR: 0.000006  \n","Epoch: [4][3500/5754] Elapsed 14m 18s (remain 9m 12s) Loss: 0.0000(0.0028) Grad: 22.4794  LR: 0.000006  \n","Epoch: [4][3600/5754] Elapsed 14m 42s (remain 8m 47s) Loss: 0.0070(0.0028) Grad: 79589.1016  LR: 0.000006  \n","Epoch: [4][3700/5754] Elapsed 15m 7s (remain 8m 23s) Loss: 0.0005(0.0028) Grad: 4287.4590  LR: 0.000006  \n","Epoch: [4][3800/5754] Elapsed 15m 31s (remain 7m 58s) Loss: 0.0019(0.0028) Grad: 38494.6758  LR: 0.000006  \n","Epoch: [4][3900/5754] Elapsed 15m 56s (remain 7m 34s) Loss: 0.0002(0.0028) Grad: 747.5411  LR: 0.000006  \n","Epoch: [4][4000/5754] Elapsed 16m 21s (remain 7m 9s) Loss: 0.0008(0.0028) Grad: 17378.6328  LR: 0.000006  \n","Epoch: [4][4100/5754] Elapsed 16m 45s (remain 6m 45s) Loss: 0.0003(0.0028) Grad: 2126.1545  LR: 0.000006  \n","Epoch: [4][4200/5754] Elapsed 17m 9s (remain 6m 20s) Loss: 0.0000(0.0028) Grad: 51.4102  LR: 0.000006  \n","Epoch: [4][4300/5754] Elapsed 17m 33s (remain 5m 56s) Loss: 0.0001(0.0028) Grad: 474.2903  LR: 0.000006  \n","Epoch: [4][4400/5754] Elapsed 17m 57s (remain 5m 31s) Loss: 0.0000(0.0027) Grad: 2.9428  LR: 0.000005  \n","Epoch: [4][4500/5754] Elapsed 18m 22s (remain 5m 6s) Loss: 0.0000(0.0027) Grad: 2.7716  LR: 0.000005  \n","Epoch: [4][4600/5754] Elapsed 18m 46s (remain 4m 42s) Loss: 0.0108(0.0028) Grad: 11930.6387  LR: 0.000005  \n","Epoch: [4][4700/5754] Elapsed 19m 10s (remain 4m 17s) Loss: 0.0003(0.0028) Grad: 2806.5410  LR: 0.000005  \n","Epoch: [4][4800/5754] Elapsed 19m 34s (remain 3m 53s) Loss: 0.0000(0.0028) Grad: 41.8191  LR: 0.000005  \n","Epoch: [4][4900/5754] Elapsed 19m 59s (remain 3m 28s) Loss: 0.0000(0.0028) Grad: 79.1136  LR: 0.000005  \n","Epoch: [4][5000/5754] Elapsed 20m 23s (remain 3m 4s) Loss: 0.0000(0.0028) Grad: 53.6126  LR: 0.000005  \n","Epoch: [4][5100/5754] Elapsed 20m 47s (remain 2m 39s) Loss: 0.0003(0.0027) Grad: 1446.0150  LR: 0.000005  \n","Epoch: [4][5200/5754] Elapsed 21m 11s (remain 2m 15s) Loss: 0.0005(0.0027) Grad: 3697.7471  LR: 0.000005  \n","Epoch: [4][5300/5754] Elapsed 21m 35s (remain 1m 50s) Loss: 0.0002(0.0027) Grad: 3221.3259  LR: 0.000005  \n","Epoch: [4][5400/5754] Elapsed 22m 0s (remain 1m 26s) Loss: 0.0000(0.0027) Grad: 47.5304  LR: 0.000005  \n","Epoch: [4][5500/5754] Elapsed 22m 24s (remain 1m 1s) Loss: 0.0001(0.0027) Grad: 453.5832  LR: 0.000005  \n","Epoch: [4][5600/5754] Elapsed 22m 48s (remain 0m 37s) Loss: 0.0006(0.0027) Grad: 1818.5286  LR: 0.000005  \n","Epoch: [4][5700/5754] Elapsed 23m 12s (remain 0m 12s) Loss: 0.0000(0.0027) Grad: 15.7943  LR: 0.000004  \n","Epoch: [4][5753/5754] Elapsed 23m 25s (remain 0m 0s) Loss: 0.0000(0.0027) Grad: 999.6056  LR: 0.000004  \n","EVAL: [0/1396] Elapsed 0m 0s (remain 10m 7s) Loss: 0.0000(0.0000) \n","EVAL: [100/1396] Elapsed 0m 12s (remain 2m 40s) Loss: 0.0000(0.0029) \n","EVAL: [200/1396] Elapsed 0m 24s (remain 2m 25s) Loss: 0.0013(0.0030) \n","EVAL: [300/1396] Elapsed 0m 36s (remain 2m 13s) Loss: 0.0000(0.0034) \n","EVAL: [400/1396] Elapsed 0m 48s (remain 2m 0s) Loss: 0.0002(0.0045) \n","EVAL: [500/1396] Elapsed 1m 0s (remain 1m 48s) Loss: 0.0034(0.0044) \n","EVAL: [600/1396] Elapsed 1m 12s (remain 1m 36s) Loss: 0.0000(0.0043) \n","EVAL: [700/1396] Elapsed 1m 24s (remain 1m 23s) Loss: 0.0000(0.0040) \n","EVAL: [800/1396] Elapsed 1m 36s (remain 1m 11s) Loss: 0.0004(0.0045) \n","EVAL: [900/1396] Elapsed 1m 48s (remain 0m 59s) Loss: 0.0000(0.0047) \n","EVAL: [1000/1396] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0032(0.0046) \n","EVAL: [1100/1396] Elapsed 2m 12s (remain 0m 35s) Loss: 0.0050(0.0045) \n","EVAL: [1200/1396] Elapsed 2m 25s (remain 0m 23s) Loss: 0.0000(0.0043) \n","EVAL: [1300/1396] Elapsed 2m 37s (remain 0m 11s) Loss: 0.0003(0.0042) \n","EVAL: [1395/1396] Elapsed 2m 48s (remain 0m 0s) Loss: 0.0000(0.0041) \n","Epoch 4 - avg_train_loss: 0.0027  avg_val_loss: 0.0041  time: 1578s\n","Epoch 4 - Score: 0.8863\n","Epoch 4 - Save Best Score: 0.8863 Model\n","Epoch: [5][0/5754] Elapsed 0m 0s (remain 56m 47s) Loss: 0.0000(0.0000) Grad: 997.9320  LR: 0.000004  \n","Epoch: [5][100/5754] Elapsed 0m 28s (remain 27m 1s) Loss: 0.0000(0.0015) Grad: 382.8710  LR: 0.000004  \n","Epoch: [5][200/5754] Elapsed 0m 54s (remain 25m 3s) Loss: 0.0266(0.0014) Grad: 60282.9297  LR: 0.000004  \n","Epoch: [5][300/5754] Elapsed 1m 18s (remain 23m 48s) Loss: 0.0340(0.0017) Grad: 136216.5469  LR: 0.000004  \n","Epoch: [5][400/5754] Elapsed 1m 43s (remain 22m 58s) Loss: 0.0001(0.0020) Grad: 310.7249  LR: 0.000004  \n","Epoch: [5][500/5754] Elapsed 2m 7s (remain 22m 19s) Loss: 0.0026(0.0020) Grad: 3778.7280  LR: 0.000004  \n","Epoch: [5][600/5754] Elapsed 2m 32s (remain 21m 45s) Loss: 0.0000(0.0020) Grad: 72.0676  LR: 0.000004  \n","Epoch: [5][700/5754] Elapsed 2m 56s (remain 21m 12s) Loss: 0.0000(0.0021) Grad: 4.5425  LR: 0.000004  \n","Epoch: [5][800/5754] Elapsed 3m 20s (remain 20m 41s) Loss: 0.0078(0.0021) Grad: 19358.6992  LR: 0.000004  \n","Epoch: [5][900/5754] Elapsed 3m 44s (remain 20m 11s) Loss: 0.0039(0.0021) Grad: 9914.3359  LR: 0.000004  \n","Epoch: [5][1000/5754] Elapsed 4m 9s (remain 19m 42s) Loss: 0.0000(0.0021) Grad: 2.7299  LR: 0.000004  \n","Epoch: [5][1100/5754] Elapsed 4m 33s (remain 19m 15s) Loss: 0.0000(0.0021) Grad: 41.8231  LR: 0.000004  \n","Epoch: [5][1200/5754] Elapsed 4m 57s (remain 18m 48s) Loss: 0.0000(0.0021) Grad: 4.4894  LR: 0.000004  \n","Epoch: [5][1300/5754] Elapsed 5m 21s (remain 18m 21s) Loss: 0.0000(0.0021) Grad: 272.9154  LR: 0.000003  \n","Epoch: [5][1400/5754] Elapsed 5m 46s (remain 17m 55s) Loss: 0.0000(0.0021) Grad: 116.0192  LR: 0.000003  \n","Epoch: [5][1500/5754] Elapsed 6m 10s (remain 17m 29s) Loss: 0.0000(0.0022) Grad: 8.9578  LR: 0.000003  \n","Epoch: [5][1600/5754] Elapsed 6m 34s (remain 17m 4s) Loss: 0.0000(0.0022) Grad: 174.6966  LR: 0.000003  \n","Epoch: [5][1700/5754] Elapsed 6m 58s (remain 16m 37s) Loss: 0.0002(0.0023) Grad: 2102.2131  LR: 0.000003  \n","Epoch: [5][1800/5754] Elapsed 7m 22s (remain 16m 12s) Loss: 0.0155(0.0023) Grad: 9434.0635  LR: 0.000003  \n","Epoch: [5][1900/5754] Elapsed 7m 46s (remain 15m 46s) Loss: 0.0002(0.0023) Grad: 2197.6604  LR: 0.000003  \n","Epoch: [5][2000/5754] Elapsed 8m 11s (remain 15m 21s) Loss: 0.0000(0.0024) Grad: 21.8075  LR: 0.000003  \n","Epoch: [5][2100/5754] Elapsed 8m 35s (remain 14m 55s) Loss: 0.0000(0.0023) Grad: 5.3228  LR: 0.000003  \n","Epoch: [5][2200/5754] Elapsed 8m 59s (remain 14m 30s) Loss: 0.0010(0.0023) Grad: 7847.5894  LR: 0.000003  \n","Epoch: [5][2300/5754] Elapsed 9m 23s (remain 14m 5s) Loss: 0.0000(0.0023) Grad: 67.4712  LR: 0.000003  \n","Epoch: [5][2400/5754] Elapsed 9m 47s (remain 13m 40s) Loss: 0.0033(0.0023) Grad: 2504.1594  LR: 0.000003  \n","Epoch: [5][2500/5754] Elapsed 10m 11s (remain 13m 15s) Loss: 0.0001(0.0023) Grad: 312.5276  LR: 0.000003  \n","Epoch: [5][2600/5754] Elapsed 10m 35s (remain 12m 50s) Loss: 0.0017(0.0023) Grad: 18991.1758  LR: 0.000002  \n","Epoch: [5][2700/5754] Elapsed 10m 59s (remain 12m 25s) Loss: 0.0000(0.0023) Grad: 8.6990  LR: 0.000002  \n","Epoch: [5][2800/5754] Elapsed 11m 23s (remain 12m 1s) Loss: 0.0000(0.0023) Grad: 74.5330  LR: 0.000002  \n","Epoch: [5][2900/5754] Elapsed 11m 48s (remain 11m 36s) Loss: 0.0000(0.0023) Grad: 15.5108  LR: 0.000002  \n","Epoch: [5][3000/5754] Elapsed 12m 12s (remain 11m 11s) Loss: 0.0000(0.0023) Grad: 17.5677  LR: 0.000002  \n","Epoch: [5][3100/5754] Elapsed 12m 36s (remain 10m 46s) Loss: 0.0000(0.0023) Grad: 3.1290  LR: 0.000002  \n","Epoch: [5][3200/5754] Elapsed 13m 0s (remain 10m 22s) Loss: 0.0001(0.0023) Grad: 879.4641  LR: 0.000002  \n","Epoch: [5][3300/5754] Elapsed 13m 24s (remain 9m 57s) Loss: 0.0000(0.0023) Grad: 53.4453  LR: 0.000002  \n","Epoch: [5][3400/5754] Elapsed 13m 48s (remain 9m 33s) Loss: 0.0108(0.0023) Grad: 17493.7129  LR: 0.000002  \n","Epoch: [5][3500/5754] Elapsed 14m 12s (remain 9m 8s) Loss: 0.0007(0.0023) Grad: 5282.7363  LR: 0.000002  \n","Epoch: [5][3600/5754] Elapsed 14m 36s (remain 8m 44s) Loss: 0.0079(0.0023) Grad: 33252.4453  LR: 0.000002  \n","Epoch: [5][3700/5754] Elapsed 15m 0s (remain 8m 19s) Loss: 0.0003(0.0023) Grad: 1559.2415  LR: 0.000002  \n","Epoch: [5][3800/5754] Elapsed 15m 24s (remain 7m 55s) Loss: 0.0000(0.0023) Grad: 37.7543  LR: 0.000002  \n","Epoch: [5][3900/5754] Elapsed 15m 48s (remain 7m 30s) Loss: 0.0000(0.0023) Grad: 2.5795  LR: 0.000001  \n","Epoch: [5][4000/5754] Elapsed 16m 12s (remain 7m 6s) Loss: 0.0000(0.0023) Grad: 4.0062  LR: 0.000001  \n","Epoch: [5][4100/5754] Elapsed 16m 36s (remain 6m 41s) Loss: 0.0000(0.0023) Grad: 92.5574  LR: 0.000001  \n","Epoch: [5][4200/5754] Elapsed 17m 0s (remain 6m 17s) Loss: 0.0174(0.0023) Grad: 30681.5840  LR: 0.000001  \n","Epoch: [5][4300/5754] Elapsed 17m 24s (remain 5m 52s) Loss: 0.0000(0.0023) Grad: 57.4665  LR: 0.000001  \n","Epoch: [5][4400/5754] Elapsed 17m 48s (remain 5m 28s) Loss: 0.0001(0.0023) Grad: 355.1552  LR: 0.000001  \n","Epoch: [5][4500/5754] Elapsed 18m 12s (remain 5m 4s) Loss: 0.0000(0.0023) Grad: 36.8923  LR: 0.000001  \n","Epoch: [5][4600/5754] Elapsed 18m 36s (remain 4m 39s) Loss: 0.0003(0.0023) Grad: 1681.6066  LR: 0.000001  \n","Epoch: [5][4700/5754] Elapsed 19m 0s (remain 4m 15s) Loss: 0.0005(0.0023) Grad: 27138.6973  LR: 0.000001  \n","Epoch: [5][4800/5754] Elapsed 19m 24s (remain 3m 51s) Loss: 0.0012(0.0023) Grad: 15807.6338  LR: 0.000001  \n","Epoch: [5][4900/5754] Elapsed 19m 48s (remain 3m 26s) Loss: 0.0001(0.0023) Grad: 155.2478  LR: 0.000001  \n","Epoch: [5][5000/5754] Elapsed 20m 12s (remain 3m 2s) Loss: 0.0067(0.0024) Grad: 11000.4609  LR: 0.000001  \n","Epoch: [5][5100/5754] Elapsed 20m 36s (remain 2m 38s) Loss: 0.0007(0.0024) Grad: 7228.9263  LR: 0.000001  \n","Epoch: [5][5200/5754] Elapsed 21m 0s (remain 2m 14s) Loss: 0.0000(0.0023) Grad: 24.2893  LR: 0.000000  \n","Epoch: [5][5300/5754] Elapsed 21m 24s (remain 1m 49s) Loss: 0.0001(0.0023) Grad: 1251.8766  LR: 0.000000  \n","Epoch: [5][5400/5754] Elapsed 21m 48s (remain 1m 25s) Loss: 0.0000(0.0023) Grad: 100.3866  LR: 0.000000  \n","Epoch: [5][5500/5754] Elapsed 22m 12s (remain 1m 1s) Loss: 0.0000(0.0023) Grad: 71.0403  LR: 0.000000  \n","Epoch: [5][5600/5754] Elapsed 22m 36s (remain 0m 37s) Loss: 0.0000(0.0023) Grad: 7.8265  LR: 0.000000  \n","Epoch: [5][5700/5754] Elapsed 23m 0s (remain 0m 12s) Loss: 0.0338(0.0023) Grad: 42579.3984  LR: 0.000000  \n","Epoch: [5][5753/5754] Elapsed 23m 13s (remain 0m 0s) Loss: 0.0000(0.0023) Grad: 254.2950  LR: 0.000000  \n","EVAL: [0/1396] Elapsed 0m 0s (remain 9m 22s) Loss: 0.0001(0.0001) \n","EVAL: [100/1396] Elapsed 0m 12s (remain 2m 39s) Loss: 0.0000(0.0035) \n","EVAL: [200/1396] Elapsed 0m 24s (remain 2m 25s) Loss: 0.0017(0.0033) \n","EVAL: [300/1396] Elapsed 0m 36s (remain 2m 12s) Loss: 0.0000(0.0036) \n","EVAL: [400/1396] Elapsed 0m 48s (remain 2m 0s) Loss: 0.0001(0.0047) \n","EVAL: [500/1396] Elapsed 1m 0s (remain 1m 47s) Loss: 0.0019(0.0046) \n","EVAL: [600/1396] Elapsed 1m 12s (remain 1m 35s) Loss: 0.0000(0.0045) \n","EVAL: [700/1396] Elapsed 1m 24s (remain 1m 23s) Loss: 0.0000(0.0041) \n","EVAL: [800/1396] Elapsed 1m 36s (remain 1m 11s) Loss: 0.0009(0.0047) \n","EVAL: [900/1396] Elapsed 1m 48s (remain 0m 59s) Loss: 0.0000(0.0049) \n","EVAL: [1000/1396] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0037(0.0048) \n","EVAL: [1100/1396] Elapsed 2m 12s (remain 0m 35s) Loss: 0.0037(0.0047) \n","EVAL: [1200/1396] Elapsed 2m 24s (remain 0m 23s) Loss: 0.0000(0.0045) \n","EVAL: [1300/1396] Elapsed 2m 36s (remain 0m 11s) Loss: 0.0000(0.0045) \n","EVAL: [1395/1396] Elapsed 2m 47s (remain 0m 0s) Loss: 0.0000(0.0044) \n","Epoch 5 - avg_train_loss: 0.0023  avg_val_loss: 0.0044  time: 1565s\n","Epoch 5 - Score: 0.8843\n","========== fold: 4 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5700] Elapsed 0m 0s (remain 57m 6s) Loss: 0.3292(0.3292) Grad: 100372.1562  LR: 0.000000  \n","Epoch: [1][100/5700] Elapsed 0m 24s (remain 22m 44s) Loss: 0.3337(0.2799) Grad: 52542.5000  LR: 0.000001  \n","Epoch: [1][200/5700] Elapsed 0m 48s (remain 22m 14s) Loss: 0.3004(0.2738) Grad: 23883.7188  LR: 0.000001  \n","Epoch: [1][300/5700] Elapsed 1m 12s (remain 21m 46s) Loss: 0.2987(0.2649) Grad: 25066.2402  LR: 0.000002  \n","Epoch: [1][400/5700] Elapsed 1m 37s (remain 21m 22s) Loss: 0.2106(0.2488) Grad: 21785.3125  LR: 0.000003  \n","Epoch: [1][500/5700] Elapsed 2m 1s (remain 20m 56s) Loss: 0.0686(0.2280) Grad: 9469.8652  LR: 0.000004  \n","Epoch: [1][600/5700] Elapsed 2m 25s (remain 20m 32s) Loss: 0.0353(0.2023) Grad: 1335.4170  LR: 0.000004  \n","Epoch: [1][700/5700] Elapsed 2m 49s (remain 20m 7s) Loss: 0.0296(0.1767) Grad: 769.8268  LR: 0.000005  \n","Epoch: [1][800/5700] Elapsed 3m 13s (remain 19m 42s) Loss: 0.0079(0.1573) Grad: 809.9969  LR: 0.000006  \n","Epoch: [1][900/5700] Elapsed 3m 37s (remain 19m 18s) Loss: 0.0170(0.1421) Grad: 394.0960  LR: 0.000006  \n","Epoch: [1][1000/5700] Elapsed 4m 1s (remain 18m 53s) Loss: 0.0196(0.1298) Grad: 620.6674  LR: 0.000007  \n","Epoch: [1][1100/5700] Elapsed 4m 25s (remain 18m 28s) Loss: 0.0450(0.1198) Grad: 2278.4390  LR: 0.000008  \n","Epoch: [1][1200/5700] Elapsed 4m 49s (remain 18m 3s) Loss: 0.0125(0.1112) Grad: 825.1709  LR: 0.000008  \n","Epoch: [1][1300/5700] Elapsed 5m 13s (remain 17m 40s) Loss: 0.0025(0.1037) Grad: 938.6880  LR: 0.000009  \n","Epoch: [1][1400/5700] Elapsed 5m 37s (remain 17m 15s) Loss: 0.0105(0.0972) Grad: 801.4763  LR: 0.000010  \n","Epoch: [1][1500/5700] Elapsed 6m 1s (remain 16m 51s) Loss: 0.0019(0.0914) Grad: 212.9831  LR: 0.000011  \n","Epoch: [1][1600/5700] Elapsed 6m 25s (remain 16m 27s) Loss: 0.0269(0.0862) Grad: 11689.3848  LR: 0.000011  \n","Epoch: [1][1700/5700] Elapsed 6m 49s (remain 16m 3s) Loss: 0.0049(0.0817) Grad: 1454.0571  LR: 0.000012  \n","Epoch: [1][1800/5700] Elapsed 7m 13s (remain 15m 38s) Loss: 0.0011(0.0775) Grad: 220.7603  LR: 0.000013  \n","Epoch: [1][1900/5700] Elapsed 7m 37s (remain 15m 14s) Loss: 0.0076(0.0738) Grad: 2426.0620  LR: 0.000013  \n","Epoch: [1][2000/5700] Elapsed 8m 1s (remain 14m 50s) Loss: 0.0146(0.0705) Grad: 2033.5294  LR: 0.000014  \n","Epoch: [1][2100/5700] Elapsed 8m 25s (remain 14m 26s) Loss: 0.0065(0.0676) Grad: 1353.0522  LR: 0.000015  \n","Epoch: [1][2200/5700] Elapsed 8m 49s (remain 14m 2s) Loss: 0.0057(0.0648) Grad: 1310.7096  LR: 0.000015  \n","Epoch: [1][2300/5700] Elapsed 9m 13s (remain 13m 37s) Loss: 0.0029(0.0622) Grad: 1183.7401  LR: 0.000016  \n","Epoch: [1][2400/5700] Elapsed 9m 37s (remain 13m 13s) Loss: 0.0010(0.0599) Grad: 570.1484  LR: 0.000017  \n","Epoch: [1][2500/5700] Elapsed 10m 1s (remain 12m 49s) Loss: 0.0014(0.0578) Grad: 1022.6769  LR: 0.000018  \n","Epoch: [1][2600/5700] Elapsed 10m 25s (remain 12m 25s) Loss: 0.0031(0.0558) Grad: 1179.5540  LR: 0.000018  \n","Epoch: [1][2700/5700] Elapsed 10m 49s (remain 12m 1s) Loss: 0.0160(0.0540) Grad: 7793.8057  LR: 0.000019  \n","Epoch: [1][2800/5700] Elapsed 11m 13s (remain 11m 37s) Loss: 0.0021(0.0523) Grad: 489.1291  LR: 0.000020  \n","Epoch: [1][2900/5700] Elapsed 11m 37s (remain 11m 13s) Loss: 0.0014(0.0507) Grad: 581.1786  LR: 0.000020  \n","Epoch: [1][3000/5700] Elapsed 12m 1s (remain 10m 49s) Loss: 0.0031(0.0492) Grad: 1186.2570  LR: 0.000020  \n","Epoch: [1][3100/5700] Elapsed 12m 25s (remain 10m 25s) Loss: 0.0017(0.0478) Grad: 460.5225  LR: 0.000020  \n","Epoch: [1][3200/5700] Elapsed 12m 49s (remain 10m 1s) Loss: 0.0037(0.0464) Grad: 4523.0244  LR: 0.000020  \n","Epoch: [1][3300/5700] Elapsed 13m 14s (remain 9m 37s) Loss: 0.0088(0.0452) Grad: 13955.0645  LR: 0.000020  \n","Epoch: [1][3400/5700] Elapsed 13m 38s (remain 9m 12s) Loss: 0.0038(0.0440) Grad: 1341.5950  LR: 0.000020  \n","Epoch: [1][3500/5700] Elapsed 14m 1s (remain 8m 48s) Loss: 0.0037(0.0429) Grad: 1374.6702  LR: 0.000019  \n","Epoch: [1][3600/5700] Elapsed 14m 25s (remain 8m 24s) Loss: 0.0105(0.0419) Grad: 16727.5156  LR: 0.000019  \n","Epoch: [1][3700/5700] Elapsed 14m 49s (remain 8m 0s) Loss: 0.0033(0.0409) Grad: 1596.6381  LR: 0.000019  \n","Epoch: [1][3800/5700] Elapsed 15m 13s (remain 7m 36s) Loss: 0.0003(0.0400) Grad: 143.7935  LR: 0.000019  \n","Epoch: [1][3900/5700] Elapsed 15m 37s (remain 7m 12s) Loss: 0.0008(0.0390) Grad: 454.2036  LR: 0.000019  \n","Epoch: [1][4000/5700] Elapsed 16m 1s (remain 6m 48s) Loss: 0.0001(0.0382) Grad: 64.3264  LR: 0.000019  \n","Epoch: [1][4100/5700] Elapsed 16m 25s (remain 6m 24s) Loss: 0.0104(0.0374) Grad: 3212.2893  LR: 0.000019  \n","Epoch: [1][4200/5700] Elapsed 16m 49s (remain 6m 0s) Loss: 0.0016(0.0366) Grad: 303.5402  LR: 0.000019  \n","Epoch: [1][4300/5700] Elapsed 17m 13s (remain 5m 36s) Loss: 0.0003(0.0358) Grad: 97.1996  LR: 0.000019  \n","Epoch: [1][4400/5700] Elapsed 17m 37s (remain 5m 12s) Loss: 0.0004(0.0351) Grad: 100.2479  LR: 0.000019  \n","Epoch: [1][4500/5700] Elapsed 18m 1s (remain 4m 48s) Loss: 0.0015(0.0344) Grad: 671.8813  LR: 0.000019  \n","Epoch: [1][4600/5700] Elapsed 18m 25s (remain 4m 24s) Loss: 0.0000(0.0338) Grad: 26.7792  LR: 0.000019  \n","Epoch: [1][4700/5700] Elapsed 18m 49s (remain 4m 0s) Loss: 0.0073(0.0332) Grad: 1293.9504  LR: 0.000019  \n","Epoch: [1][4800/5700] Elapsed 19m 13s (remain 3m 35s) Loss: 0.0008(0.0325) Grad: 202.5287  LR: 0.000018  \n","Epoch: [1][4900/5700] Elapsed 19m 37s (remain 3m 11s) Loss: 0.0003(0.0319) Grad: 80.5736  LR: 0.000018  \n","Epoch: [1][5000/5700] Elapsed 20m 1s (remain 2m 47s) Loss: 0.0314(0.0314) Grad: 2574.0757  LR: 0.000018  \n","Epoch: [1][5100/5700] Elapsed 20m 25s (remain 2m 23s) Loss: 0.0047(0.0309) Grad: 369.6027  LR: 0.000018  \n","Epoch: [1][5200/5700] Elapsed 20m 49s (remain 1m 59s) Loss: 0.0003(0.0303) Grad: 832.1703  LR: 0.000018  \n","Epoch: [1][5300/5700] Elapsed 21m 13s (remain 1m 35s) Loss: 0.0007(0.0299) Grad: 669.8648  LR: 0.000018  \n","Epoch: [1][5400/5700] Elapsed 21m 37s (remain 1m 11s) Loss: 0.0001(0.0294) Grad: 27.3518  LR: 0.000018  \n","Epoch: [1][5500/5700] Elapsed 22m 1s (remain 0m 47s) Loss: 0.0004(0.0289) Grad: 79.9864  LR: 0.000018  \n","Epoch: [1][5600/5700] Elapsed 22m 25s (remain 0m 23s) Loss: 0.0000(0.0284) Grad: 10.8954  LR: 0.000018  \n","Epoch: [1][5699/5700] Elapsed 22m 48s (remain 0m 0s) Loss: 0.0007(0.0280) Grad: 944.5223  LR: 0.000018  \n","EVAL: [0/1450] Elapsed 0m 0s (remain 10m 49s) Loss: 0.0022(0.0022) \n","EVAL: [100/1450] Elapsed 0m 12s (remain 2m 45s) Loss: 0.0023(0.0030) \n","EVAL: [200/1450] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0013(0.0034) \n","EVAL: [300/1450] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0061(0.0038) \n","EVAL: [400/1450] Elapsed 0m 48s (remain 2m 7s) Loss: 0.0083(0.0041) \n","EVAL: [500/1450] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0004(0.0038) \n","EVAL: [600/1450] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0022(0.0036) \n","EVAL: [700/1450] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0007(0.0037) \n","EVAL: [800/1450] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0558(0.0039) \n","EVAL: [900/1450] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0041(0.0041) \n","EVAL: [1000/1450] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0056(0.0040) \n","EVAL: [1100/1450] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0001(0.0040) \n","EVAL: [1200/1450] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0024(0.0040) \n","EVAL: [1300/1450] Elapsed 2m 36s (remain 0m 17s) Loss: 0.0002(0.0038) \n","EVAL: [1400/1450] Elapsed 2m 48s (remain 0m 5s) Loss: 0.0002(0.0037) \n","EVAL: [1449/1450] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0004(0.0036) \n","Epoch 1 - avg_train_loss: 0.0280  avg_val_loss: 0.0036  time: 1548s\n","Epoch 1 - Score: 0.8366\n","Epoch 1 - Save Best Score: 0.8366 Model\n","Epoch: [2][0/5700] Elapsed 0m 0s (remain 62m 39s) Loss: 0.0000(0.0000) Grad: 286.6710  LR: 0.000018  \n","Epoch: [2][100/5700] Elapsed 0m 28s (remain 26m 2s) Loss: 0.0005(0.0043) Grad: 952.1535  LR: 0.000018  \n","Epoch: [2][200/5700] Elapsed 0m 53s (remain 24m 28s) Loss: 0.0027(0.0037) Grad: 7492.1279  LR: 0.000018  \n","Epoch: [2][300/5700] Elapsed 1m 17s (remain 23m 15s) Loss: 0.0006(0.0035) Grad: 1773.9136  LR: 0.000018  \n","Epoch: [2][400/5700] Elapsed 1m 41s (remain 22m 25s) Loss: 0.0001(0.0035) Grad: 574.5728  LR: 0.000017  \n","Epoch: [2][500/5700] Elapsed 2m 5s (remain 21m 45s) Loss: 0.0022(0.0036) Grad: 1584.2299  LR: 0.000017  \n","Epoch: [2][600/5700] Elapsed 2m 29s (remain 21m 11s) Loss: 0.0047(0.0036) Grad: 3470.2317  LR: 0.000017  \n","Epoch: [2][700/5700] Elapsed 2m 53s (remain 20m 39s) Loss: 0.0005(0.0038) Grad: 2332.9875  LR: 0.000017  \n","Epoch: [2][800/5700] Elapsed 3m 18s (remain 20m 11s) Loss: 0.0000(0.0038) Grad: 19.8644  LR: 0.000017  \n","Epoch: [2][900/5700] Elapsed 3m 42s (remain 19m 43s) Loss: 0.0037(0.0037) Grad: 5367.8442  LR: 0.000017  \n","Epoch: [2][1000/5700] Elapsed 4m 6s (remain 19m 15s) Loss: 0.0007(0.0037) Grad: 6588.4702  LR: 0.000017  \n","Epoch: [2][1100/5700] Elapsed 4m 30s (remain 18m 47s) Loss: 0.0000(0.0037) Grad: 37.4496  LR: 0.000017  \n","Epoch: [2][1200/5700] Elapsed 4m 54s (remain 18m 21s) Loss: 0.0032(0.0038) Grad: 7639.2881  LR: 0.000017  \n","Epoch: [2][1300/5700] Elapsed 5m 18s (remain 17m 55s) Loss: 0.0008(0.0037) Grad: 2584.6582  LR: 0.000017  \n","Epoch: [2][1400/5700] Elapsed 5m 41s (remain 17m 29s) Loss: 0.0000(0.0037) Grad: 34.0069  LR: 0.000017  \n","Epoch: [2][1500/5700] Elapsed 6m 5s (remain 17m 3s) Loss: 0.0001(0.0036) Grad: 128.0320  LR: 0.000017  \n","Epoch: [2][1600/5700] Elapsed 6m 29s (remain 16m 38s) Loss: 0.0001(0.0035) Grad: 124.0304  LR: 0.000017  \n","Epoch: [2][1700/5700] Elapsed 6m 54s (remain 16m 13s) Loss: 0.0000(0.0036) Grad: 53.9272  LR: 0.000016  \n","Epoch: [2][1800/5700] Elapsed 7m 17s (remain 15m 48s) Loss: 0.0007(0.0035) Grad: 4053.6462  LR: 0.000016  \n","Epoch: [2][1900/5700] Elapsed 7m 41s (remain 15m 23s) Loss: 0.0001(0.0035) Grad: 272.0331  LR: 0.000016  \n","Epoch: [2][2000/5700] Elapsed 8m 5s (remain 14m 58s) Loss: 0.0001(0.0035) Grad: 367.5755  LR: 0.000016  \n","Epoch: [2][2100/5700] Elapsed 8m 29s (remain 14m 33s) Loss: 0.0000(0.0036) Grad: 57.5558  LR: 0.000016  \n","Epoch: [2][2200/5700] Elapsed 8m 54s (remain 14m 8s) Loss: 0.0006(0.0035) Grad: 3100.2664  LR: 0.000016  \n","Epoch: [2][2300/5700] Elapsed 9m 17s (remain 13m 44s) Loss: 0.0034(0.0035) Grad: 13875.5908  LR: 0.000016  \n","Epoch: [2][2400/5700] Elapsed 9m 41s (remain 13m 19s) Loss: 0.0000(0.0036) Grad: 94.2514  LR: 0.000016  \n","Epoch: [2][2500/5700] Elapsed 10m 5s (remain 12m 54s) Loss: 0.0062(0.0035) Grad: 23606.6133  LR: 0.000016  \n","Epoch: [2][2600/5700] Elapsed 10m 29s (remain 12m 30s) Loss: 0.0000(0.0035) Grad: 62.0234  LR: 0.000016  \n","Epoch: [2][2700/5700] Elapsed 10m 53s (remain 12m 5s) Loss: 0.0000(0.0035) Grad: 289.4112  LR: 0.000016  \n","Epoch: [2][2800/5700] Elapsed 11m 17s (remain 11m 41s) Loss: 0.0036(0.0035) Grad: 8306.2744  LR: 0.000016  \n","Epoch: [2][2900/5700] Elapsed 11m 41s (remain 11m 17s) Loss: 0.0000(0.0035) Grad: 35.5237  LR: 0.000016  \n","Epoch: [2][3000/5700] Elapsed 12m 5s (remain 10m 52s) Loss: 0.0001(0.0034) Grad: 496.7158  LR: 0.000015  \n","Epoch: [2][3100/5700] Elapsed 12m 29s (remain 10m 28s) Loss: 0.0000(0.0034) Grad: 30.2342  LR: 0.000015  \n","Epoch: [2][3200/5700] Elapsed 12m 53s (remain 10m 3s) Loss: 0.0007(0.0034) Grad: 8208.1875  LR: 0.000015  \n","Epoch: [2][3300/5700] Elapsed 13m 17s (remain 9m 39s) Loss: 0.0000(0.0034) Grad: 34.1256  LR: 0.000015  \n","Epoch: [2][3400/5700] Elapsed 13m 41s (remain 9m 15s) Loss: 0.0000(0.0034) Grad: 46.3440  LR: 0.000015  \n","Epoch: [2][3500/5700] Elapsed 14m 5s (remain 8m 51s) Loss: 0.0208(0.0034) Grad: 69084.0938  LR: 0.000015  \n","Epoch: [2][3600/5700] Elapsed 14m 29s (remain 8m 26s) Loss: 0.0001(0.0034) Grad: 1837.7894  LR: 0.000015  \n","Epoch: [2][3700/5700] Elapsed 14m 53s (remain 8m 2s) Loss: 0.0054(0.0034) Grad: 6554.9482  LR: 0.000015  \n","Epoch: [2][3800/5700] Elapsed 15m 17s (remain 7m 38s) Loss: 0.0001(0.0035) Grad: 279.2498  LR: 0.000015  \n","Epoch: [2][3900/5700] Elapsed 15m 41s (remain 7m 14s) Loss: 0.0002(0.0035) Grad: 843.8594  LR: 0.000015  \n","Epoch: [2][4000/5700] Elapsed 16m 5s (remain 6m 49s) Loss: 0.0003(0.0035) Grad: 1479.6028  LR: 0.000015  \n","Epoch: [2][4100/5700] Elapsed 16m 29s (remain 6m 25s) Loss: 0.0251(0.0034) Grad: 14175.1104  LR: 0.000015  \n","Epoch: [2][4200/5700] Elapsed 16m 53s (remain 6m 1s) Loss: 0.0112(0.0035) Grad: 27240.7402  LR: 0.000015  \n","Epoch: [2][4300/5700] Elapsed 17m 16s (remain 5m 37s) Loss: 0.0001(0.0035) Grad: 653.1650  LR: 0.000014  \n","Epoch: [2][4400/5700] Elapsed 17m 40s (remain 5m 13s) Loss: 0.0014(0.0034) Grad: 5043.6870  LR: 0.000014  \n","Epoch: [2][4500/5700] Elapsed 18m 4s (remain 4m 49s) Loss: 0.0001(0.0035) Grad: 623.1223  LR: 0.000014  \n","Epoch: [2][4600/5700] Elapsed 18m 28s (remain 4m 24s) Loss: 0.0005(0.0035) Grad: 2103.8098  LR: 0.000014  \n","Epoch: [2][4700/5700] Elapsed 18m 52s (remain 4m 0s) Loss: 0.0001(0.0035) Grad: 218.5209  LR: 0.000014  \n","Epoch: [2][4800/5700] Elapsed 19m 16s (remain 3m 36s) Loss: 0.0000(0.0035) Grad: 79.8778  LR: 0.000014  \n","Epoch: [2][4900/5700] Elapsed 19m 40s (remain 3m 12s) Loss: 0.0000(0.0035) Grad: 31.2131  LR: 0.000014  \n","Epoch: [2][5000/5700] Elapsed 20m 4s (remain 2m 48s) Loss: 0.0014(0.0035) Grad: 4445.4443  LR: 0.000014  \n","Epoch: [2][5100/5700] Elapsed 20m 28s (remain 2m 24s) Loss: 0.0000(0.0035) Grad: 19.1574  LR: 0.000014  \n","Epoch: [2][5200/5700] Elapsed 20m 52s (remain 2m 0s) Loss: 0.0001(0.0035) Grad: 394.6138  LR: 0.000014  \n","Epoch: [2][5300/5700] Elapsed 21m 16s (remain 1m 36s) Loss: 0.0010(0.0035) Grad: 2850.1824  LR: 0.000014  \n","Epoch: [2][5400/5700] Elapsed 21m 40s (remain 1m 12s) Loss: 0.0000(0.0035) Grad: 28.9786  LR: 0.000014  \n","Epoch: [2][5500/5700] Elapsed 22m 4s (remain 0m 47s) Loss: 0.0000(0.0035) Grad: 61.4603  LR: 0.000013  \n","Epoch: [2][5600/5700] Elapsed 22m 28s (remain 0m 23s) Loss: 0.0042(0.0035) Grad: 5716.3638  LR: 0.000013  \n","Epoch: [2][5699/5700] Elapsed 22m 52s (remain 0m 0s) Loss: 0.0000(0.0035) Grad: 1011.2541  LR: 0.000013  \n","EVAL: [0/1450] Elapsed 0m 0s (remain 10m 13s) Loss: 0.0080(0.0080) \n","EVAL: [100/1450] Elapsed 0m 12s (remain 2m 44s) Loss: 0.0002(0.0033) \n","EVAL: [200/1450] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0017(0.0042) \n","EVAL: [300/1450] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0060(0.0050) \n","EVAL: [400/1450] Elapsed 0m 48s (remain 2m 6s) Loss: 0.0167(0.0053) \n","EVAL: [500/1450] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0000(0.0049) \n","EVAL: [600/1450] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0001(0.0046) \n","EVAL: [700/1450] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0005(0.0046) \n","EVAL: [800/1450] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0759(0.0052) \n","EVAL: [900/1450] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0021(0.0055) \n","EVAL: [1000/1450] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0131(0.0053) \n","EVAL: [1100/1450] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0000(0.0052) \n","EVAL: [1200/1450] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0105(0.0052) \n","EVAL: [1300/1450] Elapsed 2m 36s (remain 0m 17s) Loss: 0.0000(0.0050) \n","EVAL: [1400/1450] Elapsed 2m 48s (remain 0m 5s) Loss: 0.0000(0.0048) \n","EVAL: [1449/1450] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0047) \n","Epoch 2 - avg_train_loss: 0.0035  avg_val_loss: 0.0047  time: 1551s\n","Epoch 2 - Score: 0.8680\n","Epoch 2 - Save Best Score: 0.8680 Model\n","Epoch: [3][0/5700] Elapsed 0m 0s (remain 58m 36s) Loss: 0.0043(0.0043) Grad: 17595.5586  LR: 0.000013  \n","Epoch: [3][100/5700] Elapsed 0m 27s (remain 25m 23s) Loss: 0.0000(0.0020) Grad: 444.4001  LR: 0.000013  \n","Epoch: [3][200/5700] Elapsed 0m 53s (remain 24m 18s) Loss: 0.0038(0.0026) Grad: 18713.8906  LR: 0.000013  \n","Epoch: [3][300/5700] Elapsed 1m 17s (remain 23m 4s) Loss: 0.0000(0.0028) Grad: 48.7357  LR: 0.000013  \n","Epoch: [3][400/5700] Elapsed 1m 41s (remain 22m 18s) Loss: 0.0001(0.0029) Grad: 641.7016  LR: 0.000013  \n","Epoch: [3][500/5700] Elapsed 2m 5s (remain 21m 39s) Loss: 0.0000(0.0028) Grad: 26.8739  LR: 0.000013  \n","Epoch: [3][600/5700] Elapsed 2m 29s (remain 21m 5s) Loss: 0.0001(0.0029) Grad: 172.1570  LR: 0.000013  \n","Epoch: [3][700/5700] Elapsed 2m 53s (remain 20m 35s) Loss: 0.0026(0.0029) Grad: 11113.2266  LR: 0.000013  \n","Epoch: [3][800/5700] Elapsed 3m 17s (remain 20m 6s) Loss: 0.0305(0.0029) Grad: 130547.9062  LR: 0.000013  \n","Epoch: [3][900/5700] Elapsed 3m 41s (remain 19m 37s) Loss: 0.0001(0.0030) Grad: 670.8677  LR: 0.000013  \n","Epoch: [3][1000/5700] Elapsed 4m 5s (remain 19m 10s) Loss: 0.0002(0.0030) Grad: 772.4956  LR: 0.000013  \n","Epoch: [3][1100/5700] Elapsed 4m 29s (remain 18m 43s) Loss: 0.0000(0.0030) Grad: 7.4363  LR: 0.000012  \n","Epoch: [3][1200/5700] Elapsed 4m 52s (remain 18m 17s) Loss: 0.0000(0.0030) Grad: 29.9354  LR: 0.000012  \n","Epoch: [3][1300/5700] Elapsed 5m 16s (remain 17m 51s) Loss: 0.0039(0.0031) Grad: 29619.6445  LR: 0.000012  \n","Epoch: [3][1400/5700] Elapsed 5m 40s (remain 17m 25s) Loss: 0.0001(0.0031) Grad: 478.0336  LR: 0.000012  \n","Epoch: [3][1500/5700] Elapsed 6m 4s (remain 17m 0s) Loss: 0.0000(0.0030) Grad: 32.4788  LR: 0.000012  \n","Epoch: [3][1600/5700] Elapsed 6m 28s (remain 16m 34s) Loss: 0.0122(0.0031) Grad: 13532.8281  LR: 0.000012  \n","Epoch: [3][1700/5700] Elapsed 6m 52s (remain 16m 9s) Loss: 0.0135(0.0032) Grad: 18226.4043  LR: 0.000012  \n","Epoch: [3][1800/5700] Elapsed 7m 16s (remain 15m 45s) Loss: 0.0000(0.0032) Grad: 9.5831  LR: 0.000012  \n","Epoch: [3][1900/5700] Elapsed 7m 40s (remain 15m 20s) Loss: 0.0001(0.0032) Grad: 1299.8634  LR: 0.000012  \n","Epoch: [3][2000/5700] Elapsed 8m 4s (remain 14m 55s) Loss: 0.0000(0.0031) Grad: 29.5440  LR: 0.000012  \n","Epoch: [3][2100/5700] Elapsed 8m 28s (remain 14m 30s) Loss: 0.0000(0.0030) Grad: 12.4708  LR: 0.000012  \n","Epoch: [3][2200/5700] Elapsed 8m 52s (remain 14m 5s) Loss: 0.0000(0.0031) Grad: 140.5900  LR: 0.000012  \n","Epoch: [3][2300/5700] Elapsed 9m 15s (remain 13m 41s) Loss: 0.0000(0.0031) Grad: 27.3285  LR: 0.000012  \n","Epoch: [3][2400/5700] Elapsed 9m 39s (remain 13m 16s) Loss: 0.0000(0.0031) Grad: 9.6169  LR: 0.000011  \n","Epoch: [3][2500/5700] Elapsed 10m 3s (remain 12m 52s) Loss: 0.0000(0.0031) Grad: 25.0883  LR: 0.000011  \n","Epoch: [3][2600/5700] Elapsed 10m 27s (remain 12m 27s) Loss: 0.0001(0.0031) Grad: 144.0788  LR: 0.000011  \n","Epoch: [3][2700/5700] Elapsed 10m 51s (remain 12m 3s) Loss: 0.0000(0.0031) Grad: 368.9204  LR: 0.000011  \n","Epoch: [3][2800/5700] Elapsed 11m 15s (remain 11m 38s) Loss: 0.0050(0.0030) Grad: 2786.3999  LR: 0.000011  \n","Epoch: [3][2900/5700] Elapsed 11m 39s (remain 11m 14s) Loss: 0.0066(0.0030) Grad: 18988.6914  LR: 0.000011  \n","Epoch: [3][3000/5700] Elapsed 12m 2s (remain 10m 50s) Loss: 0.0099(0.0031) Grad: 18935.9668  LR: 0.000011  \n","Epoch: [3][3100/5700] Elapsed 12m 26s (remain 10m 25s) Loss: 0.0034(0.0030) Grad: 15135.7314  LR: 0.000011  \n","Epoch: [3][3200/5700] Elapsed 12m 50s (remain 10m 1s) Loss: 0.0025(0.0030) Grad: 9045.3311  LR: 0.000011  \n","Epoch: [3][3300/5700] Elapsed 13m 14s (remain 9m 37s) Loss: 0.0291(0.0030) Grad: 41644.5195  LR: 0.000011  \n","Epoch: [3][3400/5700] Elapsed 13m 38s (remain 9m 13s) Loss: 0.0003(0.0030) Grad: 3504.1931  LR: 0.000011  \n","Epoch: [3][3500/5700] Elapsed 14m 2s (remain 8m 49s) Loss: 0.0072(0.0030) Grad: 18066.6094  LR: 0.000011  \n","Epoch: [3][3600/5700] Elapsed 14m 26s (remain 8m 24s) Loss: 0.0001(0.0030) Grad: 199.4168  LR: 0.000011  \n","Epoch: [3][3700/5700] Elapsed 14m 50s (remain 8m 0s) Loss: 0.0002(0.0030) Grad: 1023.3557  LR: 0.000010  \n","Epoch: [3][3800/5700] Elapsed 15m 13s (remain 7m 36s) Loss: 0.0000(0.0030) Grad: 17.8392  LR: 0.000010  \n","Epoch: [3][3900/5700] Elapsed 15m 37s (remain 7m 12s) Loss: 0.0000(0.0030) Grad: 55.0583  LR: 0.000010  \n","Epoch: [3][4000/5700] Elapsed 16m 1s (remain 6m 48s) Loss: 0.0000(0.0030) Grad: 6.0870  LR: 0.000010  \n","Epoch: [3][4100/5700] Elapsed 16m 25s (remain 6m 24s) Loss: 0.0000(0.0030) Grad: 9.9370  LR: 0.000010  \n","Epoch: [3][4200/5700] Elapsed 16m 49s (remain 6m 0s) Loss: 0.0008(0.0030) Grad: 3030.8972  LR: 0.000010  \n","Epoch: [3][4300/5700] Elapsed 17m 13s (remain 5m 36s) Loss: 0.0000(0.0030) Grad: 12.4965  LR: 0.000010  \n","Epoch: [3][4400/5700] Elapsed 17m 37s (remain 5m 12s) Loss: 0.0002(0.0030) Grad: 3140.2791  LR: 0.000010  \n","Epoch: [3][4500/5700] Elapsed 18m 1s (remain 4m 48s) Loss: 0.0013(0.0030) Grad: 3214.4749  LR: 0.000010  \n","Epoch: [3][4600/5700] Elapsed 18m 25s (remain 4m 23s) Loss: 0.0000(0.0030) Grad: 24.7902  LR: 0.000010  \n","Epoch: [3][4700/5700] Elapsed 18m 48s (remain 3m 59s) Loss: 0.0034(0.0030) Grad: 9151.2041  LR: 0.000010  \n","Epoch: [3][4800/5700] Elapsed 19m 12s (remain 3m 35s) Loss: 0.0004(0.0030) Grad: 5969.2192  LR: 0.000010  \n","Epoch: [3][4900/5700] Elapsed 19m 36s (remain 3m 11s) Loss: 0.0025(0.0030) Grad: 11286.4775  LR: 0.000010  \n","Epoch: [3][5000/5700] Elapsed 20m 0s (remain 2m 47s) Loss: 0.0083(0.0030) Grad: 8601.1992  LR: 0.000009  \n","Epoch: [3][5100/5700] Elapsed 20m 24s (remain 2m 23s) Loss: 0.0001(0.0030) Grad: 207.8139  LR: 0.000009  \n","Epoch: [3][5200/5700] Elapsed 20m 48s (remain 1m 59s) Loss: 0.0022(0.0030) Grad: 8805.7197  LR: 0.000009  \n","Epoch: [3][5300/5700] Elapsed 21m 12s (remain 1m 35s) Loss: 0.0050(0.0030) Grad: 8486.4160  LR: 0.000009  \n","Epoch: [3][5400/5700] Elapsed 21m 36s (remain 1m 11s) Loss: 0.0058(0.0030) Grad: 8045.9609  LR: 0.000009  \n","Epoch: [3][5500/5700] Elapsed 21m 59s (remain 0m 47s) Loss: 0.0000(0.0030) Grad: 436.2464  LR: 0.000009  \n","Epoch: [3][5600/5700] Elapsed 22m 23s (remain 0m 23s) Loss: 0.0002(0.0030) Grad: 879.8999  LR: 0.000009  \n","Epoch: [3][5699/5700] Elapsed 22m 47s (remain 0m 0s) Loss: 0.0008(0.0030) Grad: 1812.8954  LR: 0.000009  \n","EVAL: [0/1450] Elapsed 0m 0s (remain 10m 56s) Loss: 0.0050(0.0050) \n","EVAL: [100/1450] Elapsed 0m 12s (remain 2m 45s) Loss: 0.0001(0.0025) \n","EVAL: [200/1450] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0013(0.0038) \n","EVAL: [300/1450] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0052(0.0047) \n","EVAL: [400/1450] Elapsed 0m 48s (remain 2m 7s) Loss: 0.0070(0.0049) \n","EVAL: [500/1450] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0000(0.0046) \n","EVAL: [600/1450] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0001(0.0043) \n","EVAL: [700/1450] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0003(0.0043) \n","EVAL: [800/1450] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0764(0.0048) \n","EVAL: [900/1450] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0020(0.0050) \n","EVAL: [1000/1450] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0123(0.0048) \n","EVAL: [1100/1450] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0000(0.0047) \n","EVAL: [1200/1450] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0114(0.0047) \n","EVAL: [1300/1450] Elapsed 2m 36s (remain 0m 17s) Loss: 0.0000(0.0045) \n","EVAL: [1400/1450] Elapsed 2m 48s (remain 0m 5s) Loss: 0.0000(0.0043) \n","EVAL: [1449/1450] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0042) \n","Epoch 3 - avg_train_loss: 0.0030  avg_val_loss: 0.0042  time: 1547s\n","Epoch 3 - Score: 0.8746\n","Epoch 3 - Save Best Score: 0.8746 Model\n","Epoch: [4][0/5700] Elapsed 0m 0s (remain 54m 40s) Loss: 0.0000(0.0000) Grad: 32.4729  LR: 0.000009  \n","Epoch: [4][100/5700] Elapsed 0m 28s (remain 26m 0s) Loss: 0.0000(0.0023) Grad: 154.4239  LR: 0.000009  \n","Epoch: [4][200/5700] Elapsed 0m 53s (remain 24m 21s) Loss: 0.0000(0.0031) Grad: 67.9138  LR: 0.000009  \n","Epoch: [4][300/5700] Elapsed 1m 17s (remain 23m 6s) Loss: 0.0824(0.0031) Grad: 45350.6562  LR: 0.000009  \n","Epoch: [4][400/5700] Elapsed 1m 41s (remain 22m 17s) Loss: 0.0001(0.0029) Grad: 182.4862  LR: 0.000009  \n","Epoch: [4][500/5700] Elapsed 2m 5s (remain 21m 37s) Loss: 0.0003(0.0026) Grad: 845.2471  LR: 0.000008  \n","Epoch: [4][600/5700] Elapsed 2m 28s (remain 21m 3s) Loss: 0.0001(0.0024) Grad: 164.9302  LR: 0.000008  \n","Epoch: [4][700/5700] Elapsed 2m 52s (remain 20m 33s) Loss: 0.0021(0.0023) Grad: 5072.5405  LR: 0.000008  \n","Epoch: [4][800/5700] Elapsed 3m 16s (remain 20m 3s) Loss: 0.0000(0.0022) Grad: 3.9318  LR: 0.000008  \n","Epoch: [4][900/5700] Elapsed 3m 40s (remain 19m 35s) Loss: 0.0012(0.0022) Grad: 7123.0073  LR: 0.000008  \n","Epoch: [4][1000/5700] Elapsed 4m 4s (remain 19m 9s) Loss: 0.0053(0.0022) Grad: 7260.4771  LR: 0.000008  \n","Epoch: [4][1100/5700] Elapsed 4m 28s (remain 18m 42s) Loss: 0.0000(0.0024) Grad: 30.6681  LR: 0.000008  \n","Epoch: [4][1200/5700] Elapsed 4m 52s (remain 18m 16s) Loss: 0.0000(0.0024) Grad: 25.1589  LR: 0.000008  \n","Epoch: [4][1300/5700] Elapsed 5m 16s (remain 17m 50s) Loss: 0.0000(0.0024) Grad: 22.0153  LR: 0.000008  \n","Epoch: [4][1400/5700] Elapsed 5m 40s (remain 17m 25s) Loss: 0.0036(0.0024) Grad: 10762.9736  LR: 0.000008  \n","Epoch: [4][1500/5700] Elapsed 6m 4s (remain 16m 59s) Loss: 0.0001(0.0025) Grad: 605.9354  LR: 0.000008  \n","Epoch: [4][1600/5700] Elapsed 6m 28s (remain 16m 34s) Loss: 0.0000(0.0025) Grad: 132.1197  LR: 0.000008  \n","Epoch: [4][1700/5700] Elapsed 6m 52s (remain 16m 9s) Loss: 0.0004(0.0025) Grad: 1942.3156  LR: 0.000008  \n","Epoch: [4][1800/5700] Elapsed 7m 16s (remain 15m 44s) Loss: 0.0078(0.0024) Grad: 13624.7168  LR: 0.000007  \n","Epoch: [4][1900/5700] Elapsed 7m 40s (remain 15m 19s) Loss: 0.0274(0.0024) Grad: 91660.2109  LR: 0.000007  \n","Epoch: [4][2000/5700] Elapsed 8m 4s (remain 14m 54s) Loss: 0.0082(0.0024) Grad: 16025.0371  LR: 0.000007  \n","Epoch: [4][2100/5700] Elapsed 8m 27s (remain 14m 30s) Loss: 0.0000(0.0025) Grad: 33.0004  LR: 0.000007  \n","Epoch: [4][2200/5700] Elapsed 8m 51s (remain 14m 5s) Loss: 0.0018(0.0025) Grad: 2558.2769  LR: 0.000007  \n","Epoch: [4][2300/5700] Elapsed 9m 15s (remain 13m 40s) Loss: 0.0007(0.0025) Grad: 1945.9084  LR: 0.000007  \n","Epoch: [4][2400/5700] Elapsed 9m 39s (remain 13m 16s) Loss: 0.0002(0.0024) Grad: 3672.7759  LR: 0.000007  \n","Epoch: [4][2500/5700] Elapsed 10m 3s (remain 12m 51s) Loss: 0.0305(0.0024) Grad: 78752.8906  LR: 0.000007  \n","Epoch: [4][2600/5700] Elapsed 10m 27s (remain 12m 27s) Loss: 0.0000(0.0024) Grad: 14.4375  LR: 0.000007  \n","Epoch: [4][2700/5700] Elapsed 10m 51s (remain 12m 3s) Loss: 0.0000(0.0025) Grad: 13.0764  LR: 0.000007  \n","Epoch: [4][2800/5700] Elapsed 11m 15s (remain 11m 38s) Loss: 0.0001(0.0025) Grad: 655.6866  LR: 0.000007  \n","Epoch: [4][2900/5700] Elapsed 11m 39s (remain 11m 14s) Loss: 0.0000(0.0025) Grad: 13.5365  LR: 0.000007  \n","Epoch: [4][3000/5700] Elapsed 12m 3s (remain 10m 50s) Loss: 0.0000(0.0025) Grad: 27.2260  LR: 0.000007  \n","Epoch: [4][3100/5700] Elapsed 12m 26s (remain 10m 26s) Loss: 0.0000(0.0025) Grad: 54.5991  LR: 0.000006  \n","Epoch: [4][3200/5700] Elapsed 12m 50s (remain 10m 1s) Loss: 0.0000(0.0025) Grad: 8.6986  LR: 0.000006  \n","Epoch: [4][3300/5700] Elapsed 13m 14s (remain 9m 37s) Loss: 0.0033(0.0025) Grad: 22703.6758  LR: 0.000006  \n","Epoch: [4][3400/5700] Elapsed 13m 38s (remain 9m 13s) Loss: 0.0179(0.0025) Grad: 232426.4531  LR: 0.000006  \n","Epoch: [4][3500/5700] Elapsed 14m 2s (remain 8m 49s) Loss: 0.0001(0.0025) Grad: 672.4807  LR: 0.000006  \n","Epoch: [4][3600/5700] Elapsed 14m 26s (remain 8m 24s) Loss: 0.0000(0.0025) Grad: 10.3785  LR: 0.000006  \n","Epoch: [4][3700/5700] Elapsed 14m 50s (remain 8m 0s) Loss: 0.0000(0.0025) Grad: 88.2260  LR: 0.000006  \n","Epoch: [4][3800/5700] Elapsed 15m 14s (remain 7m 36s) Loss: 0.0082(0.0025) Grad: 33847.2617  LR: 0.000006  \n","Epoch: [4][3900/5700] Elapsed 15m 37s (remain 7m 12s) Loss: 0.0142(0.0025) Grad: 20983.3535  LR: 0.000006  \n","Epoch: [4][4000/5700] Elapsed 16m 1s (remain 6m 48s) Loss: 0.0003(0.0025) Grad: 4966.4165  LR: 0.000006  \n","Epoch: [4][4100/5700] Elapsed 16m 25s (remain 6m 24s) Loss: 0.0000(0.0025) Grad: 27.2419  LR: 0.000006  \n","Epoch: [4][4200/5700] Elapsed 16m 49s (remain 6m 0s) Loss: 0.0024(0.0025) Grad: 29236.8965  LR: 0.000006  \n","Epoch: [4][4300/5700] Elapsed 17m 13s (remain 5m 36s) Loss: 0.0000(0.0025) Grad: 17.3409  LR: 0.000006  \n","Epoch: [4][4400/5700] Elapsed 17m 37s (remain 5m 12s) Loss: 0.0000(0.0025) Grad: 4.7790  LR: 0.000005  \n","Epoch: [4][4500/5700] Elapsed 18m 1s (remain 4m 48s) Loss: 0.0001(0.0025) Grad: 774.7473  LR: 0.000005  \n","Epoch: [4][4600/5700] Elapsed 18m 25s (remain 4m 24s) Loss: 0.0000(0.0025) Grad: 6.1363  LR: 0.000005  \n","Epoch: [4][4700/5700] Elapsed 18m 49s (remain 3m 59s) Loss: 0.0083(0.0025) Grad: 13961.8604  LR: 0.000005  \n","Epoch: [4][4800/5700] Elapsed 19m 13s (remain 3m 35s) Loss: 0.0000(0.0025) Grad: 140.2156  LR: 0.000005  \n","Epoch: [4][4900/5700] Elapsed 19m 37s (remain 3m 11s) Loss: 0.0000(0.0024) Grad: 42.6758  LR: 0.000005  \n","Epoch: [4][5000/5700] Elapsed 20m 0s (remain 2m 47s) Loss: 0.0004(0.0025) Grad: 1571.6980  LR: 0.000005  \n","Epoch: [4][5100/5700] Elapsed 20m 24s (remain 2m 23s) Loss: 0.0040(0.0025) Grad: 31626.6562  LR: 0.000005  \n","Epoch: [4][5200/5700] Elapsed 20m 48s (remain 1m 59s) Loss: 0.0000(0.0025) Grad: 3.7900  LR: 0.000005  \n","Epoch: [4][5300/5700] Elapsed 21m 12s (remain 1m 35s) Loss: 0.0000(0.0025) Grad: 36.9960  LR: 0.000005  \n","Epoch: [4][5400/5700] Elapsed 21m 36s (remain 1m 11s) Loss: 0.0000(0.0025) Grad: 367.6210  LR: 0.000005  \n","Epoch: [4][5500/5700] Elapsed 22m 0s (remain 0m 47s) Loss: 0.0001(0.0025) Grad: 3778.7947  LR: 0.000005  \n","Epoch: [4][5600/5700] Elapsed 22m 24s (remain 0m 23s) Loss: 0.0261(0.0025) Grad: 28185.3516  LR: 0.000005  \n","Epoch: [4][5699/5700] Elapsed 22m 48s (remain 0m 0s) Loss: 0.0000(0.0025) Grad: 999.8439  LR: 0.000004  \n","EVAL: [0/1450] Elapsed 0m 0s (remain 9m 37s) Loss: 0.0067(0.0067) \n","EVAL: [100/1450] Elapsed 0m 12s (remain 2m 44s) Loss: 0.0001(0.0028) \n","EVAL: [200/1450] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0012(0.0038) \n","EVAL: [300/1450] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0065(0.0049) \n","EVAL: [400/1450] Elapsed 0m 48s (remain 2m 6s) Loss: 0.0030(0.0052) \n","EVAL: [500/1450] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0000(0.0048) \n","EVAL: [600/1450] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0045) \n","EVAL: [700/1450] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0003(0.0045) \n","EVAL: [800/1450] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0691(0.0049) \n","EVAL: [900/1450] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0030(0.0051) \n","EVAL: [1000/1450] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0118(0.0048) \n","EVAL: [1100/1450] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0000(0.0048) \n","EVAL: [1200/1450] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0148(0.0047) \n","EVAL: [1300/1450] Elapsed 2m 36s (remain 0m 17s) Loss: 0.0000(0.0045) \n","EVAL: [1400/1450] Elapsed 2m 48s (remain 0m 5s) Loss: 0.0000(0.0043) \n","EVAL: [1449/1450] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0043) \n","Epoch 4 - avg_train_loss: 0.0025  avg_val_loss: 0.0043  time: 1547s\n","Epoch 4 - Score: 0.8804\n","Epoch 4 - Save Best Score: 0.8804 Model\n","Epoch: [5][0/5700] Elapsed 0m 0s (remain 59m 36s) Loss: 0.0000(0.0000) Grad: 35.3339  LR: 0.000004  \n","Epoch: [5][100/5700] Elapsed 0m 28s (remain 26m 21s) Loss: 0.0002(0.0023) Grad: 745.2178  LR: 0.000004  \n","Epoch: [5][200/5700] Elapsed 0m 53s (remain 24m 29s) Loss: 0.0000(0.0023) Grad: 30.3017  LR: 0.000004  \n","Epoch: [5][300/5700] Elapsed 1m 17s (remain 23m 13s) Loss: 0.0006(0.0022) Grad: 28597.1250  LR: 0.000004  \n","Epoch: [5][400/5700] Elapsed 1m 41s (remain 22m 24s) Loss: 0.0000(0.0021) Grad: 45.3861  LR: 0.000004  \n","Epoch: [5][500/5700] Elapsed 2m 5s (remain 21m 44s) Loss: 0.0001(0.0024) Grad: 274.5362  LR: 0.000004  \n","Epoch: [5][600/5700] Elapsed 2m 29s (remain 21m 10s) Loss: 0.0023(0.0024) Grad: 17605.5684  LR: 0.000004  \n","Epoch: [5][700/5700] Elapsed 2m 53s (remain 20m 38s) Loss: 0.0000(0.0023) Grad: 116.7853  LR: 0.000004  \n","Epoch: [5][800/5700] Elapsed 3m 17s (remain 20m 8s) Loss: 0.0000(0.0023) Grad: 37.9164  LR: 0.000004  \n","Epoch: [5][900/5700] Elapsed 3m 41s (remain 19m 40s) Loss: 0.0002(0.0023) Grad: 10707.1406  LR: 0.000004  \n","Epoch: [5][1000/5700] Elapsed 4m 5s (remain 19m 14s) Loss: 0.0000(0.0023) Grad: 230.1328  LR: 0.000004  \n","Epoch: [5][1100/5700] Elapsed 4m 29s (remain 18m 47s) Loss: 0.0099(0.0022) Grad: 23757.5098  LR: 0.000004  \n","Epoch: [5][1200/5700] Elapsed 4m 53s (remain 18m 21s) Loss: 0.0229(0.0022) Grad: 42517.6445  LR: 0.000004  \n","Epoch: [5][1300/5700] Elapsed 5m 17s (remain 17m 54s) Loss: 0.0058(0.0022) Grad: 15548.5664  LR: 0.000003  \n","Epoch: [5][1400/5700] Elapsed 5m 41s (remain 17m 29s) Loss: 0.0001(0.0022) Grad: 710.1728  LR: 0.000003  \n","Epoch: [5][1500/5700] Elapsed 6m 5s (remain 17m 3s) Loss: 0.0002(0.0021) Grad: 1309.4899  LR: 0.000003  \n","Epoch: [5][1600/5700] Elapsed 6m 30s (remain 16m 38s) Loss: 0.0001(0.0021) Grad: 639.5865  LR: 0.000003  \n","Epoch: [5][1700/5700] Elapsed 6m 54s (remain 16m 13s) Loss: 0.0001(0.0021) Grad: 616.7722  LR: 0.000003  \n","Epoch: [5][1800/5700] Elapsed 7m 18s (remain 15m 48s) Loss: 0.0000(0.0021) Grad: 132.6741  LR: 0.000003  \n","Epoch: [5][1900/5700] Elapsed 7m 41s (remain 15m 23s) Loss: 0.0000(0.0021) Grad: 4.1930  LR: 0.000003  \n","Epoch: [5][2000/5700] Elapsed 8m 5s (remain 14m 58s) Loss: 0.0000(0.0021) Grad: 19.1663  LR: 0.000003  \n","Epoch: [5][2100/5700] Elapsed 8m 29s (remain 14m 33s) Loss: 0.0000(0.0021) Grad: 73.6592  LR: 0.000003  \n","Epoch: [5][2200/5700] Elapsed 8m 53s (remain 14m 8s) Loss: 0.0011(0.0021) Grad: 11821.1973  LR: 0.000003  \n","Epoch: [5][2300/5700] Elapsed 9m 17s (remain 13m 43s) Loss: 0.0007(0.0021) Grad: 11459.6602  LR: 0.000003  \n","Epoch: [5][2400/5700] Elapsed 9m 41s (remain 13m 18s) Loss: 0.0000(0.0020) Grad: 70.4223  LR: 0.000003  \n","Epoch: [5][2500/5700] Elapsed 10m 5s (remain 12m 54s) Loss: 0.0029(0.0020) Grad: 17108.6328  LR: 0.000002  \n","Epoch: [5][2600/5700] Elapsed 10m 29s (remain 12m 29s) Loss: 0.0000(0.0020) Grad: 32.4413  LR: 0.000002  \n","Epoch: [5][2700/5700] Elapsed 10m 53s (remain 12m 5s) Loss: 0.0000(0.0020) Grad: 87.1887  LR: 0.000002  \n","Epoch: [5][2800/5700] Elapsed 11m 17s (remain 11m 40s) Loss: 0.0000(0.0021) Grad: 110.6130  LR: 0.000002  \n","Epoch: [5][2900/5700] Elapsed 11m 40s (remain 11m 16s) Loss: 0.0000(0.0020) Grad: 251.6621  LR: 0.000002  \n","Epoch: [5][3000/5700] Elapsed 12m 4s (remain 10m 51s) Loss: 0.0001(0.0021) Grad: 900.0325  LR: 0.000002  \n","Epoch: [5][3100/5700] Elapsed 12m 28s (remain 10m 27s) Loss: 0.0000(0.0021) Grad: 87.6273  LR: 0.000002  \n","Epoch: [5][3200/5700] Elapsed 12m 52s (remain 10m 3s) Loss: 0.0034(0.0021) Grad: 20033.5625  LR: 0.000002  \n","Epoch: [5][3300/5700] Elapsed 13m 16s (remain 9m 38s) Loss: 0.0000(0.0021) Grad: 4.1633  LR: 0.000002  \n","Epoch: [5][3400/5700] Elapsed 13m 40s (remain 9m 14s) Loss: 0.0031(0.0022) Grad: 7992.0347  LR: 0.000002  \n","Epoch: [5][3500/5700] Elapsed 14m 4s (remain 8m 50s) Loss: 0.0036(0.0021) Grad: 11743.5010  LR: 0.000002  \n","Epoch: [5][3600/5700] Elapsed 14m 28s (remain 8m 26s) Loss: 0.0000(0.0021) Grad: 4.4057  LR: 0.000002  \n","Epoch: [5][3700/5700] Elapsed 14m 52s (remain 8m 1s) Loss: 0.0000(0.0021) Grad: 47.8613  LR: 0.000002  \n","Epoch: [5][3800/5700] Elapsed 15m 16s (remain 7m 37s) Loss: 0.0112(0.0021) Grad: 27776.7891  LR: 0.000001  \n","Epoch: [5][3900/5700] Elapsed 15m 40s (remain 7m 13s) Loss: 0.0000(0.0021) Grad: 258.4944  LR: 0.000001  \n","Epoch: [5][4000/5700] Elapsed 16m 4s (remain 6m 49s) Loss: 0.0000(0.0021) Grad: 3.5365  LR: 0.000001  \n","Epoch: [5][4100/5700] Elapsed 16m 28s (remain 6m 25s) Loss: 0.0000(0.0021) Grad: 653.6055  LR: 0.000001  \n","Epoch: [5][4200/5700] Elapsed 16m 52s (remain 6m 1s) Loss: 0.0003(0.0021) Grad: 4604.6807  LR: 0.000001  \n","Epoch: [5][4300/5700] Elapsed 17m 16s (remain 5m 37s) Loss: 0.0000(0.0020) Grad: 15.9243  LR: 0.000001  \n","Epoch: [5][4400/5700] Elapsed 17m 40s (remain 5m 13s) Loss: 0.0000(0.0020) Grad: 145.2175  LR: 0.000001  \n","Epoch: [5][4500/5700] Elapsed 18m 4s (remain 4m 48s) Loss: 0.0033(0.0021) Grad: 2077.0835  LR: 0.000001  \n","Epoch: [5][4600/5700] Elapsed 18m 28s (remain 4m 24s) Loss: 0.0022(0.0021) Grad: 15366.1914  LR: 0.000001  \n","Epoch: [5][4700/5700] Elapsed 18m 52s (remain 4m 0s) Loss: 0.0000(0.0021) Grad: 286.3563  LR: 0.000001  \n","Epoch: [5][4800/5700] Elapsed 19m 16s (remain 3m 36s) Loss: 0.0048(0.0021) Grad: 101377.1484  LR: 0.000001  \n","Epoch: [5][4900/5700] Elapsed 19m 40s (remain 3m 12s) Loss: 0.0000(0.0021) Grad: 3.2950  LR: 0.000001  \n","Epoch: [5][5000/5700] Elapsed 20m 4s (remain 2m 48s) Loss: 0.0000(0.0021) Grad: 174.0879  LR: 0.000001  \n","Epoch: [5][5100/5700] Elapsed 20m 28s (remain 2m 24s) Loss: 0.0045(0.0020) Grad: 6684.9985  LR: 0.000000  \n","Epoch: [5][5200/5700] Elapsed 20m 52s (remain 2m 0s) Loss: 0.0080(0.0021) Grad: 12084.3096  LR: 0.000000  \n","Epoch: [5][5300/5700] Elapsed 21m 16s (remain 1m 36s) Loss: 0.0000(0.0021) Grad: 35.4562  LR: 0.000000  \n","Epoch: [5][5400/5700] Elapsed 21m 40s (remain 1m 11s) Loss: 0.0000(0.0021) Grad: 104.8420  LR: 0.000000  \n","Epoch: [5][5500/5700] Elapsed 22m 4s (remain 0m 47s) Loss: 0.0000(0.0021) Grad: 3.5862  LR: 0.000000  \n","Epoch: [5][5600/5700] Elapsed 22m 28s (remain 0m 23s) Loss: 0.0000(0.0021) Grad: 122.3589  LR: 0.000000  \n","Epoch: [5][5699/5700] Elapsed 22m 52s (remain 0m 0s) Loss: 0.0004(0.0021) Grad: 4667.3184  LR: 0.000000  \n","EVAL: [0/1450] Elapsed 0m 0s (remain 9m 34s) Loss: 0.0055(0.0055) \n","EVAL: [100/1450] Elapsed 0m 12s (remain 2m 43s) Loss: 0.0001(0.0034) \n","EVAL: [200/1450] Elapsed 0m 24s (remain 2m 31s) Loss: 0.0013(0.0045) \n","EVAL: [300/1450] Elapsed 0m 36s (remain 2m 19s) Loss: 0.0072(0.0056) \n","EVAL: [400/1450] Elapsed 0m 48s (remain 2m 6s) Loss: 0.0029(0.0059) \n","EVAL: [500/1450] Elapsed 1m 0s (remain 1m 54s) Loss: 0.0000(0.0054) \n","EVAL: [600/1450] Elapsed 1m 12s (remain 1m 42s) Loss: 0.0000(0.0050) \n","EVAL: [700/1450] Elapsed 1m 24s (remain 1m 30s) Loss: 0.0021(0.0050) \n","EVAL: [800/1450] Elapsed 1m 36s (remain 1m 18s) Loss: 0.0565(0.0056) \n","EVAL: [900/1450] Elapsed 1m 48s (remain 1m 6s) Loss: 0.0079(0.0058) \n","EVAL: [1000/1450] Elapsed 2m 0s (remain 0m 54s) Loss: 0.0143(0.0055) \n","EVAL: [1100/1450] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0000(0.0055) \n","EVAL: [1200/1450] Elapsed 2m 24s (remain 0m 30s) Loss: 0.0147(0.0054) \n","EVAL: [1300/1450] Elapsed 2m 36s (remain 0m 17s) Loss: 0.0000(0.0052) \n","EVAL: [1400/1450] Elapsed 2m 48s (remain 0m 5s) Loss: 0.0000(0.0050) \n","EVAL: [1449/1450] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0049) \n","Epoch 5 - avg_train_loss: 0.0021  avg_val_loss: 0.0049  time: 1551s\n","Epoch 5 - Score: 0.8832\n","Epoch 5 - Save Best Score: 0.8832 Model\n","Best thres: 0.5, Score: 0.8825\n","Best thres: 0.43671874999999993, Score: 0.8829\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc820db4c20404ba98ee79396b5b363"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"335266df983d42e5ad63eecd50b18672"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35696f212e1a40a99dc7b90f1d880aac"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7170281bab5e4e50a7b33a19b56aee66"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57377a103924888b18915e9080df51a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27d59314703f45b49d2449929c9fe6d0"}},"metadata":{}}],"source":["if __name__ == \"__main__\":\n","    main()"],"id":"local-thesis"}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp042.ipynb","provenance":[{"file_id":"1IGrH_NiE5GYcbPXtAUAEG0WD0twl5S9A","timestamp":1647349066902}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0399a39c415444dc849bc2af68c994bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8820fa4608e8494fb1eb79aa2d92e62b","placeholder":"​","style":"IPY_MODEL_838177e0e1a44fa8acf383398d7989ae","value":" 42146/42146 [00:36&lt;00:00, 1910.08it/s]"}},"0bc0430a9bd34eb68fa8bfe9d67f816e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcdee0f86ee44521ada35550f53cf8b4","placeholder":"​","style":"IPY_MODEL_2aafe85d44784db69061af1a3139e3fc","value":"100%"}},"0db5c6f7136546abbc3e6fd2b64e1935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aba16da8f13419f92e351a0a63cce96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1abb815356f9446193fa316f1a76ffe8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"283d3b0fa75a47c5b361e49d8fee8a0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aafe85d44784db69061af1a3139e3fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2f4c5b0da14c85b45872bb1d70e2f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_789018951c5a44cab8e88c13aea8597b","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1aba16da8f13419f92e351a0a63cce96","value":143}},"3a325138c0d64b8e9d08db5250cf25e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62b527b8654e48819e8987e042be0a61":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72a583da875e4453aaf69b0c395a27a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1abb815356f9446193fa316f1a76ffe8","placeholder":"​","style":"IPY_MODEL_72b2634c24434f3ab6a1f3c4f1645852","value":" 143/143 [00:00&lt;00:00, 2167.38it/s]"}},"72b2634c24434f3ab6a1f3c4f1645852":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"789018951c5a44cab8e88c13aea8597b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"838177e0e1a44fa8acf383398d7989ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8820fa4608e8494fb1eb79aa2d92e62b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c1c08f024594e2f8e62af5973101472":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff284eb9d326463dbcd0c13233604d01","placeholder":"​","style":"IPY_MODEL_0db5c6f7136546abbc3e6fd2b64e1935","value":"100%"}},"a068a967d95945cab627216b77c83cda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0bc0430a9bd34eb68fa8bfe9d67f816e","IPY_MODEL_d121bf9ada4f4c128b16df1c1ac6cefe","IPY_MODEL_0399a39c415444dc849bc2af68c994bc"],"layout":"IPY_MODEL_ec3ae1c9fd86497c832e0f370c439a60"}},"b442b1c4458c49deb830c280d7f57b55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c1c08f024594e2f8e62af5973101472","IPY_MODEL_2b2f4c5b0da14c85b45872bb1d70e2f6","IPY_MODEL_72a583da875e4453aaf69b0c395a27a9"],"layout":"IPY_MODEL_283d3b0fa75a47c5b361e49d8fee8a0d"}},"d121bf9ada4f4c128b16df1c1ac6cefe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62b527b8654e48819e8987e042be0a61","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a325138c0d64b8e9d08db5250cf25e4","value":42146}},"dcdee0f86ee44521ada35550f53cf8b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec3ae1c9fd86497c832e0f370c439a60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff284eb9d326463dbcd0c13233604d01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fc820db4c20404ba98ee79396b5b363":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f191def88d74437900b7ce926e113ad","IPY_MODEL_3a841058dd2147dfaf7dad9f5e83fc77","IPY_MODEL_59e0df25eb5447a191edc8878f3d9447"],"layout":"IPY_MODEL_707499c5a22a495f9cd814480c1009a1"}},"3f191def88d74437900b7ce926e113ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a906a29299024c1e853d86bf147495b5","placeholder":"​","style":"IPY_MODEL_e11b0696ad3e4ae584530d42ac45b44b","value":"Downloading: 100%"}},"3a841058dd2147dfaf7dad9f5e83fc77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f47b3673d6724f049090cde9038ff571","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e79157a631a640f4af3377e9823f6493","value":1627284589}},"59e0df25eb5447a191edc8878f3d9447":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c896dcb5fb14a8997eb6e43a9c65d0e","placeholder":"​","style":"IPY_MODEL_b59c6338355e4a619dc2579039d172e5","value":" 1.52G/1.52G [00:32&lt;00:00, 56.2MB/s]"}},"707499c5a22a495f9cd814480c1009a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a906a29299024c1e853d86bf147495b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e11b0696ad3e4ae584530d42ac45b44b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f47b3673d6724f049090cde9038ff571":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e79157a631a640f4af3377e9823f6493":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c896dcb5fb14a8997eb6e43a9c65d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b59c6338355e4a619dc2579039d172e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"335266df983d42e5ad63eecd50b18672":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c02ecf6b54a747eb9db10ada1ed8b3c8","IPY_MODEL_4a6c536580ef4d84bb46d14363fba24d","IPY_MODEL_c08bef1dc00a4718a18583cf7b3f4795"],"layout":"IPY_MODEL_e238f0dbdd504648a4bac20cc6c906b6"}},"c02ecf6b54a747eb9db10ada1ed8b3c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43d0dd24bbb74774acd32c10c4ceb229","placeholder":"​","style":"IPY_MODEL_c5333198d8424c7d855127266f2dc456","value":"100%"}},"4a6c536580ef4d84bb46d14363fba24d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16997f093267472484f47e7e751f876f","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fa54cefe1414a8c90a4b50e48dce3a6","value":3}},"c08bef1dc00a4718a18583cf7b3f4795":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_611387a35e8a4cc9b634b4b4730fc903","placeholder":"​","style":"IPY_MODEL_154aaf74cdb240748892b0dcf954199a","value":" 3/3 [00:01&lt;00:00,  1.63it/s]"}},"e238f0dbdd504648a4bac20cc6c906b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43d0dd24bbb74774acd32c10c4ceb229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5333198d8424c7d855127266f2dc456":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16997f093267472484f47e7e751f876f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa54cefe1414a8c90a4b50e48dce3a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"611387a35e8a4cc9b634b4b4730fc903":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"154aaf74cdb240748892b0dcf954199a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35696f212e1a40a99dc7b90f1d880aac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af76eee3a96e4509b9fb4e5d85bb5447","IPY_MODEL_7d43de8fbfad43cc80fd928799af703b","IPY_MODEL_0e53274a03de4c0cb17a50bb8cdd0456"],"layout":"IPY_MODEL_66eeb3ee376548bfb139cd3b8395a1ff"}},"af76eee3a96e4509b9fb4e5d85bb5447":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_844310b0f9974437b21be474a4f13221","placeholder":"​","style":"IPY_MODEL_e60c7cd8678d46f2a3ad00b3d32585da","value":"100%"}},"7d43de8fbfad43cc80fd928799af703b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30664846d2d441aeab45e6a2700f31ac","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7bbd07ed4734367ab6fbe3548c9d913","value":3}},"0e53274a03de4c0cb17a50bb8cdd0456":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42eae6e871644489827fa7b1cdea551d","placeholder":"​","style":"IPY_MODEL_c944c0fe12564dae98134683fc5d0c2d","value":" 3/3 [00:01&lt;00:00,  1.75it/s]"}},"66eeb3ee376548bfb139cd3b8395a1ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844310b0f9974437b21be474a4f13221":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e60c7cd8678d46f2a3ad00b3d32585da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30664846d2d441aeab45e6a2700f31ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7bbd07ed4734367ab6fbe3548c9d913":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42eae6e871644489827fa7b1cdea551d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c944c0fe12564dae98134683fc5d0c2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7170281bab5e4e50a7b33a19b56aee66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6c6561965b044c19ee5419924422bc8","IPY_MODEL_d9052c48c3ee4359a8d963be6fc7f98d","IPY_MODEL_a89fcdeacc194a56917c2c2ccc3228c1"],"layout":"IPY_MODEL_452d7d9bc5a94e96bd91b5b4dbec3760"}},"c6c6561965b044c19ee5419924422bc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8eb96a8cd934659953a7a154a2732a2","placeholder":"​","style":"IPY_MODEL_bb2ffd8904854588b8fc53a8a4845860","value":"100%"}},"d9052c48c3ee4359a8d963be6fc7f98d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b14372a025aa4d069474d8aab8499693","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59f08270bf734b73b586ff9e3d98fa2a","value":3}},"a89fcdeacc194a56917c2c2ccc3228c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3be8e07394d94ccba9de0a6db92674f8","placeholder":"​","style":"IPY_MODEL_85f364edbf79498fa60543d03a9895d1","value":" 3/3 [00:02&lt;00:00,  1.34it/s]"}},"452d7d9bc5a94e96bd91b5b4dbec3760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8eb96a8cd934659953a7a154a2732a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb2ffd8904854588b8fc53a8a4845860":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b14372a025aa4d069474d8aab8499693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59f08270bf734b73b586ff9e3d98fa2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3be8e07394d94ccba9de0a6db92674f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85f364edbf79498fa60543d03a9895d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d57377a103924888b18915e9080df51a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_425ff7de89704088a80eb1e60790a108","IPY_MODEL_3c437ba94dcd48dd8b9137571e47f4cf","IPY_MODEL_217ef0160bc042f99a0954fb12760c33"],"layout":"IPY_MODEL_06747c463e8346de93cd49b1426d1776"}},"425ff7de89704088a80eb1e60790a108":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e6fd51ccfa647efa31037168fbbb59f","placeholder":"​","style":"IPY_MODEL_507f7d66b75048a7bf791dc00d632978","value":"100%"}},"3c437ba94dcd48dd8b9137571e47f4cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c085f947e824413b97fe56be4775785c","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04c8b1ad279d48d285d2e79357bb16fe","value":3}},"217ef0160bc042f99a0954fb12760c33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_213e0af4ea0442f78a5e2f3620bcf8be","placeholder":"​","style":"IPY_MODEL_346ae89d47954f7eb8a0db84621de7fd","value":" 3/3 [00:01&lt;00:00,  1.69it/s]"}},"06747c463e8346de93cd49b1426d1776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e6fd51ccfa647efa31037168fbbb59f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507f7d66b75048a7bf791dc00d632978":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c085f947e824413b97fe56be4775785c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04c8b1ad279d48d285d2e79357bb16fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"213e0af4ea0442f78a5e2f3620bcf8be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"346ae89d47954f7eb8a0db84621de7fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27d59314703f45b49d2449929c9fe6d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b648b6374274930b3f284e38bc3b1a0","IPY_MODEL_ecfe056930a1409fa771fbfacfd5e657","IPY_MODEL_ffa66c875f7147ebbc93545f3833decf"],"layout":"IPY_MODEL_82494331726b4d00afdc0d74f03da57e"}},"9b648b6374274930b3f284e38bc3b1a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04d710e17b66405d936d87a73c1bf4d7","placeholder":"​","style":"IPY_MODEL_ecdfe18de07c486494a870c92da04a75","value":"100%"}},"ecfe056930a1409fa771fbfacfd5e657":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf962fb724bd46a7a8d59fc484c51caf","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_572b08467e884783a75fe2f78a953c1d","value":3}},"ffa66c875f7147ebbc93545f3833decf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f316cabf2164a3389a687ea4744e3be","placeholder":"​","style":"IPY_MODEL_039f43676fcc468fbaeb92e98e3f912d","value":" 3/3 [00:02&lt;00:00,  2.42it/s]"}},"82494331726b4d00afdc0d74f03da57e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d710e17b66405d936d87a73c1bf4d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecdfe18de07c486494a870c92da04a75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf962fb724bd46a7a8d59fc484c51caf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"572b08467e884783a75fe2f78a953c1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f316cabf2164a3389a687ea4744e3be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"039f43676fcc468fbaeb92e98e3f912d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}