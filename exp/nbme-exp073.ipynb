{"cells":[{"cell_type":"markdown","metadata":{"id":"xXLg6vRyDD7j"},"source":["# Check device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":877,"status":"ok","timestamp":1649127866519,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"FBD1QhJFCQl-","outputId":"6f3d3fa9-efc8-4bb7-89af-c43199906c29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Apr  5 03:04:25 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["######################################################\n","\n","# Check device\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"rQoT8i9JDBTE"},"source":["# Package Install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17951,"status":"ok","timestamp":1649127885224,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"K4MqdKKCCkx0","outputId":"42197404-b579-4333-f019-2b8031e98dce"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 311 kB 4.3 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 66.2 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 6.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 58.8 MB/s \n","\u001b[K     |████████████████████████████████| 136 kB 74.7 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 65.2 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 73.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 4.2 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 4.1 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 56.8 MB/s \n","\u001b[K     |████████████████████████████████| 6.5 MB 55.5 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 70.3 MB/s \n","\u001b[?25h"]}],"source":["# ====================================================\n","# Install\n","# ====================================================\n","\n","!pip install -q datasets==1.18.3\n","!pip install -q sentencepiece==0.1.96\n","!pip install -q transformers==4.16.2"]},{"cell_type":"markdown","metadata":{"id":"bFFR897MDASq"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Yzuy2OlC60E"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    env=\"colab\"\n","    debug=False\n","    apex=True\n","    exp_name=\"nbme-exp073\"\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=15\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=1\n","    fc_dropout=0.2\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=8\n","    max_grad_norm=1000\n","    # MLM setting\n","    mlm_probability=0.15\n","    max_seq_length=512\n","    seed=42\n","    n_fold=1\n","    trn_fold=[0]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29709,"status":"ok","timestamp":1649127914915,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"lyzct7eRCwjh","outputId":"3f891f06-b4d9-46dd-c7ba-14c6aad71c82"},"outputs":[{"name":"stdout","output_type":"stream","text":["colab\n","Mounted at /content/drive\n"]}],"source":["# ====================================================\n","# Define path\n","# ====================================================\n","import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    INPUT_DIR = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    OUTPUT_DIR = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not OUTPUT_DIR.exists():\n","        OUTPUT_DIR.mkdir()"]},{"cell_type":"markdown","metadata":{"id":"nSxdKeDkEHpo"},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1nhqvzy8Eax"},"outputs":[],"source":["# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n","# This must be done before importing transformers\n","import shutil\n","from pathlib import Path\n","\n","if CFG.env == \"colab\":\n","    input_dir = Path(\"./drive/MyDrive/00.kaggle/input/deberta-v2-3-fast-tokenizer\")\n","    transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","else:\n","    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n","    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)\n","    \n","    \n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5240,"status":"ok","timestamp":1649127930119,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"1slPlvh0D4Eg","outputId":"a9014a45-c798-4940-9e6a-1e192597529c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForMaskedLM\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers.modeling_outputs import MaskedLMOutput\n","from transformers import DataCollatorForLanguageModeling\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"ja9YYx88Ft73"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9nzv90GFhSg"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ===================================================\n","def get_logger(filename=OUTPUT_DIR/'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"markdown","metadata":{"id":"1lQulrBSFvS3"},"source":["# Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRlCCUEqEZPh"},"outputs":[],"source":["######################################################\n","\n","# Trainer\n","def trainer(model, data_loader, optimizer, scheduler, CFG):\n","    model.train()\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = []\n","\n","    optimizer.zero_grad()\n","\n","    for idx, batch in enumerate(data_loader):\n","        for k, v in batch.items():\n","            batch[k] = v.to(device, dtype=torch.long)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            outputs = model(**batch)\n","\n","        loss = outputs.loss\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (idx + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            CFG.global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        \n","        losses.append(loss.detach().cpu().item())\n","\n","        # if (CFG.global_step % CFG.save_step) == 0:\n","        #     LOGGER.info(\n","        #         \"Epoch {} Step {}: Train Loss {:.4f}, elapsed {:.4f}s\".format(\n","        #             CFG.epoch + 1, CFG.global_step, np.mean(losses), time.time() - start)\n","        #         )\n","        #     torch.save(\n","        #         model.state_dict(),\n","        #         OUTPUT_DIR + '{}-mlm-step-{}.bin'.format(\n","        #             CFG.model.replace('/', '-'),\n","        #             CFG.global_step))\n","        \n","        if idx % 500 == 0 or idx == (len(data_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss:.4f} '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, idx, len(data_loader), \n","                          remain=timeSince(start, float(idx+1)/len(data_loader)),\n","                          loss=np.mean(losses),\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","    \n","    return np.mean(losses)"]},{"cell_type":"markdown","metadata":{"id":"3PH7O4VlFw-N"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KU9B4j-YLNzI"},"outputs":[],"source":["def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","         'lr': encoder_lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","         'lr': encoder_lr, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","         'lr': decoder_lr, 'weight_decay': 0.0}\n","    ]\n","    return optimizer_parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kg_-7UmLZNT"},"outputs":[],"source":["def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler=='linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler=='cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","    return scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMX-oU8IFs-s"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(\n","                cfg.model,\n","                output_hidden_states=False\n","                )\n","        else:\n","            self.config = torch.load(config_path)\n","        \n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","            self.lm_head = AutoModelForMaskedLM.from_pretrained(cfg.model, config=self.config).cls # [cls, lm_head]\n","        else:\n","            self.model = AutoModel(self.config)\n","            self.lm_head = AutoModelForMaskedLM(self.config).cls # [cls, lm_head]\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(\n","            self, \n","            input_ids=None,\n","            attention_mask=None,\n","            token_type_ids=None,\n","            #position_ids=None,\n","            inputs_embeds=None,\n","            labels=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None):\n","        \n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            #position_ids=position_ids,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,)\n","        \n","        sequence_output = outputs[0]\n","        prediction_scores = self.lm_head(sequence_output)\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n","\n","        return MaskedLMOutput(loss=masked_lm_loss,\n","                              logits=prediction_scores,\n","                              hidden_states=outputs.hidden_states,\n","                              attentions=outputs.attentions)"]},{"cell_type":"markdown","metadata":{"id":"sycLu0otG9Po"},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3624,"status":"ok","timestamp":1649127933726,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"IxbWX2UaFcob","outputId":"58eb5083-06d3-4a9e-988b-a7641d5ffec6"},"outputs":[{"data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(INPUT_DIR / \"train.csv\")\n","features = pd.read_csv(INPUT_DIR / \"features.csv\")\n","patient_notes = pd.read_csv(INPUT_DIR / \"patient_notes.csv\")\n","test = pd.read_csv(INPUT_DIR / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["0109dd308cb04d0786497a4152e78bab","230b21d0f18c417198f558ea5e9d0bdd","ccce250b5db94d94b19a5e4b6d822de2","ea4ddd4cd9b745d8ae9e0f83ac710628","b95b45ae5fc443a29ace285b23d3515f","cb5b632bb0e0423d939371de0216a431","67848d80cae448a39087ffb0cfca8aca","8f14544b70ec45a68f2181b0c0c7defc","0cff8b7fedcc4271836eb12dbee41d79","d2f0b2f31420463e9421793871921000","50daa8438b98410d999ce75b177434d1","7b039e613167470a9d2f95ea86b36446","2e0298183be641cf9a832aa2c48fe2b3","1a9703d427ed481382237a75b442273f","d2c71f10274c4f0cb47148c0676d670e","39df27d4fc49489c92f0abdd04840086","9b9c2b22f17041d68c313a3ee4df8b3f","c84066dee1ce41f0a7107c2da776580f","5330ffe6a68149e9900508561f3fd25b","c663d9616841495d969942d0ebb18ba9","fd74fd69bfef406699fc9c36dcc9e1f7","12ea7a5274664c0a951c27e362dabf68","5b40d18e533c46888a83666000d702eb","bacde0cbcef944f0971fc241f326d521","a0c9e0cfa9104777ac14124ba4b3d8b3","e852b24e3c34484c98301fc9c4612bd4","6afb3ba4d1774206bde923140d4fd8ef","af6ce36b4735443ea9c7456d6c220bf7","11406036650648a0ad3d3add0989dfdc","3de39728397d459b955edc17daca2331","762ef75cdaa94a1aa07e70c39b2c6845","d0fa80a0274d477fbf455fae913bc09a","19a3990171d14eb6b66bdbe4a40e0c53"]},"executionInfo":{"elapsed":11848,"status":"ok","timestamp":1649127945572,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"p6ClBuTUHnB_","outputId":"48512ce0-8d20-48c5-f4dd-3f5ed15f9a46"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0109dd308cb04d0786497a4152e78bab","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b039e613167470a9d2f95ea86b36446","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b40d18e533c46888a83666000d702eb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR / \"tokenizer/\")\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1649127945573,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"-lBjEwhD5FTX","outputId":"b6fa7b7f-d872-439b-f9bb-b70b2ce646bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}],"source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1386,"status":"ok","timestamp":1649127946951,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"GQwm8FinILp4","outputId":"c8233ab5-e426-4624-a06e-69a6e725578c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved mlm data: mlm_data.csv\n","mlm data: (42146, 1)\n"]}],"source":["mlm_data = patient_notes[['pn_history']].reset_index(drop=True)\n","mlm_data = mlm_data.rename(columns={'pn_history': 'text'})\n","csv_name = f'mlm_data.csv'\n","mlm_data.to_csv(OUTPUT_DIR / csv_name, index=False)\n","print(f\"Saved mlm data: {csv_name}\")\n","print(f\"mlm data: {mlm_data.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JrxMxf2I9cA"},"outputs":[],"source":["#####################################################\n","\n","# Training support\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], return_special_tokens_mask=True)\n","\n","def group_texts(examples):\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    total_length = (total_length // CFG.max_len) * CFG.max_len\n","    result = {\n","        k: [t[i : i + CFG.max_len] for i in range(0, total_length, CFG.max_len)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186,"referenced_widgets":["74ed29d22799436ea3d3783a0d4e26fa","d21d9ef4ca1c42a0a2aa7951931d32e2","e31b7c7e865d4347b91cc173b1fd6905","005f948f01394319bd0d25b1710efbaf","aa2478c174f14e918d8cdc1f6407af0b","eb88c740cb5943449c9dd6d7c875d6f6","e0eb9f790ab840e5b31f674f18d95bf0","bd6f44af8a0a4ed7b70a6cac56114471","c1fc032086694052b55c0db015ec4af5","ba1fd0a0d95c4bd9a57d0fe44060f8ec","e914306cf3e44eaaa74e710e1e4d5f82","5217788e32904d6c923105b58e862927","e2db800c33f54071aff8bd24a608da9e","aa5444bc09b347f79844de70330da7c4","cf35f0dc63954104a2f0534b5e52fd28","036f09461f4e46fe87e7088e758be7ec","0f625954347d40049f35aeb9d86d6a65","2269f7a2ee2040e0928bbd0b7f450081","160131b9bc70473fa27d89d989d2ac7c","92a875e3c34243b4b6970a1d3b94db7d","272962ce28b84484af29abd549a1a01f","6bfa87cf0b6e4bb5a65c1b11b4094e0b","3c133338395040baadec82002a079fce","93f86e5f79524ffcaeaa81c73f74a3e1","ab5f6671b49d456bb2918208a5b25d8e","9957f44492224e2caf4357250a1a251c","13e3b72595a440928c390e375bc60708","2bf13ce818f5436cbcad478a04caca91","507f671b3d93440798dc0cfe9b00721d","be600a39ef2f41bb9f098b91190b8f8d","a2c821291b23425a9799312833c74432","8f43c375803a4e59814d857413b0a254","3bd3c082d6734d518f4013ce26e892c2"]},"executionInfo":{"elapsed":1399,"status":"ok","timestamp":1649127948349,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"Q1Q-3LQ0J0Dq","outputId":"1f794255-02bf-4c69-9c34-3940857d10d9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using custom data configuration default-361353aaab79983e\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-361353aaab79983e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74ed29d22799436ea3d3783a0d4e26fa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5217788e32904d6c923105b58e862927","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-361353aaab79983e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c133338395040baadec82002a079fce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["seed_everything(CFG.seed)\n","\n","CFG.train_file = f\"mlm_data.csv\"\n","data_files = {'train': str(OUTPUT_DIR / CFG.train_file)}\n","raw_datasets = load_dataset('csv', data_files=data_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYAa6Ax9KD_W"},"outputs":[],"source":["if CFG.max_seq_length is None:\n","    max_seq_length = tokenizer.model_max_length\n","else:\n","    if CFG.max_seq_length > tokenizer.model_max_length:\n","        max_seq_length = min(CFG.max_seq_length, tokenizer.model_max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649127948350,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"tJ67inBI5FTZ","outputId":"afa133c0-d632-4b9a-fbed-7a3a82a519ee"},"outputs":[{"data":{"text/plain":["1000000000000000019884624838656"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.model_max_length"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17722,"status":"ok","timestamp":1649127966067,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"ZGA8iIsEKP5J","outputId":"e76391c9-50ff-4e2a-b429-2dceaf191f8e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting TOKENIZERS_PARALLELISM=false for forked processes.\n","tokenized_datasets: DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n","        num_rows: 42146\n","    })\n","})\n"]}],"source":["tokenized_datasets = raw_datasets.map(\n","    tokenize_function,\n","    batched=True,\n","    num_proc=4,\n","    remove_columns=[\"text\"],\n","    load_from_cache_file=not True,\n","    )\n","LOGGER.info(f\"tokenized_datasets: {tokenized_datasets}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60215,"status":"ok","timestamp":1649128026280,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"xAQzKUP6KVZi","outputId":"3b3c4d56-1b99-4c5e-8a5f-03defe49fc5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting TOKENIZERS_PARALLELISM=false for forked processes.\n","train_dataset: Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n","    num_rows: 15622\n","})\n"]}],"source":["tokenized_datasets = tokenized_datasets.map(\n","    group_texts,\n","    batched=True,\n","    num_proc=4,\n","    load_from_cache_file=not True,\n","    )\n","train_dataset = tokenized_datasets[\"train\"]\n","LOGGER.info(f\"train_dataset: {train_dataset}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUeXUD3vKZZ3"},"outputs":[],"source":["data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm_probability=CFG.mlm_probability\n","    )\n","train_loader = DataLoader(\n","    train_dataset,\n","    shuffle=True,\n","    collate_fn=data_collator,\n","    batch_size=CFG.batch_size\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212,"referenced_widgets":["b1ae525735a24fea834a9491f06c8755","da5a8c32ca3e4b97ad423556adcc4467","a4e7d46eff3f45cb90813fafe6d9dda6","a63e8722a9954338bb39a30929481b06","a3ab76a47bb84a969990ee1e3500439f","af117d2669c94af3a4a8010e68a85387","14521830d1d24c61beac59f816f1396a","d14f229b26624a3cb99b86abd880d315","84a6a9552b4f4b0cb587bbc1b5e8b9e5","13e660e2968940e7abff867bf4aa8ce2","1be2060aa806499db5255e241b1bf518"]},"executionInfo":{"elapsed":43028,"status":"ok","timestamp":1649128069306,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"k5XyBapSK216","outputId":"cd717acc-74a4-4e00-d57a-50f369211f6e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1ae525735a24fea834a9491f06c8755","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForMaskedLM: ['mask_predictions.dense.weight', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = CustomModel(CFG, config_path=None, pretrained=True)\n","model.to(device)\n","optimizer_parameters = get_optimizer_params(\n","    model,\n","    encoder_lr=CFG.encoder_lr, \n","    decoder_lr=CFG.decoder_lr,\n","    weight_decay=CFG.weight_decay)\n","optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSVXH6yyLU9h"},"outputs":[],"source":["num_train_steps = int(len(mlm_data) / CFG.batch_size * CFG.epochs)\n","scheduler = get_scheduler(CFG, optimizer, num_train_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1649128069307,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"FV7uRz4gMAth","outputId":"de7a414e-ec84-4f34-abb2-08f7b888717d"},"outputs":[{"name":"stdout","output_type":"stream","text":["632190\n"]}],"source":["print(num_train_steps)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DwOleusaL7X4","executionInfo":{"status":"error","timestamp":1649164406120,"user_tz":-540,"elapsed":83779,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"4d89e061-e07f-4148-8995-8a8529f4dd5c"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/15622] Elapsed 0m 1s (remain 443m 55s) Loss: 1.5002 Grad: 355674.5312  LR: 0.00002000  \n","Epoch: [1][500/15622] Elapsed 1m 59s (remain 60m 15s) Loss: 1.0712 Grad: 104145.1016  LR: 0.00002000  \n","Epoch: [1][1000/15622] Elapsed 3m 44s (remain 54m 35s) Loss: 0.9778 Grad: 112734.4531  LR: 0.00002000  \n","Epoch: [1][1500/15622] Elapsed 5m 18s (remain 49m 59s) Loss: 0.9181 Grad: 134490.7188  LR: 0.00002000  \n","Epoch: [1][2000/15622] Elapsed 6m 52s (remain 46m 48s) Loss: 0.8735 Grad: 135526.1875  LR: 0.00002000  \n","Epoch: [1][2500/15622] Elapsed 8m 26s (remain 44m 16s) Loss: 0.8389 Grad: 111095.7656  LR: 0.00002000  \n","Epoch: [1][3000/15622] Elapsed 9m 59s (remain 42m 1s) Loss: 0.8094 Grad: 136808.8750  LR: 0.00002000  \n","Epoch: [1][3500/15622] Elapsed 11m 32s (remain 39m 58s) Loss: 0.7843 Grad: 125526.3203  LR: 0.00002000  \n","Epoch: [1][4000/15622] Elapsed 13m 6s (remain 38m 4s) Loss: 0.7619 Grad: 130371.5781  LR: 0.00002000  \n","Epoch: [1][4500/15622] Elapsed 14m 39s (remain 36m 13s) Loss: 0.7427 Grad: 120671.1250  LR: 0.00002000  \n","Epoch: [1][5000/15622] Elapsed 16m 12s (remain 34m 25s) Loss: 0.7244 Grad: 124396.8281  LR: 0.00002000  \n","Epoch: [1][5500/15622] Elapsed 17m 46s (remain 32m 41s) Loss: 0.7082 Grad: 118052.9922  LR: 0.00002000  \n","Epoch: [1][6000/15622] Elapsed 19m 20s (remain 30m 59s) Loss: 0.6939 Grad: 109888.6953  LR: 0.00002000  \n","Epoch: [1][6500/15622] Elapsed 20m 52s (remain 29m 17s) Loss: 0.6802 Grad: 96793.6719  LR: 0.00002000  \n","Epoch: [1][7000/15622] Elapsed 22m 25s (remain 27m 37s) Loss: 0.6679 Grad: 125082.7422  LR: 0.00002000  \n","Epoch: [1][7500/15622] Elapsed 23m 58s (remain 25m 57s) Loss: 0.6567 Grad: 131219.0938  LR: 0.00002000  \n","Epoch: [1][8000/15622] Elapsed 25m 32s (remain 24m 19s) Loss: 0.6463 Grad: 145971.4531  LR: 0.00002000  \n","Epoch: [1][8500/15622] Elapsed 27m 4s (remain 22m 40s) Loss: 0.6370 Grad: 127328.5234  LR: 0.00002000  \n","Epoch: [1][9000/15622] Elapsed 28m 35s (remain 21m 2s) Loss: 0.6280 Grad: 110250.0859  LR: 0.00002000  \n","Epoch: [1][9500/15622] Elapsed 30m 7s (remain 19m 24s) Loss: 0.6193 Grad: 99390.8750  LR: 0.00002000  \n","Epoch: [1][10000/15622] Elapsed 31m 39s (remain 17m 47s) Loss: 0.6109 Grad: 131073.6875  LR: 0.00002000  \n","Epoch: [1][10500/15622] Elapsed 33m 11s (remain 16m 11s) Loss: 0.6032 Grad: 114426.3828  LR: 0.00002000  \n","Epoch: [1][11000/15622] Elapsed 34m 43s (remain 14m 35s) Loss: 0.5961 Grad: 173702.4219  LR: 0.00002000  \n","Epoch: [1][11500/15622] Elapsed 36m 15s (remain 12m 59s) Loss: 0.5889 Grad: 108662.3203  LR: 0.00002000  \n","Epoch: [1][12000/15622] Elapsed 37m 47s (remain 11m 24s) Loss: 0.5821 Grad: 125871.9688  LR: 0.00002000  \n","Epoch: [1][12500/15622] Elapsed 39m 19s (remain 9m 49s) Loss: 0.5757 Grad: 148815.5469  LR: 0.00002000  \n","Epoch: [1][13000/15622] Elapsed 40m 51s (remain 8m 14s) Loss: 0.5696 Grad: 117954.0859  LR: 0.00002000  \n","Epoch: [1][13500/15622] Elapsed 42m 24s (remain 6m 39s) Loss: 0.5638 Grad: 117311.5469  LR: 0.00002000  \n","Epoch: [1][14000/15622] Elapsed 43m 56s (remain 5m 5s) Loss: 0.5580 Grad: 120437.2344  LR: 0.00002000  \n","Epoch: [1][14500/15622] Elapsed 45m 28s (remain 3m 30s) Loss: 0.5527 Grad: 133319.7812  LR: 0.00002000  \n","Epoch: [1][15000/15622] Elapsed 47m 0s (remain 1m 56s) Loss: 0.5477 Grad: 118716.5469  LR: 0.00002000  \n","Epoch: [1][15500/15622] Elapsed 48m 32s (remain 0m 22s) Loss: 0.5424 Grad: 96693.5703  LR: 0.00002000  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1: Train Loss 0.5413, elapsed 2934.7519s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][15621/15622] Elapsed 48m 54s (remain 0m 0s) Loss: 0.5413 Grad: 124059.5234  LR: 0.00002000  \n","Epoch: [2][0/15622] Elapsed 0m 0s (remain 67m 19s) Loss: 0.3377 Grad: 114214.3906  LR: 0.00002000  \n","Epoch: [2][500/15622] Elapsed 1m 38s (remain 49m 47s) Loss: 0.3842 Grad: 181291.1094  LR: 0.00002000  \n","Epoch: [2][1000/15622] Elapsed 3m 11s (remain 46m 35s) Loss: 0.3808 Grad: 104461.5156  LR: 0.00002000  \n","Epoch: [2][1500/15622] Elapsed 4m 43s (remain 44m 28s) Loss: 0.3766 Grad: 112049.0625  LR: 0.00002000  \n","Epoch: [2][2000/15622] Elapsed 6m 15s (remain 42m 37s) Loss: 0.3756 Grad: 139150.2344  LR: 0.00002000  \n","Epoch: [2][2500/15622] Elapsed 7m 47s (remain 40m 54s) Loss: 0.3748 Grad: 108020.1328  LR: 0.00002000  \n","Epoch: [2][3000/15622] Elapsed 9m 20s (remain 39m 16s) Loss: 0.3738 Grad: 123903.1484  LR: 0.00002000  \n","Epoch: [2][3500/15622] Elapsed 10m 53s (remain 37m 40s) Loss: 0.3722 Grad: 113182.0391  LR: 0.00002000  \n","Epoch: [2][4000/15622] Elapsed 12m 27s (remain 36m 10s) Loss: 0.3703 Grad: 120390.6406  LR: 0.00002000  \n","Epoch: [2][4500/15622] Elapsed 14m 0s (remain 34m 35s) Loss: 0.3687 Grad: 134146.7969  LR: 0.00002000  \n","Epoch: [2][5000/15622] Elapsed 15m 32s (remain 32m 59s) Loss: 0.3670 Grad: 150475.9531  LR: 0.00002000  \n","Epoch: [2][5500/15622] Elapsed 17m 4s (remain 31m 25s) Loss: 0.3655 Grad: 158727.0312  LR: 0.00002000  \n","Epoch: [2][6000/15622] Elapsed 18m 37s (remain 29m 52s) Loss: 0.3641 Grad: 169974.1562  LR: 0.00002000  \n","Epoch: [2][6500/15622] Elapsed 20m 10s (remain 28m 18s) Loss: 0.3624 Grad: 133374.8281  LR: 0.00002000  \n","Epoch: [2][7000/15622] Elapsed 21m 44s (remain 26m 46s) Loss: 0.3609 Grad: 121313.6953  LR: 0.00002000  \n","Epoch: [2][7500/15622] Elapsed 23m 19s (remain 25m 14s) Loss: 0.3595 Grad: 135492.5781  LR: 0.00002000  \n","Epoch: [2][8000/15622] Elapsed 24m 52s (remain 23m 42s) Loss: 0.3578 Grad: 111809.1094  LR: 0.00002000  \n","Epoch: [2][8500/15622] Elapsed 26m 26s (remain 22m 9s) Loss: 0.3563 Grad: 125782.4688  LR: 0.00002000  \n","Epoch: [2][9000/15622] Elapsed 28m 1s (remain 20m 37s) Loss: 0.3546 Grad: 108855.3047  LR: 0.00002000  \n","Epoch: [2][9500/15622] Elapsed 29m 35s (remain 19m 3s) Loss: 0.3532 Grad: 125521.9766  LR: 0.00002000  \n","Epoch: [2][10000/15622] Elapsed 31m 9s (remain 17m 30s) Loss: 0.3521 Grad: 181650.3438  LR: 0.00002000  \n","Epoch: [2][10500/15622] Elapsed 32m 43s (remain 15m 57s) Loss: 0.3506 Grad: 121437.3906  LR: 0.00002000  \n","Epoch: [2][11000/15622] Elapsed 34m 18s (remain 14m 24s) Loss: 0.3495 Grad: 97746.4844  LR: 0.00002000  \n","Epoch: [2][11500/15622] Elapsed 35m 52s (remain 12m 51s) Loss: 0.3483 Grad: 106726.4688  LR: 0.00002000  \n","Epoch: [2][12000/15622] Elapsed 37m 26s (remain 11m 17s) Loss: 0.3471 Grad: 108933.0078  LR: 0.00002000  \n","Epoch: [2][12500/15622] Elapsed 39m 0s (remain 9m 44s) Loss: 0.3459 Grad: 130529.6172  LR: 0.00002000  \n","Epoch: [2][13000/15622] Elapsed 40m 34s (remain 8m 10s) Loss: 0.3448 Grad: 102953.2969  LR: 0.00002000  \n","Epoch: [2][13500/15622] Elapsed 42m 8s (remain 6m 37s) Loss: 0.3435 Grad: 101459.2578  LR: 0.00002000  \n","Epoch: [2][14000/15622] Elapsed 43m 42s (remain 5m 3s) Loss: 0.3424 Grad: 100112.1172  LR: 0.00002000  \n","Epoch: [2][14500/15622] Elapsed 45m 15s (remain 3m 29s) Loss: 0.3414 Grad: 121581.2891  LR: 0.00002000  \n","Epoch: [2][15000/15622] Elapsed 46m 49s (remain 1m 56s) Loss: 0.3403 Grad: 97524.2266  LR: 0.00002000  \n","Epoch: [2][15500/15622] Elapsed 48m 23s (remain 0m 22s) Loss: 0.3391 Grad: 104346.0391  LR: 0.00002000  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2: Train Loss 0.3388, elapsed 2926.8347s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][15621/15622] Elapsed 48m 46s (remain 0m 0s) Loss: 0.3388 Grad: 107116.8984  LR: 0.00002000  \n","Epoch: [3][0/15622] Elapsed 0m 0s (remain 61m 1s) Loss: 0.3111 Grad: 93935.1719  LR: 0.00002000  \n","Epoch: [3][500/15622] Elapsed 1m 41s (remain 51m 10s) Loss: 0.3023 Grad: 102337.0234  LR: 0.00002000  \n","Epoch: [3][1000/15622] Elapsed 3m 16s (remain 47m 44s) Loss: 0.3011 Grad: 99505.4375  LR: 0.00002000  \n","Epoch: [3][1500/15622] Elapsed 4m 50s (remain 45m 34s) Loss: 0.3010 Grad: 80483.4453  LR: 0.00002000  \n","Epoch: [3][2000/15622] Elapsed 6m 25s (remain 43m 45s) Loss: 0.3008 Grad: 115001.9453  LR: 0.00002000  \n","Epoch: [3][2500/15622] Elapsed 7m 59s (remain 41m 57s) Loss: 0.3002 Grad: 111458.1719  LR: 0.00002000  \n","Epoch: [3][3000/15622] Elapsed 9m 35s (remain 40m 18s) Loss: 0.2992 Grad: 109338.2266  LR: 0.00002000  \n","Epoch: [3][3500/15622] Elapsed 11m 8s (remain 38m 35s) Loss: 0.2986 Grad: 125289.1094  LR: 0.00002000  \n","Epoch: [3][4000/15622] Elapsed 12m 43s (remain 36m 57s) Loss: 0.2977 Grad: 118337.5469  LR: 0.00002000  \n","Epoch: [3][4500/15622] Elapsed 14m 16s (remain 35m 16s) Loss: 0.2972 Grad: 81933.3672  LR: 0.00002000  \n","Epoch: [3][5000/15622] Elapsed 15m 50s (remain 33m 37s) Loss: 0.2968 Grad: 113587.4766  LR: 0.00002000  \n","Epoch: [3][5500/15622] Elapsed 17m 23s (remain 32m 0s) Loss: 0.2962 Grad: 115974.4453  LR: 0.00002000  \n","Epoch: [3][6000/15622] Elapsed 18m 56s (remain 30m 21s) Loss: 0.2953 Grad: 151260.2656  LR: 0.00002000  \n","Epoch: [3][6500/15622] Elapsed 20m 28s (remain 28m 43s) Loss: 0.2943 Grad: 118314.4609  LR: 0.00002000  \n","Epoch: [3][7000/15622] Elapsed 22m 0s (remain 27m 6s) Loss: 0.2935 Grad: 132890.5781  LR: 0.00002000  \n","Epoch: [3][7500/15622] Elapsed 23m 33s (remain 25m 29s) Loss: 0.2930 Grad: 131042.0312  LR: 0.00002000  \n","Epoch: [3][8000/15622] Elapsed 25m 5s (remain 23m 54s) Loss: 0.2918 Grad: 119905.0156  LR: 0.00002000  \n","Epoch: [3][8500/15622] Elapsed 26m 38s (remain 22m 19s) Loss: 0.2911 Grad: 100601.4219  LR: 0.00002000  \n","Epoch: [3][9000/15622] Elapsed 28m 11s (remain 20m 44s) Loss: 0.2903 Grad: 100561.9297  LR: 0.00002000  \n","Epoch: [3][9500/15622] Elapsed 29m 44s (remain 19m 9s) Loss: 0.2898 Grad: 129402.0312  LR: 0.00002000  \n","Epoch: [3][10000/15622] Elapsed 31m 17s (remain 17m 35s) Loss: 0.2890 Grad: 92649.0938  LR: 0.00002000  \n","Epoch: [3][10500/15622] Elapsed 32m 50s (remain 16m 0s) Loss: 0.2882 Grad: 124710.8906  LR: 0.00002000  \n","Epoch: [3][11000/15622] Elapsed 34m 23s (remain 14m 26s) Loss: 0.2877 Grad: 138112.2656  LR: 0.00002000  \n","Epoch: [3][11500/15622] Elapsed 35m 54s (remain 12m 52s) Loss: 0.2872 Grad: 135225.4375  LR: 0.00002000  \n","Epoch: [3][12000/15622] Elapsed 37m 26s (remain 11m 17s) Loss: 0.2866 Grad: 122868.0156  LR: 0.00002000  \n","Epoch: [3][12500/15622] Elapsed 38m 58s (remain 9m 43s) Loss: 0.2860 Grad: 132740.1094  LR: 0.00002000  \n","Epoch: [3][13000/15622] Elapsed 40m 32s (remain 8m 10s) Loss: 0.2853 Grad: 113379.2734  LR: 0.00002000  \n","Epoch: [3][13500/15622] Elapsed 42m 3s (remain 6m 36s) Loss: 0.2847 Grad: 105407.7188  LR: 0.00002000  \n","Epoch: [3][14000/15622] Elapsed 43m 35s (remain 5m 2s) Loss: 0.2840 Grad: 118164.3438  LR: 0.00002000  \n","Epoch: [3][14500/15622] Elapsed 45m 7s (remain 3m 29s) Loss: 0.2834 Grad: 109066.6562  LR: 0.00002000  \n","Epoch: [3][15000/15622] Elapsed 46m 38s (remain 1m 55s) Loss: 0.2828 Grad: 100550.7266  LR: 0.00002000  \n","Epoch: [3][15500/15622] Elapsed 48m 10s (remain 0m 22s) Loss: 0.2821 Grad: 106222.3125  LR: 0.00002000  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3: Train Loss 0.2820, elapsed 2913.4266s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][15621/15622] Elapsed 48m 33s (remain 0m 0s) Loss: 0.2820 Grad: 123203.3594  LR: 0.00002000  \n","Epoch: [4][0/15622] Elapsed 0m 0s (remain 67m 34s) Loss: 0.2628 Grad: 101402.5312  LR: 0.00002000  \n","Epoch: [4][500/15622] Elapsed 1m 39s (remain 50m 15s) Loss: 0.2647 Grad: 108177.6250  LR: 0.00002000  \n","Epoch: [4][1000/15622] Elapsed 3m 12s (remain 46m 58s) Loss: 0.2629 Grad: 111227.9297  LR: 0.00002000  \n","Epoch: [4][1500/15622] Elapsed 4m 45s (remain 44m 47s) Loss: 0.2617 Grad: 112201.3984  LR: 0.00002000  \n","Epoch: [4][2000/15622] Elapsed 6m 18s (remain 42m 56s) Loss: 0.2612 Grad: 126573.3125  LR: 0.00002000  \n","Epoch: [4][2500/15622] Elapsed 7m 51s (remain 41m 12s) Loss: 0.2613 Grad: 91985.5547  LR: 0.00002000  \n","Epoch: [4][3000/15622] Elapsed 9m 23s (remain 39m 31s) Loss: 0.2606 Grad: 96756.3594  LR: 0.00002000  \n","Epoch: [4][3500/15622] Elapsed 10m 55s (remain 37m 50s) Loss: 0.2606 Grad: 119351.1484  LR: 0.00002000  \n","Epoch: [4][4000/15622] Elapsed 12m 27s (remain 36m 12s) Loss: 0.2598 Grad: 109861.0078  LR: 0.00002000  \n","Epoch: [4][4500/15622] Elapsed 14m 0s (remain 34m 36s) Loss: 0.2597 Grad: 102533.2891  LR: 0.00001999  \n","Epoch: [4][5000/15622] Elapsed 15m 32s (remain 33m 0s) Loss: 0.2596 Grad: 107223.8672  LR: 0.00001999  \n","Epoch: [4][5500/15622] Elapsed 17m 5s (remain 31m 27s) Loss: 0.2592 Grad: 100563.0938  LR: 0.00001999  \n","Epoch: [4][6000/15622] Elapsed 18m 38s (remain 29m 53s) Loss: 0.2594 Grad: 87007.8516  LR: 0.00001999  \n","Epoch: [4][6500/15622] Elapsed 20m 11s (remain 28m 19s) Loss: 0.2588 Grad: 109877.1094  LR: 0.00001999  \n","Epoch: [4][7000/15622] Elapsed 21m 43s (remain 26m 45s) Loss: 0.2581 Grad: 111017.6094  LR: 0.00001999  \n","Epoch: [4][7500/15622] Elapsed 23m 16s (remain 25m 11s) Loss: 0.2574 Grad: 98911.7969  LR: 0.00001999  \n","Epoch: [4][8000/15622] Elapsed 24m 48s (remain 23m 38s) Loss: 0.2572 Grad: 114157.4062  LR: 0.00001999  \n","Epoch: [4][8500/15622] Elapsed 26m 21s (remain 22m 4s) Loss: 0.2568 Grad: 100637.9609  LR: 0.00001999  \n","Epoch: [4][9000/15622] Elapsed 27m 53s (remain 20m 31s) Loss: 0.2561 Grad: 117483.5000  LR: 0.00001999  \n","Epoch: [4][9500/15622] Elapsed 29m 25s (remain 18m 57s) Loss: 0.2556 Grad: 114399.6172  LR: 0.00001999  \n","Epoch: [4][10000/15622] Elapsed 30m 57s (remain 17m 24s) Loss: 0.2551 Grad: 87356.7109  LR: 0.00001999  \n","Epoch: [4][10500/15622] Elapsed 32m 30s (remain 15m 51s) Loss: 0.2549 Grad: 92260.3125  LR: 0.00001999  \n","Epoch: [4][11000/15622] Elapsed 34m 1s (remain 14m 17s) Loss: 0.2544 Grad: 146019.1406  LR: 0.00001999  \n","Epoch: [4][11500/15622] Elapsed 35m 33s (remain 12m 44s) Loss: 0.2539 Grad: 100488.5781  LR: 0.00001999  \n","Epoch: [4][12000/15622] Elapsed 37m 6s (remain 11m 11s) Loss: 0.2535 Grad: 143972.3438  LR: 0.00001999  \n","Epoch: [4][12500/15622] Elapsed 38m 39s (remain 9m 39s) Loss: 0.2533 Grad: 111858.1484  LR: 0.00001999  \n","Epoch: [4][13000/15622] Elapsed 40m 12s (remain 8m 6s) Loss: 0.2529 Grad: 127469.7109  LR: 0.00001999  \n","Epoch: [4][13500/15622] Elapsed 41m 44s (remain 6m 33s) Loss: 0.2526 Grad: 106015.6250  LR: 0.00001999  \n","Epoch: [4][14000/15622] Elapsed 43m 16s (remain 5m 0s) Loss: 0.2521 Grad: 92311.3906  LR: 0.00001999  \n","Epoch: [4][14500/15622] Elapsed 44m 47s (remain 3m 27s) Loss: 0.2517 Grad: 77475.5156  LR: 0.00001999  \n","Epoch: [4][15000/15622] Elapsed 46m 19s (remain 1m 55s) Loss: 0.2514 Grad: 95476.5391  LR: 0.00001999  \n","Epoch: [4][15500/15622] Elapsed 47m 52s (remain 0m 22s) Loss: 0.2509 Grad: 119762.1250  LR: 0.00001999  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4: Train Loss 0.2509, elapsed 2895.7241s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][15621/15622] Elapsed 48m 15s (remain 0m 0s) Loss: 0.2509 Grad: 99596.1094  LR: 0.00001999  \n","Epoch: [5][0/15622] Elapsed 0m 0s (remain 48m 24s) Loss: 0.2104 Grad: 89402.7578  LR: 0.00001999  \n","Epoch: [5][500/15622] Elapsed 1m 40s (remain 50m 30s) Loss: 0.2391 Grad: 103636.0859  LR: 0.00001999  \n","Epoch: [5][1000/15622] Elapsed 3m 12s (remain 46m 52s) Loss: 0.2403 Grad: 120120.9453  LR: 0.00001999  \n","Epoch: [5][1500/15622] Elapsed 4m 46s (remain 44m 55s) Loss: 0.2400 Grad: 134751.6406  LR: 0.00001999  \n","Epoch: [5][2000/15622] Elapsed 6m 19s (remain 43m 5s) Loss: 0.2398 Grad: 103772.3203  LR: 0.00001999  \n","Epoch: [5][2500/15622] Elapsed 7m 52s (remain 41m 17s) Loss: 0.2393 Grad: 86399.3516  LR: 0.00001999  \n","Epoch: [5][3000/15622] Elapsed 9m 24s (remain 39m 34s) Loss: 0.2385 Grad: 97491.7188  LR: 0.00001999  \n","Epoch: [5][3500/15622] Elapsed 10m 57s (remain 37m 55s) Loss: 0.2386 Grad: 146712.6094  LR: 0.00001999  \n","Epoch: [5][4000/15622] Elapsed 12m 29s (remain 36m 16s) Loss: 0.2387 Grad: 102918.4219  LR: 0.00001999  \n","Epoch: [5][4500/15622] Elapsed 14m 1s (remain 34m 38s) Loss: 0.2384 Grad: 118886.5312  LR: 0.00001999  \n","Epoch: [5][5000/15622] Elapsed 15m 33s (remain 33m 2s) Loss: 0.2378 Grad: 134476.5625  LR: 0.00001999  \n","Epoch: [5][5500/15622] Elapsed 17m 5s (remain 31m 26s) Loss: 0.2373 Grad: 90913.3516  LR: 0.00001999  \n","Epoch: [5][6000/15622] Elapsed 18m 37s (remain 29m 51s) Loss: 0.2365 Grad: 104532.8047  LR: 0.00001999  \n","Epoch: [5][6500/15622] Elapsed 20m 9s (remain 28m 17s) Loss: 0.2363 Grad: 125838.3047  LR: 0.00001999  \n","Epoch: [5][7000/15622] Elapsed 21m 42s (remain 26m 44s) Loss: 0.2364 Grad: 106631.5312  LR: 0.00001999  \n","Epoch: [5][7500/15622] Elapsed 23m 15s (remain 25m 11s) Loss: 0.2362 Grad: 142942.3906  LR: 0.00001999  \n","Epoch: [5][8000/15622] Elapsed 24m 48s (remain 23m 38s) Loss: 0.2361 Grad: 119227.3438  LR: 0.00001999  \n","Epoch: [5][8500/15622] Elapsed 26m 21s (remain 22m 4s) Loss: 0.2359 Grad: 93293.7344  LR: 0.00001999  \n","Epoch: [5][9000/15622] Elapsed 27m 54s (remain 20m 31s) Loss: 0.2356 Grad: 107354.6250  LR: 0.00001999  \n","Epoch: [5][9500/15622] Elapsed 29m 26s (remain 18m 57s) Loss: 0.2356 Grad: 91606.6406  LR: 0.00001999  \n","Epoch: [5][10000/15622] Elapsed 30m 58s (remain 17m 24s) Loss: 0.2353 Grad: 84069.4219  LR: 0.00001999  \n","Epoch: [5][10500/15622] Elapsed 32m 31s (remain 15m 51s) Loss: 0.2348 Grad: 105830.6250  LR: 0.00001999  \n","Epoch: [5][11000/15622] Elapsed 34m 3s (remain 14m 18s) Loss: 0.2344 Grad: 101166.7969  LR: 0.00001999  \n","Epoch: [5][11500/15622] Elapsed 35m 35s (remain 12m 45s) Loss: 0.2342 Grad: 81988.9688  LR: 0.00001999  \n","Epoch: [5][12000/15622] Elapsed 37m 7s (remain 11m 12s) Loss: 0.2339 Grad: 141520.8125  LR: 0.00001999  \n","Epoch: [5][12500/15622] Elapsed 38m 39s (remain 9m 39s) Loss: 0.2335 Grad: 126413.7578  LR: 0.00001999  \n","Epoch: [5][13000/15622] Elapsed 40m 11s (remain 8m 6s) Loss: 0.2334 Grad: 107514.8203  LR: 0.00001999  \n","Epoch: [5][13500/15622] Elapsed 41m 43s (remain 6m 33s) Loss: 0.2330 Grad: 106810.0469  LR: 0.00001999  \n","Epoch: [5][14000/15622] Elapsed 43m 15s (remain 5m 0s) Loss: 0.2327 Grad: 94633.3359  LR: 0.00001999  \n","Epoch: [5][14500/15622] Elapsed 44m 47s (remain 3m 27s) Loss: 0.2324 Grad: 110830.2891  LR: 0.00001999  \n","Epoch: [5][15000/15622] Elapsed 46m 19s (remain 1m 55s) Loss: 0.2322 Grad: 77730.4141  LR: 0.00001999  \n","Epoch: [5][15500/15622] Elapsed 47m 50s (remain 0m 22s) Loss: 0.2319 Grad: 102953.1797  LR: 0.00001999  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5: Train Loss 0.2319, elapsed 2893.3945s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][15621/15622] Elapsed 48m 13s (remain 0m 0s) Loss: 0.2319 Grad: 116433.8516  LR: 0.00001999  \n","Epoch: [6][0/15622] Elapsed 0m 0s (remain 58m 39s) Loss: 0.2499 Grad: 100288.1250  LR: 0.00001999  \n","Epoch: [6][500/15622] Elapsed 1m 41s (remain 51m 7s) Loss: 0.2238 Grad: 78101.0625  LR: 0.00001999  \n","Epoch: [6][1000/15622] Elapsed 3m 13s (remain 47m 9s) Loss: 0.2241 Grad: 97514.3984  LR: 0.00001999  \n","Epoch: [6][1500/15622] Elapsed 4m 45s (remain 44m 49s) Loss: 0.2249 Grad: 115479.0156  LR: 0.00001999  \n","Epoch: [6][2000/15622] Elapsed 6m 17s (remain 42m 52s) Loss: 0.2229 Grad: 104525.5547  LR: 0.00001999  \n","Epoch: [6][2500/15622] Elapsed 7m 50s (remain 41m 5s) Loss: 0.2226 Grad: 95958.9219  LR: 0.00001999  \n","Epoch: [6][3000/15622] Elapsed 9m 21s (remain 39m 23s) Loss: 0.2226 Grad: 100439.1797  LR: 0.00001999  \n","Epoch: [6][3500/15622] Elapsed 10m 54s (remain 37m 46s) Loss: 0.2226 Grad: 102744.9375  LR: 0.00001999  \n","Epoch: [6][4000/15622] Elapsed 12m 26s (remain 36m 8s) Loss: 0.2228 Grad: 88549.2422  LR: 0.00001999  \n","Epoch: [6][4500/15622] Elapsed 13m 57s (remain 34m 30s) Loss: 0.2225 Grad: 101020.0156  LR: 0.00001999  \n","Epoch: [6][5000/15622] Elapsed 15m 29s (remain 32m 53s) Loss: 0.2224 Grad: 102057.9531  LR: 0.00001999  \n","Epoch: [6][5500/15622] Elapsed 17m 1s (remain 31m 18s) Loss: 0.2221 Grad: 89097.6797  LR: 0.00001999  \n","Epoch: [6][6000/15622] Elapsed 18m 33s (remain 29m 44s) Loss: 0.2219 Grad: 87210.6328  LR: 0.00001999  \n","Epoch: [6][6500/15622] Elapsed 20m 6s (remain 28m 12s) Loss: 0.2216 Grad: 116125.7344  LR: 0.00001999  \n","Epoch: [6][7000/15622] Elapsed 21m 39s (remain 26m 39s) Loss: 0.2212 Grad: 108383.7109  LR: 0.00001999  \n","Epoch: [6][7500/15622] Elapsed 23m 11s (remain 25m 6s) Loss: 0.2211 Grad: 102031.5703  LR: 0.00001999  \n","Epoch: [6][8000/15622] Elapsed 24m 43s (remain 23m 32s) Loss: 0.2210 Grad: 89795.1797  LR: 0.00001999  \n","Epoch: [6][8500/15622] Elapsed 26m 16s (remain 22m 0s) Loss: 0.2208 Grad: 80325.6328  LR: 0.00001999  \n","Epoch: [6][9000/15622] Elapsed 27m 50s (remain 20m 28s) Loss: 0.2206 Grad: 106129.7578  LR: 0.00001999  \n","Epoch: [6][9500/15622] Elapsed 29m 23s (remain 18m 56s) Loss: 0.2203 Grad: 83172.5625  LR: 0.00001999  \n","Epoch: [6][10000/15622] Elapsed 30m 58s (remain 17m 24s) Loss: 0.2200 Grad: 94005.9531  LR: 0.00001999  \n","Epoch: [6][10500/15622] Elapsed 32m 32s (remain 15m 51s) Loss: 0.2197 Grad: 133552.4531  LR: 0.00001998  \n","Epoch: [6][11000/15622] Elapsed 34m 5s (remain 14m 19s) Loss: 0.2196 Grad: 98774.1016  LR: 0.00001998  \n","Epoch: [6][11500/15622] Elapsed 35m 39s (remain 12m 46s) Loss: 0.2194 Grad: 85587.9844  LR: 0.00001998  \n","Epoch: [6][12000/15622] Elapsed 37m 13s (remain 11m 13s) Loss: 0.2192 Grad: 84127.8906  LR: 0.00001998  \n","Epoch: [6][12500/15622] Elapsed 38m 47s (remain 9m 41s) Loss: 0.2190 Grad: 105640.1562  LR: 0.00001998  \n","Epoch: [6][13000/15622] Elapsed 40m 21s (remain 8m 8s) Loss: 0.2188 Grad: 89455.4844  LR: 0.00001998  \n","Epoch: [6][13500/15622] Elapsed 41m 55s (remain 6m 35s) Loss: 0.2185 Grad: 143032.9844  LR: 0.00001998  \n","Epoch: [6][14000/15622] Elapsed 43m 30s (remain 5m 2s) Loss: 0.2183 Grad: 76531.4922  LR: 0.00001998  \n","Epoch: [6][14500/15622] Elapsed 45m 4s (remain 3m 29s) Loss: 0.2182 Grad: 70099.7812  LR: 0.00001998  \n","Epoch: [6][15000/15622] Elapsed 46m 38s (remain 1m 55s) Loss: 0.2180 Grad: 93548.7734  LR: 0.00001998  \n","Epoch: [6][15500/15622] Elapsed 48m 12s (remain 0m 22s) Loss: 0.2179 Grad: 92522.2109  LR: 0.00001998  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 6: Train Loss 0.2179, elapsed 2916.0028s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [6][15621/15622] Elapsed 48m 35s (remain 0m 0s) Loss: 0.2179 Grad: 112889.9844  LR: 0.00001998  \n","Epoch: [7][0/15622] Elapsed 0m 0s (remain 59m 57s) Loss: 0.2205 Grad: 100851.7891  LR: 0.00001998  \n","Epoch: [7][500/15622] Elapsed 1m 43s (remain 51m 54s) Loss: 0.2067 Grad: 109201.8594  LR: 0.00001998  \n","Epoch: [7][1000/15622] Elapsed 3m 18s (remain 48m 18s) Loss: 0.2084 Grad: 89271.1719  LR: 0.00001998  \n","Epoch: [7][1500/15622] Elapsed 4m 53s (remain 45m 57s) Loss: 0.2084 Grad: 73267.5234  LR: 0.00001998  \n","Epoch: [7][2000/15622] Elapsed 6m 27s (remain 43m 57s) Loss: 0.2081 Grad: 125338.9609  LR: 0.00001998  \n","Epoch: [7][2500/15622] Elapsed 8m 2s (remain 42m 11s) Loss: 0.2089 Grad: 65648.1875  LR: 0.00001998  \n","Epoch: [7][3000/15622] Elapsed 9m 38s (remain 40m 32s) Loss: 0.2097 Grad: 113556.2578  LR: 0.00001998  \n","Epoch: [7][3500/15622] Elapsed 11m 13s (remain 38m 52s) Loss: 0.2094 Grad: 99659.4609  LR: 0.00001998  \n","Epoch: [7][4000/15622] Elapsed 12m 50s (remain 37m 16s) Loss: 0.2097 Grad: 107492.9453  LR: 0.00001998  \n","Epoch: [7][4500/15622] Elapsed 14m 24s (remain 35m 36s) Loss: 0.2098 Grad: 90995.4297  LR: 0.00001998  \n","Epoch: [7][5000/15622] Elapsed 15m 59s (remain 33m 58s) Loss: 0.2098 Grad: 87899.9141  LR: 0.00001998  \n","Epoch: [7][5500/15622] Elapsed 17m 35s (remain 32m 21s) Loss: 0.2097 Grad: 100218.3125  LR: 0.00001998  \n","Epoch: [7][6000/15622] Elapsed 19m 10s (remain 30m 45s) Loss: 0.2096 Grad: 111238.2812  LR: 0.00001998  \n","Epoch: [7][6500/15622] Elapsed 20m 46s (remain 29m 8s) Loss: 0.2091 Grad: 154646.3750  LR: 0.00001998  \n","Epoch: [7][7000/15622] Elapsed 22m 22s (remain 27m 32s) Loss: 0.2089 Grad: 83374.1250  LR: 0.00001998  \n","Epoch: [7][7500/15622] Elapsed 23m 57s (remain 25m 56s) Loss: 0.2089 Grad: 124516.8047  LR: 0.00001998  \n","Epoch: [7][8000/15622] Elapsed 25m 33s (remain 24m 20s) Loss: 0.2088 Grad: 91727.0312  LR: 0.00001998  \n","Epoch: [7][8500/15622] Elapsed 27m 8s (remain 22m 43s) Loss: 0.2088 Grad: 92424.4609  LR: 0.00001998  \n","Epoch: [7][9000/15622] Elapsed 28m 45s (remain 21m 9s) Loss: 0.2086 Grad: 114446.9531  LR: 0.00001998  \n","Epoch: [7][9500/15622] Elapsed 30m 20s (remain 19m 32s) Loss: 0.2087 Grad: 92944.0781  LR: 0.00001998  \n","Epoch: [7][10000/15622] Elapsed 31m 55s (remain 17m 56s) Loss: 0.2085 Grad: 105436.2031  LR: 0.00001998  \n","Epoch: [7][10500/15622] Elapsed 33m 31s (remain 16m 20s) Loss: 0.2083 Grad: 113151.7656  LR: 0.00001998  \n","Epoch: [7][11000/15622] Elapsed 35m 6s (remain 14m 44s) Loss: 0.2081 Grad: 91709.3828  LR: 0.00001998  \n","Epoch: [7][11500/15622] Elapsed 36m 41s (remain 13m 8s) Loss: 0.2080 Grad: 89399.2344  LR: 0.00001998  \n","Epoch: [7][12000/15622] Elapsed 38m 18s (remain 11m 33s) Loss: 0.2079 Grad: 101666.9688  LR: 0.00001998  \n","Epoch: [7][12500/15622] Elapsed 39m 52s (remain 9m 57s) Loss: 0.2080 Grad: 92324.9688  LR: 0.00001998  \n","Epoch: [7][13000/15622] Elapsed 41m 28s (remain 8m 21s) Loss: 0.2077 Grad: 106439.2422  LR: 0.00001998  \n","Epoch: [7][13500/15622] Elapsed 43m 2s (remain 6m 45s) Loss: 0.2076 Grad: 101346.9141  LR: 0.00001998  \n","Epoch: [7][14000/15622] Elapsed 44m 38s (remain 5m 10s) Loss: 0.2075 Grad: 85914.9688  LR: 0.00001998  \n","Epoch: [7][14500/15622] Elapsed 46m 12s (remain 3m 34s) Loss: 0.2074 Grad: 81073.2344  LR: 0.00001998  \n","Epoch: [7][15000/15622] Elapsed 47m 47s (remain 1m 58s) Loss: 0.2072 Grad: 117399.9688  LR: 0.00001998  \n","Epoch: [7][15500/15622] Elapsed 49m 23s (remain 0m 23s) Loss: 0.2070 Grad: 125001.0234  LR: 0.00001998  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 7: Train Loss 0.2070, elapsed 2986.2392s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [7][15621/15622] Elapsed 49m 46s (remain 0m 0s) Loss: 0.2070 Grad: 104375.6719  LR: 0.00001998  \n","Epoch: [8][0/15622] Elapsed 0m 0s (remain 72m 51s) Loss: 0.1567 Grad: 98333.3984  LR: 0.00001998  \n","Epoch: [8][500/15622] Elapsed 1m 45s (remain 53m 10s) Loss: 0.1980 Grad: 142617.9219  LR: 0.00001998  \n","Epoch: [8][1000/15622] Elapsed 3m 21s (remain 49m 1s) Loss: 0.2006 Grad: 115004.7734  LR: 0.00001998  \n","Epoch: [8][1500/15622] Elapsed 4m 57s (remain 46m 35s) Loss: 0.2013 Grad: 86391.8125  LR: 0.00001998  \n","Epoch: [8][2000/15622] Elapsed 6m 32s (remain 44m 29s) Loss: 0.2016 Grad: 91405.5312  LR: 0.00001998  \n","Epoch: [8][2500/15622] Elapsed 8m 6s (remain 42m 32s) Loss: 0.2008 Grad: 138417.6406  LR: 0.00001998  \n","Epoch: [8][3000/15622] Elapsed 9m 41s (remain 40m 47s) Loss: 0.2008 Grad: 105140.0234  LR: 0.00001998  \n","Epoch: [8][3500/15622] Elapsed 11m 17s (remain 39m 6s) Loss: 0.2008 Grad: 97816.0938  LR: 0.00001998  \n","Epoch: [8][4000/15622] Elapsed 12m 53s (remain 37m 26s) Loss: 0.2005 Grad: 80656.4609  LR: 0.00001998  \n","Epoch: [8][4500/15622] Elapsed 14m 27s (remain 35m 44s) Loss: 0.2004 Grad: 77387.6641  LR: 0.00001998  \n","Epoch: [8][5000/15622] Elapsed 16m 3s (remain 34m 5s) Loss: 0.2004 Grad: 101441.2656  LR: 0.00001997  \n","Epoch: [8][5500/15622] Elapsed 17m 37s (remain 32m 26s) Loss: 0.2004 Grad: 93630.5859  LR: 0.00001997  \n","Epoch: [8][6000/15622] Elapsed 19m 11s (remain 30m 46s) Loss: 0.2002 Grad: 77325.1641  LR: 0.00001997  \n","Epoch: [8][6500/15622] Elapsed 20m 46s (remain 29m 9s) Loss: 0.1997 Grad: 90925.7734  LR: 0.00001997  \n","Epoch: [8][7000/15622] Elapsed 22m 21s (remain 27m 31s) Loss: 0.1997 Grad: 95151.1406  LR: 0.00001997  \n","Epoch: [8][7500/15622] Elapsed 23m 55s (remain 25m 54s) Loss: 0.1997 Grad: 97764.8828  LR: 0.00001997  \n","Epoch: [8][8000/15622] Elapsed 25m 30s (remain 24m 17s) Loss: 0.1993 Grad: 96655.9844  LR: 0.00001997  \n","Epoch: [8][8500/15622] Elapsed 27m 4s (remain 22m 40s) Loss: 0.1992 Grad: 84235.6641  LR: 0.00001997  \n","Epoch: [8][9000/15622] Elapsed 28m 38s (remain 21m 3s) Loss: 0.1988 Grad: 68125.3125  LR: 0.00001997  \n","Epoch: [8][9500/15622] Elapsed 30m 12s (remain 19m 27s) Loss: 0.1984 Grad: 80449.8359  LR: 0.00001997  \n","Epoch: [8][10000/15622] Elapsed 31m 47s (remain 17m 51s) Loss: 0.1984 Grad: 105933.5547  LR: 0.00001997  \n","Epoch: [8][10500/15622] Elapsed 33m 21s (remain 16m 15s) Loss: 0.1983 Grad: 171676.5312  LR: 0.00001997  \n","Epoch: [8][11000/15622] Elapsed 34m 57s (remain 14m 40s) Loss: 0.1981 Grad: 73036.6172  LR: 0.00001997  \n","Epoch: [8][11500/15622] Elapsed 36m 32s (remain 13m 5s) Loss: 0.1981 Grad: 116458.6953  LR: 0.00001997  \n","Epoch: [8][12000/15622] Elapsed 38m 7s (remain 11m 30s) Loss: 0.1981 Grad: 112974.2188  LR: 0.00001997  \n","Epoch: [8][12500/15622] Elapsed 39m 42s (remain 9m 54s) Loss: 0.1981 Grad: 110426.4375  LR: 0.00001997  \n","Epoch: [8][13000/15622] Elapsed 41m 19s (remain 8m 19s) Loss: 0.1980 Grad: 115961.8984  LR: 0.00001997  \n","Epoch: [8][13500/15622] Elapsed 42m 54s (remain 6m 44s) Loss: 0.1980 Grad: 101986.5078  LR: 0.00001997  \n","Epoch: [8][14000/15622] Elapsed 44m 29s (remain 5m 9s) Loss: 0.1979 Grad: 74804.5078  LR: 0.00001997  \n","Epoch: [8][14500/15622] Elapsed 46m 4s (remain 3m 33s) Loss: 0.1979 Grad: 215150.1875  LR: 0.00001997  \n","Epoch: [8][15000/15622] Elapsed 47m 38s (remain 1m 58s) Loss: 0.1977 Grad: 69446.6562  LR: 0.00001997  \n","Epoch: [8][15500/15622] Elapsed 49m 14s (remain 0m 23s) Loss: 0.1976 Grad: 119661.9609  LR: 0.00001997  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 8: Train Loss 0.1976, elapsed 2977.7061s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [8][15621/15622] Elapsed 49m 37s (remain 0m 0s) Loss: 0.1976 Grad: 136931.0156  LR: 0.00001997  \n","Epoch: [9][0/15622] Elapsed 0m 0s (remain 67m 30s) Loss: 0.2638 Grad: 100935.5547  LR: 0.00001997  \n","Epoch: [9][500/15622] Elapsed 1m 46s (remain 53m 23s) Loss: 0.1922 Grad: 97066.3047  LR: 0.00001997  \n","Epoch: [9][1000/15622] Elapsed 3m 21s (remain 49m 9s) Loss: 0.1947 Grad: 97520.4688  LR: 0.00001997  \n","Epoch: [9][1500/15622] Elapsed 4m 57s (remain 46m 34s) Loss: 0.1955 Grad: 97019.2109  LR: 0.00001997  \n","Epoch: [9][2000/15622] Elapsed 6m 31s (remain 44m 25s) Loss: 0.1946 Grad: 90397.1797  LR: 0.00001997  \n","Epoch: [9][2500/15622] Elapsed 8m 6s (remain 42m 33s) Loss: 0.1944 Grad: 120440.5078  LR: 0.00001997  \n","Epoch: [9][3000/15622] Elapsed 9m 42s (remain 40m 47s) Loss: 0.1950 Grad: 90488.0078  LR: 0.00001997  \n","Epoch: [9][3500/15622] Elapsed 11m 17s (remain 39m 4s) Loss: 0.1946 Grad: 114172.5938  LR: 0.00001997  \n","Epoch: [9][4000/15622] Elapsed 12m 52s (remain 37m 24s) Loss: 0.1943 Grad: 81934.2578  LR: 0.00001997  \n","Epoch: [9][4500/15622] Elapsed 14m 27s (remain 35m 43s) Loss: 0.1942 Grad: 101422.5312  LR: 0.00001997  \n","Epoch: [9][5000/15622] Elapsed 16m 3s (remain 34m 5s) Loss: 0.1939 Grad: 93448.1328  LR: 0.00001997  \n","Epoch: [9][5500/15622] Elapsed 17m 38s (remain 32m 26s) Loss: 0.1939 Grad: 110981.3672  LR: 0.00001997  \n","Epoch: [9][6000/15622] Elapsed 19m 12s (remain 30m 48s) Loss: 0.1938 Grad: 80296.0312  LR: 0.00001997  \n","Epoch: [9][6500/15622] Elapsed 20m 48s (remain 29m 11s) Loss: 0.1936 Grad: 75998.2422  LR: 0.00001997  \n","Epoch: [9][7000/15622] Elapsed 22m 22s (remain 27m 33s) Loss: 0.1934 Grad: 73246.0781  LR: 0.00001997  \n","Epoch: [9][7500/15622] Elapsed 23m 56s (remain 25m 55s) Loss: 0.1934 Grad: 110047.8594  LR: 0.00001997  \n","Epoch: [9][8000/15622] Elapsed 25m 32s (remain 24m 19s) Loss: 0.1933 Grad: 83736.9922  LR: 0.00001997  \n","Epoch: [9][8500/15622] Elapsed 27m 7s (remain 22m 43s) Loss: 0.1930 Grad: 105103.2578  LR: 0.00001997  \n","Epoch: [9][9000/15622] Elapsed 28m 42s (remain 21m 6s) Loss: 0.1929 Grad: 80290.1484  LR: 0.00001997  \n","Epoch: [9][9500/15622] Elapsed 30m 17s (remain 19m 31s) Loss: 0.1927 Grad: 98644.8750  LR: 0.00001997  \n","Epoch: [9][10000/15622] Elapsed 31m 53s (remain 17m 55s) Loss: 0.1927 Grad: 89657.8125  LR: 0.00001996  \n","Epoch: [9][10500/15622] Elapsed 33m 27s (remain 16m 18s) Loss: 0.1927 Grad: 88241.4844  LR: 0.00001996  \n","Epoch: [9][11000/15622] Elapsed 35m 2s (remain 14m 43s) Loss: 0.1926 Grad: 90370.7656  LR: 0.00001996  \n","Epoch: [9][11500/15622] Elapsed 36m 38s (remain 13m 7s) Loss: 0.1923 Grad: 97314.8750  LR: 0.00001996  \n","Epoch: [9][12000/15622] Elapsed 38m 13s (remain 11m 32s) Loss: 0.1922 Grad: 93629.1484  LR: 0.00001996  \n","Epoch: [9][12500/15622] Elapsed 39m 47s (remain 9m 56s) Loss: 0.1921 Grad: 89764.3672  LR: 0.00001996  \n","Epoch: [9][13000/15622] Elapsed 41m 22s (remain 8m 20s) Loss: 0.1921 Grad: 98813.6250  LR: 0.00001996  \n","Epoch: [9][13500/15622] Elapsed 42m 57s (remain 6m 44s) Loss: 0.1921 Grad: 108178.3984  LR: 0.00001996  \n","Epoch: [9][14000/15622] Elapsed 44m 31s (remain 5m 9s) Loss: 0.1922 Grad: 72933.3281  LR: 0.00001996  \n","Epoch: [9][14500/15622] Elapsed 46m 5s (remain 3m 33s) Loss: 0.1920 Grad: 121506.0078  LR: 0.00001996  \n","Epoch: [9][15000/15622] Elapsed 47m 39s (remain 1m 58s) Loss: 0.1919 Grad: 88272.2422  LR: 0.00001996  \n","Epoch: [9][15500/15622] Elapsed 49m 13s (remain 0m 23s) Loss: 0.1917 Grad: 76389.0625  LR: 0.00001996  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 9: Train Loss 0.1918, elapsed 2976.3851s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [9][15621/15622] Elapsed 49m 36s (remain 0m 0s) Loss: 0.1918 Grad: 115436.5469  LR: 0.00001996  \n","Epoch: [10][0/15622] Elapsed 0m 0s (remain 60m 24s) Loss: 0.1684 Grad: 69516.3672  LR: 0.00001996  \n","Epoch: [10][500/15622] Elapsed 1m 45s (remain 53m 2s) Loss: 0.1819 Grad: 105049.3828  LR: 0.00001996  \n","Epoch: [10][1000/15622] Elapsed 3m 20s (remain 48m 44s) Loss: 0.1854 Grad: 110306.8906  LR: 0.00001996  \n","Epoch: [10][1500/15622] Elapsed 4m 55s (remain 46m 19s) Loss: 0.1857 Grad: 92074.4531  LR: 0.00001996  \n","Epoch: [10][2000/15622] Elapsed 6m 31s (remain 44m 25s) Loss: 0.1860 Grad: 92158.1562  LR: 0.00001996  \n","Epoch: [10][2500/15622] Elapsed 8m 6s (remain 42m 34s) Loss: 0.1860 Grad: 111127.7891  LR: 0.00001996  \n","Epoch: [10][3000/15622] Elapsed 9m 43s (remain 40m 54s) Loss: 0.1861 Grad: 93360.0234  LR: 0.00001996  \n","Epoch: [10][3500/15622] Elapsed 11m 18s (remain 39m 10s) Loss: 0.1869 Grad: 109110.6875  LR: 0.00001996  \n","Epoch: [10][4000/15622] Elapsed 12m 53s (remain 37m 26s) Loss: 0.1873 Grad: 81970.3516  LR: 0.00001996  \n","Epoch: [10][4500/15622] Elapsed 14m 28s (remain 35m 46s) Loss: 0.1871 Grad: 93960.8750  LR: 0.00001996  \n","Epoch: [10][5000/15622] Elapsed 16m 3s (remain 34m 7s) Loss: 0.1869 Grad: 99146.2578  LR: 0.00001996  \n","Epoch: [10][5500/15622] Elapsed 17m 38s (remain 32m 27s) Loss: 0.1870 Grad: 62100.0312  LR: 0.00001996  \n","Epoch: [10][6000/15622] Elapsed 19m 13s (remain 30m 49s) Loss: 0.1867 Grad: 79805.3203  LR: 0.00001996  \n","Epoch: [10][6500/15622] Elapsed 20m 47s (remain 29m 10s) Loss: 0.1866 Grad: 82885.2500  LR: 0.00001996  \n","Epoch: [10][7000/15622] Elapsed 22m 22s (remain 27m 33s) Loss: 0.1866 Grad: 98753.1953  LR: 0.00001996  \n","Epoch: [10][7500/15622] Elapsed 23m 57s (remain 25m 56s) Loss: 0.1865 Grad: 103699.4688  LR: 0.00001996  \n","Epoch: [10][8000/15622] Elapsed 25m 31s (remain 24m 18s) Loss: 0.1866 Grad: 124644.3984  LR: 0.00001996  \n","Epoch: [10][8500/15622] Elapsed 27m 5s (remain 22m 41s) Loss: 0.1868 Grad: 75433.1562  LR: 0.00001996  \n","Epoch: [10][9000/15622] Elapsed 28m 40s (remain 21m 5s) Loss: 0.1866 Grad: 99863.8047  LR: 0.00001996  \n","Epoch: [10][9500/15622] Elapsed 30m 14s (remain 19m 28s) Loss: 0.1865 Grad: 97051.2656  LR: 0.00001996  \n","Epoch: [10][10000/15622] Elapsed 31m 47s (remain 17m 52s) Loss: 0.1862 Grad: 62048.1250  LR: 0.00001996  \n","Epoch: [10][10500/15622] Elapsed 33m 21s (remain 16m 15s) Loss: 0.1860 Grad: 71022.0391  LR: 0.00001996  \n","Epoch: [10][11000/15622] Elapsed 34m 54s (remain 14m 39s) Loss: 0.1859 Grad: 90634.7188  LR: 0.00001996  \n","Epoch: [10][11500/15622] Elapsed 36m 27s (remain 13m 3s) Loss: 0.1859 Grad: 98819.1953  LR: 0.00001996  \n","Epoch: [10][12000/15622] Elapsed 38m 0s (remain 11m 27s) Loss: 0.1859 Grad: 117338.3906  LR: 0.00001996  \n","Epoch: [10][12500/15622] Elapsed 39m 32s (remain 9m 52s) Loss: 0.1856 Grad: 83373.2812  LR: 0.00001995  \n","Epoch: [10][13000/15622] Elapsed 41m 4s (remain 8m 16s) Loss: 0.1855 Grad: 92058.1641  LR: 0.00001995  \n","Epoch: [10][13500/15622] Elapsed 42m 37s (remain 6m 41s) Loss: 0.1854 Grad: 85043.0000  LR: 0.00001995  \n","Epoch: [10][14000/15622] Elapsed 44m 9s (remain 5m 6s) Loss: 0.1852 Grad: 108082.3125  LR: 0.00001995  \n","Epoch: [10][14500/15622] Elapsed 45m 40s (remain 3m 31s) Loss: 0.1851 Grad: 91020.0781  LR: 0.00001995  \n","Epoch: [10][15000/15622] Elapsed 47m 13s (remain 1m 57s) Loss: 0.1850 Grad: 82717.0938  LR: 0.00001995  \n","Epoch: [10][15500/15622] Elapsed 48m 45s (remain 0m 22s) Loss: 0.1850 Grad: 60095.5273  LR: 0.00001995  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 10: Train Loss 0.1850, elapsed 2948.0547s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [10][15621/15622] Elapsed 49m 8s (remain 0m 0s) Loss: 0.1850 Grad: 87651.4062  LR: 0.00001995  \n","Epoch: [11][0/15622] Elapsed 0m 0s (remain 56m 43s) Loss: 0.1706 Grad: 89788.8672  LR: 0.00001995  \n","Epoch: [11][500/15622] Elapsed 1m 41s (remain 51m 1s) Loss: 0.1822 Grad: 105637.6953  LR: 0.00001995  \n","Epoch: [11][1000/15622] Elapsed 3m 13s (remain 47m 11s) Loss: 0.1832 Grad: 105709.3672  LR: 0.00001995  \n","Epoch: [11][1500/15622] Elapsed 4m 46s (remain 44m 52s) Loss: 0.1823 Grad: 92253.1016  LR: 0.00001995  \n","Epoch: [11][2000/15622] Elapsed 6m 18s (remain 42m 57s) Loss: 0.1827 Grad: 108051.3047  LR: 0.00001995  \n","Epoch: [11][2500/15622] Elapsed 7m 50s (remain 41m 7s) Loss: 0.1823 Grad: 93790.1875  LR: 0.00001995  \n","Epoch: [11][3000/15622] Elapsed 9m 21s (remain 39m 23s) Loss: 0.1822 Grad: 85281.2734  LR: 0.00001995  \n","Epoch: [11][3500/15622] Elapsed 10m 54s (remain 37m 45s) Loss: 0.1821 Grad: 92487.6875  LR: 0.00001995  \n","Epoch: [11][4000/15622] Elapsed 12m 27s (remain 36m 12s) Loss: 0.1819 Grad: 76877.1250  LR: 0.00001995  \n","Epoch: [11][4500/15622] Elapsed 14m 2s (remain 34m 42s) Loss: 0.1817 Grad: 83616.9297  LR: 0.00001995  \n","Epoch: [11][5000/15622] Elapsed 15m 35s (remain 33m 6s) Loss: 0.1816 Grad: 98891.9531  LR: 0.00001995  \n","Epoch: [11][5500/15622] Elapsed 17m 7s (remain 31m 30s) Loss: 0.1813 Grad: 87882.0625  LR: 0.00001995  \n","Epoch: [11][6000/15622] Elapsed 18m 40s (remain 29m 55s) Loss: 0.1811 Grad: 99087.9531  LR: 0.00001995  \n","Epoch: [11][6500/15622] Elapsed 20m 12s (remain 28m 20s) Loss: 0.1809 Grad: 74462.2812  LR: 0.00001995  \n","Epoch: [11][7000/15622] Elapsed 21m 45s (remain 26m 47s) Loss: 0.1809 Grad: 100999.5703  LR: 0.00001995  \n","Epoch: [11][7500/15622] Elapsed 23m 18s (remain 25m 14s) Loss: 0.1807 Grad: 58053.9961  LR: 0.00001995  \n","Epoch: [11][8000/15622] Elapsed 24m 51s (remain 23m 40s) Loss: 0.1807 Grad: 178677.9375  LR: 0.00001995  \n","Epoch: [11][8500/15622] Elapsed 26m 25s (remain 22m 7s) Loss: 0.1805 Grad: 80425.3906  LR: 0.00001995  \n","Epoch: [11][9000/15622] Elapsed 27m 58s (remain 20m 34s) Loss: 0.1803 Grad: 76145.2188  LR: 0.00001995  \n","Epoch: [11][9500/15622] Elapsed 29m 30s (remain 19m 0s) Loss: 0.1801 Grad: 129859.5781  LR: 0.00001995  \n","Epoch: [11][10000/15622] Elapsed 31m 2s (remain 17m 27s) Loss: 0.1801 Grad: 90561.6484  LR: 0.00001995  \n","Epoch: [11][10500/15622] Elapsed 32m 35s (remain 15m 53s) Loss: 0.1801 Grad: 119698.7578  LR: 0.00001995  \n","Epoch: [11][11000/15622] Elapsed 34m 7s (remain 14m 20s) Loss: 0.1803 Grad: 125931.6641  LR: 0.00001995  \n","Epoch: [11][11500/15622] Elapsed 35m 39s (remain 12m 46s) Loss: 0.1803 Grad: 80955.7344  LR: 0.00001995  \n","Epoch: [11][12000/15622] Elapsed 37m 12s (remain 11m 13s) Loss: 0.1804 Grad: 116290.1719  LR: 0.00001995  \n","Epoch: [11][12500/15622] Elapsed 38m 45s (remain 9m 40s) Loss: 0.1802 Grad: 105281.2422  LR: 0.00001995  \n","Epoch: [11][13000/15622] Elapsed 40m 16s (remain 8m 7s) Loss: 0.1803 Grad: 84396.8047  LR: 0.00001994  \n","Epoch: [11][13500/15622] Elapsed 41m 49s (remain 6m 34s) Loss: 0.1803 Grad: 83744.8203  LR: 0.00001994  \n","Epoch: [11][14000/15622] Elapsed 43m 21s (remain 5m 1s) Loss: 0.1801 Grad: 110013.5938  LR: 0.00001994  \n","Epoch: [11][14500/15622] Elapsed 44m 55s (remain 3m 28s) Loss: 0.1801 Grad: 99994.7031  LR: 0.00001994  \n","Epoch: [11][15000/15622] Elapsed 46m 28s (remain 1m 55s) Loss: 0.1800 Grad: 89855.1953  LR: 0.00001994  \n","Epoch: [11][15500/15622] Elapsed 48m 1s (remain 0m 22s) Loss: 0.1798 Grad: 89861.7656  LR: 0.00001994  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 11: Train Loss 0.1798, elapsed 2903.1409s\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [11][15621/15622] Elapsed 48m 23s (remain 0m 0s) Loss: 0.1798 Grad: 86432.0391  LR: 0.00001994  \n","Epoch: [12][0/15622] Elapsed 0m 0s (remain 71m 31s) Loss: 0.1019 Grad: 67177.0000  LR: 0.00001994  \n","Epoch: [12][500/15622] Elapsed 1m 41s (remain 51m 8s) Loss: 0.1800 Grad: 132893.7812  LR: 0.00001994  \n","Epoch: [12][1000/15622] Elapsed 3m 13s (remain 47m 5s) Loss: 0.1783 Grad: 129994.8438  LR: 0.00001994  \n","Epoch: [12][1500/15622] Elapsed 4m 45s (remain 44m 44s) Loss: 0.1775 Grad: 76830.8984  LR: 0.00001994  \n","Epoch: [12][2000/15622] Elapsed 6m 17s (remain 42m 52s) Loss: 0.1775 Grad: 109596.2734  LR: 0.00001994  \n","Epoch: [12][2500/15622] Elapsed 7m 48s (remain 40m 59s) Loss: 0.1770 Grad: 83541.4531  LR: 0.00001994  \n","Epoch: [12][3000/15622] Elapsed 9m 21s (remain 39m 19s) Loss: 0.1769 Grad: 79250.1094  LR: 0.00001994  \n","Epoch: [12][3500/15622] Elapsed 10m 52s (remain 37m 38s) Loss: 0.1769 Grad: 79704.7891  LR: 0.00001994  \n","Epoch: [12][4000/15622] Elapsed 12m 24s (remain 36m 3s) Loss: 0.1770 Grad: 90086.1406  LR: 0.00001994  \n","Epoch: [12][4500/15622] Elapsed 13m 57s (remain 34m 28s) Loss: 0.1771 Grad: 96851.6875  LR: 0.00001994  \n","Epoch: [12][5000/15622] Elapsed 15m 28s (remain 32m 52s) Loss: 0.1772 Grad: 33010.6719  LR: 0.00001994  \n","Epoch: [12][5500/15622] Elapsed 17m 0s (remain 31m 17s) Loss: 0.1773 Grad: 37486.4375  LR: 0.00001994  \n","Epoch: [12][6000/15622] Elapsed 18m 32s (remain 29m 43s) Loss: 0.1776 Grad: 51620.6602  LR: 0.00001994  \n","Epoch: [12][6500/15622] Elapsed 20m 5s (remain 28m 10s) Loss: 0.1781 Grad: 47563.3594  LR: 0.00001994  \n","Epoch: [12][7000/15622] Elapsed 21m 36s (remain 26m 37s) Loss: 0.1781 Grad: 40503.6094  LR: 0.00001994  \n","Epoch: [12][7500/15622] Elapsed 23m 9s (remain 25m 4s) Loss: 0.1783 Grad: 57347.9023  LR: 0.00001994  \n","Epoch: [12][8000/15622] Elapsed 24m 41s (remain 23m 31s) Loss: 0.1789 Grad: 41621.2891  LR: 0.00001994  \n","Epoch: [12][8500/15622] Elapsed 26m 13s (remain 21m 58s) Loss: 0.1790 Grad: 41277.6289  LR: 0.00001994  \n","Epoch: [12][9000/15622] Elapsed 27m 46s (remain 20m 26s) Loss: 0.1791 Grad: 40895.4336  LR: 0.00001994  \n","Epoch: [12][9500/15622] Elapsed 29m 19s (remain 18m 53s) Loss: 0.1790 Grad: 35934.6719  LR: 0.00001994  \n","Epoch: [12][10000/15622] Elapsed 30m 51s (remain 17m 20s) Loss: 0.1790 Grad: 42747.2930  LR: 0.00001994  \n","Epoch: [12][10500/15622] Elapsed 32m 24s (remain 15m 48s) Loss: 0.1790 Grad: 34871.7734  LR: 0.00001994  \n","Epoch: [12][11000/15622] Elapsed 33m 57s (remain 14m 15s) Loss: 0.1792 Grad: 39836.5352  LR: 0.00001994  \n","Epoch: [12][11500/15622] Elapsed 35m 28s (remain 12m 42s) Loss: 0.1793 Grad: 39347.3125  LR: 0.00001994  \n","Epoch: [12][12000/15622] Elapsed 37m 0s (remain 11m 10s) Loss: 0.1794 Grad: 44051.6641  LR: 0.00001993  \n","Epoch: [12][12500/15622] Elapsed 38m 32s (remain 9m 37s) Loss: 0.1794 Grad: 67671.0391  LR: 0.00001993  \n","Epoch: [12][13000/15622] Elapsed 40m 3s (remain 8m 4s) Loss: 0.1794 Grad: 42539.5938  LR: 0.00001993  \n","Epoch: [12][13500/15622] Elapsed 41m 35s (remain 6m 32s) Loss: 0.1794 Grad: 38908.0273  LR: 0.00001993  \n","Epoch: [12][14000/15622] Elapsed 43m 7s (remain 4m 59s) Loss: 0.1794 Grad: 42088.0234  LR: 0.00001993  \n","Epoch: [12][14500/15622] Elapsed 44m 39s (remain 3m 27s) Loss: 0.1793 Grad: 50693.6875  LR: 0.00001993  \n","Epoch: [12][15000/15622] Elapsed 46m 11s (remain 1m 54s) Loss: 0.1792 Grad: 39615.1328  LR: 0.00001993  \n","Epoch: [12][15500/15622] Elapsed 47m 44s (remain 0m 22s) Loss: 0.1792 Grad: 40991.0078  LR: 0.00001993  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 12: Train Loss 0.1792, elapsed 2886.6191s\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [12][15621/15622] Elapsed 48m 6s (remain 0m 0s) Loss: 0.1792 Grad: 40001.1602  LR: 0.00001993  \n","Epoch: [13][0/15622] Elapsed 0m 0s (remain 63m 50s) Loss: 0.1742 Grad: 77735.8281  LR: 0.00001993  \n","Epoch: [13][500/15622] Elapsed 1m 43s (remain 51m 52s) Loss: 0.1768 Grad: 84145.0156  LR: 0.00001993  \n","Epoch: [13][1000/15622] Elapsed 3m 16s (remain 47m 49s) Loss: 0.1757 Grad: 91087.8984  LR: 0.00001993  \n","Epoch: [13][1500/15622] Elapsed 4m 49s (remain 45m 21s) Loss: 0.1747 Grad: 95914.7656  LR: 0.00001993  \n","Epoch: [13][2000/15622] Elapsed 6m 22s (remain 43m 22s) Loss: 0.1741 Grad: 107993.8828  LR: 0.00001993  \n","Epoch: [13][2500/15622] Elapsed 7m 55s (remain 41m 34s) Loss: 0.1728 Grad: 92399.5078  LR: 0.00001993  \n","Epoch: [13][3000/15622] Elapsed 9m 28s (remain 39m 51s) Loss: 0.1730 Grad: 90549.5156  LR: 0.00001993  \n","Epoch: [13][3500/15622] Elapsed 11m 1s (remain 38m 8s) Loss: 0.1737 Grad: 103059.1328  LR: 0.00001993  \n","Epoch: [13][4000/15622] Elapsed 12m 34s (remain 36m 32s) Loss: 0.1739 Grad: 54263.8398  LR: 0.00001993  \n","Epoch: [13][4500/15622] Elapsed 14m 7s (remain 34m 54s) Loss: 0.1742 Grad: 45593.4609  LR: 0.00001993  \n","Epoch: [13][5000/15622] Elapsed 15m 40s (remain 33m 17s) Loss: 0.1745 Grad: 29428.9375  LR: 0.00001993  \n","Epoch: [13][5500/15622] Elapsed 17m 13s (remain 31m 42s) Loss: 0.1746 Grad: 44821.7070  LR: 0.00001993  \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-c202dd6e1ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     LOGGER.info(\n","\u001b[0;32m<ipython-input-9-746312366df7>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(model, data_loader, optimizer, scheduler, CFG)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["CFG.global_step = 0\n","CFG.save_step = 25000\n","\n","for epoch in range(CFG.epochs):\n","    CFG.epoch = epoch\n","    start = time.time()\n","        \n","    train_loss = trainer(model, train_loader, optimizer, scheduler, CFG)\n","\n","    LOGGER.info(\n","        \"Epoch {}: Train Loss {:.4f}, elapsed {:.4f}s\".format(\n","            epoch + 1, train_loss, time.time() - start)\n","        )\n","    torch.save(\n","        model.state_dict(),\n","        str(OUTPUT_DIR / '{}-mlm-epoch-{}.bin'.format(\n","            CFG.model.replace('/', '-'),\n","            epoch + 1))\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6H4ZsRoKtQW","executionInfo":{"status":"aborted","timestamp":1649164406123,"user_tz":-540,"elapsed":3,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp073.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"005f948f01394319bd0d25b1710efbaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba1fd0a0d95c4bd9a57d0fe44060f8ec","placeholder":"​","style":"IPY_MODEL_e914306cf3e44eaaa74e710e1e4d5f82","value":" 1/1 [00:00&lt;00:00, 25.00it/s]"}},"0109dd308cb04d0786497a4152e78bab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_230b21d0f18c417198f558ea5e9d0bdd","IPY_MODEL_ccce250b5db94d94b19a5e4b6d822de2","IPY_MODEL_ea4ddd4cd9b745d8ae9e0f83ac710628"],"layout":"IPY_MODEL_b95b45ae5fc443a29ace285b23d3515f"}},"036f09461f4e46fe87e7088e758be7ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cff8b7fedcc4271836eb12dbee41d79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f625954347d40049f35aeb9d86d6a65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11406036650648a0ad3d3add0989dfdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12ea7a5274664c0a951c27e362dabf68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13e3b72595a440928c390e375bc60708":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13e660e2968940e7abff867bf4aa8ce2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14521830d1d24c61beac59f816f1396a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"160131b9bc70473fa27d89d989d2ac7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19a3990171d14eb6b66bdbe4a40e0c53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a9703d427ed481382237a75b442273f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5330ffe6a68149e9900508561f3fd25b","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c663d9616841495d969942d0ebb18ba9","value":2464616}},"1be2060aa806499db5255e241b1bf518":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2269f7a2ee2040e0928bbd0b7f450081":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"230b21d0f18c417198f558ea5e9d0bdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb5b632bb0e0423d939371de0216a431","placeholder":"​","style":"IPY_MODEL_67848d80cae448a39087ffb0cfca8aca","value":"Downloading: 100%"}},"272962ce28b84484af29abd549a1a01f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bf13ce818f5436cbcad478a04caca91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e0298183be641cf9a832aa2c48fe2b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b9c2b22f17041d68c313a3ee4df8b3f","placeholder":"​","style":"IPY_MODEL_c84066dee1ce41f0a7107c2da776580f","value":"Downloading: 100%"}},"39df27d4fc49489c92f0abdd04840086":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bd3c082d6734d518f4013ce26e892c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c133338395040baadec82002a079fce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93f86e5f79524ffcaeaa81c73f74a3e1","IPY_MODEL_ab5f6671b49d456bb2918208a5b25d8e","IPY_MODEL_9957f44492224e2caf4357250a1a251c"],"layout":"IPY_MODEL_13e3b72595a440928c390e375bc60708"}},"3de39728397d459b955edc17daca2331":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507f671b3d93440798dc0cfe9b00721d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50daa8438b98410d999ce75b177434d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5217788e32904d6c923105b58e862927":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2db800c33f54071aff8bd24a608da9e","IPY_MODEL_aa5444bc09b347f79844de70330da7c4","IPY_MODEL_cf35f0dc63954104a2f0534b5e52fd28"],"layout":"IPY_MODEL_036f09461f4e46fe87e7088e758be7ec"}},"5330ffe6a68149e9900508561f3fd25b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b40d18e533c46888a83666000d702eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bacde0cbcef944f0971fc241f326d521","IPY_MODEL_a0c9e0cfa9104777ac14124ba4b3d8b3","IPY_MODEL_e852b24e3c34484c98301fc9c4612bd4"],"layout":"IPY_MODEL_6afb3ba4d1774206bde923140d4fd8ef"}},"67848d80cae448a39087ffb0cfca8aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6afb3ba4d1774206bde923140d4fd8ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bfa87cf0b6e4bb5a65c1b11b4094e0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74ed29d22799436ea3d3783a0d4e26fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d21d9ef4ca1c42a0a2aa7951931d32e2","IPY_MODEL_e31b7c7e865d4347b91cc173b1fd6905","IPY_MODEL_005f948f01394319bd0d25b1710efbaf"],"layout":"IPY_MODEL_aa2478c174f14e918d8cdc1f6407af0b"}},"762ef75cdaa94a1aa07e70c39b2c6845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b039e613167470a9d2f95ea86b36446":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e0298183be641cf9a832aa2c48fe2b3","IPY_MODEL_1a9703d427ed481382237a75b442273f","IPY_MODEL_d2c71f10274c4f0cb47148c0676d670e"],"layout":"IPY_MODEL_39df27d4fc49489c92f0abdd04840086"}},"84a6a9552b4f4b0cb587bbc1b5e8b9e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f14544b70ec45a68f2181b0c0c7defc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f43c375803a4e59814d857413b0a254":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92a875e3c34243b4b6970a1d3b94db7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93f86e5f79524ffcaeaa81c73f74a3e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bf13ce818f5436cbcad478a04caca91","placeholder":"​","style":"IPY_MODEL_507f671b3d93440798dc0cfe9b00721d","value":"100%"}},"9957f44492224e2caf4357250a1a251c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f43c375803a4e59814d857413b0a254","placeholder":"​","style":"IPY_MODEL_3bd3c082d6734d518f4013ce26e892c2","value":" 1/1 [00:00&lt;00:00, 25.09it/s]"}},"9b9c2b22f17041d68c313a3ee4df8b3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0c9e0cfa9104777ac14124ba4b3d8b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3de39728397d459b955edc17daca2331","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_762ef75cdaa94a1aa07e70c39b2c6845","value":580}},"a2c821291b23425a9799312833c74432":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3ab76a47bb84a969990ee1e3500439f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4e7d46eff3f45cb90813fafe6d9dda6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d14f229b26624a3cb99b86abd880d315","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84a6a9552b4f4b0cb587bbc1b5e8b9e5","value":873673253}},"a63e8722a9954338bb39a30929481b06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13e660e2968940e7abff867bf4aa8ce2","placeholder":"​","style":"IPY_MODEL_1be2060aa806499db5255e241b1bf518","value":" 833M/833M [00:16&lt;00:00, 46.5MB/s]"}},"aa2478c174f14e918d8cdc1f6407af0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa5444bc09b347f79844de70330da7c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_160131b9bc70473fa27d89d989d2ac7c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92a875e3c34243b4b6970a1d3b94db7d","value":1}},"ab5f6671b49d456bb2918208a5b25d8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be600a39ef2f41bb9f098b91190b8f8d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2c821291b23425a9799312833c74432","value":1}},"af117d2669c94af3a4a8010e68a85387":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af6ce36b4735443ea9c7456d6c220bf7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ae525735a24fea834a9491f06c8755":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da5a8c32ca3e4b97ad423556adcc4467","IPY_MODEL_a4e7d46eff3f45cb90813fafe6d9dda6","IPY_MODEL_a63e8722a9954338bb39a30929481b06"],"layout":"IPY_MODEL_a3ab76a47bb84a969990ee1e3500439f"}},"b95b45ae5fc443a29ace285b23d3515f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba1fd0a0d95c4bd9a57d0fe44060f8ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bacde0cbcef944f0971fc241f326d521":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af6ce36b4735443ea9c7456d6c220bf7","placeholder":"​","style":"IPY_MODEL_11406036650648a0ad3d3add0989dfdc","value":"Downloading: 100%"}},"bd6f44af8a0a4ed7b70a6cac56114471":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be600a39ef2f41bb9f098b91190b8f8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1fc032086694052b55c0db015ec4af5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c663d9616841495d969942d0ebb18ba9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c84066dee1ce41f0a7107c2da776580f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb5b632bb0e0423d939371de0216a431":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccce250b5db94d94b19a5e4b6d822de2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f14544b70ec45a68f2181b0c0c7defc","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0cff8b7fedcc4271836eb12dbee41d79","value":52}},"cf35f0dc63954104a2f0534b5e52fd28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_272962ce28b84484af29abd549a1a01f","placeholder":"​","style":"IPY_MODEL_6bfa87cf0b6e4bb5a65c1b11b4094e0b","value":" 1/1 [00:00&lt;00:00, 16.22it/s]"}},"d0fa80a0274d477fbf455fae913bc09a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14f229b26624a3cb99b86abd880d315":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d21d9ef4ca1c42a0a2aa7951931d32e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb88c740cb5943449c9dd6d7c875d6f6","placeholder":"​","style":"IPY_MODEL_e0eb9f790ab840e5b31f674f18d95bf0","value":"100%"}},"d2c71f10274c4f0cb47148c0676d670e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd74fd69bfef406699fc9c36dcc9e1f7","placeholder":"​","style":"IPY_MODEL_12ea7a5274664c0a951c27e362dabf68","value":" 2.35M/2.35M [00:00&lt;00:00, 8.35MB/s]"}},"d2f0b2f31420463e9421793871921000":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da5a8c32ca3e4b97ad423556adcc4467":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af117d2669c94af3a4a8010e68a85387","placeholder":"​","style":"IPY_MODEL_14521830d1d24c61beac59f816f1396a","value":"Downloading: 100%"}},"e0eb9f790ab840e5b31f674f18d95bf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2db800c33f54071aff8bd24a608da9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f625954347d40049f35aeb9d86d6a65","placeholder":"​","style":"IPY_MODEL_2269f7a2ee2040e0928bbd0b7f450081","value":"100%"}},"e31b7c7e865d4347b91cc173b1fd6905":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd6f44af8a0a4ed7b70a6cac56114471","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1fc032086694052b55c0db015ec4af5","value":1}},"e852b24e3c34484c98301fc9c4612bd4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0fa80a0274d477fbf455fae913bc09a","placeholder":"​","style":"IPY_MODEL_19a3990171d14eb6b66bdbe4a40e0c53","value":" 580/580 [00:00&lt;00:00, 18.1kB/s]"}},"e914306cf3e44eaaa74e710e1e4d5f82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea4ddd4cd9b745d8ae9e0f83ac710628":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2f0b2f31420463e9421793871921000","placeholder":"​","style":"IPY_MODEL_50daa8438b98410d999ce75b177434d1","value":" 52.0/52.0 [00:00&lt;00:00, 1.49kB/s]"}},"eb88c740cb5943449c9dd6d7c875d6f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd74fd69bfef406699fc9c36dcc9e1f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}