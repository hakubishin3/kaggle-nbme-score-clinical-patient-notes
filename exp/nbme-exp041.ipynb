{"cells":[{"cell_type":"markdown","metadata":{"id":"uniform-bangkok"},"source":["## References"],"id":"uniform-bangkok"},{"cell_type":"markdown","metadata":{"id":"addressed-fitting"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"],"id":"addressed-fitting"},{"cell_type":"markdown","metadata":{"id":"concerned-services"},"source":["## Configurations"],"id":"concerned-services"},{"cell_type":"code","execution_count":null,"metadata":{"id":"smoking-english"},"outputs":[],"source":["EXP_NAME = \"nbme-exp041\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"],"id":"smoking-english"},{"cell_type":"code","execution_count":null,"metadata":{"id":"appropriate-carol"},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=2\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    loss='bce' # ['bce', 'ce']\n","    alpha=1\n","    gamma=2\n","    smoothing=0.0001\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=4\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"],"id":"appropriate-carol"},{"cell_type":"code","execution_count":null,"metadata":{"id":"amber-confidence"},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"],"id":"amber-confidence"},{"cell_type":"markdown","metadata":{"id":"integral-nutrition"},"source":["## Directory Settings"],"id":"integral-nutrition"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13318,"status":"ok","timestamp":1647391791399,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"synthetic-portfolio","outputId":"aa12900e-f5b6-4a72-8c8e-4659bc53e6b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers\n","    !pip install sentencepiece\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"],"id":"synthetic-portfolio"},{"cell_type":"code","execution_count":null,"metadata":{"id":"communist-principle"},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"id":"communist-principle"},{"cell_type":"markdown","metadata":{"id":"integrated-tractor"},"source":["## Utilities"],"id":"integrated-tractor"},{"cell_type":"code","execution_count":null,"metadata":{"id":"statewide-methodology"},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"],"id":"statewide-methodology"},{"cell_type":"code","execution_count":null,"metadata":{"id":"alert-internet"},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"],"id":"alert-internet"},{"cell_type":"code","execution_count":null,"metadata":{"id":"packed-number"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"id":"packed-number"},{"cell_type":"code","execution_count":null,"metadata":{"id":"thousand-government"},"outputs":[],"source":["seed_everything()"],"id":"thousand-government"},{"cell_type":"markdown","metadata":{"id":"fluid-sympathy"},"source":["## Data Loading"],"id":"fluid-sympathy"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1647391800304,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"alive-dairy","outputId":"ebf3d999-3542-4fb9-f211-f990bafba89c"},"outputs":[{"data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"],"id":"alive-dairy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"warming-custom"},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"],"id":"warming-custom"},{"cell_type":"markdown","metadata":{"id":"three-founder"},"source":["## Preprocessing"],"id":"three-founder"},{"cell_type":"code","execution_count":null,"metadata":{"id":"utility-surface"},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"],"id":"utility-surface"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647391800304,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"naval-mexican","outputId":"a36406fe-9b78-4279-f1cd-4b948a3274fc"},"outputs":[{"data":{"text/plain":["((14300, 8), (5, 6))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"],"id":"naval-mexican"},{"cell_type":"code","execution_count":null,"metadata":{"id":"excellent-father"},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"],"id":"excellent-father"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647391800697,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"multiple-making","outputId":"8c1db027-f120-444f-f6af-ae4c3f8d7f54"},"outputs":[{"data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"],"id":"multiple-making"},{"cell_type":"markdown","metadata":{"id":"concerned-wilson"},"source":["## CV split"],"id":"concerned-wilson"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647391800698,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"allied-oriental","outputId":"67955664-3c42-4460-df73-2b8e0ecbb81e"},"outputs":[{"data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"],"id":"allied-oriental"},{"cell_type":"markdown","metadata":{"id":"indie-hands"},"source":["## Setup tokenizer"],"id":"indie-hands"},{"cell_type":"code","execution_count":null,"metadata":{"id":"placed-pavilion"},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\", trim_offsets=False)\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name, trim_offsets=False)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"],"id":"placed-pavilion"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647391805600,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"abandoned-offer","outputId":"bc1c50be-ef6c-4461-f441-5081812492c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}],"source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"],"id":"abandoned-offer"},{"cell_type":"markdown","metadata":{"id":"secure-mattress"},"source":["## Create dataset"],"id":"secure-mattress"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["804143bbdc894a9e9d217e8341a6f5e8","b67290b23f7743a8940f1786fd62c420","55ac100ee9454506bafed861979a98af","19553a7a76bd4cbb961d971391e377f5","315e2287c4474aca80d6650069881c64","400714f150d64e0785fc04856af6232c","9f2f0ee40a31436eb216000ef3f11563","d4737cc39a6340389e1c55638a4c477e","14a952eacf8c4d90936a9ad04d86be58","b41bb17e82c040638fa4343086f8c3c1","de5f2795155447219dfeb4b772bbad2f"]},"executionInfo":{"elapsed":36681,"status":"ok","timestamp":1647391842275,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"phantom-reverse","outputId":"02bc11a8-f529-4f00-9f4b-959939b431e8"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"804143bbdc894a9e9d217e8341a6f5e8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"],"id":"phantom-reverse"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["a3e5bdf2bb454162a7d53e2eb495b2ae","cc71e7f8d1654888b1825dd16e4e8b8f","8ffc7f496aed4ee78f8eb4bfba37b657","bc346217d9974441989d171cd0bc2790","a5f73808ceec46cebdfad18e8dede294","bc6a2e70a90640f8a8ff51b0671744e0","ff70987fd36c4e299f711c48db3da431","f1feab8ab0b4489aa00d7230eb653c4c","ba2ea79c94034391b4eb66b222743251","7516bd3698ca4a33ae2ee85ef72b35cf","b00f5f81ec48436a84488f58f76a26c2"]},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1647391842276,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"helpful-obligation","outputId":"ae1fe0a6-cb9b-4ff8-bc0a-17317e151a61"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3e5bdf2bb454162a7d53e2eb495b2ae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"],"id":"helpful-obligation"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1647391842276,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"happy-buyer","outputId":"25f3a608-568d-4033-962c-68871e5af32a"},"outputs":[{"name":"stdout","output_type":"stream","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"],"id":"happy-buyer"},{"cell_type":"code","execution_count":null,"metadata":{"id":"therapeutic-handy"},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"],"id":"therapeutic-handy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"handed-teens"},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"],"id":"handed-teens"},{"cell_type":"markdown","metadata":{"id":"familiar-football"},"source":["## Model"],"id":"familiar-football"},{"cell_type":"code","execution_count":null,"metadata":{"id":"prospective-flour"},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            #path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"],"id":"prospective-flour"},{"cell_type":"markdown","metadata":{"id":"domestic-prerequisite"},"source":["## Training"],"id":"domestic-prerequisite"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJcvpYFqbqaa"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2):\n","        super().__init__()\n","        self.reduction = reduction\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, inputs, targets):\n","        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n","        pt = torch.exp(-bce_loss)\n","        loss = self.alpha * (1. - pt)**self.gamma * bce_loss\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","\n","class SmoothFocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2, smoothing=0.0):\n","        super().__init__()\n","        self.reduction = reduction\n","        self.focal_loss = FocalLoss(reduction='none', alpha=alpha, gamma=gamma)\n","        self.smoothing = smoothing\n","\n","    @staticmethod\n","    def _smooth(targets:torch.Tensor, smoothing=0.0):\n","        assert 0 <= smoothing < 1\n","        with torch.no_grad():\n","            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n","        return targets\n","\n","    def forward(self, inputs, targets):\n","        targets = SmoothFocalLoss._smooth(targets, self.smoothing)\n","        loss = self.focal_loss(inputs, targets)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","    \n","class CEFocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2):\n","        super(CEFocalLoss, self).__init__()\n","        self.reduction = reduction\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        loss = self.alpha * (1. - pt)**self.gamma * ce_loss\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","    \n","class SmoothCEFocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2, smoothing=0.0):\n","        super(SmoothCEFocalLoss, self).__init__()\n","        self.reduction = reduction\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.smoothing = smoothing\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.smoothing) # torch >= 1.10.0\n","        pt = torch.exp(-ce_loss)\n","        loss = self.alpha * (1. - pt)**self.gamma * ce_loss\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"],"id":"TJcvpYFqbqaa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"sticky-blink"},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"],"id":"sticky-blink"},{"cell_type":"code","execution_count":null,"metadata":{"id":"medium-completion"},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"],"id":"medium-completion"},{"cell_type":"code","execution_count":null,"metadata":{"id":"excellent-eligibility"},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"],"id":"excellent-eligibility"},{"cell_type":"code","execution_count":null,"metadata":{"id":"subject-chapel"},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    if CFG.loss == 'bce':\n","        criterion = SmoothFocalLoss(reduction='none', alpha=CFG.alpha, gamma=CFG.gamma, smoothing=CFG.smoothing)\n","    elif CFG.loss == 'ce':\n","        criterion = CEFocalLoss(reduction='none', alpha=CFG.alpha, gamma=CFG.gamma)\n","    best_score = -1 * np.inf\n","  \n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"],"id":"subject-chapel"},{"cell_type":"markdown","metadata":{"id":"monetary-state"},"source":["## Main"],"id":"monetary-state"},{"cell_type":"code","execution_count":null,"metadata":{"id":"selected-maple"},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"],"id":"selected-maple"},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2bf06bcc08444ba7949645b547ce3fc8","cb8759124bbb4dbf8531874f81b03767","601929a1404647aab5beff525b6714bc","0eece35b85a84108bbf4c42b2407e566","ed098845954245749ca99d61ea587c78","87e24105108d4222878f5e3774fe09ff","94c0d72371b6494389d2860bb4e8ce83","6bbcc64b7629448ca287b84b800ebcf0","31409bb7aeff4a78af049eabd47f3b85","45b8a5b6a04b4049a0f8ca5e21b5232d","01fcc07086b24317a1185dcb97af2b8d","1392b34e5d074358bb2a0c16470bdf4c","e66850f233a443568fcf0e536b43cab4","6f1b159b97834c6fb3e3843da242e6a0","fdc1bd9ab36f4fac8d640f36dcc98641","d0fc43acc0ba4bb098ff60443e2dd9ab","76ba5e3f50394ef59b56e1213dceed26","7d94afcbb52d4b6abf3cddb49ef7de54","af70803daf8e480f8a01a8a8d912983c","8f5e6a8fe94f421fb3f7efeb5268ae0d","7e5f473e8ed7498cbb7e4689e382a47c","583501f192d64dbb9b4e363aa8ac90a5","993d695a47d249e898cee3720dbe69b4","fef5536e97d14092b051b333666a2931","0f6fdb43f8c149b7b5ad0b37038a901f","44c64b7d43c241f6aaf68520aaf286f9","fd5ae17ab6944b4cb5afb8f7df65fb36","f9e597d2b1174b26bcf698674bb02fd6","5e986625aa044d7d93e9f6db35e4358c","67aeb5f7801c4f07afe9868aef52e02f","179bae4b6ef74209b0c0c410b02dc894","f3fcda60f5ca4fe2bad82b7161c16747","1f8a920d1c4246059c947b8770914fdb","d5cd33c6a0ae473fa03155b7c7c43e9b","2764653fd14f43e38f5bbf9098cb4d59","1e1befb3f6204e9cae66bc4d243f6fcb","76909d22e1f8450691077e44519db540","56e8876d9cab4782b03d7186e3c45e2c","d238593b3ded40c9b36eb748bb23882b","2255d6b6e91646948d49b044e7a4c09e","0a0a4142255c4b17b98188c7d16885ea","c49b4911542f42ecb890df5bd5fd6431","1e56ed2d220f4d6da58bb3d182c8c6cc","825417eb400b47c8a283f9a4816e5551"]},"id":"local-thesis","executionInfo":{"status":"ok","timestamp":1647423370565,"user_tz":-540,"elapsed":6658274,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"a39c272e-ed81-4b39-aa63-19687a374905"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 0s (remain 66m 1s) Loss: 0.1131(0.1131) Grad: 164688.8281  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 0m 24s (remain 21m 23s) Loss: 0.0658(0.0544) Grad: 102378.6641  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 0m 48s (remain 20m 48s) Loss: 0.0263(0.0513) Grad: 34466.4688  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 1m 14s (remain 20m 44s) Loss: 0.0240(0.0451) Grad: 19269.4531  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 1m 37s (remain 20m 11s) Loss: 0.0081(0.0374) Grad: 2124.8350  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 2m 2s (remain 19m 44s) Loss: 0.0083(0.0315) Grad: 2547.2539  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 2m 25s (remain 19m 15s) Loss: 0.0069(0.0275) Grad: 2904.6274  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 2m 49s (remain 18m 48s) Loss: 0.0056(0.0245) Grad: 1769.6469  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 3m 13s (remain 18m 21s) Loss: 0.0027(0.0223) Grad: 3174.1245  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 3m 37s (remain 17m 55s) Loss: 0.0025(0.0205) Grad: 1949.1068  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 4m 1s (remain 17m 30s) Loss: 0.0061(0.0191) Grad: 2405.3794  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 4m 25s (remain 17m 5s) Loss: 0.0021(0.0179) Grad: 1274.0527  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 4m 48s (remain 16m 40s) Loss: 0.0074(0.0168) Grad: 4857.0933  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 5m 12s (remain 16m 15s) Loss: 0.0027(0.0159) Grad: 2389.0237  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 5m 36s (remain 15m 51s) Loss: 0.0007(0.0150) Grad: 1919.5126  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 6m 0s (remain 15m 26s) Loss: 0.0008(0.0142) Grad: 1928.9304  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 6m 24s (remain 15m 2s) Loss: 0.0005(0.0135) Grad: 600.2064  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 6m 47s (remain 14m 37s) Loss: 0.0005(0.0128) Grad: 448.6847  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 7m 11s (remain 14m 13s) Loss: 0.0003(0.0123) Grad: 575.8078  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 7m 35s (remain 13m 49s) Loss: 0.0009(0.0118) Grad: 2910.2571  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 7m 59s (remain 13m 25s) Loss: 0.0003(0.0113) Grad: 317.6201  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 8m 23s (remain 13m 1s) Loss: 0.0043(0.0109) Grad: 6467.1719  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 8m 47s (remain 12m 37s) Loss: 0.0009(0.0105) Grad: 4674.9922  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 9m 11s (remain 12m 13s) Loss: 0.0000(0.0101) Grad: 66.2310  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 9m 35s (remain 11m 49s) Loss: 0.0009(0.0098) Grad: 5805.8369  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 9m 59s (remain 11m 25s) Loss: 0.0011(0.0094) Grad: 1188.7341  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 10m 22s (remain 11m 1s) Loss: 0.0006(0.0091) Grad: 868.1917  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 10m 46s (remain 10m 37s) Loss: 0.0004(0.0089) Grad: 630.0297  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 11m 10s (remain 10m 13s) Loss: 0.0001(0.0086) Grad: 232.6392  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 11m 34s (remain 9m 48s) Loss: 0.0015(0.0084) Grad: 2596.6406  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 11m 57s (remain 9m 24s) Loss: 0.0002(0.0081) Grad: 405.2574  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 12m 21s (remain 9m 0s) Loss: 0.0033(0.0079) Grad: 8829.5176  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 12m 45s (remain 8m 36s) Loss: 0.0002(0.0077) Grad: 490.6292  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 13m 9s (remain 8m 12s) Loss: 0.0003(0.0075) Grad: 570.8539  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 13m 32s (remain 7m 48s) Loss: 0.0011(0.0074) Grad: 1515.6882  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 13m 56s (remain 7m 24s) Loss: 0.0003(0.0072) Grad: 1104.7815  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 14m 20s (remain 7m 0s) Loss: 0.0001(0.0071) Grad: 211.8129  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 14m 44s (remain 6m 36s) Loss: 0.0000(0.0069) Grad: 71.6364  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 15m 8s (remain 6m 12s) Loss: 0.0035(0.0068) Grad: 27422.6934  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 15m 31s (remain 5m 49s) Loss: 0.0013(0.0066) Grad: 2896.6287  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 15m 55s (remain 5m 25s) Loss: 0.0003(0.0065) Grad: 1652.3577  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 16m 19s (remain 5m 1s) Loss: 0.0004(0.0064) Grad: 854.5815  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 16m 43s (remain 4m 37s) Loss: 0.0005(0.0063) Grad: 605.2438  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 17m 6s (remain 4m 13s) Loss: 0.0006(0.0062) Grad: 761.9745  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 17m 30s (remain 3m 49s) Loss: 0.0009(0.0061) Grad: 894.0559  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 17m 54s (remain 3m 25s) Loss: 0.0003(0.0060) Grad: 549.4672  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 18m 18s (remain 3m 1s) Loss: 0.0000(0.0059) Grad: 4.4171  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 18m 42s (remain 2m 37s) Loss: 0.0007(0.0058) Grad: 5243.9819  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 19m 5s (remain 2m 13s) Loss: 0.0014(0.0057) Grad: 4564.1372  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 19m 29s (remain 1m 50s) Loss: 0.0008(0.0056) Grad: 3030.8528  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 19m 53s (remain 1m 26s) Loss: 0.0008(0.0055) Grad: 746.1566  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 20m 17s (remain 1m 2s) Loss: 0.0000(0.0054) Grad: 116.4999  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 20m 41s (remain 0m 38s) Loss: 0.0039(0.0053) Grad: 5140.4702  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 21m 5s (remain 0m 14s) Loss: 0.0003(0.0053) Grad: 886.3487  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 21m 19s (remain 0m 0s) Loss: 0.0003(0.0052) Grad: 1085.7333  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 11s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0001(0.0011) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 14s) Loss: 0.0047(0.0012) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0078(0.0012) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0018(0.0012) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0012) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 24s) Loss: 0.0006(0.0011) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 11s) Loss: 0.0014(0.0011) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0005(0.0010) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0087(0.0011) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0001(0.0013) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0015) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0002(0.0014) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0000(0.0015) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0001(0.0014) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0014) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0014) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0008(0.0013) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0001(0.0013) \n","Epoch 1 - avg_train_loss: 0.0052  avg_val_loss: 0.0013  time: 1502s\n","Epoch 1 - Score: 0.8419\n","Epoch 1 - Save Best Score: 0.8419 Model\n","Epoch: [2][0/5362] Elapsed 0m 0s (remain 52m 39s) Loss: 0.0003(0.0003) Grad: 1442.3551  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 0m 30s (remain 26m 12s) Loss: 0.0000(0.0010) Grad: 151.0920  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 0m 54s (remain 23m 30s) Loss: 0.0000(0.0008) Grad: 32.5955  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 1m 18s (remain 22m 2s) Loss: 0.0001(0.0009) Grad: 287.7761  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 1m 42s (remain 21m 8s) Loss: 0.0137(0.0010) Grad: 17448.1523  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 2m 6s (remain 20m 26s) Loss: 0.0013(0.0010) Grad: 2978.8579  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 2m 30s (remain 19m 49s) Loss: 0.0001(0.0010) Grad: 869.1754  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 2m 53s (remain 19m 16s) Loss: 0.0000(0.0011) Grad: 58.8908  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 3m 17s (remain 18m 46s) Loss: 0.0006(0.0011) Grad: 1911.9935  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 3m 41s (remain 18m 16s) Loss: 0.0026(0.0011) Grad: 4434.0605  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 4m 5s (remain 17m 48s) Loss: 0.0000(0.0011) Grad: 43.4119  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 4m 29s (remain 17m 21s) Loss: 0.0009(0.0011) Grad: 1800.4645  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 4m 52s (remain 16m 54s) Loss: 0.0002(0.0011) Grad: 1418.8522  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 5m 16s (remain 16m 28s) Loss: 0.0001(0.0011) Grad: 457.1217  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 5m 40s (remain 16m 3s) Loss: 0.0014(0.0011) Grad: 10796.7246  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 6m 4s (remain 15m 37s) Loss: 0.0000(0.0011) Grad: 129.4725  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 6m 28s (remain 15m 12s) Loss: 0.0005(0.0011) Grad: 2527.5769  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 6m 51s (remain 14m 46s) Loss: 0.0000(0.0011) Grad: 425.9328  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 7m 15s (remain 14m 21s) Loss: 0.0000(0.0011) Grad: 174.7201  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 7m 39s (remain 13m 56s) Loss: 0.0006(0.0011) Grad: 2033.1947  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 8m 3s (remain 13m 31s) Loss: 0.0000(0.0011) Grad: 172.9161  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 8m 26s (remain 13m 6s) Loss: 0.0000(0.0012) Grad: 54.4294  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 8m 50s (remain 12m 42s) Loss: 0.0013(0.0012) Grad: 6310.1030  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 9m 14s (remain 12m 17s) Loss: 0.0000(0.0012) Grad: 111.2633  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 9m 38s (remain 11m 52s) Loss: 0.0000(0.0011) Grad: 21.5324  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 10m 1s (remain 11m 28s) Loss: 0.0049(0.0011) Grad: 12227.5176  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 10m 25s (remain 11m 4s) Loss: 0.0033(0.0011) Grad: 7167.8164  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 10m 49s (remain 10m 39s) Loss: 0.0000(0.0011) Grad: 229.6342  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 11m 13s (remain 10m 15s) Loss: 0.0000(0.0011) Grad: 80.6842  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 11m 37s (remain 9m 51s) Loss: 0.0011(0.0011) Grad: 2790.0139  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 12m 0s (remain 9m 26s) Loss: 0.0001(0.0011) Grad: 598.1100  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 12m 24s (remain 9m 2s) Loss: 0.0037(0.0011) Grad: 18878.2188  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 12m 47s (remain 8m 38s) Loss: 0.0000(0.0011) Grad: 51.2570  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 13m 11s (remain 8m 14s) Loss: 0.0002(0.0011) Grad: 776.7205  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 13m 35s (remain 7m 49s) Loss: 0.0003(0.0011) Grad: 899.9040  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 13m 58s (remain 7m 25s) Loss: 0.0001(0.0011) Grad: 407.8715  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 14m 22s (remain 7m 1s) Loss: 0.0002(0.0011) Grad: 1319.0671  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 14m 45s (remain 6m 37s) Loss: 0.0006(0.0011) Grad: 2394.3540  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 15m 9s (remain 6m 13s) Loss: 0.0000(0.0011) Grad: 129.8923  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 15m 32s (remain 5m 49s) Loss: 0.0000(0.0011) Grad: 115.2071  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 15m 56s (remain 5m 25s) Loss: 0.0000(0.0011) Grad: 136.3057  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 16m 20s (remain 5m 1s) Loss: 0.0001(0.0011) Grad: 1195.3761  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 16m 43s (remain 4m 37s) Loss: 0.0000(0.0011) Grad: 179.7646  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 17m 7s (remain 4m 13s) Loss: 0.0000(0.0011) Grad: 4.4293  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 17m 31s (remain 3m 49s) Loss: 0.0004(0.0011) Grad: 1345.3491  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 17m 55s (remain 3m 25s) Loss: 0.0002(0.0011) Grad: 570.2288  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 18m 18s (remain 3m 1s) Loss: 0.0010(0.0011) Grad: 18302.4844  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 18m 42s (remain 2m 37s) Loss: 0.0002(0.0011) Grad: 891.4520  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 19m 5s (remain 2m 13s) Loss: 0.0001(0.0011) Grad: 572.8176  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 19m 29s (remain 1m 49s) Loss: 0.0001(0.0011) Grad: 406.5361  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 19m 53s (remain 1m 26s) Loss: 0.0000(0.0011) Grad: 10.9504  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 20m 16s (remain 1m 2s) Loss: 0.0000(0.0011) Grad: 1.6249  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 20m 40s (remain 0m 38s) Loss: 0.0004(0.0011) Grad: 898.5525  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 21m 3s (remain 0m 14s) Loss: 0.0113(0.0011) Grad: 9750.0811  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 21m 18s (remain 0m 0s) Loss: 0.0001(0.0011) Grad: 499.1392  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 0s) Loss: 0.0002(0.0002) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0000(0.0009) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0000(0.0010) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0030(0.0009) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0021(0.0009) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 37s) Loss: 0.0000(0.0009) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0006(0.0009) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 11s) Loss: 0.0006(0.0009) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0007(0.0009) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0057(0.0009) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0000(0.0011) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0013) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0001(0.0013) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0000(0.0013) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0013) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0012) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0012) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0003(0.0012) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0000(0.0012) \n","Epoch 2 - avg_train_loss: 0.0011  avg_val_loss: 0.0012  time: 1499s\n","Epoch 2 - Score: 0.8680\n","Epoch 2 - Save Best Score: 0.8680 Model\n","Epoch: [3][0/5362] Elapsed 0m 0s (remain 55m 0s) Loss: 0.0008(0.0008) Grad: 1997.2708  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 0m 27s (remain 23m 59s) Loss: 0.0000(0.0007) Grad: 6.7063  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 0m 53s (remain 22m 41s) Loss: 0.0031(0.0007) Grad: 6151.8091  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 1m 16s (remain 21m 28s) Loss: 0.0006(0.0009) Grad: 1818.3635  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 1m 40s (remain 20m 39s) Loss: 0.0000(0.0009) Grad: 30.0922  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 2m 3s (remain 20m 0s) Loss: 0.0000(0.0008) Grad: 13.6772  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 2m 27s (remain 19m 27s) Loss: 0.0028(0.0009) Grad: 11201.4561  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 2m 50s (remain 18m 56s) Loss: 0.0043(0.0009) Grad: 11317.7812  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 3m 14s (remain 18m 27s) Loss: 0.0001(0.0009) Grad: 321.4563  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 3m 38s (remain 18m 0s) Loss: 0.0030(0.0008) Grad: 32420.4414  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 4m 1s (remain 17m 33s) Loss: 0.0000(0.0009) Grad: 24.9246  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 4m 25s (remain 17m 7s) Loss: 0.0002(0.0009) Grad: 903.0428  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 4m 49s (remain 16m 41s) Loss: 0.0000(0.0008) Grad: 251.3837  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 5m 12s (remain 16m 16s) Loss: 0.0011(0.0008) Grad: 3113.1501  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 5m 37s (remain 15m 52s) Loss: 0.0000(0.0008) Grad: 17.1925  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 6m 0s (remain 15m 28s) Loss: 0.0001(0.0008) Grad: 375.4092  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 6m 24s (remain 15m 3s) Loss: 0.0001(0.0008) Grad: 393.5538  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 6m 48s (remain 14m 39s) Loss: 0.0005(0.0008) Grad: 1665.9685  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 7m 12s (remain 14m 14s) Loss: 0.0008(0.0008) Grad: 3480.2061  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 7m 36s (remain 13m 50s) Loss: 0.0004(0.0008) Grad: 1656.9957  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 8m 0s (remain 13m 26s) Loss: 0.0000(0.0008) Grad: 6.9213  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 8m 23s (remain 13m 2s) Loss: 0.0007(0.0008) Grad: 3724.0083  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 8m 47s (remain 12m 38s) Loss: 0.0001(0.0008) Grad: 926.3688  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 9m 11s (remain 12m 13s) Loss: 0.0000(0.0008) Grad: 44.1136  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 9m 35s (remain 11m 49s) Loss: 0.0001(0.0008) Grad: 526.0621  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 9m 58s (remain 11m 25s) Loss: 0.0000(0.0008) Grad: 62.4877  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 10m 22s (remain 11m 1s) Loss: 0.0000(0.0008) Grad: 12.2791  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 10m 46s (remain 10m 36s) Loss: 0.0005(0.0008) Grad: 2308.3596  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 11m 9s (remain 10m 12s) Loss: 0.0000(0.0008) Grad: 23.1425  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 11m 33s (remain 9m 48s) Loss: 0.0028(0.0008) Grad: 18725.4473  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 11m 57s (remain 9m 24s) Loss: 0.0044(0.0008) Grad: 20561.1855  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 12m 20s (remain 9m 0s) Loss: 0.0001(0.0008) Grad: 293.1850  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 12m 44s (remain 8m 36s) Loss: 0.0003(0.0008) Grad: 2162.0967  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 13m 8s (remain 8m 12s) Loss: 0.0010(0.0008) Grad: 6221.7290  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 13m 31s (remain 7m 48s) Loss: 0.0000(0.0008) Grad: 77.7108  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 13m 55s (remain 7m 24s) Loss: 0.0001(0.0008) Grad: 376.4409  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 14m 19s (remain 7m 0s) Loss: 0.0003(0.0008) Grad: 1042.6511  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 14m 42s (remain 6m 36s) Loss: 0.0000(0.0008) Grad: 239.5280  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 15m 6s (remain 6m 12s) Loss: 0.0000(0.0008) Grad: 20.9587  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 15m 30s (remain 5m 48s) Loss: 0.0000(0.0008) Grad: 104.1423  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 15m 53s (remain 5m 24s) Loss: 0.0139(0.0008) Grad: 33635.3086  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 16m 17s (remain 5m 0s) Loss: 0.0029(0.0008) Grad: 7322.2773  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 16m 40s (remain 4m 36s) Loss: 0.0006(0.0008) Grad: 1823.3822  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 17m 4s (remain 4m 12s) Loss: 0.0000(0.0008) Grad: 47.3277  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 17m 28s (remain 3m 48s) Loss: 0.0011(0.0008) Grad: 3821.7930  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 17m 51s (remain 3m 25s) Loss: 0.0000(0.0008) Grad: 23.5609  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 18m 15s (remain 3m 1s) Loss: 0.0002(0.0008) Grad: 976.9293  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 18m 38s (remain 2m 37s) Loss: 0.0000(0.0008) Grad: 150.1249  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 19m 2s (remain 2m 13s) Loss: 0.0000(0.0008) Grad: 145.7094  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 19m 26s (remain 1m 49s) Loss: 0.0000(0.0008) Grad: 34.7835  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 19m 49s (remain 1m 25s) Loss: 0.0000(0.0008) Grad: 49.9260  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 20m 13s (remain 1m 2s) Loss: 0.0000(0.0008) Grad: 15.2560  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 20m 37s (remain 0m 38s) Loss: 0.0001(0.0009) Grad: 740.4433  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 21m 0s (remain 0m 14s) Loss: 0.0005(0.0009) Grad: 2528.3901  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 21m 15s (remain 0m 0s) Loss: 0.0003(0.0008) Grad: 1195.2126  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 45s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0000(0.0011) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0000(0.0011) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0023(0.0010) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0022(0.0011) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0011) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0003(0.0011) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0004(0.0010) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0004(0.0010) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0012(0.0010) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 35s) Loss: 0.0000(0.0012) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0000(0.0014) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0001(0.0014) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0000(0.0014) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0014) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0014) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0013) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0002(0.0013) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0000(0.0013) \n","Epoch 3 - avg_train_loss: 0.0008  avg_val_loss: 0.0013  time: 1496s\n","Epoch 3 - Score: 0.8767\n","Epoch 3 - Save Best Score: 0.8767 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 55m 8s) Loss: 0.0010(0.0010) Grad: 11109.9043  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 0m 27s (remain 24m 2s) Loss: 0.0000(0.0003) Grad: 136.8231  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 0m 53s (remain 22m 42s) Loss: 0.0006(0.0007) Grad: 2776.2427  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 1m 17s (remain 21m 34s) Loss: 0.0001(0.0008) Grad: 236.0754  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 1m 41s (remain 20m 50s) Loss: 0.0039(0.0008) Grad: 14345.3877  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 2m 5s (remain 20m 14s) Loss: 0.0000(0.0008) Grad: 9.6727  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 2m 28s (remain 19m 39s) Loss: 0.0001(0.0008) Grad: 962.7035  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 2m 52s (remain 19m 9s) Loss: 0.0002(0.0008) Grad: 1775.9000  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 3m 16s (remain 18m 40s) Loss: 0.0000(0.0008) Grad: 330.9119  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 3m 40s (remain 18m 13s) Loss: 0.0001(0.0008) Grad: 1009.4173  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 4m 4s (remain 17m 46s) Loss: 0.0000(0.0008) Grad: 1.7759  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 4m 28s (remain 17m 20s) Loss: 0.0025(0.0007) Grad: 13969.3506  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 4m 52s (remain 16m 53s) Loss: 0.0000(0.0007) Grad: 642.0785  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 5m 16s (remain 16m 27s) Loss: 0.0000(0.0007) Grad: 492.4377  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 5m 40s (remain 16m 1s) Loss: 0.0000(0.0007) Grad: 523.4607  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 6m 3s (remain 15m 36s) Loss: 0.0000(0.0007) Grad: 189.5536  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 6m 27s (remain 15m 10s) Loss: 0.0000(0.0007) Grad: 70.6176  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 6m 51s (remain 14m 45s) Loss: 0.0000(0.0007) Grad: 116.5154  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 7m 15s (remain 14m 20s) Loss: 0.0000(0.0007) Grad: 124.8008  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 7m 39s (remain 13m 55s) Loss: 0.0000(0.0007) Grad: 154.2158  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 8m 2s (remain 13m 31s) Loss: 0.0000(0.0007) Grad: 39.8431  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 8m 26s (remain 13m 6s) Loss: 0.0000(0.0007) Grad: 407.5073  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 8m 50s (remain 12m 41s) Loss: 0.0000(0.0007) Grad: 18.6574  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 9m 14s (remain 12m 17s) Loss: 0.0000(0.0007) Grad: 73.3902  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 9m 38s (remain 11m 53s) Loss: 0.0000(0.0007) Grad: 244.8297  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 10m 2s (remain 11m 28s) Loss: 0.0000(0.0007) Grad: 21.1051  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 10m 25s (remain 11m 4s) Loss: 0.0002(0.0007) Grad: 1062.3014  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 10m 49s (remain 10m 40s) Loss: 0.0000(0.0007) Grad: 33.4890  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 11m 13s (remain 10m 15s) Loss: 0.0002(0.0007) Grad: 1571.6357  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 11m 37s (remain 9m 51s) Loss: 0.0000(0.0007) Grad: 4.6490  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 12m 1s (remain 9m 27s) Loss: 0.0004(0.0007) Grad: 1656.0809  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 12m 25s (remain 9m 3s) Loss: 0.0012(0.0007) Grad: 22523.1660  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 12m 49s (remain 8m 39s) Loss: 0.0000(0.0007) Grad: 41.9037  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 13m 12s (remain 8m 15s) Loss: 0.0009(0.0007) Grad: 3039.6365  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 13m 36s (remain 7m 50s) Loss: 0.0004(0.0007) Grad: 1917.5360  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 14m 0s (remain 7m 26s) Loss: 0.0000(0.0007) Grad: 123.3446  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 14m 24s (remain 7m 2s) Loss: 0.0000(0.0007) Grad: 136.9229  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 14m 48s (remain 6m 38s) Loss: 0.0000(0.0007) Grad: 5.1029  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 15m 12s (remain 6m 14s) Loss: 0.0001(0.0007) Grad: 420.8329  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 15m 36s (remain 5m 50s) Loss: 0.0000(0.0007) Grad: 14.3726  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 16m 0s (remain 5m 26s) Loss: 0.0007(0.0007) Grad: 3942.4883  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 16m 24s (remain 5m 2s) Loss: 0.0308(0.0007) Grad: 66348.3203  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 16m 48s (remain 4m 38s) Loss: 0.0005(0.0007) Grad: 1709.8604  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 17m 12s (remain 4m 14s) Loss: 0.0000(0.0007) Grad: 21.7007  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 17m 36s (remain 3m 50s) Loss: 0.0002(0.0007) Grad: 4924.0112  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 17m 59s (remain 3m 26s) Loss: 0.0000(0.0007) Grad: 4.5490  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 18m 23s (remain 3m 2s) Loss: 0.0010(0.0007) Grad: 3604.8108  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 18m 47s (remain 2m 38s) Loss: 0.0000(0.0007) Grad: 27.9794  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 19m 11s (remain 2m 14s) Loss: 0.0000(0.0007) Grad: 16.2639  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 19m 35s (remain 1m 50s) Loss: 0.0000(0.0007) Grad: 8.0279  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 19m 59s (remain 1m 26s) Loss: 0.0002(0.0007) Grad: 1373.9329  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 20m 23s (remain 1m 2s) Loss: 0.0011(0.0007) Grad: 10611.7139  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 20m 47s (remain 0m 38s) Loss: 0.0004(0.0007) Grad: 4933.2744  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 21m 11s (remain 0m 14s) Loss: 0.0001(0.0007) Grad: 1027.3501  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 21m 25s (remain 0m 0s) Loss: 0.0004(0.0007) Grad: 1957.5635  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 15s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0000(0.0013) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 14s) Loss: 0.0000(0.0013) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0052(0.0012) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 49s) Loss: 0.0024(0.0012) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 37s) Loss: 0.0000(0.0013) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0005(0.0012) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0009(0.0011) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0004(0.0011) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0004(0.0012) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0000(0.0014) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0017) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0002(0.0016) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 59s) Loss: 0.0000(0.0017) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0016) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0016) \n","EVAL: [1600/1788] Elapsed 3m 14s (remain 0m 22s) Loss: 0.0000(0.0016) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0004(0.0016) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0000(0.0015) \n","Epoch 4 - avg_train_loss: 0.0007  avg_val_loss: 0.0015  time: 1511s\n","Epoch 4 - Score: 0.8782\n","Epoch 4 - Save Best Score: 0.8782 Model\n","Epoch: [5][0/5362] Elapsed 0m 0s (remain 50m 55s) Loss: 0.0001(0.0001) Grad: 1610.3905  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 0m 28s (remain 24m 25s) Loss: 0.0001(0.0004) Grad: 572.4281  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 0m 53s (remain 22m 56s) Loss: 0.0000(0.0004) Grad: 0.8250  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 1m 17s (remain 21m 41s) Loss: 0.0000(0.0005) Grad: 1.4204  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 1m 41s (remain 20m 53s) Loss: 0.0000(0.0005) Grad: 122.8516  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 2m 5s (remain 20m 14s) Loss: 0.0000(0.0005) Grad: 36.4024  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 2m 28s (remain 19m 39s) Loss: 0.0000(0.0005) Grad: 34.9376  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 2m 52s (remain 19m 9s) Loss: 0.0000(0.0005) Grad: 9.6296  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 3m 16s (remain 18m 39s) Loss: 0.0002(0.0005) Grad: 674.5670  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 3m 40s (remain 18m 12s) Loss: 0.0004(0.0005) Grad: 1820.8536  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 4m 4s (remain 17m 45s) Loss: 0.0001(0.0005) Grad: 528.3349  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 4m 28s (remain 17m 18s) Loss: 0.0264(0.0005) Grad: 28676.5488  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 4m 52s (remain 16m 52s) Loss: 0.0016(0.0005) Grad: 6505.3696  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 5m 16s (remain 16m 27s) Loss: 0.0005(0.0006) Grad: 1746.1115  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 5m 40s (remain 16m 1s) Loss: 0.0000(0.0006) Grad: 1.0534  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 6m 3s (remain 15m 35s) Loss: 0.0000(0.0005) Grad: 349.9621  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 6m 27s (remain 15m 10s) Loss: 0.0000(0.0006) Grad: 90.1189  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 6m 51s (remain 14m 44s) Loss: 0.0000(0.0006) Grad: 28.8964  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 7m 14s (remain 14m 19s) Loss: 0.0000(0.0006) Grad: 1.6671  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 7m 38s (remain 13m 54s) Loss: 0.0000(0.0006) Grad: 18.4685  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 8m 2s (remain 13m 29s) Loss: 0.0000(0.0006) Grad: 9.7083  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 8m 25s (remain 13m 4s) Loss: 0.0001(0.0006) Grad: 233.3247  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 8m 49s (remain 12m 40s) Loss: 0.0005(0.0006) Grad: 2127.8687  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 9m 12s (remain 12m 15s) Loss: 0.0000(0.0006) Grad: 9.7334  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 9m 36s (remain 11m 50s) Loss: 0.0001(0.0006) Grad: 502.0671  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 10m 0s (remain 11m 26s) Loss: 0.0000(0.0006) Grad: 4.0820  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 10m 23s (remain 11m 2s) Loss: 0.0001(0.0006) Grad: 987.9990  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 10m 47s (remain 10m 37s) Loss: 0.0007(0.0006) Grad: 2080.3982  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 11m 10s (remain 10m 13s) Loss: 0.0006(0.0006) Grad: 3457.1379  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 11m 34s (remain 9m 49s) Loss: 0.0000(0.0006) Grad: 2.6947  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 11m 58s (remain 9m 25s) Loss: 0.0000(0.0006) Grad: 1.2498  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 12m 22s (remain 9m 1s) Loss: 0.0000(0.0006) Grad: 6.2109  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 12m 46s (remain 8m 37s) Loss: 0.0000(0.0006) Grad: 169.9999  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 13m 10s (remain 8m 13s) Loss: 0.0000(0.0006) Grad: 3.6299  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 13m 34s (remain 7m 49s) Loss: 0.0091(0.0006) Grad: 26372.8242  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 13m 58s (remain 7m 25s) Loss: 0.0000(0.0006) Grad: 1.1750  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 14m 21s (remain 7m 1s) Loss: 0.0000(0.0006) Grad: 15.4288  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 14m 45s (remain 6m 37s) Loss: 0.0000(0.0006) Grad: 1.9615  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 15m 9s (remain 6m 13s) Loss: 0.0000(0.0006) Grad: 99.4646  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 15m 33s (remain 5m 49s) Loss: 0.0002(0.0006) Grad: 1206.3772  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 15m 57s (remain 5m 25s) Loss: 0.0000(0.0006) Grad: 7.0357  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 16m 21s (remain 5m 1s) Loss: 0.0000(0.0006) Grad: 38.6216  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 16m 45s (remain 4m 37s) Loss: 0.0003(0.0006) Grad: 1913.8976  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 17m 9s (remain 4m 13s) Loss: 0.0000(0.0006) Grad: 4.4819  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 17m 33s (remain 3m 49s) Loss: 0.0000(0.0006) Grad: 109.3904  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 17m 57s (remain 3m 26s) Loss: 0.0000(0.0006) Grad: 21.5905  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 18m 20s (remain 3m 2s) Loss: 0.0000(0.0006) Grad: 7.6102  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 18m 44s (remain 2m 38s) Loss: 0.0000(0.0006) Grad: 40.8210  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 19m 8s (remain 2m 14s) Loss: 0.0004(0.0006) Grad: 1474.2213  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 19m 32s (remain 1m 50s) Loss: 0.0000(0.0006) Grad: 9.6378  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 19m 56s (remain 1m 26s) Loss: 0.0006(0.0006) Grad: 6389.1362  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 20m 20s (remain 1m 2s) Loss: 0.0000(0.0006) Grad: 4.5668  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 20m 44s (remain 0m 38s) Loss: 0.0016(0.0006) Grad: 10512.8535  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 21m 8s (remain 0m 14s) Loss: 0.0000(0.0005) Grad: 21.1850  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 21m 22s (remain 0m 0s) Loss: 0.0004(0.0005) Grad: 1781.5691  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 42s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0000(0.0012) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0001(0.0012) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0056(0.0012) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0025(0.0012) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 36s) Loss: 0.0000(0.0013) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0006(0.0012) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0006(0.0011) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0005(0.0011) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0007(0.0012) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0000(0.0014) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0017) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0002(0.0016) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 59s) Loss: 0.0000(0.0017) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0016) \n","EVAL: [1500/1788] Elapsed 3m 2s (remain 0m 34s) Loss: 0.0000(0.0016) \n","EVAL: [1600/1788] Elapsed 3m 14s (remain 0m 22s) Loss: 0.0000(0.0016) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0004(0.0016) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0000(0.0016) \n","Epoch 5 - avg_train_loss: 0.0005  avg_val_loss: 0.0016  time: 1505s\n","Epoch 5 - Score: 0.8784\n","Epoch 5 - Save Best Score: 0.8784 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 93m 38s) Loss: 0.0530(0.0530) Grad: 65836.3047  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 0m 27s (remain 24m 8s) Loss: 0.1112(0.0960) Grad: 76264.5703  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 0m 51s (remain 22m 7s) Loss: 0.0366(0.0842) Grad: 25257.6133  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 1m 15s (remain 21m 9s) Loss: 0.0194(0.0701) Grad: 12168.6846  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 1m 39s (remain 20m 31s) Loss: 0.0063(0.0570) Grad: 3238.8289  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 2m 3s (remain 19m 58s) Loss: 0.0063(0.0472) Grad: 2352.7800  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 2m 27s (remain 19m 27s) Loss: 0.0038(0.0405) Grad: 1788.2474  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 2m 51s (remain 18m 58s) Loss: 0.0041(0.0357) Grad: 1511.7339  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 3m 15s (remain 18m 30s) Loss: 0.0029(0.0320) Grad: 1221.8972  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 3m 39s (remain 18m 4s) Loss: 0.0060(0.0292) Grad: 2464.5591  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 4m 2s (remain 17m 38s) Loss: 0.0142(0.0270) Grad: 5218.3091  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 4m 26s (remain 17m 12s) Loss: 0.0057(0.0251) Grad: 2287.9290  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 4m 50s (remain 16m 47s) Loss: 0.0263(0.0235) Grad: 9352.0693  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 5m 14s (remain 16m 22s) Loss: 0.0063(0.0221) Grad: 1922.7972  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 5m 38s (remain 15m 57s) Loss: 0.0010(0.0208) Grad: 475.1928  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 6m 2s (remain 15m 32s) Loss: 0.0006(0.0196) Grad: 370.6169  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 6m 26s (remain 15m 7s) Loss: 0.0020(0.0186) Grad: 1241.4142  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 6m 50s (remain 14m 43s) Loss: 0.0028(0.0176) Grad: 3321.5879  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 7m 14s (remain 14m 18s) Loss: 0.0014(0.0168) Grad: 668.3846  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 7m 38s (remain 13m 53s) Loss: 0.0000(0.0160) Grad: 13.6321  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 8m 2s (remain 13m 29s) Loss: 0.0043(0.0153) Grad: 3647.8057  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 8m 25s (remain 13m 5s) Loss: 0.0008(0.0147) Grad: 656.5880  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 8m 49s (remain 12m 40s) Loss: 0.0035(0.0142) Grad: 2035.7985  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 9m 13s (remain 12m 16s) Loss: 0.0002(0.0136) Grad: 140.6320  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 9m 37s (remain 11m 51s) Loss: 0.0003(0.0132) Grad: 249.8486  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 10m 1s (remain 11m 27s) Loss: 0.0074(0.0127) Grad: 5206.8706  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 10m 25s (remain 11m 3s) Loss: 0.0011(0.0123) Grad: 1208.0804  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 10m 49s (remain 10m 39s) Loss: 0.0019(0.0119) Grad: 1213.4221  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 11m 13s (remain 10m 15s) Loss: 0.0004(0.0115) Grad: 1078.4976  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 11m 36s (remain 9m 51s) Loss: 0.0020(0.0112) Grad: 1796.9355  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 12m 0s (remain 9m 27s) Loss: 0.0003(0.0108) Grad: 298.6778  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 12m 24s (remain 9m 3s) Loss: 0.0000(0.0105) Grad: 18.0494  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 12m 48s (remain 8m 38s) Loss: 0.0001(0.0102) Grad: 229.4294  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 13m 12s (remain 8m 14s) Loss: 0.0000(0.0100) Grad: 35.4441  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 13m 36s (remain 7m 50s) Loss: 0.0007(0.0097) Grad: 521.8013  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 14m 0s (remain 7m 26s) Loss: 0.0004(0.0095) Grad: 318.4307  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 14m 24s (remain 7m 2s) Loss: 0.0003(0.0093) Grad: 228.5764  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 14m 48s (remain 6m 38s) Loss: 0.0004(0.0090) Grad: 307.9327  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 15m 12s (remain 6m 14s) Loss: 0.0003(0.0089) Grad: 314.0774  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 15m 36s (remain 5m 50s) Loss: 0.0010(0.0087) Grad: 1868.9648  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 16m 0s (remain 5m 26s) Loss: 0.0001(0.0085) Grad: 79.1487  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 16m 24s (remain 5m 2s) Loss: 0.0002(0.0083) Grad: 337.0038  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 16m 48s (remain 4m 38s) Loss: 0.0000(0.0081) Grad: 24.1182  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 17m 12s (remain 4m 14s) Loss: 0.0004(0.0080) Grad: 397.7109  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 17m 36s (remain 3m 50s) Loss: 0.0001(0.0078) Grad: 100.1053  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 18m 0s (remain 3m 26s) Loss: 0.0003(0.0077) Grad: 250.8573  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 18m 24s (remain 3m 2s) Loss: 0.0000(0.0075) Grad: 10.7390  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 18m 48s (remain 2m 38s) Loss: 0.0000(0.0074) Grad: 23.1879  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 19m 12s (remain 2m 14s) Loss: 0.0015(0.0073) Grad: 682.1628  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 19m 36s (remain 1m 50s) Loss: 0.0007(0.0071) Grad: 245.6101  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 20m 0s (remain 1m 26s) Loss: 0.0002(0.0070) Grad: 110.4200  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 20m 23s (remain 1m 2s) Loss: 0.0004(0.0069) Grad: 319.4639  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 20m 48s (remain 0m 38s) Loss: 0.0001(0.0068) Grad: 115.2019  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 21m 12s (remain 0m 14s) Loss: 0.0010(0.0067) Grad: 760.4296  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 21m 27s (remain 0m 0s) Loss: 0.0000(0.0066) Grad: 159.3401  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 26s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 30s) Loss: 0.0001(0.0008) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0005(0.0008) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0002(0.0009) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0021(0.0014) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0016) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0019(0.0015) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0006(0.0015) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0000(0.0014) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0323(0.0014) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0011(0.0015) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0002(0.0016) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0026(0.0015) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0003(0.0015) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0001(0.0015) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0015) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0002(0.0014) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0001(0.0014) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0024(0.0013) \n","Epoch 1 - avg_train_loss: 0.0066  avg_val_loss: 0.0013  time: 1512s\n","Epoch 1 - Score: 0.8534\n","Epoch 1 - Save Best Score: 0.8534 Model\n","Epoch: [2][0/5362] Elapsed 0m 0s (remain 56m 54s) Loss: 0.0111(0.0111) Grad: 21334.7793  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 0m 27s (remain 24m 7s) Loss: 0.0001(0.0014) Grad: 519.7328  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 0m 53s (remain 22m 45s) Loss: 0.0003(0.0013) Grad: 967.3864  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 1m 16s (remain 21m 32s) Loss: 0.0104(0.0011) Grad: 14451.0000  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 1m 40s (remain 20m 43s) Loss: 0.0006(0.0011) Grad: 3656.8921  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 2m 4s (remain 20m 5s) Loss: 0.0000(0.0011) Grad: 189.6139  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 2m 27s (remain 19m 32s) Loss: 0.0001(0.0011) Grad: 352.7196  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 2m 51s (remain 19m 2s) Loss: 0.0048(0.0011) Grad: 16486.4688  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 3m 15s (remain 18m 33s) Loss: 0.0001(0.0011) Grad: 252.4611  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 3m 39s (remain 18m 6s) Loss: 0.0000(0.0011) Grad: 113.5371  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 4m 3s (remain 17m 39s) Loss: 0.0000(0.0010) Grad: 99.5828  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 4m 27s (remain 17m 13s) Loss: 0.0000(0.0010) Grad: 11.8388  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 4m 50s (remain 16m 47s) Loss: 0.0008(0.0010) Grad: 2321.3369  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 5m 15s (remain 16m 23s) Loss: 0.0015(0.0010) Grad: 3910.2290  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 5m 39s (remain 15m 58s) Loss: 0.0104(0.0010) Grad: 14547.8770  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 6m 2s (remain 15m 33s) Loss: 0.0037(0.0010) Grad: 15316.4756  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 6m 26s (remain 15m 7s) Loss: 0.0000(0.0010) Grad: 29.4070  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 6m 50s (remain 14m 42s) Loss: 0.0009(0.0010) Grad: 2767.3938  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 7m 13s (remain 14m 17s) Loss: 0.0000(0.0010) Grad: 1328.8480  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 7m 37s (remain 13m 52s) Loss: 0.0009(0.0010) Grad: 2241.8147  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 8m 1s (remain 13m 28s) Loss: 0.0004(0.0010) Grad: 1918.9614  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 8m 24s (remain 13m 3s) Loss: 0.0000(0.0010) Grad: 21.1846  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 8m 48s (remain 12m 39s) Loss: 0.0001(0.0010) Grad: 318.9337  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 9m 12s (remain 12m 14s) Loss: 0.0000(0.0010) Grad: 19.8605  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 9m 36s (remain 11m 50s) Loss: 0.0001(0.0010) Grad: 229.8879  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 9m 59s (remain 11m 26s) Loss: 0.0037(0.0010) Grad: 35856.1406  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 10m 23s (remain 11m 2s) Loss: 0.0002(0.0010) Grad: 1548.9786  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 10m 47s (remain 10m 37s) Loss: 0.0000(0.0010) Grad: 19.8782  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 11m 11s (remain 10m 13s) Loss: 0.0005(0.0010) Grad: 1270.7916  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 11m 35s (remain 9m 49s) Loss: 0.0000(0.0010) Grad: 4.8385  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 11m 58s (remain 9m 25s) Loss: 0.0000(0.0010) Grad: 140.5115  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 12m 22s (remain 9m 1s) Loss: 0.0009(0.0010) Grad: 5496.0288  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 12m 46s (remain 8m 37s) Loss: 0.0001(0.0010) Grad: 518.8828  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 13m 10s (remain 8m 13s) Loss: 0.0003(0.0010) Grad: 874.8099  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 13m 34s (remain 7m 49s) Loss: 0.0001(0.0010) Grad: 187.6789  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 13m 58s (remain 7m 25s) Loss: 0.0000(0.0010) Grad: 97.1062  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 14m 22s (remain 7m 1s) Loss: 0.0006(0.0010) Grad: 3390.3997  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 14m 46s (remain 6m 37s) Loss: 0.0002(0.0010) Grad: 802.7106  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 15m 10s (remain 6m 13s) Loss: 0.0006(0.0010) Grad: 1152.5363  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 15m 34s (remain 5m 49s) Loss: 0.0013(0.0010) Grad: 3149.3093  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 15m 58s (remain 5m 25s) Loss: 0.0001(0.0010) Grad: 456.8357  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 16m 22s (remain 5m 2s) Loss: 0.0000(0.0010) Grad: 215.7487  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 16m 46s (remain 4m 38s) Loss: 0.0000(0.0010) Grad: 11.2557  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 17m 10s (remain 4m 14s) Loss: 0.0006(0.0010) Grad: 17217.2539  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 17m 33s (remain 3m 50s) Loss: 0.0000(0.0010) Grad: 171.1629  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 17m 57s (remain 3m 26s) Loss: 0.0001(0.0010) Grad: 368.3923  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 18m 21s (remain 3m 2s) Loss: 0.0006(0.0010) Grad: 4560.8589  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 18m 45s (remain 2m 38s) Loss: 0.0002(0.0010) Grad: 702.1550  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 19m 9s (remain 2m 14s) Loss: 0.0028(0.0010) Grad: 37464.3320  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 19m 33s (remain 1m 50s) Loss: 0.0002(0.0010) Grad: 515.5862  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 19m 57s (remain 1m 26s) Loss: 0.0034(0.0010) Grad: 17439.2793  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 20m 21s (remain 1m 2s) Loss: 0.0043(0.0010) Grad: 7785.4590  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 20m 45s (remain 0m 38s) Loss: 0.0000(0.0010) Grad: 26.9068  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 21m 9s (remain 0m 14s) Loss: 0.0012(0.0010) Grad: 3721.4277  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 21m 23s (remain 0m 0s) Loss: 0.0000(0.0010) Grad: 990.7282  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 19s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0002(0.0010) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0004(0.0008) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0001(0.0008) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0037(0.0014) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0015) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0035(0.0014) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0009(0.0014) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0000(0.0014) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0251(0.0014) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 35s) Loss: 0.0006(0.0015) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0001(0.0015) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0009(0.0015) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0001(0.0015) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0014) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0014) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0003(0.0013) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0000(0.0013) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0028(0.0012) \n","Epoch 2 - avg_train_loss: 0.0010  avg_val_loss: 0.0012  time: 1512s\n","Epoch 2 - Score: 0.8690\n","Epoch 2 - Save Best Score: 0.8690 Model\n","Epoch: [3][0/5362] Elapsed 0m 0s (remain 53m 47s) Loss: 0.0000(0.0000) Grad: 985.6111  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 0m 28s (remain 25m 9s) Loss: 0.0001(0.0005) Grad: 557.5412  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 0m 54s (remain 23m 25s) Loss: 0.0000(0.0006) Grad: 50.8231  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 1m 18s (remain 21m 59s) Loss: 0.0000(0.0006) Grad: 15.0916  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 1m 42s (remain 21m 6s) Loss: 0.0001(0.0007) Grad: 235.7391  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 2m 5s (remain 20m 22s) Loss: 0.0003(0.0008) Grad: 1205.9170  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 2m 29s (remain 19m 45s) Loss: 0.0001(0.0008) Grad: 1189.2140  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 2m 53s (remain 19m 12s) Loss: 0.0000(0.0008) Grad: 252.7267  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 3m 17s (remain 18m 42s) Loss: 0.0019(0.0008) Grad: 11139.0781  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 3m 41s (remain 18m 14s) Loss: 0.0000(0.0008) Grad: 9.5993  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 4m 4s (remain 17m 46s) Loss: 0.0000(0.0008) Grad: 303.8959  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 4m 28s (remain 17m 18s) Loss: 0.0002(0.0008) Grad: 1406.2933  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 4m 52s (remain 16m 51s) Loss: 0.0004(0.0008) Grad: 4294.7109  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 5m 15s (remain 16m 26s) Loss: 0.0001(0.0008) Grad: 534.8956  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 5m 39s (remain 16m 1s) Loss: 0.0000(0.0008) Grad: 269.9078  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 6m 3s (remain 15m 35s) Loss: 0.0000(0.0008) Grad: 240.7015  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 6m 27s (remain 15m 9s) Loss: 0.0008(0.0008) Grad: 2207.7258  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 6m 51s (remain 14m 44s) Loss: 0.0001(0.0008) Grad: 494.3033  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 7m 14s (remain 14m 19s) Loss: 0.0013(0.0008) Grad: 3660.3557  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 7m 38s (remain 13m 54s) Loss: 0.0000(0.0008) Grad: 315.7081  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 8m 2s (remain 13m 29s) Loss: 0.0000(0.0008) Grad: 52.4770  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 8m 25s (remain 13m 4s) Loss: 0.0000(0.0008) Grad: 15.7337  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 8m 49s (remain 12m 40s) Loss: 0.0001(0.0008) Grad: 1533.0735  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 9m 13s (remain 12m 16s) Loss: 0.0000(0.0008) Grad: 21.9458  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 9m 36s (remain 11m 51s) Loss: 0.0001(0.0008) Grad: 345.7023  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 10m 0s (remain 11m 27s) Loss: 0.0007(0.0008) Grad: 6502.7100  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 10m 24s (remain 11m 2s) Loss: 0.0000(0.0008) Grad: 4.3390  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 10m 48s (remain 10m 38s) Loss: 0.0002(0.0008) Grad: 835.2336  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 11m 11s (remain 10m 14s) Loss: 0.0000(0.0008) Grad: 104.3827  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 11m 35s (remain 9m 50s) Loss: 0.0003(0.0008) Grad: 2481.6294  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 11m 59s (remain 9m 25s) Loss: 0.0000(0.0007) Grad: 1.2841  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 12m 22s (remain 9m 1s) Loss: 0.0004(0.0007) Grad: 1976.6100  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 12m 46s (remain 8m 37s) Loss: 0.0000(0.0008) Grad: 94.6570  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 13m 10s (remain 8m 13s) Loss: 0.0000(0.0007) Grad: 417.0491  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 13m 33s (remain 7m 49s) Loss: 0.0000(0.0007) Grad: 35.9366  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 13m 57s (remain 7m 25s) Loss: 0.0000(0.0008) Grad: 54.7057  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 14m 21s (remain 7m 1s) Loss: 0.0002(0.0008) Grad: 543.9052  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 14m 45s (remain 6m 37s) Loss: 0.0009(0.0007) Grad: 5631.8193  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 15m 8s (remain 6m 13s) Loss: 0.0073(0.0007) Grad: 73088.3594  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 15m 32s (remain 5m 49s) Loss: 0.0000(0.0007) Grad: 64.1732  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 15m 56s (remain 5m 25s) Loss: 0.0000(0.0007) Grad: 180.4039  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 16m 19s (remain 5m 1s) Loss: 0.0010(0.0008) Grad: 2405.7874  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 16m 43s (remain 4m 37s) Loss: 0.0000(0.0008) Grad: 13.4618  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 17m 7s (remain 4m 13s) Loss: 0.0005(0.0008) Grad: 1779.5239  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 17m 31s (remain 3m 49s) Loss: 0.0001(0.0008) Grad: 456.6092  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 17m 55s (remain 3m 25s) Loss: 0.0000(0.0008) Grad: 27.6806  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 18m 19s (remain 3m 1s) Loss: 0.0003(0.0008) Grad: 1988.6255  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 18m 43s (remain 2m 38s) Loss: 0.0000(0.0008) Grad: 58.0926  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 19m 7s (remain 2m 14s) Loss: 0.0012(0.0008) Grad: 7032.6982  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 19m 31s (remain 1m 50s) Loss: 0.0004(0.0008) Grad: 2263.0034  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 19m 55s (remain 1m 26s) Loss: 0.0002(0.0008) Grad: 696.6036  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 20m 19s (remain 1m 2s) Loss: 0.0000(0.0008) Grad: 26.6474  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 20m 43s (remain 0m 38s) Loss: 0.0100(0.0008) Grad: 14917.4775  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 21m 7s (remain 0m 14s) Loss: 0.0003(0.0008) Grad: 840.8901  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 21m 22s (remain 0m 0s) Loss: 0.0004(0.0008) Grad: 2088.4973  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 18s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0001(0.0009) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0010(0.0008) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0000(0.0009) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0058(0.0015) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0017) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0037(0.0016) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0021(0.0016) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0000(0.0015) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0314(0.0015) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 35s) Loss: 0.0004(0.0016) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0000(0.0017) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0014(0.0016) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0001(0.0016) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0016) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0015) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0003(0.0015) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0000(0.0014) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0059(0.0014) \n","Epoch 3 - avg_train_loss: 0.0008  avg_val_loss: 0.0014  time: 1506s\n","Epoch 3 - Score: 0.8760\n","Epoch 3 - Save Best Score: 0.8760 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 56m 47s) Loss: 0.0001(0.0001) Grad: 1038.5508  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 0m 28s (remain 24m 22s) Loss: 0.0001(0.0007) Grad: 647.1557  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 0m 53s (remain 22m 59s) Loss: 0.0009(0.0007) Grad: 4872.6450  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 1m 17s (remain 21m 44s) Loss: 0.0000(0.0007) Grad: 97.0865  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 1m 41s (remain 20m 56s) Loss: 0.0005(0.0007) Grad: 3362.4292  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 2m 5s (remain 20m 18s) Loss: 0.0000(0.0007) Grad: 121.4792  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 2m 29s (remain 19m 42s) Loss: 0.0000(0.0007) Grad: 328.7272  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 2m 53s (remain 19m 13s) Loss: 0.0000(0.0006) Grad: 3.9720  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 3m 17s (remain 18m 44s) Loss: 0.0032(0.0006) Grad: 8261.4180  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 3m 41s (remain 18m 15s) Loss: 0.0000(0.0006) Grad: 5.3699  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 4m 5s (remain 17m 48s) Loss: 0.0013(0.0006) Grad: 3067.0979  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 4m 29s (remain 17m 21s) Loss: 0.0002(0.0006) Grad: 1676.0649  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 4m 52s (remain 16m 54s) Loss: 0.0000(0.0006) Grad: 23.7367  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 5m 16s (remain 16m 28s) Loss: 0.0000(0.0006) Grad: 3.2024  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 5m 40s (remain 16m 3s) Loss: 0.0000(0.0006) Grad: 0.4864  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 6m 4s (remain 15m 37s) Loss: 0.0001(0.0006) Grad: 908.6501  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 6m 28s (remain 15m 12s) Loss: 0.0002(0.0006) Grad: 857.9265  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 6m 52s (remain 14m 47s) Loss: 0.0000(0.0005) Grad: 52.4318  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 7m 16s (remain 14m 22s) Loss: 0.0016(0.0005) Grad: 6241.6641  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 7m 40s (remain 13m 57s) Loss: 0.0025(0.0006) Grad: 11455.7383  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 8m 4s (remain 13m 33s) Loss: 0.0026(0.0006) Grad: 9966.5020  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 8m 28s (remain 13m 9s) Loss: 0.0000(0.0006) Grad: 47.2762  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 8m 52s (remain 12m 44s) Loss: 0.0060(0.0006) Grad: 73273.8750  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 9m 16s (remain 12m 20s) Loss: 0.0001(0.0006) Grad: 752.7618  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 9m 40s (remain 11m 55s) Loss: 0.0003(0.0006) Grad: 1246.5924  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 10m 4s (remain 11m 31s) Loss: 0.0000(0.0006) Grad: 6.7996  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 10m 28s (remain 11m 7s) Loss: 0.0000(0.0006) Grad: 25.5777  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 10m 52s (remain 10m 42s) Loss: 0.0000(0.0006) Grad: 24.6431  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 11m 16s (remain 10m 18s) Loss: 0.0001(0.0006) Grad: 255.8907  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 11m 40s (remain 9m 54s) Loss: 0.0000(0.0006) Grad: 334.9121  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 12m 4s (remain 9m 29s) Loss: 0.0006(0.0006) Grad: 2634.9111  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 12m 28s (remain 9m 5s) Loss: 0.0000(0.0006) Grad: 53.6770  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 12m 52s (remain 8m 41s) Loss: 0.0002(0.0006) Grad: 1285.3046  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 13m 16s (remain 8m 17s) Loss: 0.0004(0.0006) Grad: 1458.6259  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 13m 40s (remain 7m 52s) Loss: 0.0001(0.0006) Grad: 756.2792  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 14m 4s (remain 7m 28s) Loss: 0.0018(0.0006) Grad: 6965.3457  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 14m 28s (remain 7m 4s) Loss: 0.0003(0.0006) Grad: 4284.4199  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 14m 52s (remain 6m 40s) Loss: 0.0001(0.0006) Grad: 843.6709  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 15m 16s (remain 6m 16s) Loss: 0.0000(0.0006) Grad: 58.0115  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 15m 40s (remain 5m 52s) Loss: 0.0016(0.0006) Grad: 6513.2012  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 16m 4s (remain 5m 27s) Loss: 0.0000(0.0006) Grad: 175.7645  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 16m 28s (remain 5m 3s) Loss: 0.0001(0.0006) Grad: 185.2624  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 16m 52s (remain 4m 39s) Loss: 0.0000(0.0006) Grad: 23.0725  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 17m 15s (remain 4m 15s) Loss: 0.0006(0.0006) Grad: 3185.0271  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 17m 39s (remain 3m 51s) Loss: 0.0001(0.0006) Grad: 1170.2095  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 18m 3s (remain 3m 27s) Loss: 0.0000(0.0006) Grad: 167.5783  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 18m 27s (remain 3m 3s) Loss: 0.0000(0.0006) Grad: 32.3311  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 18m 51s (remain 2m 39s) Loss: 0.0000(0.0006) Grad: 22.8582  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 19m 15s (remain 2m 15s) Loss: 0.0016(0.0006) Grad: 5158.6660  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 19m 39s (remain 1m 50s) Loss: 0.0000(0.0006) Grad: 50.0569  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 20m 3s (remain 1m 26s) Loss: 0.0001(0.0006) Grad: 1138.7496  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 20m 26s (remain 1m 2s) Loss: 0.0001(0.0006) Grad: 1190.9473  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 20m 50s (remain 0m 38s) Loss: 0.0001(0.0006) Grad: 4764.5830  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 21m 14s (remain 0m 14s) Loss: 0.0003(0.0006) Grad: 4229.9780  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 21m 29s (remain 0m 0s) Loss: 0.0011(0.0006) Grad: 13505.4707  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 39s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0002(0.0011) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0006(0.0011) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0000(0.0011) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0054(0.0019) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0020) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0052(0.0019) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0023(0.0018) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0000(0.0017) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0323(0.0017) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 35s) Loss: 0.0005(0.0019) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0020) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0013(0.0019) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0001(0.0019) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0018) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0018) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0002(0.0017) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0000(0.0017) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0085(0.0016) \n","Epoch 4 - avg_train_loss: 0.0006  avg_val_loss: 0.0016  time: 1529s\n","Epoch 4 - Score: 0.8765\n","Epoch 4 - Save Best Score: 0.8765 Model\n","Epoch: [5][0/5362] Elapsed 0m 0s (remain 56m 57s) Loss: 0.0000(0.0000) Grad: 1002.4395  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 0m 28s (remain 24m 57s) Loss: 0.0002(0.0003) Grad: 1027.1167  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 0m 54s (remain 23m 9s) Loss: 0.0000(0.0004) Grad: 170.6492  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 1m 18s (remain 21m 55s) Loss: 0.0000(0.0004) Grad: 64.1225  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 1m 42s (remain 21m 7s) Loss: 0.0000(0.0004) Grad: 164.2405  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 2m 6s (remain 20m 26s) Loss: 0.0000(0.0005) Grad: 27.3430  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 2m 30s (remain 19m 50s) Loss: 0.0000(0.0004) Grad: 96.6442  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 2m 54s (remain 19m 18s) Loss: 0.0000(0.0005) Grad: 1.6286  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 3m 18s (remain 18m 47s) Loss: 0.0001(0.0005) Grad: 549.2263  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 3m 41s (remain 18m 18s) Loss: 0.0000(0.0005) Grad: 10.2719  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 4m 5s (remain 17m 50s) Loss: 0.0000(0.0005) Grad: 18.0944  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 4m 29s (remain 17m 24s) Loss: 0.0000(0.0005) Grad: 50.5683  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 4m 53s (remain 16m 57s) Loss: 0.0016(0.0005) Grad: 5198.5415  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 5m 17s (remain 16m 30s) Loss: 0.0001(0.0004) Grad: 551.5104  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 5m 41s (remain 16m 5s) Loss: 0.0000(0.0005) Grad: 4.7060  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 6m 5s (remain 15m 39s) Loss: 0.0400(0.0005) Grad: 52416.9883  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 6m 29s (remain 15m 14s) Loss: 0.0000(0.0005) Grad: 165.2586  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 6m 53s (remain 14m 49s) Loss: 0.0003(0.0005) Grad: 5098.3882  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 7m 17s (remain 14m 24s) Loss: 0.0011(0.0005) Grad: 8723.9131  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 7m 41s (remain 13m 59s) Loss: 0.0000(0.0005) Grad: 3.0536  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 8m 4s (remain 13m 34s) Loss: 0.0009(0.0005) Grad: 5422.2627  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 8m 28s (remain 13m 9s) Loss: 0.0002(0.0005) Grad: 1834.0232  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 8m 53s (remain 12m 45s) Loss: 0.0023(0.0005) Grad: 11401.9482  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 9m 17s (remain 12m 21s) Loss: 0.0000(0.0005) Grad: 30.3383  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 9m 41s (remain 11m 56s) Loss: 0.0000(0.0005) Grad: 13.0118  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 10m 5s (remain 11m 32s) Loss: 0.0000(0.0005) Grad: 257.8035  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 10m 28s (remain 11m 7s) Loss: 0.0000(0.0005) Grad: 4.3763  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 10m 52s (remain 10m 43s) Loss: 0.0002(0.0005) Grad: 1391.8079  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 11m 16s (remain 10m 18s) Loss: 0.0002(0.0005) Grad: 1353.6528  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 11m 40s (remain 9m 54s) Loss: 0.0000(0.0005) Grad: 3.8512  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 12m 4s (remain 9m 30s) Loss: 0.0000(0.0005) Grad: 143.1505  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 12m 28s (remain 9m 5s) Loss: 0.0000(0.0005) Grad: 18.2549  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 12m 52s (remain 8m 41s) Loss: 0.0002(0.0005) Grad: 902.1572  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 13m 16s (remain 8m 17s) Loss: 0.0000(0.0005) Grad: 61.6864  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 13m 40s (remain 7m 53s) Loss: 0.0000(0.0005) Grad: 180.4603  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 14m 4s (remain 7m 29s) Loss: 0.0000(0.0005) Grad: 89.7856  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 14m 28s (remain 7m 4s) Loss: 0.0001(0.0005) Grad: 302.4397  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 14m 52s (remain 6m 40s) Loss: 0.0034(0.0005) Grad: 15845.4082  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 15m 16s (remain 6m 16s) Loss: 0.0001(0.0005) Grad: 498.5939  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 15m 40s (remain 5m 52s) Loss: 0.0001(0.0005) Grad: 404.5431  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 16m 4s (remain 5m 27s) Loss: 0.0000(0.0005) Grad: 0.9084  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 16m 28s (remain 5m 3s) Loss: 0.0000(0.0005) Grad: 1.6197  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 16m 52s (remain 4m 39s) Loss: 0.0000(0.0005) Grad: 70.0143  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 17m 16s (remain 4m 15s) Loss: 0.0000(0.0005) Grad: 99.2636  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 17m 40s (remain 3m 51s) Loss: 0.0000(0.0005) Grad: 109.0644  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 18m 4s (remain 3m 27s) Loss: 0.0000(0.0005) Grad: 19.0066  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 18m 28s (remain 3m 3s) Loss: 0.0003(0.0005) Grad: 3817.9243  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 18m 52s (remain 2m 39s) Loss: 0.0000(0.0005) Grad: 230.4775  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 19m 15s (remain 2m 15s) Loss: 0.0000(0.0005) Grad: 50.8336  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 19m 39s (remain 1m 50s) Loss: 0.0000(0.0005) Grad: 15.6974  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 20m 3s (remain 1m 26s) Loss: 0.0010(0.0005) Grad: 7815.2383  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 20m 27s (remain 1m 2s) Loss: 0.0000(0.0005) Grad: 236.5234  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 20m 51s (remain 0m 38s) Loss: 0.0000(0.0005) Grad: 52.9426  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 21m 15s (remain 0m 14s) Loss: 0.0000(0.0005) Grad: 12.6687  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 21m 29s (remain 0m 0s) Loss: 0.0000(0.0005) Grad: 135.9780  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 46s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0001(0.0012) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0012(0.0011) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0000(0.0012) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0055(0.0019) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0021) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0056(0.0020) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0023(0.0019) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0000(0.0018) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0338(0.0018) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0004(0.0020) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0021) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0010(0.0020) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0001(0.0020) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0019) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0019) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0001(0.0018) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0000(0.0018) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0084(0.0017) \n","Epoch 5 - avg_train_loss: 0.0005  avg_val_loss: 0.0017  time: 1529s\n","Epoch 5 - Score: 0.8778\n","Epoch 5 - Save Best Score: 0.8778 Model\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 0s (remain 70m 23s) Loss: 0.0601(0.0601) Grad: 84601.5625  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 0m 27s (remain 24m 5s) Loss: 0.0572(0.0586) Grad: 42782.1094  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 0m 51s (remain 22m 10s) Loss: 0.0405(0.0502) Grad: 30665.7500  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 1m 15s (remain 21m 16s) Loss: 0.0140(0.0419) Grad: 5859.5913  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 1m 39s (remain 20m 35s) Loss: 0.0059(0.0344) Grad: 4303.0776  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 2m 3s (remain 20m 0s) Loss: 0.0066(0.0290) Grad: 1027.3948  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 2m 27s (remain 19m 30s) Loss: 0.0191(0.0253) Grad: 2774.2715  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 2m 51s (remain 19m 1s) Loss: 0.0060(0.0226) Grad: 778.6112  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 3m 15s (remain 18m 33s) Loss: 0.0032(0.0205) Grad: 566.6901  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 3m 39s (remain 18m 6s) Loss: 0.0050(0.0189) Grad: 555.4612  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 4m 3s (remain 17m 40s) Loss: 0.0041(0.0176) Grad: 558.6865  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 4m 27s (remain 17m 14s) Loss: 0.0074(0.0164) Grad: 5233.4648  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 4m 51s (remain 16m 48s) Loss: 0.0011(0.0153) Grad: 282.6139  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 5m 15s (remain 16m 24s) Loss: 0.0008(0.0143) Grad: 332.1998  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 5m 39s (remain 15m 59s) Loss: 0.0005(0.0135) Grad: 113.2487  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 6m 3s (remain 15m 34s) Loss: 0.0038(0.0127) Grad: 1664.4813  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 6m 27s (remain 15m 9s) Loss: 0.0003(0.0120) Grad: 115.2414  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 6m 51s (remain 14m 44s) Loss: 0.0020(0.0114) Grad: 923.3570  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 7m 15s (remain 14m 20s) Loss: 0.0007(0.0109) Grad: 373.3093  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 7m 39s (remain 13m 56s) Loss: 0.0005(0.0104) Grad: 180.3082  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 8m 3s (remain 13m 31s) Loss: 0.0023(0.0099) Grad: 799.4346  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 8m 27s (remain 13m 7s) Loss: 0.0009(0.0095) Grad: 824.9420  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 8m 51s (remain 12m 42s) Loss: 0.0002(0.0092) Grad: 161.8573  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 9m 14s (remain 12m 18s) Loss: 0.0004(0.0089) Grad: 169.0450  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 9m 38s (remain 11m 53s) Loss: 0.0016(0.0086) Grad: 333.0196  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 10m 2s (remain 11m 29s) Loss: 0.0013(0.0083) Grad: 391.0614  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 10m 27s (remain 11m 5s) Loss: 0.0001(0.0080) Grad: 105.1212  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 10m 51s (remain 10m 42s) Loss: 0.0044(0.0078) Grad: 1469.8954  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 11m 16s (remain 10m 18s) Loss: 0.0020(0.0076) Grad: 767.8893  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 11m 40s (remain 9m 54s) Loss: 0.0002(0.0073) Grad: 103.6979  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 12m 4s (remain 9m 30s) Loss: 0.0068(0.0071) Grad: 1545.5516  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 12m 29s (remain 9m 6s) Loss: 0.0009(0.0069) Grad: 195.2148  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 12m 53s (remain 8m 42s) Loss: 0.0015(0.0068) Grad: 275.4797  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 13m 18s (remain 8m 18s) Loss: 0.0002(0.0066) Grad: 140.2225  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 13m 42s (remain 7m 54s) Loss: 0.0007(0.0064) Grad: 159.5231  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 14m 6s (remain 7m 30s) Loss: 0.0004(0.0063) Grad: 131.4010  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 14m 31s (remain 7m 6s) Loss: 0.0001(0.0062) Grad: 25.6463  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 14m 55s (remain 6m 41s) Loss: 0.0114(0.0060) Grad: 2227.0181  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 15m 20s (remain 6m 17s) Loss: 0.0005(0.0059) Grad: 168.0432  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 15m 44s (remain 5m 53s) Loss: 0.0001(0.0058) Grad: 26.5982  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 16m 9s (remain 5m 29s) Loss: 0.0003(0.0057) Grad: 75.2934  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 16m 33s (remain 5m 5s) Loss: 0.0013(0.0056) Grad: 385.0900  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 16m 57s (remain 4m 41s) Loss: 0.0004(0.0055) Grad: 115.3006  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 17m 22s (remain 4m 17s) Loss: 0.0007(0.0054) Grad: 266.4258  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 17m 46s (remain 3m 52s) Loss: 0.0027(0.0053) Grad: 878.4092  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 18m 10s (remain 3m 28s) Loss: 0.0007(0.0052) Grad: 287.8261  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 18m 35s (remain 3m 4s) Loss: 0.0000(0.0051) Grad: 17.1929  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 18m 59s (remain 2m 40s) Loss: 0.0001(0.0050) Grad: 44.7326  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 19m 23s (remain 2m 15s) Loss: 0.0000(0.0049) Grad: 10.3937  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 19m 48s (remain 1m 51s) Loss: 0.0004(0.0048) Grad: 118.3944  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 20m 12s (remain 1m 27s) Loss: 0.0003(0.0048) Grad: 172.9731  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 20m 36s (remain 1m 3s) Loss: 0.0030(0.0047) Grad: 603.5900  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 21m 1s (remain 0m 39s) Loss: 0.0011(0.0046) Grad: 159.2292  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 21m 25s (remain 0m 14s) Loss: 0.0001(0.0046) Grad: 41.2594  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 21m 40s (remain 0m 0s) Loss: 0.0004(0.0045) Grad: 184.1908  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 16m 5s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 33s) Loss: 0.0000(0.0008) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 17s) Loss: 0.0008(0.0009) \n","EVAL: [300/1788] Elapsed 0m 37s (remain 3m 3s) Loss: 0.0015(0.0009) \n","EVAL: [400/1788] Elapsed 0m 49s (remain 2m 51s) Loss: 0.0000(0.0010) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 38s) Loss: 0.0043(0.0011) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 26s) Loss: 0.0002(0.0011) \n","EVAL: [700/1788] Elapsed 1m 26s (remain 2m 13s) Loss: 0.0020(0.0010) \n","EVAL: [800/1788] Elapsed 1m 38s (remain 2m 1s) Loss: 0.0000(0.0010) \n","EVAL: [900/1788] Elapsed 1m 50s (remain 1m 49s) Loss: 0.0009(0.0010) \n","EVAL: [1000/1788] Elapsed 2m 3s (remain 1m 36s) Loss: 0.0011(0.0011) \n","EVAL: [1100/1788] Elapsed 2m 15s (remain 1m 24s) Loss: 0.0001(0.0011) \n","EVAL: [1200/1788] Elapsed 2m 27s (remain 1m 12s) Loss: 0.0000(0.0011) \n","EVAL: [1300/1788] Elapsed 2m 39s (remain 0m 59s) Loss: 0.0003(0.0011) \n","EVAL: [1400/1788] Elapsed 2m 51s (remain 0m 47s) Loss: 0.0057(0.0011) \n","EVAL: [1500/1788] Elapsed 3m 4s (remain 0m 35s) Loss: 0.0034(0.0011) \n","EVAL: [1600/1788] Elapsed 3m 16s (remain 0m 22s) Loss: 0.0000(0.0011) \n","EVAL: [1700/1788] Elapsed 3m 28s (remain 0m 10s) Loss: 0.0001(0.0010) \n","EVAL: [1787/1788] Elapsed 3m 39s (remain 0m 0s) Loss: 0.0003(0.0010) \n","Epoch 1 - avg_train_loss: 0.0045  avg_val_loss: 0.0010  time: 1547s\n","Epoch 1 - Score: 0.8600\n","Epoch 1 - Save Best Score: 0.8600 Model\n","Epoch: [2][0/5362] Elapsed 0m 0s (remain 54m 48s) Loss: 0.0000(0.0000) Grad: 251.0006  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 0m 30s (remain 26m 28s) Loss: 0.0014(0.0008) Grad: 3438.5337  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 0m 56s (remain 24m 4s) Loss: 0.0003(0.0008) Grad: 1307.8081  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 1m 20s (remain 22m 35s) Loss: 0.0004(0.0007) Grad: 618.1047  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 1m 44s (remain 21m 36s) Loss: 0.0000(0.0008) Grad: 47.6742  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 2m 9s (remain 20m 51s) Loss: 0.0009(0.0008) Grad: 3947.6160  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 2m 33s (remain 20m 14s) Loss: 0.0001(0.0008) Grad: 286.5597  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 2m 57s (remain 19m 39s) Loss: 0.0000(0.0008) Grad: 31.3022  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 3m 21s (remain 19m 7s) Loss: 0.0000(0.0008) Grad: 10.4757  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 3m 45s (remain 18m 36s) Loss: 0.0000(0.0008) Grad: 2.5098  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 4m 9s (remain 18m 7s) Loss: 0.0000(0.0008) Grad: 42.2444  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 4m 34s (remain 17m 40s) Loss: 0.0065(0.0008) Grad: 13331.3545  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 4m 58s (remain 17m 12s) Loss: 0.0000(0.0008) Grad: 103.8979  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 5m 22s (remain 16m 45s) Loss: 0.0008(0.0008) Grad: 2025.2502  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 5m 46s (remain 16m 19s) Loss: 0.0000(0.0008) Grad: 87.7874  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 6m 10s (remain 15m 53s) Loss: 0.0001(0.0009) Grad: 679.9696  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 6m 35s (remain 15m 27s) Loss: 0.0002(0.0009) Grad: 1396.9268  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 6m 59s (remain 15m 2s) Loss: 0.0000(0.0009) Grad: 20.9810  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 7m 23s (remain 14m 37s) Loss: 0.0000(0.0009) Grad: 148.0321  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 7m 48s (remain 14m 12s) Loss: 0.0117(0.0009) Grad: 25427.4961  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 8m 12s (remain 13m 47s) Loss: 0.0016(0.0009) Grad: 6167.9868  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 8m 36s (remain 13m 21s) Loss: 0.0091(0.0009) Grad: 21297.9141  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 9m 0s (remain 12m 56s) Loss: 0.0001(0.0009) Grad: 223.7592  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 9m 24s (remain 12m 31s) Loss: 0.0039(0.0009) Grad: 5359.1987  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 9m 49s (remain 12m 6s) Loss: 0.0000(0.0009) Grad: 72.2327  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 10m 13s (remain 11m 41s) Loss: 0.0000(0.0009) Grad: 46.2032  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 10m 37s (remain 11m 16s) Loss: 0.0000(0.0009) Grad: 152.7758  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 11m 1s (remain 10m 51s) Loss: 0.0000(0.0009) Grad: 78.1154  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 11m 25s (remain 10m 27s) Loss: 0.0001(0.0009) Grad: 316.9163  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 11m 50s (remain 10m 2s) Loss: 0.0000(0.0009) Grad: 6.7562  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 12m 14s (remain 9m 37s) Loss: 0.0000(0.0009) Grad: 3.4502  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 12m 38s (remain 9m 13s) Loss: 0.0006(0.0009) Grad: 3075.9893  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 13m 2s (remain 8m 48s) Loss: 0.0000(0.0009) Grad: 18.9243  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 13m 27s (remain 8m 23s) Loss: 0.0000(0.0009) Grad: 10.9227  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 13m 51s (remain 7m 59s) Loss: 0.0001(0.0009) Grad: 213.4198  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 14m 15s (remain 7m 34s) Loss: 0.0000(0.0009) Grad: 32.6958  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 14m 39s (remain 7m 10s) Loss: 0.0001(0.0009) Grad: 474.9978  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 15m 3s (remain 6m 45s) Loss: 0.0000(0.0009) Grad: 128.2823  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 15m 28s (remain 6m 21s) Loss: 0.0009(0.0009) Grad: 2959.4944  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 15m 52s (remain 5m 56s) Loss: 0.0002(0.0009) Grad: 648.4348  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 16m 16s (remain 5m 32s) Loss: 0.0001(0.0009) Grad: 515.6537  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 16m 40s (remain 5m 7s) Loss: 0.0000(0.0009) Grad: 34.3002  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 17m 4s (remain 4m 43s) Loss: 0.0002(0.0009) Grad: 1142.5575  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 17m 29s (remain 4m 18s) Loss: 0.0000(0.0009) Grad: 46.4106  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 17m 53s (remain 3m 54s) Loss: 0.0000(0.0009) Grad: 141.3701  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 18m 17s (remain 3m 29s) Loss: 0.0004(0.0009) Grad: 1806.7428  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 18m 41s (remain 3m 5s) Loss: 0.0003(0.0009) Grad: 1314.4891  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 19m 5s (remain 2m 41s) Loss: 0.0046(0.0009) Grad: 6917.8662  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 19m 29s (remain 2m 16s) Loss: 0.0003(0.0009) Grad: 1192.2507  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 19m 53s (remain 1m 52s) Loss: 0.0000(0.0009) Grad: 133.7103  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 20m 17s (remain 1m 27s) Loss: 0.0010(0.0009) Grad: 2957.8188  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 20m 41s (remain 1m 3s) Loss: 0.0000(0.0009) Grad: 207.2599  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 21m 6s (remain 0m 39s) Loss: 0.0000(0.0009) Grad: 59.8338  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 21m 30s (remain 0m 14s) Loss: 0.0000(0.0009) Grad: 4.9529  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 21m 45s (remain 0m 0s) Loss: 0.0000(0.0009) Grad: 171.9334  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 24s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 32s) Loss: 0.0000(0.0012) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 16s) Loss: 0.0008(0.0012) \n","EVAL: [300/1788] Elapsed 0m 37s (remain 3m 3s) Loss: 0.0019(0.0011) \n","EVAL: [400/1788] Elapsed 0m 49s (remain 2m 51s) Loss: 0.0000(0.0011) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 38s) Loss: 0.0071(0.0012) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 25s) Loss: 0.0001(0.0012) \n","EVAL: [700/1788] Elapsed 1m 26s (remain 2m 13s) Loss: 0.0008(0.0011) \n","EVAL: [800/1788] Elapsed 1m 38s (remain 2m 1s) Loss: 0.0001(0.0011) \n","EVAL: [900/1788] Elapsed 1m 50s (remain 1m 48s) Loss: 0.0012(0.0011) \n","EVAL: [1000/1788] Elapsed 2m 2s (remain 1m 36s) Loss: 0.0004(0.0012) \n","EVAL: [1100/1788] Elapsed 2m 14s (remain 1m 24s) Loss: 0.0002(0.0012) \n","EVAL: [1200/1788] Elapsed 2m 27s (remain 1m 11s) Loss: 0.0000(0.0012) \n","EVAL: [1300/1788] Elapsed 2m 39s (remain 0m 59s) Loss: 0.0003(0.0012) \n","EVAL: [1400/1788] Elapsed 2m 51s (remain 0m 47s) Loss: 0.0079(0.0012) \n","EVAL: [1500/1788] Elapsed 3m 3s (remain 0m 35s) Loss: 0.0026(0.0012) \n","EVAL: [1600/1788] Elapsed 3m 15s (remain 0m 22s) Loss: 0.0000(0.0012) \n","EVAL: [1700/1788] Elapsed 3m 28s (remain 0m 10s) Loss: 0.0001(0.0011) \n","EVAL: [1787/1788] Elapsed 3m 38s (remain 0m 0s) Loss: 0.0001(0.0011) \n","Epoch 2 - avg_train_loss: 0.0009  avg_val_loss: 0.0011  time: 1534s\n","Epoch 2 - Score: 0.8796\n","Epoch 2 - Save Best Score: 0.8796 Model\n","Epoch: [3][0/5362] Elapsed 0m 0s (remain 57m 26s) Loss: 0.0001(0.0001) Grad: 498.0004  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 0m 29s (remain 26m 1s) Loss: 0.0072(0.0004) Grad: 16815.1777  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 0m 55s (remain 23m 32s) Loss: 0.0002(0.0005) Grad: 2145.8870  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 1m 19s (remain 22m 9s) Loss: 0.0023(0.0006) Grad: 15284.2725  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 1m 43s (remain 21m 17s) Loss: 0.0000(0.0007) Grad: 1.2113  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 2m 7s (remain 20m 35s) Loss: 0.0000(0.0007) Grad: 106.2902  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 2m 31s (remain 20m 0s) Loss: 0.0000(0.0007) Grad: 278.1602  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 2m 55s (remain 19m 27s) Loss: 0.0000(0.0007) Grad: 30.5950  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 3m 19s (remain 18m 57s) Loss: 0.0000(0.0007) Grad: 5.0495  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 3m 43s (remain 18m 28s) Loss: 0.0000(0.0007) Grad: 51.1853  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 4m 8s (remain 18m 1s) Loss: 0.0000(0.0007) Grad: 5.9237  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 4m 32s (remain 17m 34s) Loss: 0.0000(0.0007) Grad: 586.4977  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 4m 56s (remain 17m 7s) Loss: 0.0000(0.0007) Grad: 11.4276  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 5m 20s (remain 16m 40s) Loss: 0.0001(0.0007) Grad: 436.8510  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 5m 44s (remain 16m 14s) Loss: 0.0000(0.0007) Grad: 77.4494  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 6m 8s (remain 15m 48s) Loss: 0.0000(0.0007) Grad: 50.3271  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 6m 32s (remain 15m 23s) Loss: 0.0000(0.0007) Grad: 10.1256  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 6m 56s (remain 14m 57s) Loss: 0.0005(0.0007) Grad: 1523.7759  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 7m 21s (remain 14m 32s) Loss: 0.0000(0.0007) Grad: 13.8211  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 7m 45s (remain 14m 7s) Loss: 0.0000(0.0007) Grad: 18.4594  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 8m 9s (remain 13m 41s) Loss: 0.0001(0.0007) Grad: 443.9779  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 8m 33s (remain 13m 17s) Loss: 0.0000(0.0007) Grad: 63.5042  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 8m 57s (remain 12m 52s) Loss: 0.0000(0.0007) Grad: 11.1118  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 9m 21s (remain 12m 27s) Loss: 0.0017(0.0007) Grad: 2997.7524  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 9m 46s (remain 12m 2s) Loss: 0.0000(0.0007) Grad: 7.0773  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 10m 10s (remain 11m 38s) Loss: 0.0000(0.0007) Grad: 5.0644  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 10m 34s (remain 11m 13s) Loss: 0.0000(0.0007) Grad: 124.6624  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 10m 58s (remain 10m 49s) Loss: 0.0000(0.0007) Grad: 20.6197  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 11m 22s (remain 10m 24s) Loss: 0.0000(0.0007) Grad: 59.4509  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 11m 47s (remain 9m 59s) Loss: 0.0009(0.0007) Grad: 4411.9600  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 12m 10s (remain 9m 35s) Loss: 0.0000(0.0007) Grad: 61.9950  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 12m 34s (remain 9m 10s) Loss: 0.0000(0.0007) Grad: 236.8916  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 12m 58s (remain 8m 45s) Loss: 0.0007(0.0007) Grad: 2969.3120  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 13m 21s (remain 8m 20s) Loss: 0.0008(0.0007) Grad: 2103.0090  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 13m 45s (remain 7m 55s) Loss: 0.0000(0.0007) Grad: 2.3166  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 14m 9s (remain 7m 31s) Loss: 0.0176(0.0007) Grad: 18103.1641  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 14m 32s (remain 7m 6s) Loss: 0.0000(0.0007) Grad: 21.3454  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 14m 56s (remain 6m 42s) Loss: 0.0000(0.0007) Grad: 21.4360  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 15m 19s (remain 6m 17s) Loss: 0.0025(0.0007) Grad: 9160.4424  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 15m 43s (remain 5m 53s) Loss: 0.0001(0.0007) Grad: 431.3788  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 16m 7s (remain 5m 28s) Loss: 0.0000(0.0007) Grad: 2.4853  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 16m 30s (remain 5m 4s) Loss: 0.0002(0.0007) Grad: 647.1443  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 16m 54s (remain 4m 40s) Loss: 0.0001(0.0007) Grad: 436.5455  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 17m 17s (remain 4m 15s) Loss: 0.0000(0.0007) Grad: 14.6545  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 17m 41s (remain 3m 51s) Loss: 0.0000(0.0007) Grad: 90.7829  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 18m 4s (remain 3m 27s) Loss: 0.0000(0.0007) Grad: 5.9084  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 18m 28s (remain 3m 3s) Loss: 0.0002(0.0007) Grad: 2232.4487  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 18m 51s (remain 2m 39s) Loss: 0.0002(0.0007) Grad: 1109.7589  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 19m 15s (remain 2m 15s) Loss: 0.0021(0.0007) Grad: 6341.8477  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 19m 39s (remain 1m 50s) Loss: 0.0005(0.0007) Grad: 1656.6207  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 20m 2s (remain 1m 26s) Loss: 0.0034(0.0007) Grad: 6500.9062  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 20m 26s (remain 1m 2s) Loss: 0.0001(0.0007) Grad: 306.1539  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 20m 50s (remain 0m 38s) Loss: 0.0004(0.0007) Grad: 1332.2878  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 21m 13s (remain 0m 14s) Loss: 0.0002(0.0007) Grad: 636.6385  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 21m 27s (remain 0m 0s) Loss: 0.0000(0.0007) Grad: 999.5328  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 27s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0002(0.0015) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0001(0.0014) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0014(0.0013) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0000(0.0012) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0076(0.0013) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0001(0.0013) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0010(0.0012) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0008(0.0012) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0011(0.0012) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0002(0.0013) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0013) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0000(0.0013) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0002(0.0013) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0092(0.0013) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0019(0.0013) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0012) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0002(0.0012) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0000(0.0012) \n","Epoch 3 - avg_train_loss: 0.0007  avg_val_loss: 0.0012  time: 1509s\n","Epoch 3 - Score: 0.8808\n","Epoch 3 - Save Best Score: 0.8808 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 57m 53s) Loss: 0.0005(0.0005) Grad: 2740.8083  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 0m 27s (remain 24m 10s) Loss: 0.0000(0.0004) Grad: 22.3755  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 0m 53s (remain 22m 57s) Loss: 0.0000(0.0005) Grad: 129.4606  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 1m 17s (remain 21m 37s) Loss: 0.0009(0.0004) Grad: 4822.8438  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 1m 40s (remain 20m 44s) Loss: 0.0000(0.0005) Grad: 6.1668  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 2m 4s (remain 20m 4s) Loss: 0.0020(0.0004) Grad: 4416.5054  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 2m 27s (remain 19m 29s) Loss: 0.0000(0.0004) Grad: 249.8530  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 2m 51s (remain 18m 58s) Loss: 0.0033(0.0004) Grad: 24042.7617  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 3m 14s (remain 18m 30s) Loss: 0.0000(0.0005) Grad: 4.3310  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 3m 38s (remain 18m 1s) Loss: 0.0000(0.0005) Grad: 297.4089  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 4m 2s (remain 17m 34s) Loss: 0.0240(0.0005) Grad: 39465.0000  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 4m 25s (remain 17m 7s) Loss: 0.0004(0.0005) Grad: 1529.9580  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 4m 49s (remain 16m 41s) Loss: 0.0006(0.0005) Grad: 1982.5316  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 5m 12s (remain 16m 16s) Loss: 0.0001(0.0005) Grad: 540.3553  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 5m 36s (remain 15m 50s) Loss: 0.0018(0.0005) Grad: 7023.4170  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 5m 59s (remain 15m 24s) Loss: 0.0000(0.0005) Grad: 2.8605  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 6m 23s (remain 15m 0s) Loss: 0.0047(0.0005) Grad: 15021.7529  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 6m 46s (remain 14m 35s) Loss: 0.0001(0.0005) Grad: 3960.3286  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 7m 10s (remain 14m 10s) Loss: 0.0005(0.0005) Grad: 1947.8785  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 7m 33s (remain 13m 45s) Loss: 0.0000(0.0005) Grad: 11.3608  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 7m 56s (remain 13m 20s) Loss: 0.0148(0.0005) Grad: 48525.9609  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 8m 20s (remain 12m 56s) Loss: 0.0001(0.0006) Grad: 566.0805  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 8m 43s (remain 12m 32s) Loss: 0.0000(0.0006) Grad: 11.1150  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 9m 7s (remain 12m 7s) Loss: 0.0000(0.0006) Grad: 10.5792  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 9m 30s (remain 11m 43s) Loss: 0.0000(0.0006) Grad: 0.6259  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 9m 53s (remain 11m 19s) Loss: 0.0000(0.0006) Grad: 11.5984  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 10m 17s (remain 10m 55s) Loss: 0.0000(0.0006) Grad: 75.6690  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 10m 40s (remain 10m 31s) Loss: 0.0000(0.0006) Grad: 5.5221  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 11m 4s (remain 10m 7s) Loss: 0.0002(0.0006) Grad: 2279.7363  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 11m 27s (remain 9m 43s) Loss: 0.0000(0.0006) Grad: 312.4828  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 11m 51s (remain 9m 19s) Loss: 0.0001(0.0006) Grad: 529.4954  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 12m 14s (remain 8m 55s) Loss: 0.0000(0.0006) Grad: 182.4781  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 12m 37s (remain 8m 31s) Loss: 0.0000(0.0006) Grad: 1.2264  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 13m 1s (remain 8m 7s) Loss: 0.0001(0.0006) Grad: 307.0976  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 13m 24s (remain 7m 43s) Loss: 0.0001(0.0006) Grad: 350.1777  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 13m 48s (remain 7m 20s) Loss: 0.0000(0.0006) Grad: 90.6235  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 14m 12s (remain 6m 56s) Loss: 0.0000(0.0006) Grad: 59.4247  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 14m 35s (remain 6m 33s) Loss: 0.0001(0.0006) Grad: 419.0173  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 14m 59s (remain 6m 9s) Loss: 0.0091(0.0006) Grad: 15713.4141  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 15m 23s (remain 5m 45s) Loss: 0.0000(0.0006) Grad: 0.6955  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 15m 46s (remain 5m 22s) Loss: 0.0000(0.0006) Grad: 200.1320  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 16m 10s (remain 4m 58s) Loss: 0.0054(0.0006) Grad: 16287.4951  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 16m 33s (remain 4m 34s) Loss: 0.0000(0.0006) Grad: 22.6356  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 16m 57s (remain 4m 10s) Loss: 0.0000(0.0006) Grad: 205.2357  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 17m 21s (remain 3m 47s) Loss: 0.0000(0.0006) Grad: 11.0702  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 17m 44s (remain 3m 23s) Loss: 0.0000(0.0006) Grad: 0.9410  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 18m 8s (remain 3m 0s) Loss: 0.0000(0.0006) Grad: 507.7776  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 18m 32s (remain 2m 36s) Loss: 0.0000(0.0006) Grad: 1.4680  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 18m 55s (remain 2m 12s) Loss: 0.0000(0.0006) Grad: 295.9088  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 19m 19s (remain 1m 49s) Loss: 0.0000(0.0006) Grad: 138.9360  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 19m 43s (remain 1m 25s) Loss: 0.0000(0.0006) Grad: 26.8163  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 20m 6s (remain 1m 1s) Loss: 0.0000(0.0006) Grad: 5.7780  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 20m 30s (remain 0m 38s) Loss: 0.0000(0.0006) Grad: 12.0854  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 20m 54s (remain 0m 14s) Loss: 0.0000(0.0006) Grad: 160.4313  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 21m 8s (remain 0m 0s) Loss: 0.0000(0.0006) Grad: 191.8623  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 46s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0000(0.0014) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 14s) Loss: 0.0001(0.0014) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0016(0.0013) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0000(0.0012) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0089(0.0014) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0001(0.0013) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 11s) Loss: 0.0005(0.0013) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0000(0.0012) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0014(0.0013) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0002(0.0013) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0014) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0000(0.0014) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0002(0.0014) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0097(0.0014) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0013) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0013) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0002(0.0013) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0000(0.0013) \n","Epoch 4 - avg_train_loss: 0.0006  avg_val_loss: 0.0013  time: 1490s\n","Epoch 4 - Score: 0.8870\n","Epoch 4 - Save Best Score: 0.8870 Model\n","Epoch: [5][0/5362] Elapsed 0m 0s (remain 54m 42s) Loss: 0.0000(0.0000) Grad: 192.3316  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 0m 27s (remain 24m 7s) Loss: 0.0000(0.0003) Grad: 5.3118  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 0m 53s (remain 22m 42s) Loss: 0.0012(0.0006) Grad: 5950.3765  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 1m 16s (remain 21m 29s) Loss: 0.0001(0.0005) Grad: 1346.6628  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 1m 40s (remain 20m 41s) Loss: 0.0004(0.0005) Grad: 1305.5051  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 2m 3s (remain 20m 3s) Loss: 0.0007(0.0004) Grad: 3637.7595  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 2m 27s (remain 19m 31s) Loss: 0.0000(0.0004) Grad: 32.2975  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 2m 51s (remain 18m 59s) Loss: 0.0012(0.0004) Grad: 7167.5122  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 3m 15s (remain 18m 31s) Loss: 0.0000(0.0004) Grad: 10.5344  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 3m 38s (remain 18m 3s) Loss: 0.0000(0.0004) Grad: 16.1477  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 4m 2s (remain 17m 36s) Loss: 0.0000(0.0004) Grad: 55.8775  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 4m 26s (remain 17m 9s) Loss: 0.0000(0.0004) Grad: 2.5748  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 4m 49s (remain 16m 43s) Loss: 0.0000(0.0004) Grad: 6.6890  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 5m 13s (remain 16m 18s) Loss: 0.0000(0.0004) Grad: 9.7315  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 5m 37s (remain 15m 52s) Loss: 0.0004(0.0005) Grad: 1506.6217  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 6m 0s (remain 15m 27s) Loss: 0.0000(0.0005) Grad: 0.8160  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 6m 24s (remain 15m 2s) Loss: 0.0002(0.0005) Grad: 1387.5331  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 6m 48s (remain 14m 38s) Loss: 0.0000(0.0005) Grad: 290.4233  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 7m 11s (remain 14m 13s) Loss: 0.0000(0.0005) Grad: 1.8575  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 7m 35s (remain 13m 49s) Loss: 0.0001(0.0005) Grad: 705.2360  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 7m 59s (remain 13m 24s) Loss: 0.0000(0.0005) Grad: 3.9077  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 8m 22s (remain 13m 0s) Loss: 0.0001(0.0005) Grad: 3357.2817  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 8m 46s (remain 12m 36s) Loss: 0.0000(0.0005) Grad: 10.7899  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 9m 9s (remain 12m 11s) Loss: 0.0004(0.0005) Grad: 1282.8597  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 9m 33s (remain 11m 47s) Loss: 0.0000(0.0005) Grad: 1.7233  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 9m 57s (remain 11m 23s) Loss: 0.0000(0.0005) Grad: 101.5546  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 10m 20s (remain 10m 59s) Loss: 0.0000(0.0005) Grad: 6.6556  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 10m 44s (remain 10m 34s) Loss: 0.0099(0.0005) Grad: 7965.0889  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 11m 8s (remain 10m 10s) Loss: 0.0000(0.0005) Grad: 11.6864  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 11m 31s (remain 9m 46s) Loss: 0.0001(0.0005) Grad: 544.8272  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 11m 55s (remain 9m 22s) Loss: 0.0002(0.0005) Grad: 1677.1395  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 12m 19s (remain 8m 58s) Loss: 0.0002(0.0005) Grad: 1570.1294  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 12m 42s (remain 8m 34s) Loss: 0.0000(0.0005) Grad: 342.4811  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 13m 6s (remain 8m 11s) Loss: 0.0003(0.0005) Grad: 2818.6267  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 13m 30s (remain 7m 47s) Loss: 0.0000(0.0005) Grad: 129.5809  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 13m 53s (remain 7m 23s) Loss: 0.0001(0.0005) Grad: 1197.7312  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 14m 17s (remain 6m 59s) Loss: 0.0000(0.0005) Grad: 438.1879  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 14m 40s (remain 6m 35s) Loss: 0.0000(0.0005) Grad: 6.8374  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 15m 4s (remain 6m 11s) Loss: 0.0000(0.0005) Grad: 255.2454  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 15m 28s (remain 5m 47s) Loss: 0.0000(0.0005) Grad: 2.3487  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 15m 52s (remain 5m 23s) Loss: 0.0014(0.0005) Grad: 4588.3794  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 16m 15s (remain 4m 59s) Loss: 0.0000(0.0005) Grad: 3.7193  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 16m 39s (remain 4m 36s) Loss: 0.0004(0.0005) Grad: 2296.9009  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 17m 2s (remain 4m 12s) Loss: 0.0000(0.0005) Grad: 1.7808  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 17m 26s (remain 3m 48s) Loss: 0.0000(0.0005) Grad: 13.6910  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 17m 50s (remain 3m 24s) Loss: 0.0000(0.0005) Grad: 4.1514  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 18m 14s (remain 3m 0s) Loss: 0.0001(0.0005) Grad: 1111.9432  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 18m 37s (remain 2m 37s) Loss: 0.0000(0.0005) Grad: 0.5878  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 19m 1s (remain 2m 13s) Loss: 0.0000(0.0005) Grad: 17.0880  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 19m 25s (remain 1m 49s) Loss: 0.0000(0.0005) Grad: 14.6809  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 19m 48s (remain 1m 25s) Loss: 0.0001(0.0005) Grad: 639.1565  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 20m 12s (remain 1m 2s) Loss: 0.0005(0.0005) Grad: 3988.4778  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 20m 36s (remain 0m 38s) Loss: 0.0019(0.0005) Grad: 4701.9893  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 21m 0s (remain 0m 14s) Loss: 0.0000(0.0005) Grad: 1.4992  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 21m 14s (remain 0m 0s) Loss: 0.0000(0.0005) Grad: 463.8975  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 8s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0000(0.0017) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 14s) Loss: 0.0001(0.0017) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0011(0.0015) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 49s) Loss: 0.0000(0.0014) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0103(0.0016) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 24s) Loss: 0.0001(0.0016) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0005(0.0015) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0000(0.0014) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0015(0.0015) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0002(0.0015) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0016) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0000(0.0016) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 59s) Loss: 0.0002(0.0016) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0126(0.0016) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0016) \n","EVAL: [1600/1788] Elapsed 3m 14s (remain 0m 22s) Loss: 0.0000(0.0015) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0002(0.0015) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0000(0.0015) \n","Epoch 5 - avg_train_loss: 0.0005  avg_val_loss: 0.0015  time: 1496s\n","Epoch 5 - Score: 0.8869\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 0s (remain 55m 45s) Loss: 0.1609(0.1609) Grad: 196576.8906  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 0m 24s (remain 21m 9s) Loss: 0.1441(0.1286) Grad: 42124.8086  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 0m 48s (remain 20m 34s) Loss: 0.0906(0.1156) Grad: 31239.8320  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 1m 11s (remain 20m 4s) Loss: 0.0650(0.0954) Grad: 26008.0898  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 1m 35s (remain 19m 39s) Loss: 0.0108(0.0764) Grad: 1566.1636  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 1m 59s (remain 19m 15s) Loss: 0.0014(0.0627) Grad: 980.7708  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 2m 22s (remain 18m 50s) Loss: 0.0042(0.0535) Grad: 1306.0067  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 2m 46s (remain 18m 26s) Loss: 0.0183(0.0469) Grad: 3077.0266  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 3m 10s (remain 18m 2s) Loss: 0.0079(0.0418) Grad: 1161.6494  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 3m 33s (remain 17m 38s) Loss: 0.0022(0.0379) Grad: 617.4952  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 3m 57s (remain 17m 13s) Loss: 0.0113(0.0347) Grad: 1599.7909  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 4m 20s (remain 16m 49s) Loss: 0.0048(0.0320) Grad: 1394.8256  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 4m 44s (remain 16m 25s) Loss: 0.0017(0.0297) Grad: 1996.1549  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 5m 8s (remain 16m 2s) Loss: 0.0005(0.0276) Grad: 430.8154  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 5m 32s (remain 15m 38s) Loss: 0.0021(0.0259) Grad: 1286.1462  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 5m 55s (remain 15m 14s) Loss: 0.0004(0.0243) Grad: 406.6878  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 6m 19s (remain 14m 51s) Loss: 0.0024(0.0230) Grad: 1954.7834  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 6m 43s (remain 14m 27s) Loss: 0.0023(0.0218) Grad: 2101.2627  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 7m 6s (remain 14m 4s) Loss: 0.0025(0.0207) Grad: 3819.2551  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 7m 30s (remain 13m 40s) Loss: 0.0069(0.0197) Grad: 5134.0562  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 7m 54s (remain 13m 16s) Loss: 0.0054(0.0188) Grad: 3362.9465  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 8m 18s (remain 12m 53s) Loss: 0.0003(0.0180) Grad: 303.7381  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 8m 41s (remain 12m 29s) Loss: 0.0005(0.0173) Grad: 512.7605  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 9m 5s (remain 12m 5s) Loss: 0.0015(0.0166) Grad: 877.8450  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 9m 29s (remain 11m 41s) Loss: 0.0003(0.0160) Grad: 380.7710  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 9m 52s (remain 11m 18s) Loss: 0.0008(0.0154) Grad: 814.1605  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 10m 16s (remain 10m 54s) Loss: 0.0004(0.0149) Grad: 958.1479  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 10m 40s (remain 10m 30s) Loss: 0.0016(0.0144) Grad: 1366.5369  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 11m 4s (remain 10m 7s) Loss: 0.0001(0.0139) Grad: 213.5842  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 11m 27s (remain 9m 43s) Loss: 0.0000(0.0135) Grad: 36.3449  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 11m 51s (remain 9m 19s) Loss: 0.0003(0.0131) Grad: 234.8458  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 12m 15s (remain 8m 55s) Loss: 0.0018(0.0127) Grad: 724.7840  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 12m 38s (remain 8m 32s) Loss: 0.0011(0.0124) Grad: 1475.1936  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 13m 2s (remain 8m 8s) Loss: 0.0001(0.0121) Grad: 109.3908  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 13m 25s (remain 7m 44s) Loss: 0.0005(0.0117) Grad: 1082.5673  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 13m 49s (remain 7m 20s) Loss: 0.0006(0.0115) Grad: 573.2233  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 14m 13s (remain 6m 57s) Loss: 0.0007(0.0112) Grad: 836.8970  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 14m 36s (remain 6m 33s) Loss: 0.0181(0.0109) Grad: 5003.7173  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 15m 0s (remain 6m 9s) Loss: 0.0003(0.0107) Grad: 222.4094  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 15m 23s (remain 5m 46s) Loss: 0.0016(0.0104) Grad: 578.4919  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 15m 47s (remain 5m 22s) Loss: 0.0000(0.0102) Grad: 31.8819  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 16m 11s (remain 4m 58s) Loss: 0.0001(0.0100) Grad: 61.4714  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 16m 34s (remain 4m 34s) Loss: 0.0046(0.0098) Grad: 1796.8065  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 16m 58s (remain 4m 11s) Loss: 0.0020(0.0096) Grad: 2256.6990  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 17m 22s (remain 3m 47s) Loss: 0.0002(0.0094) Grad: 191.3580  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 17m 45s (remain 3m 23s) Loss: 0.0056(0.0092) Grad: 2206.2812  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 18m 9s (remain 3m 0s) Loss: 0.0012(0.0091) Grad: 779.9829  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 18m 33s (remain 2m 36s) Loss: 0.0005(0.0089) Grad: 241.3329  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 18m 57s (remain 2m 12s) Loss: 0.0018(0.0087) Grad: 1829.9666  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 19m 20s (remain 1m 49s) Loss: 0.0001(0.0086) Grad: 55.9727  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 19m 44s (remain 1m 25s) Loss: 0.0002(0.0084) Grad: 166.6982  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 20m 8s (remain 1m 1s) Loss: 0.0007(0.0083) Grad: 479.8966  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 20m 31s (remain 0m 38s) Loss: 0.0009(0.0081) Grad: 402.7239  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 20m 55s (remain 0m 14s) Loss: 0.0008(0.0080) Grad: 505.3895  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 21m 9s (remain 0m 0s) Loss: 0.0001(0.0079) Grad: 189.9856  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 35s) Loss: 0.0007(0.0007) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0033(0.0008) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0002(0.0008) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0018(0.0008) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0002(0.0009) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0009) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0000(0.0009) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0012(0.0009) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0007(0.0008) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0002(0.0009) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0005(0.0010) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0002(0.0010) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0026(0.0010) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0001(0.0010) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0010(0.0010) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0001(0.0010) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0002(0.0010) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0003(0.0010) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0001(0.0009) \n","Epoch 1 - avg_train_loss: 0.0079  avg_val_loss: 0.0009  time: 1491s\n","Epoch 1 - Score: 0.8499\n","Epoch 1 - Save Best Score: 0.8499 Model\n","Epoch: [2][0/5362] Elapsed 0m 0s (remain 53m 58s) Loss: 0.0005(0.0005) Grad: 1476.1163  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 0m 27s (remain 23m 51s) Loss: 0.0000(0.0013) Grad: 56.0289  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 0m 53s (remain 22m 42s) Loss: 0.0000(0.0011) Grad: 140.3858  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 1m 16s (remain 21m 30s) Loss: 0.0001(0.0011) Grad: 648.0856  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 1m 40s (remain 20m 40s) Loss: 0.0000(0.0012) Grad: 5.7857  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 2m 4s (remain 20m 3s) Loss: 0.0003(0.0011) Grad: 1043.4679  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 2m 27s (remain 19m 31s) Loss: 0.0000(0.0010) Grad: 0.9172  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 2m 51s (remain 19m 0s) Loss: 0.0000(0.0011) Grad: 113.6322  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 3m 15s (remain 18m 31s) Loss: 0.0018(0.0011) Grad: 11800.5029  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 3m 39s (remain 18m 4s) Loss: 0.0012(0.0011) Grad: 2992.1121  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 4m 2s (remain 17m 37s) Loss: 0.0003(0.0010) Grad: 1490.8818  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 4m 26s (remain 17m 11s) Loss: 0.0000(0.0010) Grad: 428.3936  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 4m 50s (remain 16m 45s) Loss: 0.0017(0.0010) Grad: 3665.2502  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 5m 13s (remain 16m 19s) Loss: 0.0001(0.0010) Grad: 630.4578  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 5m 37s (remain 15m 54s) Loss: 0.0007(0.0010) Grad: 1777.6547  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 6m 1s (remain 15m 29s) Loss: 0.0002(0.0010) Grad: 780.2231  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 6m 24s (remain 15m 4s) Loss: 0.0001(0.0010) Grad: 741.2881  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 6m 48s (remain 14m 39s) Loss: 0.0000(0.0010) Grad: 19.2852  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 7m 12s (remain 14m 14s) Loss: 0.0015(0.0010) Grad: 3322.7087  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 7m 35s (remain 13m 49s) Loss: 0.0000(0.0010) Grad: 38.5787  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 7m 59s (remain 13m 25s) Loss: 0.0000(0.0010) Grad: 144.5261  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 8m 23s (remain 13m 0s) Loss: 0.0000(0.0010) Grad: 207.3349  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 8m 46s (remain 12m 36s) Loss: 0.0000(0.0010) Grad: 182.5318  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 9m 10s (remain 12m 12s) Loss: 0.0000(0.0010) Grad: 31.5976  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 9m 34s (remain 11m 48s) Loss: 0.0040(0.0010) Grad: 8953.5371  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 9m 58s (remain 11m 24s) Loss: 0.0005(0.0010) Grad: 3034.0623  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 10m 22s (remain 11m 0s) Loss: 0.0001(0.0010) Grad: 406.1560  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 10m 46s (remain 10m 37s) Loss: 0.0000(0.0010) Grad: 18.3288  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 11m 11s (remain 10m 14s) Loss: 0.0001(0.0010) Grad: 1333.2510  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 11m 36s (remain 9m 50s) Loss: 0.0085(0.0010) Grad: 12621.1318  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 12m 0s (remain 9m 26s) Loss: 0.0005(0.0010) Grad: 1431.7709  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 12m 25s (remain 9m 3s) Loss: 0.0000(0.0010) Grad: 21.6122  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 12m 49s (remain 8m 39s) Loss: 0.0040(0.0010) Grad: 13212.1807  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 13m 14s (remain 8m 15s) Loss: 0.0001(0.0010) Grad: 442.2640  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 13m 38s (remain 7m 52s) Loss: 0.0008(0.0010) Grad: 2618.7253  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 14m 3s (remain 7m 28s) Loss: 0.0000(0.0010) Grad: 50.3747  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 14m 27s (remain 7m 4s) Loss: 0.0000(0.0010) Grad: 5.6292  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 14m 52s (remain 6m 40s) Loss: 0.0000(0.0010) Grad: 44.2582  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 15m 17s (remain 6m 16s) Loss: 0.0001(0.0010) Grad: 238.7465  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 15m 42s (remain 5m 52s) Loss: 0.0005(0.0010) Grad: 2505.6052  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 16m 7s (remain 5m 28s) Loss: 0.0008(0.0010) Grad: 1953.0571  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 16m 31s (remain 5m 4s) Loss: 0.0000(0.0010) Grad: 237.6293  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 16m 55s (remain 4m 40s) Loss: 0.0030(0.0010) Grad: 8509.2764  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 17m 19s (remain 4m 16s) Loss: 0.0000(0.0010) Grad: 128.3697  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 17m 43s (remain 3m 52s) Loss: 0.0006(0.0010) Grad: 1118.1504  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 18m 7s (remain 3m 28s) Loss: 0.0013(0.0010) Grad: 3286.0234  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 18m 31s (remain 3m 3s) Loss: 0.0002(0.0010) Grad: 507.8210  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 18m 55s (remain 2m 39s) Loss: 0.0000(0.0010) Grad: 15.7241  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 19m 19s (remain 2m 15s) Loss: 0.0002(0.0010) Grad: 979.9554  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 19m 43s (remain 1m 51s) Loss: 0.0000(0.0010) Grad: 13.4902  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 20m 8s (remain 1m 27s) Loss: 0.0001(0.0010) Grad: 619.3224  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 20m 32s (remain 1m 3s) Loss: 0.0000(0.0010) Grad: 21.3450  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 20m 56s (remain 0m 38s) Loss: 0.0001(0.0010) Grad: 413.8128  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 21m 20s (remain 0m 14s) Loss: 0.0004(0.0010) Grad: 3431.5742  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 21m 35s (remain 0m 0s) Loss: 0.0000(0.0010) Grad: 635.6931  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 44s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 30s) Loss: 0.0003(0.0007) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 15s) Loss: 0.0000(0.0007) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 2s) Loss: 0.0013(0.0007) \n","EVAL: [400/1788] Elapsed 0m 49s (remain 2m 49s) Loss: 0.0000(0.0008) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 37s) Loss: 0.0000(0.0008) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 25s) Loss: 0.0000(0.0009) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0002(0.0008) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 2m 0s) Loss: 0.0008(0.0008) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 48s) Loss: 0.0000(0.0009) \n","EVAL: [1000/1788] Elapsed 2m 2s (remain 1m 35s) Loss: 0.0010(0.0009) \n","EVAL: [1100/1788] Elapsed 2m 14s (remain 1m 23s) Loss: 0.0001(0.0010) \n","EVAL: [1200/1788] Elapsed 2m 26s (remain 1m 11s) Loss: 0.0030(0.0010) \n","EVAL: [1300/1788] Elapsed 2m 38s (remain 0m 59s) Loss: 0.0000(0.0010) \n","EVAL: [1400/1788] Elapsed 2m 50s (remain 0m 47s) Loss: 0.0007(0.0010) \n","EVAL: [1500/1788] Elapsed 3m 2s (remain 0m 34s) Loss: 0.0000(0.0010) \n","EVAL: [1600/1788] Elapsed 3m 15s (remain 0m 22s) Loss: 0.0002(0.0010) \n","EVAL: [1700/1788] Elapsed 3m 27s (remain 0m 10s) Loss: 0.0001(0.0010) \n","EVAL: [1787/1788] Elapsed 3m 37s (remain 0m 0s) Loss: 0.0000(0.0010) \n","Epoch 2 - avg_train_loss: 0.0010  avg_val_loss: 0.0010  time: 1519s\n","Epoch 2 - Score: 0.8838\n","Epoch 2 - Save Best Score: 0.8838 Model\n","Epoch: [3][0/5362] Elapsed 0m 0s (remain 56m 31s) Loss: 0.0000(0.0000) Grad: 694.0881  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 0m 28s (remain 24m 54s) Loss: 0.0000(0.0005) Grad: 80.5553  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 0m 54s (remain 23m 24s) Loss: 0.0000(0.0005) Grad: 4.3913  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 1m 18s (remain 22m 6s) Loss: 0.0001(0.0005) Grad: 402.3575  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 1m 43s (remain 21m 14s) Loss: 0.0011(0.0006) Grad: 1634.7112  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 2m 7s (remain 20m 32s) Loss: 0.0001(0.0006) Grad: 324.7942  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 2m 31s (remain 19m 56s) Loss: 0.0016(0.0006) Grad: 6930.5854  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 2m 55s (remain 19m 24s) Loss: 0.0000(0.0006) Grad: 34.1230  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 3m 19s (remain 18m 53s) Loss: 0.0192(0.0007) Grad: 20369.0195  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 3m 43s (remain 18m 26s) Loss: 0.0000(0.0007) Grad: 1.2351  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 4m 7s (remain 17m 58s) Loss: 0.0004(0.0007) Grad: 820.0178  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 4m 31s (remain 17m 31s) Loss: 0.0001(0.0007) Grad: 399.6365  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 4m 55s (remain 17m 5s) Loss: 0.0001(0.0007) Grad: 599.7388  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 5m 20s (remain 16m 39s) Loss: 0.0008(0.0007) Grad: 2332.6824  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 5m 44s (remain 16m 12s) Loss: 0.0001(0.0007) Grad: 200.3138  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 6m 8s (remain 15m 46s) Loss: 0.0000(0.0007) Grad: 70.0602  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 6m 32s (remain 15m 21s) Loss: 0.0004(0.0007) Grad: 1627.8344  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 6m 56s (remain 14m 56s) Loss: 0.0000(0.0007) Grad: 24.7106  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 7m 20s (remain 14m 30s) Loss: 0.0008(0.0007) Grad: 2313.3276  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 7m 44s (remain 14m 5s) Loss: 0.0001(0.0007) Grad: 995.4861  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 8m 8s (remain 13m 40s) Loss: 0.0000(0.0007) Grad: 61.1922  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 8m 32s (remain 13m 15s) Loss: 0.0000(0.0007) Grad: 6.4971  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 8m 56s (remain 12m 50s) Loss: 0.0002(0.0007) Grad: 1404.0470  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 9m 20s (remain 12m 25s) Loss: 0.0000(0.0007) Grad: 31.1341  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 9m 44s (remain 12m 0s) Loss: 0.0005(0.0007) Grad: 1708.3494  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 10m 8s (remain 11m 36s) Loss: 0.0001(0.0007) Grad: 549.5087  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 10m 32s (remain 11m 11s) Loss: 0.0056(0.0007) Grad: 4684.3315  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 10m 56s (remain 10m 46s) Loss: 0.0069(0.0007) Grad: 34289.1641  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 11m 20s (remain 10m 22s) Loss: 0.0001(0.0007) Grad: 377.0968  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 11m 44s (remain 9m 57s) Loss: 0.0003(0.0008) Grad: 3648.8213  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 12m 8s (remain 9m 32s) Loss: 0.0005(0.0008) Grad: 1226.0417  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 12m 31s (remain 9m 8s) Loss: 0.0000(0.0007) Grad: 133.1136  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 12m 55s (remain 8m 43s) Loss: 0.0014(0.0008) Grad: 4773.5488  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 13m 19s (remain 8m 19s) Loss: 0.0004(0.0008) Grad: 1403.0315  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 13m 43s (remain 7m 54s) Loss: 0.0071(0.0008) Grad: 19541.4043  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 14m 7s (remain 7m 30s) Loss: 0.0002(0.0008) Grad: 1041.3710  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 14m 31s (remain 7m 6s) Loss: 0.0002(0.0008) Grad: 1217.0780  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 14m 54s (remain 6m 41s) Loss: 0.0001(0.0008) Grad: 421.0456  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 15m 18s (remain 6m 17s) Loss: 0.0000(0.0008) Grad: 291.6229  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 15m 42s (remain 5m 53s) Loss: 0.0006(0.0008) Grad: 2968.4211  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 16m 6s (remain 5m 28s) Loss: 0.0000(0.0008) Grad: 169.7446  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 16m 30s (remain 5m 4s) Loss: 0.0001(0.0008) Grad: 408.8242  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 16m 55s (remain 4m 40s) Loss: 0.0000(0.0008) Grad: 121.7886  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 17m 19s (remain 4m 16s) Loss: 0.0026(0.0008) Grad: 29297.0449  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 17m 43s (remain 3m 52s) Loss: 0.0000(0.0008) Grad: 192.6676  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 18m 7s (remain 3m 28s) Loss: 0.0000(0.0008) Grad: 38.6620  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 18m 31s (remain 3m 3s) Loss: 0.0000(0.0008) Grad: 96.6256  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 18m 55s (remain 2m 39s) Loss: 0.0000(0.0008) Grad: 19.2494  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 19m 19s (remain 2m 15s) Loss: 0.0005(0.0008) Grad: 1543.1252  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 19m 44s (remain 1m 51s) Loss: 0.0000(0.0008) Grad: 176.9163  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 20m 9s (remain 1m 27s) Loss: 0.0010(0.0008) Grad: 6641.9517  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 20m 33s (remain 1m 3s) Loss: 0.0000(0.0008) Grad: 3.1875  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 20m 57s (remain 0m 38s) Loss: 0.0000(0.0008) Grad: 14.3254  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 21m 21s (remain 0m 14s) Loss: 0.0001(0.0008) Grad: 611.9311  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 21m 36s (remain 0m 0s) Loss: 0.0000(0.0008) Grad: 1056.1268  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 54s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0049(0.0012) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 14s) Loss: 0.0000(0.0010) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0012(0.0010) \n","EVAL: [400/1788] Elapsed 0m 49s (remain 2m 49s) Loss: 0.0000(0.0011) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 37s) Loss: 0.0000(0.0011) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0000(0.0010) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0001(0.0010) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 2m 0s) Loss: 0.0008(0.0010) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0000(0.0011) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0010(0.0011) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0001(0.0011) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0028(0.0012) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 59s) Loss: 0.0000(0.0012) \n","EVAL: [1400/1788] Elapsed 2m 50s (remain 0m 47s) Loss: 0.0008(0.0012) \n","EVAL: [1500/1788] Elapsed 3m 2s (remain 0m 34s) Loss: 0.0000(0.0012) \n","EVAL: [1600/1788] Elapsed 3m 14s (remain 0m 22s) Loss: 0.0002(0.0012) \n","EVAL: [1700/1788] Elapsed 3m 26s (remain 0m 10s) Loss: 0.0001(0.0011) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0000(0.0011) \n","Epoch 3 - avg_train_loss: 0.0008  avg_val_loss: 0.0011  time: 1519s\n","Epoch 3 - Score: 0.8840\n","Epoch 3 - Save Best Score: 0.8840 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 56m 35s) Loss: 0.0000(0.0000) Grad: 994.0925  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 0m 27s (remain 23m 48s) Loss: 0.0008(0.0008) Grad: 2357.5300  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 0m 54s (remain 23m 6s) Loss: 0.0000(0.0006) Grad: 79.6376  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 1m 18s (remain 21m 51s) Loss: 0.0000(0.0005) Grad: 11.6276  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 1m 41s (remain 21m 1s) Loss: 0.0002(0.0006) Grad: 993.9947  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 2m 6s (remain 20m 22s) Loss: 0.0001(0.0006) Grad: 394.8600  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 2m 29s (remain 19m 48s) Loss: 0.0001(0.0006) Grad: 1050.2178  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 2m 54s (remain 19m 17s) Loss: 0.0002(0.0005) Grad: 1877.6704  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 3m 18s (remain 18m 49s) Loss: 0.0003(0.0006) Grad: 3845.4460  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 3m 42s (remain 18m 20s) Loss: 0.0003(0.0006) Grad: 2132.3037  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 4m 6s (remain 17m 53s) Loss: 0.0016(0.0006) Grad: 4671.9536  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 4m 30s (remain 17m 26s) Loss: 0.0000(0.0006) Grad: 33.7851  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 4m 54s (remain 16m 59s) Loss: 0.0007(0.0006) Grad: 3301.6360  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 5m 18s (remain 16m 33s) Loss: 0.0003(0.0007) Grad: 1246.4408  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 5m 42s (remain 16m 7s) Loss: 0.0001(0.0006) Grad: 780.8140  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 6m 6s (remain 15m 42s) Loss: 0.0000(0.0006) Grad: 16.4983  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 6m 30s (remain 15m 16s) Loss: 0.0000(0.0006) Grad: 9.7807  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 6m 54s (remain 14m 51s) Loss: 0.0000(0.0006) Grad: 12.5863  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 7m 18s (remain 14m 26s) Loss: 0.0003(0.0006) Grad: 1566.8812  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 7m 42s (remain 14m 1s) Loss: 0.0001(0.0006) Grad: 424.9160  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 8m 6s (remain 13m 36s) Loss: 0.0054(0.0006) Grad: 50096.4922  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 8m 30s (remain 13m 11s) Loss: 0.0013(0.0006) Grad: 3976.5369  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 8m 54s (remain 12m 47s) Loss: 0.0003(0.0006) Grad: 2219.7649  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 9m 19s (remain 12m 23s) Loss: 0.0000(0.0006) Grad: 1.1198  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 9m 43s (remain 11m 59s) Loss: 0.0000(0.0006) Grad: 3.2817  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 10m 8s (remain 11m 35s) Loss: 0.0002(0.0006) Grad: 1834.7609  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 10m 32s (remain 11m 11s) Loss: 0.0000(0.0006) Grad: 44.8703  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 10m 56s (remain 10m 47s) Loss: 0.0001(0.0006) Grad: 411.1900  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 11m 21s (remain 10m 22s) Loss: 0.0000(0.0006) Grad: 127.5384  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 11m 45s (remain 9m 58s) Loss: 0.0000(0.0006) Grad: 9.2459  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 12m 9s (remain 9m 33s) Loss: 0.0000(0.0006) Grad: 6.2581  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 12m 33s (remain 9m 9s) Loss: 0.0000(0.0006) Grad: 6.5575  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 12m 58s (remain 8m 45s) Loss: 0.0000(0.0006) Grad: 35.0399  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 13m 22s (remain 8m 21s) Loss: 0.0000(0.0006) Grad: 16.5355  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 13m 46s (remain 7m 56s) Loss: 0.0000(0.0006) Grad: 5.4595  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 14m 11s (remain 7m 32s) Loss: 0.0000(0.0006) Grad: 111.4477  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 14m 35s (remain 7m 8s) Loss: 0.0001(0.0006) Grad: 825.8069  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 14m 59s (remain 6m 43s) Loss: 0.0000(0.0006) Grad: 5.4568  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 15m 24s (remain 6m 19s) Loss: 0.0000(0.0006) Grad: 19.9402  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 15m 48s (remain 5m 55s) Loss: 0.0003(0.0006) Grad: 1365.6331  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 16m 12s (remain 5m 30s) Loss: 0.0001(0.0006) Grad: 385.5520  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 16m 36s (remain 5m 6s) Loss: 0.0004(0.0006) Grad: 2711.4783  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 17m 0s (remain 4m 42s) Loss: 0.0000(0.0006) Grad: 9.7806  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 17m 25s (remain 4m 17s) Loss: 0.0000(0.0006) Grad: 27.1357  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 17m 49s (remain 3m 53s) Loss: 0.0005(0.0006) Grad: 2304.4314  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 18m 13s (remain 3m 29s) Loss: 0.0003(0.0006) Grad: 2061.3250  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 18m 37s (remain 3m 4s) Loss: 0.0000(0.0006) Grad: 33.6020  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 19m 1s (remain 2m 40s) Loss: 0.0012(0.0006) Grad: 14519.6826  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 19m 26s (remain 2m 16s) Loss: 0.0001(0.0006) Grad: 1677.1643  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 19m 50s (remain 1m 51s) Loss: 0.0008(0.0006) Grad: 1612.6495  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 20m 14s (remain 1m 27s) Loss: 0.0003(0.0006) Grad: 2144.8938  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 20m 39s (remain 1m 3s) Loss: 0.0000(0.0006) Grad: 98.2748  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 21m 3s (remain 0m 39s) Loss: 0.0000(0.0006) Grad: 102.9105  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 21m 27s (remain 0m 14s) Loss: 0.0000(0.0006) Grad: 159.7718  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 21m 42s (remain 0m 0s) Loss: 0.0010(0.0006) Grad: 2890.1997  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 6s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0006(0.0010) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 15s) Loss: 0.0000(0.0010) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 2s) Loss: 0.0010(0.0010) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 49s) Loss: 0.0000(0.0011) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 37s) Loss: 0.0000(0.0012) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0000(0.0011) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0000(0.0012) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 2m 0s) Loss: 0.0013(0.0011) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0000(0.0012) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0016(0.0012) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0001(0.0013) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0026(0.0013) \n","EVAL: [1300/1788] Elapsed 2m 38s (remain 0m 59s) Loss: 0.0000(0.0013) \n","EVAL: [1400/1788] Elapsed 2m 50s (remain 0m 47s) Loss: 0.0008(0.0013) \n","EVAL: [1500/1788] Elapsed 3m 2s (remain 0m 34s) Loss: 0.0000(0.0013) \n","EVAL: [1600/1788] Elapsed 3m 14s (remain 0m 22s) Loss: 0.0001(0.0013) \n","EVAL: [1700/1788] Elapsed 3m 26s (remain 0m 10s) Loss: 0.0000(0.0013) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0000(0.0012) \n","Epoch 4 - avg_train_loss: 0.0006  avg_val_loss: 0.0012  time: 1525s\n","Epoch 4 - Score: 0.8872\n","Epoch 4 - Save Best Score: 0.8872 Model\n","Epoch: [5][0/5362] Elapsed 0m 0s (remain 60m 4s) Loss: 0.0007(0.0007) Grad: 5279.6704  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 0m 28s (remain 24m 30s) Loss: 0.0000(0.0006) Grad: 11.5689  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 0m 54s (remain 23m 12s) Loss: 0.0003(0.0005) Grad: 1182.5970  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 1m 18s (remain 21m 56s) Loss: 0.0000(0.0006) Grad: 71.8393  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 1m 42s (remain 21m 6s) Loss: 0.0003(0.0006) Grad: 1255.8005  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 2m 6s (remain 20m 26s) Loss: 0.0000(0.0006) Grad: 66.8432  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 2m 30s (remain 19m 53s) Loss: 0.0000(0.0006) Grad: 11.2216  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 2m 54s (remain 19m 21s) Loss: 0.0000(0.0006) Grad: 179.1568  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 3m 18s (remain 18m 51s) Loss: 0.0004(0.0006) Grad: 2581.5046  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 3m 42s (remain 18m 23s) Loss: 0.0001(0.0006) Grad: 504.7354  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 4m 6s (remain 17m 55s) Loss: 0.0000(0.0006) Grad: 14.4158  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 4m 31s (remain 17m 28s) Loss: 0.0000(0.0005) Grad: 2.8175  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 4m 55s (remain 17m 2s) Loss: 0.0000(0.0005) Grad: 62.2394  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 5m 19s (remain 16m 36s) Loss: 0.0001(0.0005) Grad: 731.1837  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 5m 43s (remain 16m 11s) Loss: 0.0001(0.0005) Grad: 584.6351  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 6m 7s (remain 15m 45s) Loss: 0.0009(0.0005) Grad: 7316.8237  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 6m 32s (remain 15m 21s) Loss: 0.0000(0.0005) Grad: 24.4077  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 6m 56s (remain 14m 56s) Loss: 0.0000(0.0005) Grad: 4.4522  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 7m 20s (remain 14m 30s) Loss: 0.0000(0.0005) Grad: 20.7244  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 7m 44s (remain 14m 5s) Loss: 0.0026(0.0005) Grad: 9100.6719  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 8m 8s (remain 13m 41s) Loss: 0.0000(0.0005) Grad: 2.3671  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 8m 32s (remain 13m 16s) Loss: 0.0000(0.0005) Grad: 252.0397  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 8m 57s (remain 12m 51s) Loss: 0.0000(0.0005) Grad: 2.8078  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 9m 21s (remain 12m 26s) Loss: 0.0001(0.0005) Grad: 598.3943  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 9m 45s (remain 12m 1s) Loss: 0.0001(0.0005) Grad: 1122.9762  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 10m 9s (remain 11m 37s) Loss: 0.0000(0.0005) Grad: 8.2377  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 10m 33s (remain 11m 12s) Loss: 0.0001(0.0005) Grad: 385.3005  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 10m 57s (remain 10m 48s) Loss: 0.0058(0.0005) Grad: 7297.9922  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 11m 21s (remain 10m 23s) Loss: 0.0000(0.0005) Grad: 69.2942  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 11m 46s (remain 9m 58s) Loss: 0.0002(0.0005) Grad: 935.8044  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 12m 10s (remain 9m 34s) Loss: 0.0001(0.0005) Grad: 1121.1194  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 12m 34s (remain 9m 9s) Loss: 0.0001(0.0005) Grad: 448.2649  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 12m 58s (remain 8m 45s) Loss: 0.0000(0.0005) Grad: 11.6977  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 13m 23s (remain 8m 21s) Loss: 0.0000(0.0005) Grad: 2.9300  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 13m 48s (remain 7m 57s) Loss: 0.0000(0.0005) Grad: 26.0070  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 14m 12s (remain 7m 33s) Loss: 0.0005(0.0005) Grad: 2971.5132  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 14m 37s (remain 7m 8s) Loss: 0.0000(0.0005) Grad: 22.1138  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 15m 1s (remain 6m 44s) Loss: 0.0000(0.0005) Grad: 216.5793  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 15m 26s (remain 6m 20s) Loss: 0.0019(0.0005) Grad: 4584.5308  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 15m 50s (remain 5m 56s) Loss: 0.0002(0.0005) Grad: 1869.3301  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 16m 15s (remain 5m 31s) Loss: 0.0000(0.0005) Grad: 2.7320  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 16m 39s (remain 5m 7s) Loss: 0.0008(0.0005) Grad: 3674.8767  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 17m 4s (remain 4m 43s) Loss: 0.0000(0.0005) Grad: 1.6747  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 17m 29s (remain 4m 18s) Loss: 0.0384(0.0005) Grad: 83521.4609  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 17m 54s (remain 3m 54s) Loss: 0.0000(0.0005) Grad: 1.6598  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 18m 18s (remain 3m 30s) Loss: 0.0000(0.0005) Grad: 1.0527  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 18m 43s (remain 3m 5s) Loss: 0.0001(0.0005) Grad: 746.1064  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 19m 7s (remain 2m 41s) Loss: 0.0000(0.0005) Grad: 14.1483  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 19m 31s (remain 2m 16s) Loss: 0.0000(0.0005) Grad: 1.4722  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 19m 55s (remain 1m 52s) Loss: 0.0000(0.0005) Grad: 4.2666  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 20m 20s (remain 1m 28s) Loss: 0.0000(0.0005) Grad: 1.4985  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 20m 44s (remain 1m 3s) Loss: 0.0000(0.0005) Grad: 16.8016  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 21m 8s (remain 0m 39s) Loss: 0.0000(0.0005) Grad: 61.9466  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 21m 32s (remain 0m 14s) Loss: 0.0003(0.0005) Grad: 1630.9978  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 21m 47s (remain 0m 0s) Loss: 0.0004(0.0005) Grad: 3071.3684  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 9s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0020(0.0013) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 14s) Loss: 0.0000(0.0012) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 2s) Loss: 0.0003(0.0011) \n","EVAL: [400/1788] Elapsed 0m 49s (remain 2m 49s) Loss: 0.0000(0.0012) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 37s) Loss: 0.0000(0.0013) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 25s) Loss: 0.0000(0.0013) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 12s) Loss: 0.0000(0.0013) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 2m 0s) Loss: 0.0009(0.0012) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 48s) Loss: 0.0000(0.0013) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0014(0.0014) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0002(0.0014) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 11s) Loss: 0.0039(0.0015) \n","EVAL: [1300/1788] Elapsed 2m 38s (remain 0m 59s) Loss: 0.0000(0.0015) \n","EVAL: [1400/1788] Elapsed 2m 50s (remain 0m 47s) Loss: 0.0009(0.0014) \n","EVAL: [1500/1788] Elapsed 3m 2s (remain 0m 34s) Loss: 0.0000(0.0014) \n","EVAL: [1600/1788] Elapsed 3m 14s (remain 0m 22s) Loss: 0.0000(0.0014) \n","EVAL: [1700/1788] Elapsed 3m 26s (remain 0m 10s) Loss: 0.0000(0.0014) \n","EVAL: [1787/1788] Elapsed 3m 36s (remain 0m 0s) Loss: 0.0000(0.0014) \n","Epoch 5 - avg_train_loss: 0.0005  avg_val_loss: 0.0014  time: 1530s\n","Epoch 5 - Score: 0.8882\n","Epoch 5 - Save Best Score: 0.8882 Model\n","Best thres: 0.5, Score: 0.8828\n","Best thres: 0.5022460937500001, Score: 0.8829\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bf06bcc08444ba7949645b547ce3fc8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1392b34e5d074358bb2a0c16470bdf4c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"993d695a47d249e898cee3720dbe69b4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5cd33c6a0ae473fa03155b7c7c43e9b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"],"id":"local-thesis"}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp041.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"14a952eacf8c4d90936a9ad04d86be58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19553a7a76bd4cbb961d971391e377f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b41bb17e82c040638fa4343086f8c3c1","placeholder":"​","style":"IPY_MODEL_de5f2795155447219dfeb4b772bbad2f","value":" 42146/42146 [00:37&lt;00:00, 1895.43it/s]"}},"315e2287c4474aca80d6650069881c64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"400714f150d64e0785fc04856af6232c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55ac100ee9454506bafed861979a98af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4737cc39a6340389e1c55638a4c477e","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14a952eacf8c4d90936a9ad04d86be58","value":42146}},"7516bd3698ca4a33ae2ee85ef72b35cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"804143bbdc894a9e9d217e8341a6f5e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b67290b23f7743a8940f1786fd62c420","IPY_MODEL_55ac100ee9454506bafed861979a98af","IPY_MODEL_19553a7a76bd4cbb961d971391e377f5"],"layout":"IPY_MODEL_315e2287c4474aca80d6650069881c64"}},"8ffc7f496aed4ee78f8eb4bfba37b657":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1feab8ab0b4489aa00d7230eb653c4c","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba2ea79c94034391b4eb66b222743251","value":143}},"9f2f0ee40a31436eb216000ef3f11563":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3e5bdf2bb454162a7d53e2eb495b2ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc71e7f8d1654888b1825dd16e4e8b8f","IPY_MODEL_8ffc7f496aed4ee78f8eb4bfba37b657","IPY_MODEL_bc346217d9974441989d171cd0bc2790"],"layout":"IPY_MODEL_a5f73808ceec46cebdfad18e8dede294"}},"a5f73808ceec46cebdfad18e8dede294":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00f5f81ec48436a84488f58f76a26c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b41bb17e82c040638fa4343086f8c3c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b67290b23f7743a8940f1786fd62c420":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_400714f150d64e0785fc04856af6232c","placeholder":"​","style":"IPY_MODEL_9f2f0ee40a31436eb216000ef3f11563","value":"100%"}},"ba2ea79c94034391b4eb66b222743251":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc346217d9974441989d171cd0bc2790":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7516bd3698ca4a33ae2ee85ef72b35cf","placeholder":"​","style":"IPY_MODEL_b00f5f81ec48436a84488f58f76a26c2","value":" 143/143 [00:00&lt;00:00, 2301.71it/s]"}},"bc6a2e70a90640f8a8ff51b0671744e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc71e7f8d1654888b1825dd16e4e8b8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc6a2e70a90640f8a8ff51b0671744e0","placeholder":"​","style":"IPY_MODEL_ff70987fd36c4e299f711c48db3da431","value":"100%"}},"d4737cc39a6340389e1c55638a4c477e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de5f2795155447219dfeb4b772bbad2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1feab8ab0b4489aa00d7230eb653c4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff70987fd36c4e299f711c48db3da431":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bf06bcc08444ba7949645b547ce3fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb8759124bbb4dbf8531874f81b03767","IPY_MODEL_601929a1404647aab5beff525b6714bc","IPY_MODEL_0eece35b85a84108bbf4c42b2407e566"],"layout":"IPY_MODEL_ed098845954245749ca99d61ea587c78"}},"cb8759124bbb4dbf8531874f81b03767":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87e24105108d4222878f5e3774fe09ff","placeholder":"​","style":"IPY_MODEL_94c0d72371b6494389d2860bb4e8ce83","value":"100%"}},"601929a1404647aab5beff525b6714bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bbcc64b7629448ca287b84b800ebcf0","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31409bb7aeff4a78af049eabd47f3b85","value":3}},"0eece35b85a84108bbf4c42b2407e566":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45b8a5b6a04b4049a0f8ca5e21b5232d","placeholder":"​","style":"IPY_MODEL_01fcc07086b24317a1185dcb97af2b8d","value":" 3/3 [00:01&lt;00:00,  1.57it/s]"}},"ed098845954245749ca99d61ea587c78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87e24105108d4222878f5e3774fe09ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94c0d72371b6494389d2860bb4e8ce83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bbcc64b7629448ca287b84b800ebcf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31409bb7aeff4a78af049eabd47f3b85":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45b8a5b6a04b4049a0f8ca5e21b5232d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01fcc07086b24317a1185dcb97af2b8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1392b34e5d074358bb2a0c16470bdf4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e66850f233a443568fcf0e536b43cab4","IPY_MODEL_6f1b159b97834c6fb3e3843da242e6a0","IPY_MODEL_fdc1bd9ab36f4fac8d640f36dcc98641"],"layout":"IPY_MODEL_d0fc43acc0ba4bb098ff60443e2dd9ab"}},"e66850f233a443568fcf0e536b43cab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76ba5e3f50394ef59b56e1213dceed26","placeholder":"​","style":"IPY_MODEL_7d94afcbb52d4b6abf3cddb49ef7de54","value":"100%"}},"6f1b159b97834c6fb3e3843da242e6a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af70803daf8e480f8a01a8a8d912983c","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f5e6a8fe94f421fb3f7efeb5268ae0d","value":3}},"fdc1bd9ab36f4fac8d640f36dcc98641":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e5f473e8ed7498cbb7e4689e382a47c","placeholder":"​","style":"IPY_MODEL_583501f192d64dbb9b4e363aa8ac90a5","value":" 3/3 [00:02&lt;00:00,  1.37it/s]"}},"d0fc43acc0ba4bb098ff60443e2dd9ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ba5e3f50394ef59b56e1213dceed26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d94afcbb52d4b6abf3cddb49ef7de54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af70803daf8e480f8a01a8a8d912983c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f5e6a8fe94f421fb3f7efeb5268ae0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e5f473e8ed7498cbb7e4689e382a47c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"583501f192d64dbb9b4e363aa8ac90a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"993d695a47d249e898cee3720dbe69b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fef5536e97d14092b051b333666a2931","IPY_MODEL_0f6fdb43f8c149b7b5ad0b37038a901f","IPY_MODEL_44c64b7d43c241f6aaf68520aaf286f9"],"layout":"IPY_MODEL_fd5ae17ab6944b4cb5afb8f7df65fb36"}},"fef5536e97d14092b051b333666a2931":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9e597d2b1174b26bcf698674bb02fd6","placeholder":"​","style":"IPY_MODEL_5e986625aa044d7d93e9f6db35e4358c","value":"100%"}},"0f6fdb43f8c149b7b5ad0b37038a901f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67aeb5f7801c4f07afe9868aef52e02f","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_179bae4b6ef74209b0c0c410b02dc894","value":3}},"44c64b7d43c241f6aaf68520aaf286f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3fcda60f5ca4fe2bad82b7161c16747","placeholder":"​","style":"IPY_MODEL_1f8a920d1c4246059c947b8770914fdb","value":" 3/3 [00:01&lt;00:00,  1.59it/s]"}},"fd5ae17ab6944b4cb5afb8f7df65fb36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9e597d2b1174b26bcf698674bb02fd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e986625aa044d7d93e9f6db35e4358c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67aeb5f7801c4f07afe9868aef52e02f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"179bae4b6ef74209b0c0c410b02dc894":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3fcda60f5ca4fe2bad82b7161c16747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f8a920d1c4246059c947b8770914fdb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5cd33c6a0ae473fa03155b7c7c43e9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2764653fd14f43e38f5bbf9098cb4d59","IPY_MODEL_1e1befb3f6204e9cae66bc4d243f6fcb","IPY_MODEL_76909d22e1f8450691077e44519db540"],"layout":"IPY_MODEL_56e8876d9cab4782b03d7186e3c45e2c"}},"2764653fd14f43e38f5bbf9098cb4d59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d238593b3ded40c9b36eb748bb23882b","placeholder":"​","style":"IPY_MODEL_2255d6b6e91646948d49b044e7a4c09e","value":"100%"}},"1e1befb3f6204e9cae66bc4d243f6fcb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a0a4142255c4b17b98188c7d16885ea","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c49b4911542f42ecb890df5bd5fd6431","value":3}},"76909d22e1f8450691077e44519db540":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e56ed2d220f4d6da58bb3d182c8c6cc","placeholder":"​","style":"IPY_MODEL_825417eb400b47c8a283f9a4816e5551","value":" 3/3 [00:02&lt;00:00,  1.40it/s]"}},"56e8876d9cab4782b03d7186e3c45e2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d238593b3ded40c9b36eb748bb23882b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2255d6b6e91646948d49b044e7a4c09e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a0a4142255c4b17b98188c7d16885ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c49b4911542f42ecb890df5bd5fd6431":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e56ed2d220f4d6da58bb3d182c8c6cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"825417eb400b47c8a283f9a4816e5551":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}