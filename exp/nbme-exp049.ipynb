{"cells":[{"cell_type":"markdown","id":"brave-teach","metadata":{"id":"brave-teach"},"source":["## References"]},{"cell_type":"markdown","id":"orange-toilet","metadata":{"id":"orange-toilet"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"serious-sending","metadata":{"id":"serious-sending"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"august-providence","metadata":{"id":"august-providence","executionInfo":{"status":"ok","timestamp":1647515057862,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp049\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"cathedral-horror","metadata":{"id":"cathedral-horror","executionInfo":{"status":"ok","timestamp":1647515057863,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    alpha=1\n","    gamma=2\n","    smoothing=0.0001\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"armed-norfolk","metadata":{"id":"armed-norfolk","executionInfo":{"status":"ok","timestamp":1647515057863,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"atlantic-warrant","metadata":{"id":"atlantic-warrant"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"federal-marsh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"federal-marsh","outputId":"1a56f7fa-6eb4-49da-cca5-8857d1a034f8","executionInfo":{"status":"ok","timestamp":1647515065368,"user_tz":-540,"elapsed":7511,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.49)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"recent-harrison","metadata":{"id":"recent-harrison","executionInfo":{"status":"ok","timestamp":1647515076549,"user_tz":-540,"elapsed":11185,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"technical-story","metadata":{"id":"technical-story"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"understanding-trial","metadata":{"id":"understanding-trial","executionInfo":{"status":"ok","timestamp":1647515076550,"user_tz":-540,"elapsed":16,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"pursuant-lover","metadata":{"id":"pursuant-lover","executionInfo":{"status":"ok","timestamp":1647515076550,"user_tz":-540,"elapsed":15,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"matched-hollow","metadata":{"id":"matched-hollow","executionInfo":{"status":"ok","timestamp":1647515077135,"user_tz":-540,"elapsed":599,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"weighted-screw","metadata":{"id":"weighted-screw","executionInfo":{"status":"ok","timestamp":1647515077136,"user_tz":-540,"elapsed":12,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"following-passport","metadata":{"id":"following-passport"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"absent-performance","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"absent-performance","outputId":"d8e95d70-0476-4e07-bed6-92bdaeb43e46","executionInfo":{"status":"ok","timestamp":1647515077646,"user_tz":-540,"elapsed":522,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"automated-proportion","metadata":{"id":"automated-proportion","executionInfo":{"status":"ok","timestamp":1647515077647,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"preceding-january","metadata":{"id":"preceding-january"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"monetary-camera","metadata":{"id":"monetary-camera","executionInfo":{"status":"ok","timestamp":1647515077647,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"fitted-current","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fitted-current","outputId":"1c7a4371-14c8-48a3-aaab-05f570603d01","executionInfo":{"status":"ok","timestamp":1647515077648,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"australian-vehicle","metadata":{"id":"australian-vehicle","executionInfo":{"status":"ok","timestamp":1647515078150,"user_tz":-540,"elapsed":506,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"devoted-peter","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"devoted-peter","outputId":"47f39fa7-f797-46c0-e813-703344e212e8","executionInfo":{"status":"ok","timestamp":1647515078151,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"incorrect-honey","metadata":{"id":"incorrect-honey"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"adjacent-antibody","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"adjacent-antibody","outputId":"9b0ef3f9-1170-47bf-91b2-6c7755054538","executionInfo":{"status":"ok","timestamp":1647515078151,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"breathing-state","metadata":{"id":"breathing-state"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"former-beast","metadata":{"id":"former-beast","executionInfo":{"status":"ok","timestamp":1647515082458,"user_tz":-540,"elapsed":4313,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDMSkwTNgOOh","executionInfo":{"status":"ok","timestamp":1647515082459,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"1c6d4250-ffb5-4ec6-e1a9-caa1bca05de1"},"id":"TDMSkwTNgOOh","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}]},{"cell_type":"markdown","id":"employed-foster","metadata":{"id":"employed-foster"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":19,"id":"biblical-mailing","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["74b6705228ab40bab11566271a41c948","67eb23b36672444eb2b6c22019687159","caca175a31454896b19e5a6b2df59081","29b1ebae772e45208158b638d35581c0","34e3cc79e7ad42499d5038e334aac022","9d853b3d7d2e45eca55fd8a5489c2b8d","3695f404a0b0450787bc69ac912de747","940741bb1e5c491ba9e55c4d108a61c3","1289b1bf271347e5aaed4301f3f4a8d6","f98abd91b678427692a8ee40a8b335aa","23edcb78ccd34bce89f36117176b40c7"]},"id":"biblical-mailing","outputId":"d398da58-cf1b-4552-eb3d-9b40feec2860","executionInfo":{"status":"ok","timestamp":1647515121884,"user_tz":-540,"elapsed":39433,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74b6705228ab40bab11566271a41c948"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":20,"id":"renewable-mercury","metadata":{"id":"renewable-mercury","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["be6ddecf071f4a6096da2b6d83dadc63","beda28445189496083ab7c435f1e81ee","acfb74900b90481c9f1d18dffb519bd5","eb61b6f56cc146b7acf1c4caaf17ba19","a616621b2d0444d58240de3f5753d932","b5c04e076a53457d8e3000f631c2d645","fd411a7f08f6424fbd6076b825e4ad0b","6827db9bb7274e6583d304b0bd39c751","d192c62a2186491689b24184f7bd6d90","f4722866857a499e8d1b0c12c1af716e","764472f1126f44f2b1b40b1cecef4bdd"]},"executionInfo":{"status":"ok","timestamp":1647515122404,"user_tz":-540,"elapsed":538,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"546df646-e422-463a-f2fc-165d3215b8f9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be6ddecf071f4a6096da2b6d83dadc63"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":21,"id":"latin-burlington","metadata":{"id":"latin-burlington","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647515122404,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"c7c05872-95b5-4a6f-cf1e-3cfe8d7f1def"},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":22,"id":"minor-stock","metadata":{"id":"minor-stock","executionInfo":{"status":"ok","timestamp":1647515122405,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":23,"id":"decimal-schema","metadata":{"id":"decimal-schema","executionInfo":{"status":"ok","timestamp":1647515122405,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"exceptional-vertical","metadata":{"id":"exceptional-vertical"},"source":["## Model"]},{"cell_type":"code","execution_count":24,"id":"dynamic-fifteen","metadata":{"id":"dynamic-fifteen","executionInfo":{"status":"ok","timestamp":1647515122406,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            #path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","        self.cnn1 = nn.Conv1d(self.model_config.hidden_size, 256, kernel_size=2, padding=\"same\")\n","        self.cnn2 = nn.Conv1d(256, 1, kernel_size=2, padding=\"same\")\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]   # [batch, seq_len, d_model]\n","        h = h.permute(0, 2, 1)   # [batch, d_model, seq_len]\n","        cnn_embeddings = F.relu(self.cnn1(h))\n","        cnn_embeddings = self.cnn2(cnn_embeddings)\n","        output, _ = torch.max(cnn_embeddings, 1)\n","        return output"]},{"cell_type":"markdown","id":"driving-commercial","metadata":{"id":"driving-commercial"},"source":["## Training"]},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2):\n","        super().__init__()\n","        self.reduction = reduction\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, inputs, targets):\n","        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n","        pt = torch.exp(-bce_loss)\n","        loss = self.alpha * (1. - pt)**self.gamma * bce_loss\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","\n","class SmoothFocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2, smoothing=0.0):\n","        super().__init__()\n","        self.reduction = reduction\n","        self.focal_loss = FocalLoss(reduction='none', alpha=alpha, gamma=gamma)\n","        self.smoothing = smoothing\n","\n","    @staticmethod\n","    def _smooth(targets:torch.Tensor, smoothing=0.0):\n","        assert 0 <= smoothing < 1\n","        with torch.no_grad():\n","            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n","        return targets\n","\n","    def forward(self, inputs, targets):\n","        targets = SmoothFocalLoss._smooth(targets, self.smoothing)\n","        loss = self.focal_loss(inputs, targets)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","    \n","class CEFocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2):\n","        super(CEFocalLoss, self).__init__()\n","        self.reduction = reduction\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        loss = self.alpha * (1. - pt)**self.gamma * ce_loss\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","    \n","class SmoothCEFocalLoss(nn.Module):\n","    def __init__(self, reduction='none', alpha=1, gamma=2, smoothing=0.0):\n","        super(SmoothCEFocalLoss, self).__init__()\n","        self.reduction = reduction\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.smoothing = smoothing\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.smoothing) # torch >= 1.10.0\n","        pt = torch.exp(-ce_loss)\n","        loss = self.alpha * (1. - pt)**self.gamma * ce_loss\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"],"metadata":{"id":"86D0afuEh7Q0","executionInfo":{"status":"ok","timestamp":1647515122406,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"86D0afuEh7Q0","execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":26,"id":"cathedral-component","metadata":{"id":"cathedral-component","executionInfo":{"status":"ok","timestamp":1647515122407,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":27,"id":"expired-wilson","metadata":{"id":"expired-wilson","executionInfo":{"status":"ok","timestamp":1647515122407,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        #preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","        preds.append(output.sigmoid().detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":28,"id":"chinese-sympathy","metadata":{"id":"chinese-sympathy","executionInfo":{"status":"ok","timestamp":1647515122408,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        #preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","        preds.append(output.sigmoid().detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":29,"id":"healthy-sleep","metadata":{"id":"healthy-sleep","executionInfo":{"status":"ok","timestamp":1647515122408,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = SmoothFocalLoss(reduction='none', alpha=CFG.alpha, gamma=CFG.gamma, smoothing=CFG.smoothing)\n","    #criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"balanced-novel","metadata":{"id":"balanced-novel"},"source":["## Main"]},{"cell_type":"code","execution_count":30,"id":"sound-silly","metadata":{"id":"sound-silly","executionInfo":{"status":"ok","timestamp":1647515122844,"user_tz":-540,"elapsed":445,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"id":"reduced-indication","metadata":{"id":"reduced-indication","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cd1c05a94601472cb6033f4541d7c43d","4afbe69ede7940aeab64181817f549d9","ce48bb2da0de4bed9c325a01c53da228","353853d148674105a87c8d195f45c693","e16bf5b9fb954986a58f5cdfd59af5c5","9bb74e6da10c4e04a207bec929d75b88","509f5cc612f74c849bc0b2514ce843c7","2780dad4842243d4b26fdcccd8900fd3","cb484c9ff5ff4afdb3d4ea60e4ae13c3","d096d281521b45c0ab80f6918508de10","80310b9bc2a44459ac8cec12ddb98d37","a65440dc3a95443dbd61e7f63881d64c","b58bdc872dcb42bba175b0ebb550706e","cca8a73f15674f59b3a3b5dd3dcbe220","309a70f368a348758bef8ca38fd34683","637e341f5fc448cdb12f8c7ba1a5a201","9f4387689849412d978e7048c1e7e299","330bbbb93e254612a1985209d9553830","d11edb75ac64475da753a448d89411f1","2529231b962848ccabeb6d4e59578070","e9f82860dace4bfebc59245059f77b90","c957adc61edb44ee809ccd4e5ca7b0fd","8f6f49857c3b450184118d32c513378d","38d918115c03427e80652b99254ac8fc","6e959ce6674942eaa4e61e96970e9e92","32688fc1ddde4f33895aaf296e09abb3","ac7e5979b0054858aaca6feb5877ea0d","17072c6b6cd04bdf9126810fc57e1392","7efee909a13c4b7a938c6f008e6dc0db","1abf5aa27dd34cae8ac3cbb3c6b7e3a2","f5577ed688244fb89769ba4117bfb246","4f4467426b3a46e293d6574f78cde9fd","11b34e75a35b4317b08e41b10ff7a8e3"]},"outputId":"14bf9f11-dcf1-44fe-d712-447df13a6089"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 1s (remain 87m 50s) Loss: 0.1095(0.1095) Grad: 75785.1094  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 29s (remain 17m 8s) Loss: 0.0940(0.1036) Grad: 67225.2266  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 58s (remain 16m 19s) Loss: 0.0631(0.0920) Grad: 22807.6348  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 28s (remain 16m 3s) Loss: 0.0200(0.0744) Grad: 6671.6470  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 57s (remain 15m 26s) Loss: 0.0150(0.0589) Grad: 3147.1431  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 25s (remain 14m 53s) Loss: 0.0048(0.0492) Grad: 1684.3589  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 54s (remain 14m 21s) Loss: 0.0155(0.0429) Grad: 3522.7856  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 22s (remain 13m 49s) Loss: 0.0057(0.0383) Grad: 865.1765  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 50s (remain 13m 18s) Loss: 0.0025(0.0347) Grad: 1435.1355  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 18s (remain 12m 48s) Loss: 0.0048(0.0316) Grad: 1151.8422  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 47s (remain 12m 18s) Loss: 0.0045(0.0289) Grad: 1415.2598  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 15s (remain 11m 49s) Loss: 0.0016(0.0266) Grad: 1040.3586  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 43s (remain 11m 19s) Loss: 0.0121(0.0247) Grad: 6865.2993  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 12s (remain 10m 50s) Loss: 0.0045(0.0230) Grad: 3299.4524  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 40s (remain 10m 21s) Loss: 0.0008(0.0216) Grad: 271.7754  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 8s (remain 9m 51s) Loss: 0.0009(0.0203) Grad: 639.8664  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 36s (remain 9m 22s) Loss: 0.0001(0.0193) Grad: 59.7279  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 4s (remain 8m 53s) Loss: 0.0015(0.0183) Grad: 1549.3490  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 32s (remain 8m 24s) Loss: 0.0012(0.0174) Grad: 1975.3152  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 0s (remain 7m 55s) Loss: 0.0009(0.0166) Grad: 503.5109  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 28s (remain 7m 27s) Loss: 0.0021(0.0159) Grad: 3163.3379  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 56s (remain 6m 58s) Loss: 0.0004(0.0153) Grad: 216.0836  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 24s (remain 6m 29s) Loss: 0.0006(0.0147) Grad: 298.6534  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 52s (remain 6m 1s) Loss: 0.0184(0.0142) Grad: 7104.2544  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 20s (remain 5m 32s) Loss: 0.0011(0.0137) Grad: 1133.1482  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 48s (remain 5m 4s) Loss: 0.0002(0.0132) Grad: 100.8439  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 16s (remain 4m 35s) Loss: 0.0011(0.0128) Grad: 619.6172  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 44s (remain 4m 7s) Loss: 0.0034(0.0124) Grad: 1025.9558  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 12s (remain 3m 38s) Loss: 0.0001(0.0120) Grad: 90.6825  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 40s (remain 3m 10s) Loss: 0.0025(0.0117) Grad: 803.8289  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 8s (remain 2m 42s) Loss: 0.0003(0.0113) Grad: 260.7096  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 35s (remain 2m 13s) Loss: 0.0016(0.0110) Grad: 461.6436  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 3s (remain 1m 45s) Loss: 0.0026(0.0107) Grad: 842.7812  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 31s (remain 1m 17s) Loss: 0.0010(0.0105) Grad: 510.5322  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 59s (remain 0m 49s) Loss: 0.0011(0.0102) Grad: 571.1858  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 27s (remain 0m 20s) Loss: 0.0009(0.0100) Grad: 388.0039  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 48s (remain 0m 0s) Loss: 0.0007(0.0098) Grad: 323.0232  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 35s) Loss: 0.0004(0.0004) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0030(0.0013) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0028(0.0014) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0022(0.0015) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0006(0.0014) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0022(0.0013) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0059(0.0014) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0199(0.0017) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0010(0.0018) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0030(0.0018) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0027(0.0018) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0013(0.0017) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0002(0.0017) \n","Epoch 1 - avg_train_loss: 0.0098  avg_val_loss: 0.0017  time: 1189s\n","Epoch 1 - Score: 0.8542\n","Epoch 1 - Save Best Score: 0.8542 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 38m 38s) Loss: 0.0029(0.0029) Grad: 8284.1973  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 30s (remain 17m 21s) Loss: 0.0013(0.0014) Grad: 3763.5552  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 58s (remain 16m 25s) Loss: 0.0000(0.0015) Grad: 32.9261  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 26s (remain 15m 39s) Loss: 0.0004(0.0016) Grad: 1883.4125  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 54s (remain 15m 3s) Loss: 0.0003(0.0015) Grad: 991.8409  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 21s (remain 14m 30s) Loss: 0.0005(0.0015) Grad: 1862.8971  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 49s (remain 13m 59s) Loss: 0.0007(0.0015) Grad: 3377.7300  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 17s (remain 13m 28s) Loss: 0.0001(0.0016) Grad: 357.7612  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 45s (remain 12m 59s) Loss: 0.0000(0.0015) Grad: 129.6250  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 12s (remain 12m 30s) Loss: 0.0001(0.0015) Grad: 593.6545  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 40s (remain 12m 1s) Loss: 0.0000(0.0015) Grad: 347.6107  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 8s (remain 11m 33s) Loss: 0.0010(0.0016) Grad: 3722.8250  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 36s (remain 11m 4s) Loss: 0.0024(0.0016) Grad: 9189.1836  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 3s (remain 10m 35s) Loss: 0.0011(0.0016) Grad: 4616.1885  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0001(0.0016) Grad: 432.1287  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0002(0.0016) Grad: 1204.5375  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 26s (remain 9m 11s) Loss: 0.0001(0.0016) Grad: 779.8542  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 54s (remain 8m 42s) Loss: 0.0008(0.0015) Grad: 2869.6414  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 22s (remain 8m 14s) Loss: 0.0001(0.0015) Grad: 513.8460  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 50s (remain 7m 46s) Loss: 0.0141(0.0015) Grad: 23662.3477  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0005(0.0015) Grad: 3415.1680  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0001(0.0015) Grad: 472.5878  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 13s (remain 6m 22s) Loss: 0.0000(0.0015) Grad: 318.3183  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 41s (remain 5m 55s) Loss: 0.0013(0.0015) Grad: 6490.7236  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 8s (remain 5m 27s) Loss: 0.0095(0.0015) Grad: 8954.8057  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 36s (remain 4m 59s) Loss: 0.0002(0.0015) Grad: 732.9971  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 4s (remain 4m 31s) Loss: 0.0000(0.0014) Grad: 9.8160  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 32s (remain 4m 3s) Loss: 0.0041(0.0015) Grad: 5492.8110  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 0s (remain 3m 35s) Loss: 0.0032(0.0015) Grad: 5783.8442  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 28s (remain 3m 7s) Loss: 0.0002(0.0014) Grad: 509.8841  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 56s (remain 2m 39s) Loss: 0.0136(0.0014) Grad: 15444.0801  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 24s (remain 2m 12s) Loss: 0.0019(0.0014) Grad: 5128.7495  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 52s (remain 1m 44s) Loss: 0.0014(0.0014) Grad: 1609.8503  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 20s (remain 1m 16s) Loss: 0.0034(0.0014) Grad: 14403.9912  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 48s (remain 0m 48s) Loss: 0.0002(0.0014) Grad: 681.1925  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 16s (remain 0m 20s) Loss: 0.0001(0.0014) Grad: 259.9688  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 36s (remain 0m 0s) Loss: 0.0007(0.0014) Grad: 5365.0264  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 55s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0026(0.0013) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0042(0.0014) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0019(0.0016) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0006(0.0015) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0019(0.0014) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0051(0.0015) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 10s) Loss: 0.0231(0.0018) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0007(0.0019) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0004(0.0019) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.0001(0.0018) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0016(0.0017) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0017) \n","Epoch 2 - avg_train_loss: 0.0014  avg_val_loss: 0.0017  time: 1174s\n","Epoch 2 - Score: 0.8752\n","Epoch 2 - Save Best Score: 0.8752 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 35m 56s) Loss: 0.0009(0.0009) Grad: 2867.0374  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 30s (remain 17m 32s) Loss: 0.0000(0.0010) Grad: 23.2959  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 58s (remain 16m 27s) Loss: 0.0000(0.0011) Grad: 62.1349  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 26s (remain 15m 41s) Loss: 0.0001(0.0010) Grad: 491.5855  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 54s (remain 15m 4s) Loss: 0.0001(0.0010) Grad: 570.2943  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 21s (remain 14m 30s) Loss: 0.0022(0.0010) Grad: 6718.1245  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 49s (remain 13m 58s) Loss: 0.0000(0.0011) Grad: 106.2722  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 17s (remain 13m 28s) Loss: 0.0002(0.0011) Grad: 4133.7964  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 44s (remain 12m 58s) Loss: 0.0001(0.0011) Grad: 955.5267  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 12s (remain 12m 29s) Loss: 0.0062(0.0011) Grad: 11084.8643  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 40s (remain 12m 0s) Loss: 0.0000(0.0011) Grad: 190.1351  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 7s (remain 11m 32s) Loss: 0.0007(0.0011) Grad: 2324.0950  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 35s (remain 11m 3s) Loss: 0.0003(0.0011) Grad: 2026.4169  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 3s (remain 10m 35s) Loss: 0.0002(0.0011) Grad: 869.8760  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0002(0.0010) Grad: 2879.8582  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 58s (remain 9m 38s) Loss: 0.0012(0.0010) Grad: 2212.0278  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 26s (remain 9m 10s) Loss: 0.0021(0.0010) Grad: 9131.0508  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 54s (remain 8m 42s) Loss: 0.0008(0.0010) Grad: 3462.3569  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 21s (remain 8m 14s) Loss: 0.0039(0.0010) Grad: 8105.3398  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 49s (remain 7m 46s) Loss: 0.0001(0.0010) Grad: 301.0398  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0005(0.0010) Grad: 2929.3096  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0004(0.0010) Grad: 1645.0005  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 12s (remain 6m 22s) Loss: 0.0000(0.0010) Grad: 39.9768  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 40s (remain 5m 54s) Loss: 0.0015(0.0011) Grad: 4622.7666  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 8s (remain 5m 26s) Loss: 0.0014(0.0011) Grad: 3304.8538  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 35s (remain 4m 58s) Loss: 0.0000(0.0011) Grad: 142.2625  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 3s (remain 4m 30s) Loss: 0.0015(0.0011) Grad: 12076.5449  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 31s (remain 4m 3s) Loss: 0.0000(0.0011) Grad: 56.4024  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 59s (remain 3m 35s) Loss: 0.0000(0.0011) Grad: 15.7083  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 26s (remain 3m 7s) Loss: 0.0043(0.0011) Grad: 8905.9326  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 54s (remain 2m 39s) Loss: 0.0000(0.0011) Grad: 104.2736  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 22s (remain 2m 11s) Loss: 0.0001(0.0011) Grad: 442.2956  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 49s (remain 1m 43s) Loss: 0.0036(0.0011) Grad: 6326.1851  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 17s (remain 1m 16s) Loss: 0.0003(0.0011) Grad: 1167.8002  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 45s (remain 0m 48s) Loss: 0.0004(0.0011) Grad: 1073.6880  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 12s (remain 0m 20s) Loss: 0.0009(0.0011) Grad: 7198.1362  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 33s (remain 0m 0s) Loss: 0.0000(0.0011) Grad: 95.3386  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 54s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0028(0.0014) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0040(0.0015) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0013(0.0017) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0009(0.0017) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0020(0.0015) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0016(0.0016) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0256(0.0020) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0005(0.0020) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0005(0.0020) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0020) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0017(0.0019) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0018) \n","Epoch 3 - avg_train_loss: 0.0011  avg_val_loss: 0.0018  time: 1174s\n","Epoch 3 - Score: 0.8779\n","Epoch 3 - Save Best Score: 0.8779 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 35m 33s) Loss: 0.0007(0.0007) Grad: 1852.1501  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 30s (remain 17m 35s) Loss: 0.0017(0.0007) Grad: 3813.4009  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 59s (remain 16m 31s) Loss: 0.0000(0.0006) Grad: 5.9605  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 27s (remain 15m 46s) Loss: 0.0021(0.0006) Grad: 17626.1426  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 54s (remain 15m 7s) Loss: 0.0001(0.0008) Grad: 670.7037  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 22s (remain 14m 33s) Loss: 0.0010(0.0007) Grad: 2081.4685  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 50s (remain 14m 1s) Loss: 0.0002(0.0007) Grad: 1894.3009  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 17s (remain 13m 30s) Loss: 0.0011(0.0007) Grad: 4390.7793  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 45s (remain 13m 0s) Loss: 0.0013(0.0008) Grad: 5362.0298  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 13s (remain 12m 31s) Loss: 0.0050(0.0008) Grad: 10090.0801  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 40s (remain 12m 1s) Loss: 0.0018(0.0008) Grad: 8164.9365  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 8s (remain 11m 33s) Loss: 0.0000(0.0008) Grad: 84.4036  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 36s (remain 11m 5s) Loss: 0.0001(0.0008) Grad: 322.8476  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 4s (remain 10m 36s) Loss: 0.0007(0.0008) Grad: 5276.7798  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 32s (remain 10m 8s) Loss: 0.0000(0.0008) Grad: 379.9517  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 0s (remain 9m 40s) Loss: 0.0004(0.0008) Grad: 1631.3700  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 28s (remain 9m 12s) Loss: 0.0004(0.0008) Grad: 2830.7737  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 56s (remain 8m 44s) Loss: 0.0000(0.0008) Grad: 412.8117  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 24s (remain 8m 16s) Loss: 0.0000(0.0008) Grad: 10.2761  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 52s (remain 7m 48s) Loss: 0.0000(0.0008) Grad: 12.0438  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 20s (remain 7m 20s) Loss: 0.0000(0.0008) Grad: 60.3398  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 48s (remain 6m 52s) Loss: 0.0003(0.0008) Grad: 3823.4209  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 15s (remain 6m 24s) Loss: 0.0000(0.0008) Grad: 3.6931  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 43s (remain 5m 56s) Loss: 0.0002(0.0008) Grad: 939.3511  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 11s (remain 5m 28s) Loss: 0.0022(0.0008) Grad: 12545.2695  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 39s (remain 5m 0s) Loss: 0.0000(0.0008) Grad: 66.7530  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 7s (remain 4m 32s) Loss: 0.0006(0.0008) Grad: 4016.8416  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 34s (remain 4m 4s) Loss: 0.0006(0.0008) Grad: 2625.2817  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 2s (remain 3m 36s) Loss: 0.0000(0.0008) Grad: 7.4679  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 30s (remain 3m 8s) Loss: 0.0004(0.0008) Grad: 3148.0229  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 57s (remain 2m 40s) Loss: 0.0010(0.0008) Grad: 7897.3999  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 25s (remain 2m 12s) Loss: 0.0010(0.0008) Grad: 7716.5972  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 53s (remain 1m 44s) Loss: 0.0000(0.0008) Grad: 15.8494  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 21s (remain 1m 16s) Loss: 0.0027(0.0008) Grad: 10075.2734  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 48s (remain 0m 48s) Loss: 0.0000(0.0008) Grad: 167.4182  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 16s (remain 0m 20s) Loss: 0.0000(0.0008) Grad: 32.1691  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 36s (remain 0m 0s) Loss: 0.0000(0.0008) Grad: 90.3585  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 53s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0022(0.0015) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0034(0.0017) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0019(0.0019) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0006(0.0020) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0021(0.0018) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0026(0.0019) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0278(0.0023) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0005(0.0024) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0002(0.0023) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0024) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0029(0.0022) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0022) \n","Epoch 4 - avg_train_loss: 0.0008  avg_val_loss: 0.0022  time: 1177s\n","Epoch 4 - Score: 0.8799\n","Epoch 4 - Save Best Score: 0.8799 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 36m 50s) Loss: 0.0001(0.0001) Grad: 766.0680  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 30s (remain 17m 29s) Loss: 0.0000(0.0007) Grad: 42.0240  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 59s (remain 16m 32s) Loss: 0.0000(0.0006) Grad: 27.5121  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 26s (remain 15m 44s) Loss: 0.0000(0.0006) Grad: 40.5413  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 54s (remain 15m 6s) Loss: 0.0000(0.0006) Grad: 2.3911  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 22s (remain 14m 32s) Loss: 0.0000(0.0006) Grad: 139.4910  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 49s (remain 14m 1s) Loss: 0.0003(0.0006) Grad: 1159.1504  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 17s (remain 13m 31s) Loss: 0.0000(0.0006) Grad: 200.1116  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 45s (remain 13m 1s) Loss: 0.0000(0.0006) Grad: 4.2393  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 13s (remain 12m 31s) Loss: 0.0000(0.0006) Grad: 10.6464  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 41s (remain 12m 2s) Loss: 0.0000(0.0006) Grad: 7.7380  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 8s (remain 11m 33s) Loss: 0.0005(0.0006) Grad: 2651.8381  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 36s (remain 11m 4s) Loss: 0.0000(0.0006) Grad: 132.4451  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 4s (remain 10m 36s) Loss: 0.0000(0.0006) Grad: 20.6033  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0000(0.0006) Grad: 163.5339  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0001(0.0006) Grad: 469.5273  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 27s (remain 9m 11s) Loss: 0.0009(0.0006) Grad: 2671.9624  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 54s (remain 8m 43s) Loss: 0.0000(0.0006) Grad: 20.3565  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 22s (remain 8m 15s) Loss: 0.0000(0.0006) Grad: 59.8654  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 50s (remain 7m 46s) Loss: 0.0022(0.0006) Grad: 9774.5312  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0024(0.0006) Grad: 24295.3887  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0000(0.0006) Grad: 69.8761  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 13s (remain 6m 22s) Loss: 0.0003(0.0006) Grad: 1316.5789  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 41s (remain 5m 55s) Loss: 0.0007(0.0006) Grad: 3040.0168  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 8s (remain 5m 27s) Loss: 0.0000(0.0006) Grad: 34.3992  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 36s (remain 4m 59s) Loss: 0.0005(0.0006) Grad: 3951.8433  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 4s (remain 4m 31s) Loss: 0.0000(0.0006) Grad: 13.2185  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 31s (remain 4m 3s) Loss: 0.0000(0.0006) Grad: 154.5042  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 59s (remain 3m 35s) Loss: 0.0009(0.0006) Grad: 2764.0259  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 27s (remain 3m 7s) Loss: 0.0000(0.0006) Grad: 144.0522  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 54s (remain 2m 39s) Loss: 0.0000(0.0006) Grad: 24.7517  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 22s (remain 2m 11s) Loss: 0.0000(0.0006) Grad: 13.7198  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 50s (remain 1m 44s) Loss: 0.0039(0.0006) Grad: 15894.8066  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 18s (remain 1m 16s) Loss: 0.0002(0.0006) Grad: 1731.4340  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 45s (remain 0m 48s) Loss: 0.0000(0.0006) Grad: 9.8064  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 13s (remain 0m 20s) Loss: 0.0000(0.0006) Grad: 1.3153  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 34s (remain 0m 0s) Loss: 0.0019(0.0006) Grad: 15093.0859  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 56s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0019(0.0020) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0035(0.0022) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0016(0.0023) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0010(0.0023) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0025(0.0021) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0022(0.0022) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0298(0.0028) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0004(0.0028) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0001(0.0028) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0028) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0017(0.0027) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0026) \n","Epoch 5 - avg_train_loss: 0.0006  avg_val_loss: 0.0026  time: 1171s\n","Epoch 5 - Score: 0.8804\n","Epoch 5 - Save Best Score: 0.8804 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 50m 36s) Loss: 0.0814(0.0814) Grad: 60223.3945  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 30s (remain 17m 35s) Loss: 0.0724(0.0776) Grad: 27775.1797  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 58s (remain 16m 25s) Loss: 0.0385(0.0658) Grad: 14833.3799  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 26s (remain 15m 43s) Loss: 0.0113(0.0517) Grad: 4786.1484  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 54s (remain 15m 7s) Loss: 0.0148(0.0417) Grad: 1495.5535  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 22s (remain 14m 35s) Loss: 0.0165(0.0357) Grad: 1650.1897  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 50s (remain 14m 4s) Loss: 0.0220(0.0316) Grad: 3006.0720  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 18s (remain 13m 34s) Loss: 0.0059(0.0282) Grad: 2188.0474  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 46s (remain 13m 5s) Loss: 0.0016(0.0253) Grad: 1888.5938  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 14s (remain 12m 35s) Loss: 0.0020(0.0229) Grad: 671.8623  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 42s (remain 12m 5s) Loss: 0.0002(0.0210) Grad: 174.1314  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 9s (remain 11m 36s) Loss: 0.0021(0.0194) Grad: 978.8757  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 37s (remain 11m 7s) Loss: 0.0074(0.0181) Grad: 4249.1440  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 5s (remain 10m 39s) Loss: 0.0027(0.0169) Grad: 2238.9009  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 33s (remain 10m 10s) Loss: 0.0006(0.0159) Grad: 321.4760  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 1s (remain 9m 41s) Loss: 0.0007(0.0150) Grad: 358.7169  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 28s (remain 9m 13s) Loss: 0.0001(0.0143) Grad: 275.8526  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 56s (remain 8m 45s) Loss: 0.0148(0.0135) Grad: 6079.8320  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 24s (remain 8m 16s) Loss: 0.0004(0.0129) Grad: 245.2008  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 52s (remain 7m 48s) Loss: 0.0001(0.0124) Grad: 95.4710  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 19s (remain 7m 20s) Loss: 0.0010(0.0119) Grad: 1029.2556  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 47s (remain 6m 52s) Loss: 0.0005(0.0114) Grad: 547.1628  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 15s (remain 6m 24s) Loss: 0.0001(0.0110) Grad: 398.5932  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 42s (remain 5m 55s) Loss: 0.0003(0.0106) Grad: 131.8015  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 10s (remain 5m 27s) Loss: 0.0015(0.0102) Grad: 1182.0344  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 38s (remain 4m 59s) Loss: 0.0013(0.0099) Grad: 369.1281  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 6s (remain 4m 31s) Loss: 0.0027(0.0096) Grad: 1151.0870  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 33s (remain 4m 3s) Loss: 0.0023(0.0093) Grad: 680.9410  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 1s (remain 3m 36s) Loss: 0.0025(0.0090) Grad: 1051.4316  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 29s (remain 3m 8s) Loss: 0.0023(0.0088) Grad: 753.4352  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 57s (remain 2m 40s) Loss: 0.0007(0.0086) Grad: 392.6238  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 24s (remain 2m 12s) Loss: 0.0006(0.0083) Grad: 670.9715  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 52s (remain 1m 44s) Loss: 0.0001(0.0081) Grad: 78.8363  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 20s (remain 1m 16s) Loss: 0.0022(0.0079) Grad: 704.2822  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 48s (remain 0m 48s) Loss: 0.0015(0.0078) Grad: 857.1269  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 15s (remain 0m 20s) Loss: 0.0149(0.0076) Grad: 8260.1152  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 36s (remain 0m 0s) Loss: 0.0006(0.0075) Grad: 642.3871  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 13s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0002(0.0012) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0001(0.0015) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0015(0.0021) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0025(0.0021) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0034(0.0019) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0281(0.0020) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0024(0.0022) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0013(0.0021) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0008(0.0021) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0001(0.0020) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0012(0.0019) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0019(0.0019) \n","Epoch 1 - avg_train_loss: 0.0075  avg_val_loss: 0.0019  time: 1173s\n","Epoch 1 - Score: 0.8576\n","Epoch 1 - Save Best Score: 0.8576 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 38m 37s) Loss: 0.0021(0.0021) Grad: 6596.0835  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 30s (remain 17m 19s) Loss: 0.0000(0.0014) Grad: 81.2029  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 59s (remain 16m 36s) Loss: 0.0019(0.0014) Grad: 5731.7529  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 27s (remain 15m 47s) Loss: 0.0000(0.0015) Grad: 290.6653  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 54s (remain 15m 8s) Loss: 0.0003(0.0014) Grad: 670.3785  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 22s (remain 14m 34s) Loss: 0.0009(0.0013) Grad: 3020.8240  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 50s (remain 14m 2s) Loss: 0.0006(0.0013) Grad: 1239.8556  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 18s (remain 13m 32s) Loss: 0.0001(0.0013) Grad: 592.2199  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 45s (remain 13m 2s) Loss: 0.0000(0.0014) Grad: 272.1093  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 13s (remain 12m 32s) Loss: 0.0000(0.0013) Grad: 81.2510  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 41s (remain 12m 3s) Loss: 0.0022(0.0013) Grad: 4038.4744  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 9s (remain 11m 34s) Loss: 0.0000(0.0013) Grad: 12.7324  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 36s (remain 11m 5s) Loss: 0.0123(0.0014) Grad: 26286.3867  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 4s (remain 10m 37s) Loss: 0.0004(0.0013) Grad: 2578.8469  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 32s (remain 10m 8s) Loss: 0.0017(0.0014) Grad: 3626.8354  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 59s (remain 9m 40s) Loss: 0.0002(0.0013) Grad: 1482.7822  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 27s (remain 9m 11s) Loss: 0.0095(0.0013) Grad: 36565.4141  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 55s (remain 8m 43s) Loss: 0.0001(0.0013) Grad: 529.3287  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 23s (remain 8m 15s) Loss: 0.0016(0.0014) Grad: 3446.3616  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 51s (remain 7m 47s) Loss: 0.0000(0.0014) Grad: 44.5576  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 18s (remain 7m 19s) Loss: 0.0057(0.0013) Grad: 13090.8857  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 46s (remain 6m 51s) Loss: 0.0005(0.0014) Grad: 938.6743  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 14s (remain 6m 23s) Loss: 0.0030(0.0014) Grad: 9771.5605  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 42s (remain 5m 55s) Loss: 0.0036(0.0014) Grad: 19492.7754  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 10s (remain 5m 27s) Loss: 0.0006(0.0014) Grad: 958.3845  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 38s (remain 4m 59s) Loss: 0.0017(0.0014) Grad: 3460.4209  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 6s (remain 4m 32s) Loss: 0.0015(0.0014) Grad: 4204.9644  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 34s (remain 4m 4s) Loss: 0.0003(0.0014) Grad: 1541.5388  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 2s (remain 3m 36s) Loss: 0.0003(0.0014) Grad: 786.0922  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 30s (remain 3m 8s) Loss: 0.0007(0.0014) Grad: 3581.9395  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 58s (remain 2m 40s) Loss: 0.0001(0.0014) Grad: 375.6880  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 26s (remain 2m 12s) Loss: 0.0000(0.0014) Grad: 45.2593  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 54s (remain 1m 44s) Loss: 0.0013(0.0014) Grad: 2976.1155  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 22s (remain 1m 16s) Loss: 0.0004(0.0014) Grad: 986.5497  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 50s (remain 0m 48s) Loss: 0.0010(0.0014) Grad: 2768.8550  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 18s (remain 0m 20s) Loss: 0.0005(0.0014) Grad: 1689.8323  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 39s (remain 0m 0s) Loss: 0.0001(0.0014) Grad: 348.7777  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 48s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0000(0.0012) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0001(0.0014) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0003(0.0021) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0030(0.0021) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0043(0.0020) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0308(0.0020) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0027(0.0023) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0022(0.0022) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0005(0.0021) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0021) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0012(0.0020) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0009(0.0018) \n","Epoch 2 - avg_train_loss: 0.0014  avg_val_loss: 0.0018  time: 1179s\n","Epoch 2 - Score: 0.8721\n","Epoch 2 - Save Best Score: 0.8721 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 37m 24s) Loss: 0.0005(0.0005) Grad: 1210.2682  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 30s (remain 17m 14s) Loss: 0.0000(0.0008) Grad: 6.6582  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 58s (remain 16m 27s) Loss: 0.0002(0.0009) Grad: 859.9330  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 26s (remain 15m 41s) Loss: 0.0000(0.0009) Grad: 123.1421  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 54s (remain 15m 4s) Loss: 0.0000(0.0009) Grad: 38.0767  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 22s (remain 14m 31s) Loss: 0.0001(0.0008) Grad: 1554.2064  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 49s (remain 14m 0s) Loss: 0.0030(0.0009) Grad: 6260.0024  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 17s (remain 13m 30s) Loss: 0.0018(0.0009) Grad: 7554.7974  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 45s (remain 13m 0s) Loss: 0.0000(0.0009) Grad: 215.4711  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 13s (remain 12m 31s) Loss: 0.0000(0.0009) Grad: 56.7023  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 40s (remain 12m 2s) Loss: 0.0002(0.0009) Grad: 622.8814  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 8s (remain 11m 33s) Loss: 0.0027(0.0010) Grad: 2641.6167  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 36s (remain 11m 4s) Loss: 0.0001(0.0010) Grad: 326.8819  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 4s (remain 10m 36s) Loss: 0.0000(0.0010) Grad: 34.9421  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 31s (remain 10m 8s) Loss: 0.0001(0.0010) Grad: 211.4552  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0001(0.0010) Grad: 1221.3553  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 27s (remain 9m 11s) Loss: 0.0009(0.0010) Grad: 3424.8735  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 55s (remain 8m 43s) Loss: 0.0000(0.0010) Grad: 133.0536  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 22s (remain 8m 15s) Loss: 0.0000(0.0010) Grad: 14.0259  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 50s (remain 7m 47s) Loss: 0.0026(0.0010) Grad: 13721.5908  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 18s (remain 7m 19s) Loss: 0.0001(0.0010) Grad: 408.7177  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 46s (remain 6m 51s) Loss: 0.0001(0.0010) Grad: 610.9243  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 13s (remain 6m 23s) Loss: 0.0022(0.0010) Grad: 7222.5391  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 41s (remain 5m 55s) Loss: 0.0001(0.0010) Grad: 330.3159  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 9s (remain 5m 27s) Loss: 0.0002(0.0010) Grad: 1293.5265  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 37s (remain 4m 59s) Loss: 0.0000(0.0010) Grad: 23.9008  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 4s (remain 4m 31s) Loss: 0.0000(0.0010) Grad: 96.1770  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 32s (remain 4m 3s) Loss: 0.0000(0.0010) Grad: 85.7089  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 0s (remain 3m 35s) Loss: 0.0000(0.0010) Grad: 5.6262  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 28s (remain 3m 7s) Loss: 0.0001(0.0010) Grad: 321.0666  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 55s (remain 2m 39s) Loss: 0.0025(0.0010) Grad: 6785.5913  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 23s (remain 2m 11s) Loss: 0.0000(0.0010) Grad: 9.9328  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 51s (remain 1m 44s) Loss: 0.0007(0.0010) Grad: 2493.0566  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 18s (remain 1m 16s) Loss: 0.0008(0.0010) Grad: 3254.9165  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 46s (remain 0m 48s) Loss: 0.0002(0.0010) Grad: 2149.5354  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 14s (remain 0m 20s) Loss: 0.0012(0.0010) Grad: 8401.2344  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 35s (remain 0m 0s) Loss: 0.0002(0.0010) Grad: 744.4487  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 56s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0000(0.0015) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0001(0.0019) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0002(0.0028) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0038(0.0028) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0061(0.0026) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0468(0.0026) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0064(0.0030) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0066(0.0029) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0001(0.0028) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0027) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0019(0.0025) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0025(0.0024) \n","Epoch 3 - avg_train_loss: 0.0010  avg_val_loss: 0.0024  time: 1175s\n","Epoch 3 - Score: 0.8760\n","Epoch 3 - Save Best Score: 0.8760 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 35m 45s) Loss: 0.0000(0.0000) Grad: 746.3420  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 29s (remain 17m 0s) Loss: 0.0015(0.0008) Grad: 3371.1206  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 58s (remain 16m 21s) Loss: 0.0001(0.0007) Grad: 478.7126  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 26s (remain 15m 37s) Loss: 0.0000(0.0007) Grad: 8.9629  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 53s (remain 15m 1s) Loss: 0.0002(0.0008) Grad: 1581.9727  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 21s (remain 14m 28s) Loss: 0.0029(0.0008) Grad: 4525.3994  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 49s (remain 13m 58s) Loss: 0.0001(0.0007) Grad: 317.0406  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 17s (remain 13m 29s) Loss: 0.0000(0.0007) Grad: 134.6579  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 45s (remain 13m 0s) Loss: 0.0001(0.0007) Grad: 439.2946  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 13s (remain 12m 31s) Loss: 0.0008(0.0007) Grad: 3452.9209  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 41s (remain 12m 3s) Loss: 0.0000(0.0007) Grad: 45.0398  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 9s (remain 11m 35s) Loss: 0.0000(0.0007) Grad: 136.8773  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 37s (remain 11m 7s) Loss: 0.0007(0.0007) Grad: 4138.8052  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 5s (remain 10m 38s) Loss: 0.0006(0.0007) Grad: 1916.7615  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 33s (remain 10m 10s) Loss: 0.0000(0.0007) Grad: 422.6804  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 1s (remain 9m 42s) Loss: 0.0014(0.0007) Grad: 5394.3735  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 29s (remain 9m 13s) Loss: 0.0003(0.0007) Grad: 1814.7170  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 56s (remain 8m 45s) Loss: 0.0000(0.0007) Grad: 42.4395  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 24s (remain 8m 17s) Loss: 0.0004(0.0007) Grad: 1650.2689  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 52s (remain 7m 49s) Loss: 0.0000(0.0007) Grad: 198.9369  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 20s (remain 7m 20s) Loss: 0.0021(0.0007) Grad: 4850.6597  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 48s (remain 6m 52s) Loss: 0.0000(0.0007) Grad: 7.2963  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 15s (remain 6m 24s) Loss: 0.0000(0.0007) Grad: 39.1063  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 43s (remain 5m 56s) Loss: 0.0006(0.0007) Grad: 4051.7886  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 10s (remain 5m 28s) Loss: 0.0000(0.0007) Grad: 17.4510  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 38s (remain 5m 0s) Loss: 0.0000(0.0007) Grad: 37.1433  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 6s (remain 4m 32s) Loss: 0.0000(0.0007) Grad: 10.7780  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 34s (remain 4m 4s) Loss: 0.0000(0.0007) Grad: 37.8715  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 1s (remain 3m 36s) Loss: 0.0000(0.0007) Grad: 28.1842  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 29s (remain 3m 8s) Loss: 0.0000(0.0007) Grad: 121.0132  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 57s (remain 2m 40s) Loss: 0.0001(0.0007) Grad: 611.1903  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 24s (remain 2m 12s) Loss: 0.0004(0.0007) Grad: 1537.0841  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 52s (remain 1m 44s) Loss: 0.0001(0.0008) Grad: 637.7925  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 19s (remain 1m 16s) Loss: 0.0000(0.0007) Grad: 6.3304  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 47s (remain 0m 48s) Loss: 0.0000(0.0007) Grad: 159.4165  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 15s (remain 0m 20s) Loss: 0.0003(0.0007) Grad: 1738.6328  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 35s (remain 0m 0s) Loss: 0.0000(0.0007) Grad: 22.0666  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 34s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0000(0.0018) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0000(0.0022) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0001(0.0032) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0066(0.0031) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0062(0.0029) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0476(0.0030) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0067(0.0034) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0046(0.0032) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0003(0.0032) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0030) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0020(0.0029) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0030(0.0027) \n","Epoch 4 - avg_train_loss: 0.0007  avg_val_loss: 0.0027  time: 1175s\n","Epoch 4 - Score: 0.8767\n","Epoch 4 - Save Best Score: 0.8767 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 35m 28s) Loss: 0.0000(0.0000) Grad: 75.0504  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 30s (remain 17m 13s) Loss: 0.0000(0.0007) Grad: 78.9218  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 58s (remain 16m 30s) Loss: 0.0010(0.0007) Grad: 5136.4814  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 26s (remain 15m 42s) Loss: 0.0006(0.0006) Grad: 2086.8577  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 54s (remain 15m 4s) Loss: 0.0000(0.0006) Grad: 23.3629  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 21s (remain 14m 31s) Loss: 0.0049(0.0006) Grad: 28298.5742  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 49s (remain 13m 59s) Loss: 0.0000(0.0006) Grad: 2.6616  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 17s (remain 13m 28s) Loss: 0.0000(0.0006) Grad: 34.5730  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 44s (remain 12m 58s) Loss: 0.0009(0.0006) Grad: 3953.6206  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 12s (remain 12m 29s) Loss: 0.0043(0.0006) Grad: 6662.9404  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 40s (remain 12m 0s) Loss: 0.0002(0.0006) Grad: 742.7996  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 7s (remain 11m 31s) Loss: 0.0005(0.0006) Grad: 3954.8865  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 35s (remain 11m 3s) Loss: 0.0000(0.0006) Grad: 103.4914  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 3s (remain 10m 34s) Loss: 0.0002(0.0006) Grad: 1218.7323  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 30s (remain 10m 6s) Loss: 0.0001(0.0006) Grad: 926.5175  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 58s (remain 9m 38s) Loss: 0.0001(0.0006) Grad: 354.5098  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 26s (remain 9m 10s) Loss: 0.0000(0.0006) Grad: 93.4858  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 54s (remain 8m 42s) Loss: 0.0003(0.0006) Grad: 2311.3909  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 21s (remain 8m 14s) Loss: 0.0000(0.0006) Grad: 242.9019  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 49s (remain 7m 46s) Loss: 0.0000(0.0006) Grad: 31.9498  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0000(0.0006) Grad: 33.0280  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 44s (remain 6m 50s) Loss: 0.0000(0.0006) Grad: 1.6073  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 12s (remain 6m 22s) Loss: 0.0000(0.0006) Grad: 0.8367  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 40s (remain 5m 54s) Loss: 0.0000(0.0006) Grad: 211.0965  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 7s (remain 5m 26s) Loss: 0.0003(0.0006) Grad: 2461.5737  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 35s (remain 4m 58s) Loss: 0.0001(0.0006) Grad: 1524.2557  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 3s (remain 4m 30s) Loss: 0.0000(0.0006) Grad: 160.0966  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 30s (remain 4m 2s) Loss: 0.0000(0.0006) Grad: 5.1221  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 58s (remain 3m 35s) Loss: 0.0023(0.0006) Grad: 2459.4165  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 26s (remain 3m 7s) Loss: 0.0005(0.0006) Grad: 2338.9424  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 53s (remain 2m 39s) Loss: 0.0000(0.0006) Grad: 36.0168  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 21s (remain 2m 11s) Loss: 0.0002(0.0006) Grad: 931.5108  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 49s (remain 1m 43s) Loss: 0.0080(0.0006) Grad: 152559.4844  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 17s (remain 1m 16s) Loss: 0.0000(0.0006) Grad: 36.0632  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 44s (remain 0m 48s) Loss: 0.0001(0.0006) Grad: 1923.5122  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 12s (remain 0m 20s) Loss: 0.0000(0.0006) Grad: 1009.7097  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 33s (remain 0m 0s) Loss: 0.0000(0.0006) Grad: 60.2150  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 43s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0000(0.0018) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0000(0.0022) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0001(0.0033) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0069(0.0033) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0065(0.0031) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0458(0.0031) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0065(0.0035) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0135(0.0034) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0003(0.0033) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.0000(0.0032) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0022(0.0030) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0031(0.0029) \n","Epoch 5 - avg_train_loss: 0.0006  avg_val_loss: 0.0029  time: 1174s\n","Epoch 5 - Score: 0.8782\n","Epoch 5 - Save Best Score: 0.8782 Model\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 48m 12s) Loss: 0.0909(0.0909) Grad: 65004.9258  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 30s (remain 17m 23s) Loss: 0.0786(0.0867) Grad: 28607.8340  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 58s (remain 16m 19s) Loss: 0.0436(0.0740) Grad: 17726.5000  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 26s (remain 15m 39s) Loss: 0.0123(0.0584) Grad: 6003.1050  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 54s (remain 15m 3s) Loss: 0.0143(0.0470) Grad: 2503.9475  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 21s (remain 14m 30s) Loss: 0.0072(0.0399) Grad: 1543.5854  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 49s (remain 13m 59s) Loss: 0.0095(0.0352) Grad: 1700.1880  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 17s (remain 13m 29s) Loss: 0.0070(0.0314) Grad: 2958.1348  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 45s (remain 12m 59s) Loss: 0.0535(0.0284) Grad: 20965.8652  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 12s (remain 12m 30s) Loss: 0.0032(0.0258) Grad: 1176.6876  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 40s (remain 12m 1s) Loss: 0.0118(0.0237) Grad: 8210.7842  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 8s (remain 11m 32s) Loss: 0.0016(0.0219) Grad: 755.4055  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 35s (remain 11m 4s) Loss: 0.0013(0.0204) Grad: 961.4961  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 3s (remain 10m 36s) Loss: 0.0014(0.0190) Grad: 395.2112  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0175(0.0179) Grad: 10784.6621  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0007(0.0169) Grad: 380.2856  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 27s (remain 9m 11s) Loss: 0.0015(0.0160) Grad: 659.9468  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 54s (remain 8m 43s) Loss: 0.0013(0.0152) Grad: 996.3194  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 22s (remain 8m 15s) Loss: 0.0001(0.0145) Grad: 96.9236  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 50s (remain 7m 47s) Loss: 0.0039(0.0139) Grad: 2119.1323  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 18s (remain 7m 19s) Loss: 0.0006(0.0133) Grad: 328.8020  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0058(0.0128) Grad: 1829.0890  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 13s (remain 6m 23s) Loss: 0.0034(0.0123) Grad: 1386.9830  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 41s (remain 5m 55s) Loss: 0.0001(0.0119) Grad: 68.7338  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 9s (remain 5m 27s) Loss: 0.0002(0.0115) Grad: 454.2117  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 36s (remain 4m 59s) Loss: 0.0000(0.0111) Grad: 81.3341  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 4s (remain 4m 31s) Loss: 0.0000(0.0107) Grad: 93.8036  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 32s (remain 4m 3s) Loss: 0.0067(0.0104) Grad: 7084.7725  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 0s (remain 3m 35s) Loss: 0.0001(0.0101) Grad: 50.0107  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 27s (remain 3m 7s) Loss: 0.0013(0.0098) Grad: 1057.8615  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 55s (remain 2m 39s) Loss: 0.0032(0.0096) Grad: 1340.6414  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 23s (remain 2m 11s) Loss: 0.0004(0.0093) Grad: 251.9337  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 51s (remain 1m 44s) Loss: 0.0014(0.0091) Grad: 2729.8694  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 18s (remain 1m 16s) Loss: 0.0006(0.0089) Grad: 340.6060  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 46s (remain 0m 48s) Loss: 0.0030(0.0087) Grad: 901.6848  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 14s (remain 0m 20s) Loss: 0.0006(0.0085) Grad: 265.7516  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 34s (remain 0m 0s) Loss: 0.0005(0.0084) Grad: 385.1107  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 39s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.0035(0.0016) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0016(0.0016) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0033(0.0016) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0007(0.0016) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0000(0.0015) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0018(0.0016) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0010(0.0018) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0007(0.0017) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0017(0.0017) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0004(0.0017) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0017(0.0016) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0002(0.0016) \n","Epoch 1 - avg_train_loss: 0.0084  avg_val_loss: 0.0016  time: 1177s\n","Epoch 1 - Score: 0.8671\n","Epoch 1 - Save Best Score: 0.8671 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 40m 56s) Loss: 0.0005(0.0005) Grad: 1067.8217  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 30s (remain 17m 23s) Loss: 0.0001(0.0012) Grad: 234.7499  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 58s (remain 16m 27s) Loss: 0.0000(0.0014) Grad: 14.7299  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 26s (remain 15m 43s) Loss: 0.0018(0.0014) Grad: 3735.8438  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 54s (remain 15m 6s) Loss: 0.0038(0.0014) Grad: 5422.5361  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 22s (remain 14m 32s) Loss: 0.0016(0.0014) Grad: 3625.2361  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 49s (remain 14m 0s) Loss: 0.0015(0.0016) Grad: 6194.4258  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 17s (remain 13m 30s) Loss: 0.0001(0.0016) Grad: 311.7603  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 45s (remain 13m 0s) Loss: 0.0000(0.0015) Grad: 76.3203  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 13s (remain 12m 30s) Loss: 0.0003(0.0015) Grad: 633.4048  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 40s (remain 12m 1s) Loss: 0.0009(0.0015) Grad: 1266.6198  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 8s (remain 11m 32s) Loss: 0.0032(0.0015) Grad: 5986.4077  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 36s (remain 11m 4s) Loss: 0.0000(0.0015) Grad: 151.0815  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 3s (remain 10m 35s) Loss: 0.0000(0.0015) Grad: 275.8235  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0009(0.0014) Grad: 2238.5930  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0011(0.0014) Grad: 3305.9983  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 26s (remain 9m 11s) Loss: 0.0020(0.0014) Grad: 4328.7915  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 55s (remain 8m 43s) Loss: 0.0016(0.0014) Grad: 5025.6084  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 22s (remain 8m 15s) Loss: 0.0000(0.0014) Grad: 257.2522  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 50s (remain 7m 47s) Loss: 0.0000(0.0014) Grad: 9.1287  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 18s (remain 7m 19s) Loss: 0.0116(0.0014) Grad: 108026.5078  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 46s (remain 6m 51s) Loss: 0.0000(0.0014) Grad: 146.9003  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 14s (remain 6m 23s) Loss: 0.0005(0.0014) Grad: 1758.2581  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 42s (remain 5m 55s) Loss: 0.0001(0.0014) Grad: 632.1420  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 10s (remain 5m 27s) Loss: 0.0000(0.0014) Grad: 66.7409  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 38s (remain 4m 59s) Loss: 0.0001(0.0014) Grad: 523.1873  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 6s (remain 4m 32s) Loss: 0.0002(0.0014) Grad: 634.5744  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 34s (remain 4m 4s) Loss: 0.0000(0.0014) Grad: 58.0412  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 2s (remain 3m 36s) Loss: 0.0004(0.0014) Grad: 1192.8884  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 30s (remain 3m 8s) Loss: 0.0027(0.0014) Grad: 4954.8682  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 58s (remain 2m 40s) Loss: 0.0087(0.0014) Grad: 85005.0703  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 26s (remain 2m 12s) Loss: 0.0001(0.0014) Grad: 652.3377  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 53s (remain 1m 44s) Loss: 0.0007(0.0014) Grad: 3517.1846  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 21s (remain 1m 16s) Loss: 0.0003(0.0014) Grad: 2925.5645  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 49s (remain 0m 48s) Loss: 0.0000(0.0014) Grad: 98.8647  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 17s (remain 0m 20s) Loss: 0.0000(0.0014) Grad: 49.3054  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 37s (remain 0m 0s) Loss: 0.0006(0.0014) Grad: 1362.1685  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 42s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0050(0.0019) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0013(0.0018) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0024(0.0017) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0003(0.0018) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0000(0.0017) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0007(0.0017) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0010(0.0019) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.0019) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0010(0.0019) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0030(0.0019) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0150(0.0018) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0017) \n","Epoch 2 - avg_train_loss: 0.0014  avg_val_loss: 0.0017  time: 1178s\n","Epoch 2 - Score: 0.8770\n","Epoch 2 - Save Best Score: 0.8770 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 37m 15s) Loss: 0.0014(0.0014) Grad: 4087.9937  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 29s (remain 17m 10s) Loss: 0.0010(0.0008) Grad: 4577.9375  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 58s (remain 16m 21s) Loss: 0.0044(0.0008) Grad: 10321.8955  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 26s (remain 15m 37s) Loss: 0.0001(0.0009) Grad: 475.3285  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 53s (remain 15m 1s) Loss: 0.0001(0.0010) Grad: 189.0564  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 21s (remain 14m 28s) Loss: 0.0023(0.0010) Grad: 18362.3516  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 49s (remain 13m 57s) Loss: 0.0000(0.0010) Grad: 82.7630  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 17s (remain 13m 28s) Loss: 0.0008(0.0010) Grad: 1721.6958  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 44s (remain 12m 58s) Loss: 0.0004(0.0010) Grad: 1128.5272  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 12s (remain 12m 29s) Loss: 0.0023(0.0010) Grad: 3901.1477  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 40s (remain 12m 0s) Loss: 0.0038(0.0010) Grad: 5347.2378  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 7s (remain 11m 32s) Loss: 0.0000(0.0010) Grad: 541.4128  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 35s (remain 11m 3s) Loss: 0.0013(0.0010) Grad: 6589.3877  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 3s (remain 10m 35s) Loss: 0.0054(0.0011) Grad: 7059.7383  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 31s (remain 10m 6s) Loss: 0.0000(0.0011) Grad: 183.3112  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 58s (remain 9m 38s) Loss: 0.0000(0.0011) Grad: 74.9405  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 26s (remain 9m 10s) Loss: 0.0000(0.0011) Grad: 15.0805  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 54s (remain 8m 42s) Loss: 0.0000(0.0011) Grad: 364.1850  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 21s (remain 8m 14s) Loss: 0.0005(0.0011) Grad: 1558.0762  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 49s (remain 7m 46s) Loss: 0.0000(0.0011) Grad: 244.9675  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0001(0.0011) Grad: 342.1815  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0047(0.0011) Grad: 9572.7383  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 12s (remain 6m 22s) Loss: 0.0000(0.0011) Grad: 49.9990  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 40s (remain 5m 54s) Loss: 0.0001(0.0011) Grad: 507.1238  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 8s (remain 5m 26s) Loss: 0.0080(0.0011) Grad: 55308.4922  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 35s (remain 4m 58s) Loss: 0.0024(0.0011) Grad: 11486.9521  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 3s (remain 4m 30s) Loss: 0.0013(0.0011) Grad: 7914.3345  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 31s (remain 4m 3s) Loss: 0.0001(0.0011) Grad: 2099.5281  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 58s (remain 3m 35s) Loss: 0.0003(0.0011) Grad: 1217.8359  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 26s (remain 3m 7s) Loss: 0.0000(0.0011) Grad: 6.7329  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 54s (remain 2m 39s) Loss: 0.0001(0.0011) Grad: 547.8339  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 22s (remain 2m 11s) Loss: 0.0012(0.0011) Grad: 18380.7422  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 49s (remain 1m 43s) Loss: 0.0061(0.0011) Grad: 4630.7388  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 17s (remain 1m 16s) Loss: 0.0000(0.0011) Grad: 34.2354  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 45s (remain 0m 48s) Loss: 0.0000(0.0011) Grad: 8.6029  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 13s (remain 0m 20s) Loss: 0.0008(0.0011) Grad: 2309.8857  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 33s (remain 0m 0s) Loss: 0.0000(0.0011) Grad: 11.5722  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 38s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0048(0.0020) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0009(0.0019) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0028(0.0018) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0001(0.0019) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0000(0.0017) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0011(0.0018) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0011(0.0020) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.0020) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0012(0.0021) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0002(0.0020) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0160(0.0019) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0019) \n","Epoch 3 - avg_train_loss: 0.0011  avg_val_loss: 0.0019  time: 1174s\n","Epoch 3 - Score: 0.8847\n","Epoch 3 - Save Best Score: 0.8847 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 37m 37s) Loss: 0.0011(0.0011) Grad: 1658.7817  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 30s (remain 17m 27s) Loss: 0.0009(0.0007) Grad: 1881.6227  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 59s (remain 16m 40s) Loss: 0.0011(0.0010) Grad: 4021.0747  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 27s (remain 15m 52s) Loss: 0.0000(0.0009) Grad: 2.5364  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 55s (remain 15m 14s) Loss: 0.0012(0.0008) Grad: 3166.8694  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 23s (remain 14m 40s) Loss: 0.0000(0.0008) Grad: 392.9101  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 51s (remain 14m 8s) Loss: 0.0000(0.0008) Grad: 90.7639  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 19s (remain 13m 37s) Loss: 0.0001(0.0008) Grad: 394.3176  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 47s (remain 13m 6s) Loss: 0.0027(0.0008) Grad: 15047.6904  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 15s (remain 12m 37s) Loss: 0.0008(0.0008) Grad: 3575.3147  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 43s (remain 12m 7s) Loss: 0.0032(0.0008) Grad: 7935.3823  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 10s (remain 11m 38s) Loss: 0.0000(0.0008) Grad: 7.1234  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 39s (remain 11m 10s) Loss: 0.0000(0.0008) Grad: 9.0595  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 7s (remain 10m 41s) Loss: 0.0000(0.0008) Grad: 38.8800  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 35s (remain 10m 12s) Loss: 0.0010(0.0008) Grad: 5460.6455  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 2s (remain 9m 44s) Loss: 0.0000(0.0008) Grad: 6.8778  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 30s (remain 9m 15s) Loss: 0.0000(0.0008) Grad: 148.5142  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 58s (remain 8m 46s) Loss: 0.0000(0.0008) Grad: 62.5262  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 25s (remain 8m 18s) Loss: 0.0001(0.0007) Grad: 558.2338  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 53s (remain 7m 49s) Loss: 0.0042(0.0008) Grad: 9210.6924  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 21s (remain 7m 21s) Loss: 0.0076(0.0008) Grad: 25797.0117  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 49s (remain 6m 53s) Loss: 0.0005(0.0008) Grad: 9605.2480  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 16s (remain 6m 25s) Loss: 0.0000(0.0008) Grad: 39.1274  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 44s (remain 5m 56s) Loss: 0.0000(0.0008) Grad: 12.6839  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 12s (remain 5m 28s) Loss: 0.0000(0.0008) Grad: 13.6750  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 39s (remain 5m 0s) Loss: 0.0000(0.0008) Grad: 94.2629  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 7s (remain 4m 32s) Loss: 0.0000(0.0008) Grad: 80.5294  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 35s (remain 4m 4s) Loss: 0.0000(0.0008) Grad: 4.7502  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 3s (remain 3m 36s) Loss: 0.0000(0.0008) Grad: 276.5800  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 30s (remain 3m 8s) Loss: 0.0000(0.0008) Grad: 602.7665  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 58s (remain 2m 40s) Loss: 0.0000(0.0008) Grad: 21.4366  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 26s (remain 2m 12s) Loss: 0.0000(0.0008) Grad: 15.9635  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 53s (remain 1m 44s) Loss: 0.0001(0.0008) Grad: 846.1431  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 21s (remain 1m 16s) Loss: 0.0000(0.0008) Grad: 5.3512  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 49s (remain 0m 48s) Loss: 0.0001(0.0008) Grad: 941.7969  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 16s (remain 0m 20s) Loss: 0.0000(0.0008) Grad: 85.5523  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 37s (remain 0m 0s) Loss: 0.0000(0.0008) Grad: 24.7717  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 7s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0048(0.0024) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0014(0.0022) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0053(0.0021) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0001(0.0022) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0000(0.0021) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0015(0.0022) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0006(0.0023) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.0024) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0034(0.0024) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0001(0.0024) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0152(0.0022) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0022) \n","Epoch 4 - avg_train_loss: 0.0008  avg_val_loss: 0.0022  time: 1178s\n","Epoch 4 - Score: 0.8870\n","Epoch 4 - Save Best Score: 0.8870 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 37m 58s) Loss: 0.0015(0.0015) Grad: 4219.4907  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 30s (remain 17m 41s) Loss: 0.0000(0.0007) Grad: 196.1726  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 59s (remain 16m 33s) Loss: 0.0000(0.0007) Grad: 36.5054  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 26s (remain 15m 44s) Loss: 0.0000(0.0007) Grad: 353.6231  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 54s (remain 15m 6s) Loss: 0.0007(0.0006) Grad: 4008.3433  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 22s (remain 14m 33s) Loss: 0.0000(0.0006) Grad: 19.2961  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 50s (remain 14m 1s) Loss: 0.0000(0.0006) Grad: 360.6310  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 17s (remain 13m 30s) Loss: 0.0000(0.0006) Grad: 329.7767  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 45s (remain 13m 0s) Loss: 0.0000(0.0006) Grad: 8.9753  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 13s (remain 12m 31s) Loss: 0.0015(0.0006) Grad: 3444.1177  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 40s (remain 12m 2s) Loss: 0.0001(0.0006) Grad: 304.5383  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 8s (remain 11m 33s) Loss: 0.0000(0.0006) Grad: 12.5706  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 36s (remain 11m 4s) Loss: 0.0000(0.0006) Grad: 286.3906  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 3s (remain 10m 36s) Loss: 0.0000(0.0006) Grad: 11.8844  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0006(0.0006) Grad: 2975.5312  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0000(0.0006) Grad: 77.8584  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 27s (remain 9m 11s) Loss: 0.0000(0.0006) Grad: 32.0616  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 54s (remain 8m 43s) Loss: 0.0000(0.0006) Grad: 11.3728  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 22s (remain 8m 14s) Loss: 0.0000(0.0006) Grad: 60.1418  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 50s (remain 7m 46s) Loss: 0.0005(0.0006) Grad: 1865.5653  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0000(0.0006) Grad: 511.0123  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0000(0.0006) Grad: 91.5568  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 13s (remain 6m 22s) Loss: 0.0003(0.0006) Grad: 1633.2736  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 40s (remain 5m 54s) Loss: 0.0004(0.0006) Grad: 1781.1348  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 8s (remain 5m 26s) Loss: 0.0000(0.0006) Grad: 11.1263  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 36s (remain 4m 59s) Loss: 0.0000(0.0006) Grad: 203.6275  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 3s (remain 4m 31s) Loss: 0.0000(0.0006) Grad: 345.0413  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 31s (remain 4m 3s) Loss: 0.0000(0.0006) Grad: 28.0890  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 59s (remain 3m 35s) Loss: 0.0000(0.0006) Grad: 216.3705  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 27s (remain 3m 7s) Loss: 0.0000(0.0006) Grad: 199.1612  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 55s (remain 2m 39s) Loss: 0.0000(0.0006) Grad: 204.7004  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 23s (remain 2m 11s) Loss: 0.0000(0.0006) Grad: 68.3844  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 51s (remain 1m 44s) Loss: 0.0012(0.0006) Grad: 3187.1638  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 19s (remain 1m 16s) Loss: 0.0000(0.0006) Grad: 190.9575  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 47s (remain 0m 48s) Loss: 0.0000(0.0006) Grad: 68.8924  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 15s (remain 0m 20s) Loss: 0.0000(0.0006) Grad: 1.2558  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 35s (remain 0m 0s) Loss: 0.0001(0.0006) Grad: 518.1942  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 19s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.0062(0.0028) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0018(0.0025) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0027(0.0023) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0001(0.0025) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0000(0.0023) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0018(0.0024) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0008(0.0026) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.0027) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0024(0.0027) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.0001(0.0027) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0185(0.0025) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0025) \n","Epoch 5 - avg_train_loss: 0.0006  avg_val_loss: 0.0025  time: 1177s\n","Epoch 5 - Score: 0.8880\n","Epoch 5 - Save Best Score: 0.8880 Model\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 44m 35s) Loss: 0.0840(0.0840) Grad: 62870.7656  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 30s (remain 17m 39s) Loss: 0.0699(0.0782) Grad: 26643.9355  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 58s (remain 16m 22s) Loss: 0.0372(0.0668) Grad: 17339.6367  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 26s (remain 15m 38s) Loss: 0.0104(0.0531) Grad: 6075.9663  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 54s (remain 15m 2s) Loss: 0.0157(0.0430) Grad: 3173.2527  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 21s (remain 14m 29s) Loss: 0.0133(0.0366) Grad: 2340.4758  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 49s (remain 13m 58s) Loss: 0.0188(0.0322) Grad: 2332.3298  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 17s (remain 13m 28s) Loss: 0.0026(0.0290) Grad: 846.9153  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 44s (remain 12m 58s) Loss: 0.0034(0.0264) Grad: 1417.0048  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 12s (remain 12m 29s) Loss: 0.0023(0.0240) Grad: 835.0651  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 40s (remain 12m 0s) Loss: 0.0011(0.0219) Grad: 628.6658  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 8s (remain 11m 32s) Loss: 0.0030(0.0203) Grad: 1161.2448  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 35s (remain 11m 3s) Loss: 0.0005(0.0189) Grad: 541.0626  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 3s (remain 10m 35s) Loss: 0.0135(0.0177) Grad: 3726.5139  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0001(0.0166) Grad: 80.4009  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0022(0.0157) Grad: 1291.3433  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 26s (remain 9m 11s) Loss: 0.0005(0.0148) Grad: 299.6714  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 54s (remain 8m 42s) Loss: 0.0056(0.0141) Grad: 3726.2920  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 22s (remain 8m 14s) Loss: 0.0147(0.0134) Grad: 9627.5381  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 49s (remain 7m 46s) Loss: 0.0005(0.0128) Grad: 328.1462  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0004(0.0124) Grad: 226.9501  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0012(0.0119) Grad: 898.7900  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 13s (remain 6m 22s) Loss: 0.0030(0.0114) Grad: 4169.0415  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 40s (remain 5m 54s) Loss: 0.0004(0.0110) Grad: 245.9787  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 8s (remain 5m 26s) Loss: 0.0002(0.0107) Grad: 154.0338  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 36s (remain 4m 58s) Loss: 0.0006(0.0103) Grad: 346.7879  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 3s (remain 4m 31s) Loss: 0.0013(0.0100) Grad: 1832.8679  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 31s (remain 4m 3s) Loss: 0.0000(0.0097) Grad: 3.3360  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 59s (remain 3m 35s) Loss: 0.0009(0.0094) Grad: 255.8857  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 27s (remain 3m 7s) Loss: 0.0003(0.0091) Grad: 273.8964  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 54s (remain 2m 39s) Loss: 0.0047(0.0089) Grad: 7683.1670  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 22s (remain 2m 11s) Loss: 0.0005(0.0087) Grad: 595.8822  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 50s (remain 1m 44s) Loss: 0.0021(0.0085) Grad: 1975.4644  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 18s (remain 1m 16s) Loss: 0.0022(0.0083) Grad: 449.6853  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 45s (remain 0m 48s) Loss: 0.0010(0.0081) Grad: 659.5493  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 13s (remain 0m 20s) Loss: 0.0019(0.0080) Grad: 1110.6680  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 33s (remain 0m 0s) Loss: 0.0000(0.0078) Grad: 13.4015  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 47s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.0041(0.0014) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0017(0.0014) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0018(0.0016) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0000(0.0015) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0057(0.0014) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0006(0.0016) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0012(0.0018) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0016(0.0018) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0011(0.0018) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0017) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0030(0.0017) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0001(0.0016) \n","Epoch 1 - avg_train_loss: 0.0078  avg_val_loss: 0.0016  time: 1171s\n","Epoch 1 - Score: 0.8558\n","Epoch 1 - Save Best Score: 0.8558 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 40m 39s) Loss: 0.0003(0.0003) Grad: 534.7711  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 30s (remain 17m 36s) Loss: 0.0027(0.0017) Grad: 3474.1990  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 59s (remain 16m 35s) Loss: 0.0002(0.0016) Grad: 424.1891  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 27s (remain 15m 46s) Loss: 0.0006(0.0018) Grad: 1829.7844  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 54s (remain 15m 8s) Loss: 0.0014(0.0017) Grad: 4433.3823  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 22s (remain 14m 34s) Loss: 0.0010(0.0016) Grad: 3849.4995  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 50s (remain 14m 2s) Loss: 0.0001(0.0016) Grad: 446.0474  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 17s (remain 13m 31s) Loss: 0.0011(0.0016) Grad: 2350.9482  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 45s (remain 13m 1s) Loss: 0.0015(0.0015) Grad: 4002.0710  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 13s (remain 12m 31s) Loss: 0.0006(0.0015) Grad: 1959.5061  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 41s (remain 12m 2s) Loss: 0.0002(0.0015) Grad: 855.2484  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 8s (remain 11m 33s) Loss: 0.0000(0.0015) Grad: 7.2678  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 36s (remain 11m 5s) Loss: 0.0003(0.0015) Grad: 1800.8209  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 4s (remain 10m 36s) Loss: 0.0001(0.0015) Grad: 632.8770  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 32s (remain 10m 8s) Loss: 0.0006(0.0015) Grad: 1660.8677  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 0s (remain 9m 40s) Loss: 0.0027(0.0015) Grad: 12114.4150  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 28s (remain 9m 12s) Loss: 0.0021(0.0015) Grad: 2622.7952  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 56s (remain 8m 44s) Loss: 0.0001(0.0015) Grad: 1570.5776  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 24s (remain 8m 16s) Loss: 0.0004(0.0015) Grad: 1496.8796  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 52s (remain 7m 48s) Loss: 0.0000(0.0015) Grad: 233.5794  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 20s (remain 7m 20s) Loss: 0.0002(0.0015) Grad: 394.7130  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 48s (remain 6m 52s) Loss: 0.0029(0.0015) Grad: 7869.1680  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 16s (remain 6m 24s) Loss: 0.0033(0.0015) Grad: 5103.1660  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 44s (remain 5m 56s) Loss: 0.0000(0.0015) Grad: 194.7885  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 12s (remain 5m 28s) Loss: 0.0003(0.0015) Grad: 1017.3669  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 40s (remain 5m 0s) Loss: 0.0057(0.0015) Grad: 10010.5361  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 7s (remain 4m 32s) Loss: 0.0001(0.0015) Grad: 284.1580  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 35s (remain 4m 4s) Loss: 0.0003(0.0015) Grad: 833.5734  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 3s (remain 3m 36s) Loss: 0.0001(0.0015) Grad: 616.2466  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 31s (remain 3m 8s) Loss: 0.0024(0.0015) Grad: 3903.6716  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 59s (remain 2m 40s) Loss: 0.0000(0.0015) Grad: 40.7579  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 26s (remain 2m 12s) Loss: 0.0123(0.0015) Grad: 22127.0195  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 54s (remain 1m 44s) Loss: 0.0002(0.0015) Grad: 1500.0582  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 22s (remain 1m 16s) Loss: 0.0013(0.0015) Grad: 2514.2415  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 49s (remain 0m 48s) Loss: 0.0004(0.0015) Grad: 1458.4453  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 17s (remain 0m 20s) Loss: 0.0009(0.0015) Grad: 2842.7737  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 38s (remain 0m 0s) Loss: 0.0001(0.0015) Grad: 469.2285  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 2s) Loss: 0.0003(0.0003) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0070(0.0012) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0009(0.0012) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0010(0.0014) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0000(0.0014) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0064(0.0013) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0010(0.0014) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0004(0.0016) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0022(0.0016) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0002(0.0017) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0016) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0044(0.0016) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0016) \n","Epoch 2 - avg_train_loss: 0.0015  avg_val_loss: 0.0016  time: 1175s\n","Epoch 2 - Score: 0.8734\n","Epoch 2 - Save Best Score: 0.8734 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 38m 2s) Loss: 0.0032(0.0032) Grad: 3612.5752  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 30s (remain 17m 25s) Loss: 0.0003(0.0013) Grad: 889.0341  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 58s (remain 16m 27s) Loss: 0.0000(0.0012) Grad: 161.0210  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 26s (remain 15m 40s) Loss: 0.0002(0.0012) Grad: 821.0214  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 54s (remain 15m 3s) Loss: 0.0000(0.0011) Grad: 110.0890  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 21s (remain 14m 30s) Loss: 0.0000(0.0011) Grad: 68.1801  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 49s (remain 14m 0s) Loss: 0.0032(0.0012) Grad: 6650.0957  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 17s (remain 13m 29s) Loss: 0.0000(0.0011) Grad: 35.7195  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 45s (remain 13m 0s) Loss: 0.0002(0.0011) Grad: 646.8943  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 12s (remain 12m 30s) Loss: 0.0002(0.0011) Grad: 536.8795  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 40s (remain 12m 1s) Loss: 0.0008(0.0011) Grad: 2316.0452  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 8s (remain 11m 32s) Loss: 0.0009(0.0011) Grad: 2719.0073  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 35s (remain 11m 4s) Loss: 0.0031(0.0011) Grad: 5953.4204  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 3s (remain 10m 35s) Loss: 0.0004(0.0011) Grad: 1308.5645  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 31s (remain 10m 7s) Loss: 0.0000(0.0011) Grad: 15.6053  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0000(0.0011) Grad: 261.8903  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 26s (remain 9m 10s) Loss: 0.0022(0.0011) Grad: 3207.3108  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 54s (remain 8m 42s) Loss: 0.0000(0.0010) Grad: 30.4932  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 22s (remain 8m 14s) Loss: 0.0010(0.0010) Grad: 3113.7617  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 49s (remain 7m 46s) Loss: 0.0015(0.0010) Grad: 3501.6350  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 17s (remain 7m 18s) Loss: 0.0000(0.0010) Grad: 287.4780  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 45s (remain 6m 50s) Loss: 0.0034(0.0010) Grad: 5657.9316  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 13s (remain 6m 22s) Loss: 0.0000(0.0010) Grad: 8.4177  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 40s (remain 5m 54s) Loss: 0.0006(0.0010) Grad: 2969.7673  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 8s (remain 5m 26s) Loss: 0.0009(0.0011) Grad: 3447.3259  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 36s (remain 4m 58s) Loss: 0.0007(0.0011) Grad: 2623.9209  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 3s (remain 4m 31s) Loss: 0.0000(0.0011) Grad: 290.9911  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 31s (remain 4m 3s) Loss: 0.0012(0.0011) Grad: 2864.0955  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 59s (remain 3m 35s) Loss: 0.0014(0.0011) Grad: 2544.2273  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 26s (remain 3m 7s) Loss: 0.0000(0.0011) Grad: 7.4042  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 54s (remain 2m 39s) Loss: 0.0022(0.0011) Grad: 4697.1895  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 22s (remain 2m 11s) Loss: 0.0015(0.0011) Grad: 5544.7598  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 50s (remain 1m 43s) Loss: 0.0002(0.0011) Grad: 2100.6787  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 17s (remain 1m 16s) Loss: 0.0000(0.0010) Grad: 31.4937  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 45s (remain 0m 48s) Loss: 0.0001(0.0011) Grad: 481.4539  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 13s (remain 0m 20s) Loss: 0.0003(0.0011) Grad: 801.5938  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 33s (remain 0m 0s) Loss: 0.0002(0.0011) Grad: 1249.3967  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 3s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0089(0.0014) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0011(0.0013) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0012(0.0015) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0000(0.0015) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0097(0.0014) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0012(0.0015) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0007(0.0017) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0039(0.0017) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0013(0.0018) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0017) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0041(0.0017) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0016) \n","Epoch 3 - avg_train_loss: 0.0011  avg_val_loss: 0.0016  time: 1171s\n","Epoch 3 - Score: 0.8814\n","Epoch 3 - Save Best Score: 0.8814 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 39m 9s) Loss: 0.0002(0.0002) Grad: 1203.6876  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 32s (remain 18m 29s) Loss: 0.0036(0.0007) Grad: 13908.6875  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 0s (remain 16m 58s) Loss: 0.0000(0.0008) Grad: 19.1524  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 28s (remain 16m 3s) Loss: 0.0006(0.0007) Grad: 2303.0120  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 56s (remain 15m 22s) Loss: 0.0002(0.0007) Grad: 816.3504  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 24s (remain 14m 46s) Loss: 0.0000(0.0007) Grad: 0.9481  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 52s (remain 14m 13s) Loss: 0.0000(0.0007) Grad: 387.5510  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 20s (remain 13m 41s) Loss: 0.0003(0.0007) Grad: 2095.4753  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 48s (remain 13m 10s) Loss: 0.0010(0.0007) Grad: 4794.5581  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 16s (remain 12m 40s) Loss: 0.0000(0.0007) Grad: 6.6381  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 44s (remain 12m 10s) Loss: 0.0000(0.0007) Grad: 159.2728  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 12s (remain 11m 41s) Loss: 0.0005(0.0007) Grad: 3566.2715  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 40s (remain 11m 12s) Loss: 0.0080(0.0007) Grad: 11581.1836  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 7s (remain 10m 42s) Loss: 0.0006(0.0007) Grad: 3676.2642  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 35s (remain 10m 13s) Loss: 0.0000(0.0007) Grad: 12.8231  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 3s (remain 9m 44s) Loss: 0.0001(0.0007) Grad: 568.0685  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 30s (remain 9m 15s) Loss: 0.0002(0.0007) Grad: 1225.9824  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 58s (remain 8m 47s) Loss: 0.0001(0.0007) Grad: 741.8723  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 26s (remain 8m 18s) Loss: 0.0000(0.0007) Grad: 23.8506  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 53s (remain 7m 50s) Loss: 0.0003(0.0007) Grad: 1071.8970  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 21s (remain 7m 21s) Loss: 0.0000(0.0007) Grad: 7.3937  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 49s (remain 6m 53s) Loss: 0.0029(0.0008) Grad: 12695.8232  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 17s (remain 6m 25s) Loss: 0.0001(0.0008) Grad: 464.0475  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 44s (remain 5m 57s) Loss: 0.0002(0.0008) Grad: 3175.7317  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 12s (remain 5m 28s) Loss: 0.0003(0.0008) Grad: 2343.1221  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 40s (remain 5m 0s) Loss: 0.0000(0.0008) Grad: 5.9437  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 8s (remain 4m 32s) Loss: 0.0019(0.0008) Grad: 8132.3716  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 35s (remain 4m 4s) Loss: 0.0002(0.0008) Grad: 1520.6267  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 3s (remain 3m 36s) Loss: 0.0037(0.0008) Grad: 7646.7236  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 31s (remain 3m 8s) Loss: 0.0000(0.0008) Grad: 11.3433  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 58s (remain 2m 40s) Loss: 0.0000(0.0008) Grad: 5.8153  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 26s (remain 2m 12s) Loss: 0.0000(0.0008) Grad: 114.9367  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 54s (remain 1m 44s) Loss: 0.0004(0.0008) Grad: 1707.4612  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 22s (remain 1m 16s) Loss: 0.0000(0.0008) Grad: 29.8310  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 49s (remain 0m 48s) Loss: 0.0000(0.0008) Grad: 4.4335  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 17s (remain 0m 20s) Loss: 0.0000(0.0008) Grad: 77.4784  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 37s (remain 0m 0s) Loss: 0.0000(0.0008) Grad: 33.5620  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 47s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0146(0.0020) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0012(0.0017) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0026(0.0019) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0000(0.0019) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0148(0.0018) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0006(0.0019) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0010(0.0021) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0046(0.0021) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0028(0.0022) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0021) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0070(0.0021) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0021) \n","Epoch 4 - avg_train_loss: 0.0008  avg_val_loss: 0.0021  time: 1175s\n","Epoch 4 - Score: 0.8842\n","Epoch 4 - Save Best Score: 0.8842 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 37m 16s) Loss: 0.0004(0.0004) Grad: 1242.7172  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 30s (remain 17m 37s) Loss: 0.0003(0.0005) Grad: 2437.2998  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 59s (remain 16m 36s) Loss: 0.0000(0.0005) Grad: 51.8053  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 27s (remain 15m 46s) Loss: 0.0000(0.0005) Grad: 334.5741  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 54s (remain 15m 8s) Loss: 0.0000(0.0005) Grad: 31.9137  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 22s (remain 14m 34s) Loss: 0.0000(0.0005) Grad: 2.2713  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 50s (remain 14m 2s) Loss: 0.0056(0.0005) Grad: 15080.9893  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 17s (remain 13m 31s) Loss: 0.0000(0.0005) Grad: 1258.3282  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 45s (remain 13m 1s) Loss: 0.0000(0.0006) Grad: 70.0140  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 13s (remain 12m 31s) Loss: 0.0012(0.0006) Grad: 4331.2197  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 41s (remain 12m 2s) Loss: 0.0003(0.0006) Grad: 2562.2708  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 8s (remain 11m 33s) Loss: 0.0000(0.0006) Grad: 943.2999  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 36s (remain 11m 5s) Loss: 0.0000(0.0006) Grad: 13.3465  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 4s (remain 10m 36s) Loss: 0.0000(0.0006) Grad: 1.9284  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 31s (remain 10m 8s) Loss: 0.0015(0.0005) Grad: 3388.3169  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 59s (remain 9m 39s) Loss: 0.0000(0.0006) Grad: 20.6817  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 27s (remain 9m 11s) Loss: 0.0002(0.0006) Grad: 897.7506  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 55s (remain 8m 43s) Loss: 0.0001(0.0006) Grad: 578.6444  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 22s (remain 8m 15s) Loss: 0.0059(0.0006) Grad: 15351.2568  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 50s (remain 7m 47s) Loss: 0.0000(0.0006) Grad: 5.1602  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 18s (remain 7m 19s) Loss: 0.0000(0.0006) Grad: 37.9926  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 46s (remain 6m 51s) Loss: 0.0044(0.0006) Grad: 7407.8403  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 13s (remain 6m 23s) Loss: 0.0000(0.0006) Grad: 3.4547  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 41s (remain 5m 55s) Loss: 0.0076(0.0006) Grad: 8941.4346  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 9s (remain 5m 27s) Loss: 0.0000(0.0006) Grad: 4.3941  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 36s (remain 4m 59s) Loss: 0.0000(0.0006) Grad: 21.4114  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 4s (remain 4m 31s) Loss: 0.0000(0.0006) Grad: 2.0200  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 32s (remain 4m 3s) Loss: 0.0000(0.0006) Grad: 68.0486  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 0s (remain 3m 35s) Loss: 0.0003(0.0006) Grad: 4156.1851  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 28s (remain 3m 7s) Loss: 0.0001(0.0006) Grad: 737.2458  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 56s (remain 2m 39s) Loss: 0.0002(0.0006) Grad: 4889.8706  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 24s (remain 2m 12s) Loss: 0.0000(0.0006) Grad: 158.9780  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 52s (remain 1m 44s) Loss: 0.0000(0.0006) Grad: 1.9203  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 20s (remain 1m 16s) Loss: 0.0006(0.0006) Grad: 2934.7107  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 48s (remain 0m 48s) Loss: 0.0000(0.0006) Grad: 255.1423  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 16s (remain 0m 20s) Loss: 0.0001(0.0006) Grad: 1935.2981  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 36s (remain 0m 0s) Loss: 0.0004(0.0006) Grad: 1275.2378  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 20s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.0152(0.0023) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 24s) Loss: 0.0032(0.0020) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.0030(0.0021) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0000(0.0021) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0164(0.0021) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.0010(0.0022) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 10s) Loss: 0.0012(0.0024) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0055(0.0024) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0028(0.0024) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.0000(0.0024) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0073(0.0023) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0023) \n","Epoch 5 - avg_train_loss: 0.0006  avg_val_loss: 0.0023  time: 1174s\n","Epoch 5 - Score: 0.8844\n","Epoch 5 - Save Best Score: 0.8844 Model\n","Best thres: 0.5, Score: 0.8827\n","Best thres: 0.4589843749999999, Score: 0.8830\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd1c05a94601472cb6033f4541d7c43d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65440dc3a95443dbd61e7f63881d64c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f6f49857c3b450184118d32c513378d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp049.ipynb","provenance":[{"file_id":"17d5VktGiKlzZFZ4DX0Xh1M3Yr83oZpnY","timestamp":1647514414930}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"74b6705228ab40bab11566271a41c948":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67eb23b36672444eb2b6c22019687159","IPY_MODEL_caca175a31454896b19e5a6b2df59081","IPY_MODEL_29b1ebae772e45208158b638d35581c0"],"layout":"IPY_MODEL_34e3cc79e7ad42499d5038e334aac022"}},"67eb23b36672444eb2b6c22019687159":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d853b3d7d2e45eca55fd8a5489c2b8d","placeholder":"​","style":"IPY_MODEL_3695f404a0b0450787bc69ac912de747","value":"100%"}},"caca175a31454896b19e5a6b2df59081":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_940741bb1e5c491ba9e55c4d108a61c3","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1289b1bf271347e5aaed4301f3f4a8d6","value":42146}},"29b1ebae772e45208158b638d35581c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f98abd91b678427692a8ee40a8b335aa","placeholder":"​","style":"IPY_MODEL_23edcb78ccd34bce89f36117176b40c7","value":" 42146/42146 [00:39&lt;00:00, 1869.83it/s]"}},"34e3cc79e7ad42499d5038e334aac022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d853b3d7d2e45eca55fd8a5489c2b8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3695f404a0b0450787bc69ac912de747":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"940741bb1e5c491ba9e55c4d108a61c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1289b1bf271347e5aaed4301f3f4a8d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f98abd91b678427692a8ee40a8b335aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23edcb78ccd34bce89f36117176b40c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be6ddecf071f4a6096da2b6d83dadc63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_beda28445189496083ab7c435f1e81ee","IPY_MODEL_acfb74900b90481c9f1d18dffb519bd5","IPY_MODEL_eb61b6f56cc146b7acf1c4caaf17ba19"],"layout":"IPY_MODEL_a616621b2d0444d58240de3f5753d932"}},"beda28445189496083ab7c435f1e81ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5c04e076a53457d8e3000f631c2d645","placeholder":"​","style":"IPY_MODEL_fd411a7f08f6424fbd6076b825e4ad0b","value":"100%"}},"acfb74900b90481c9f1d18dffb519bd5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6827db9bb7274e6583d304b0bd39c751","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d192c62a2186491689b24184f7bd6d90","value":143}},"eb61b6f56cc146b7acf1c4caaf17ba19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4722866857a499e8d1b0c12c1af716e","placeholder":"​","style":"IPY_MODEL_764472f1126f44f2b1b40b1cecef4bdd","value":" 143/143 [00:00&lt;00:00, 1958.76it/s]"}},"a616621b2d0444d58240de3f5753d932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c04e076a53457d8e3000f631c2d645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd411a7f08f6424fbd6076b825e4ad0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6827db9bb7274e6583d304b0bd39c751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d192c62a2186491689b24184f7bd6d90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4722866857a499e8d1b0c12c1af716e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"764472f1126f44f2b1b40b1cecef4bdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd1c05a94601472cb6033f4541d7c43d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4afbe69ede7940aeab64181817f549d9","IPY_MODEL_ce48bb2da0de4bed9c325a01c53da228","IPY_MODEL_353853d148674105a87c8d195f45c693"],"layout":"IPY_MODEL_e16bf5b9fb954986a58f5cdfd59af5c5"}},"4afbe69ede7940aeab64181817f549d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bb74e6da10c4e04a207bec929d75b88","placeholder":"​","style":"IPY_MODEL_509f5cc612f74c849bc0b2514ce843c7","value":"Downloading: 100%"}},"ce48bb2da0de4bed9c325a01c53da228":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2780dad4842243d4b26fdcccd8900fd3","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb484c9ff5ff4afdb3d4ea60e4ae13c3","value":1627284589}},"353853d148674105a87c8d195f45c693":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d096d281521b45c0ab80f6918508de10","placeholder":"​","style":"IPY_MODEL_80310b9bc2a44459ac8cec12ddb98d37","value":" 1.52G/1.52G [00:48&lt;00:00, 27.1MB/s]"}},"e16bf5b9fb954986a58f5cdfd59af5c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bb74e6da10c4e04a207bec929d75b88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509f5cc612f74c849bc0b2514ce843c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2780dad4842243d4b26fdcccd8900fd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb484c9ff5ff4afdb3d4ea60e4ae13c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d096d281521b45c0ab80f6918508de10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80310b9bc2a44459ac8cec12ddb98d37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a65440dc3a95443dbd61e7f63881d64c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b58bdc872dcb42bba175b0ebb550706e","IPY_MODEL_cca8a73f15674f59b3a3b5dd3dcbe220","IPY_MODEL_309a70f368a348758bef8ca38fd34683"],"layout":"IPY_MODEL_637e341f5fc448cdb12f8c7ba1a5a201"}},"b58bdc872dcb42bba175b0ebb550706e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f4387689849412d978e7048c1e7e299","placeholder":"​","style":"IPY_MODEL_330bbbb93e254612a1985209d9553830","value":"100%"}},"cca8a73f15674f59b3a3b5dd3dcbe220":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d11edb75ac64475da753a448d89411f1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2529231b962848ccabeb6d4e59578070","value":2}},"309a70f368a348758bef8ca38fd34683":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9f82860dace4bfebc59245059f77b90","placeholder":"​","style":"IPY_MODEL_c957adc61edb44ee809ccd4e5ca7b0fd","value":" 2/2 [00:02&lt;00:00,  1.48it/s]"}},"637e341f5fc448cdb12f8c7ba1a5a201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f4387689849412d978e7048c1e7e299":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"330bbbb93e254612a1985209d9553830":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d11edb75ac64475da753a448d89411f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2529231b962848ccabeb6d4e59578070":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9f82860dace4bfebc59245059f77b90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c957adc61edb44ee809ccd4e5ca7b0fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f6f49857c3b450184118d32c513378d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38d918115c03427e80652b99254ac8fc","IPY_MODEL_6e959ce6674942eaa4e61e96970e9e92","IPY_MODEL_32688fc1ddde4f33895aaf296e09abb3"],"layout":"IPY_MODEL_ac7e5979b0054858aaca6feb5877ea0d"}},"38d918115c03427e80652b99254ac8fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17072c6b6cd04bdf9126810fc57e1392","placeholder":"​","style":"IPY_MODEL_7efee909a13c4b7a938c6f008e6dc0db","value":"100%"}},"6e959ce6674942eaa4e61e96970e9e92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1abf5aa27dd34cae8ac3cbb3c6b7e3a2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5577ed688244fb89769ba4117bfb246","value":2}},"32688fc1ddde4f33895aaf296e09abb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f4467426b3a46e293d6574f78cde9fd","placeholder":"​","style":"IPY_MODEL_11b34e75a35b4317b08e41b10ff7a8e3","value":" 2/2 [00:02&lt;00:00,  1.34it/s]"}},"ac7e5979b0054858aaca6feb5877ea0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17072c6b6cd04bdf9126810fc57e1392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7efee909a13c4b7a938c6f008e6dc0db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1abf5aa27dd34cae8ac3cbb3c6b7e3a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5577ed688244fb89769ba4117bfb246":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f4467426b3a46e293d6574f78cde9fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11b34e75a35b4317b08e41b10ff7a8e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}