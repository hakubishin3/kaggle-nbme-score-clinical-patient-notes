{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adolescent-cause",
   "metadata": {
    "id": "incredible-principle"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-defeat",
   "metadata": {
    "id": "simplified-tract"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-brighton",
   "metadata": {
    "id": "boolean-shame"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "featured-corporation",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625690811,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "needed-consistency"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp021\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "limiting-addiction",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625690812,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "operational-trader"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-v3-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saving-biodiversity",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625690812,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "seasonal-consistency"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-platinum",
   "metadata": {
    "id": "billion-composite"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-angle",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30309,
     "status": "ok",
     "timestamp": 1645625721113,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "desperate-collect",
    "outputId": "c2d67c04-3582-414c-aae4-0c0bf1988f09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupational-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)\n",
    "    \n",
    "    \n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fleet-toronto",
   "metadata": {
    "executionInfo": {
     "elapsed": 8037,
     "status": "ok",
     "timestamp": 1645625729146,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "acute-pregnancy"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-passage",
   "metadata": {
    "id": "generous-raleigh"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opponent-accessory",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625729146,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "controlling-headset"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comfortable-exercise",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625729146,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "UOscbQSt4Cqo"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "textile-masters",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625729146,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "mmZHVaPkh0Qc"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "binary-afternoon",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645625729146,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "IydDnpFyh4PX"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-sampling",
   "metadata": {
    "id": "formed-handbook"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "irish-melbourne",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2454,
     "status": "ok",
     "timestamp": 1645625731592,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "vanilla-register",
    "outputId": "ddf6ea25-10ab-44c7-cc42-450d38c46955"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "executive-pledge",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1645625731593,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "approximate-transmission"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-chase",
   "metadata": {
    "id": "civic-advisory"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "golden-machine",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645625731593,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "irish-nature"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecological-decrease",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645625732029,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "parliamentary-stupid",
    "outputId": "1c2552a9-f7e7-488a-a24f-b7ce7c1b0d9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "instant-passing",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1645625732030,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "imposed-encyclopedia"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electrical-coverage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1645625732030,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "collected-princeton",
    "outputId": "4410d6a9-9663-4648-a272-d6aca0b0db88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-relevance",
   "metadata": {
    "id": "downtown-frame"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "executed-procurement",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645625732030,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "detailed-drive"
   },
   "outputs": [],
   "source": [
    "def get_groupkfold(df, group_name):\n",
    "    groups = df[group_name].unique()\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=CFG.n_fold,\n",
    "        shuffle=True,\n",
    "        random_state=CFG.seed,\n",
    "    )\n",
    "    folds_ids = []\n",
    "    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n",
    "        val_group = groups[val_group_idx]\n",
    "        is_val = df[group_name].isin(val_group)\n",
    "        val_idx = df[is_val].index\n",
    "        df.loc[val_idx, \"fold\"] = int(i_fold)\n",
    "\n",
    "    df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "purple-football",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645625732030,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "other-satisfaction",
    "outputId": "5bcc96ed-688a-4f92-be01-2fe26c29ad9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    2902\n",
       "1    2894\n",
       "2    2813\n",
       "3    2791\n",
       "4    2900\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_groupkfold(train, \"pn_num\")\n",
    "display(train.groupby(\"fold\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-phenomenon",
   "metadata": {
    "id": "senior-wichita"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "infinite-manitoba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 1939,
     "status": "ok",
     "timestamp": 1645625733959,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "thrown-theology",
    "outputId": "02ac3be1-5413-40cc-a03e-ac30f5650d45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-trading",
   "metadata": {
    "id": "varying-tourism"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impressive-parallel",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "executionInfo": {
     "elapsed": 21477,
     "status": "ok",
     "timestamp": 1645625755427,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "white-integral",
    "outputId": "3608a2a1-43f7-40e3-b900-463179dcb231"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9526ac5c042e46cfb54c0a3a4754b628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 323\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "shared-jesus",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645625755764,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "demonstrated-version",
    "outputId": "f5296056-7b0c-44ea-92b8-bd7f3b9a6647"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e88c264d9a1478d9eaf8e682527d5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 28\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "known-phase",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645625755765,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "posted-miami",
    "outputId": "16b6ec3a-dde9-4981-ac74-439a6e3a9339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 354\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tested-siemens",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625755765,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "fossil-supply"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "serial-monkey",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625755765,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "apparent-norfolk"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-disposal",
   "metadata": {
    "id": "motivated-bread"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "natural-culture",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625755766,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "minute-virginia"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "        else:\n",
    "            self.backbone = AutoModel.from_config(self.model_config)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-police",
   "metadata": {
    "id": "seventh-configuration"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "familiar-elevation",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625755766,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "rocky-lexington"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "express-homeless",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625755766,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "honest-programming"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loaded-sunday",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625755766,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "junior-international"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "czech-innocent",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645625755767,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "complicated-testament"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    best_score = -1 * np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-consciousness",
   "metadata": {
    "id": "returning-banner"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "remarkable-christmas",
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1645625756032,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "ongoing-budget"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        #oof_df.to_csv(CFG.output_dir / \"oof_df.csv\", index=False)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    score = scoring(oof_df, th=0.5)\n",
    "    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n",
    "    best_thres = get_best_thres(oof_df)\n",
    "    score = scoring(oof_df, th=best_thres)\n",
    "    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            test_token_probs = inference_fn(test_dataloader, model, device)\n",
    "            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n",
    "            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_token_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coordinated-carnival",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nearby-ultimate"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Epoch: [1][0/2849] Elapsed 0m 1s (remain 56m 33s) Loss: 0.3148(0.3148) Grad: 1160180.8750  LR: 0.000000  \n",
      "Epoch: [1][100/2849] Elapsed 0m 33s (remain 15m 19s) Loss: 0.0273(0.1340) Grad: 11662.2373  LR: 0.000001  \n",
      "Epoch: [1][200/2849] Elapsed 1m 6s (remain 14m 32s) Loss: 0.0139(0.0881) Grad: 25978.1367  LR: 0.000003  \n",
      "Epoch: [1][300/2849] Elapsed 1m 39s (remain 13m 59s) Loss: 0.0069(0.0726) Grad: 25098.0352  LR: 0.000004  \n",
      "Epoch: [1][400/2849] Elapsed 2m 11s (remain 13m 21s) Loss: 0.0173(0.0638) Grad: 15479.5693  LR: 0.000006  \n",
      "Epoch: [1][500/2849] Elapsed 2m 44s (remain 12m 48s) Loss: 0.0348(0.0593) Grad: 13310.6689  LR: 0.000007  \n",
      "Epoch: [1][600/2849] Elapsed 3m 16s (remain 12m 15s) Loss: 0.0451(0.0555) Grad: 18478.4004  LR: 0.000008  \n",
      "Epoch: [1][700/2849] Elapsed 3m 49s (remain 11m 43s) Loss: 0.0244(0.0527) Grad: 7447.2593  LR: 0.000010  \n",
      "Epoch: [1][800/2849] Elapsed 4m 22s (remain 11m 11s) Loss: 0.0193(0.0510) Grad: 7894.9736  LR: 0.000011  \n",
      "Epoch: [1][900/2849] Elapsed 4m 55s (remain 10m 38s) Loss: 0.0485(0.0497) Grad: 12055.6221  LR: 0.000013  \n",
      "Epoch: [1][1000/2849] Elapsed 5m 27s (remain 10m 4s) Loss: 0.0527(0.0488) Grad: 17070.9023  LR: 0.000014  \n",
      "Epoch: [1][1100/2849] Elapsed 5m 59s (remain 9m 31s) Loss: 0.0083(0.0474) Grad: 14375.5635  LR: 0.000015  \n",
      "Epoch: [1][1200/2849] Elapsed 6m 32s (remain 8m 58s) Loss: 0.0810(0.0466) Grad: 29686.2070  LR: 0.000017  \n",
      "Epoch: [1][1300/2849] Elapsed 7m 5s (remain 8m 25s) Loss: 0.0198(0.0460) Grad: 4326.1704  LR: 0.000018  \n",
      "Epoch: [1][1400/2849] Elapsed 7m 37s (remain 7m 52s) Loss: 0.0674(0.0455) Grad: 23592.5195  LR: 0.000020  \n",
      "Epoch: [1][1500/2849] Elapsed 8m 9s (remain 7m 19s) Loss: 0.0301(0.0449) Grad: 6589.7021  LR: 0.000020  \n",
      "Epoch: [1][1600/2849] Elapsed 8m 42s (remain 6m 47s) Loss: 0.0249(0.0447) Grad: 5405.6709  LR: 0.000020  \n",
      "Epoch: [1][1700/2849] Elapsed 9m 15s (remain 6m 14s) Loss: 0.0239(0.0442) Grad: 4433.3491  LR: 0.000020  \n",
      "Epoch: [1][1800/2849] Elapsed 9m 47s (remain 5m 41s) Loss: 0.0414(0.0440) Grad: 12992.5859  LR: 0.000019  \n",
      "Epoch: [1][1900/2849] Elapsed 10m 20s (remain 5m 9s) Loss: 0.0511(0.0436) Grad: 9276.2725  LR: 0.000019  \n",
      "Epoch: [1][2000/2849] Elapsed 10m 53s (remain 4m 36s) Loss: 0.0163(0.0432) Grad: 8924.5908  LR: 0.000019  \n",
      "Epoch: [1][2100/2849] Elapsed 11m 25s (remain 4m 3s) Loss: 0.0242(0.0430) Grad: 3790.3792  LR: 0.000019  \n",
      "Epoch: [1][2200/2849] Elapsed 11m 57s (remain 3m 31s) Loss: 0.0221(0.0429) Grad: 3155.6101  LR: 0.000019  \n",
      "Epoch: [1][2300/2849] Elapsed 12m 30s (remain 2m 58s) Loss: 0.0247(0.0427) Grad: 4752.1323  LR: 0.000019  \n",
      "Epoch: [1][2400/2849] Elapsed 13m 3s (remain 2m 26s) Loss: 0.0390(0.0425) Grad: 8607.4365  LR: 0.000018  \n",
      "Epoch: [1][2500/2849] Elapsed 13m 35s (remain 1m 53s) Loss: 0.0363(0.0423) Grad: 8087.9731  LR: 0.000018  \n",
      "Epoch: [1][2600/2849] Elapsed 14m 8s (remain 1m 20s) Loss: 0.0346(0.0421) Grad: 7131.4941  LR: 0.000018  \n",
      "Epoch: [1][2700/2849] Elapsed 14m 41s (remain 0m 48s) Loss: 0.0525(0.0418) Grad: 18444.6953  LR: 0.000018  \n",
      "Epoch: [1][2800/2849] Elapsed 15m 14s (remain 0m 15s) Loss: 0.0648(0.0416) Grad: 19983.7148  LR: 0.000018  \n",
      "Epoch: [1][2848/2849] Elapsed 15m 30s (remain 0m 0s) Loss: 0.0693(0.0415) Grad: 19638.9883  LR: 0.000018  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 39s) Loss: 0.0330(0.0330) \n",
      "EVAL: [100/726] Elapsed 0m 15s (remain 1m 38s) Loss: 0.0296(0.0359) \n",
      "EVAL: [200/726] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0339(0.0366) \n",
      "EVAL: [300/726] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0141(0.0377) \n",
      "EVAL: [400/726] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0860(0.0397) \n",
      "EVAL: [500/726] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0546(0.0395) \n",
      "EVAL: [600/726] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0203(0.0388) \n",
      "EVAL: [700/726] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0274(0.0369) \n",
      "EVAL: [725/726] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0178(0.0364) \n",
      "Epoch 1 - avg_train_loss: 0.0415  avg_val_loss: 0.0364  time: 1049s\n",
      "Epoch 1 - Score: 0.0000\n",
      "Epoch 1 - Save Best Score: 0.0000 Model\n",
      "Epoch: [2][0/2849] Elapsed 0m 0s (remain 31m 20s) Loss: 0.0774(0.0774) Grad: 26106.6582  LR: 0.000018  \n",
      "Epoch: [2][100/2849] Elapsed 0m 33s (remain 15m 5s) Loss: 0.0167(0.0337) Grad: 6992.4185  LR: 0.000018  \n",
      "Epoch: [2][200/2849] Elapsed 1m 5s (remain 14m 27s) Loss: 0.0813(0.0356) Grad: 31150.6816  LR: 0.000017  \n",
      "Epoch: [2][300/2849] Elapsed 1m 38s (remain 13m 54s) Loss: 0.0264(0.0362) Grad: 5511.4976  LR: 0.000017  \n",
      "Epoch: [2][400/2849] Elapsed 2m 11s (remain 13m 21s) Loss: 0.0302(0.0359) Grad: 9231.6807  LR: 0.000017  \n",
      "Epoch: [2][500/2849] Elapsed 2m 43s (remain 12m 46s) Loss: 0.0256(0.0355) Grad: 5249.2495  LR: 0.000017  \n",
      "Epoch: [2][600/2849] Elapsed 3m 16s (remain 12m 14s) Loss: 0.0233(0.0353) Grad: 5351.2661  LR: 0.000017  \n",
      "Epoch: [2][700/2849] Elapsed 3m 48s (remain 11m 40s) Loss: 0.0335(0.0357) Grad: 6542.1118  LR: 0.000017  \n",
      "Epoch: [2][800/2849] Elapsed 4m 21s (remain 11m 8s) Loss: 0.0354(0.0356) Grad: 5852.3457  LR: 0.000017  \n",
      "Epoch: [2][900/2849] Elapsed 4m 54s (remain 10m 36s) Loss: 0.0225(0.0355) Grad: 8014.2598  LR: 0.000016  \n",
      "Epoch: [2][1000/2849] Elapsed 5m 26s (remain 10m 3s) Loss: 0.0474(0.0359) Grad: 8124.7529  LR: 0.000016  \n",
      "Epoch: [2][1100/2849] Elapsed 5m 59s (remain 9m 30s) Loss: 0.0333(0.0359) Grad: 4937.5605  LR: 0.000016  \n",
      "Epoch: [2][1200/2849] Elapsed 6m 32s (remain 8m 57s) Loss: 0.0544(0.0360) Grad: 12763.5527  LR: 0.000016  \n",
      "Epoch: [2][1300/2849] Elapsed 7m 5s (remain 8m 26s) Loss: 0.0363(0.0361) Grad: 7513.3223  LR: 0.000016  \n",
      "Epoch: [2][1400/2849] Elapsed 7m 38s (remain 7m 53s) Loss: 0.0585(0.0363) Grad: 17961.8789  LR: 0.000016  \n",
      "Epoch: [2][1500/2849] Elapsed 8m 10s (remain 7m 20s) Loss: 0.0196(0.0363) Grad: 3143.0911  LR: 0.000015  \n",
      "Epoch: [2][1600/2849] Elapsed 8m 42s (remain 6m 47s) Loss: 0.0266(0.0362) Grad: 4198.2705  LR: 0.000015  \n",
      "Epoch: [2][1700/2849] Elapsed 9m 15s (remain 6m 14s) Loss: 0.0259(0.0361) Grad: 5715.8716  LR: 0.000015  \n",
      "Epoch: [2][1800/2849] Elapsed 9m 48s (remain 5m 42s) Loss: 0.0323(0.0362) Grad: 5483.9092  LR: 0.000015  \n",
      "Epoch: [2][1900/2849] Elapsed 10m 21s (remain 5m 9s) Loss: 0.0292(0.0362) Grad: 4360.4985  LR: 0.000015  \n",
      "Epoch: [2][2000/2849] Elapsed 10m 54s (remain 4m 37s) Loss: 0.0329(0.0362) Grad: 4299.0708  LR: 0.000015  \n",
      "Epoch: [2][2100/2849] Elapsed 11m 26s (remain 4m 4s) Loss: 0.0263(0.0361) Grad: 4588.0615  LR: 0.000014  \n",
      "Epoch: [2][2200/2849] Elapsed 11m 59s (remain 3m 31s) Loss: 0.0249(0.0360) Grad: 5538.5464  LR: 0.000014  \n",
      "Epoch: [2][2300/2849] Elapsed 12m 32s (remain 2m 59s) Loss: 0.0490(0.0359) Grad: 13588.4893  LR: 0.000014  \n",
      "Epoch: [2][2400/2849] Elapsed 13m 4s (remain 2m 26s) Loss: 0.0586(0.0359) Grad: 7813.0913  LR: 0.000014  \n",
      "Epoch: [2][2500/2849] Elapsed 13m 37s (remain 1m 53s) Loss: 0.0714(0.0358) Grad: 21783.5273  LR: 0.000014  \n",
      "Epoch: [2][2600/2849] Elapsed 14m 10s (remain 1m 21s) Loss: 0.0228(0.0358) Grad: 12630.7949  LR: 0.000014  \n",
      "Epoch: [2][2700/2849] Elapsed 14m 42s (remain 0m 48s) Loss: 0.0463(0.0358) Grad: 10780.1641  LR: 0.000014  \n",
      "Epoch: [2][2800/2849] Elapsed 15m 15s (remain 0m 15s) Loss: 0.0398(0.0358) Grad: 5733.1646  LR: 0.000013  \n",
      "Epoch: [2][2848/2849] Elapsed 15m 30s (remain 0m 0s) Loss: 0.0422(0.0358) Grad: 9749.3125  LR: 0.000013  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 10s) Loss: 0.0307(0.0307) \n",
      "EVAL: [100/726] Elapsed 0m 15s (remain 1m 38s) Loss: 0.0216(0.0343) \n",
      "EVAL: [200/726] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0395(0.0356) \n",
      "EVAL: [300/726] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0100(0.0368) \n",
      "EVAL: [400/726] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0817(0.0391) \n",
      "EVAL: [500/726] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0480(0.0390) \n",
      "EVAL: [600/726] Elapsed 1m 33s (remain 0m 19s) Loss: 0.0228(0.0383) \n",
      "EVAL: [700/726] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0261(0.0365) \n",
      "EVAL: [725/726] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0219(0.0361) \n",
      "Epoch 2 - avg_train_loss: 0.0358  avg_val_loss: 0.0361  time: 1049s\n",
      "Epoch 2 - Score: 0.0000\n",
      "Epoch: [3][0/2849] Elapsed 0m 0s (remain 29m 45s) Loss: 0.0273(0.0273) Grad: 6004.9077  LR: 0.000013  \n",
      "Epoch: [3][100/2849] Elapsed 0m 33s (remain 15m 20s) Loss: 0.0435(0.0338) Grad: 11563.8516  LR: 0.000013  \n",
      "Epoch: [3][200/2849] Elapsed 1m 6s (remain 14m 37s) Loss: 0.0530(0.0344) Grad: 16300.8691  LR: 0.000013  \n",
      "Epoch: [3][300/2849] Elapsed 1m 38s (remain 13m 55s) Loss: 0.0343(0.0350) Grad: 7374.5029  LR: 0.000013  \n",
      "Epoch: [3][400/2849] Elapsed 2m 11s (remain 13m 23s) Loss: 0.0316(0.0345) Grad: 8852.6660  LR: 0.000013  \n",
      "Epoch: [3][500/2849] Elapsed 2m 43s (remain 12m 48s) Loss: 0.0418(0.0351) Grad: 7972.9922  LR: 0.000013  \n",
      "Epoch: [3][600/2849] Elapsed 3m 16s (remain 12m 14s) Loss: 0.0308(0.0348) Grad: 7746.4932  LR: 0.000012  \n",
      "Epoch: [3][700/2849] Elapsed 3m 48s (remain 11m 40s) Loss: 0.0360(0.0346) Grad: 9787.8223  LR: 0.000012  \n",
      "Epoch: [3][800/2849] Elapsed 4m 21s (remain 11m 8s) Loss: 0.0163(0.0347) Grad: 5505.0894  LR: 0.000012  \n",
      "Epoch: [3][900/2849] Elapsed 4m 54s (remain 10m 36s) Loss: 0.0111(0.0345) Grad: 8390.6309  LR: 0.000012  \n",
      "Epoch: [3][1000/2849] Elapsed 5m 27s (remain 10m 4s) Loss: 0.0557(0.0349) Grad: 10520.5000  LR: 0.000012  \n",
      "Epoch: [3][1100/2849] Elapsed 5m 59s (remain 9m 30s) Loss: 0.0196(0.0348) Grad: 5894.4512  LR: 0.000012  \n",
      "Epoch: [3][1200/2849] Elapsed 6m 31s (remain 8m 57s) Loss: 0.0625(0.0348) Grad: 18478.8555  LR: 0.000011  \n",
      "Epoch: [3][1300/2849] Elapsed 7m 4s (remain 8m 24s) Loss: 0.0169(0.0348) Grad: 7342.3052  LR: 0.000011  \n",
      "Epoch: [3][1400/2849] Elapsed 7m 36s (remain 7m 51s) Loss: 0.0244(0.0346) Grad: 5897.9106  LR: 0.000011  \n",
      "Epoch: [3][1500/2849] Elapsed 8m 9s (remain 7m 19s) Loss: 0.0604(0.0348) Grad: 22181.0020  LR: 0.000011  \n",
      "Epoch: [3][1600/2849] Elapsed 8m 41s (remain 6m 46s) Loss: 0.0232(0.0347) Grad: 6616.3398  LR: 0.000011  \n",
      "Epoch: [3][1700/2849] Elapsed 9m 14s (remain 6m 14s) Loss: 0.0279(0.0347) Grad: 8303.9844  LR: 0.000011  \n",
      "Epoch: [3][1800/2849] Elapsed 9m 46s (remain 5m 41s) Loss: 0.0580(0.0346) Grad: 16224.0928  LR: 0.000011  \n",
      "Epoch: [3][1900/2849] Elapsed 10m 19s (remain 5m 8s) Loss: 0.0410(0.0347) Grad: 7301.1343  LR: 0.000010  \n",
      "Epoch: [3][2000/2849] Elapsed 10m 52s (remain 4m 36s) Loss: 0.0273(0.0346) Grad: 6064.1465  LR: 0.000010  \n",
      "Epoch: [3][2100/2849] Elapsed 11m 24s (remain 4m 3s) Loss: 0.0302(0.0345) Grad: 7801.1304  LR: 0.000010  \n",
      "Epoch: [3][2200/2849] Elapsed 11m 57s (remain 3m 31s) Loss: 0.0287(0.0344) Grad: 13483.2500  LR: 0.000010  \n",
      "Epoch: [3][2300/2849] Elapsed 12m 30s (remain 2m 58s) Loss: 0.0565(0.0345) Grad: 17725.3496  LR: 0.000010  \n",
      "Epoch: [3][2400/2849] Elapsed 13m 3s (remain 2m 26s) Loss: 0.0224(0.0345) Grad: 10631.5020  LR: 0.000010  \n",
      "Epoch: [3][2500/2849] Elapsed 13m 35s (remain 1m 53s) Loss: 0.0201(0.0344) Grad: 6278.6948  LR: 0.000009  \n",
      "Epoch: [3][2600/2849] Elapsed 14m 7s (remain 1m 20s) Loss: 0.0241(0.0345) Grad: 6886.1060  LR: 0.000009  \n",
      "Epoch: [3][2700/2849] Elapsed 14m 40s (remain 0m 48s) Loss: 0.0195(0.0344) Grad: 6451.3408  LR: 0.000009  \n",
      "Epoch: [3][2800/2849] Elapsed 15m 13s (remain 0m 15s) Loss: 0.0592(0.0343) Grad: 15966.5967  LR: 0.000009  \n",
      "Epoch: [3][2848/2849] Elapsed 15m 28s (remain 0m 0s) Loss: 0.0638(0.0343) Grad: 27552.2441  LR: 0.000009  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 4m 48s) Loss: 0.0280(0.0280) \n",
      "EVAL: [100/726] Elapsed 0m 15s (remain 1m 38s) Loss: 0.0213(0.0323) \n",
      "EVAL: [200/726] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0362(0.0338) \n",
      "EVAL: [300/726] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0105(0.0350) \n",
      "EVAL: [400/726] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0833(0.0372) \n",
      "EVAL: [500/726] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0465(0.0370) \n",
      "EVAL: [600/726] Elapsed 1m 33s (remain 0m 19s) Loss: 0.0230(0.0364) \n",
      "EVAL: [700/726] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0230(0.0346) \n",
      "EVAL: [725/726] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0201(0.0342) \n",
      "Epoch 3 - avg_train_loss: 0.0343  avg_val_loss: 0.0342  time: 1047s\n",
      "Epoch 3 - Score: 0.0184\n",
      "Epoch 3 - Save Best Score: 0.0184 Model\n",
      "Epoch: [4][0/2849] Elapsed 0m 0s (remain 30m 50s) Loss: 0.0149(0.0149) Grad: 6081.0576  LR: 0.000009  \n",
      "Epoch: [4][100/2849] Elapsed 0m 33s (remain 15m 3s) Loss: 0.0179(0.0326) Grad: 6318.9824  LR: 0.000009  \n",
      "Epoch: [4][200/2849] Elapsed 1m 6s (remain 14m 31s) Loss: 0.0047(0.0332) Grad: 10028.7363  LR: 0.000009  \n",
      "Epoch: [4][300/2849] Elapsed 1m 38s (remain 13m 56s) Loss: 0.0123(0.0335) Grad: 8952.6934  LR: 0.000008  \n",
      "Epoch: [4][400/2849] Elapsed 2m 11s (remain 13m 24s) Loss: 0.0236(0.0331) Grad: 8184.4668  LR: 0.000008  \n",
      "Epoch: [4][500/2849] Elapsed 2m 44s (remain 12m 50s) Loss: 0.0618(0.0334) Grad: 16847.6250  LR: 0.000008  \n",
      "Epoch: [4][600/2849] Elapsed 3m 16s (remain 12m 16s) Loss: 0.0136(0.0332) Grad: 14291.2832  LR: 0.000008  \n",
      "Epoch: [4][700/2849] Elapsed 3m 49s (remain 11m 43s) Loss: 0.0659(0.0333) Grad: 19564.9492  LR: 0.000008  \n",
      "Epoch: [4][800/2849] Elapsed 4m 22s (remain 11m 10s) Loss: 0.0279(0.0334) Grad: 6802.0068  LR: 0.000008  \n",
      "Epoch: [4][900/2849] Elapsed 4m 55s (remain 10m 37s) Loss: 0.0109(0.0333) Grad: 9080.2754  LR: 0.000007  \n",
      "Epoch: [4][1000/2849] Elapsed 5m 27s (remain 10m 4s) Loss: 0.0614(0.0333) Grad: 25580.4004  LR: 0.000007  \n",
      "Epoch: [4][1100/2849] Elapsed 6m 0s (remain 9m 31s) Loss: 0.0316(0.0333) Grad: 11458.8184  LR: 0.000007  \n",
      "Epoch: [4][1200/2849] Elapsed 6m 32s (remain 8m 58s) Loss: 0.0209(0.0332) Grad: 9036.7852  LR: 0.000007  \n",
      "Epoch: [4][1300/2849] Elapsed 7m 4s (remain 8m 25s) Loss: 0.0304(0.0331) Grad: 5803.7969  LR: 0.000007  \n",
      "Epoch: [4][1400/2849] Elapsed 7m 36s (remain 7m 52s) Loss: 0.0404(0.0333) Grad: 8323.4150  LR: 0.000007  \n",
      "Epoch: [4][1500/2849] Elapsed 8m 9s (remain 7m 19s) Loss: 0.0612(0.0333) Grad: 23235.5410  LR: 0.000007  \n",
      "Epoch: [4][1600/2849] Elapsed 8m 41s (remain 6m 46s) Loss: 0.0250(0.0333) Grad: 7098.0015  LR: 0.000006  \n",
      "Epoch: [4][1700/2849] Elapsed 9m 14s (remain 6m 13s) Loss: 0.0277(0.0332) Grad: 6300.1411  LR: 0.000006  \n",
      "Epoch: [4][1800/2849] Elapsed 9m 47s (remain 5m 41s) Loss: 0.0248(0.0333) Grad: 10323.3789  LR: 0.000006  \n",
      "Epoch: [4][1900/2849] Elapsed 10m 19s (remain 5m 9s) Loss: 0.0261(0.0333) Grad: 8990.2822  LR: 0.000006  \n",
      "Epoch: [4][2000/2849] Elapsed 10m 52s (remain 4m 36s) Loss: 0.0605(0.0332) Grad: 22781.9277  LR: 0.000006  \n",
      "Epoch: [4][2100/2849] Elapsed 11m 24s (remain 4m 3s) Loss: 0.0138(0.0332) Grad: 9679.7012  LR: 0.000006  \n",
      "Epoch: [4][2200/2849] Elapsed 11m 57s (remain 3m 31s) Loss: 0.0240(0.0333) Grad: 9933.6758  LR: 0.000005  \n",
      "Epoch: [4][2300/2849] Elapsed 12m 30s (remain 2m 58s) Loss: 0.0895(0.0332) Grad: 39997.5000  LR: 0.000005  \n",
      "Epoch: [4][2400/2849] Elapsed 13m 2s (remain 2m 25s) Loss: 0.0463(0.0332) Grad: 17549.9707  LR: 0.000005  \n",
      "Epoch: [4][2500/2849] Elapsed 13m 34s (remain 1m 53s) Loss: 0.0156(0.0331) Grad: 8941.7861  LR: 0.000005  \n",
      "Epoch: [4][2600/2849] Elapsed 14m 7s (remain 1m 20s) Loss: 0.0458(0.0330) Grad: 21731.3184  LR: 0.000005  \n",
      "Epoch: [4][2700/2849] Elapsed 14m 40s (remain 0m 48s) Loss: 0.0306(0.0330) Grad: 8747.7188  LR: 0.000005  \n",
      "Epoch: [4][2800/2849] Elapsed 15m 12s (remain 0m 15s) Loss: 0.0187(0.0329) Grad: 6312.2285  LR: 0.000005  \n",
      "Epoch: [4][2848/2849] Elapsed 15m 28s (remain 0m 0s) Loss: 0.0184(0.0328) Grad: 12971.9727  LR: 0.000004  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 31s) Loss: 0.0277(0.0277) \n",
      "EVAL: [100/726] Elapsed 0m 15s (remain 1m 38s) Loss: 0.0181(0.0301) \n",
      "EVAL: [200/726] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0329(0.0315) \n",
      "EVAL: [300/726] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0103(0.0330) \n",
      "EVAL: [400/726] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0782(0.0350) \n",
      "EVAL: [500/726] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0416(0.0349) \n",
      "EVAL: [600/726] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0225(0.0344) \n",
      "EVAL: [700/726] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0213(0.0327) \n",
      "EVAL: [725/726] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0225(0.0324) \n",
      "Epoch 4 - avg_train_loss: 0.0328  avg_val_loss: 0.0324  time: 1046s\n",
      "Epoch 4 - Score: 0.0294\n",
      "Epoch 4 - Save Best Score: 0.0294 Model\n",
      "Epoch: [5][0/2849] Elapsed 0m 0s (remain 31m 32s) Loss: 0.0227(0.0227) Grad: 6892.6187  LR: 0.000004  \n",
      "Epoch: [5][100/2849] Elapsed 0m 33s (remain 15m 13s) Loss: 0.0668(0.0321) Grad: 29968.5078  LR: 0.000004  \n",
      "Epoch: [5][200/2849] Elapsed 1m 5s (remain 14m 25s) Loss: 0.0243(0.0320) Grad: 9291.9785  LR: 0.000004  \n",
      "Epoch: [5][300/2849] Elapsed 1m 38s (remain 13m 53s) Loss: 0.0286(0.0315) Grad: 8099.5122  LR: 0.000004  \n",
      "Epoch: [5][400/2849] Elapsed 2m 10s (remain 13m 19s) Loss: 0.0756(0.0316) Grad: 42572.4609  LR: 0.000004  \n",
      "Epoch: [5][500/2849] Elapsed 2m 43s (remain 12m 46s) Loss: 0.0335(0.0319) Grad: 6892.6396  LR: 0.000004  \n",
      "Epoch: [5][600/2849] Elapsed 3m 16s (remain 12m 14s) Loss: 0.0221(0.0316) Grad: 9329.5029  LR: 0.000004  \n",
      "Epoch: [5][700/2849] Elapsed 3m 48s (remain 11m 40s) Loss: 0.0419(0.0318) Grad: 12017.0732  LR: 0.000003  \n",
      "Epoch: [5][800/2849] Elapsed 4m 21s (remain 11m 8s) Loss: 0.0242(0.0320) Grad: 12303.9375  LR: 0.000003  \n",
      "Epoch: [5][900/2849] Elapsed 4m 53s (remain 10m 34s) Loss: 0.0242(0.0319) Grad: 13985.5947  LR: 0.000003  \n",
      "Epoch: [5][1000/2849] Elapsed 5m 25s (remain 10m 1s) Loss: 0.0226(0.0319) Grad: 14099.4971  LR: 0.000003  \n",
      "Epoch: [5][1100/2849] Elapsed 5m 57s (remain 9m 28s) Loss: 0.0747(0.0321) Grad: 24437.2207  LR: 0.000003  \n",
      "Epoch: [5][1200/2849] Elapsed 6m 30s (remain 8m 55s) Loss: 0.0333(0.0319) Grad: 14532.1982  LR: 0.000003  \n",
      "Epoch: [5][1300/2849] Elapsed 7m 3s (remain 8m 23s) Loss: 0.0301(0.0317) Grad: 14011.8213  LR: 0.000002  \n",
      "Epoch: [5][1400/2849] Elapsed 7m 35s (remain 7m 51s) Loss: 0.0420(0.0318) Grad: 15823.5215  LR: 0.000002  \n",
      "Epoch: [5][1500/2849] Elapsed 8m 8s (remain 7m 18s) Loss: 0.0296(0.0319) Grad: 6722.8652  LR: 0.000002  \n",
      "Epoch: [5][1600/2849] Elapsed 8m 40s (remain 6m 46s) Loss: 0.0273(0.0318) Grad: 8695.9521  LR: 0.000002  \n",
      "Epoch: [5][1700/2849] Elapsed 9m 14s (remain 6m 13s) Loss: 0.0270(0.0320) Grad: 13738.0137  LR: 0.000002  \n",
      "Epoch: [5][1800/2849] Elapsed 9m 46s (remain 5m 41s) Loss: 0.0277(0.0318) Grad: 19604.9863  LR: 0.000002  \n",
      "Epoch: [5][1900/2849] Elapsed 10m 19s (remain 5m 9s) Loss: 0.0517(0.0318) Grad: 23513.6367  LR: 0.000001  \n",
      "Epoch: [5][2000/2849] Elapsed 10m 52s (remain 4m 36s) Loss: 0.0288(0.0317) Grad: 11786.2910  LR: 0.000001  \n",
      "Epoch: [5][2100/2849] Elapsed 11m 24s (remain 4m 3s) Loss: 0.1047(0.0317) Grad: 54338.5547  LR: 0.000001  \n",
      "Epoch: [5][2200/2849] Elapsed 11m 57s (remain 3m 31s) Loss: 0.0385(0.0317) Grad: 16274.9941  LR: 0.000001  \n",
      "Epoch: [5][2300/2849] Elapsed 12m 30s (remain 2m 58s) Loss: 0.0283(0.0318) Grad: 13846.4277  LR: 0.000001  \n",
      "Epoch: [5][2400/2849] Elapsed 13m 2s (remain 2m 26s) Loss: 0.0390(0.0318) Grad: 19765.3984  LR: 0.000001  \n",
      "Epoch: [5][2500/2849] Elapsed 13m 35s (remain 1m 53s) Loss: 0.0289(0.0317) Grad: 13532.6865  LR: 0.000001  \n",
      "Epoch: [5][2600/2849] Elapsed 14m 8s (remain 1m 20s) Loss: 0.0616(0.0317) Grad: 27058.2148  LR: 0.000000  \n",
      "Epoch: [5][2700/2849] Elapsed 14m 41s (remain 0m 48s) Loss: 0.0125(0.0317) Grad: 6926.7373  LR: 0.000000  \n",
      "Epoch: [5][2800/2849] Elapsed 15m 13s (remain 0m 15s) Loss: 0.0584(0.0317) Grad: 25292.5938  LR: 0.000000  \n",
      "Epoch: [5][2848/2849] Elapsed 15m 29s (remain 0m 0s) Loss: 0.0208(0.0317) Grad: 9182.7617  LR: 0.000000  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 4m 52s) Loss: 0.0284(0.0284) \n",
      "EVAL: [100/726] Elapsed 0m 15s (remain 1m 38s) Loss: 0.0149(0.0299) \n",
      "EVAL: [200/726] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0349(0.0315) \n",
      "EVAL: [300/726] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0096(0.0330) \n",
      "EVAL: [400/726] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0788(0.0351) \n",
      "EVAL: [500/726] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0422(0.0350) \n",
      "EVAL: [600/726] Elapsed 1m 33s (remain 0m 19s) Loss: 0.0226(0.0345) \n",
      "EVAL: [700/726] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0204(0.0328) \n",
      "EVAL: [725/726] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0247(0.0325) \n",
      "Epoch 5 - avg_train_loss: 0.0317  avg_val_loss: 0.0325  time: 1047s\n",
      "Epoch 5 - Score: 0.0463\n",
      "Epoch 5 - Save Best Score: 0.0463 Model\n",
      "========== fold: 1 training ==========\n",
      "Epoch: [1][0/2851] Elapsed 0m 0s (remain 30m 25s) Loss: 0.2701(0.2701) Grad: 929745.5000  LR: 0.000000  \n",
      "Epoch: [1][100/2851] Elapsed 0m 33s (remain 15m 2s) Loss: 0.0336(0.1120) Grad: 14125.1885  LR: 0.000001  \n",
      "Epoch: [1][200/2851] Elapsed 1m 5s (remain 14m 28s) Loss: 0.0206(0.0764) Grad: 11205.1934  LR: 0.000003  \n",
      "Epoch: [1][300/2851] Elapsed 1m 38s (remain 13m 52s) Loss: 0.0396(0.0645) Grad: 12065.7578  LR: 0.000004  \n",
      "Epoch: [1][400/2851] Elapsed 2m 10s (remain 13m 17s) Loss: 0.0754(0.0583) Grad: 37605.0625  LR: 0.000006  \n",
      "Epoch: [1][500/2851] Elapsed 2m 43s (remain 12m 46s) Loss: 0.0381(0.0549) Grad: 11914.1543  LR: 0.000007  \n",
      "Epoch: [1][600/2851] Elapsed 3m 15s (remain 12m 12s) Loss: 0.0424(0.0522) Grad: 14671.0430  LR: 0.000008  \n",
      "Epoch: [1][700/2851] Elapsed 3m 47s (remain 11m 37s) Loss: 0.0501(0.0503) Grad: 15087.4199  LR: 0.000010  \n",
      "Epoch: [1][800/2851] Elapsed 4m 19s (remain 11m 5s) Loss: 0.0751(0.0485) Grad: 35638.7734  LR: 0.000011  \n",
      "Epoch: [1][900/2851] Elapsed 4m 52s (remain 10m 33s) Loss: 0.0325(0.0476) Grad: 34614.3438  LR: 0.000013  \n",
      "Epoch: [1][1000/2851] Elapsed 5m 25s (remain 10m 1s) Loss: 0.0623(0.0466) Grad: 24623.5742  LR: 0.000014  \n",
      "Epoch: [1][1100/2851] Elapsed 5m 57s (remain 9m 28s) Loss: 0.0727(0.0458) Grad: 28546.2715  LR: 0.000015  \n",
      "Epoch: [1][1200/2851] Elapsed 6m 30s (remain 8m 56s) Loss: 0.0311(0.0453) Grad: 9279.6172  LR: 0.000017  \n",
      "Epoch: [1][1300/2851] Elapsed 7m 2s (remain 8m 23s) Loss: 0.0256(0.0446) Grad: 17018.4316  LR: 0.000018  \n",
      "Epoch: [1][1400/2851] Elapsed 7m 35s (remain 7m 51s) Loss: 0.0297(0.0442) Grad: 5251.9624  LR: 0.000020  \n",
      "Epoch: [1][1500/2851] Elapsed 8m 8s (remain 7m 19s) Loss: 0.0107(0.0438) Grad: 13367.8555  LR: 0.000020  \n",
      "Epoch: [1][1600/2851] Elapsed 8m 41s (remain 6m 46s) Loss: 0.0113(0.0434) Grad: 7235.6177  LR: 0.000020  \n",
      "Epoch: [1][1700/2851] Elapsed 9m 14s (remain 6m 14s) Loss: 0.0472(0.0430) Grad: 13723.4990  LR: 0.000020  \n",
      "Epoch: [1][1800/2851] Elapsed 9m 46s (remain 5m 42s) Loss: 0.0187(0.0428) Grad: 16709.1484  LR: 0.000019  \n",
      "Epoch: [1][1900/2851] Elapsed 10m 19s (remain 5m 9s) Loss: 0.0212(0.0425) Grad: 11515.1875  LR: 0.000019  \n",
      "Epoch: [1][2000/2851] Elapsed 10m 52s (remain 4m 37s) Loss: 0.0442(0.0420) Grad: 6766.5703  LR: 0.000019  \n",
      "Epoch: [1][2100/2851] Elapsed 11m 25s (remain 4m 4s) Loss: 0.0260(0.0417) Grad: 5703.8213  LR: 0.000019  \n",
      "Epoch: [1][2200/2851] Elapsed 11m 57s (remain 3m 31s) Loss: 0.0280(0.0415) Grad: 4590.6421  LR: 0.000019  \n",
      "Epoch: [1][2300/2851] Elapsed 12m 29s (remain 2m 59s) Loss: 0.0340(0.0412) Grad: 6642.1953  LR: 0.000019  \n",
      "Epoch: [1][2400/2851] Elapsed 13m 1s (remain 2m 26s) Loss: 0.0231(0.0411) Grad: 4139.4014  LR: 0.000018  \n",
      "Epoch: [1][2500/2851] Elapsed 13m 34s (remain 1m 54s) Loss: 0.0342(0.0410) Grad: 8697.9727  LR: 0.000018  \n",
      "Epoch: [1][2600/2851] Elapsed 14m 7s (remain 1m 21s) Loss: 0.0198(0.0408) Grad: 11917.0537  LR: 0.000018  \n",
      "Epoch: [1][2700/2851] Elapsed 14m 40s (remain 0m 48s) Loss: 0.0280(0.0408) Grad: 30344.2480  LR: 0.000018  \n",
      "Epoch: [1][2800/2851] Elapsed 15m 13s (remain 0m 16s) Loss: 0.0266(0.0407) Grad: 14236.2178  LR: 0.000018  \n",
      "Epoch: [1][2850/2851] Elapsed 15m 29s (remain 0m 0s) Loss: 0.0324(0.0406) Grad: 5093.3164  LR: 0.000018  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 43s) Loss: 0.0278(0.0278) \n",
      "EVAL: [100/724] Elapsed 0m 16s (remain 1m 38s) Loss: 0.0181(0.0353) \n",
      "EVAL: [200/724] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0138(0.0351) \n",
      "EVAL: [300/724] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0235(0.0357) \n",
      "EVAL: [400/724] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0075(0.0364) \n",
      "EVAL: [500/724] Elapsed 1m 18s (remain 0m 34s) Loss: 0.0376(0.0361) \n",
      "EVAL: [600/724] Elapsed 1m 33s (remain 0m 19s) Loss: 0.0313(0.0363) \n",
      "EVAL: [700/724] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0098(0.0354) \n",
      "EVAL: [723/724] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0306(0.0352) \n",
      "Epoch 1 - avg_train_loss: 0.0406  avg_val_loss: 0.0352  time: 1048s\n",
      "Epoch 1 - Score: 0.0000\n",
      "Epoch 1 - Save Best Score: 0.0000 Model\n",
      "Epoch: [2][0/2851] Elapsed 0m 0s (remain 29m 49s) Loss: 0.0296(0.0296) Grad: 5580.8262  LR: 0.000018  \n",
      "Epoch: [2][100/2851] Elapsed 0m 33s (remain 15m 5s) Loss: 0.0122(0.0341) Grad: 8191.5854  LR: 0.000018  \n",
      "Epoch: [2][200/2851] Elapsed 1m 6s (remain 14m 36s) Loss: 0.0306(0.0355) Grad: 4946.8359  LR: 0.000017  \n",
      "Epoch: [2][300/2851] Elapsed 1m 39s (remain 14m 5s) Loss: 0.0473(0.0353) Grad: 17229.5742  LR: 0.000017  \n",
      "Epoch: [2][400/2851] Elapsed 2m 13s (remain 13m 33s) Loss: 0.0776(0.0362) Grad: 28747.7852  LR: 0.000017  \n",
      "Epoch: [2][500/2851] Elapsed 2m 45s (remain 12m 56s) Loss: 0.0112(0.0364) Grad: 3944.4336  LR: 0.000017  \n",
      "Epoch: [2][600/2851] Elapsed 3m 18s (remain 12m 21s) Loss: 0.0525(0.0365) Grad: 17141.4863  LR: 0.000017  \n",
      "Epoch: [2][700/2851] Elapsed 3m 50s (remain 11m 48s) Loss: 0.0876(0.0367) Grad: 29728.6582  LR: 0.000017  \n",
      "Epoch: [2][800/2851] Elapsed 4m 24s (remain 11m 17s) Loss: 0.0566(0.0369) Grad: 18184.0684  LR: 0.000017  \n",
      "Epoch: [2][900/2851] Elapsed 4m 57s (remain 10m 43s) Loss: 0.0473(0.0364) Grad: 7658.6533  LR: 0.000016  \n",
      "Epoch: [2][1000/2851] Elapsed 5m 30s (remain 10m 10s) Loss: 0.0423(0.0366) Grad: 6228.8540  LR: 0.000016  \n",
      "Epoch: [2][1100/2851] Elapsed 6m 3s (remain 9m 37s) Loss: 0.0271(0.0366) Grad: 5819.4639  LR: 0.000016  \n",
      "Epoch: [2][1200/2851] Elapsed 6m 36s (remain 9m 4s) Loss: 0.0573(0.0365) Grad: 12778.9531  LR: 0.000016  \n",
      "Epoch: [2][1300/2851] Elapsed 7m 8s (remain 8m 30s) Loss: 0.0308(0.0366) Grad: 4310.4238  LR: 0.000016  \n",
      "Epoch: [2][1400/2851] Elapsed 7m 41s (remain 7m 57s) Loss: 0.0543(0.0366) Grad: 19270.6582  LR: 0.000016  \n",
      "Epoch: [2][1500/2851] Elapsed 8m 14s (remain 7m 25s) Loss: 0.0524(0.0363) Grad: 11394.8467  LR: 0.000015  \n",
      "Epoch: [2][1600/2851] Elapsed 8m 47s (remain 6m 51s) Loss: 0.0358(0.0363) Grad: 5599.0713  LR: 0.000015  \n",
      "Epoch: [2][1700/2851] Elapsed 9m 20s (remain 6m 18s) Loss: 0.0152(0.0363) Grad: 11949.3828  LR: 0.000015  \n",
      "Epoch: [2][1800/2851] Elapsed 9m 52s (remain 5m 45s) Loss: 0.0219(0.0364) Grad: 5733.9507  LR: 0.000015  \n",
      "Epoch: [2][1900/2851] Elapsed 10m 25s (remain 5m 12s) Loss: 0.0466(0.0364) Grad: 14963.9443  LR: 0.000015  \n",
      "Epoch: [2][2000/2851] Elapsed 10m 58s (remain 4m 39s) Loss: 0.0160(0.0362) Grad: 3308.0229  LR: 0.000015  \n",
      "Epoch: [2][2100/2851] Elapsed 11m 31s (remain 4m 6s) Loss: 0.0390(0.0362) Grad: 4881.0620  LR: 0.000015  \n",
      "Epoch: [2][2200/2851] Elapsed 12m 4s (remain 3m 33s) Loss: 0.0058(0.0361) Grad: 7033.2363  LR: 0.000014  \n",
      "Epoch: [2][2300/2851] Elapsed 12m 36s (remain 3m 0s) Loss: 0.0513(0.0362) Grad: 13359.8291  LR: 0.000014  \n",
      "Epoch: [2][2400/2851] Elapsed 13m 9s (remain 2m 27s) Loss: 0.0110(0.0360) Grad: 9522.5654  LR: 0.000014  \n",
      "Epoch: [2][2500/2851] Elapsed 13m 42s (remain 1m 55s) Loss: 0.0259(0.0360) Grad: 7219.4287  LR: 0.000014  \n",
      "Epoch: [2][2600/2851] Elapsed 14m 16s (remain 1m 22s) Loss: 0.0338(0.0361) Grad: 4874.3584  LR: 0.000014  \n",
      "Epoch: [2][2700/2851] Elapsed 14m 49s (remain 0m 49s) Loss: 0.0232(0.0361) Grad: 3790.5913  LR: 0.000014  \n",
      "Epoch: [2][2800/2851] Elapsed 15m 22s (remain 0m 16s) Loss: 0.0174(0.0361) Grad: 9851.0234  LR: 0.000013  \n",
      "Epoch: [2][2850/2851] Elapsed 15m 38s (remain 0m 0s) Loss: 0.0566(0.0361) Grad: 17900.7715  LR: 0.000013  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 6m 17s) Loss: 0.0258(0.0258) \n",
      "EVAL: [100/724] Elapsed 0m 16s (remain 1m 39s) Loss: 0.0177(0.0348) \n",
      "EVAL: [200/724] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0116(0.0349) \n",
      "EVAL: [300/724] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0230(0.0355) \n",
      "EVAL: [400/724] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0061(0.0365) \n",
      "EVAL: [500/724] Elapsed 1m 18s (remain 0m 34s) Loss: 0.0355(0.0361) \n",
      "EVAL: [600/724] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0306(0.0364) \n",
      "EVAL: [700/724] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0071(0.0354) \n",
      "EVAL: [723/724] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0318(0.0352) \n",
      "Epoch 2 - avg_train_loss: 0.0361  avg_val_loss: 0.0352  time: 1057s\n",
      "Epoch 2 - Score: 0.0000\n",
      "Epoch: [3][0/2851] Elapsed 0m 0s (remain 30m 29s) Loss: 0.0402(0.0402) Grad: 13265.5586  LR: 0.000013  \n",
      "Epoch: [3][100/2851] Elapsed 0m 34s (remain 15m 31s) Loss: 0.0229(0.0327) Grad: 12251.9219  LR: 0.000013  \n",
      "Epoch: [3][200/2851] Elapsed 1m 6s (remain 14m 40s) Loss: 0.0330(0.0341) Grad: 5412.3613  LR: 0.000013  \n",
      "Epoch: [3][300/2851] Elapsed 1m 41s (remain 14m 15s) Loss: 0.0193(0.0348) Grad: 6579.9023  LR: 0.000013  \n",
      "Epoch: [3][400/2851] Elapsed 2m 14s (remain 13m 40s) Loss: 0.0354(0.0342) Grad: 6586.5684  LR: 0.000013  \n",
      "Epoch: [3][500/2851] Elapsed 2m 46s (remain 13m 2s) Loss: 0.0197(0.0336) Grad: 7248.3638  LR: 0.000013  \n",
      "Epoch: [3][600/2851] Elapsed 3m 19s (remain 12m 25s) Loss: 0.0410(0.0344) Grad: 10448.0654  LR: 0.000012  \n",
      "Epoch: [3][700/2851] Elapsed 3m 52s (remain 11m 54s) Loss: 0.0378(0.0341) Grad: 7454.9985  LR: 0.000012  \n",
      "Epoch: [3][800/2851] Elapsed 4m 25s (remain 11m 20s) Loss: 0.0109(0.0341) Grad: 12884.4746  LR: 0.000012  \n",
      "Epoch: [3][900/2851] Elapsed 4m 58s (remain 10m 46s) Loss: 0.0379(0.0342) Grad: 5869.1030  LR: 0.000012  \n",
      "Epoch: [3][1000/2851] Elapsed 5m 31s (remain 10m 12s) Loss: 0.0334(0.0341) Grad: 11908.1904  LR: 0.000012  \n",
      "Epoch: [3][1100/2851] Elapsed 6m 5s (remain 9m 40s) Loss: 0.0239(0.0339) Grad: 5384.5566  LR: 0.000012  \n",
      "Epoch: [3][1200/2851] Elapsed 6m 37s (remain 9m 6s) Loss: 0.0199(0.0343) Grad: 20035.8730  LR: 0.000011  \n",
      "Epoch: [3][1300/2851] Elapsed 7m 12s (remain 8m 34s) Loss: 0.0286(0.0344) Grad: 8061.3438  LR: 0.000011  \n",
      "Epoch: [3][1400/2851] Elapsed 7m 46s (remain 8m 2s) Loss: 0.0064(0.0344) Grad: 10442.6055  LR: 0.000011  \n",
      "Epoch: [3][1500/2851] Elapsed 8m 18s (remain 7m 28s) Loss: 0.0129(0.0344) Grad: 8239.4072  LR: 0.000011  \n",
      "Epoch: [3][1600/2851] Elapsed 8m 51s (remain 6m 54s) Loss: 0.0571(0.0344) Grad: 15918.8906  LR: 0.000011  \n",
      "Epoch: [3][1700/2851] Elapsed 9m 23s (remain 6m 21s) Loss: 0.0172(0.0344) Grad: 9103.3857  LR: 0.000011  \n",
      "Epoch: [3][1800/2851] Elapsed 9m 57s (remain 5m 48s) Loss: 0.0434(0.0344) Grad: 8854.6787  LR: 0.000011  \n",
      "Epoch: [3][1900/2851] Elapsed 10m 29s (remain 5m 14s) Loss: 0.1152(0.0345) Grad: 52060.0000  LR: 0.000010  \n",
      "Epoch: [3][2000/2851] Elapsed 11m 2s (remain 4m 41s) Loss: 0.0145(0.0345) Grad: 15022.7783  LR: 0.000010  \n",
      "Epoch: [3][2100/2851] Elapsed 11m 35s (remain 4m 8s) Loss: 0.0475(0.0344) Grad: 12672.6133  LR: 0.000010  \n",
      "Epoch: [3][2200/2851] Elapsed 12m 8s (remain 3m 35s) Loss: 0.0609(0.0344) Grad: 20950.3887  LR: 0.000010  \n",
      "Epoch: [3][2300/2851] Elapsed 12m 40s (remain 3m 1s) Loss: 0.0333(0.0345) Grad: 7537.0225  LR: 0.000010  \n",
      "Epoch: [3][2400/2851] Elapsed 13m 13s (remain 2m 28s) Loss: 0.0142(0.0343) Grad: 9027.2959  LR: 0.000010  \n",
      "Epoch: [3][2500/2851] Elapsed 13m 46s (remain 1m 55s) Loss: 0.0505(0.0345) Grad: 12109.7637  LR: 0.000009  \n",
      "Epoch: [3][2600/2851] Elapsed 14m 19s (remain 1m 22s) Loss: 0.0144(0.0344) Grad: 9886.1211  LR: 0.000009  \n",
      "Epoch: [3][2700/2851] Elapsed 14m 52s (remain 0m 49s) Loss: 0.0299(0.0345) Grad: 7221.1450  LR: 0.000009  \n",
      "Epoch: [3][2800/2851] Elapsed 15m 25s (remain 0m 16s) Loss: 0.0105(0.0344) Grad: 11369.1641  LR: 0.000009  \n",
      "Epoch: [3][2850/2851] Elapsed 15m 42s (remain 0m 0s) Loss: 0.0379(0.0345) Grad: 12314.2393  LR: 0.000009  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 36s) Loss: 0.0243(0.0243) \n",
      "EVAL: [100/724] Elapsed 0m 15s (remain 1m 38s) Loss: 0.0155(0.0339) \n",
      "EVAL: [200/724] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0112(0.0335) \n",
      "EVAL: [300/724] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0206(0.0340) \n",
      "EVAL: [400/724] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0063(0.0350) \n",
      "EVAL: [500/724] Elapsed 1m 18s (remain 0m 34s) Loss: 0.0374(0.0347) \n",
      "EVAL: [600/724] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0321(0.0349) \n",
      "EVAL: [700/724] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0064(0.0340) \n",
      "EVAL: [723/724] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0316(0.0339) \n",
      "Epoch 3 - avg_train_loss: 0.0345  avg_val_loss: 0.0339  time: 1060s\n",
      "Epoch 3 - Score: 0.0122\n",
      "Epoch 3 - Save Best Score: 0.0122 Model\n",
      "Epoch: [4][0/2851] Elapsed 0m 0s (remain 33m 58s) Loss: 0.0325(0.0325) Grad: 6185.4849  LR: 0.000009  \n",
      "Epoch: [4][100/2851] Elapsed 0m 33s (remain 15m 18s) Loss: 0.0322(0.0350) Grad: 6548.7275  LR: 0.000009  \n",
      "Epoch: [4][200/2851] Elapsed 1m 6s (remain 14m 32s) Loss: 0.0075(0.0338) Grad: 12190.0850  LR: 0.000009  \n",
      "Epoch: [4][300/2851] Elapsed 1m 38s (remain 13m 56s) Loss: 0.0725(0.0336) Grad: 30345.8184  LR: 0.000008  \n",
      "Epoch: [4][400/2851] Elapsed 2m 11s (remain 13m 22s) Loss: 0.0253(0.0334) Grad: 8530.0791  LR: 0.000008  \n",
      "Epoch: [4][500/2851] Elapsed 2m 44s (remain 12m 51s) Loss: 0.0272(0.0329) Grad: 8613.0723  LR: 0.000008  \n",
      "Epoch: [4][600/2851] Elapsed 3m 18s (remain 12m 22s) Loss: 0.0403(0.0334) Grad: 17458.4297  LR: 0.000008  \n",
      "Epoch: [4][700/2851] Elapsed 3m 50s (remain 11m 46s) Loss: 0.0212(0.0331) Grad: 9016.4609  LR: 0.000008  \n",
      "Epoch: [4][800/2851] Elapsed 4m 22s (remain 11m 12s) Loss: 0.0475(0.0331) Grad: 10560.3936  LR: 0.000008  \n",
      "Epoch: [4][900/2851] Elapsed 4m 56s (remain 10m 41s) Loss: 0.0510(0.0333) Grad: 12515.6357  LR: 0.000007  \n",
      "Epoch: [4][1000/2851] Elapsed 5m 28s (remain 10m 7s) Loss: 0.0253(0.0329) Grad: 11648.0381  LR: 0.000007  \n",
      "Epoch: [4][1100/2851] Elapsed 6m 1s (remain 9m 34s) Loss: 0.0150(0.0329) Grad: 10834.4209  LR: 0.000007  \n",
      "Epoch: [4][1200/2851] Elapsed 6m 35s (remain 9m 3s) Loss: 0.0113(0.0331) Grad: 20577.6621  LR: 0.000007  \n",
      "Epoch: [4][1300/2851] Elapsed 7m 8s (remain 8m 30s) Loss: 0.0150(0.0333) Grad: 3754.4543  LR: 0.000007  \n",
      "Epoch: [4][1400/2851] Elapsed 7m 42s (remain 7m 58s) Loss: 0.0383(0.0334) Grad: 12031.9531  LR: 0.000007  \n",
      "Epoch: [4][1500/2851] Elapsed 8m 16s (remain 7m 26s) Loss: 0.0232(0.0334) Grad: 14766.2500  LR: 0.000007  \n",
      "Epoch: [4][1600/2851] Elapsed 8m 49s (remain 6m 53s) Loss: 0.0200(0.0334) Grad: 13672.7207  LR: 0.000006  \n",
      "Epoch: [4][1700/2851] Elapsed 9m 22s (remain 6m 20s) Loss: 0.0653(0.0333) Grad: 21134.5840  LR: 0.000006  \n",
      "Epoch: [4][1800/2851] Elapsed 9m 55s (remain 5m 47s) Loss: 0.0282(0.0333) Grad: 6031.5791  LR: 0.000006  \n",
      "Epoch: [4][1900/2851] Elapsed 10m 27s (remain 5m 13s) Loss: 0.0534(0.0333) Grad: 16592.0039  LR: 0.000006  \n",
      "Epoch: [4][2000/2851] Elapsed 10m 59s (remain 4m 40s) Loss: 0.0369(0.0333) Grad: 13625.2500  LR: 0.000006  \n",
      "Epoch: [4][2100/2851] Elapsed 11m 33s (remain 4m 7s) Loss: 0.0558(0.0332) Grad: 23758.8145  LR: 0.000006  \n",
      "Epoch: [4][2200/2851] Elapsed 12m 5s (remain 3m 34s) Loss: 0.0426(0.0332) Grad: 7970.7979  LR: 0.000005  \n",
      "Epoch: [4][2300/2851] Elapsed 12m 38s (remain 3m 1s) Loss: 0.0354(0.0330) Grad: 13030.3262  LR: 0.000005  \n",
      "Epoch: [4][2400/2851] Elapsed 13m 10s (remain 2m 28s) Loss: 0.0227(0.0331) Grad: 7919.5435  LR: 0.000005  \n",
      "Epoch: [4][2500/2851] Elapsed 13m 45s (remain 1m 55s) Loss: 0.0405(0.0331) Grad: 11285.8594  LR: 0.000005  \n",
      "Epoch: [4][2600/2851] Elapsed 14m 17s (remain 1m 22s) Loss: 0.0275(0.0331) Grad: 8314.9248  LR: 0.000005  \n",
      "Epoch: [4][2700/2851] Elapsed 14m 50s (remain 0m 49s) Loss: 0.0228(0.0332) Grad: 13582.8008  LR: 0.000005  \n",
      "Epoch: [4][2800/2851] Elapsed 15m 22s (remain 0m 16s) Loss: 0.0319(0.0332) Grad: 7073.8940  LR: 0.000005  \n",
      "Epoch: [4][2850/2851] Elapsed 15m 38s (remain 0m 0s) Loss: 0.0183(0.0332) Grad: 6292.8486  LR: 0.000004  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 56s) Loss: 0.0230(0.0230) \n",
      "EVAL: [100/724] Elapsed 0m 16s (remain 1m 39s) Loss: 0.0129(0.0331) \n",
      "EVAL: [200/724] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0112(0.0327) \n",
      "EVAL: [300/724] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0199(0.0330) \n",
      "EVAL: [400/724] Elapsed 1m 3s (remain 0m 50s) Loss: 0.0061(0.0340) \n",
      "EVAL: [500/724] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0353(0.0336) \n",
      "EVAL: [600/724] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0310(0.0339) \n",
      "EVAL: [700/724] Elapsed 1m 50s (remain 0m 3s) Loss: 0.0055(0.0330) \n",
      "EVAL: [723/724] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0294(0.0329) \n",
      "Epoch 4 - avg_train_loss: 0.0332  avg_val_loss: 0.0329  time: 1058s\n",
      "Epoch 4 - Score: 0.0148\n",
      "Epoch 4 - Save Best Score: 0.0148 Model\n",
      "Epoch: [5][0/2851] Elapsed 0m 0s (remain 35m 23s) Loss: 0.0206(0.0206) Grad: 7694.1567  LR: 0.000004  \n",
      "Epoch: [5][100/2851] Elapsed 0m 33s (remain 15m 9s) Loss: 0.0224(0.0324) Grad: 12169.3281  LR: 0.000004  \n",
      "Epoch: [5][200/2851] Elapsed 1m 6s (remain 14m 40s) Loss: 0.0062(0.0326) Grad: 11065.0898  LR: 0.000004  \n",
      "Epoch: [5][300/2851] Elapsed 1m 39s (remain 14m 4s) Loss: 0.0483(0.0321) Grad: 23343.4316  LR: 0.000004  \n",
      "Epoch: [5][400/2851] Elapsed 2m 11s (remain 13m 26s) Loss: 0.0246(0.0314) Grad: 8295.2969  LR: 0.000004  \n",
      "Epoch: [5][500/2851] Elapsed 2m 44s (remain 12m 50s) Loss: 0.0332(0.0310) Grad: 7551.0991  LR: 0.000004  \n",
      "Epoch: [5][600/2851] Elapsed 3m 16s (remain 12m 16s) Loss: 0.0228(0.0320) Grad: 27928.1367  LR: 0.000004  \n",
      "Epoch: [5][700/2851] Elapsed 3m 49s (remain 11m 42s) Loss: 0.0343(0.0319) Grad: 14333.2188  LR: 0.000003  \n",
      "Epoch: [5][800/2851] Elapsed 4m 21s (remain 11m 8s) Loss: 0.0115(0.0319) Grad: 10862.7080  LR: 0.000003  \n",
      "Epoch: [5][900/2851] Elapsed 4m 54s (remain 10m 37s) Loss: 0.0319(0.0321) Grad: 17920.5332  LR: 0.000003  \n",
      "Epoch: [5][1000/2851] Elapsed 5m 27s (remain 10m 4s) Loss: 0.0589(0.0319) Grad: 28819.3223  LR: 0.000003  \n",
      "Epoch: [5][1100/2851] Elapsed 5m 59s (remain 9m 31s) Loss: 0.0253(0.0320) Grad: 10235.1836  LR: 0.000003  \n",
      "Epoch: [5][1200/2851] Elapsed 6m 32s (remain 8m 58s) Loss: 0.0353(0.0319) Grad: 17795.5859  LR: 0.000003  \n",
      "Epoch: [5][1300/2851] Elapsed 7m 5s (remain 8m 26s) Loss: 0.0210(0.0319) Grad: 7136.1484  LR: 0.000002  \n",
      "Epoch: [5][1400/2851] Elapsed 7m 37s (remain 7m 53s) Loss: 0.0177(0.0320) Grad: 9570.7344  LR: 0.000002  \n",
      "Epoch: [5][1500/2851] Elapsed 8m 10s (remain 7m 21s) Loss: 0.0329(0.0320) Grad: 10999.5801  LR: 0.000002  \n",
      "Epoch: [5][1600/2851] Elapsed 8m 43s (remain 6m 48s) Loss: 0.0451(0.0320) Grad: 18694.3652  LR: 0.000002  \n",
      "Epoch: [5][1700/2851] Elapsed 9m 16s (remain 6m 15s) Loss: 0.0367(0.0321) Grad: 8897.8945  LR: 0.000002  \n",
      "Epoch: [5][1800/2851] Elapsed 9m 48s (remain 5m 43s) Loss: 0.0312(0.0322) Grad: 11061.8125  LR: 0.000002  \n",
      "Epoch: [5][1900/2851] Elapsed 10m 22s (remain 5m 10s) Loss: 0.0247(0.0320) Grad: 7577.6450  LR: 0.000001  \n",
      "Epoch: [5][2000/2851] Elapsed 10m 56s (remain 4m 38s) Loss: 0.0338(0.0321) Grad: 16203.1475  LR: 0.000001  \n",
      "Epoch: [5][2100/2851] Elapsed 11m 29s (remain 4m 6s) Loss: 0.0284(0.0321) Grad: 10249.9619  LR: 0.000001  \n",
      "Epoch: [5][2200/2851] Elapsed 12m 1s (remain 3m 33s) Loss: 0.0241(0.0322) Grad: 9350.3271  LR: 0.000001  \n",
      "Epoch: [5][2300/2851] Elapsed 12m 35s (remain 3m 0s) Loss: 0.0319(0.0321) Grad: 9196.9961  LR: 0.000001  \n",
      "Epoch: [5][2400/2851] Elapsed 13m 10s (remain 2m 28s) Loss: 0.0317(0.0321) Grad: 10358.7637  LR: 0.000001  \n",
      "Epoch: [5][2500/2851] Elapsed 13m 42s (remain 1m 55s) Loss: 0.0261(0.0320) Grad: 10975.8535  LR: 0.000001  \n",
      "Epoch: [5][2600/2851] Elapsed 14m 15s (remain 1m 22s) Loss: 0.0524(0.0321) Grad: 23114.3047  LR: 0.000000  \n",
      "Epoch: [5][2700/2851] Elapsed 14m 47s (remain 0m 49s) Loss: 0.0638(0.0322) Grad: 38418.3008  LR: 0.000000  \n",
      "Epoch: [5][2800/2851] Elapsed 15m 20s (remain 0m 16s) Loss: 0.0262(0.0321) Grad: 15619.9873  LR: 0.000000  \n",
      "Epoch: [5][2850/2851] Elapsed 15m 36s (remain 0m 0s) Loss: 0.0151(0.0321) Grad: 9050.9619  LR: 0.000000  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 52s) Loss: 0.0217(0.0217) \n",
      "EVAL: [100/724] Elapsed 0m 16s (remain 1m 38s) Loss: 0.0141(0.0323) \n",
      "EVAL: [200/724] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0118(0.0320) \n",
      "EVAL: [300/724] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0195(0.0326) \n",
      "EVAL: [400/724] Elapsed 1m 2s (remain 0m 50s) Loss: 0.0075(0.0335) \n",
      "EVAL: [500/724] Elapsed 1m 18s (remain 0m 34s) Loss: 0.0329(0.0331) \n",
      "EVAL: [600/724] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0319(0.0333) \n",
      "EVAL: [700/724] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0061(0.0325) \n",
      "EVAL: [723/724] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0298(0.0324) \n",
      "Epoch 5 - avg_train_loss: 0.0321  avg_val_loss: 0.0324  time: 1055s\n",
      "Epoch 5 - Score: 0.0313\n",
      "Epoch 5 - Save Best Score: 0.0313 Model\n",
      "========== fold: 2 training ==========\n",
      "Epoch: [1][0/2871] Elapsed 0m 0s (remain 32m 30s) Loss: 0.3546(0.3546) Grad: 1259541.6250  LR: 0.000000  \n",
      "Epoch: [1][100/2871] Elapsed 0m 34s (remain 15m 37s) Loss: 0.0387(0.1414) Grad: 21839.0156  LR: 0.000001  \n",
      "Epoch: [1][200/2871] Elapsed 1m 7s (remain 14m 53s) Loss: 0.0798(0.0899) Grad: 44112.9258  LR: 0.000003  \n",
      "Epoch: [1][300/2871] Elapsed 1m 40s (remain 14m 21s) Loss: 0.0285(0.0739) Grad: 26519.5938  LR: 0.000004  \n",
      "Epoch: [1][400/2871] Elapsed 2m 13s (remain 13m 43s) Loss: 0.0466(0.0648) Grad: 11228.6455  LR: 0.000006  \n",
      "Epoch: [1][500/2871] Elapsed 2m 46s (remain 13m 6s) Loss: 0.0165(0.0591) Grad: 15187.7002  LR: 0.000007  \n",
      "Epoch: [1][600/2871] Elapsed 3m 18s (remain 12m 29s) Loss: 0.0298(0.0562) Grad: 34963.3281  LR: 0.000008  \n",
      "Epoch: [1][700/2871] Elapsed 3m 51s (remain 11m 57s) Loss: 0.0270(0.0535) Grad: 7590.5771  LR: 0.000010  \n",
      "Epoch: [1][800/2871] Elapsed 4m 24s (remain 11m 23s) Loss: 0.0263(0.0518) Grad: 7301.7197  LR: 0.000011  \n",
      "Epoch: [1][900/2871] Elapsed 4m 56s (remain 10m 49s) Loss: 0.0297(0.0504) Grad: 13570.6084  LR: 0.000013  \n",
      "Epoch: [1][1000/2871] Elapsed 5m 29s (remain 10m 15s) Loss: 0.0652(0.0494) Grad: 21194.7637  LR: 0.000014  \n",
      "Epoch: [1][1100/2871] Elapsed 6m 3s (remain 9m 44s) Loss: 0.0743(0.0483) Grad: 27790.9863  LR: 0.000015  \n",
      "Epoch: [1][1200/2871] Elapsed 6m 36s (remain 9m 11s) Loss: 0.0265(0.0473) Grad: 6947.0381  LR: 0.000017  \n",
      "Epoch: [1][1300/2871] Elapsed 7m 9s (remain 8m 37s) Loss: 0.0316(0.0466) Grad: 11079.1123  LR: 0.000018  \n",
      "Epoch: [1][1400/2871] Elapsed 7m 41s (remain 8m 4s) Loss: 0.0484(0.0457) Grad: 18403.5059  LR: 0.000020  \n",
      "Epoch: [1][1500/2871] Elapsed 8m 14s (remain 7m 31s) Loss: 0.0240(0.0451) Grad: 4721.8540  LR: 0.000020  \n",
      "Epoch: [1][1600/2871] Elapsed 8m 47s (remain 6m 58s) Loss: 0.0396(0.0449) Grad: 11902.4053  LR: 0.000020  \n",
      "Epoch: [1][1700/2871] Elapsed 9m 20s (remain 6m 25s) Loss: 0.0132(0.0443) Grad: 14472.0449  LR: 0.000020  \n",
      "Epoch: [1][1800/2871] Elapsed 9m 52s (remain 5m 52s) Loss: 0.0221(0.0440) Grad: 3888.7427  LR: 0.000019  \n",
      "Epoch: [1][1900/2871] Elapsed 10m 25s (remain 5m 19s) Loss: 0.0276(0.0437) Grad: 4705.1797  LR: 0.000019  \n",
      "Epoch: [1][2000/2871] Elapsed 10m 58s (remain 4m 46s) Loss: 0.0091(0.0433) Grad: 3754.6714  LR: 0.000019  \n",
      "Epoch: [1][2100/2871] Elapsed 11m 32s (remain 4m 13s) Loss: 0.0147(0.0430) Grad: 4619.8413  LR: 0.000019  \n",
      "Epoch: [1][2200/2871] Elapsed 12m 5s (remain 3m 40s) Loss: 0.0256(0.0429) Grad: 6662.7466  LR: 0.000019  \n",
      "Epoch: [1][2300/2871] Elapsed 12m 38s (remain 3m 7s) Loss: 0.0338(0.0426) Grad: 7827.9019  LR: 0.000019  \n",
      "Epoch: [1][2400/2871] Elapsed 13m 11s (remain 2m 34s) Loss: 0.0417(0.0424) Grad: 8879.8506  LR: 0.000019  \n",
      "Epoch: [1][2500/2871] Elapsed 13m 44s (remain 2m 1s) Loss: 0.0260(0.0422) Grad: 13303.8740  LR: 0.000018  \n",
      "Epoch: [1][2600/2871] Elapsed 14m 16s (remain 1m 28s) Loss: 0.0230(0.0421) Grad: 7924.6460  LR: 0.000018  \n",
      "Epoch: [1][2700/2871] Elapsed 14m 50s (remain 0m 56s) Loss: 0.0512(0.0418) Grad: 15447.3516  LR: 0.000018  \n",
      "Epoch: [1][2800/2871] Elapsed 15m 24s (remain 0m 23s) Loss: 0.0333(0.0417) Grad: 5520.0210  LR: 0.000018  \n",
      "Epoch: [1][2870/2871] Elapsed 15m 47s (remain 0m 0s) Loss: 0.0234(0.0416) Grad: 6518.9712  LR: 0.000018  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 6m 0s) Loss: 0.0459(0.0459) \n",
      "EVAL: [100/704] Elapsed 0m 16s (remain 1m 36s) Loss: 0.0413(0.0340) \n",
      "EVAL: [200/704] Elapsed 0m 31s (remain 1m 19s) Loss: 0.0092(0.0342) \n",
      "EVAL: [300/704] Elapsed 0m 47s (remain 1m 3s) Loss: 0.0239(0.0351) \n",
      "EVAL: [400/704] Elapsed 1m 2s (remain 0m 47s) Loss: 0.0628(0.0363) \n",
      "EVAL: [500/704] Elapsed 1m 18s (remain 0m 31s) Loss: 0.0262(0.0362) \n",
      "EVAL: [600/704] Elapsed 1m 34s (remain 0m 16s) Loss: 0.0170(0.0368) \n",
      "EVAL: [700/704] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0084(0.0360) \n",
      "EVAL: [703/704] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0061(0.0359) \n",
      "Epoch 1 - avg_train_loss: 0.0416  avg_val_loss: 0.0359  time: 1062s\n",
      "Epoch 1 - Score: 0.0000\n",
      "Epoch 1 - Save Best Score: 0.0000 Model\n",
      "Epoch: [2][0/2871] Elapsed 0m 0s (remain 30m 53s) Loss: 0.0197(0.0197) Grad: 8447.5400  LR: 0.000018  \n",
      "Epoch: [2][100/2871] Elapsed 0m 33s (remain 15m 16s) Loss: 0.0476(0.0347) Grad: 14825.6406  LR: 0.000018  \n",
      "Epoch: [2][200/2871] Elapsed 1m 5s (remain 14m 34s) Loss: 0.0151(0.0345) Grad: 4823.4888  LR: 0.000017  \n",
      "Epoch: [2][300/2871] Elapsed 1m 37s (remain 13m 54s) Loss: 0.0267(0.0338) Grad: 5208.5430  LR: 0.000017  \n",
      "Epoch: [2][400/2871] Elapsed 2m 10s (remain 13m 21s) Loss: 0.0466(0.0347) Grad: 13899.7148  LR: 0.000017  \n",
      "Epoch: [2][500/2871] Elapsed 2m 43s (remain 12m 51s) Loss: 0.0396(0.0354) Grad: 11518.2871  LR: 0.000017  \n",
      "Epoch: [2][600/2871] Elapsed 3m 17s (remain 12m 24s) Loss: 0.0270(0.0357) Grad: 8506.9814  LR: 0.000017  \n",
      "Epoch: [2][700/2871] Elapsed 3m 52s (remain 12m 0s) Loss: 0.0179(0.0355) Grad: 10647.8389  LR: 0.000017  \n",
      "Epoch: [2][800/2871] Elapsed 4m 25s (remain 11m 26s) Loss: 0.0450(0.0358) Grad: 8347.6992  LR: 0.000017  \n",
      "Epoch: [2][900/2871] Elapsed 4m 57s (remain 10m 50s) Loss: 0.0534(0.0359) Grad: 13869.2139  LR: 0.000016  \n",
      "Epoch: [2][1000/2871] Elapsed 5m 30s (remain 10m 16s) Loss: 0.0383(0.0360) Grad: 7046.9048  LR: 0.000016  \n",
      "Epoch: [2][1100/2871] Elapsed 6m 2s (remain 9m 43s) Loss: 0.0338(0.0360) Grad: 8449.9492  LR: 0.000016  \n",
      "Epoch: [2][1200/2871] Elapsed 6m 36s (remain 9m 10s) Loss: 0.0376(0.0361) Grad: 4857.5742  LR: 0.000016  \n",
      "Epoch: [2][1300/2871] Elapsed 7m 8s (remain 8m 37s) Loss: 0.0126(0.0361) Grad: 8987.8408  LR: 0.000016  \n",
      "Epoch: [2][1400/2871] Elapsed 7m 41s (remain 8m 4s) Loss: 0.0378(0.0361) Grad: 6968.8945  LR: 0.000016  \n",
      "Epoch: [2][1500/2871] Elapsed 8m 14s (remain 7m 31s) Loss: 0.0410(0.0360) Grad: 12779.9932  LR: 0.000015  \n",
      "Epoch: [2][1600/2871] Elapsed 8m 46s (remain 6m 57s) Loss: 0.0255(0.0359) Grad: 9172.3506  LR: 0.000015  \n",
      "Epoch: [2][1700/2871] Elapsed 9m 19s (remain 6m 24s) Loss: 0.0504(0.0359) Grad: 12593.1270  LR: 0.000015  \n",
      "Epoch: [2][1800/2871] Elapsed 9m 51s (remain 5m 51s) Loss: 0.0381(0.0359) Grad: 8797.1963  LR: 0.000015  \n",
      "Epoch: [2][1900/2871] Elapsed 10m 24s (remain 5m 18s) Loss: 0.0466(0.0359) Grad: 9880.3340  LR: 0.000015  \n",
      "Epoch: [2][2000/2871] Elapsed 10m 58s (remain 4m 46s) Loss: 0.0205(0.0358) Grad: 5814.0132  LR: 0.000015  \n",
      "Epoch: [2][2100/2871] Elapsed 11m 31s (remain 4m 13s) Loss: 0.0592(0.0357) Grad: 15154.2471  LR: 0.000015  \n",
      "Epoch: [2][2200/2871] Elapsed 12m 3s (remain 3m 40s) Loss: 0.0209(0.0357) Grad: 4217.3994  LR: 0.000014  \n",
      "Epoch: [2][2300/2871] Elapsed 12m 35s (remain 3m 7s) Loss: 0.0264(0.0357) Grad: 5826.7246  LR: 0.000014  \n",
      "Epoch: [2][2400/2871] Elapsed 13m 8s (remain 2m 34s) Loss: 0.0211(0.0356) Grad: 10635.8682  LR: 0.000014  \n",
      "Epoch: [2][2500/2871] Elapsed 13m 41s (remain 2m 1s) Loss: 0.0294(0.0358) Grad: 6778.9731  LR: 0.000014  \n",
      "Epoch: [2][2600/2871] Elapsed 14m 14s (remain 1m 28s) Loss: 0.0218(0.0357) Grad: 8169.6816  LR: 0.000014  \n",
      "Epoch: [2][2700/2871] Elapsed 14m 46s (remain 0m 55s) Loss: 0.0750(0.0357) Grad: 27217.5820  LR: 0.000014  \n",
      "Epoch: [2][2800/2871] Elapsed 15m 19s (remain 0m 22s) Loss: 0.0272(0.0358) Grad: 12979.8047  LR: 0.000013  \n",
      "Epoch: [2][2870/2871] Elapsed 15m 41s (remain 0m 0s) Loss: 0.0128(0.0358) Grad: 10893.1289  LR: 0.000013  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 6m 7s) Loss: 0.0422(0.0422) \n",
      "EVAL: [100/704] Elapsed 0m 16s (remain 1m 36s) Loss: 0.0391(0.0334) \n",
      "EVAL: [200/704] Elapsed 0m 31s (remain 1m 19s) Loss: 0.0092(0.0334) \n",
      "EVAL: [300/704] Elapsed 0m 47s (remain 1m 3s) Loss: 0.0235(0.0344) \n",
      "EVAL: [400/704] Elapsed 1m 2s (remain 0m 47s) Loss: 0.0597(0.0356) \n",
      "EVAL: [500/704] Elapsed 1m 18s (remain 0m 31s) Loss: 0.0257(0.0354) \n",
      "EVAL: [600/704] Elapsed 1m 34s (remain 0m 16s) Loss: 0.0161(0.0360) \n",
      "EVAL: [700/704] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0065(0.0352) \n",
      "EVAL: [703/704] Elapsed 1m 50s (remain 0m 0s) Loss: 0.0042(0.0351) \n",
      "Epoch 2 - avg_train_loss: 0.0358  avg_val_loss: 0.0351  time: 1057s\n",
      "Epoch 2 - Score: 0.0000\n",
      "Epoch: [3][0/2871] Elapsed 0m 0s (remain 27m 55s) Loss: 0.0200(0.0200) Grad: 11106.7578  LR: 0.000013  \n",
      "Epoch: [3][100/2871] Elapsed 0m 33s (remain 15m 25s) Loss: 0.0521(0.0327) Grad: 19479.8086  LR: 0.000013  \n",
      "Epoch: [3][200/2871] Elapsed 1m 8s (remain 15m 11s) Loss: 0.0368(0.0347) Grad: 8144.3706  LR: 0.000013  \n",
      "Epoch: [3][300/2871] Elapsed 1m 40s (remain 14m 22s) Loss: 0.0494(0.0358) Grad: 13873.9893  LR: 0.000013  \n",
      "Epoch: [3][400/2871] Elapsed 2m 13s (remain 13m 44s) Loss: 0.0269(0.0353) Grad: 5667.2344  LR: 0.000013  \n",
      "Epoch: [3][500/2871] Elapsed 2m 47s (remain 13m 10s) Loss: 0.0197(0.0348) Grad: 6659.2988  LR: 0.000013  \n",
      "Epoch: [3][600/2871] Elapsed 3m 19s (remain 12m 34s) Loss: 0.0191(0.0348) Grad: 8613.3213  LR: 0.000012  \n",
      "Epoch: [3][700/2871] Elapsed 3m 52s (remain 12m 1s) Loss: 0.0301(0.0349) Grad: 5220.0615  LR: 0.000012  \n",
      "Epoch: [3][800/2871] Elapsed 4m 26s (remain 11m 28s) Loss: 0.0423(0.0350) Grad: 13766.6289  LR: 0.000012  \n",
      "Epoch: [3][900/2871] Elapsed 4m 58s (remain 10m 53s) Loss: 0.0163(0.0352) Grad: 7736.5425  LR: 0.000012  \n",
      "Epoch: [3][1000/2871] Elapsed 5m 31s (remain 10m 19s) Loss: 0.0370(0.0351) Grad: 8576.1484  LR: 0.000012  \n",
      "Epoch: [3][1100/2871] Elapsed 6m 3s (remain 9m 44s) Loss: 0.0626(0.0348) Grad: 18858.6504  LR: 0.000012  \n",
      "Epoch: [3][1200/2871] Elapsed 6m 36s (remain 9m 10s) Loss: 0.0369(0.0347) Grad: 10331.8105  LR: 0.000011  \n",
      "Epoch: [3][1300/2871] Elapsed 7m 9s (remain 8m 38s) Loss: 0.0703(0.0346) Grad: 23637.5605  LR: 0.000011  \n",
      "Epoch: [3][1400/2871] Elapsed 7m 43s (remain 8m 6s) Loss: 0.0292(0.0345) Grad: 12213.9922  LR: 0.000011  \n",
      "Epoch: [3][1500/2871] Elapsed 8m 16s (remain 7m 32s) Loss: 0.0544(0.0346) Grad: 12112.7236  LR: 0.000011  \n",
      "Epoch: [3][1600/2871] Elapsed 8m 48s (remain 6m 59s) Loss: 0.0206(0.0345) Grad: 13026.4316  LR: 0.000011  \n",
      "Epoch: [3][1700/2871] Elapsed 9m 21s (remain 6m 26s) Loss: 0.0504(0.0344) Grad: 11550.8018  LR: 0.000011  \n",
      "Epoch: [3][1800/2871] Elapsed 9m 54s (remain 5m 53s) Loss: 0.0250(0.0344) Grad: 9010.8057  LR: 0.000011  \n",
      "Epoch: [3][1900/2871] Elapsed 10m 28s (remain 5m 20s) Loss: 0.0181(0.0345) Grad: 6713.9268  LR: 0.000010  \n",
      "Epoch: [3][2000/2871] Elapsed 11m 1s (remain 4m 47s) Loss: 0.0530(0.0346) Grad: 16314.8496  LR: 0.000010  \n",
      "Epoch: [3][2100/2871] Elapsed 11m 33s (remain 4m 14s) Loss: 0.0322(0.0345) Grad: 11792.9121  LR: 0.000010  \n",
      "Epoch: [3][2200/2871] Elapsed 12m 5s (remain 3m 40s) Loss: 0.1155(0.0345) Grad: 49695.7773  LR: 0.000010  \n",
      "Epoch: [3][2300/2871] Elapsed 12m 38s (remain 3m 7s) Loss: 0.0292(0.0346) Grad: 6174.4136  LR: 0.000010  \n",
      "Epoch: [3][2400/2871] Elapsed 13m 10s (remain 2m 34s) Loss: 0.0452(0.0346) Grad: 13825.0264  LR: 0.000010  \n",
      "Epoch: [3][2500/2871] Elapsed 13m 43s (remain 2m 1s) Loss: 0.0370(0.0346) Grad: 8653.3633  LR: 0.000009  \n",
      "Epoch: [3][2600/2871] Elapsed 14m 16s (remain 1m 28s) Loss: 0.0148(0.0347) Grad: 6747.4424  LR: 0.000009  \n",
      "Epoch: [3][2700/2871] Elapsed 14m 49s (remain 0m 55s) Loss: 0.0238(0.0346) Grad: 6672.8237  LR: 0.000009  \n",
      "Epoch: [3][2800/2871] Elapsed 15m 21s (remain 0m 23s) Loss: 0.0310(0.0346) Grad: 9259.6611  LR: 0.000009  \n",
      "Epoch: [3][2870/2871] Elapsed 15m 44s (remain 0m 0s) Loss: 0.0383(0.0346) Grad: 7636.4580  LR: 0.000009  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 56s) Loss: 0.0425(0.0425) \n",
      "EVAL: [100/704] Elapsed 0m 16s (remain 1m 35s) Loss: 0.0379(0.0320) \n",
      "EVAL: [200/704] Elapsed 0m 31s (remain 1m 19s) Loss: 0.0099(0.0320) \n",
      "EVAL: [300/704] Elapsed 0m 47s (remain 1m 3s) Loss: 0.0240(0.0327) \n",
      "EVAL: [400/704] Elapsed 1m 2s (remain 0m 47s) Loss: 0.0601(0.0340) \n",
      "EVAL: [500/704] Elapsed 1m 18s (remain 0m 31s) Loss: 0.0257(0.0339) \n",
      "EVAL: [600/704] Elapsed 1m 34s (remain 0m 16s) Loss: 0.0155(0.0345) \n",
      "EVAL: [700/704] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0063(0.0338) \n",
      "EVAL: [703/704] Elapsed 1m 50s (remain 0m 0s) Loss: 0.0036(0.0337) \n",
      "Epoch 3 - avg_train_loss: 0.0346  avg_val_loss: 0.0337  time: 1059s\n",
      "Epoch 3 - Score: 0.0028\n",
      "Epoch 3 - Save Best Score: 0.0028 Model\n",
      "Epoch: [4][0/2871] Elapsed 0m 0s (remain 34m 5s) Loss: 0.0388(0.0388) Grad: 9707.0088  LR: 0.000009  \n",
      "Epoch: [4][100/2871] Elapsed 0m 33s (remain 15m 22s) Loss: 0.0602(0.0337) Grad: 20145.5176  LR: 0.000009  \n",
      "Epoch: [4][200/2871] Elapsed 1m 6s (remain 14m 37s) Loss: 0.0159(0.0326) Grad: 13081.6670  LR: 0.000009  \n",
      "Epoch: [4][300/2871] Elapsed 1m 38s (remain 14m 3s) Loss: 0.0384(0.0324) Grad: 10205.8486  LR: 0.000008  \n",
      "Epoch: [4][400/2871] Elapsed 2m 11s (remain 13m 29s) Loss: 0.0284(0.0327) Grad: 9583.1973  LR: 0.000008  \n",
      "Epoch: [4][500/2871] Elapsed 2m 43s (remain 12m 55s) Loss: 0.0366(0.0328) Grad: 15830.1533  LR: 0.000008  \n",
      "Epoch: [4][600/2871] Elapsed 3m 17s (remain 12m 25s) Loss: 0.0295(0.0328) Grad: 5971.9463  LR: 0.000008  \n",
      "Epoch: [4][700/2871] Elapsed 3m 50s (remain 11m 53s) Loss: 0.0180(0.0328) Grad: 9794.5684  LR: 0.000008  \n",
      "Epoch: [4][800/2871] Elapsed 4m 22s (remain 11m 19s) Loss: 0.0492(0.0331) Grad: 14929.8770  LR: 0.000008  \n",
      "Epoch: [4][900/2871] Elapsed 4m 55s (remain 10m 47s) Loss: 0.0192(0.0332) Grad: 7416.6030  LR: 0.000007  \n",
      "Epoch: [4][1000/2871] Elapsed 5m 28s (remain 10m 14s) Loss: 0.0335(0.0332) Grad: 10152.9932  LR: 0.000007  \n",
      "Epoch: [4][1100/2871] Elapsed 6m 1s (remain 9m 41s) Loss: 0.0056(0.0331) Grad: 12001.4248  LR: 0.000007  \n",
      "Epoch: [4][1200/2871] Elapsed 6m 34s (remain 9m 7s) Loss: 0.0149(0.0334) Grad: 21215.9238  LR: 0.000007  \n",
      "Epoch: [4][1300/2871] Elapsed 7m 6s (remain 8m 34s) Loss: 0.0804(0.0333) Grad: 34272.4883  LR: 0.000007  \n",
      "Epoch: [4][1400/2871] Elapsed 7m 39s (remain 8m 1s) Loss: 0.0244(0.0335) Grad: 11391.6875  LR: 0.000007  \n",
      "Epoch: [4][1500/2871] Elapsed 8m 11s (remain 7m 28s) Loss: 0.0412(0.0334) Grad: 12043.4805  LR: 0.000007  \n",
      "Epoch: [4][1600/2871] Elapsed 8m 44s (remain 6m 55s) Loss: 0.0392(0.0334) Grad: 12754.5557  LR: 0.000006  \n",
      "Epoch: [4][1700/2871] Elapsed 9m 18s (remain 6m 24s) Loss: 0.0250(0.0334) Grad: 6758.8438  LR: 0.000006  \n",
      "Epoch: [4][1800/2871] Elapsed 9m 51s (remain 5m 51s) Loss: 0.0179(0.0335) Grad: 17148.6934  LR: 0.000006  \n",
      "Epoch: [4][1900/2871] Elapsed 10m 23s (remain 5m 18s) Loss: 0.0377(0.0334) Grad: 18237.2129  LR: 0.000006  \n",
      "Epoch: [4][2000/2871] Elapsed 10m 57s (remain 4m 45s) Loss: 0.0221(0.0333) Grad: 16071.5576  LR: 0.000006  \n",
      "Epoch: [4][2100/2871] Elapsed 11m 32s (remain 4m 13s) Loss: 0.0633(0.0333) Grad: 27078.6094  LR: 0.000006  \n",
      "Epoch: [4][2200/2871] Elapsed 12m 5s (remain 3m 40s) Loss: 0.0095(0.0334) Grad: 16132.2988  LR: 0.000005  \n",
      "Epoch: [4][2300/2871] Elapsed 12m 37s (remain 3m 7s) Loss: 0.0410(0.0334) Grad: 8210.0244  LR: 0.000005  \n",
      "Epoch: [4][2400/2871] Elapsed 13m 10s (remain 2m 34s) Loss: 0.0174(0.0332) Grad: 5372.5767  LR: 0.000005  \n",
      "Epoch: [4][2500/2871] Elapsed 13m 42s (remain 2m 1s) Loss: 0.0136(0.0331) Grad: 9976.7041  LR: 0.000005  \n",
      "Epoch: [4][2600/2871] Elapsed 14m 16s (remain 1m 28s) Loss: 0.0445(0.0330) Grad: 15955.4873  LR: 0.000005  \n",
      "Epoch: [4][2700/2871] Elapsed 14m 48s (remain 0m 55s) Loss: 0.0565(0.0330) Grad: 21361.3848  LR: 0.000005  \n",
      "Epoch: [4][2800/2871] Elapsed 15m 21s (remain 0m 23s) Loss: 0.0562(0.0330) Grad: 14697.0146  LR: 0.000005  \n",
      "Epoch: [4][2870/2871] Elapsed 15m 44s (remain 0m 0s) Loss: 0.0381(0.0330) Grad: 16598.1504  LR: 0.000004  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 14s) Loss: 0.0442(0.0442) \n",
      "EVAL: [100/704] Elapsed 0m 15s (remain 1m 35s) Loss: 0.0360(0.0316) \n",
      "EVAL: [200/704] Elapsed 0m 31s (remain 1m 18s) Loss: 0.0080(0.0313) \n",
      "EVAL: [300/704] Elapsed 0m 47s (remain 1m 3s) Loss: 0.0235(0.0323) \n",
      "EVAL: [400/704] Elapsed 1m 2s (remain 0m 47s) Loss: 0.0638(0.0337) \n",
      "EVAL: [500/704] Elapsed 1m 18s (remain 0m 31s) Loss: 0.0225(0.0334) \n",
      "EVAL: [600/704] Elapsed 1m 34s (remain 0m 16s) Loss: 0.0154(0.0339) \n",
      "EVAL: [700/704] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0061(0.0332) \n",
      "EVAL: [703/704] Elapsed 1m 50s (remain 0m 0s) Loss: 0.0036(0.0331) \n",
      "Epoch 4 - avg_train_loss: 0.0330  avg_val_loss: 0.0331  time: 1059s\n",
      "Epoch 4 - Score: 0.0062\n",
      "Epoch 4 - Save Best Score: 0.0062 Model\n",
      "Epoch: [5][0/2871] Elapsed 0m 0s (remain 30m 17s) Loss: 0.0383(0.0383) Grad: 13610.9443  LR: 0.000004  \n",
      "Epoch: [5][100/2871] Elapsed 0m 33s (remain 15m 8s) Loss: 0.0277(0.0357) Grad: 12224.5029  LR: 0.000004  \n",
      "Epoch: [5][200/2871] Elapsed 1m 5s (remain 14m 31s) Loss: 0.0217(0.0347) Grad: 10271.9629  LR: 0.000004  \n",
      "Epoch: [5][300/2871] Elapsed 1m 39s (remain 14m 5s) Loss: 0.0250(0.0331) Grad: 10116.7910  LR: 0.000004  \n",
      "Epoch: [5][400/2871] Elapsed 2m 13s (remain 13m 43s) Loss: 0.0344(0.0329) Grad: 14500.9258  LR: 0.000004  \n",
      "Epoch: [5][500/2871] Elapsed 2m 46s (remain 13m 9s) Loss: 0.0197(0.0325) Grad: 11166.8359  LR: 0.000004  \n",
      "Epoch: [5][600/2871] Elapsed 3m 19s (remain 12m 32s) Loss: 0.0264(0.0326) Grad: 9887.7881  LR: 0.000004  \n",
      "Epoch: [5][700/2871] Elapsed 3m 51s (remain 11m 57s) Loss: 0.0089(0.0320) Grad: 13556.9639  LR: 0.000003  \n",
      "Epoch: [5][800/2871] Elapsed 4m 24s (remain 11m 22s) Loss: 0.0094(0.0320) Grad: 8193.3994  LR: 0.000003  \n",
      "Epoch: [5][900/2871] Elapsed 4m 58s (remain 10m 52s) Loss: 0.0091(0.0318) Grad: 13696.4795  LR: 0.000003  \n",
      "Epoch: [5][1000/2871] Elapsed 5m 31s (remain 10m 18s) Loss: 0.0150(0.0316) Grad: 7251.2485  LR: 0.000003  \n",
      "Epoch: [5][1100/2871] Elapsed 6m 3s (remain 9m 44s) Loss: 0.0123(0.0314) Grad: 7836.7207  LR: 0.000003  \n",
      "Epoch: [5][1200/2871] Elapsed 6m 36s (remain 9m 10s) Loss: 0.0302(0.0316) Grad: 11571.4678  LR: 0.000003  \n",
      "Epoch: [5][1300/2871] Elapsed 7m 8s (remain 8m 37s) Loss: 0.0466(0.0315) Grad: 19116.5430  LR: 0.000002  \n",
      "Epoch: [5][1400/2871] Elapsed 7m 42s (remain 8m 4s) Loss: 0.0324(0.0314) Grad: 18724.7422  LR: 0.000002  \n",
      "Epoch: [5][1500/2871] Elapsed 8m 16s (remain 7m 33s) Loss: 0.0425(0.0313) Grad: 26903.2480  LR: 0.000002  \n",
      "Epoch: [5][1600/2871] Elapsed 8m 49s (remain 7m 0s) Loss: 0.0207(0.0314) Grad: 11556.5244  LR: 0.000002  \n",
      "Epoch: [5][1700/2871] Elapsed 9m 22s (remain 6m 26s) Loss: 0.0172(0.0314) Grad: 13110.0049  LR: 0.000002  \n",
      "Epoch: [5][1800/2871] Elapsed 9m 55s (remain 5m 53s) Loss: 0.0415(0.0315) Grad: 15170.1787  LR: 0.000002  \n",
      "Epoch: [5][1900/2871] Elapsed 10m 28s (remain 5m 20s) Loss: 0.0284(0.0315) Grad: 10669.0273  LR: 0.000002  \n",
      "Epoch: [5][2000/2871] Elapsed 11m 0s (remain 4m 47s) Loss: 0.0389(0.0315) Grad: 11738.9062  LR: 0.000001  \n",
      "Epoch: [5][2100/2871] Elapsed 11m 33s (remain 4m 14s) Loss: 0.0624(0.0314) Grad: 27584.6914  LR: 0.000001  \n",
      "Epoch: [5][2200/2871] Elapsed 12m 6s (remain 3m 41s) Loss: 0.0310(0.0315) Grad: 12223.0947  LR: 0.000001  \n",
      "Epoch: [5][2300/2871] Elapsed 12m 39s (remain 3m 8s) Loss: 0.0489(0.0316) Grad: 13914.4697  LR: 0.000001  \n",
      "Epoch: [5][2400/2871] Elapsed 13m 12s (remain 2m 35s) Loss: 0.0472(0.0318) Grad: 18763.5469  LR: 0.000001  \n",
      "Epoch: [5][2500/2871] Elapsed 13m 44s (remain 2m 2s) Loss: 0.0214(0.0319) Grad: 14936.5947  LR: 0.000001  \n",
      "Epoch: [5][2600/2871] Elapsed 14m 17s (remain 1m 28s) Loss: 0.0197(0.0318) Grad: 14334.6729  LR: 0.000000  \n",
      "Epoch: [5][2700/2871] Elapsed 14m 50s (remain 0m 56s) Loss: 0.0564(0.0318) Grad: 19687.6074  LR: 0.000000  \n",
      "Epoch: [5][2800/2871] Elapsed 15m 22s (remain 0m 23s) Loss: 0.0320(0.0318) Grad: 9193.9453  LR: 0.000000  \n",
      "Epoch: [5][2870/2871] Elapsed 15m 45s (remain 0m 0s) Loss: 0.0269(0.0318) Grad: 11168.9404  LR: 0.000000  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 12s) Loss: 0.0434(0.0434) \n",
      "EVAL: [100/704] Elapsed 0m 16s (remain 1m 35s) Loss: 0.0341(0.0311) \n",
      "EVAL: [200/704] Elapsed 0m 31s (remain 1m 19s) Loss: 0.0079(0.0308) \n",
      "EVAL: [300/704] Elapsed 0m 47s (remain 1m 3s) Loss: 0.0236(0.0316) \n",
      "EVAL: [400/704] Elapsed 1m 3s (remain 0m 47s) Loss: 0.0610(0.0329) \n",
      "EVAL: [500/704] Elapsed 1m 18s (remain 0m 31s) Loss: 0.0220(0.0327) \n",
      "EVAL: [600/704] Elapsed 1m 34s (remain 0m 16s) Loss: 0.0160(0.0332) \n",
      "EVAL: [700/704] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0061(0.0326) \n",
      "EVAL: [703/704] Elapsed 1m 50s (remain 0m 0s) Loss: 0.0034(0.0325) \n",
      "Epoch 5 - avg_train_loss: 0.0318  avg_val_loss: 0.0325  time: 1060s\n",
      "Epoch 5 - Score: 0.0366\n",
      "Epoch 5 - Save Best Score: 0.0366 Model\n",
      "========== fold: 3 training ==========\n",
      "Epoch: [1][0/2877] Elapsed 0m 0s (remain 31m 50s) Loss: 0.3829(0.3829) Grad: 1263823.5000  LR: 0.000000  \n",
      "Epoch: [1][100/2877] Elapsed 0m 33s (remain 15m 17s) Loss: 0.0492(0.1504) Grad: 24679.4473  LR: 0.000001  \n",
      "Epoch: [1][200/2877] Elapsed 1m 5s (remain 14m 36s) Loss: 0.0319(0.0951) Grad: 11077.7793  LR: 0.000003  \n",
      "Epoch: [1][300/2877] Elapsed 1m 38s (remain 14m 6s) Loss: 0.0336(0.0766) Grad: 10977.5635  LR: 0.000004  \n",
      "Epoch: [1][400/2877] Elapsed 2m 12s (remain 13m 36s) Loss: 0.0148(0.0679) Grad: 9288.4053  LR: 0.000006  \n",
      "Epoch: [1][500/2877] Elapsed 2m 46s (remain 13m 10s) Loss: 0.0458(0.0623) Grad: 12986.4521  LR: 0.000007  \n",
      "Epoch: [1][600/2877] Elapsed 3m 20s (remain 12m 39s) Loss: 0.0222(0.0592) Grad: 45005.7734  LR: 0.000008  \n",
      "Epoch: [1][700/2877] Elapsed 3m 53s (remain 12m 4s) Loss: 0.0299(0.0560) Grad: 10044.6387  LR: 0.000010  \n",
      "Epoch: [1][800/2877] Elapsed 4m 26s (remain 11m 29s) Loss: 0.0494(0.0542) Grad: 22174.5566  LR: 0.000011  \n",
      "Epoch: [1][900/2877] Elapsed 4m 58s (remain 10m 55s) Loss: 0.0283(0.0522) Grad: 8104.2847  LR: 0.000013  \n",
      "Epoch: [1][1000/2877] Elapsed 5m 31s (remain 10m 20s) Loss: 0.0129(0.0509) Grad: 21381.0723  LR: 0.000014  \n",
      "Epoch: [1][1100/2877] Elapsed 6m 4s (remain 9m 48s) Loss: 0.0315(0.0496) Grad: 7232.6079  LR: 0.000015  \n",
      "Epoch: [1][1200/2877] Elapsed 6m 37s (remain 9m 14s) Loss: 0.0381(0.0489) Grad: 15047.3916  LR: 0.000017  \n",
      "Epoch: [1][1300/2877] Elapsed 7m 9s (remain 8m 40s) Loss: 0.0681(0.0480) Grad: 26563.0820  LR: 0.000018  \n",
      "Epoch: [1][1400/2877] Elapsed 7m 42s (remain 8m 7s) Loss: 0.0121(0.0473) Grad: 4922.7637  LR: 0.000019  \n",
      "Epoch: [1][1500/2877] Elapsed 8m 17s (remain 7m 36s) Loss: 0.0184(0.0465) Grad: 16291.5000  LR: 0.000020  \n",
      "Epoch: [1][1600/2877] Elapsed 8m 50s (remain 7m 2s) Loss: 0.0594(0.0459) Grad: 22050.9688  LR: 0.000020  \n",
      "Epoch: [1][1700/2877] Elapsed 9m 22s (remain 6m 29s) Loss: 0.0469(0.0454) Grad: 9389.4902  LR: 0.000020  \n",
      "Epoch: [1][1800/2877] Elapsed 9m 58s (remain 5m 57s) Loss: 0.0202(0.0448) Grad: 14756.0078  LR: 0.000019  \n",
      "Epoch: [1][1900/2877] Elapsed 10m 32s (remain 5m 24s) Loss: 0.1105(0.0445) Grad: 42036.4961  LR: 0.000019  \n",
      "Epoch: [1][2000/2877] Elapsed 11m 5s (remain 4m 51s) Loss: 0.0067(0.0442) Grad: 8831.3193  LR: 0.000019  \n",
      "Epoch: [1][2100/2877] Elapsed 11m 37s (remain 4m 17s) Loss: 0.0640(0.0439) Grad: 23541.7129  LR: 0.000019  \n",
      "Epoch: [1][2200/2877] Elapsed 12m 10s (remain 3m 44s) Loss: 0.0736(0.0435) Grad: 28040.8340  LR: 0.000019  \n",
      "Epoch: [1][2300/2877] Elapsed 12m 44s (remain 3m 11s) Loss: 0.0096(0.0432) Grad: 6020.9526  LR: 0.000019  \n",
      "Epoch: [1][2400/2877] Elapsed 13m 17s (remain 2m 38s) Loss: 0.0442(0.0429) Grad: 11258.2900  LR: 0.000019  \n",
      "Epoch: [1][2500/2877] Elapsed 13m 50s (remain 2m 4s) Loss: 0.0426(0.0427) Grad: 13479.0498  LR: 0.000018  \n",
      "Epoch: [1][2600/2877] Elapsed 14m 23s (remain 1m 31s) Loss: 0.0419(0.0426) Grad: 13944.1816  LR: 0.000018  \n",
      "Epoch: [1][2700/2877] Elapsed 14m 55s (remain 0m 58s) Loss: 0.0483(0.0424) Grad: 8321.2949  LR: 0.000018  \n",
      "Epoch: [1][2800/2877] Elapsed 15m 28s (remain 0m 25s) Loss: 0.0236(0.0421) Grad: 6351.0552  LR: 0.000018  \n",
      "Epoch: [1][2876/2877] Elapsed 15m 54s (remain 0m 0s) Loss: 0.0307(0.0419) Grad: 5624.9292  LR: 0.000018  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 51s) Loss: 0.0598(0.0598) \n",
      "EVAL: [100/698] Elapsed 0m 16s (remain 1m 35s) Loss: 0.0550(0.0331) \n",
      "EVAL: [200/698] Elapsed 0m 31s (remain 1m 18s) Loss: 0.0094(0.0356) \n",
      "EVAL: [300/698] Elapsed 0m 47s (remain 1m 2s) Loss: 0.0518(0.0357) \n",
      "EVAL: [400/698] Elapsed 1m 2s (remain 0m 46s) Loss: 0.0419(0.0373) \n",
      "EVAL: [500/698] Elapsed 1m 18s (remain 0m 30s) Loss: 0.0360(0.0384) \n",
      "EVAL: [600/698] Elapsed 1m 34s (remain 0m 15s) Loss: 0.0355(0.0382) \n",
      "EVAL: [697/698] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0035(0.0369) \n",
      "Epoch 1 - avg_train_loss: 0.0419  avg_val_loss: 0.0369  time: 1068s\n",
      "Epoch 1 - Score: 0.0000\n",
      "Epoch 1 - Save Best Score: 0.0000 Model\n",
      "Epoch: [2][0/2877] Elapsed 0m 0s (remain 30m 49s) Loss: 0.0202(0.0202) Grad: 5267.8887  LR: 0.000018  \n",
      "Epoch: [2][100/2877] Elapsed 0m 33s (remain 15m 31s) Loss: 0.1003(0.0355) Grad: 34958.4531  LR: 0.000018  \n",
      "Epoch: [2][200/2877] Elapsed 1m 6s (remain 14m 44s) Loss: 0.0239(0.0359) Grad: 15065.1885  LR: 0.000017  \n",
      "Epoch: [2][300/2877] Elapsed 1m 39s (remain 14m 14s) Loss: 0.0260(0.0368) Grad: 7371.9233  LR: 0.000017  \n",
      "Epoch: [2][400/2877] Elapsed 2m 12s (remain 13m 37s) Loss: 0.0406(0.0373) Grad: 9644.8955  LR: 0.000017  \n",
      "Epoch: [2][500/2877] Elapsed 2m 44s (remain 13m 2s) Loss: 0.0215(0.0372) Grad: 5582.9785  LR: 0.000017  \n",
      "Epoch: [2][600/2877] Elapsed 3m 17s (remain 12m 27s) Loss: 0.0291(0.0364) Grad: 3548.9194  LR: 0.000017  \n",
      "Epoch: [2][700/2877] Elapsed 3m 50s (remain 11m 55s) Loss: 0.0546(0.0368) Grad: 12373.7861  LR: 0.000017  \n",
      "Epoch: [2][800/2877] Elapsed 4m 24s (remain 11m 24s) Loss: 0.0533(0.0366) Grad: 16349.6465  LR: 0.000017  \n",
      "Epoch: [2][900/2877] Elapsed 4m 56s (remain 10m 50s) Loss: 0.0484(0.0367) Grad: 8093.7559  LR: 0.000016  \n",
      "Epoch: [2][1000/2877] Elapsed 5m 29s (remain 10m 17s) Loss: 0.0240(0.0365) Grad: 4304.9399  LR: 0.000016  \n",
      "Epoch: [2][1100/2877] Elapsed 6m 1s (remain 9m 43s) Loss: 0.0141(0.0364) Grad: 7566.5605  LR: 0.000016  \n",
      "Epoch: [2][1200/2877] Elapsed 6m 35s (remain 9m 11s) Loss: 0.0356(0.0363) Grad: 4749.4790  LR: 0.000016  \n",
      "Epoch: [2][1300/2877] Elapsed 7m 8s (remain 8m 38s) Loss: 0.0273(0.0363) Grad: 8264.2988  LR: 0.000016  \n",
      "Epoch: [2][1400/2877] Elapsed 7m 40s (remain 8m 5s) Loss: 0.0337(0.0365) Grad: 4838.6675  LR: 0.000016  \n",
      "Epoch: [2][1500/2877] Elapsed 8m 13s (remain 7m 32s) Loss: 0.0179(0.0364) Grad: 4692.0161  LR: 0.000015  \n",
      "Epoch: [2][1600/2877] Elapsed 8m 46s (remain 6m 59s) Loss: 0.0678(0.0364) Grad: 23852.9043  LR: 0.000015  \n",
      "Epoch: [2][1700/2877] Elapsed 9m 19s (remain 6m 27s) Loss: 0.0180(0.0363) Grad: 8312.3516  LR: 0.000015  \n",
      "Epoch: [2][1800/2877] Elapsed 9m 52s (remain 5m 53s) Loss: 0.0195(0.0362) Grad: 7630.7896  LR: 0.000015  \n",
      "Epoch: [2][1900/2877] Elapsed 10m 25s (remain 5m 20s) Loss: 0.0498(0.0363) Grad: 7013.5576  LR: 0.000015  \n",
      "Epoch: [2][2000/2877] Elapsed 10m 59s (remain 4m 48s) Loss: 0.0373(0.0362) Grad: 8270.8730  LR: 0.000015  \n",
      "Epoch: [2][2100/2877] Elapsed 11m 31s (remain 4m 15s) Loss: 0.0491(0.0361) Grad: 4840.9229  LR: 0.000015  \n",
      "Epoch: [2][2200/2877] Elapsed 12m 4s (remain 3m 42s) Loss: 0.0424(0.0362) Grad: 6186.1865  LR: 0.000014  \n",
      "Epoch: [2][2300/2877] Elapsed 12m 36s (remain 3m 9s) Loss: 0.0362(0.0363) Grad: 5213.4668  LR: 0.000014  \n",
      "Epoch: [2][2400/2877] Elapsed 13m 9s (remain 2m 36s) Loss: 0.0168(0.0364) Grad: 6784.2412  LR: 0.000014  \n",
      "Epoch: [2][2500/2877] Elapsed 13m 42s (remain 2m 3s) Loss: 0.0121(0.0363) Grad: 7674.6792  LR: 0.000014  \n",
      "Epoch: [2][2600/2877] Elapsed 14m 15s (remain 1m 30s) Loss: 0.0272(0.0362) Grad: 5322.8701  LR: 0.000014  \n",
      "Epoch: [2][2700/2877] Elapsed 14m 47s (remain 0m 57s) Loss: 0.0734(0.0361) Grad: 23759.5684  LR: 0.000014  \n",
      "Epoch: [2][2800/2877] Elapsed 15m 20s (remain 0m 24s) Loss: 0.0075(0.0360) Grad: 9183.6484  LR: 0.000013  \n",
      "Epoch: [2][2876/2877] Elapsed 15m 45s (remain 0m 0s) Loss: 0.0481(0.0360) Grad: 12739.1953  LR: 0.000013  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 8s) Loss: 0.0589(0.0589) \n",
      "EVAL: [100/698] Elapsed 0m 15s (remain 1m 34s) Loss: 0.0502(0.0317) \n",
      "EVAL: [200/698] Elapsed 0m 31s (remain 1m 17s) Loss: 0.0101(0.0337) \n",
      "EVAL: [300/698] Elapsed 0m 47s (remain 1m 2s) Loss: 0.0489(0.0340) \n",
      "EVAL: [400/698] Elapsed 1m 2s (remain 0m 46s) Loss: 0.0369(0.0355) \n",
      "EVAL: [500/698] Elapsed 1m 18s (remain 0m 30s) Loss: 0.0339(0.0367) \n",
      "EVAL: [600/698] Elapsed 1m 33s (remain 0m 15s) Loss: 0.0349(0.0365) \n",
      "EVAL: [697/698] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0033(0.0353) \n",
      "Epoch 2 - avg_train_loss: 0.0360  avg_val_loss: 0.0353  time: 1059s\n",
      "Epoch 2 - Score: 0.0000\n",
      "Epoch: [3][0/2877] Elapsed 0m 0s (remain 29m 11s) Loss: 0.0528(0.0528) Grad: 17766.0195  LR: 0.000013  \n",
      "Epoch: [3][100/2877] Elapsed 0m 33s (remain 15m 10s) Loss: 0.0197(0.0370) Grad: 8821.8457  LR: 0.000013  \n",
      "Epoch: [3][200/2877] Elapsed 1m 5s (remain 14m 36s) Loss: 0.0978(0.0371) Grad: 37867.8359  LR: 0.000013  \n",
      "Epoch: [3][300/2877] Elapsed 1m 38s (remain 14m 5s) Loss: 0.0107(0.0371) Grad: 12917.2354  LR: 0.000013  \n",
      "Epoch: [3][400/2877] Elapsed 2m 11s (remain 13m 30s) Loss: 0.0601(0.0366) Grad: 21779.3184  LR: 0.000013  \n",
      "Epoch: [3][500/2877] Elapsed 2m 44s (remain 13m 1s) Loss: 0.0116(0.0362) Grad: 12396.3223  LR: 0.000013  \n",
      "Epoch: [3][600/2877] Elapsed 3m 19s (remain 12m 37s) Loss: 0.0306(0.0353) Grad: 6737.2144  LR: 0.000012  \n",
      "Epoch: [3][700/2877] Elapsed 3m 52s (remain 12m 1s) Loss: 0.0495(0.0354) Grad: 12392.5322  LR: 0.000012  \n",
      "Epoch: [3][800/2877] Elapsed 4m 24s (remain 11m 26s) Loss: 0.0090(0.0353) Grad: 12415.1143  LR: 0.000012  \n",
      "Epoch: [3][900/2877] Elapsed 4m 57s (remain 10m 51s) Loss: 0.0434(0.0353) Grad: 8913.5146  LR: 0.000012  \n",
      "Epoch: [3][1000/2877] Elapsed 5m 29s (remain 10m 17s) Loss: 0.0830(0.0355) Grad: 30620.8105  LR: 0.000012  \n",
      "Epoch: [3][1100/2877] Elapsed 6m 2s (remain 9m 44s) Loss: 0.0253(0.0356) Grad: 7993.4902  LR: 0.000012  \n",
      "Epoch: [3][1200/2877] Elapsed 6m 35s (remain 9m 12s) Loss: 0.0245(0.0356) Grad: 4531.6206  LR: 0.000011  \n",
      "Epoch: [3][1300/2877] Elapsed 7m 8s (remain 8m 39s) Loss: 0.0426(0.0353) Grad: 12480.0107  LR: 0.000011  \n",
      "Epoch: [3][1400/2877] Elapsed 7m 41s (remain 8m 6s) Loss: 0.0536(0.0353) Grad: 16502.0586  LR: 0.000011  \n",
      "Epoch: [3][1500/2877] Elapsed 8m 13s (remain 7m 32s) Loss: 0.0314(0.0353) Grad: 5833.4302  LR: 0.000011  \n",
      "Epoch: [3][1600/2877] Elapsed 8m 46s (remain 6m 59s) Loss: 0.0210(0.0353) Grad: 6527.6030  LR: 0.000011  \n",
      "Epoch: [3][1700/2877] Elapsed 9m 19s (remain 6m 26s) Loss: 0.0377(0.0351) Grad: 14729.8975  LR: 0.000011  \n",
      "Epoch: [3][1800/2877] Elapsed 9m 52s (remain 5m 53s) Loss: 0.0314(0.0350) Grad: 7812.3745  LR: 0.000011  \n",
      "Epoch: [3][1900/2877] Elapsed 10m 24s (remain 5m 20s) Loss: 0.0349(0.0351) Grad: 6986.0469  LR: 0.000010  \n",
      "Epoch: [3][2000/2877] Elapsed 10m 57s (remain 4m 47s) Loss: 0.0271(0.0349) Grad: 6079.3506  LR: 0.000010  \n",
      "Epoch: [3][2100/2877] Elapsed 11m 30s (remain 4m 14s) Loss: 0.0566(0.0349) Grad: 17737.0859  LR: 0.000010  \n",
      "Epoch: [3][2200/2877] Elapsed 12m 3s (remain 3m 42s) Loss: 0.0625(0.0348) Grad: 24848.8008  LR: 0.000010  \n",
      "Epoch: [3][2300/2877] Elapsed 12m 37s (remain 3m 9s) Loss: 0.0196(0.0347) Grad: 7465.9341  LR: 0.000010  \n",
      "Epoch: [3][2400/2877] Elapsed 13m 9s (remain 2m 36s) Loss: 0.0136(0.0346) Grad: 9904.9570  LR: 0.000010  \n",
      "Epoch: [3][2500/2877] Elapsed 13m 42s (remain 2m 3s) Loss: 0.0835(0.0347) Grad: 26435.0781  LR: 0.000009  \n",
      "Epoch: [3][2600/2877] Elapsed 14m 17s (remain 1m 30s) Loss: 0.0226(0.0346) Grad: 5897.0503  LR: 0.000009  \n",
      "Epoch: [3][2700/2877] Elapsed 14m 50s (remain 0m 58s) Loss: 0.0307(0.0346) Grad: 6461.2964  LR: 0.000009  \n",
      "Epoch: [3][2800/2877] Elapsed 15m 23s (remain 0m 25s) Loss: 0.0247(0.0345) Grad: 6780.8823  LR: 0.000009  \n",
      "Epoch: [3][2876/2877] Elapsed 15m 48s (remain 0m 0s) Loss: 0.0245(0.0345) Grad: 8098.2656  LR: 0.000009  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 55s) Loss: 0.0542(0.0542) \n",
      "EVAL: [100/698] Elapsed 0m 16s (remain 1m 34s) Loss: 0.0404(0.0302) \n",
      "EVAL: [200/698] Elapsed 0m 31s (remain 1m 18s) Loss: 0.0117(0.0317) \n",
      "EVAL: [300/698] Elapsed 0m 47s (remain 1m 2s) Loss: 0.0481(0.0321) \n",
      "EVAL: [400/698] Elapsed 1m 2s (remain 0m 46s) Loss: 0.0345(0.0335) \n",
      "EVAL: [500/698] Elapsed 1m 18s (remain 0m 30s) Loss: 0.0355(0.0347) \n",
      "EVAL: [600/698] Elapsed 1m 34s (remain 0m 15s) Loss: 0.0343(0.0346) \n",
      "EVAL: [697/698] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0053(0.0335) \n",
      "Epoch 3 - avg_train_loss: 0.0345  avg_val_loss: 0.0335  time: 1062s\n",
      "Epoch 3 - Score: 0.0125\n",
      "Epoch 3 - Save Best Score: 0.0125 Model\n",
      "Epoch: [4][0/2877] Elapsed 0m 0s (remain 31m 12s) Loss: 0.0517(0.0517) Grad: 16625.2559  LR: 0.000009  \n",
      "Epoch: [4][100/2877] Elapsed 0m 33s (remain 15m 15s) Loss: 0.0305(0.0349) Grad: 8719.6279  LR: 0.000009  \n",
      "Epoch: [4][200/2877] Elapsed 1m 6s (remain 14m 42s) Loss: 0.0243(0.0348) Grad: 7899.3296  LR: 0.000009  \n",
      "Epoch: [4][300/2877] Elapsed 1m 39s (remain 14m 14s) Loss: 0.0250(0.0344) Grad: 5952.8149  LR: 0.000008  \n",
      "Epoch: [4][400/2877] Elapsed 2m 12s (remain 13m 40s) Loss: 0.0143(0.0344) Grad: 12082.5742  LR: 0.000008  \n",
      "Epoch: [4][500/2877] Elapsed 2m 45s (remain 13m 4s) Loss: 0.0068(0.0342) Grad: 14323.2109  LR: 0.000008  \n",
      "Epoch: [4][600/2877] Elapsed 3m 18s (remain 12m 32s) Loss: 0.0288(0.0341) Grad: 6098.9453  LR: 0.000008  \n",
      "Epoch: [4][700/2877] Elapsed 3m 51s (remain 11m 59s) Loss: 0.0450(0.0343) Grad: 12949.4980  LR: 0.000008  \n",
      "Epoch: [4][800/2877] Elapsed 4m 24s (remain 11m 26s) Loss: 0.0391(0.0338) Grad: 11571.6123  LR: 0.000008  \n",
      "Epoch: [4][900/2877] Elapsed 4m 57s (remain 10m 53s) Loss: 0.0183(0.0338) Grad: 6025.2388  LR: 0.000007  \n",
      "Epoch: [4][1000/2877] Elapsed 5m 30s (remain 10m 18s) Loss: 0.0210(0.0333) Grad: 9884.8076  LR: 0.000007  \n",
      "Epoch: [4][1100/2877] Elapsed 6m 3s (remain 9m 45s) Loss: 0.0136(0.0331) Grad: 7329.5459  LR: 0.000007  \n",
      "Epoch: [4][1200/2877] Elapsed 6m 36s (remain 9m 12s) Loss: 0.0328(0.0331) Grad: 7145.3066  LR: 0.000007  \n",
      "Epoch: [4][1300/2877] Elapsed 7m 9s (remain 8m 39s) Loss: 0.0177(0.0331) Grad: 8297.5479  LR: 0.000007  \n",
      "Epoch: [4][1400/2877] Elapsed 7m 41s (remain 8m 6s) Loss: 0.0197(0.0330) Grad: 12557.6006  LR: 0.000007  \n",
      "Epoch: [4][1500/2877] Elapsed 8m 14s (remain 7m 33s) Loss: 0.0183(0.0331) Grad: 9529.2959  LR: 0.000007  \n",
      "Epoch: [4][1600/2877] Elapsed 8m 47s (remain 7m 0s) Loss: 0.0241(0.0331) Grad: 13578.2070  LR: 0.000006  \n",
      "Epoch: [4][1700/2877] Elapsed 9m 20s (remain 6m 27s) Loss: 0.0244(0.0330) Grad: 9647.8887  LR: 0.000006  \n",
      "Epoch: [4][1800/2877] Elapsed 9m 53s (remain 5m 54s) Loss: 0.0316(0.0329) Grad: 11757.5254  LR: 0.000006  \n",
      "Epoch: [4][1900/2877] Elapsed 10m 26s (remain 5m 21s) Loss: 0.0342(0.0330) Grad: 9635.9434  LR: 0.000006  \n",
      "Epoch: [4][2000/2877] Elapsed 11m 0s (remain 4m 48s) Loss: 0.0091(0.0331) Grad: 9539.4912  LR: 0.000006  \n",
      "Epoch: [4][2100/2877] Elapsed 11m 32s (remain 4m 15s) Loss: 0.0405(0.0331) Grad: 12237.2412  LR: 0.000006  \n",
      "Epoch: [4][2200/2877] Elapsed 12m 5s (remain 3m 42s) Loss: 0.0423(0.0332) Grad: 10861.9287  LR: 0.000005  \n",
      "Epoch: [4][2300/2877] Elapsed 12m 38s (remain 3m 9s) Loss: 0.0140(0.0331) Grad: 9356.4502  LR: 0.000005  \n",
      "Epoch: [4][2400/2877] Elapsed 13m 12s (remain 2m 37s) Loss: 0.0723(0.0330) Grad: 28566.2461  LR: 0.000005  \n",
      "Epoch: [4][2500/2877] Elapsed 13m 44s (remain 2m 3s) Loss: 0.0340(0.0332) Grad: 6864.4243  LR: 0.000005  \n",
      "Epoch: [4][2600/2877] Elapsed 14m 17s (remain 1m 30s) Loss: 0.0498(0.0331) Grad: 12881.3467  LR: 0.000005  \n",
      "Epoch: [4][2700/2877] Elapsed 14m 49s (remain 0m 57s) Loss: 0.0344(0.0332) Grad: 15561.6455  LR: 0.000005  \n",
      "Epoch: [4][2800/2877] Elapsed 15m 22s (remain 0m 25s) Loss: 0.0205(0.0332) Grad: 8256.3994  LR: 0.000005  \n",
      "Epoch: [4][2876/2877] Elapsed 15m 47s (remain 0m 0s) Loss: 0.0254(0.0332) Grad: 8265.3799  LR: 0.000004  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 18s) Loss: 0.0566(0.0566) \n",
      "EVAL: [100/698] Elapsed 0m 16s (remain 1m 34s) Loss: 0.0401(0.0289) \n",
      "EVAL: [200/698] Elapsed 0m 31s (remain 1m 18s) Loss: 0.0095(0.0307) \n",
      "EVAL: [300/698] Elapsed 0m 47s (remain 1m 2s) Loss: 0.0501(0.0311) \n",
      "EVAL: [400/698] Elapsed 1m 2s (remain 0m 46s) Loss: 0.0329(0.0327) \n",
      "EVAL: [500/698] Elapsed 1m 18s (remain 0m 30s) Loss: 0.0349(0.0340) \n",
      "EVAL: [600/698] Elapsed 1m 34s (remain 0m 15s) Loss: 0.0337(0.0339) \n",
      "EVAL: [697/698] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0033(0.0329) \n",
      "Epoch 4 - avg_train_loss: 0.0332  avg_val_loss: 0.0329  time: 1061s\n",
      "Epoch 4 - Score: 0.0418\n",
      "Epoch 4 - Save Best Score: 0.0418 Model\n",
      "Epoch: [5][0/2877] Elapsed 0m 0s (remain 33m 37s) Loss: 0.0285(0.0285) Grad: 10271.7432  LR: 0.000004  \n",
      "Epoch: [5][100/2877] Elapsed 0m 33s (remain 15m 20s) Loss: 0.0153(0.0314) Grad: 6277.5713  LR: 0.000004  \n",
      "Epoch: [5][200/2877] Elapsed 1m 6s (remain 14m 38s) Loss: 0.0314(0.0311) Grad: 8785.4141  LR: 0.000004  \n",
      "Epoch: [5][300/2877] Elapsed 1m 38s (remain 14m 4s) Loss: 0.0187(0.0308) Grad: 11390.1221  LR: 0.000004  \n",
      "Epoch: [5][400/2877] Elapsed 2m 11s (remain 13m 30s) Loss: 0.0070(0.0306) Grad: 11166.9756  LR: 0.000004  \n",
      "Epoch: [5][500/2877] Elapsed 2m 43s (remain 12m 56s) Loss: 0.0358(0.0307) Grad: 12694.7021  LR: 0.000004  \n",
      "Epoch: [5][600/2877] Elapsed 3m 17s (remain 12m 26s) Loss: 0.0474(0.0311) Grad: 18681.7246  LR: 0.000004  \n",
      "Epoch: [5][700/2877] Elapsed 3m 50s (remain 11m 55s) Loss: 0.0306(0.0311) Grad: 10596.6729  LR: 0.000003  \n",
      "Epoch: [5][800/2877] Elapsed 4m 23s (remain 11m 23s) Loss: 0.0344(0.0310) Grad: 16805.4512  LR: 0.000003  \n",
      "Epoch: [5][900/2877] Elapsed 4m 56s (remain 10m 50s) Loss: 0.0247(0.0310) Grad: 9186.2617  LR: 0.000003  \n",
      "Epoch: [5][1000/2877] Elapsed 5m 29s (remain 10m 17s) Loss: 0.0246(0.0310) Grad: 9038.6543  LR: 0.000003  \n",
      "Epoch: [5][1100/2877] Elapsed 6m 2s (remain 9m 45s) Loss: 0.0377(0.0310) Grad: 16331.8945  LR: 0.000003  \n",
      "Epoch: [5][1200/2877] Elapsed 6m 37s (remain 9m 14s) Loss: 0.0243(0.0311) Grad: 9267.8398  LR: 0.000003  \n",
      "Epoch: [5][1300/2877] Elapsed 7m 9s (remain 8m 40s) Loss: 0.0228(0.0313) Grad: 12328.1670  LR: 0.000002  \n",
      "Epoch: [5][1400/2877] Elapsed 7m 42s (remain 8m 7s) Loss: 0.0242(0.0314) Grad: 11756.9150  LR: 0.000002  \n",
      "Epoch: [5][1500/2877] Elapsed 8m 14s (remain 7m 33s) Loss: 0.0206(0.0312) Grad: 9555.9434  LR: 0.000002  \n",
      "Epoch: [5][1600/2877] Elapsed 8m 46s (remain 6m 59s) Loss: 0.0488(0.0313) Grad: 19800.9551  LR: 0.000002  \n",
      "Epoch: [5][1700/2877] Elapsed 9m 18s (remain 6m 26s) Loss: 0.0135(0.0314) Grad: 5995.3901  LR: 0.000002  \n",
      "Epoch: [5][1800/2877] Elapsed 9m 51s (remain 5m 53s) Loss: 0.0342(0.0314) Grad: 10204.7773  LR: 0.000002  \n",
      "Epoch: [5][1900/2877] Elapsed 10m 24s (remain 5m 20s) Loss: 0.0194(0.0314) Grad: 10112.8330  LR: 0.000002  \n",
      "Epoch: [5][2000/2877] Elapsed 10m 57s (remain 4m 47s) Loss: 0.0383(0.0315) Grad: 10350.7461  LR: 0.000001  \n",
      "Epoch: [5][2100/2877] Elapsed 11m 31s (remain 4m 15s) Loss: 0.0494(0.0315) Grad: 22537.8281  LR: 0.000001  \n",
      "Epoch: [5][2200/2877] Elapsed 12m 3s (remain 3m 42s) Loss: 0.0688(0.0316) Grad: 28847.2148  LR: 0.000001  \n",
      "Epoch: [5][2300/2877] Elapsed 12m 35s (remain 3m 9s) Loss: 0.0262(0.0316) Grad: 8292.1699  LR: 0.000001  \n",
      "Epoch: [5][2400/2877] Elapsed 13m 8s (remain 2m 36s) Loss: 0.0674(0.0316) Grad: 46119.9688  LR: 0.000001  \n",
      "Epoch: [5][2500/2877] Elapsed 13m 41s (remain 2m 3s) Loss: 0.0397(0.0317) Grad: 13893.4268  LR: 0.000001  \n",
      "Epoch: [5][2600/2877] Elapsed 14m 15s (remain 1m 30s) Loss: 0.0104(0.0317) Grad: 14963.2627  LR: 0.000000  \n",
      "Epoch: [5][2700/2877] Elapsed 14m 47s (remain 0m 57s) Loss: 0.0244(0.0317) Grad: 10270.1357  LR: 0.000000  \n",
      "Epoch: [5][2800/2877] Elapsed 15m 19s (remain 0m 24s) Loss: 0.0293(0.0318) Grad: 10681.0771  LR: 0.000000  \n",
      "Epoch: [5][2876/2877] Elapsed 15m 44s (remain 0m 0s) Loss: 0.0231(0.0321) Grad: 11014.2422  LR: 0.000000  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 34s) Loss: 0.0554(0.0554) \n",
      "EVAL: [100/698] Elapsed 0m 16s (remain 1m 34s) Loss: 0.0378(0.0285) \n",
      "EVAL: [200/698] Elapsed 0m 31s (remain 1m 18s) Loss: 0.0089(0.0302) \n",
      "EVAL: [300/698] Elapsed 0m 47s (remain 1m 2s) Loss: 0.0502(0.0306) \n",
      "EVAL: [400/698] Elapsed 1m 2s (remain 0m 46s) Loss: 0.0320(0.0323) \n",
      "EVAL: [500/698] Elapsed 1m 18s (remain 0m 30s) Loss: 0.0339(0.0337) \n",
      "EVAL: [600/698] Elapsed 1m 34s (remain 0m 15s) Loss: 0.0337(0.0336) \n",
      "EVAL: [697/698] Elapsed 1m 49s (remain 0m 0s) Loss: 0.0037(0.0326) \n",
      "Epoch 5 - avg_train_loss: 0.0321  avg_val_loss: 0.0326  time: 1058s\n",
      "Epoch 5 - Score: 0.0530\n",
      "Epoch 5 - Save Best Score: 0.0530 Model\n",
      "========== fold: 4 training ==========\n",
      "Epoch: [1][0/2850] Elapsed 0m 0s (remain 31m 25s) Loss: 0.3786(0.3786) Grad: 1351239.0000  LR: 0.000000  \n",
      "Epoch: [1][100/2850] Elapsed 0m 33s (remain 15m 17s) Loss: 0.0383(0.1510) Grad: 17885.6758  LR: 0.000001  \n",
      "Epoch: [1][200/2850] Elapsed 1m 6s (remain 14m 37s) Loss: 0.0130(0.0961) Grad: 7271.0107  LR: 0.000003  \n",
      "Epoch: [1][300/2850] Elapsed 1m 39s (remain 14m 5s) Loss: 0.0325(0.0778) Grad: 15593.3057  LR: 0.000004  \n",
      "Epoch: [1][400/2850] Elapsed 2m 14s (remain 13m 41s) Loss: 0.0163(0.0680) Grad: 38102.7031  LR: 0.000006  \n",
      "Epoch: [1][500/2850] Elapsed 2m 46s (remain 13m 2s) Loss: 0.0438(0.0626) Grad: 13364.2344  LR: 0.000007  \n",
      "Epoch: [1][600/2850] Elapsed 3m 19s (remain 12m 26s) Loss: 0.0216(0.0585) Grad: 40983.3672  LR: 0.000008  \n",
      "Epoch: [1][700/2850] Elapsed 3m 52s (remain 11m 51s) Loss: 0.0542(0.0561) Grad: 25484.6309  LR: 0.000010  \n",
      "Epoch: [1][800/2850] Elapsed 4m 24s (remain 11m 16s) Loss: 0.0314(0.0537) Grad: 18524.9531  LR: 0.000011  \n",
      "Epoch: [1][900/2850] Elapsed 4m 56s (remain 10m 41s) Loss: 0.0680(0.0521) Grad: 20785.5996  LR: 0.000013  \n",
      "Epoch: [1][1000/2850] Elapsed 5m 29s (remain 10m 7s) Loss: 0.0492(0.0505) Grad: 11496.5840  LR: 0.000014  \n",
      "Epoch: [1][1100/2850] Elapsed 6m 2s (remain 9m 35s) Loss: 0.0311(0.0496) Grad: 7638.1270  LR: 0.000015  \n",
      "Epoch: [1][1200/2850] Elapsed 6m 34s (remain 9m 1s) Loss: 0.0515(0.0485) Grad: 22684.2676  LR: 0.000017  \n",
      "Epoch: [1][1300/2850] Elapsed 7m 6s (remain 8m 28s) Loss: 0.0734(0.0477) Grad: 24207.9688  LR: 0.000018  \n",
      "Epoch: [1][1400/2850] Elapsed 7m 41s (remain 7m 56s) Loss: 0.0954(0.0470) Grad: 40401.9219  LR: 0.000020  \n",
      "Epoch: [1][1500/2850] Elapsed 8m 15s (remain 7m 24s) Loss: 0.0501(0.0465) Grad: 11506.7705  LR: 0.000020  \n",
      "Epoch: [1][1600/2850] Elapsed 8m 47s (remain 6m 51s) Loss: 0.0202(0.0457) Grad: 6785.8979  LR: 0.000020  \n",
      "Epoch: [1][1700/2850] Elapsed 9m 19s (remain 6m 18s) Loss: 0.0311(0.0454) Grad: 6744.3682  LR: 0.000020  \n",
      "Epoch: [1][1800/2850] Elapsed 9m 52s (remain 5m 45s) Loss: 0.0233(0.0450) Grad: 21670.3750  LR: 0.000019  \n",
      "Epoch: [1][1900/2850] Elapsed 10m 25s (remain 5m 12s) Loss: 0.0249(0.0447) Grad: 15830.5537  LR: 0.000019  \n",
      "Epoch: [1][2000/2850] Elapsed 10m 59s (remain 4m 39s) Loss: 0.0356(0.0443) Grad: 5781.9819  LR: 0.000019  \n",
      "Epoch: [1][2100/2850] Elapsed 11m 32s (remain 4m 6s) Loss: 0.0260(0.0439) Grad: 11599.1885  LR: 0.000019  \n",
      "Epoch: [1][2200/2850] Elapsed 12m 5s (remain 3m 33s) Loss: 0.0554(0.0435) Grad: 17366.1172  LR: 0.000019  \n",
      "Epoch: [1][2300/2850] Elapsed 12m 37s (remain 3m 0s) Loss: 0.0597(0.0433) Grad: 13128.2881  LR: 0.000019  \n",
      "Epoch: [1][2400/2850] Elapsed 13m 10s (remain 2m 27s) Loss: 0.0542(0.0429) Grad: 14540.5723  LR: 0.000018  \n",
      "Epoch: [1][2500/2850] Elapsed 13m 42s (remain 1m 54s) Loss: 0.1473(0.0426) Grad: 60673.2695  LR: 0.000018  \n",
      "Epoch: [1][2600/2850] Elapsed 14m 15s (remain 1m 21s) Loss: 0.0433(0.0424) Grad: 12508.7598  LR: 0.000018  \n",
      "Epoch: [1][2700/2850] Elapsed 14m 47s (remain 0m 48s) Loss: 0.0948(0.0423) Grad: 35432.7305  LR: 0.000018  \n",
      "Epoch: [1][2800/2850] Elapsed 15m 20s (remain 0m 16s) Loss: 0.0584(0.0422) Grad: 12355.9736  LR: 0.000018  \n",
      "Epoch: [1][2849/2850] Elapsed 15m 36s (remain 0m 0s) Loss: 0.0570(0.0421) Grad: 18428.9316  LR: 0.000018  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 47s) Loss: 0.0459(0.0459) \n",
      "EVAL: [100/725] Elapsed 0m 16s (remain 1m 39s) Loss: 0.0268(0.0377) \n",
      "EVAL: [200/725] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0806(0.0387) \n",
      "EVAL: [300/725] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0614(0.0386) \n",
      "EVAL: [400/725] Elapsed 1m 3s (remain 0m 50s) Loss: 0.1391(0.0405) \n",
      "EVAL: [500/725] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0615(0.0402) \n",
      "EVAL: [600/725] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0493(0.0400) \n",
      "EVAL: [700/725] Elapsed 1m 50s (remain 0m 3s) Loss: 0.0054(0.0384) \n",
      "EVAL: [724/725] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0297(0.0379) \n",
      "Epoch 1 - avg_train_loss: 0.0421  avg_val_loss: 0.0379  time: 1055s\n",
      "Epoch 1 - Score: 0.0000\n",
      "Epoch 1 - Save Best Score: 0.0000 Model\n",
      "Epoch: [2][0/2850] Elapsed 0m 0s (remain 30m 3s) Loss: 0.0492(0.0492) Grad: 15467.2373  LR: 0.000018  \n",
      "Epoch: [2][100/2850] Elapsed 0m 33s (remain 15m 17s) Loss: 0.0225(0.0393) Grad: 11051.0166  LR: 0.000018  \n",
      "Epoch: [2][200/2850] Elapsed 1m 6s (remain 14m 36s) Loss: 0.0640(0.0389) Grad: 21762.5352  LR: 0.000017  \n",
      "Epoch: [2][300/2850] Elapsed 1m 40s (remain 14m 8s) Loss: 0.0183(0.0379) Grad: 6216.7905  LR: 0.000017  \n",
      "Epoch: [2][400/2850] Elapsed 2m 14s (remain 13m 40s) Loss: 0.0341(0.0373) Grad: 9234.6416  LR: 0.000017  \n",
      "Epoch: [2][500/2850] Elapsed 2m 47s (remain 13m 4s) Loss: 0.0272(0.0372) Grad: 4162.9165  LR: 0.000017  \n",
      "Epoch: [2][600/2850] Elapsed 3m 20s (remain 12m 28s) Loss: 0.0484(0.0365) Grad: 11535.2812  LR: 0.000017  \n",
      "Epoch: [2][700/2850] Elapsed 3m 52s (remain 11m 54s) Loss: 0.0229(0.0361) Grad: 4840.3643  LR: 0.000017  \n",
      "Epoch: [2][800/2850] Elapsed 4m 25s (remain 11m 19s) Loss: 0.0435(0.0364) Grad: 5747.2412  LR: 0.000017  \n",
      "Epoch: [2][900/2850] Elapsed 4m 58s (remain 10m 46s) Loss: 0.0331(0.0362) Grad: 8042.9678  LR: 0.000016  \n",
      "Epoch: [2][1000/2850] Elapsed 5m 32s (remain 10m 14s) Loss: 0.0764(0.0363) Grad: 24242.7930  LR: 0.000016  \n",
      "Epoch: [2][1100/2850] Elapsed 6m 5s (remain 9m 40s) Loss: 0.0065(0.0362) Grad: 8233.5293  LR: 0.000016  \n",
      "Epoch: [2][1200/2850] Elapsed 6m 38s (remain 9m 6s) Loss: 0.0263(0.0362) Grad: 6188.9810  LR: 0.000016  \n",
      "Epoch: [2][1300/2850] Elapsed 7m 10s (remain 8m 32s) Loss: 0.0178(0.0363) Grad: 3681.3198  LR: 0.000016  \n",
      "Epoch: [2][1400/2850] Elapsed 7m 43s (remain 7m 59s) Loss: 0.0181(0.0363) Grad: 11688.8564  LR: 0.000016  \n",
      "Epoch: [2][1500/2850] Elapsed 8m 17s (remain 7m 27s) Loss: 0.0300(0.0365) Grad: 5983.8447  LR: 0.000015  \n",
      "Epoch: [2][1600/2850] Elapsed 8m 50s (remain 6m 53s) Loss: 0.0209(0.0364) Grad: 7555.2246  LR: 0.000015  \n",
      "Epoch: [2][1700/2850] Elapsed 9m 24s (remain 6m 20s) Loss: 0.0279(0.0361) Grad: 5073.9458  LR: 0.000015  \n",
      "Epoch: [2][1800/2850] Elapsed 9m 57s (remain 5m 47s) Loss: 0.0230(0.0362) Grad: 8751.6758  LR: 0.000015  \n",
      "Epoch: [2][1900/2850] Elapsed 10m 29s (remain 5m 14s) Loss: 0.0119(0.0362) Grad: 9402.5674  LR: 0.000015  \n",
      "Epoch: [2][2000/2850] Elapsed 11m 3s (remain 4m 41s) Loss: 0.0581(0.0361) Grad: 16321.1973  LR: 0.000015  \n",
      "Epoch: [2][2100/2850] Elapsed 11m 37s (remain 4m 8s) Loss: 0.0172(0.0359) Grad: 8921.3301  LR: 0.000015  \n",
      "Epoch: [2][2200/2850] Elapsed 12m 9s (remain 3m 35s) Loss: 0.0250(0.0359) Grad: 11680.6777  LR: 0.000014  \n",
      "Epoch: [2][2300/2850] Elapsed 12m 42s (remain 3m 1s) Loss: 0.0232(0.0359) Grad: 12475.7715  LR: 0.000014  \n",
      "Epoch: [2][2400/2850] Elapsed 13m 16s (remain 2m 28s) Loss: 0.0371(0.0360) Grad: 9980.2568  LR: 0.000014  \n",
      "Epoch: [2][2500/2850] Elapsed 13m 49s (remain 1m 55s) Loss: 0.0250(0.0360) Grad: 10083.8252  LR: 0.000014  \n",
      "Epoch: [2][2600/2850] Elapsed 14m 21s (remain 1m 22s) Loss: 0.0282(0.0360) Grad: 4688.6768  LR: 0.000014  \n",
      "Epoch: [2][2700/2850] Elapsed 14m 55s (remain 0m 49s) Loss: 0.0461(0.0360) Grad: 10052.5439  LR: 0.000014  \n",
      "Epoch: [2][2800/2850] Elapsed 15m 28s (remain 0m 16s) Loss: 0.0403(0.0359) Grad: 6741.9619  LR: 0.000013  \n",
      "Epoch: [2][2849/2850] Elapsed 15m 44s (remain 0m 0s) Loss: 0.0156(0.0359) Grad: 14804.5449  LR: 0.000013  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 34s) Loss: 0.0432(0.0432) \n",
      "EVAL: [100/725] Elapsed 0m 15s (remain 1m 38s) Loss: 0.0284(0.0347) \n",
      "EVAL: [200/725] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0683(0.0358) \n",
      "EVAL: [300/725] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0541(0.0357) \n",
      "EVAL: [400/725] Elapsed 1m 2s (remain 0m 50s) Loss: 0.1163(0.0373) \n",
      "EVAL: [500/725] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0546(0.0371) \n",
      "EVAL: [600/725] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0442(0.0370) \n",
      "EVAL: [700/725] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0079(0.0357) \n",
      "EVAL: [724/725] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0273(0.0353) \n",
      "Epoch 2 - avg_train_loss: 0.0359  avg_val_loss: 0.0353  time: 1063s\n",
      "Epoch 2 - Score: 0.0000\n",
      "Epoch: [3][0/2850] Elapsed 0m 0s (remain 29m 6s) Loss: 0.0458(0.0458) Grad: 6266.0894  LR: 0.000013  \n",
      "Epoch: [3][100/2850] Elapsed 0m 33s (remain 15m 18s) Loss: 0.0402(0.0323) Grad: 9081.8936  LR: 0.000013  \n",
      "Epoch: [3][200/2850] Elapsed 1m 7s (remain 14m 55s) Loss: 0.0208(0.0336) Grad: 5330.4253  LR: 0.000013  \n",
      "Epoch: [3][300/2850] Elapsed 1m 40s (remain 14m 10s) Loss: 0.0313(0.0346) Grad: 8048.2539  LR: 0.000013  \n",
      "Epoch: [3][400/2850] Elapsed 2m 12s (remain 13m 31s) Loss: 0.0270(0.0351) Grad: 5827.5859  LR: 0.000013  \n",
      "Epoch: [3][500/2850] Elapsed 2m 46s (remain 13m 0s) Loss: 0.0142(0.0349) Grad: 7159.5459  LR: 0.000013  \n",
      "Epoch: [3][600/2850] Elapsed 3m 19s (remain 12m 24s) Loss: 0.0236(0.0348) Grad: 8081.1538  LR: 0.000012  \n",
      "Epoch: [3][700/2850] Elapsed 3m 51s (remain 11m 49s) Loss: 0.0381(0.0348) Grad: 8910.0283  LR: 0.000012  \n",
      "Epoch: [3][800/2850] Elapsed 4m 25s (remain 11m 20s) Loss: 0.0576(0.0351) Grad: 17536.6367  LR: 0.000012  \n",
      "Epoch: [3][900/2850] Elapsed 4m 58s (remain 10m 45s) Loss: 0.0406(0.0350) Grad: 7900.4717  LR: 0.000012  \n",
      "Epoch: [3][1000/2850] Elapsed 5m 30s (remain 10m 10s) Loss: 0.1028(0.0349) Grad: 40074.8945  LR: 0.000012  \n",
      "Epoch: [3][1100/2850] Elapsed 6m 2s (remain 9m 36s) Loss: 0.0392(0.0350) Grad: 10407.8594  LR: 0.000012  \n",
      "Epoch: [3][1200/2850] Elapsed 6m 36s (remain 9m 3s) Loss: 0.0327(0.0349) Grad: 7943.2744  LR: 0.000011  \n",
      "Epoch: [3][1300/2850] Elapsed 7m 10s (remain 8m 32s) Loss: 0.0297(0.0350) Grad: 8019.1152  LR: 0.000011  \n",
      "Epoch: [3][1400/2850] Elapsed 7m 42s (remain 7m 58s) Loss: 0.0570(0.0349) Grad: 24509.0488  LR: 0.000011  \n",
      "Epoch: [3][1500/2850] Elapsed 8m 15s (remain 7m 25s) Loss: 0.0262(0.0350) Grad: 5121.4160  LR: 0.000011  \n",
      "Epoch: [3][1600/2850] Elapsed 8m 48s (remain 6m 52s) Loss: 0.0471(0.0349) Grad: 12820.6338  LR: 0.000011  \n",
      "Epoch: [3][1700/2850] Elapsed 9m 21s (remain 6m 19s) Loss: 0.0215(0.0347) Grad: 9901.0088  LR: 0.000011  \n",
      "Epoch: [3][1800/2850] Elapsed 9m 57s (remain 5m 47s) Loss: 0.0542(0.0346) Grad: 19498.5137  LR: 0.000011  \n",
      "Epoch: [3][1900/2850] Elapsed 10m 30s (remain 5m 14s) Loss: 0.0381(0.0345) Grad: 12676.3955  LR: 0.000010  \n",
      "Epoch: [3][2000/2850] Elapsed 11m 3s (remain 4m 41s) Loss: 0.0356(0.0346) Grad: 6847.2769  LR: 0.000010  \n",
      "Epoch: [3][2100/2850] Elapsed 11m 35s (remain 4m 7s) Loss: 0.0231(0.0346) Grad: 6925.5669  LR: 0.000010  \n",
      "Epoch: [3][2200/2850] Elapsed 12m 8s (remain 3m 34s) Loss: 0.0225(0.0345) Grad: 9810.6533  LR: 0.000010  \n",
      "Epoch: [3][2300/2850] Elapsed 12m 41s (remain 3m 1s) Loss: 0.0241(0.0345) Grad: 4795.1118  LR: 0.000010  \n",
      "Epoch: [3][2400/2850] Elapsed 13m 15s (remain 2m 28s) Loss: 0.0203(0.0345) Grad: 5811.9492  LR: 0.000010  \n",
      "Epoch: [3][2500/2850] Elapsed 13m 51s (remain 1m 55s) Loss: 0.0233(0.0345) Grad: 5769.9663  LR: 0.000009  \n",
      "Epoch: [3][2600/2850] Elapsed 14m 23s (remain 1m 22s) Loss: 0.0070(0.0345) Grad: 15011.8926  LR: 0.000009  \n",
      "Epoch: [3][2700/2850] Elapsed 14m 56s (remain 0m 49s) Loss: 0.0443(0.0345) Grad: 11132.1885  LR: 0.000009  \n",
      "Epoch: [3][2800/2850] Elapsed 15m 28s (remain 0m 16s) Loss: 0.0124(0.0344) Grad: 12084.9248  LR: 0.000009  \n",
      "Epoch: [3][2849/2850] Elapsed 15m 45s (remain 0m 0s) Loss: 0.0216(0.0344) Grad: 7732.8579  LR: 0.000009  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 6m 10s) Loss: 0.0430(0.0430) \n",
      "EVAL: [100/725] Elapsed 0m 16s (remain 1m 39s) Loss: 0.0269(0.0336) \n",
      "EVAL: [200/725] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0673(0.0351) \n",
      "EVAL: [300/725] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0556(0.0350) \n",
      "EVAL: [400/725] Elapsed 1m 2s (remain 0m 50s) Loss: 0.1276(0.0368) \n",
      "EVAL: [500/725] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0542(0.0365) \n",
      "EVAL: [600/725] Elapsed 1m 33s (remain 0m 19s) Loss: 0.0460(0.0364) \n",
      "EVAL: [700/725] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0063(0.0351) \n",
      "EVAL: [724/725] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0274(0.0347) \n",
      "Epoch 3 - avg_train_loss: 0.0344  avg_val_loss: 0.0347  time: 1063s\n",
      "Epoch 3 - Score: 0.0003\n",
      "Epoch 3 - Save Best Score: 0.0003 Model\n",
      "Epoch: [4][0/2850] Elapsed 0m 0s (remain 33m 31s) Loss: 0.0297(0.0297) Grad: 7636.3804  LR: 0.000009  \n",
      "Epoch: [4][100/2850] Elapsed 0m 33s (remain 15m 9s) Loss: 0.0523(0.0346) Grad: 12137.3438  LR: 0.000009  \n",
      "Epoch: [4][200/2850] Elapsed 1m 6s (remain 14m 36s) Loss: 0.0087(0.0357) Grad: 15769.5166  LR: 0.000009  \n",
      "Epoch: [4][300/2850] Elapsed 1m 39s (remain 14m 3s) Loss: 0.0232(0.0342) Grad: 7823.2334  LR: 0.000008  \n",
      "Epoch: [4][400/2850] Elapsed 2m 12s (remain 13m 28s) Loss: 0.0360(0.0339) Grad: 9653.9619  LR: 0.000008  \n",
      "Epoch: [4][500/2850] Elapsed 2m 45s (remain 12m 54s) Loss: 0.0197(0.0340) Grad: 9866.9316  LR: 0.000008  \n",
      "Epoch: [4][600/2850] Elapsed 3m 18s (remain 12m 23s) Loss: 0.0294(0.0344) Grad: 11150.9824  LR: 0.000008  \n",
      "Epoch: [4][700/2850] Elapsed 3m 52s (remain 11m 51s) Loss: 0.0254(0.0342) Grad: 6228.6245  LR: 0.000008  \n",
      "Epoch: [4][800/2850] Elapsed 4m 24s (remain 11m 17s) Loss: 0.0225(0.0340) Grad: 5812.9038  LR: 0.000008  \n",
      "Epoch: [4][900/2850] Elapsed 4m 57s (remain 10m 44s) Loss: 0.0287(0.0334) Grad: 9053.0186  LR: 0.000007  \n",
      "Epoch: [4][1000/2850] Elapsed 5m 32s (remain 10m 14s) Loss: 0.0328(0.0336) Grad: 7278.3760  LR: 0.000007  \n",
      "Epoch: [4][1100/2850] Elapsed 6m 5s (remain 9m 40s) Loss: 0.0334(0.0334) Grad: 9847.7051  LR: 0.000007  \n",
      "Epoch: [4][1200/2850] Elapsed 6m 38s (remain 9m 7s) Loss: 0.0649(0.0333) Grad: 26473.5449  LR: 0.000007  \n",
      "Epoch: [4][1300/2850] Elapsed 7m 11s (remain 8m 33s) Loss: 0.0290(0.0336) Grad: 10922.0840  LR: 0.000007  \n",
      "Epoch: [4][1400/2850] Elapsed 7m 44s (remain 8m 0s) Loss: 0.0318(0.0333) Grad: 7350.2070  LR: 0.000007  \n",
      "Epoch: [4][1500/2850] Elapsed 8m 17s (remain 7m 26s) Loss: 0.0497(0.0332) Grad: 20699.6973  LR: 0.000007  \n",
      "Epoch: [4][1600/2850] Elapsed 8m 49s (remain 6m 53s) Loss: 0.0571(0.0333) Grad: 22711.9023  LR: 0.000006  \n",
      "Epoch: [4][1700/2850] Elapsed 9m 21s (remain 6m 19s) Loss: 0.0099(0.0332) Grad: 9041.0195  LR: 0.000006  \n",
      "Epoch: [4][1800/2850] Elapsed 9m 55s (remain 5m 46s) Loss: 0.0188(0.0331) Grad: 6581.7778  LR: 0.000006  \n",
      "Epoch: [4][1900/2850] Elapsed 10m 27s (remain 5m 13s) Loss: 0.0318(0.0332) Grad: 9336.9365  LR: 0.000006  \n",
      "Epoch: [4][2000/2850] Elapsed 11m 0s (remain 4m 40s) Loss: 0.0385(0.0331) Grad: 14539.9941  LR: 0.000006  \n",
      "Epoch: [4][2100/2850] Elapsed 11m 34s (remain 4m 7s) Loss: 0.0093(0.0331) Grad: 7255.4971  LR: 0.000006  \n",
      "Epoch: [4][2200/2850] Elapsed 12m 6s (remain 3m 34s) Loss: 0.0176(0.0331) Grad: 8965.5205  LR: 0.000005  \n",
      "Epoch: [4][2300/2850] Elapsed 12m 39s (remain 3m 1s) Loss: 0.0282(0.0332) Grad: 8450.6875  LR: 0.000005  \n",
      "Epoch: [4][2400/2850] Elapsed 13m 11s (remain 2m 28s) Loss: 0.0139(0.0330) Grad: 9475.3018  LR: 0.000005  \n",
      "Epoch: [4][2500/2850] Elapsed 13m 44s (remain 1m 55s) Loss: 0.0667(0.0330) Grad: 27967.4551  LR: 0.000005  \n",
      "Epoch: [4][2600/2850] Elapsed 14m 17s (remain 1m 22s) Loss: 0.0573(0.0329) Grad: 27616.2109  LR: 0.000005  \n",
      "Epoch: [4][2700/2850] Elapsed 14m 50s (remain 0m 49s) Loss: 0.0371(0.0329) Grad: 12262.7822  LR: 0.000005  \n",
      "Epoch: [4][2800/2850] Elapsed 15m 22s (remain 0m 16s) Loss: 0.0261(0.0329) Grad: 10393.5771  LR: 0.000005  \n",
      "Epoch: [4][2849/2850] Elapsed 15m 38s (remain 0m 0s) Loss: 0.0193(0.0328) Grad: 9531.2393  LR: 0.000004  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 6m 9s) Loss: 0.0463(0.0463) \n",
      "EVAL: [100/725] Elapsed 0m 16s (remain 1m 39s) Loss: 0.0282(0.0336) \n",
      "EVAL: [200/725] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0629(0.0350) \n",
      "EVAL: [300/725] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0613(0.0347) \n",
      "EVAL: [400/725] Elapsed 1m 2s (remain 0m 50s) Loss: 0.1216(0.0365) \n",
      "EVAL: [500/725] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0524(0.0361) \n",
      "EVAL: [600/725] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0413(0.0358) \n",
      "EVAL: [700/725] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0049(0.0346) \n",
      "EVAL: [724/725] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0273(0.0342) \n",
      "Epoch 4 - avg_train_loss: 0.0328  avg_val_loss: 0.0342  time: 1057s\n",
      "Epoch 4 - Score: 0.0186\n",
      "Epoch 4 - Save Best Score: 0.0186 Model\n",
      "Epoch: [5][0/2850] Elapsed 0m 0s (remain 33m 41s) Loss: 0.0339(0.0339) Grad: 8967.6143  LR: 0.000004  \n",
      "Epoch: [5][100/2850] Elapsed 0m 35s (remain 16m 6s) Loss: 0.0272(0.0324) Grad: 9881.6758  LR: 0.000004  \n",
      "Epoch: [5][200/2850] Elapsed 1m 8s (remain 15m 0s) Loss: 0.0682(0.0318) Grad: 34940.7969  LR: 0.000004  \n",
      "Epoch: [5][300/2850] Elapsed 1m 40s (remain 14m 13s) Loss: 0.0582(0.0320) Grad: 26023.2656  LR: 0.000004  \n",
      "Epoch: [5][400/2850] Elapsed 2m 13s (remain 13m 34s) Loss: 0.0449(0.0326) Grad: 17543.6543  LR: 0.000004  \n",
      "Epoch: [5][500/2850] Elapsed 2m 45s (remain 12m 57s) Loss: 0.0697(0.0324) Grad: 22682.6367  LR: 0.000004  \n",
      "Epoch: [5][600/2850] Elapsed 3m 18s (remain 12m 23s) Loss: 0.0298(0.0319) Grad: 13834.4668  LR: 0.000004  \n",
      "Epoch: [5][700/2850] Elapsed 3m 51s (remain 11m 49s) Loss: 0.0411(0.0316) Grad: 13742.1553  LR: 0.000003  \n",
      "Epoch: [5][800/2850] Elapsed 4m 24s (remain 11m 15s) Loss: 0.0379(0.0319) Grad: 13509.4287  LR: 0.000003  \n",
      "Epoch: [5][900/2850] Elapsed 4m 57s (remain 10m 43s) Loss: 0.0159(0.0323) Grad: 11636.1289  LR: 0.000003  \n",
      "Epoch: [5][1000/2850] Elapsed 5m 30s (remain 10m 9s) Loss: 0.0871(0.0323) Grad: 41473.9180  LR: 0.000003  \n",
      "Epoch: [5][1100/2850] Elapsed 6m 2s (remain 9m 36s) Loss: 0.0179(0.0322) Grad: 13874.0039  LR: 0.000003  \n",
      "Epoch: [5][1200/2850] Elapsed 6m 35s (remain 9m 2s) Loss: 0.0153(0.0321) Grad: 9201.2598  LR: 0.000003  \n",
      "Epoch: [5][1300/2850] Elapsed 7m 8s (remain 8m 29s) Loss: 0.0164(0.0319) Grad: 13101.0908  LR: 0.000002  \n",
      "Epoch: [5][1400/2850] Elapsed 7m 41s (remain 7m 56s) Loss: 0.0673(0.0320) Grad: 31579.4824  LR: 0.000002  \n",
      "Epoch: [5][1500/2850] Elapsed 8m 15s (remain 7m 25s) Loss: 0.0222(0.0319) Grad: 9635.8086  LR: 0.000002  \n",
      "Epoch: [5][1600/2850] Elapsed 8m 48s (remain 6m 52s) Loss: 0.0243(0.0321) Grad: 10450.3525  LR: 0.000002  \n",
      "Epoch: [5][1700/2850] Elapsed 9m 21s (remain 6m 19s) Loss: 0.0106(0.0319) Grad: 10823.2285  LR: 0.000002  \n",
      "Epoch: [5][1800/2850] Elapsed 9m 53s (remain 5m 45s) Loss: 0.0179(0.0320) Grad: 7875.6382  LR: 0.000002  \n",
      "Epoch: [5][1900/2850] Elapsed 10m 26s (remain 5m 12s) Loss: 0.0201(0.0321) Grad: 9198.4355  LR: 0.000001  \n",
      "Epoch: [5][2000/2850] Elapsed 10m 58s (remain 4m 39s) Loss: 0.0237(0.0321) Grad: 9326.4297  LR: 0.000001  \n",
      "Epoch: [5][2100/2850] Elapsed 11m 31s (remain 4m 6s) Loss: 0.0346(0.0321) Grad: 9905.3018  LR: 0.000001  \n",
      "Epoch: [5][2200/2850] Elapsed 12m 4s (remain 3m 33s) Loss: 0.0651(0.0319) Grad: 29048.5781  LR: 0.000001  \n",
      "Epoch: [5][2300/2850] Elapsed 12m 37s (remain 3m 0s) Loss: 0.0345(0.0318) Grad: 12749.1436  LR: 0.000001  \n",
      "Epoch: [5][2400/2850] Elapsed 13m 10s (remain 2m 27s) Loss: 0.0789(0.0318) Grad: 38439.1016  LR: 0.000001  \n",
      "Epoch: [5][2500/2850] Elapsed 13m 43s (remain 1m 54s) Loss: 0.0379(0.0319) Grad: 16337.8350  LR: 0.000001  \n",
      "Epoch: [5][2600/2850] Elapsed 14m 17s (remain 1m 22s) Loss: 0.0298(0.0318) Grad: 10751.2998  LR: 0.000000  \n",
      "Epoch: [5][2700/2850] Elapsed 14m 50s (remain 0m 49s) Loss: 0.0240(0.0317) Grad: 13270.4570  LR: 0.000000  \n",
      "Epoch: [5][2800/2850] Elapsed 15m 22s (remain 0m 16s) Loss: 0.0385(0.0317) Grad: 11410.2334  LR: 0.000000  \n",
      "Epoch: [5][2849/2850] Elapsed 15m 38s (remain 0m 0s) Loss: 0.0409(0.0317) Grad: 15035.4854  LR: 0.000000  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 22s) Loss: 0.0446(0.0446) \n",
      "EVAL: [100/725] Elapsed 0m 16s (remain 1m 39s) Loss: 0.0279(0.0323) \n",
      "EVAL: [200/725] Elapsed 0m 31s (remain 1m 22s) Loss: 0.0571(0.0338) \n",
      "EVAL: [300/725] Elapsed 0m 47s (remain 1m 6s) Loss: 0.0583(0.0336) \n",
      "EVAL: [400/725] Elapsed 1m 2s (remain 0m 50s) Loss: 0.1230(0.0356) \n",
      "EVAL: [500/725] Elapsed 1m 18s (remain 0m 35s) Loss: 0.0491(0.0351) \n",
      "EVAL: [600/725] Elapsed 1m 34s (remain 0m 19s) Loss: 0.0429(0.0349) \n",
      "EVAL: [700/725] Elapsed 1m 49s (remain 0m 3s) Loss: 0.0055(0.0337) \n",
      "EVAL: [724/725] Elapsed 1m 53s (remain 0m 0s) Loss: 0.0276(0.0333) \n",
      "Epoch 5 - avg_train_loss: 0.0317  avg_val_loss: 0.0333  time: 1057s\n",
      "Epoch 5 - Score: 0.0301\n",
      "Epoch 5 - Save Best Score: 0.0301 Model\n",
      "Best thres: 0.5, Score: 0.0395\n",
      "Best thres: 0.09863281249999965, Score: 0.1861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e354e62e5c004e84a1bff41a44c0803d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af20b0cfa4714d3d86cb37baf5df9c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abab18279e84dab826dda52fa8f46c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e94291b49b94fee8fedfe49c9389538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597df5597eaa42b2865c1e47aa36b79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48efe7a963a4462b3499bf9ee91bf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp003.ipynb",
   "provenance": [
    {
     "file_id": "1k6U1erE6sYu9U7bfGdYhvEovwiTN0ehD",
     "timestamp": 1645625636482
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "079b2574766243d8a23f92570dbd1533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0934c9bd53b0406e9cf09f228d67c87e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27b7dcd8fbc8450eb6c510b3b2313dc3",
      "placeholder": "​",
      "style": "IPY_MODEL_a8d954da9d4b40549108b9c288061a05",
      "value": " 446k/446k [00:00&lt;00:00, 4.73MB/s]"
     }
    },
    "094cb1ec381449fba8d0669bc35917f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e1a0f5a4b01443c8602b850235bdcbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc94ea4b3f8b4e3584da1f151cd0e103",
      "placeholder": "​",
      "style": "IPY_MODEL_a16d54cd03bb478f96da89474b8e0074",
      "value": "100%"
     }
    },
    "0e721d1b98094e3fb391c77c74e06019": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_724392a8d4724dc98fd0b3c7273c693d",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9a771c7a74a4fc998b4d14db9a60100",
      "value": 42146
     }
    },
    "0f5b33bc213e47b39ea128bb3f2687ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f6a177c8f9d44e29c877783bd023862",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2daba5168eb42048830cb6010d64d43",
      "value": 456318
     }
    },
    "121f0221a8a449388deebec0ead6ef58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_079b2574766243d8a23f92570dbd1533",
      "placeholder": "​",
      "style": "IPY_MODEL_f5afd1b96eac4094b7a1d783cf9e6192",
      "value": " 52.0/52.0 [00:00&lt;00:00, 2.06kB/s]"
     }
    },
    "1240e074abae4cd7bee98a82b6acb493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d5785ea9e7140cc8e4144e1c714a548",
       "IPY_MODEL_eca43aa1df0b4a4782bb253a3623a838",
       "IPY_MODEL_121f0221a8a449388deebec0ead6ef58"
      ],
      "layout": "IPY_MODEL_426455dc60f34b4a9bba3919ceabc78b"
     }
    },
    "13a13b1845cc4259acc074970cb3168e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "166073c76ef54ab0bfa7606bba547fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5267216ad0344df89010b0317bd3334",
      "placeholder": "​",
      "style": "IPY_MODEL_e6a75dff1d394befa5d623ef2e48f89d",
      "value": "100%"
     }
    },
    "16dfaf81ac3f45b19a8ec4e7959a89d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb194c973adf479fab7d725f4d5efaff",
      "placeholder": "​",
      "style": "IPY_MODEL_28c54474f1d4498b8875825e5ca8bffa",
      "value": " 878k/878k [00:00&lt;00:00, 6.82MB/s]"
     }
    },
    "1c229d668fcc4097b1588a501934e619": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5ad1b8f2fb74dd5a56b1a935ebea106",
      "max": 898825,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f101287c0464ad88e5ed3fa8f26f948",
      "value": 898825
     }
    },
    "1e7d3e75b4d149209c30aa744bd4fc6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2ac13512d945c5821d461ba7b351ca",
      "placeholder": "​",
      "style": "IPY_MODEL_508c64fbb0624368a2796b165cc28837",
      "value": " 474/474 [00:00&lt;00:00, 19.6kB/s]"
     }
    },
    "23802b98bd184620bb7ee14fd4bb8556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0e1a0f5a4b01443c8602b850235bdcbf",
       "IPY_MODEL_0e721d1b98094e3fb391c77c74e06019",
       "IPY_MODEL_26a9df7de1914dc4ad1997e803513aad"
      ],
      "layout": "IPY_MODEL_dc4914db9bff475f947303c210f86731"
     }
    },
    "239cf276bdb947fea9b828055094e931": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "251a7e5a2c704ea38bcd9def4c0a1bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "264273174f4e4f6884a89dfe47402205": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26a9df7de1914dc4ad1997e803513aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_094cb1ec381449fba8d0669bc35917f2",
      "placeholder": "​",
      "style": "IPY_MODEL_7de976b196c04471bb4f8d53f73d9de6",
      "value": " 42146/42146 [00:21&lt;00:00, 2026.70it/s]"
     }
    },
    "27b7dcd8fbc8450eb6c510b3b2313dc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c54474f1d4498b8875825e5ca8bffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2bb15fefe29448e3b61c9e7de0e1fed3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f101287c0464ad88e5ed3fa8f26f948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3456bcab5db4469f8cf2127fb6154d8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e616a2fcd19e42a2a43e48d2b225c566",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5c3416c69504775af0ff33e9101a8ad",
      "value": 143
     }
    },
    "3771f967cbd94395abce58ca3c3b4340": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3efb0e72f3fb4e9389f170c6ba25304a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "426455dc60f34b4a9bba3919ceabc78b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42b6d0dc088541b4bafb28520bb67a11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_926e7f1cadb64f91b912d889d85f8bfe",
      "placeholder": "​",
      "style": "IPY_MODEL_dab2c4c56e3446578737b1efa0086ad3",
      "value": "Downloading: 100%"
     }
    },
    "49ff5f982cb2446487ce5d0c7886dd00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "508c64fbb0624368a2796b165cc28837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58dfc4d72c4b409899cbbcbf4d2adadd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b30914e5fe8d4a0898a9a180e3023593",
      "placeholder": "​",
      "style": "IPY_MODEL_749990b6bb24490b840efa59c6504336",
      "value": " 533M/533M [00:10&lt;00:00, 58.3MB/s]"
     }
    },
    "5c2ac13512d945c5821d461ba7b351ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63beac326cd4473098340ccec7fae7a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65892b37358e4e8d844c3081fe47639a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6acb6389a35747fe80ae529923369dcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce9dbfbda065477da4d7dafe3a389f03",
      "max": 558614189,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5771c13f32846c4b2cf616c8493fe39",
      "value": 558614189
     }
    },
    "6f6a177c8f9d44e29c877783bd023862": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "724392a8d4724dc98fd0b3c7273c693d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "749990b6bb24490b840efa59c6504336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76b633fd8cb644a491d7d10ead4885ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a36709849a204bb998f11338d3c17098",
      "placeholder": "​",
      "style": "IPY_MODEL_93454c251e14468b96dce46bdea4fdd0",
      "value": " 143/143 [00:00&lt;00:00, 3169.53it/s]"
     }
    },
    "774d7cf77c1840f8b3c5dba91c057258": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7de976b196c04471bb4f8d53f73d9de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80d784b724f844dbb2416d49dbf7d280": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13a13b1845cc4259acc074970cb3168e",
      "max": 474,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7862193e22d4fdda484ae0f71414163",
      "value": 474
     }
    },
    "83267a4bd06940c3a06b4d61425c4490": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_42b6d0dc088541b4bafb28520bb67a11",
       "IPY_MODEL_6acb6389a35747fe80ae529923369dcc",
       "IPY_MODEL_58dfc4d72c4b409899cbbcbf4d2adadd"
      ],
      "layout": "IPY_MODEL_63beac326cd4473098340ccec7fae7a8"
     }
    },
    "8d5785ea9e7140cc8e4144e1c714a548": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_239cf276bdb947fea9b828055094e931",
      "placeholder": "​",
      "style": "IPY_MODEL_e9e4a84d9114421d8a8ae6b3b026e842",
      "value": "Downloading: 100%"
     }
    },
    "8f0c338c4759472f9250d8f08b347d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae427a5b962e4b7b91668401a18e0dd5",
       "IPY_MODEL_1c229d668fcc4097b1588a501934e619",
       "IPY_MODEL_16dfaf81ac3f45b19a8ec4e7959a89d0"
      ],
      "layout": "IPY_MODEL_65892b37358e4e8d844c3081fe47639a"
     }
    },
    "926e7f1cadb64f91b912d889d85f8bfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93454c251e14468b96dce46bdea4fdd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a16d54cd03bb478f96da89474b8e0074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a36709849a204bb998f11338d3c17098": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5ad1b8f2fb74dd5a56b1a935ebea106": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8d954da9d4b40549108b9c288061a05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a928ded64c5341e598412cf5309e558c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae427a5b962e4b7b91668401a18e0dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a928ded64c5341e598412cf5309e558c",
      "placeholder": "​",
      "style": "IPY_MODEL_264273174f4e4f6884a89dfe47402205",
      "value": "Downloading: 100%"
     }
    },
    "b2daba5168eb42048830cb6010d64d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b30914e5fe8d4a0898a9a180e3023593": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b43b86df432c458f941c269460d19898": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9f3c3b86db74db7bef8fc86f2d246ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0a3ac7d83f44dd793039141a4485f52",
       "IPY_MODEL_0f5b33bc213e47b39ea128bb3f2687ed",
       "IPY_MODEL_0934c9bd53b0406e9cf09f228d67c87e"
      ],
      "layout": "IPY_MODEL_49ff5f982cb2446487ce5d0c7886dd00"
     }
    },
    "bb194c973adf479fab7d725f4d5efaff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc94ea4b3f8b4e3584da1f151cd0e103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5c3416c69504775af0ff33e9101a8ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c64066983b5c4aa688e22b41a2431341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_166073c76ef54ab0bfa7606bba547fa1",
       "IPY_MODEL_3456bcab5db4469f8cf2127fb6154d8a",
       "IPY_MODEL_76b633fd8cb644a491d7d10ead4885ef"
      ],
      "layout": "IPY_MODEL_774d7cf77c1840f8b3c5dba91c057258"
     }
    },
    "c9a771c7a74a4fc998b4d14db9a60100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce9dbfbda065477da4d7dafe3a389f03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5771c13f32846c4b2cf616c8493fe39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dab2c4c56e3446578737b1efa0086ad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc4914db9bff475f947303c210f86731": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0a3ac7d83f44dd793039141a4485f52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b43b86df432c458f941c269460d19898",
      "placeholder": "​",
      "style": "IPY_MODEL_251a7e5a2c704ea38bcd9def4c0a1bbe",
      "value": "Downloading: 100%"
     }
    },
    "e616a2fcd19e42a2a43e48d2b225c566": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6a75dff1d394befa5d623ef2e48f89d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9e4a84d9114421d8a8ae6b3b026e842": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eace1904db414e0cbaa2344a3bb308f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3efb0e72f3fb4e9389f170c6ba25304a",
      "placeholder": "​",
      "style": "IPY_MODEL_f9e1f3b203bb404fb6cf04957f6f4f40",
      "value": "Downloading: 100%"
     }
    },
    "ec2808cf5be240038c006801e0626fef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eca43aa1df0b4a4782bb253a3623a838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3771f967cbd94395abce58ca3c3b4340",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2bb15fefe29448e3b61c9e7de0e1fed3",
      "value": 52
     }
    },
    "ef70a47928e241f69a9b9c114a6ed384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eace1904db414e0cbaa2344a3bb308f5",
       "IPY_MODEL_80d784b724f844dbb2416d49dbf7d280",
       "IPY_MODEL_1e7d3e75b4d149209c30aa744bd4fc6c"
      ],
      "layout": "IPY_MODEL_ec2808cf5be240038c006801e0626fef"
     }
    },
    "f5267216ad0344df89010b0317bd3334": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5afd1b96eac4094b7a1d783cf9e6192": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7862193e22d4fdda484ae0f71414163": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9e1f3b203bb404fb6cf04957f6f4f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
