{"cells":[{"cell_type":"markdown","id":"colored-security","metadata":{"id":"colored-security"},"source":["## References"]},{"cell_type":"markdown","id":"educational-operator","metadata":{"id":"educational-operator"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"incorrect-greek","metadata":{"id":"incorrect-greek"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"alive-granny","metadata":{"id":"alive-granny","executionInfo":{"status":"ok","timestamp":1648963878727,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp071\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"heavy-prophet","metadata":{"id":"heavy-prophet","executionInfo":{"status":"ok","timestamp":1648963878728,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"vocational-coating","metadata":{"id":"vocational-coating","executionInfo":{"status":"ok","timestamp":1648963878728,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"private-moderator","metadata":{"id":"private-moderator"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"married-tokyo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"married-tokyo","outputId":"4e3b71f5-0333-45e4-c191-8b9ef2323afd","executionInfo":{"status":"ok","timestamp":1648963888432,"user_tz":-540,"elapsed":9712,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 65.4 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 79.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 79.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"blank-pierre","metadata":{"id":"blank-pierre","executionInfo":{"status":"ok","timestamp":1648963896763,"user_tz":-540,"elapsed":8336,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"sound-still","metadata":{"id":"sound-still"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"surprised-commercial","metadata":{"id":"surprised-commercial","executionInfo":{"status":"ok","timestamp":1648963896764,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"interstate-accident","metadata":{"id":"interstate-accident","executionInfo":{"status":"ok","timestamp":1648963896764,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"coated-pioneer","metadata":{"id":"coated-pioneer","executionInfo":{"status":"ok","timestamp":1648963896765,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"nervous-delaware","metadata":{"id":"nervous-delaware","executionInfo":{"status":"ok","timestamp":1648963896765,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"functioning-destruction","metadata":{"id":"functioning-destruction"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"global-monte","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"global-monte","outputId":"44cbcb2c-9006-42e9-8a2c-3a86b0542034","executionInfo":{"status":"ok","timestamp":1648963898546,"user_tz":-540,"elapsed":1789,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"independent-airfare","metadata":{"id":"independent-airfare","executionInfo":{"status":"ok","timestamp":1648963898547,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"silent-locator","metadata":{"id":"silent-locator"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"unusual-fifty","metadata":{"id":"unusual-fifty","executionInfo":{"status":"ok","timestamp":1648963898547,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"decreased-mustang","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"decreased-mustang","outputId":"5570ec56-c000-4311-e583-957fdb5dcfc1","executionInfo":{"status":"ok","timestamp":1648963898548,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"boolean-trade","metadata":{"id":"boolean-trade","executionInfo":{"status":"ok","timestamp":1648963898927,"user_tz":-540,"elapsed":383,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"accomplished-dakota","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"accomplished-dakota","outputId":"64428741-8a7f-419f-adfe-c57c37d8a0be","executionInfo":{"status":"ok","timestamp":1648963898928,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"funded-elizabeth","metadata":{"id":"funded-elizabeth"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"unexpected-columbia","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"unexpected-columbia","outputId":"6dcbe890-9d56-4e5e-e425-7238cdfc97af","executionInfo":{"status":"ok","timestamp":1648963898928,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"critical-archive","metadata":{"id":"critical-archive"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"broken-generator","metadata":{"id":"broken-generator","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["9fb7f6cc6c7f49299255aab12b7a4446","38765acbf3e645c9a6fbd735b14ed45d","eb88ab3ce3094c369269c38ef96ba2c0","191feabbe7eb478e82e166ba19fe2c24","9c5784d4767143d093bb24d778309e35","9df610d483504972a05ce85213898f1b","2e1236bfb05040218ca07b9f1c1b9cec","4bb882ffb50a43f99f923c2099e0c581","94a97d42f8f4474b826f29bf29858276","4d7aa6ec98334920aade6a9ac5514ef2","dc4a5300f2744199a132fe59d0fd0040","d9c9fcbac7e544499aaf30c579ccc9e0","29becb9692464f6e9da0819107d97312","dffbdf6285ae44259d740d271f2f2230","6e08326d01c44ce9854d9caf54420b40","f32e7ab085c64a25a20e40ec271aa0de","bbea311999444ff991cf827a737045c4","6fadcc2535234dc79602b4ff3a239696","8aaa81b3fead463282cae340a1b8b120","abf5467703a34442bb4dc9cae1bc5cfe","b7bc9fbb51a747f5926f54cdc332eed1","e5fba81603a24d339cf764c05971759d","7ad6c995e3b3478da93be5213e5604cd","a37b7a37eda34cbbab753394f67683b5","b82e4f34d5304ed1bef2278383160945","0106fbf194ac4b90868c07c03eeebe83","9ba7ec6669bf42228a4fecdc57b26327","7b5010681d7f4985b3e2a524c0c0fb60","d0dc082a7ae144a8879641b91ffff6f5","7976cea67b0a4fbabc60edcdfa29e0fc","57905f1975e2425b80b040dbc3256e02","0b03a196ad68421098e7c3a5eb57abd9","54825ae8089f4e129e59eb03a3aa03fe","812befa2af344c5cb9bace3b72043e41","b304cfc9adb54df58c3f8ec711ff24b6","4bcd248afdf64b338863f5340a96f189","0f703b0c433543f3a889f2d4f295602e","6fe978ac136740148401ceecd7701baa","937ef855282d4323bfb8c0e515243f6e","5d75b713791d4b79b96918d0fb92f062","b496d1cb368140e2a89b74552983631b","80f7b8f9ce7e4931a978da7e2cbcc9de","fc6625c85ecd4110a1b2ecf621c473c1","f060b75d46ff448f8a504a64d2bf8278"]},"executionInfo":{"status":"ok","timestamp":1648963900964,"user_tz":-540,"elapsed":2041,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"1986bf26-7bbb-405f-af60-fcc3ae9cc6bc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fb7f6cc6c7f49299255aab12b7a4446"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c9fcbac7e544499aaf30c579ccc9e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ad6c995e3b3478da93be5213e5604cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"812befa2af344c5cb9bace3b72043e41"}},"metadata":{}}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","id":"compatible-lincoln","metadata":{"id":"compatible-lincoln"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":18,"id":"fluid-nancy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["f06e1e3490d44e59803c4564f4af278b","ca57952ce30b465ca0be1c593f381213","d1a5a386a3e4412b91513277013ef85a","de2ab99046aa4d9f88374de9f3dbc58c","9e1b9cce113548f7996bebbd746cdacc","3c1a180a1ff14e3fa2a9dbd87e462075","9ac223816b984e1c838e9f49988bc7cc","c253c03d7b3c4615815cc68596c0e3fa","e4e787a7dcd24aa395bcbb90b62ee59b","a4dad4e487e14f9ab77dbdc5e66b62a5","938f51f9ee3d45bca42fdabd83d6e219"]},"id":"fluid-nancy","outputId":"6ee5f65e-a105-4b24-818d-af1a935f762f","executionInfo":{"status":"ok","timestamp":1648963922780,"user_tz":-540,"elapsed":21822,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06e1e3490d44e59803c4564f4af278b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":19,"id":"posted-humidity","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["8ca9ebd113134606bfac51f032cf543d","acfba18ac9c54b67815b46edd3227851","27cfc00781224f0784f59f030be9f2f4","886305916d4d4c86ac60d29d41cb453d","244fe41544cc435b82e7928b54d8ca69","234b7e741d674ccf90e695537820244f","d2e5b3bd3fb6466d9cc30e4b32a8b6fa","71521173672a4c6fa844875d22f732b7","0c367a1ceb6c434b8ae515be09aca78d","f270441732a94c788275442843caad44","4c482939850741dc842ea5a40182cfb2"]},"id":"posted-humidity","outputId":"9c1d8a05-3bbb-4fff-b276-99ef28945b65","executionInfo":{"status":"ok","timestamp":1648963922781,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ca9ebd113134606bfac51f032cf543d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":20,"id":"resistant-amount","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"resistant-amount","outputId":"abcd4099-9a16-440a-8785-6a650c0e5403","executionInfo":{"status":"ok","timestamp":1648963922781,"user_tz":-540,"elapsed":22,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":21,"id":"august-equity","metadata":{"id":"august-equity","executionInfo":{"status":"ok","timestamp":1648963922781,"user_tz":-540,"elapsed":19,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":22,"id":"weird-interaction","metadata":{"id":"weird-interaction","executionInfo":{"status":"ok","timestamp":1648963922782,"user_tz":-540,"elapsed":19,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"upper-mobility","metadata":{"id":"upper-mobility"},"source":["## Model"]},{"cell_type":"code","execution_count":23,"id":"spanish-destruction","metadata":{"id":"spanish-destruction","executionInfo":{"status":"ok","timestamp":1648963922782,"user_tz":-540,"elapsed":19,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"chronic-bullet","metadata":{"id":"chronic-bullet"},"source":["## Training"]},{"cell_type":"code","execution_count":24,"id":"biological-hunger","metadata":{"id":"biological-hunger","executionInfo":{"status":"ok","timestamp":1648963922782,"user_tz":-540,"elapsed":19,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":25,"id":"satisfied-sterling","metadata":{"id":"satisfied-sterling","executionInfo":{"status":"ok","timestamp":1648963922783,"user_tz":-540,"elapsed":19,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":26,"id":"incorporate-viking","metadata":{"id":"incorporate-viking","executionInfo":{"status":"ok","timestamp":1648963922783,"user_tz":-540,"elapsed":19,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":27,"id":"dental-sunset","metadata":{"id":"dental-sunset","executionInfo":{"status":"ok","timestamp":1648963923137,"user_tz":-540,"elapsed":373,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    pseudo_plain_path = './drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl'\n","    pseudo_plain = pd.read_pickle(pseudo_plain_path)\n","    pseudo_label_path = f'./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_{i_fold}.npy'\n","    pseudo_label = np.load(pseudo_label_path)\n","    print(f\"get pseudo plain from {pseudo_plain_path}\")\n","    print(f\"get pseudo labels from {pseudo_label_path}\")\n","    print(pseudo_plain.shape, pseudo_label.shape)\n","    pseudo_plain[\"pseudo_idx\"] = np.arange(len(pseudo_plain))\n","    pseudo_plain = pseudo_plain.sample(n=100000, random_state=i_fold)\n","    print(pseudo_plain.shape)\n","    train_folds = pd.concat([train_folds, pseudo_plain], axis=0, ignore_index=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","        ###### debug ##########################################\n","        break\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"brazilian-graphics","metadata":{"id":"brazilian-graphics"},"source":["## Main"]},{"cell_type":"code","execution_count":28,"id":"connected-protein","metadata":{"id":"connected-protein","executionInfo":{"status":"ok","timestamp":1648963923137,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":29,"id":"serious-bunny","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e431d5dc3af74962ad253b9504b27d79","db6f0f5f0e5a4dbe92ff94da5cd71834","2ed70549609141c7bd014bc8ff7c3e1d","eb17d941942f47bf9b6f577a20634f28","47ef2cea3cef43d1b2bdf2b1bcd29466","693495099db44129a3d6e7236eed43e1","498181a642224613b3537abae822a7f4","1f6929bad7b64f8d8a1bca5b6081996e","6a7802b5d9af4e3792d33cd9031f5208","1e993a06592e4e11bb2e1eb72bd0346e","d1f56e7a77d843d0a7bc3497f8449e5a","e50974b1fd624020aa44630c08bc0917","c34c0205a62a4601a49cbbffaa0057e4","2dfa6cf6daf9496cae81ef38a277b6da","dd0d234eef39400fb3ecb25312d0a699","c76b744a848c470ba621bf85b8ea47c1","6af218a889b642249e2f1bdc88fe71ec","61f5e52fe74b4140b73c0c1c415cc04a","b01f6faf0ec54d508a001d5cd799490e","bb59759353e94240a7ae2596c62108d8","b1b0a1a18b15449e9f615dda59ffe10b","c76fa15aacaf4bb7b0ba65de85197e30","797a8d464b1045b4a79eb77882772602","b5bfe8e3929a419a85d7cead29b50e29","eae738f025ca434ea2d065f3039c6991","16c12f61f69c4b61af7f1f23d2c175ad","7ed479d21fa24c6ca62df63c36f6dab4","3524e58f2aa2490392e038d0c3b19dd4","90ce5841a6c247c2926b85afed6ec4c5","14c095d88da1446eb50eaebe8ff5b0bd","f867686e60ec414585f3f74528497769","6a5c79c3d4ae4aa1b239e4e29fdaa55a","15c91f65b7ad40469a42b40b28d9220a","914e794d90fc44f8a8fd9d7f53907f5c","85232a0dd30440e3a02c20dae4b3e109","c2ab9e9f1bf548349bd5fd1935d12a65","33582456a96a4d11808c00e9c1f02b42","714f7875dfdc4ca2bbd29e417a613fe3","ac5f79056f0f474b97485f41302313ba","d8439090e62242b9af305cbae322e924","791c9e174a14474ab355c027fb9d0a6e","3c20812946f34db39c5c9f8ce557c2c9","97db6ef2bfdc4e1cbd255bfcb71bc3f6","f926b0eb4f52486eb08523e79dd44a1d","c52a94a7d81d48f49cfa41449fdee377","3617fd05c6bf493680d1471911a2b4e3","e1c576aa7a30453cbc345a4090ba2306","0e4bfc44810445328ddb62023013c3b5","4170592f14814e549d2cd4db7e0689b8","d4bfc64588134d699ff2106291d78cb2","eb324daf042e4b44a6406be4e2256396","ae248e58ab3840d69e7a0ba9ac9fdaf1","8cf2c57874f04a809c99e31c9211fc3d","1c8452b7fa584809b4524edce44d049f","2eaa7c2b4cc34566b69b1d2ae1499a3d"]},"id":"serious-bunny","outputId":"c8ec677b-2770-47ac-b1d2-c0876750a9e7","executionInfo":{"status":"ok","timestamp":1648995856482,"user_tz":-540,"elapsed":31933348,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_0.npy\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/36908] Elapsed 0m 0s (remain 466m 21s) Loss: 0.3183(0.3183) Grad: 213333.1875  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 21s (remain 132m 36s) Loss: 0.3020(0.3114) Grad: 24159.2227  LR: 0.000000  \n","Epoch: [1][200/36908] Elapsed 0m 42s (remain 129m 19s) Loss: 0.2609(0.3013) Grad: 10499.1514  LR: 0.000000  \n","Epoch: [1][300/36908] Elapsed 1m 3s (remain 128m 8s) Loss: 0.2275(0.2841) Grad: 9583.3164  LR: 0.000000  \n","Epoch: [1][400/36908] Elapsed 1m 23s (remain 127m 17s) Loss: 0.1659(0.2627) Grad: 8101.9893  LR: 0.000000  \n","Epoch: [1][500/36908] Elapsed 1m 44s (remain 126m 50s) Loss: 0.1162(0.2392) Grad: 6118.6450  LR: 0.000001  \n","Epoch: [1][600/36908] Elapsed 2m 5s (remain 126m 17s) Loss: 0.0630(0.2147) Grad: 3675.2273  LR: 0.000001  \n","Epoch: [1][700/36908] Elapsed 2m 26s (remain 125m 51s) Loss: 0.0119(0.1898) Grad: 577.3410  LR: 0.000001  \n","Epoch: [1][800/36908] Elapsed 2m 46s (remain 125m 23s) Loss: 0.0016(0.1675) Grad: 131.3566  LR: 0.000001  \n","Epoch: [1][900/36908] Elapsed 3m 7s (remain 125m 2s) Loss: 0.0103(0.1495) Grad: 114.4356  LR: 0.000001  \n","Epoch: [1][1000/36908] Elapsed 3m 28s (remain 124m 38s) Loss: 0.0448(0.1352) Grad: 552.6905  LR: 0.000001  \n","Epoch: [1][1100/36908] Elapsed 3m 49s (remain 124m 11s) Loss: 0.0007(0.1234) Grad: 65.1126  LR: 0.000001  \n","Epoch: [1][1200/36908] Elapsed 4m 9s (remain 123m 45s) Loss: 0.0009(0.1136) Grad: 77.4682  LR: 0.000001  \n","Epoch: [1][1300/36908] Elapsed 4m 30s (remain 123m 20s) Loss: 0.0005(0.1051) Grad: 39.7760  LR: 0.000001  \n","Epoch: [1][1400/36908] Elapsed 4m 51s (remain 122m 56s) Loss: 0.0006(0.0979) Grad: 49.4110  LR: 0.000002  \n","Epoch: [1][1500/36908] Elapsed 5m 11s (remain 122m 32s) Loss: 0.0008(0.0917) Grad: 63.7614  LR: 0.000002  \n","Epoch: [1][1600/36908] Elapsed 5m 32s (remain 122m 8s) Loss: 0.0869(0.0864) Grad: 1057.1696  LR: 0.000002  \n","Epoch: [1][1700/36908] Elapsed 5m 52s (remain 121m 45s) Loss: 0.0140(0.0816) Grad: 158.5032  LR: 0.000002  \n","Epoch: [1][1800/36908] Elapsed 6m 13s (remain 121m 22s) Loss: 0.0004(0.0772) Grad: 31.7957  LR: 0.000002  \n","Epoch: [1][1900/36908] Elapsed 6m 34s (remain 121m 2s) Loss: 0.0009(0.0734) Grad: 72.7282  LR: 0.000002  \n","Epoch: [1][2000/36908] Elapsed 6m 54s (remain 120m 39s) Loss: 0.0013(0.0701) Grad: 97.2206  LR: 0.000002  \n","Epoch: [1][2100/36908] Elapsed 7m 15s (remain 120m 16s) Loss: 0.0006(0.0670) Grad: 47.6507  LR: 0.000002  \n","Epoch: [1][2200/36908] Elapsed 7m 36s (remain 119m 54s) Loss: 0.0003(0.0641) Grad: 28.5689  LR: 0.000002  \n","Epoch: [1][2300/36908] Elapsed 7m 56s (remain 119m 31s) Loss: 0.0003(0.0614) Grad: 27.9631  LR: 0.000002  \n","Epoch: [1][2400/36908] Elapsed 8m 17s (remain 119m 9s) Loss: 0.0004(0.0591) Grad: 30.0824  LR: 0.000003  \n","Epoch: [1][2500/36908] Elapsed 8m 38s (remain 118m 47s) Loss: 0.0003(0.0568) Grad: 27.3804  LR: 0.000003  \n","Epoch: [1][2600/36908] Elapsed 8m 58s (remain 118m 25s) Loss: 0.0004(0.0549) Grad: 35.1364  LR: 0.000003  \n","Epoch: [1][2700/36908] Elapsed 9m 19s (remain 118m 4s) Loss: 0.0004(0.0531) Grad: 36.7635  LR: 0.000003  \n","Epoch: [1][2800/36908] Elapsed 9m 40s (remain 117m 42s) Loss: 0.0112(0.0514) Grad: 144.1442  LR: 0.000003  \n","Epoch: [1][2900/36908] Elapsed 10m 0s (remain 117m 21s) Loss: 0.0011(0.0498) Grad: 87.8614  LR: 0.000003  \n","Epoch: [1][3000/36908] Elapsed 10m 21s (remain 117m 0s) Loss: 0.0004(0.0482) Grad: 38.3970  LR: 0.000003  \n","Epoch: [1][3100/36908] Elapsed 10m 42s (remain 116m 39s) Loss: 0.0001(0.0467) Grad: 12.4963  LR: 0.000003  \n","Epoch: [1][3200/36908] Elapsed 11m 2s (remain 116m 18s) Loss: 0.0005(0.0454) Grad: 45.1653  LR: 0.000003  \n","Epoch: [1][3300/36908] Elapsed 11m 23s (remain 115m 59s) Loss: 0.0005(0.0441) Grad: 48.7014  LR: 0.000004  \n","Epoch: [1][3400/36908] Elapsed 11m 44s (remain 115m 38s) Loss: 0.0057(0.0430) Grad: 129.3737  LR: 0.000004  \n","Epoch: [1][3500/36908] Elapsed 12m 4s (remain 115m 17s) Loss: 0.0006(0.0418) Grad: 62.8353  LR: 0.000004  \n","Epoch: [1][3600/36908] Elapsed 12m 25s (remain 114m 56s) Loss: 0.0002(0.0408) Grad: 22.6904  LR: 0.000004  \n","Epoch: [1][3700/36908] Elapsed 12m 46s (remain 114m 35s) Loss: 0.0000(0.0397) Grad: 9.4474  LR: 0.000004  \n","Epoch: [1][3800/36908] Elapsed 13m 6s (remain 114m 14s) Loss: 0.0004(0.0388) Grad: 53.6219  LR: 0.000004  \n","Epoch: [1][3900/36908] Elapsed 13m 27s (remain 113m 53s) Loss: 0.0003(0.0379) Grad: 46.7051  LR: 0.000004  \n","Epoch: [1][4000/36908] Elapsed 13m 48s (remain 113m 34s) Loss: 0.0003(0.0371) Grad: 33.9332  LR: 0.000004  \n","Epoch: [1][4100/36908] Elapsed 14m 9s (remain 113m 14s) Loss: 0.0005(0.0363) Grad: 66.4725  LR: 0.000004  \n","Epoch: [1][4200/36908] Elapsed 14m 30s (remain 112m 53s) Loss: 0.0010(0.0355) Grad: 133.6340  LR: 0.000005  \n","Epoch: [1][4300/36908] Elapsed 14m 50s (remain 112m 32s) Loss: 0.0004(0.0348) Grad: 43.4955  LR: 0.000005  \n","Epoch: [1][4400/36908] Elapsed 15m 11s (remain 112m 11s) Loss: 0.0003(0.0341) Grad: 29.4723  LR: 0.000005  \n","Epoch: [1][4500/36908] Elapsed 15m 32s (remain 111m 50s) Loss: 0.0003(0.0334) Grad: 25.0906  LR: 0.000005  \n","Epoch: [1][4600/36908] Elapsed 15m 52s (remain 111m 29s) Loss: 0.0002(0.0328) Grad: 25.2181  LR: 0.000005  \n","Epoch: [1][4700/36908] Elapsed 16m 13s (remain 111m 9s) Loss: 0.0002(0.0321) Grad: 36.8988  LR: 0.000005  \n","Epoch: [1][4800/36908] Elapsed 16m 34s (remain 110m 48s) Loss: 0.0086(0.0315) Grad: 879.3533  LR: 0.000005  \n","Epoch: [1][4900/36908] Elapsed 16m 54s (remain 110m 26s) Loss: 0.0002(0.0309) Grad: 39.8713  LR: 0.000005  \n","Epoch: [1][5000/36908] Elapsed 17m 15s (remain 110m 5s) Loss: 0.0010(0.0304) Grad: 156.9435  LR: 0.000005  \n","Epoch: [1][5100/36908] Elapsed 17m 36s (remain 109m 44s) Loss: 0.0010(0.0298) Grad: 155.4232  LR: 0.000006  \n","Epoch: [1][5200/36908] Elapsed 17m 56s (remain 109m 24s) Loss: 0.0004(0.0293) Grad: 74.3840  LR: 0.000006  \n","Epoch: [1][5300/36908] Elapsed 18m 17s (remain 109m 3s) Loss: 0.0001(0.0288) Grad: 33.3099  LR: 0.000006  \n","Epoch: [1][5400/36908] Elapsed 18m 38s (remain 108m 42s) Loss: 0.0005(0.0283) Grad: 80.9142  LR: 0.000006  \n","Epoch: [1][5500/36908] Elapsed 18m 58s (remain 108m 21s) Loss: 0.0002(0.0279) Grad: 43.6352  LR: 0.000006  \n","Epoch: [1][5600/36908] Elapsed 19m 19s (remain 108m 1s) Loss: 0.0069(0.0274) Grad: 432.3664  LR: 0.000006  \n","Epoch: [1][5700/36908] Elapsed 19m 40s (remain 107m 40s) Loss: 0.0006(0.0270) Grad: 96.9350  LR: 0.000006  \n","Epoch: [1][5800/36908] Elapsed 20m 1s (remain 107m 20s) Loss: 0.0002(0.0266) Grad: 28.3677  LR: 0.000006  \n","Epoch: [1][5900/36908] Elapsed 20m 21s (remain 106m 59s) Loss: 0.0149(0.0262) Grad: 852.3786  LR: 0.000006  \n","Epoch: [1][6000/36908] Elapsed 20m 42s (remain 106m 39s) Loss: 0.0004(0.0259) Grad: 64.1609  LR: 0.000007  \n","Epoch: [1][6100/36908] Elapsed 21m 3s (remain 106m 19s) Loss: 0.0007(0.0255) Grad: 102.1084  LR: 0.000007  \n","Epoch: [1][6200/36908] Elapsed 21m 24s (remain 105m 58s) Loss: 0.0006(0.0251) Grad: 86.2739  LR: 0.000007  \n","Epoch: [1][6300/36908] Elapsed 21m 44s (remain 105m 38s) Loss: 0.0008(0.0248) Grad: 113.4870  LR: 0.000007  \n","Epoch: [1][6400/36908] Elapsed 22m 5s (remain 105m 18s) Loss: 0.0005(0.0244) Grad: 70.0105  LR: 0.000007  \n","Epoch: [1][6500/36908] Elapsed 22m 26s (remain 104m 57s) Loss: 0.0118(0.0241) Grad: 911.6146  LR: 0.000007  \n","Epoch: [1][6600/36908] Elapsed 22m 47s (remain 104m 37s) Loss: 0.0014(0.0238) Grad: 230.0822  LR: 0.000007  \n","Epoch: [1][6700/36908] Elapsed 23m 8s (remain 104m 16s) Loss: 0.0002(0.0235) Grad: 38.0730  LR: 0.000007  \n","Epoch: [1][6800/36908] Elapsed 23m 28s (remain 103m 56s) Loss: 0.0009(0.0232) Grad: 126.9232  LR: 0.000007  \n","Epoch: [1][6900/36908] Elapsed 23m 49s (remain 103m 35s) Loss: 0.0006(0.0229) Grad: 72.9715  LR: 0.000007  \n","Epoch: [1][7000/36908] Elapsed 24m 10s (remain 103m 15s) Loss: 0.0003(0.0226) Grad: 37.0503  LR: 0.000008  \n","Epoch: [1][7100/36908] Elapsed 24m 30s (remain 102m 54s) Loss: 0.0001(0.0224) Grad: 25.9179  LR: 0.000008  \n","Epoch: [1][7200/36908] Elapsed 24m 51s (remain 102m 34s) Loss: 0.0004(0.0221) Grad: 62.4794  LR: 0.000008  \n","Epoch: [1][7300/36908] Elapsed 25m 12s (remain 102m 13s) Loss: 0.0003(0.0218) Grad: 57.3096  LR: 0.000008  \n","Epoch: [1][7400/36908] Elapsed 25m 33s (remain 101m 53s) Loss: 0.0005(0.0216) Grad: 65.6582  LR: 0.000008  \n","Epoch: [1][7500/36908] Elapsed 25m 54s (remain 101m 33s) Loss: 0.0002(0.0214) Grad: 24.8841  LR: 0.000008  \n","Epoch: [1][7600/36908] Elapsed 26m 15s (remain 101m 12s) Loss: 0.0004(0.0211) Grad: 81.2432  LR: 0.000008  \n","Epoch: [1][7700/36908] Elapsed 26m 35s (remain 100m 51s) Loss: 0.0015(0.0209) Grad: 217.1626  LR: 0.000008  \n","Epoch: [1][7800/36908] Elapsed 26m 56s (remain 100m 31s) Loss: 0.0068(0.0207) Grad: 521.1882  LR: 0.000008  \n","Epoch: [1][7900/36908] Elapsed 27m 17s (remain 100m 10s) Loss: 0.0001(0.0205) Grad: 21.1182  LR: 0.000009  \n","Epoch: [1][8000/36908] Elapsed 27m 37s (remain 99m 49s) Loss: 0.0007(0.0202) Grad: 105.0389  LR: 0.000009  \n","Epoch: [1][8100/36908] Elapsed 27m 58s (remain 99m 28s) Loss: 0.0009(0.0200) Grad: 119.4138  LR: 0.000009  \n","Epoch: [1][8200/36908] Elapsed 28m 19s (remain 99m 8s) Loss: 0.0003(0.0198) Grad: 46.8228  LR: 0.000009  \n","Epoch: [1][8300/36908] Elapsed 28m 40s (remain 98m 47s) Loss: 0.0005(0.0196) Grad: 69.4816  LR: 0.000009  \n","Epoch: [1][8400/36908] Elapsed 29m 0s (remain 98m 26s) Loss: 0.0172(0.0194) Grad: 669.8640  LR: 0.000009  \n","Epoch: [1][8500/36908] Elapsed 29m 21s (remain 98m 6s) Loss: 0.0004(0.0192) Grad: 106.9379  LR: 0.000009  \n","Epoch: [1][8600/36908] Elapsed 29m 42s (remain 97m 45s) Loss: 0.0008(0.0190) Grad: 87.9844  LR: 0.000009  \n","Epoch: [1][8700/36908] Elapsed 30m 2s (remain 97m 24s) Loss: 0.0002(0.0188) Grad: 47.6104  LR: 0.000009  \n","Epoch: [1][8800/36908] Elapsed 30m 23s (remain 97m 3s) Loss: 0.0003(0.0186) Grad: 104.4054  LR: 0.000010  \n","Epoch: [1][8900/36908] Elapsed 30m 44s (remain 96m 42s) Loss: 0.0052(0.0185) Grad: 473.8858  LR: 0.000010  \n","Epoch: [1][9000/36908] Elapsed 31m 4s (remain 96m 22s) Loss: 0.0479(0.0183) Grad: 3824.8591  LR: 0.000010  \n","Epoch: [1][9100/36908] Elapsed 31m 25s (remain 96m 1s) Loss: 0.0022(0.0182) Grad: 275.2130  LR: 0.000010  \n","Epoch: [1][9200/36908] Elapsed 31m 46s (remain 95m 40s) Loss: 0.0066(0.0180) Grad: 842.9666  LR: 0.000010  \n","Epoch: [1][9300/36908] Elapsed 32m 6s (remain 95m 19s) Loss: 0.0009(0.0179) Grad: 269.3289  LR: 0.000010  \n","Epoch: [1][9400/36908] Elapsed 32m 27s (remain 94m 58s) Loss: 0.0003(0.0177) Grad: 97.1664  LR: 0.000010  \n","Epoch: [1][9500/36908] Elapsed 32m 48s (remain 94m 37s) Loss: 0.0002(0.0176) Grad: 58.4985  LR: 0.000010  \n","Epoch: [1][9600/36908] Elapsed 33m 8s (remain 94m 16s) Loss: 0.0002(0.0174) Grad: 53.8208  LR: 0.000010  \n","Epoch: [1][9700/36908] Elapsed 33m 29s (remain 93m 55s) Loss: 0.0008(0.0173) Grad: 235.7299  LR: 0.000011  \n","Epoch: [1][9800/36908] Elapsed 33m 50s (remain 93m 35s) Loss: 0.0006(0.0171) Grad: 139.4041  LR: 0.000011  \n","Epoch: [1][9900/36908] Elapsed 34m 10s (remain 93m 14s) Loss: 0.0005(0.0170) Grad: 126.1685  LR: 0.000011  \n","Epoch: [1][10000/36908] Elapsed 34m 31s (remain 92m 53s) Loss: 0.0003(0.0169) Grad: 73.8103  LR: 0.000011  \n","Epoch: [1][10100/36908] Elapsed 34m 52s (remain 92m 32s) Loss: 0.0001(0.0167) Grad: 42.6232  LR: 0.000011  \n","Epoch: [1][10200/36908] Elapsed 35m 12s (remain 92m 11s) Loss: 0.0006(0.0166) Grad: 133.3395  LR: 0.000011  \n","Epoch: [1][10300/36908] Elapsed 35m 33s (remain 91m 51s) Loss: 0.0006(0.0165) Grad: 128.2252  LR: 0.000011  \n","Epoch: [1][10400/36908] Elapsed 35m 54s (remain 91m 30s) Loss: 0.0000(0.0163) Grad: 9.8055  LR: 0.000011  \n","Epoch: [1][10500/36908] Elapsed 36m 15s (remain 91m 9s) Loss: 0.0003(0.0162) Grad: 84.6898  LR: 0.000011  \n","Epoch: [1][10600/36908] Elapsed 36m 35s (remain 90m 48s) Loss: 0.0004(0.0161) Grad: 111.1029  LR: 0.000011  \n","Epoch: [1][10700/36908] Elapsed 36m 56s (remain 90m 27s) Loss: 0.0001(0.0160) Grad: 46.9361  LR: 0.000012  \n","Epoch: [1][10800/36908] Elapsed 37m 17s (remain 90m 7s) Loss: 0.0001(0.0158) Grad: 50.0104  LR: 0.000012  \n","Epoch: [1][10900/36908] Elapsed 37m 37s (remain 89m 46s) Loss: 0.0003(0.0157) Grad: 87.8919  LR: 0.000012  \n","Epoch: [1][11000/36908] Elapsed 37m 58s (remain 89m 25s) Loss: 0.0006(0.0156) Grad: 239.2915  LR: 0.000012  \n","Epoch: [1][11100/36908] Elapsed 38m 19s (remain 89m 4s) Loss: 0.0003(0.0155) Grad: 104.5598  LR: 0.000012  \n","Epoch: [1][11200/36908] Elapsed 38m 39s (remain 88m 43s) Loss: 0.0011(0.0154) Grad: 263.1501  LR: 0.000012  \n","Epoch: [1][11300/36908] Elapsed 39m 0s (remain 88m 22s) Loss: 0.0003(0.0153) Grad: 98.7095  LR: 0.000012  \n","Epoch: [1][11400/36908] Elapsed 39m 20s (remain 88m 2s) Loss: 0.0150(0.0152) Grad: 1635.4574  LR: 0.000012  \n","Epoch: [1][11500/36908] Elapsed 39m 41s (remain 87m 41s) Loss: 0.0004(0.0151) Grad: 139.3920  LR: 0.000012  \n","Epoch: [1][11600/36908] Elapsed 40m 2s (remain 87m 20s) Loss: 0.0264(0.0149) Grad: 2748.7354  LR: 0.000013  \n","Epoch: [1][11700/36908] Elapsed 40m 23s (remain 86m 59s) Loss: 0.0005(0.0149) Grad: 122.4762  LR: 0.000013  \n","Epoch: [1][11800/36908] Elapsed 40m 43s (remain 86m 39s) Loss: 0.0004(0.0148) Grad: 88.1830  LR: 0.000013  \n","Epoch: [1][11900/36908] Elapsed 41m 4s (remain 86m 18s) Loss: 0.0002(0.0147) Grad: 44.0592  LR: 0.000013  \n","Epoch: [1][12000/36908] Elapsed 41m 25s (remain 85m 57s) Loss: 0.0003(0.0146) Grad: 79.1227  LR: 0.000013  \n","Epoch: [1][12100/36908] Elapsed 41m 45s (remain 85m 36s) Loss: 0.0004(0.0145) Grad: 126.2123  LR: 0.000013  \n","Epoch: [1][12200/36908] Elapsed 42m 6s (remain 85m 15s) Loss: 0.0000(0.0144) Grad: 26.6739  LR: 0.000013  \n","Epoch: [1][12300/36908] Elapsed 42m 26s (remain 84m 54s) Loss: 0.0004(0.0143) Grad: 102.4118  LR: 0.000013  \n","Epoch: [1][12400/36908] Elapsed 42m 47s (remain 84m 34s) Loss: 0.0046(0.0142) Grad: 365.0092  LR: 0.000013  \n","Epoch: [1][12500/36908] Elapsed 43m 8s (remain 84m 13s) Loss: 0.0002(0.0141) Grad: 46.3857  LR: 0.000014  \n","Epoch: [1][12600/36908] Elapsed 43m 28s (remain 83m 52s) Loss: 0.0002(0.0140) Grad: 42.4920  LR: 0.000014  \n","Epoch: [1][12700/36908] Elapsed 43m 49s (remain 83m 31s) Loss: 0.0001(0.0139) Grad: 36.2329  LR: 0.000014  \n","Epoch: [1][12800/36908] Elapsed 44m 10s (remain 83m 10s) Loss: 0.0000(0.0139) Grad: 38.0620  LR: 0.000014  \n","Epoch: [1][12900/36908] Elapsed 44m 30s (remain 82m 50s) Loss: 0.0002(0.0138) Grad: 132.9842  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 44m 51s (remain 82m 29s) Loss: 0.0004(0.0137) Grad: 152.1811  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 45m 12s (remain 82m 8s) Loss: 0.0004(0.0136) Grad: 173.1579  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 45m 32s (remain 81m 47s) Loss: 0.0003(0.0135) Grad: 126.1542  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 45m 53s (remain 81m 27s) Loss: 0.0001(0.0134) Grad: 53.8109  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 46m 14s (remain 81m 6s) Loss: 0.0041(0.0134) Grad: 745.3278  LR: 0.000015  \n","Epoch: [1][13500/36908] Elapsed 46m 34s (remain 80m 45s) Loss: 0.0004(0.0133) Grad: 177.7583  LR: 0.000015  \n","Epoch: [1][13600/36908] Elapsed 46m 55s (remain 80m 24s) Loss: 0.0001(0.0132) Grad: 46.2233  LR: 0.000015  \n","Epoch: [1][13700/36908] Elapsed 47m 16s (remain 80m 3s) Loss: 0.0001(0.0132) Grad: 69.4784  LR: 0.000015  \n","Epoch: [1][13800/36908] Elapsed 47m 36s (remain 79m 42s) Loss: 0.0006(0.0131) Grad: 276.9521  LR: 0.000015  \n","Epoch: [1][13900/36908] Elapsed 47m 57s (remain 79m 22s) Loss: 0.0023(0.0130) Grad: 1787.0575  LR: 0.000015  \n","Epoch: [1][14000/36908] Elapsed 48m 18s (remain 79m 1s) Loss: 0.0001(0.0130) Grad: 74.7846  LR: 0.000015  \n","Epoch: [1][14100/36908] Elapsed 48m 38s (remain 78m 40s) Loss: 0.0006(0.0129) Grad: 209.3770  LR: 0.000015  \n","Epoch: [1][14200/36908] Elapsed 48m 59s (remain 78m 20s) Loss: 0.0079(0.0128) Grad: 1292.5386  LR: 0.000015  \n","Epoch: [1][14300/36908] Elapsed 49m 20s (remain 77m 59s) Loss: 0.0003(0.0128) Grad: 186.7640  LR: 0.000015  \n","Epoch: [1][14400/36908] Elapsed 49m 40s (remain 77m 38s) Loss: 0.0002(0.0127) Grad: 118.0486  LR: 0.000016  \n","Epoch: [1][14500/36908] Elapsed 50m 1s (remain 77m 17s) Loss: 0.0002(0.0126) Grad: 186.2781  LR: 0.000016  \n","Epoch: [1][14600/36908] Elapsed 50m 22s (remain 76m 57s) Loss: 0.0000(0.0126) Grad: 29.0029  LR: 0.000016  \n","Epoch: [1][14700/36908] Elapsed 50m 42s (remain 76m 36s) Loss: 0.0004(0.0125) Grad: 150.5923  LR: 0.000016  \n","Epoch: [1][14800/36908] Elapsed 51m 3s (remain 76m 15s) Loss: 0.0002(0.0124) Grad: 96.7141  LR: 0.000016  \n","Epoch: [1][14900/36908] Elapsed 51m 24s (remain 75m 55s) Loss: 0.0001(0.0124) Grad: 78.3446  LR: 0.000016  \n","Epoch: [1][15000/36908] Elapsed 51m 44s (remain 75m 34s) Loss: 0.0001(0.0123) Grad: 53.7638  LR: 0.000016  \n","Epoch: [1][15100/36908] Elapsed 52m 5s (remain 75m 13s) Loss: 0.0010(0.0123) Grad: 431.2278  LR: 0.000016  \n","Epoch: [1][15200/36908] Elapsed 52m 26s (remain 74m 52s) Loss: 0.0001(0.0122) Grad: 40.2453  LR: 0.000016  \n","Epoch: [1][15300/36908] Elapsed 52m 46s (remain 74m 32s) Loss: 0.0001(0.0121) Grad: 47.1127  LR: 0.000017  \n","Epoch: [1][15400/36908] Elapsed 53m 7s (remain 74m 11s) Loss: 0.0001(0.0121) Grad: 79.9611  LR: 0.000017  \n","Epoch: [1][15500/36908] Elapsed 53m 28s (remain 73m 50s) Loss: 0.0475(0.0120) Grad: 5533.8569  LR: 0.000017  \n","Epoch: [1][15600/36908] Elapsed 53m 49s (remain 73m 30s) Loss: 0.0175(0.0120) Grad: 3579.3613  LR: 0.000017  \n","Epoch: [1][15700/36908] Elapsed 54m 9s (remain 73m 9s) Loss: 0.0003(0.0119) Grad: 161.2992  LR: 0.000017  \n","Epoch: [1][15800/36908] Elapsed 54m 30s (remain 72m 48s) Loss: 0.0001(0.0119) Grad: 42.5143  LR: 0.000017  \n","Epoch: [1][15900/36908] Elapsed 54m 51s (remain 72m 27s) Loss: 0.0003(0.0118) Grad: 117.4384  LR: 0.000017  \n","Epoch: [1][16000/36908] Elapsed 55m 11s (remain 72m 7s) Loss: 0.0001(0.0118) Grad: 44.7067  LR: 0.000017  \n","Epoch: [1][16100/36908] Elapsed 55m 32s (remain 71m 46s) Loss: 0.0006(0.0117) Grad: 216.7727  LR: 0.000017  \n","Epoch: [1][16200/36908] Elapsed 55m 53s (remain 71m 25s) Loss: 0.0001(0.0117) Grad: 60.0046  LR: 0.000018  \n","Epoch: [1][16300/36908] Elapsed 56m 13s (remain 71m 5s) Loss: 0.0136(0.0116) Grad: 3500.4302  LR: 0.000018  \n","Epoch: [1][16400/36908] Elapsed 56m 34s (remain 70m 44s) Loss: 0.0004(0.0116) Grad: 182.2717  LR: 0.000018  \n","Epoch: [1][16500/36908] Elapsed 56m 55s (remain 70m 23s) Loss: 0.0154(0.0115) Grad: 2243.4348  LR: 0.000018  \n","Epoch: [1][16600/36908] Elapsed 57m 15s (remain 70m 3s) Loss: 0.0001(0.0115) Grad: 60.0121  LR: 0.000018  \n","Epoch: [1][16700/36908] Elapsed 57m 36s (remain 69m 42s) Loss: 0.0001(0.0114) Grad: 96.0426  LR: 0.000018  \n","Epoch: [1][16800/36908] Elapsed 57m 57s (remain 69m 21s) Loss: 0.0001(0.0114) Grad: 109.4092  LR: 0.000018  \n","Epoch: [1][16900/36908] Elapsed 58m 17s (remain 69m 0s) Loss: 0.0000(0.0113) Grad: 65.9563  LR: 0.000018  \n","Epoch: [1][17000/36908] Elapsed 58m 38s (remain 68m 40s) Loss: 0.0003(0.0113) Grad: 316.6434  LR: 0.000018  \n","Epoch: [1][17100/36908] Elapsed 58m 59s (remain 68m 19s) Loss: 0.0001(0.0113) Grad: 112.3933  LR: 0.000019  \n","Epoch: [1][17200/36908] Elapsed 59m 20s (remain 67m 58s) Loss: 0.0002(0.0112) Grad: 173.4391  LR: 0.000019  \n","Epoch: [1][17300/36908] Elapsed 59m 40s (remain 67m 37s) Loss: 0.0224(0.0112) Grad: 8404.3281  LR: 0.000019  \n","Epoch: [1][17400/36908] Elapsed 60m 1s (remain 67m 17s) Loss: 0.0004(0.0111) Grad: 290.6153  LR: 0.000019  \n","Epoch: [1][17500/36908] Elapsed 60m 22s (remain 66m 56s) Loss: 0.0071(0.0111) Grad: 2339.4275  LR: 0.000019  \n","Epoch: [1][17600/36908] Elapsed 60m 42s (remain 66m 36s) Loss: 0.0000(0.0110) Grad: 34.1649  LR: 0.000019  \n","Epoch: [1][17700/36908] Elapsed 61m 3s (remain 66m 15s) Loss: 0.0019(0.0110) Grad: 628.7507  LR: 0.000019  \n","Epoch: [1][17800/36908] Elapsed 61m 24s (remain 65m 54s) Loss: 0.0002(0.0110) Grad: 164.3762  LR: 0.000019  \n","Epoch: [1][17900/36908] Elapsed 61m 45s (remain 65m 33s) Loss: 0.0002(0.0109) Grad: 160.7049  LR: 0.000019  \n","Epoch: [1][18000/36908] Elapsed 62m 5s (remain 65m 13s) Loss: 0.0001(0.0109) Grad: 62.5624  LR: 0.000020  \n","Epoch: [1][18100/36908] Elapsed 62m 26s (remain 64m 52s) Loss: 0.0019(0.0108) Grad: 761.5967  LR: 0.000020  \n","Epoch: [1][18200/36908] Elapsed 62m 47s (remain 64m 31s) Loss: 0.0001(0.0108) Grad: 103.0328  LR: 0.000020  \n","Epoch: [1][18300/36908] Elapsed 63m 7s (remain 64m 11s) Loss: 0.0001(0.0107) Grad: 135.8706  LR: 0.000020  \n","Epoch: [1][18400/36908] Elapsed 63m 28s (remain 63m 50s) Loss: 0.0001(0.0107) Grad: 57.7003  LR: 0.000020  \n","Epoch: [1][18500/36908] Elapsed 63m 49s (remain 63m 29s) Loss: 0.0000(0.0107) Grad: 59.9445  LR: 0.000020  \n","Epoch: [1][18600/36908] Elapsed 64m 9s (remain 63m 9s) Loss: 0.0079(0.0106) Grad: 2268.4133  LR: 0.000020  \n","Epoch: [1][18700/36908] Elapsed 64m 30s (remain 62m 48s) Loss: 0.0001(0.0106) Grad: 99.5285  LR: 0.000020  \n","Epoch: [1][18800/36908] Elapsed 64m 51s (remain 62m 27s) Loss: 0.0004(0.0106) Grad: 385.8815  LR: 0.000020  \n","Epoch: [1][18900/36908] Elapsed 65m 12s (remain 62m 7s) Loss: 0.0000(0.0105) Grad: 64.3511  LR: 0.000020  \n","Epoch: [1][19000/36908] Elapsed 65m 32s (remain 61m 46s) Loss: 0.0001(0.0105) Grad: 72.4644  LR: 0.000020  \n","Epoch: [1][19100/36908] Elapsed 65m 53s (remain 61m 25s) Loss: 0.0002(0.0105) Grad: 200.1205  LR: 0.000020  \n","Epoch: [1][19200/36908] Elapsed 66m 14s (remain 61m 4s) Loss: 0.0037(0.0104) Grad: 2143.4478  LR: 0.000020  \n","Epoch: [1][19300/36908] Elapsed 66m 34s (remain 60m 44s) Loss: 0.0001(0.0104) Grad: 143.8464  LR: 0.000020  \n","Epoch: [1][19400/36908] Elapsed 66m 55s (remain 60m 23s) Loss: 0.0213(0.0104) Grad: 4680.8716  LR: 0.000020  \n","Epoch: [1][19500/36908] Elapsed 67m 16s (remain 60m 2s) Loss: 0.0025(0.0103) Grad: 883.8016  LR: 0.000020  \n","Epoch: [1][19600/36908] Elapsed 67m 36s (remain 59m 41s) Loss: 0.0001(0.0103) Grad: 103.1356  LR: 0.000020  \n","Epoch: [1][19700/36908] Elapsed 67m 57s (remain 59m 21s) Loss: 0.0004(0.0103) Grad: 339.3754  LR: 0.000020  \n","Epoch: [1][19800/36908] Elapsed 68m 18s (remain 59m 0s) Loss: 0.0000(0.0102) Grad: 22.7694  LR: 0.000020  \n","Epoch: [1][19900/36908] Elapsed 68m 38s (remain 58m 39s) Loss: 0.0000(0.0102) Grad: 10.7156  LR: 0.000020  \n","Epoch: [1][20000/36908] Elapsed 68m 59s (remain 58m 19s) Loss: 0.0004(0.0102) Grad: 412.0371  LR: 0.000020  \n","Epoch: [1][20100/36908] Elapsed 69m 20s (remain 57m 58s) Loss: 0.0001(0.0101) Grad: 109.4793  LR: 0.000020  \n","Epoch: [1][20200/36908] Elapsed 69m 40s (remain 57m 37s) Loss: 0.0001(0.0101) Grad: 102.2531  LR: 0.000020  \n","Epoch: [1][20300/36908] Elapsed 70m 1s (remain 57m 16s) Loss: 0.0001(0.0101) Grad: 125.7462  LR: 0.000020  \n","Epoch: [1][20400/36908] Elapsed 70m 22s (remain 56m 56s) Loss: 0.0003(0.0100) Grad: 304.0435  LR: 0.000020  \n","Epoch: [1][20500/36908] Elapsed 70m 42s (remain 56m 35s) Loss: 0.0002(0.0100) Grad: 147.9986  LR: 0.000020  \n","Epoch: [1][20600/36908] Elapsed 71m 3s (remain 56m 14s) Loss: 0.0000(0.0100) Grad: 41.6036  LR: 0.000020  \n","Epoch: [1][20700/36908] Elapsed 71m 24s (remain 55m 54s) Loss: 0.0000(0.0099) Grad: 70.3718  LR: 0.000020  \n","Epoch: [1][20800/36908] Elapsed 71m 44s (remain 55m 33s) Loss: 0.0001(0.0099) Grad: 270.2888  LR: 0.000020  \n","Epoch: [1][20900/36908] Elapsed 72m 5s (remain 55m 12s) Loss: 0.0001(0.0099) Grad: 189.0567  LR: 0.000020  \n","Epoch: [1][21000/36908] Elapsed 72m 26s (remain 54m 51s) Loss: 0.0001(0.0099) Grad: 250.3288  LR: 0.000020  \n","Epoch: [1][21100/36908] Elapsed 72m 46s (remain 54m 31s) Loss: 0.0104(0.0098) Grad: 5160.0786  LR: 0.000020  \n","Epoch: [1][21200/36908] Elapsed 73m 7s (remain 54m 10s) Loss: 0.0000(0.0098) Grad: 31.9357  LR: 0.000020  \n","Epoch: [1][21300/36908] Elapsed 73m 28s (remain 53m 49s) Loss: 0.0001(0.0098) Grad: 170.6151  LR: 0.000020  \n","Epoch: [1][21400/36908] Elapsed 73m 48s (remain 53m 29s) Loss: 0.0609(0.0098) Grad: 80806.7031  LR: 0.000020  \n","Epoch: [1][21500/36908] Elapsed 74m 9s (remain 53m 8s) Loss: 0.0001(0.0097) Grad: 104.9941  LR: 0.000020  \n","Epoch: [1][21600/36908] Elapsed 74m 30s (remain 52m 47s) Loss: 0.0001(0.0097) Grad: 254.4796  LR: 0.000020  \n","Epoch: [1][21700/36908] Elapsed 74m 51s (remain 52m 27s) Loss: 0.0063(0.0097) Grad: 5571.7983  LR: 0.000020  \n","Epoch: [1][21800/36908] Elapsed 75m 11s (remain 52m 6s) Loss: 0.0000(0.0097) Grad: 76.8767  LR: 0.000020  \n","Epoch: [1][21900/36908] Elapsed 75m 32s (remain 51m 45s) Loss: 0.0000(0.0096) Grad: 130.3938  LR: 0.000020  \n","Epoch: [1][22000/36908] Elapsed 75m 53s (remain 51m 25s) Loss: 0.1043(0.0096) Grad: 39181.4375  LR: 0.000020  \n","Epoch: [1][22100/36908] Elapsed 76m 14s (remain 51m 4s) Loss: 0.0001(0.0096) Grad: 109.2666  LR: 0.000020  \n","Epoch: [1][22200/36908] Elapsed 76m 34s (remain 50m 43s) Loss: 0.0000(0.0095) Grad: 68.3934  LR: 0.000020  \n","Epoch: [1][22300/36908] Elapsed 76m 55s (remain 50m 23s) Loss: 0.0002(0.0095) Grad: 362.8796  LR: 0.000020  \n","Epoch: [1][22400/36908] Elapsed 77m 16s (remain 50m 2s) Loss: 0.0045(0.0095) Grad: 3182.9556  LR: 0.000020  \n","Epoch: [1][22500/36908] Elapsed 77m 36s (remain 49m 41s) Loss: 0.0000(0.0095) Grad: 28.5813  LR: 0.000020  \n","Epoch: [1][22600/36908] Elapsed 77m 57s (remain 49m 21s) Loss: 0.0001(0.0094) Grad: 199.9360  LR: 0.000020  \n","Epoch: [1][22700/36908] Elapsed 78m 18s (remain 49m 0s) Loss: 0.0200(0.0094) Grad: 14075.6592  LR: 0.000019  \n","Epoch: [1][22800/36908] Elapsed 78m 39s (remain 48m 39s) Loss: 0.0001(0.0094) Grad: 258.8041  LR: 0.000019  \n","Epoch: [1][22900/36908] Elapsed 78m 59s (remain 48m 19s) Loss: 0.0013(0.0094) Grad: 1673.0459  LR: 0.000019  \n","Epoch: [1][23000/36908] Elapsed 79m 20s (remain 47m 58s) Loss: 0.0001(0.0093) Grad: 170.2287  LR: 0.000019  \n","Epoch: [1][23100/36908] Elapsed 79m 41s (remain 47m 37s) Loss: 0.0000(0.0093) Grad: 47.3742  LR: 0.000019  \n","Epoch: [1][23200/36908] Elapsed 80m 2s (remain 47m 17s) Loss: 0.0249(0.0093) Grad: 48353.1797  LR: 0.000019  \n","Epoch: [1][23300/36908] Elapsed 80m 23s (remain 46m 56s) Loss: 0.0061(0.0093) Grad: 10428.9180  LR: 0.000019  \n","Epoch: [1][23400/36908] Elapsed 80m 43s (remain 46m 35s) Loss: 0.0001(0.0092) Grad: 230.6998  LR: 0.000019  \n","Epoch: [1][23500/36908] Elapsed 81m 4s (remain 46m 15s) Loss: 0.0001(0.0092) Grad: 264.2290  LR: 0.000019  \n","Epoch: [1][23600/36908] Elapsed 81m 25s (remain 45m 54s) Loss: 0.0382(0.0092) Grad: 17019.5312  LR: 0.000019  \n","Epoch: [1][23700/36908] Elapsed 81m 45s (remain 45m 33s) Loss: 0.0001(0.0092) Grad: 133.1132  LR: 0.000019  \n","Epoch: [1][23800/36908] Elapsed 82m 6s (remain 45m 12s) Loss: 0.0000(0.0091) Grad: 66.8302  LR: 0.000019  \n","Epoch: [1][23900/36908] Elapsed 82m 27s (remain 44m 52s) Loss: 0.0001(0.0091) Grad: 147.1365  LR: 0.000019  \n","Epoch: [1][24000/36908] Elapsed 82m 47s (remain 44m 31s) Loss: 0.0000(0.0091) Grad: 102.6424  LR: 0.000019  \n","Epoch: [1][24100/36908] Elapsed 83m 8s (remain 44m 10s) Loss: 0.0105(0.0091) Grad: 6765.0532  LR: 0.000019  \n","Epoch: [1][24200/36908] Elapsed 83m 29s (remain 43m 50s) Loss: 0.0001(0.0091) Grad: 217.8093  LR: 0.000019  \n","Epoch: [1][24300/36908] Elapsed 83m 49s (remain 43m 29s) Loss: 0.0000(0.0090) Grad: 75.4359  LR: 0.000019  \n","Epoch: [1][24400/36908] Elapsed 84m 10s (remain 43m 8s) Loss: 0.0000(0.0090) Grad: 72.9149  LR: 0.000019  \n","Epoch: [1][24500/36908] Elapsed 84m 31s (remain 42m 48s) Loss: 0.0000(0.0090) Grad: 29.0055  LR: 0.000019  \n","Epoch: [1][24600/36908] Elapsed 84m 52s (remain 42m 27s) Loss: 0.0003(0.0090) Grad: 270.7291  LR: 0.000019  \n","Epoch: [1][24700/36908] Elapsed 85m 12s (remain 42m 6s) Loss: 0.0031(0.0089) Grad: 1413.2438  LR: 0.000019  \n","Epoch: [1][24800/36908] Elapsed 85m 33s (remain 41m 45s) Loss: 0.0001(0.0089) Grad: 108.3944  LR: 0.000019  \n","Epoch: [1][24900/36908] Elapsed 85m 54s (remain 41m 25s) Loss: 0.0275(0.0089) Grad: 7410.6606  LR: 0.000019  \n","Epoch: [1][25000/36908] Elapsed 86m 14s (remain 41m 4s) Loss: 0.0448(0.0089) Grad: 24771.9473  LR: 0.000019  \n","Epoch: [1][25100/36908] Elapsed 86m 35s (remain 40m 43s) Loss: 0.0002(0.0088) Grad: 212.9219  LR: 0.000019  \n","Epoch: [1][25200/36908] Elapsed 86m 56s (remain 40m 23s) Loss: 0.0001(0.0088) Grad: 130.3444  LR: 0.000019  \n","Epoch: [1][25300/36908] Elapsed 87m 16s (remain 40m 2s) Loss: 0.0004(0.0088) Grad: 443.3580  LR: 0.000019  \n","Epoch: [1][25400/36908] Elapsed 87m 37s (remain 39m 41s) Loss: 0.0001(0.0088) Grad: 63.1058  LR: 0.000019  \n","Epoch: [1][25500/36908] Elapsed 87m 58s (remain 39m 21s) Loss: 0.0001(0.0088) Grad: 672.2195  LR: 0.000019  \n","Epoch: [1][25600/36908] Elapsed 88m 18s (remain 39m 0s) Loss: 0.0001(0.0087) Grad: 84.6098  LR: 0.000019  \n","Epoch: [1][25700/36908] Elapsed 88m 39s (remain 38m 39s) Loss: 0.0061(0.0087) Grad: 3123.4189  LR: 0.000019  \n","Epoch: [1][25800/36908] Elapsed 89m 0s (remain 38m 19s) Loss: 0.0001(0.0087) Grad: 180.4517  LR: 0.000019  \n","Epoch: [1][25900/36908] Elapsed 89m 21s (remain 37m 58s) Loss: 0.0001(0.0087) Grad: 122.6687  LR: 0.000019  \n","Epoch: [1][26000/36908] Elapsed 89m 41s (remain 37m 37s) Loss: 0.0312(0.0087) Grad: 6680.8452  LR: 0.000019  \n","Epoch: [1][26100/36908] Elapsed 90m 2s (remain 37m 16s) Loss: 0.0001(0.0086) Grad: 114.6197  LR: 0.000019  \n","Epoch: [1][26200/36908] Elapsed 90m 23s (remain 36m 56s) Loss: 0.0001(0.0086) Grad: 82.3153  LR: 0.000019  \n","Epoch: [1][26300/36908] Elapsed 90m 44s (remain 36m 35s) Loss: 0.0002(0.0086) Grad: 176.0278  LR: 0.000019  \n","Epoch: [1][26400/36908] Elapsed 91m 4s (remain 36m 14s) Loss: 0.0263(0.0086) Grad: 10336.6660  LR: 0.000019  \n","Epoch: [1][26500/36908] Elapsed 91m 25s (remain 35m 54s) Loss: 0.0001(0.0086) Grad: 74.5498  LR: 0.000019  \n","Epoch: [1][26600/36908] Elapsed 91m 46s (remain 35m 33s) Loss: 0.0557(0.0086) Grad: 11238.4199  LR: 0.000019  \n","Epoch: [1][26700/36908] Elapsed 92m 6s (remain 35m 12s) Loss: 0.0001(0.0085) Grad: 285.6672  LR: 0.000019  \n","Epoch: [1][26800/36908] Elapsed 92m 27s (remain 34m 52s) Loss: 0.0000(0.0085) Grad: 45.7527  LR: 0.000019  \n","Epoch: [1][26900/36908] Elapsed 92m 48s (remain 34m 31s) Loss: 0.0001(0.0085) Grad: 87.8966  LR: 0.000019  \n","Epoch: [1][27000/36908] Elapsed 93m 8s (remain 34m 10s) Loss: 0.0002(0.0085) Grad: 159.6636  LR: 0.000019  \n","Epoch: [1][27100/36908] Elapsed 93m 29s (remain 33m 49s) Loss: 0.0003(0.0084) Grad: 285.3958  LR: 0.000019  \n","Epoch: [1][27200/36908] Elapsed 93m 50s (remain 33m 29s) Loss: 0.0083(0.0084) Grad: 3644.5188  LR: 0.000019  \n","Epoch: [1][27300/36908] Elapsed 94m 11s (remain 33m 8s) Loss: 0.0446(0.0084) Grad: 22154.7812  LR: 0.000019  \n","Epoch: [1][27400/36908] Elapsed 94m 31s (remain 32m 47s) Loss: 0.0146(0.0084) Grad: 3913.0339  LR: 0.000019  \n","Epoch: [1][27500/36908] Elapsed 94m 52s (remain 32m 27s) Loss: 0.0001(0.0084) Grad: 107.6992  LR: 0.000019  \n","Epoch: [1][27600/36908] Elapsed 95m 13s (remain 32m 6s) Loss: 0.0001(0.0084) Grad: 73.8679  LR: 0.000019  \n","Epoch: [1][27700/36908] Elapsed 95m 33s (remain 31m 45s) Loss: 0.0001(0.0083) Grad: 128.8672  LR: 0.000019  \n","Epoch: [1][27800/36908] Elapsed 95m 54s (remain 31m 25s) Loss: 0.0002(0.0083) Grad: 153.7235  LR: 0.000019  \n","Epoch: [1][27900/36908] Elapsed 96m 15s (remain 31m 4s) Loss: 0.1003(0.0083) Grad: 23749.0938  LR: 0.000019  \n","Epoch: [1][28000/36908] Elapsed 96m 36s (remain 30m 43s) Loss: 0.0005(0.0083) Grad: 494.5883  LR: 0.000019  \n","Epoch: [1][28100/36908] Elapsed 96m 56s (remain 30m 23s) Loss: 0.0001(0.0083) Grad: 131.1747  LR: 0.000019  \n","Epoch: [1][28200/36908] Elapsed 97m 17s (remain 30m 2s) Loss: 0.0002(0.0083) Grad: 231.8666  LR: 0.000019  \n","Epoch: [1][28300/36908] Elapsed 97m 38s (remain 29m 41s) Loss: 0.0031(0.0082) Grad: 998.7799  LR: 0.000019  \n","Epoch: [1][28400/36908] Elapsed 97m 58s (remain 29m 20s) Loss: 0.0006(0.0082) Grad: 469.9230  LR: 0.000019  \n","Epoch: [1][28500/36908] Elapsed 98m 19s (remain 29m 0s) Loss: 0.0166(0.0082) Grad: 9318.9258  LR: 0.000019  \n","Epoch: [1][28600/36908] Elapsed 98m 40s (remain 28m 39s) Loss: 0.0001(0.0082) Grad: 105.4500  LR: 0.000019  \n","Epoch: [1][28700/36908] Elapsed 99m 1s (remain 28m 18s) Loss: 0.0115(0.0082) Grad: 6737.4097  LR: 0.000019  \n","Epoch: [1][28800/36908] Elapsed 99m 21s (remain 27m 58s) Loss: 0.0001(0.0082) Grad: 112.8070  LR: 0.000019  \n","Epoch: [1][28900/36908] Elapsed 99m 42s (remain 27m 37s) Loss: 0.0001(0.0081) Grad: 159.1140  LR: 0.000019  \n","Epoch: [1][29000/36908] Elapsed 100m 3s (remain 27m 16s) Loss: 0.0000(0.0081) Grad: 71.4420  LR: 0.000019  \n","Epoch: [1][29100/36908] Elapsed 100m 23s (remain 26m 56s) Loss: 0.0001(0.0081) Grad: 207.4375  LR: 0.000019  \n","Epoch: [1][29200/36908] Elapsed 100m 44s (remain 26m 35s) Loss: 0.0001(0.0081) Grad: 120.2470  LR: 0.000019  \n","Epoch: [1][29300/36908] Elapsed 101m 5s (remain 26m 14s) Loss: 0.0001(0.0081) Grad: 182.0465  LR: 0.000019  \n","Epoch: [1][29400/36908] Elapsed 101m 25s (remain 25m 53s) Loss: 0.0001(0.0081) Grad: 129.5880  LR: 0.000019  \n","Epoch: [1][29500/36908] Elapsed 101m 46s (remain 25m 33s) Loss: 0.0001(0.0080) Grad: 179.2336  LR: 0.000019  \n","Epoch: [1][29600/36908] Elapsed 102m 7s (remain 25m 12s) Loss: 0.0001(0.0080) Grad: 185.2947  LR: 0.000019  \n","Epoch: [1][29700/36908] Elapsed 102m 27s (remain 24m 51s) Loss: 0.0003(0.0080) Grad: 544.9346  LR: 0.000019  \n","Epoch: [1][29800/36908] Elapsed 102m 48s (remain 24m 31s) Loss: 0.0001(0.0080) Grad: 183.4380  LR: 0.000019  \n","Epoch: [1][29900/36908] Elapsed 103m 9s (remain 24m 10s) Loss: 0.0053(0.0080) Grad: 2990.3145  LR: 0.000019  \n","Epoch: [1][30000/36908] Elapsed 103m 30s (remain 23m 49s) Loss: 0.0001(0.0080) Grad: 234.7681  LR: 0.000019  \n","Epoch: [1][30100/36908] Elapsed 103m 50s (remain 23m 29s) Loss: 0.0000(0.0079) Grad: 98.0589  LR: 0.000019  \n","Epoch: [1][30200/36908] Elapsed 104m 11s (remain 23m 8s) Loss: 0.0000(0.0079) Grad: 113.6623  LR: 0.000019  \n","Epoch: [1][30300/36908] Elapsed 104m 32s (remain 22m 47s) Loss: 0.0001(0.0079) Grad: 185.6270  LR: 0.000019  \n","Epoch: [1][30400/36908] Elapsed 104m 52s (remain 22m 26s) Loss: 0.0001(0.0079) Grad: 131.0023  LR: 0.000019  \n","Epoch: [1][30500/36908] Elapsed 105m 13s (remain 22m 6s) Loss: 0.0000(0.0079) Grad: 77.2459  LR: 0.000019  \n","Epoch: [1][30600/36908] Elapsed 105m 34s (remain 21m 45s) Loss: 0.0001(0.0079) Grad: 179.4204  LR: 0.000019  \n","Epoch: [1][30700/36908] Elapsed 105m 54s (remain 21m 24s) Loss: 0.0000(0.0079) Grad: 53.2880  LR: 0.000019  \n","Epoch: [1][30800/36908] Elapsed 106m 15s (remain 21m 4s) Loss: 0.0000(0.0078) Grad: 78.2755  LR: 0.000019  \n","Epoch: [1][30900/36908] Elapsed 106m 36s (remain 20m 43s) Loss: 0.0001(0.0078) Grad: 265.4577  LR: 0.000019  \n","Epoch: [1][31000/36908] Elapsed 106m 56s (remain 20m 22s) Loss: 0.0001(0.0078) Grad: 121.2812  LR: 0.000018  \n","Epoch: [1][31100/36908] Elapsed 107m 17s (remain 20m 1s) Loss: 0.0001(0.0078) Grad: 138.6595  LR: 0.000018  \n","Epoch: [1][31200/36908] Elapsed 107m 37s (remain 19m 41s) Loss: 0.0001(0.0078) Grad: 274.1141  LR: 0.000018  \n","Epoch: [1][31300/36908] Elapsed 107m 58s (remain 19m 20s) Loss: 0.0000(0.0078) Grad: 54.9269  LR: 0.000018  \n","Epoch: [1][31400/36908] Elapsed 108m 19s (remain 18m 59s) Loss: 0.0326(0.0078) Grad: 30448.1406  LR: 0.000018  \n","Epoch: [1][31500/36908] Elapsed 108m 40s (remain 18m 39s) Loss: 0.0001(0.0078) Grad: 137.2118  LR: 0.000018  \n","Epoch: [1][31600/36908] Elapsed 109m 0s (remain 18m 18s) Loss: 0.0000(0.0077) Grad: 47.6667  LR: 0.000018  \n","Epoch: [1][31700/36908] Elapsed 109m 21s (remain 17m 57s) Loss: 0.0191(0.0077) Grad: 9353.2568  LR: 0.000018  \n","Epoch: [1][31800/36908] Elapsed 109m 42s (remain 17m 37s) Loss: 0.0001(0.0077) Grad: 144.9915  LR: 0.000018  \n","Epoch: [1][31900/36908] Elapsed 110m 3s (remain 17m 16s) Loss: 0.0000(0.0077) Grad: 69.1301  LR: 0.000018  \n","Epoch: [1][32000/36908] Elapsed 110m 23s (remain 16m 55s) Loss: 0.0570(0.0077) Grad: 36212.2852  LR: 0.000018  \n","Epoch: [1][32100/36908] Elapsed 110m 44s (remain 16m 34s) Loss: 0.0737(0.0077) Grad: 76192.8594  LR: 0.000018  \n","Epoch: [1][32200/36908] Elapsed 111m 5s (remain 16m 14s) Loss: 0.0014(0.0077) Grad: 1336.6392  LR: 0.000018  \n","Epoch: [1][32300/36908] Elapsed 111m 25s (remain 15m 53s) Loss: 0.0000(0.0077) Grad: 31.6730  LR: 0.000018  \n","Epoch: [1][32400/36908] Elapsed 111m 46s (remain 15m 32s) Loss: 0.0003(0.0077) Grad: 633.3854  LR: 0.000018  \n","Epoch: [1][32500/36908] Elapsed 112m 7s (remain 15m 12s) Loss: 0.0001(0.0077) Grad: 359.1757  LR: 0.000018  \n","Epoch: [1][32600/36908] Elapsed 112m 27s (remain 14m 51s) Loss: 0.0574(0.0076) Grad: 68722.8672  LR: 0.000018  \n","Epoch: [1][32700/36908] Elapsed 112m 48s (remain 14m 30s) Loss: 0.0000(0.0076) Grad: 72.2262  LR: 0.000018  \n","Epoch: [1][32800/36908] Elapsed 113m 9s (remain 14m 10s) Loss: 0.0000(0.0076) Grad: 178.3104  LR: 0.000018  \n","Epoch: [1][32900/36908] Elapsed 113m 30s (remain 13m 49s) Loss: 0.0001(0.0076) Grad: 216.2168  LR: 0.000018  \n","Epoch: [1][33000/36908] Elapsed 113m 50s (remain 13m 28s) Loss: 0.0109(0.0076) Grad: 10730.9521  LR: 0.000018  \n","Epoch: [1][33100/36908] Elapsed 114m 11s (remain 13m 8s) Loss: 0.0144(0.0076) Grad: 12694.9951  LR: 0.000018  \n","Epoch: [1][33200/36908] Elapsed 114m 32s (remain 12m 47s) Loss: 0.0000(0.0076) Grad: 201.3877  LR: 0.000018  \n","Epoch: [1][33300/36908] Elapsed 114m 52s (remain 12m 26s) Loss: 0.0000(0.0076) Grad: 188.8317  LR: 0.000018  \n","Epoch: [1][33400/36908] Elapsed 115m 13s (remain 12m 5s) Loss: 0.0000(0.0076) Grad: 128.9091  LR: 0.000018  \n","Epoch: [1][33500/36908] Elapsed 115m 34s (remain 11m 45s) Loss: 0.0000(0.0075) Grad: 4.9378  LR: 0.000018  \n","Epoch: [1][33600/36908] Elapsed 115m 54s (remain 11m 24s) Loss: 0.0081(0.0075) Grad: 10088.0146  LR: 0.000018  \n","Epoch: [1][33700/36908] Elapsed 116m 15s (remain 11m 3s) Loss: 0.0001(0.0075) Grad: 268.8828  LR: 0.000018  \n","Epoch: [1][33800/36908] Elapsed 116m 36s (remain 10m 43s) Loss: 0.0000(0.0075) Grad: 142.0909  LR: 0.000018  \n","Epoch: [1][33900/36908] Elapsed 116m 56s (remain 10m 22s) Loss: 0.0000(0.0075) Grad: 34.1380  LR: 0.000018  \n","Epoch: [1][34000/36908] Elapsed 117m 17s (remain 10m 1s) Loss: 0.0001(0.0075) Grad: 231.7596  LR: 0.000018  \n","Epoch: [1][34100/36908] Elapsed 117m 38s (remain 9m 41s) Loss: 0.0001(0.0075) Grad: 306.8404  LR: 0.000018  \n","Epoch: [1][34200/36908] Elapsed 117m 59s (remain 9m 20s) Loss: 0.0000(0.0075) Grad: 99.0630  LR: 0.000018  \n","Epoch: [1][34300/36908] Elapsed 118m 19s (remain 8m 59s) Loss: 0.0000(0.0074) Grad: 112.1226  LR: 0.000018  \n","Epoch: [1][34400/36908] Elapsed 118m 40s (remain 8m 38s) Loss: 0.0000(0.0074) Grad: 193.2465  LR: 0.000018  \n","Epoch: [1][34500/36908] Elapsed 119m 1s (remain 8m 18s) Loss: 0.0000(0.0074) Grad: 144.8710  LR: 0.000018  \n","Epoch: [1][34600/36908] Elapsed 119m 21s (remain 7m 57s) Loss: 0.0000(0.0074) Grad: 111.9631  LR: 0.000018  \n","Epoch: [1][34700/36908] Elapsed 119m 42s (remain 7m 36s) Loss: 0.0000(0.0074) Grad: 169.1813  LR: 0.000018  \n","Epoch: [1][34800/36908] Elapsed 120m 3s (remain 7m 16s) Loss: 0.0000(0.0074) Grad: 57.2896  LR: 0.000018  \n","Epoch: [1][34900/36908] Elapsed 120m 24s (remain 6m 55s) Loss: 0.0000(0.0074) Grad: 195.5087  LR: 0.000018  \n","Epoch: [1][35000/36908] Elapsed 120m 44s (remain 6m 34s) Loss: 0.0130(0.0074) Grad: 16160.4082  LR: 0.000018  \n","Epoch: [1][35100/36908] Elapsed 121m 5s (remain 6m 14s) Loss: 0.0001(0.0074) Grad: 385.6707  LR: 0.000018  \n","Epoch: [1][35200/36908] Elapsed 121m 26s (remain 5m 53s) Loss: 0.0021(0.0074) Grad: 13046.3975  LR: 0.000018  \n","Epoch: [1][35300/36908] Elapsed 121m 47s (remain 5m 32s) Loss: 0.0001(0.0073) Grad: 404.4205  LR: 0.000018  \n","Epoch: [1][35400/36908] Elapsed 122m 8s (remain 5m 11s) Loss: 0.0001(0.0073) Grad: 411.5728  LR: 0.000018  \n","Epoch: [1][35500/36908] Elapsed 122m 29s (remain 4m 51s) Loss: 0.0279(0.0073) Grad: 30498.5215  LR: 0.000018  \n","Epoch: [1][35600/36908] Elapsed 122m 49s (remain 4m 30s) Loss: 0.0000(0.0073) Grad: 201.5749  LR: 0.000018  \n","Epoch: [1][35700/36908] Elapsed 123m 10s (remain 4m 9s) Loss: 0.0000(0.0073) Grad: 114.1983  LR: 0.000018  \n","Epoch: [1][35800/36908] Elapsed 123m 31s (remain 3m 49s) Loss: 0.0000(0.0073) Grad: 151.1880  LR: 0.000018  \n","Epoch: [1][35900/36908] Elapsed 123m 52s (remain 3m 28s) Loss: 0.0466(0.0073) Grad: 37374.9766  LR: 0.000018  \n","Epoch: [1][36000/36908] Elapsed 124m 13s (remain 3m 7s) Loss: 0.0000(0.0073) Grad: 80.1525  LR: 0.000018  \n","Epoch: [1][36100/36908] Elapsed 124m 34s (remain 2m 47s) Loss: 0.0033(0.0073) Grad: 3776.2864  LR: 0.000018  \n","Epoch: [1][36200/36908] Elapsed 124m 55s (remain 2m 26s) Loss: 0.0069(0.0073) Grad: 6763.8755  LR: 0.000018  \n","Epoch: [1][36300/36908] Elapsed 125m 15s (remain 2m 5s) Loss: 0.0000(0.0073) Grad: 139.0516  LR: 0.000018  \n","Epoch: [1][36400/36908] Elapsed 125m 36s (remain 1m 44s) Loss: 0.0000(0.0072) Grad: 72.2277  LR: 0.000018  \n","Epoch: [1][36500/36908] Elapsed 125m 57s (remain 1m 24s) Loss: 0.0000(0.0072) Grad: 118.6880  LR: 0.000018  \n","Epoch: [1][36600/36908] Elapsed 126m 18s (remain 1m 3s) Loss: 0.0000(0.0072) Grad: 7.3381  LR: 0.000018  \n","Epoch: [1][36700/36908] Elapsed 126m 39s (remain 0m 42s) Loss: 0.0000(0.0072) Grad: 264.3853  LR: 0.000018  \n","Epoch: [1][36800/36908] Elapsed 127m 0s (remain 0m 22s) Loss: 0.0000(0.0072) Grad: 95.3348  LR: 0.000018  \n","Epoch: [1][36900/36908] Elapsed 127m 21s (remain 0m 1s) Loss: 0.0000(0.0072) Grad: 146.7101  LR: 0.000018  \n","Epoch: [1][36907/36908] Elapsed 127m 22s (remain 0m 0s) Loss: 0.0000(0.0072) Grad: 401.6379  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 6m 8s) Loss: 0.0678(0.0678) \n","EVAL: [100/1192] Elapsed 0m 5s (remain 0m 59s) Loss: 0.0532(0.0414) \n","EVAL: [200/1192] Elapsed 0m 10s (remain 0m 53s) Loss: 0.0481(0.0435) \n","EVAL: [300/1192] Elapsed 0m 16s (remain 0m 47s) Loss: 0.1490(0.0440) \n","EVAL: [400/1192] Elapsed 0m 21s (remain 0m 42s) Loss: 0.0875(0.0459) \n","EVAL: [500/1192] Elapsed 0m 26s (remain 0m 36s) Loss: 0.1091(0.0473) \n","EVAL: [600/1192] Elapsed 0m 31s (remain 0m 31s) Loss: 0.0570(0.0499) \n","EVAL: [700/1192] Elapsed 0m 36s (remain 0m 25s) Loss: 0.1610(0.0532) \n","EVAL: [800/1192] Elapsed 0m 42s (remain 0m 20s) Loss: 0.0625(0.0522) \n","EVAL: [900/1192] Elapsed 0m 47s (remain 0m 15s) Loss: 0.0816(0.0528) \n","EVAL: [1000/1192] Elapsed 0m 52s (remain 0m 10s) Loss: 0.0132(0.0530) \n","EVAL: [1100/1192] Elapsed 0m 57s (remain 0m 4s) Loss: 0.0580(0.0522) \n","EVAL: [1191/1192] Elapsed 1m 2s (remain 0m 0s) Loss: 0.0185(0.0511) \n","Epoch 1 - avg_train_loss: 0.0072  avg_val_loss: 0.0511  time: 7717s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","========== fold: 1 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_1.npy\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/36908] Elapsed 0m 0s (remain 307m 43s) Loss: 0.3134(0.3134) Grad: 187008.7500  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 21s (remain 129m 54s) Loss: 0.3150(0.3168) Grad: 48336.8359  LR: 0.000000  \n","Epoch: [1][200/36908] Elapsed 0m 42s (remain 128m 24s) Loss: 0.2824(0.3090) Grad: 22538.1113  LR: 0.000000  \n","Epoch: [1][300/36908] Elapsed 1m 3s (remain 127m 42s) Loss: 0.2319(0.2947) Grad: 18572.6094  LR: 0.000000  \n","Epoch: [1][400/36908] Elapsed 1m 23s (remain 127m 12s) Loss: 0.1899(0.2762) Grad: 15984.2490  LR: 0.000000  \n","Epoch: [1][500/36908] Elapsed 1m 44s (remain 126m 45s) Loss: 0.1534(0.2548) Grad: 13456.8916  LR: 0.000001  \n","Epoch: [1][600/36908] Elapsed 2m 5s (remain 126m 23s) Loss: 0.0877(0.2319) Grad: 9268.8018  LR: 0.000001  \n","Epoch: [1][700/36908] Elapsed 2m 26s (remain 125m 59s) Loss: 0.0473(0.2087) Grad: 5694.6997  LR: 0.000001  \n","Epoch: [1][800/36908] Elapsed 2m 47s (remain 125m 37s) Loss: 0.0149(0.1866) Grad: 2507.7969  LR: 0.000001  \n","Epoch: [1][900/36908] Elapsed 3m 8s (remain 125m 13s) Loss: 0.0005(0.1668) Grad: 195.4684  LR: 0.000001  \n","Epoch: [1][1000/36908] Elapsed 3m 28s (remain 124m 50s) Loss: 0.0125(0.1506) Grad: 702.6886  LR: 0.000001  \n","Epoch: [1][1100/36908] Elapsed 3m 49s (remain 124m 27s) Loss: 0.0008(0.1376) Grad: 283.1912  LR: 0.000001  \n","Epoch: [1][1200/36908] Elapsed 4m 10s (remain 124m 4s) Loss: 0.0368(0.1267) Grad: 1852.9202  LR: 0.000001  \n","Epoch: [1][1300/36908] Elapsed 4m 31s (remain 123m 48s) Loss: 0.0012(0.1176) Grad: 406.9390  LR: 0.000001  \n","Epoch: [1][1400/36908] Elapsed 4m 52s (remain 123m 27s) Loss: 0.0002(0.1094) Grad: 91.2923  LR: 0.000002  \n","Epoch: [1][1500/36908] Elapsed 5m 13s (remain 123m 5s) Loss: 0.0003(0.1025) Grad: 108.2051  LR: 0.000002  \n","Epoch: [1][1600/36908] Elapsed 5m 33s (remain 122m 43s) Loss: 0.0004(0.0963) Grad: 162.2566  LR: 0.000002  \n","Epoch: [1][1700/36908] Elapsed 5m 54s (remain 122m 22s) Loss: 0.0005(0.0909) Grad: 170.6898  LR: 0.000002  \n","Epoch: [1][1800/36908] Elapsed 6m 15s (remain 122m 0s) Loss: 0.0003(0.0861) Grad: 147.6066  LR: 0.000002  \n","Epoch: [1][1900/36908] Elapsed 6m 36s (remain 121m 39s) Loss: 0.0003(0.0818) Grad: 122.3289  LR: 0.000002  \n","Epoch: [1][2000/36908] Elapsed 6m 57s (remain 121m 18s) Loss: 0.0290(0.0780) Grad: 2398.2720  LR: 0.000002  \n","Epoch: [1][2100/36908] Elapsed 7m 18s (remain 120m 58s) Loss: 0.0004(0.0745) Grad: 124.4321  LR: 0.000002  \n","Epoch: [1][2200/36908] Elapsed 7m 38s (remain 120m 37s) Loss: 0.0005(0.0713) Grad: 184.9529  LR: 0.000002  \n","Epoch: [1][2300/36908] Elapsed 7m 59s (remain 120m 16s) Loss: 0.0004(0.0685) Grad: 167.8602  LR: 0.000002  \n","Epoch: [1][2400/36908] Elapsed 8m 20s (remain 119m 54s) Loss: 0.0002(0.0658) Grad: 85.8362  LR: 0.000003  \n","Epoch: [1][2500/36908] Elapsed 8m 41s (remain 119m 34s) Loss: 0.0002(0.0634) Grad: 100.4900  LR: 0.000003  \n","Epoch: [1][2600/36908] Elapsed 9m 2s (remain 119m 13s) Loss: 0.0003(0.0611) Grad: 209.3136  LR: 0.000003  \n","Epoch: [1][2700/36908] Elapsed 9m 23s (remain 118m 51s) Loss: 0.0002(0.0591) Grad: 77.3602  LR: 0.000003  \n","Epoch: [1][2800/36908] Elapsed 9m 44s (remain 118m 32s) Loss: 0.0009(0.0572) Grad: 319.3333  LR: 0.000003  \n","Epoch: [1][2900/36908] Elapsed 10m 4s (remain 118m 10s) Loss: 0.0002(0.0554) Grad: 96.5757  LR: 0.000003  \n","Epoch: [1][3000/36908] Elapsed 10m 25s (remain 117m 47s) Loss: 0.0005(0.0537) Grad: 289.4915  LR: 0.000003  \n","Epoch: [1][3100/36908] Elapsed 10m 46s (remain 117m 25s) Loss: 0.0050(0.0522) Grad: 923.8842  LR: 0.000003  \n","Epoch: [1][3200/36908] Elapsed 11m 6s (remain 117m 2s) Loss: 0.0001(0.0507) Grad: 63.4313  LR: 0.000003  \n","Epoch: [1][3300/36908] Elapsed 11m 27s (remain 116m 40s) Loss: 0.0000(0.0492) Grad: 34.4583  LR: 0.000004  \n","Epoch: [1][3400/36908] Elapsed 11m 48s (remain 116m 17s) Loss: 0.0004(0.0479) Grad: 208.0213  LR: 0.000004  \n","Epoch: [1][3500/36908] Elapsed 12m 8s (remain 115m 56s) Loss: 0.0003(0.0466) Grad: 151.3842  LR: 0.000004  \n","Epoch: [1][3600/36908] Elapsed 12m 29s (remain 115m 34s) Loss: 0.0010(0.0455) Grad: 358.1107  LR: 0.000004  \n","Epoch: [1][3700/36908] Elapsed 12m 50s (remain 115m 12s) Loss: 0.0004(0.0443) Grad: 163.4134  LR: 0.000004  \n","Epoch: [1][3800/36908] Elapsed 13m 11s (remain 114m 50s) Loss: 0.0001(0.0434) Grad: 47.1975  LR: 0.000004  \n","Epoch: [1][3900/36908] Elapsed 13m 31s (remain 114m 28s) Loss: 0.0006(0.0424) Grad: 204.1172  LR: 0.000004  \n","Epoch: [1][4000/36908] Elapsed 13m 52s (remain 114m 6s) Loss: 0.0005(0.0415) Grad: 231.7335  LR: 0.000004  \n","Epoch: [1][4100/36908] Elapsed 14m 13s (remain 113m 44s) Loss: 0.0003(0.0405) Grad: 142.2266  LR: 0.000004  \n","Epoch: [1][4200/36908] Elapsed 14m 33s (remain 113m 24s) Loss: 0.0000(0.0397) Grad: 69.7946  LR: 0.000005  \n","Epoch: [1][4300/36908] Elapsed 14m 54s (remain 113m 2s) Loss: 0.0001(0.0388) Grad: 135.0960  LR: 0.000005  \n","Epoch: [1][4400/36908] Elapsed 15m 15s (remain 112m 41s) Loss: 0.0000(0.0380) Grad: 34.3248  LR: 0.000005  \n","Epoch: [1][4500/36908] Elapsed 15m 36s (remain 112m 19s) Loss: 0.0001(0.0373) Grad: 71.1595  LR: 0.000005  \n","Epoch: [1][4600/36908] Elapsed 15m 56s (remain 111m 58s) Loss: 0.0003(0.0366) Grad: 274.0095  LR: 0.000005  \n","Epoch: [1][4700/36908] Elapsed 16m 17s (remain 111m 37s) Loss: 0.0001(0.0359) Grad: 99.7289  LR: 0.000005  \n","Epoch: [1][4800/36908] Elapsed 16m 38s (remain 111m 15s) Loss: 0.0001(0.0352) Grad: 151.8509  LR: 0.000005  \n","Epoch: [1][4900/36908] Elapsed 16m 58s (remain 110m 54s) Loss: 0.0226(0.0346) Grad: 5611.5669  LR: 0.000005  \n","Epoch: [1][5000/36908] Elapsed 17m 19s (remain 110m 33s) Loss: 0.0000(0.0340) Grad: 18.2904  LR: 0.000005  \n","Epoch: [1][5100/36908] Elapsed 17m 40s (remain 110m 11s) Loss: 0.0002(0.0334) Grad: 153.3670  LR: 0.000006  \n","Epoch: [1][5200/36908] Elapsed 18m 1s (remain 109m 50s) Loss: 0.0004(0.0328) Grad: 219.9763  LR: 0.000006  \n","Epoch: [1][5300/36908] Elapsed 18m 21s (remain 109m 29s) Loss: 0.0500(0.0323) Grad: 12326.5967  LR: 0.000006  \n","Epoch: [1][5400/36908] Elapsed 18m 42s (remain 109m 8s) Loss: 0.0001(0.0318) Grad: 95.1693  LR: 0.000006  \n","Epoch: [1][5500/36908] Elapsed 19m 3s (remain 108m 46s) Loss: 0.0000(0.0312) Grad: 24.0850  LR: 0.000006  \n","Epoch: [1][5600/36908] Elapsed 19m 24s (remain 108m 26s) Loss: 0.0001(0.0308) Grad: 116.9306  LR: 0.000006  \n","Epoch: [1][5700/36908] Elapsed 19m 44s (remain 108m 5s) Loss: 0.0005(0.0303) Grad: 339.1988  LR: 0.000006  \n","Epoch: [1][5800/36908] Elapsed 20m 5s (remain 107m 44s) Loss: 0.0005(0.0298) Grad: 367.5384  LR: 0.000006  \n","Epoch: [1][5900/36908] Elapsed 20m 26s (remain 107m 23s) Loss: 0.0005(0.0294) Grad: 342.5567  LR: 0.000006  \n","Epoch: [1][6000/36908] Elapsed 20m 47s (remain 107m 2s) Loss: 0.0057(0.0290) Grad: 1395.3435  LR: 0.000007  \n","Epoch: [1][6100/36908] Elapsed 21m 7s (remain 106m 41s) Loss: 0.0003(0.0286) Grad: 221.0333  LR: 0.000007  \n","Epoch: [1][6200/36908] Elapsed 21m 28s (remain 106m 20s) Loss: 0.0000(0.0281) Grad: 72.6625  LR: 0.000007  \n","Epoch: [1][6300/36908] Elapsed 21m 49s (remain 105m 59s) Loss: 0.0125(0.0278) Grad: 3277.2700  LR: 0.000007  \n","Epoch: [1][6400/36908] Elapsed 22m 10s (remain 105m 39s) Loss: 0.0001(0.0274) Grad: 105.9760  LR: 0.000007  \n","Epoch: [1][6500/36908] Elapsed 22m 30s (remain 105m 18s) Loss: 0.0000(0.0270) Grad: 58.7276  LR: 0.000007  \n","Epoch: [1][6600/36908] Elapsed 22m 51s (remain 104m 57s) Loss: 0.0001(0.0267) Grad: 71.4644  LR: 0.000007  \n","Epoch: [1][6700/36908] Elapsed 23m 12s (remain 104m 37s) Loss: 0.0001(0.0263) Grad: 79.4409  LR: 0.000007  \n","Epoch: [1][6800/36908] Elapsed 23m 33s (remain 104m 16s) Loss: 0.0000(0.0260) Grad: 40.6606  LR: 0.000007  \n","Epoch: [1][6900/36908] Elapsed 23m 54s (remain 103m 56s) Loss: 0.0373(0.0257) Grad: 14588.5234  LR: 0.000007  \n","Epoch: [1][7000/36908] Elapsed 24m 15s (remain 103m 36s) Loss: 0.0004(0.0254) Grad: 310.9855  LR: 0.000008  \n","Epoch: [1][7100/36908] Elapsed 24m 36s (remain 103m 15s) Loss: 0.0001(0.0251) Grad: 113.5873  LR: 0.000008  \n","Epoch: [1][7200/36908] Elapsed 24m 56s (remain 102m 55s) Loss: 0.0002(0.0248) Grad: 147.8221  LR: 0.000008  \n","Epoch: [1][7300/36908] Elapsed 25m 17s (remain 102m 35s) Loss: 0.0002(0.0245) Grad: 188.9463  LR: 0.000008  \n","Epoch: [1][7400/36908] Elapsed 25m 38s (remain 102m 14s) Loss: 0.0001(0.0242) Grad: 71.4664  LR: 0.000008  \n","Epoch: [1][7500/36908] Elapsed 25m 59s (remain 101m 54s) Loss: 0.0002(0.0240) Grad: 166.6822  LR: 0.000008  \n","Epoch: [1][7600/36908] Elapsed 26m 20s (remain 101m 33s) Loss: 0.0002(0.0238) Grad: 118.7566  LR: 0.000008  \n","Epoch: [1][7700/36908] Elapsed 26m 41s (remain 101m 12s) Loss: 0.0001(0.0235) Grad: 67.3422  LR: 0.000008  \n","Epoch: [1][7800/36908] Elapsed 27m 2s (remain 100m 52s) Loss: 0.0000(0.0233) Grad: 33.9256  LR: 0.000008  \n","Epoch: [1][7900/36908] Elapsed 27m 22s (remain 100m 31s) Loss: 0.0005(0.0230) Grad: 328.9369  LR: 0.000009  \n","Epoch: [1][8000/36908] Elapsed 27m 43s (remain 100m 10s) Loss: 0.0000(0.0228) Grad: 17.7837  LR: 0.000009  \n","Epoch: [1][8100/36908] Elapsed 28m 4s (remain 99m 49s) Loss: 0.0158(0.0225) Grad: 2676.4854  LR: 0.000009  \n","Epoch: [1][8200/36908] Elapsed 28m 25s (remain 99m 29s) Loss: 0.0001(0.0223) Grad: 102.1091  LR: 0.000009  \n","Epoch: [1][8300/36908] Elapsed 28m 46s (remain 99m 8s) Loss: 0.0002(0.0221) Grad: 187.0862  LR: 0.000009  \n","Epoch: [1][8400/36908] Elapsed 29m 6s (remain 98m 47s) Loss: 0.0183(0.0219) Grad: 7132.3804  LR: 0.000009  \n","Epoch: [1][8500/36908] Elapsed 29m 27s (remain 98m 27s) Loss: 0.0001(0.0217) Grad: 197.1497  LR: 0.000009  \n","Epoch: [1][8600/36908] Elapsed 29m 48s (remain 98m 6s) Loss: 0.0001(0.0215) Grad: 90.9472  LR: 0.000009  \n","Epoch: [1][8700/36908] Elapsed 30m 9s (remain 97m 45s) Loss: 0.0001(0.0213) Grad: 155.5876  LR: 0.000009  \n","Epoch: [1][8800/36908] Elapsed 30m 29s (remain 97m 24s) Loss: 0.0003(0.0211) Grad: 298.6680  LR: 0.000010  \n","Epoch: [1][8900/36908] Elapsed 30m 50s (remain 97m 2s) Loss: 0.0000(0.0209) Grad: 26.8335  LR: 0.000010  \n","Epoch: [1][9000/36908] Elapsed 31m 11s (remain 96m 41s) Loss: 0.0002(0.0207) Grad: 225.0251  LR: 0.000010  \n","Epoch: [1][9100/36908] Elapsed 31m 31s (remain 96m 20s) Loss: 0.0001(0.0205) Grad: 105.7310  LR: 0.000010  \n","Epoch: [1][9200/36908] Elapsed 31m 52s (remain 95m 59s) Loss: 0.0184(0.0203) Grad: 6380.2754  LR: 0.000010  \n","Epoch: [1][9300/36908] Elapsed 32m 13s (remain 95m 38s) Loss: 0.0000(0.0201) Grad: 69.2217  LR: 0.000010  \n","Epoch: [1][9400/36908] Elapsed 32m 34s (remain 95m 17s) Loss: 0.0091(0.0200) Grad: 3368.9927  LR: 0.000010  \n","Epoch: [1][9500/36908] Elapsed 32m 54s (remain 94m 56s) Loss: 0.0318(0.0198) Grad: 15424.4971  LR: 0.000010  \n","Epoch: [1][9600/36908] Elapsed 33m 15s (remain 94m 35s) Loss: 0.0001(0.0196) Grad: 100.8308  LR: 0.000010  \n","Epoch: [1][9700/36908] Elapsed 33m 36s (remain 94m 14s) Loss: 0.0001(0.0194) Grad: 122.9409  LR: 0.000011  \n","Epoch: [1][9800/36908] Elapsed 33m 56s (remain 93m 53s) Loss: 0.0000(0.0193) Grad: 69.2245  LR: 0.000011  \n","Epoch: [1][9900/36908] Elapsed 34m 17s (remain 93m 32s) Loss: 0.0192(0.0191) Grad: 5938.4233  LR: 0.000011  \n","Epoch: [1][10000/36908] Elapsed 34m 38s (remain 93m 11s) Loss: 0.0001(0.0190) Grad: 104.4007  LR: 0.000011  \n","Epoch: [1][10100/36908] Elapsed 34m 59s (remain 92m 50s) Loss: 0.0003(0.0188) Grad: 302.9921  LR: 0.000011  \n","Epoch: [1][10200/36908] Elapsed 35m 19s (remain 92m 29s) Loss: 0.0000(0.0187) Grad: 79.1103  LR: 0.000011  \n","Epoch: [1][10300/36908] Elapsed 35m 40s (remain 92m 8s) Loss: 0.0001(0.0185) Grad: 101.5871  LR: 0.000011  \n","Epoch: [1][10400/36908] Elapsed 36m 1s (remain 91m 47s) Loss: 0.0023(0.0184) Grad: 2302.3708  LR: 0.000011  \n","Epoch: [1][10500/36908] Elapsed 36m 21s (remain 91m 26s) Loss: 0.0404(0.0183) Grad: 28708.8340  LR: 0.000011  \n","Epoch: [1][10600/36908] Elapsed 36m 42s (remain 91m 5s) Loss: 0.0001(0.0181) Grad: 147.7440  LR: 0.000011  \n","Epoch: [1][10700/36908] Elapsed 37m 3s (remain 90m 44s) Loss: 0.0001(0.0180) Grad: 160.6362  LR: 0.000012  \n","Epoch: [1][10800/36908] Elapsed 37m 23s (remain 90m 23s) Loss: 0.0018(0.0178) Grad: 1138.4362  LR: 0.000012  \n","Epoch: [1][10900/36908] Elapsed 37m 44s (remain 90m 2s) Loss: 0.0001(0.0177) Grad: 87.9639  LR: 0.000012  \n","Epoch: [1][11000/36908] Elapsed 38m 5s (remain 89m 41s) Loss: 0.0294(0.0176) Grad: 8037.6050  LR: 0.000012  \n","Epoch: [1][11100/36908] Elapsed 38m 25s (remain 89m 20s) Loss: 0.0002(0.0174) Grad: 322.4915  LR: 0.000012  \n","Epoch: [1][11200/36908] Elapsed 38m 46s (remain 88m 59s) Loss: 0.0352(0.0173) Grad: 8644.5449  LR: 0.000012  \n","Epoch: [1][11300/36908] Elapsed 39m 7s (remain 88m 39s) Loss: 0.0002(0.0172) Grad: 255.1845  LR: 0.000012  \n","Epoch: [1][11400/36908] Elapsed 39m 28s (remain 88m 18s) Loss: 0.0000(0.0171) Grad: 45.1749  LR: 0.000012  \n","Epoch: [1][11500/36908] Elapsed 39m 48s (remain 87m 57s) Loss: 0.0002(0.0170) Grad: 267.3304  LR: 0.000012  \n","Epoch: [1][11600/36908] Elapsed 40m 9s (remain 87m 36s) Loss: 0.0001(0.0169) Grad: 149.4252  LR: 0.000013  \n","Epoch: [1][11700/36908] Elapsed 40m 30s (remain 87m 15s) Loss: 0.0003(0.0168) Grad: 245.0232  LR: 0.000013  \n","Epoch: [1][11800/36908] Elapsed 40m 51s (remain 86m 54s) Loss: 0.0002(0.0167) Grad: 236.3272  LR: 0.000013  \n","Epoch: [1][11900/36908] Elapsed 41m 11s (remain 86m 34s) Loss: 0.0000(0.0166) Grad: 32.3806  LR: 0.000013  \n","Epoch: [1][12000/36908] Elapsed 41m 32s (remain 86m 13s) Loss: 0.0001(0.0165) Grad: 121.8832  LR: 0.000013  \n","Epoch: [1][12100/36908] Elapsed 41m 53s (remain 85m 52s) Loss: 0.0001(0.0164) Grad: 100.3684  LR: 0.000013  \n","Epoch: [1][12200/36908] Elapsed 42m 14s (remain 85m 31s) Loss: 0.0000(0.0163) Grad: 155.1507  LR: 0.000013  \n","Epoch: [1][12300/36908] Elapsed 42m 34s (remain 85m 10s) Loss: 0.0001(0.0162) Grad: 295.2373  LR: 0.000013  \n","Epoch: [1][12400/36908] Elapsed 42m 55s (remain 84m 50s) Loss: 0.0022(0.0161) Grad: 4677.3691  LR: 0.000013  \n","Epoch: [1][12500/36908] Elapsed 43m 16s (remain 84m 29s) Loss: 0.0021(0.0160) Grad: 1792.1609  LR: 0.000014  \n","Epoch: [1][12600/36908] Elapsed 43m 37s (remain 84m 8s) Loss: 0.0002(0.0159) Grad: 424.9776  LR: 0.000014  \n","Epoch: [1][12700/36908] Elapsed 43m 57s (remain 83m 47s) Loss: 0.0001(0.0158) Grad: 133.3063  LR: 0.000014  \n","Epoch: [1][12800/36908] Elapsed 44m 18s (remain 83m 26s) Loss: 0.0000(0.0157) Grad: 21.7495  LR: 0.000014  \n","Epoch: [1][12900/36908] Elapsed 44m 39s (remain 83m 6s) Loss: 0.0001(0.0156) Grad: 170.0653  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 45m 0s (remain 82m 45s) Loss: 0.0001(0.0155) Grad: 157.4510  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 45m 20s (remain 82m 24s) Loss: 0.0137(0.0154) Grad: 9881.8711  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 45m 41s (remain 82m 3s) Loss: 0.0000(0.0153) Grad: 69.9452  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 46m 2s (remain 81m 42s) Loss: 0.0001(0.0153) Grad: 306.9943  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 46m 23s (remain 81m 21s) Loss: 0.0001(0.0152) Grad: 177.3258  LR: 0.000015  \n","Epoch: [1][13500/36908] Elapsed 46m 43s (remain 81m 1s) Loss: 0.0000(0.0151) Grad: 120.4616  LR: 0.000015  \n","Epoch: [1][13600/36908] Elapsed 47m 4s (remain 80m 40s) Loss: 0.0000(0.0150) Grad: 21.1717  LR: 0.000015  \n","Epoch: [1][13700/36908] Elapsed 47m 25s (remain 80m 19s) Loss: 0.0000(0.0149) Grad: 116.3743  LR: 0.000015  \n","Epoch: [1][13800/36908] Elapsed 47m 46s (remain 79m 58s) Loss: 0.0055(0.0148) Grad: 3749.3391  LR: 0.000015  \n","Epoch: [1][13900/36908] Elapsed 48m 6s (remain 79m 37s) Loss: 0.0195(0.0148) Grad: 9968.8545  LR: 0.000015  \n","Epoch: [1][14000/36908] Elapsed 48m 27s (remain 79m 16s) Loss: 0.0000(0.0147) Grad: 93.4822  LR: 0.000015  \n","Epoch: [1][14100/36908] Elapsed 48m 48s (remain 78m 56s) Loss: 0.0004(0.0146) Grad: 914.5122  LR: 0.000015  \n","Epoch: [1][14200/36908] Elapsed 49m 9s (remain 78m 35s) Loss: 0.0212(0.0145) Grad: 8822.2383  LR: 0.000015  \n","Epoch: [1][14300/36908] Elapsed 49m 29s (remain 78m 14s) Loss: 0.0050(0.0145) Grad: 3371.8411  LR: 0.000015  \n","Epoch: [1][14400/36908] Elapsed 49m 50s (remain 77m 53s) Loss: 0.0211(0.0144) Grad: 9904.7148  LR: 0.000016  \n","Epoch: [1][14500/36908] Elapsed 50m 11s (remain 77m 33s) Loss: 0.0000(0.0143) Grad: 33.1449  LR: 0.000016  \n","Epoch: [1][14600/36908] Elapsed 50m 32s (remain 77m 12s) Loss: 0.0000(0.0142) Grad: 5.4298  LR: 0.000016  \n","Epoch: [1][14700/36908] Elapsed 50m 52s (remain 76m 51s) Loss: 0.0001(0.0142) Grad: 176.0247  LR: 0.000016  \n","Epoch: [1][14800/36908] Elapsed 51m 13s (remain 76m 30s) Loss: 0.0000(0.0141) Grad: 56.4007  LR: 0.000016  \n","Epoch: [1][14900/36908] Elapsed 51m 34s (remain 76m 10s) Loss: 0.0001(0.0140) Grad: 232.7216  LR: 0.000016  \n","Epoch: [1][15000/36908] Elapsed 51m 55s (remain 75m 49s) Loss: 0.0370(0.0140) Grad: 20885.4316  LR: 0.000016  \n","Epoch: [1][15100/36908] Elapsed 52m 15s (remain 75m 28s) Loss: 0.0372(0.0139) Grad: 92327.4531  LR: 0.000016  \n","Epoch: [1][15200/36908] Elapsed 52m 36s (remain 75m 7s) Loss: 0.0058(0.0138) Grad: 5425.5566  LR: 0.000016  \n","Epoch: [1][15300/36908] Elapsed 52m 57s (remain 74m 47s) Loss: 0.0000(0.0138) Grad: 107.2550  LR: 0.000017  \n","Epoch: [1][15400/36908] Elapsed 53m 18s (remain 74m 26s) Loss: 0.0031(0.0137) Grad: 4619.2563  LR: 0.000017  \n","Epoch: [1][15500/36908] Elapsed 53m 39s (remain 74m 5s) Loss: 0.0002(0.0136) Grad: 334.3709  LR: 0.000017  \n","Epoch: [1][15600/36908] Elapsed 54m 0s (remain 73m 45s) Loss: 0.0000(0.0136) Grad: 76.7849  LR: 0.000017  \n","Epoch: [1][15700/36908] Elapsed 54m 20s (remain 73m 24s) Loss: 0.0001(0.0135) Grad: 307.3398  LR: 0.000017  \n","Epoch: [1][15800/36908] Elapsed 54m 41s (remain 73m 3s) Loss: 0.0001(0.0135) Grad: 198.4218  LR: 0.000017  \n","Epoch: [1][15900/36908] Elapsed 55m 2s (remain 72m 43s) Loss: 0.0000(0.0134) Grad: 122.7045  LR: 0.000017  \n","Epoch: [1][16000/36908] Elapsed 55m 23s (remain 72m 22s) Loss: 0.0427(0.0134) Grad: 39129.5352  LR: 0.000017  \n","Epoch: [1][16100/36908] Elapsed 55m 44s (remain 72m 1s) Loss: 0.0096(0.0133) Grad: 6303.3408  LR: 0.000017  \n","Epoch: [1][16200/36908] Elapsed 56m 5s (remain 71m 41s) Loss: 0.0000(0.0132) Grad: 109.1793  LR: 0.000018  \n","Epoch: [1][16300/36908] Elapsed 56m 25s (remain 71m 20s) Loss: 0.0072(0.0132) Grad: 8950.8203  LR: 0.000018  \n","Epoch: [1][16400/36908] Elapsed 56m 46s (remain 70m 59s) Loss: 0.0000(0.0131) Grad: 48.6734  LR: 0.000018  \n","Epoch: [1][16500/36908] Elapsed 57m 7s (remain 70m 38s) Loss: 0.0000(0.0131) Grad: 193.8769  LR: 0.000018  \n","Epoch: [1][16600/36908] Elapsed 57m 28s (remain 70m 18s) Loss: 0.0551(0.0130) Grad: 43453.2227  LR: 0.000018  \n","Epoch: [1][16700/36908] Elapsed 57m 49s (remain 69m 57s) Loss: 0.0000(0.0130) Grad: 218.2900  LR: 0.000018  \n","Epoch: [1][16800/36908] Elapsed 58m 9s (remain 69m 36s) Loss: 0.0001(0.0129) Grad: 222.9165  LR: 0.000018  \n","Epoch: [1][16900/36908] Elapsed 58m 30s (remain 69m 16s) Loss: 0.0265(0.0129) Grad: 19991.3574  LR: 0.000018  \n","Epoch: [1][17000/36908] Elapsed 58m 51s (remain 68m 55s) Loss: 0.0001(0.0128) Grad: 320.8083  LR: 0.000018  \n","Epoch: [1][17100/36908] Elapsed 59m 12s (remain 68m 34s) Loss: 0.0000(0.0128) Grad: 76.3906  LR: 0.000019  \n","Epoch: [1][17200/36908] Elapsed 59m 33s (remain 68m 14s) Loss: 0.0000(0.0127) Grad: 141.8268  LR: 0.000019  \n","Epoch: [1][17300/36908] Elapsed 59m 54s (remain 67m 53s) Loss: 0.0000(0.0127) Grad: 52.7250  LR: 0.000019  \n","Epoch: [1][17400/36908] Elapsed 60m 14s (remain 67m 32s) Loss: 0.0000(0.0126) Grad: 130.0928  LR: 0.000019  \n","Epoch: [1][17500/36908] Elapsed 60m 35s (remain 67m 11s) Loss: 0.0000(0.0126) Grad: 114.3733  LR: 0.000019  \n","Epoch: [1][17600/36908] Elapsed 60m 56s (remain 66m 50s) Loss: 0.0001(0.0125) Grad: 394.3010  LR: 0.000019  \n","Epoch: [1][17700/36908] Elapsed 61m 17s (remain 66m 29s) Loss: 0.0000(0.0125) Grad: 124.3419  LR: 0.000019  \n","Epoch: [1][17800/36908] Elapsed 61m 37s (remain 66m 9s) Loss: 0.0000(0.0124) Grad: 129.6778  LR: 0.000019  \n","Epoch: [1][17900/36908] Elapsed 61m 58s (remain 65m 48s) Loss: 0.0000(0.0124) Grad: 41.9966  LR: 0.000019  \n","Epoch: [1][18000/36908] Elapsed 62m 19s (remain 65m 27s) Loss: 0.0001(0.0123) Grad: 208.0918  LR: 0.000020  \n","Epoch: [1][18100/36908] Elapsed 62m 40s (remain 65m 6s) Loss: 0.0000(0.0123) Grad: 179.1699  LR: 0.000020  \n","Epoch: [1][18200/36908] Elapsed 63m 0s (remain 64m 45s) Loss: 0.0000(0.0123) Grad: 113.0230  LR: 0.000020  \n","Epoch: [1][18300/36908] Elapsed 63m 21s (remain 64m 24s) Loss: 0.0001(0.0122) Grad: 347.0984  LR: 0.000020  \n","Epoch: [1][18400/36908] Elapsed 63m 42s (remain 64m 4s) Loss: 0.0000(0.0122) Grad: 149.0704  LR: 0.000020  \n","Epoch: [1][18500/36908] Elapsed 64m 3s (remain 63m 43s) Loss: 0.0000(0.0121) Grad: 67.5639  LR: 0.000020  \n","Epoch: [1][18600/36908] Elapsed 64m 23s (remain 63m 22s) Loss: 0.0000(0.0121) Grad: 24.8121  LR: 0.000020  \n","Epoch: [1][18700/36908] Elapsed 64m 44s (remain 63m 2s) Loss: 0.0000(0.0120) Grad: 242.9715  LR: 0.000020  \n","Epoch: [1][18800/36908] Elapsed 65m 5s (remain 62m 41s) Loss: 0.0000(0.0120) Grad: 39.5939  LR: 0.000020  \n","Epoch: [1][18900/36908] Elapsed 65m 26s (remain 62m 20s) Loss: 0.0000(0.0120) Grad: 48.3496  LR: 0.000020  \n","Epoch: [1][19000/36908] Elapsed 65m 47s (remain 61m 59s) Loss: 0.0001(0.0119) Grad: 561.2372  LR: 0.000020  \n","Epoch: [1][19100/36908] Elapsed 66m 7s (remain 61m 38s) Loss: 0.0001(0.0119) Grad: 285.9305  LR: 0.000020  \n","Epoch: [1][19200/36908] Elapsed 66m 28s (remain 61m 18s) Loss: 0.0000(0.0118) Grad: 132.7386  LR: 0.000020  \n","Epoch: [1][19300/36908] Elapsed 66m 49s (remain 60m 57s) Loss: 0.0000(0.0118) Grad: 108.1097  LR: 0.000020  \n","Epoch: [1][19400/36908] Elapsed 67m 9s (remain 60m 36s) Loss: 0.0234(0.0118) Grad: 27843.1484  LR: 0.000020  \n","Epoch: [1][19500/36908] Elapsed 67m 30s (remain 60m 15s) Loss: 0.0001(0.0117) Grad: 284.1605  LR: 0.000020  \n","Epoch: [1][19600/36908] Elapsed 67m 51s (remain 59m 54s) Loss: 0.0002(0.0117) Grad: 819.5211  LR: 0.000020  \n","Epoch: [1][19700/36908] Elapsed 68m 12s (remain 59m 34s) Loss: 0.0000(0.0117) Grad: 86.7792  LR: 0.000020  \n","Epoch: [1][19800/36908] Elapsed 68m 32s (remain 59m 13s) Loss: 0.0000(0.0116) Grad: 210.7444  LR: 0.000020  \n","Epoch: [1][19900/36908] Elapsed 68m 53s (remain 58m 52s) Loss: 0.0252(0.0116) Grad: 18642.5977  LR: 0.000020  \n","Epoch: [1][20000/36908] Elapsed 69m 14s (remain 58m 31s) Loss: 0.0000(0.0116) Grad: 190.6274  LR: 0.000020  \n","Epoch: [1][20100/36908] Elapsed 69m 35s (remain 58m 10s) Loss: 0.0000(0.0115) Grad: 138.3407  LR: 0.000020  \n","Epoch: [1][20200/36908] Elapsed 69m 55s (remain 57m 50s) Loss: 0.0000(0.0115) Grad: 135.4988  LR: 0.000020  \n","Epoch: [1][20300/36908] Elapsed 70m 16s (remain 57m 29s) Loss: 0.0000(0.0115) Grad: 154.9842  LR: 0.000020  \n","Epoch: [1][20400/36908] Elapsed 70m 37s (remain 57m 8s) Loss: 0.0000(0.0114) Grad: 27.0895  LR: 0.000020  \n","Epoch: [1][20500/36908] Elapsed 70m 58s (remain 56m 47s) Loss: 0.0000(0.0114) Grad: 99.0725  LR: 0.000020  \n","Epoch: [1][20600/36908] Elapsed 71m 19s (remain 56m 27s) Loss: 0.0000(0.0114) Grad: 213.1501  LR: 0.000020  \n","Epoch: [1][20700/36908] Elapsed 71m 39s (remain 56m 6s) Loss: 0.0036(0.0113) Grad: 9339.1250  LR: 0.000020  \n","Epoch: [1][20800/36908] Elapsed 72m 0s (remain 55m 45s) Loss: 0.0186(0.0113) Grad: 89762.0156  LR: 0.000020  \n","Epoch: [1][20900/36908] Elapsed 72m 21s (remain 55m 25s) Loss: 0.0000(0.0112) Grad: 130.9485  LR: 0.000020  \n","Epoch: [1][21000/36908] Elapsed 72m 42s (remain 55m 4s) Loss: 0.0291(0.0112) Grad: 171343.6875  LR: 0.000020  \n","Epoch: [1][21100/36908] Elapsed 73m 3s (remain 54m 43s) Loss: 0.0000(0.0112) Grad: 135.0330  LR: 0.000020  \n","Epoch: [1][21200/36908] Elapsed 73m 24s (remain 54m 22s) Loss: 0.0000(0.0112) Grad: 364.8858  LR: 0.000020  \n","Epoch: [1][21300/36908] Elapsed 73m 45s (remain 54m 2s) Loss: 0.0069(0.0111) Grad: 14359.1973  LR: 0.000020  \n","Epoch: [1][21400/36908] Elapsed 74m 6s (remain 53m 41s) Loss: 0.0000(0.0111) Grad: 14.5155  LR: 0.000020  \n","Epoch: [1][21500/36908] Elapsed 74m 26s (remain 53m 20s) Loss: 0.0001(0.0111) Grad: 484.0001  LR: 0.000020  \n","Epoch: [1][21600/36908] Elapsed 74m 47s (remain 53m 0s) Loss: 0.0000(0.0110) Grad: 116.5263  LR: 0.000020  \n","Epoch: [1][21700/36908] Elapsed 75m 8s (remain 52m 39s) Loss: 0.0000(0.0110) Grad: 190.7733  LR: 0.000020  \n","Epoch: [1][21800/36908] Elapsed 75m 29s (remain 52m 18s) Loss: 0.0001(0.0110) Grad: 674.6608  LR: 0.000020  \n","Epoch: [1][21900/36908] Elapsed 75m 50s (remain 51m 57s) Loss: 0.0146(0.0109) Grad: 28892.3867  LR: 0.000020  \n","Epoch: [1][22000/36908] Elapsed 76m 11s (remain 51m 37s) Loss: 0.0000(0.0109) Grad: 129.6894  LR: 0.000020  \n","Epoch: [1][22100/36908] Elapsed 76m 31s (remain 51m 16s) Loss: 0.0715(0.0109) Grad: 93592.5859  LR: 0.000020  \n","Epoch: [1][22200/36908] Elapsed 76m 52s (remain 50m 55s) Loss: 0.0000(0.0109) Grad: 297.3345  LR: 0.000020  \n","Epoch: [1][22300/36908] Elapsed 77m 13s (remain 50m 35s) Loss: 0.0000(0.0109) Grad: 732.6820  LR: 0.000020  \n","Epoch: [1][22400/36908] Elapsed 77m 34s (remain 50m 14s) Loss: 0.0000(0.0108) Grad: 152.3423  LR: 0.000020  \n","Epoch: [1][22500/36908] Elapsed 77m 55s (remain 49m 53s) Loss: 0.0001(0.0108) Grad: 790.0483  LR: 0.000020  \n","Epoch: [1][22600/36908] Elapsed 78m 16s (remain 49m 32s) Loss: 0.0419(0.0108) Grad: 71908.3438  LR: 0.000020  \n","Epoch: [1][22700/36908] Elapsed 78m 37s (remain 49m 12s) Loss: 0.0000(0.0108) Grad: 200.7118  LR: 0.000019  \n","Epoch: [1][22800/36908] Elapsed 78m 58s (remain 48m 51s) Loss: 0.0000(0.0107) Grad: 136.3348  LR: 0.000019  \n","Epoch: [1][22900/36908] Elapsed 79m 19s (remain 48m 30s) Loss: 0.0000(0.0107) Grad: 62.4425  LR: 0.000019  \n","Epoch: [1][23000/36908] Elapsed 79m 39s (remain 48m 10s) Loss: 0.0000(0.0107) Grad: 51.0821  LR: 0.000019  \n","Epoch: [1][23100/36908] Elapsed 80m 0s (remain 47m 49s) Loss: 0.0000(0.0107) Grad: 354.2086  LR: 0.000019  \n","Epoch: [1][23200/36908] Elapsed 80m 21s (remain 47m 28s) Loss: 0.0001(0.0106) Grad: 516.4479  LR: 0.000019  \n","Epoch: [1][23300/36908] Elapsed 80m 42s (remain 47m 7s) Loss: 0.0000(0.0106) Grad: 119.8365  LR: 0.000019  \n","Epoch: [1][23400/36908] Elapsed 81m 3s (remain 46m 46s) Loss: 0.0001(0.0106) Grad: 589.9783  LR: 0.000019  \n","Epoch: [1][23500/36908] Elapsed 81m 23s (remain 46m 26s) Loss: 0.0000(0.0106) Grad: 197.9907  LR: 0.000019  \n","Epoch: [1][23600/36908] Elapsed 81m 44s (remain 46m 5s) Loss: 0.0125(0.0105) Grad: 25786.9961  LR: 0.000019  \n","Epoch: [1][23700/36908] Elapsed 82m 5s (remain 45m 44s) Loss: 0.0000(0.0105) Grad: 288.8115  LR: 0.000019  \n","Epoch: [1][23800/36908] Elapsed 82m 26s (remain 45m 23s) Loss: 0.0000(0.0105) Grad: 112.7225  LR: 0.000019  \n","Epoch: [1][23900/36908] Elapsed 82m 46s (remain 45m 3s) Loss: 0.0000(0.0105) Grad: 100.6943  LR: 0.000019  \n","Epoch: [1][24000/36908] Elapsed 83m 7s (remain 44m 42s) Loss: 0.0221(0.0105) Grad: 36570.1836  LR: 0.000019  \n","Epoch: [1][24100/36908] Elapsed 83m 28s (remain 44m 21s) Loss: 0.0405(0.0104) Grad: 104248.1875  LR: 0.000019  \n","Epoch: [1][24200/36908] Elapsed 83m 49s (remain 44m 0s) Loss: 0.0000(0.0104) Grad: 65.3281  LR: 0.000019  \n","Epoch: [1][24300/36908] Elapsed 84m 10s (remain 43m 39s) Loss: 0.0000(0.0104) Grad: 103.0711  LR: 0.000019  \n","Epoch: [1][24400/36908] Elapsed 84m 30s (remain 43m 19s) Loss: 0.0000(0.0104) Grad: 96.9876  LR: 0.000019  \n","Epoch: [1][24500/36908] Elapsed 84m 51s (remain 42m 58s) Loss: 0.0000(0.0103) Grad: 552.1018  LR: 0.000019  \n","Epoch: [1][24600/36908] Elapsed 85m 12s (remain 42m 37s) Loss: 0.0000(0.0103) Grad: 156.2090  LR: 0.000019  \n","Epoch: [1][24700/36908] Elapsed 85m 32s (remain 42m 16s) Loss: 0.0000(0.0103) Grad: 165.9576  LR: 0.000019  \n","Epoch: [1][24800/36908] Elapsed 85m 53s (remain 41m 55s) Loss: 0.0000(0.0103) Grad: 66.3440  LR: 0.000019  \n","Epoch: [1][24900/36908] Elapsed 86m 14s (remain 41m 34s) Loss: 0.0000(0.0102) Grad: 343.9207  LR: 0.000019  \n","Epoch: [1][25000/36908] Elapsed 86m 35s (remain 41m 14s) Loss: 0.0000(0.0102) Grad: 153.0472  LR: 0.000019  \n","Epoch: [1][25100/36908] Elapsed 86m 55s (remain 40m 53s) Loss: 0.0078(0.0102) Grad: 30583.2305  LR: 0.000019  \n","Epoch: [1][25200/36908] Elapsed 87m 16s (remain 40m 32s) Loss: 0.0000(0.0102) Grad: 510.5798  LR: 0.000019  \n","Epoch: [1][25300/36908] Elapsed 87m 37s (remain 40m 11s) Loss: 0.0278(0.0101) Grad: 108578.8594  LR: 0.000019  \n","Epoch: [1][25400/36908] Elapsed 87m 57s (remain 39m 50s) Loss: 0.0000(0.0101) Grad: 289.4583  LR: 0.000019  \n","Epoch: [1][25500/36908] Elapsed 88m 18s (remain 39m 30s) Loss: 0.0000(0.0101) Grad: 282.0594  LR: 0.000019  \n","Epoch: [1][25600/36908] Elapsed 88m 39s (remain 39m 9s) Loss: 0.0000(0.0101) Grad: 328.4149  LR: 0.000019  \n","Epoch: [1][25700/36908] Elapsed 89m 0s (remain 38m 48s) Loss: 0.0000(0.0101) Grad: 225.5408  LR: 0.000019  \n","Epoch: [1][25800/36908] Elapsed 89m 20s (remain 38m 27s) Loss: 0.0000(0.0100) Grad: 99.1400  LR: 0.000019  \n","Epoch: [1][25900/36908] Elapsed 89m 41s (remain 38m 6s) Loss: 0.0000(0.0100) Grad: 136.0928  LR: 0.000019  \n","Epoch: [1][26000/36908] Elapsed 90m 2s (remain 37m 46s) Loss: 0.0000(0.0100) Grad: 109.1874  LR: 0.000019  \n","Epoch: [1][26100/36908] Elapsed 90m 22s (remain 37m 25s) Loss: 0.0000(0.0100) Grad: 96.0567  LR: 0.000019  \n","Epoch: [1][26200/36908] Elapsed 90m 43s (remain 37m 4s) Loss: 0.0000(0.0100) Grad: 155.6825  LR: 0.000019  \n","Epoch: [1][26300/36908] Elapsed 91m 4s (remain 36m 43s) Loss: 0.0000(0.0099) Grad: 91.9105  LR: 0.000019  \n","Epoch: [1][26400/36908] Elapsed 91m 25s (remain 36m 22s) Loss: 0.0715(0.0099) Grad: 195669.9844  LR: 0.000019  \n","Epoch: [1][26500/36908] Elapsed 91m 45s (remain 36m 2s) Loss: 0.0000(0.0099) Grad: 198.7456  LR: 0.000019  \n","Epoch: [1][26600/36908] Elapsed 92m 6s (remain 35m 41s) Loss: 0.0184(0.0099) Grad: 69526.9844  LR: 0.000019  \n","Epoch: [1][26700/36908] Elapsed 92m 27s (remain 35m 20s) Loss: 0.0000(0.0099) Grad: 125.9781  LR: 0.000019  \n","Epoch: [1][26800/36908] Elapsed 92m 47s (remain 34m 59s) Loss: 0.0000(0.0099) Grad: 269.5834  LR: 0.000019  \n","Epoch: [1][26900/36908] Elapsed 93m 8s (remain 34m 38s) Loss: 0.0343(0.0098) Grad: 88610.6719  LR: 0.000019  \n","Epoch: [1][27000/36908] Elapsed 93m 29s (remain 34m 18s) Loss: 0.0000(0.0098) Grad: 159.0363  LR: 0.000019  \n","Epoch: [1][27100/36908] Elapsed 93m 50s (remain 33m 57s) Loss: 0.0000(0.0098) Grad: 152.8272  LR: 0.000019  \n","Epoch: [1][27200/36908] Elapsed 94m 11s (remain 33m 36s) Loss: 0.0000(0.0098) Grad: 42.2534  LR: 0.000019  \n","Epoch: [1][27300/36908] Elapsed 94m 31s (remain 33m 15s) Loss: 0.0000(0.0098) Grad: 261.0932  LR: 0.000019  \n","Epoch: [1][27400/36908] Elapsed 94m 52s (remain 32m 55s) Loss: 0.0000(0.0098) Grad: 65.8186  LR: 0.000019  \n","Epoch: [1][27500/36908] Elapsed 95m 13s (remain 32m 34s) Loss: 0.0000(0.0097) Grad: 484.8035  LR: 0.000019  \n","Epoch: [1][27600/36908] Elapsed 95m 34s (remain 32m 13s) Loss: 0.0000(0.0097) Grad: 750.3901  LR: 0.000019  \n","Epoch: [1][27700/36908] Elapsed 95m 54s (remain 31m 52s) Loss: 0.0000(0.0097) Grad: 77.4887  LR: 0.000019  \n","Epoch: [1][27800/36908] Elapsed 96m 15s (remain 31m 31s) Loss: 0.0000(0.0097) Grad: 197.8020  LR: 0.000019  \n","Epoch: [1][27900/36908] Elapsed 96m 36s (remain 31m 11s) Loss: 0.0000(0.0097) Grad: 286.1324  LR: 0.000019  \n","Epoch: [1][28000/36908] Elapsed 96m 57s (remain 30m 50s) Loss: 0.0000(0.0096) Grad: 139.9271  LR: 0.000019  \n","Epoch: [1][28100/36908] Elapsed 97m 17s (remain 30m 29s) Loss: 0.0000(0.0096) Grad: 128.2771  LR: 0.000019  \n","Epoch: [1][28200/36908] Elapsed 97m 38s (remain 30m 8s) Loss: 0.0000(0.0096) Grad: 216.9006  LR: 0.000019  \n","Epoch: [1][28300/36908] Elapsed 97m 59s (remain 29m 48s) Loss: 0.0000(0.0096) Grad: 97.9585  LR: 0.000019  \n","Epoch: [1][28400/36908] Elapsed 98m 20s (remain 29m 27s) Loss: 0.0000(0.0096) Grad: 174.2410  LR: 0.000019  \n","Epoch: [1][28500/36908] Elapsed 98m 41s (remain 29m 6s) Loss: 0.0000(0.0095) Grad: 192.4050  LR: 0.000019  \n","Epoch: [1][28600/36908] Elapsed 99m 1s (remain 28m 45s) Loss: 0.0165(0.0095) Grad: 60684.4570  LR: 0.000019  \n","Epoch: [1][28700/36908] Elapsed 99m 22s (remain 28m 25s) Loss: 0.0000(0.0095) Grad: 141.4018  LR: 0.000019  \n","Epoch: [1][28800/36908] Elapsed 99m 43s (remain 28m 4s) Loss: 0.0000(0.0095) Grad: 305.7288  LR: 0.000019  \n","Epoch: [1][28900/36908] Elapsed 100m 4s (remain 27m 43s) Loss: 0.0147(0.0095) Grad: 48474.9375  LR: 0.000019  \n","Epoch: [1][29000/36908] Elapsed 100m 25s (remain 27m 22s) Loss: 0.0213(0.0095) Grad: 54996.6836  LR: 0.000019  \n","Epoch: [1][29100/36908] Elapsed 100m 45s (remain 27m 1s) Loss: 0.0000(0.0095) Grad: 121.1081  LR: 0.000019  \n","Epoch: [1][29200/36908] Elapsed 101m 6s (remain 26m 41s) Loss: 0.0000(0.0095) Grad: 283.8271  LR: 0.000019  \n","Epoch: [1][29300/36908] Elapsed 101m 27s (remain 26m 20s) Loss: 0.0000(0.0094) Grad: 3.8966  LR: 0.000019  \n","Epoch: [1][29400/36908] Elapsed 101m 47s (remain 25m 59s) Loss: 0.0000(0.0094) Grad: 182.2764  LR: 0.000019  \n","Epoch: [1][29500/36908] Elapsed 102m 8s (remain 25m 38s) Loss: 0.0000(0.0094) Grad: 153.1753  LR: 0.000019  \n","Epoch: [1][29600/36908] Elapsed 102m 29s (remain 25m 17s) Loss: 0.0000(0.0094) Grad: 188.7401  LR: 0.000019  \n","Epoch: [1][29700/36908] Elapsed 102m 50s (remain 24m 57s) Loss: 0.0189(0.0094) Grad: 71343.3359  LR: 0.000019  \n","Epoch: [1][29800/36908] Elapsed 103m 11s (remain 24m 36s) Loss: 0.0000(0.0094) Grad: 234.7941  LR: 0.000019  \n","Epoch: [1][29900/36908] Elapsed 103m 31s (remain 24m 15s) Loss: 0.0244(0.0094) Grad: 91111.4688  LR: 0.000019  \n","Epoch: [1][30000/36908] Elapsed 103m 52s (remain 23m 54s) Loss: 0.0391(0.0093) Grad: 110971.4219  LR: 0.000019  \n","Epoch: [1][30100/36908] Elapsed 104m 13s (remain 23m 34s) Loss: 0.0000(0.0093) Grad: 144.9074  LR: 0.000019  \n","Epoch: [1][30200/36908] Elapsed 104m 34s (remain 23m 13s) Loss: 0.0187(0.0093) Grad: 56727.8828  LR: 0.000019  \n","Epoch: [1][30300/36908] Elapsed 104m 55s (remain 22m 52s) Loss: 0.0000(0.0093) Grad: 4.0418  LR: 0.000019  \n","Epoch: [1][30400/36908] Elapsed 105m 15s (remain 22m 31s) Loss: 0.0000(0.0093) Grad: 143.8981  LR: 0.000019  \n","Epoch: [1][30500/36908] Elapsed 105m 36s (remain 22m 11s) Loss: 0.0000(0.0092) Grad: 93.4695  LR: 0.000019  \n","Epoch: [1][30600/36908] Elapsed 105m 57s (remain 21m 50s) Loss: 0.0403(0.0092) Grad: 276509.8750  LR: 0.000019  \n","Epoch: [1][30700/36908] Elapsed 106m 18s (remain 21m 29s) Loss: 0.0000(0.0092) Grad: 134.2120  LR: 0.000019  \n","Epoch: [1][30800/36908] Elapsed 106m 38s (remain 21m 8s) Loss: 0.0000(0.0092) Grad: 116.2493  LR: 0.000019  \n","Epoch: [1][30900/36908] Elapsed 106m 59s (remain 20m 47s) Loss: 0.0269(0.0092) Grad: 140123.9844  LR: 0.000019  \n","Epoch: [1][31000/36908] Elapsed 107m 20s (remain 20m 27s) Loss: 0.0567(0.0092) Grad: 592507.0000  LR: 0.000018  \n","Epoch: [1][31100/36908] Elapsed 107m 40s (remain 20m 6s) Loss: 0.0000(0.0092) Grad: 254.4708  LR: 0.000018  \n","Epoch: [1][31200/36908] Elapsed 108m 1s (remain 19m 45s) Loss: 0.0000(0.0092) Grad: 86.3643  LR: 0.000018  \n","Epoch: [1][31300/36908] Elapsed 108m 22s (remain 19m 24s) Loss: 0.0000(0.0091) Grad: 48.6847  LR: 0.000018  \n","Epoch: [1][31400/36908] Elapsed 108m 43s (remain 19m 4s) Loss: 0.0000(0.0091) Grad: 110.8120  LR: 0.000018  \n","Epoch: [1][31500/36908] Elapsed 109m 4s (remain 18m 43s) Loss: 0.0000(0.0091) Grad: 229.7683  LR: 0.000018  \n","Epoch: [1][31600/36908] Elapsed 109m 24s (remain 18m 22s) Loss: 0.0000(0.0091) Grad: 232.5061  LR: 0.000018  \n","Epoch: [1][31700/36908] Elapsed 109m 45s (remain 18m 1s) Loss: 0.0000(0.0091) Grad: 63.3441  LR: 0.000018  \n","Epoch: [1][31800/36908] Elapsed 110m 6s (remain 17m 40s) Loss: 0.0000(0.0091) Grad: 86.4094  LR: 0.000018  \n","Epoch: [1][31900/36908] Elapsed 110m 27s (remain 17m 20s) Loss: 0.0000(0.0091) Grad: 545.0925  LR: 0.000018  \n","Epoch: [1][32000/36908] Elapsed 110m 47s (remain 16m 59s) Loss: 0.0644(0.0091) Grad: 171733.0781  LR: 0.000018  \n","Epoch: [1][32100/36908] Elapsed 111m 8s (remain 16m 38s) Loss: 0.0000(0.0091) Grad: 36.0214  LR: 0.000018  \n","Epoch: [1][32200/36908] Elapsed 111m 29s (remain 16m 17s) Loss: 0.0036(0.0090) Grad: 21152.0996  LR: 0.000018  \n","Epoch: [1][32300/36908] Elapsed 111m 50s (remain 15m 57s) Loss: 0.0000(0.0090) Grad: 89.9493  LR: 0.000018  \n","Epoch: [1][32400/36908] Elapsed 112m 10s (remain 15m 36s) Loss: 0.0000(0.0090) Grad: 91.5048  LR: 0.000018  \n","Epoch: [1][32500/36908] Elapsed 112m 31s (remain 15m 15s) Loss: 0.0000(0.0090) Grad: 65.4285  LR: 0.000018  \n","Epoch: [1][32600/36908] Elapsed 112m 52s (remain 14m 54s) Loss: 0.0000(0.0090) Grad: 198.5993  LR: 0.000018  \n","Epoch: [1][32700/36908] Elapsed 113m 13s (remain 14m 33s) Loss: 0.1213(0.0090) Grad: 616195.0625  LR: 0.000018  \n","Epoch: [1][32800/36908] Elapsed 113m 34s (remain 14m 13s) Loss: 0.0000(0.0090) Grad: 209.2131  LR: 0.000018  \n","Epoch: [1][32900/36908] Elapsed 113m 54s (remain 13m 52s) Loss: 0.0000(0.0089) Grad: 26.0447  LR: 0.000018  \n","Epoch: [1][33000/36908] Elapsed 114m 15s (remain 13m 31s) Loss: 0.0000(0.0089) Grad: 39.4019  LR: 0.000018  \n","Epoch: [1][33100/36908] Elapsed 114m 36s (remain 13m 10s) Loss: 0.0031(0.0089) Grad: 30702.2852  LR: 0.000018  \n","Epoch: [1][33200/36908] Elapsed 114m 57s (remain 12m 50s) Loss: 0.0000(0.0089) Grad: 212.7865  LR: 0.000018  \n","Epoch: [1][33300/36908] Elapsed 115m 17s (remain 12m 29s) Loss: 0.0000(0.0089) Grad: 227.1188  LR: 0.000018  \n","Epoch: [1][33400/36908] Elapsed 115m 38s (remain 12m 8s) Loss: 0.0140(0.0089) Grad: 96044.1094  LR: 0.000018  \n","Epoch: [1][33500/36908] Elapsed 115m 59s (remain 11m 47s) Loss: 0.0000(0.0089) Grad: 154.9402  LR: 0.000018  \n","Epoch: [1][33600/36908] Elapsed 116m 19s (remain 11m 26s) Loss: 0.0000(0.0089) Grad: 88.1619  LR: 0.000018  \n","Epoch: [1][33700/36908] Elapsed 116m 40s (remain 11m 6s) Loss: 0.0000(0.0088) Grad: 100.1234  LR: 0.000018  \n","Epoch: [1][33800/36908] Elapsed 117m 1s (remain 10m 45s) Loss: 0.0000(0.0088) Grad: 62.5960  LR: 0.000018  \n","Epoch: [1][33900/36908] Elapsed 117m 22s (remain 10m 24s) Loss: 0.0000(0.0088) Grad: 186.3430  LR: 0.000018  \n","Epoch: [1][34000/36908] Elapsed 117m 43s (remain 10m 3s) Loss: 0.0000(0.0088) Grad: 83.1101  LR: 0.000018  \n","Epoch: [1][34100/36908] Elapsed 118m 3s (remain 9m 43s) Loss: 0.0000(0.0088) Grad: 75.4183  LR: 0.000018  \n","Epoch: [1][34200/36908] Elapsed 118m 24s (remain 9m 22s) Loss: 0.0000(0.0088) Grad: 708.6743  LR: 0.000018  \n","Epoch: [1][34300/36908] Elapsed 118m 45s (remain 9m 1s) Loss: 0.0000(0.0088) Grad: 17.4933  LR: 0.000018  \n","Epoch: [1][34400/36908] Elapsed 119m 6s (remain 8m 40s) Loss: 0.0000(0.0088) Grad: 92.4285  LR: 0.000018  \n","Epoch: [1][34500/36908] Elapsed 119m 26s (remain 8m 20s) Loss: 0.0029(0.0088) Grad: 12480.7178  LR: 0.000018  \n","Epoch: [1][34600/36908] Elapsed 119m 47s (remain 7m 59s) Loss: 0.0000(0.0088) Grad: 57.3303  LR: 0.000018  \n","Epoch: [1][34700/36908] Elapsed 120m 8s (remain 7m 38s) Loss: 0.0000(0.0088) Grad: 155.0146  LR: 0.000018  \n","Epoch: [1][34800/36908] Elapsed 120m 29s (remain 7m 17s) Loss: 0.0000(0.0087) Grad: 217.1708  LR: 0.000018  \n","Epoch: [1][34900/36908] Elapsed 120m 49s (remain 6m 56s) Loss: 0.0000(0.0087) Grad: 121.2522  LR: 0.000018  \n","Epoch: [1][35000/36908] Elapsed 121m 10s (remain 6m 36s) Loss: 0.0081(0.0087) Grad: 28164.4434  LR: 0.000018  \n","Epoch: [1][35100/36908] Elapsed 121m 31s (remain 6m 15s) Loss: 0.0000(0.0087) Grad: 68.5248  LR: 0.000018  \n","Epoch: [1][35200/36908] Elapsed 121m 52s (remain 5m 54s) Loss: 0.0000(0.0087) Grad: 150.0934  LR: 0.000018  \n","Epoch: [1][35300/36908] Elapsed 122m 13s (remain 5m 33s) Loss: 0.0000(0.0087) Grad: 10.8264  LR: 0.000018  \n","Epoch: [1][35400/36908] Elapsed 122m 34s (remain 5m 13s) Loss: 0.0000(0.0087) Grad: 407.7922  LR: 0.000018  \n","Epoch: [1][35500/36908] Elapsed 122m 55s (remain 4m 52s) Loss: 0.0000(0.0087) Grad: 241.6322  LR: 0.000018  \n","Epoch: [1][35600/36908] Elapsed 123m 15s (remain 4m 31s) Loss: 0.0088(0.0087) Grad: 41770.1875  LR: 0.000018  \n","Epoch: [1][35700/36908] Elapsed 123m 36s (remain 4m 10s) Loss: 0.0000(0.0087) Grad: 224.3281  LR: 0.000018  \n","Epoch: [1][35800/36908] Elapsed 123m 57s (remain 3m 49s) Loss: 0.0000(0.0087) Grad: 151.2770  LR: 0.000018  \n","Epoch: [1][35900/36908] Elapsed 124m 18s (remain 3m 29s) Loss: 0.0000(0.0086) Grad: 163.4430  LR: 0.000018  \n","Epoch: [1][36000/36908] Elapsed 124m 39s (remain 3m 8s) Loss: 0.0000(0.0086) Grad: 113.9443  LR: 0.000018  \n","Epoch: [1][36100/36908] Elapsed 124m 59s (remain 2m 47s) Loss: 0.0000(0.0086) Grad: 150.0226  LR: 0.000018  \n","Epoch: [1][36200/36908] Elapsed 125m 20s (remain 2m 26s) Loss: 0.0000(0.0086) Grad: 288.1446  LR: 0.000018  \n","Epoch: [1][36300/36908] Elapsed 125m 41s (remain 2m 6s) Loss: 0.0000(0.0086) Grad: 254.6996  LR: 0.000018  \n","Epoch: [1][36400/36908] Elapsed 126m 2s (remain 1m 45s) Loss: 0.0000(0.0086) Grad: 97.3119  LR: 0.000018  \n","Epoch: [1][36500/36908] Elapsed 126m 23s (remain 1m 24s) Loss: 0.0042(0.0086) Grad: 32071.8926  LR: 0.000018  \n","Epoch: [1][36600/36908] Elapsed 126m 43s (remain 1m 3s) Loss: 0.0000(0.0086) Grad: 54.3001  LR: 0.000018  \n","Epoch: [1][36700/36908] Elapsed 127m 4s (remain 0m 43s) Loss: 0.0000(0.0086) Grad: 93.2062  LR: 0.000018  \n","Epoch: [1][36800/36908] Elapsed 127m 25s (remain 0m 22s) Loss: 0.0000(0.0086) Grad: 161.3027  LR: 0.000018  \n","Epoch: [1][36900/36908] Elapsed 127m 46s (remain 0m 1s) Loss: 0.0207(0.0085) Grad: 68246.3438  LR: 0.000018  \n","Epoch: [1][36907/36908] Elapsed 127m 48s (remain 0m 0s) Loss: 0.0000(0.0085) Grad: 567.4219  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 6m 4s) Loss: 0.0447(0.0447) \n","EVAL: [100/1192] Elapsed 0m 5s (remain 0m 59s) Loss: 0.0395(0.0382) \n","EVAL: [200/1192] Elapsed 0m 10s (remain 0m 52s) Loss: 0.0360(0.0421) \n","EVAL: [300/1192] Elapsed 0m 15s (remain 0m 47s) Loss: 0.1182(0.0467) \n","EVAL: [400/1192] Elapsed 0m 21s (remain 0m 41s) Loss: 0.0673(0.0500) \n","EVAL: [500/1192] Elapsed 0m 26s (remain 0m 36s) Loss: 0.0388(0.0532) \n","EVAL: [600/1192] Elapsed 0m 31s (remain 0m 31s) Loss: 0.2489(0.0564) \n","EVAL: [700/1192] Elapsed 0m 36s (remain 0m 25s) Loss: 0.0000(0.0588) \n","EVAL: [800/1192] Elapsed 0m 41s (remain 0m 20s) Loss: 0.0918(0.0579) \n","EVAL: [900/1192] Elapsed 0m 47s (remain 0m 15s) Loss: 0.0711(0.0581) \n","EVAL: [1000/1192] Elapsed 0m 52s (remain 0m 9s) Loss: 0.0245(0.0575) \n","EVAL: [1100/1192] Elapsed 0m 57s (remain 0m 4s) Loss: 0.0091(0.0561) \n","EVAL: [1191/1192] Elapsed 1m 2s (remain 0m 0s) Loss: 0.0000(0.0543) \n","Epoch 1 - avg_train_loss: 0.0085  avg_val_loss: 0.0543  time: 7748s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","========== fold: 2 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_2.npy\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/36908] Elapsed 0m 0s (remain 304m 25s) Loss: 0.3899(0.3899) Grad: 227016.3281  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 21s (remain 129m 37s) Loss: 0.3881(0.3964) Grad: 55924.7188  LR: 0.000000  \n","Epoch: [1][200/36908] Elapsed 0m 42s (remain 128m 18s) Loss: 0.3501(0.3876) Grad: 50271.1133  LR: 0.000000  \n","Epoch: [1][300/36908] Elapsed 1m 2s (remain 127m 40s) Loss: 0.3172(0.3738) Grad: 52524.4258  LR: 0.000000  \n","Epoch: [1][400/36908] Elapsed 1m 23s (remain 127m 8s) Loss: 0.2649(0.3544) Grad: 21694.0000  LR: 0.000000  \n","Epoch: [1][500/36908] Elapsed 1m 44s (remain 126m 41s) Loss: 0.2058(0.3288) Grad: 16917.1582  LR: 0.000001  \n","Epoch: [1][600/36908] Elapsed 2m 5s (remain 126m 15s) Loss: 0.1171(0.3000) Grad: 11704.7891  LR: 0.000001  \n","Epoch: [1][700/36908] Elapsed 2m 26s (remain 125m 47s) Loss: 0.0589(0.2701) Grad: 11234.4570  LR: 0.000001  \n","Epoch: [1][800/36908] Elapsed 2m 46s (remain 125m 21s) Loss: 0.0109(0.2409) Grad: 2277.8901  LR: 0.000001  \n","Epoch: [1][900/36908] Elapsed 3m 7s (remain 124m 56s) Loss: 0.0005(0.2150) Grad: 180.9261  LR: 0.000001  \n","Epoch: [1][1000/36908] Elapsed 3m 28s (remain 124m 34s) Loss: 0.0002(0.1939) Grad: 105.1739  LR: 0.000001  \n","Epoch: [1][1100/36908] Elapsed 3m 49s (remain 124m 13s) Loss: 0.0004(0.1768) Grad: 134.7723  LR: 0.000001  \n","Epoch: [1][1200/36908] Elapsed 4m 9s (remain 123m 50s) Loss: 0.0005(0.1629) Grad: 169.9566  LR: 0.000001  \n","Epoch: [1][1300/36908] Elapsed 4m 30s (remain 123m 32s) Loss: 0.0003(0.1507) Grad: 93.8945  LR: 0.000001  \n","Epoch: [1][1400/36908] Elapsed 4m 51s (remain 123m 8s) Loss: 0.0006(0.1404) Grad: 172.2508  LR: 0.000002  \n","Epoch: [1][1500/36908] Elapsed 5m 12s (remain 122m 45s) Loss: 0.0002(0.1313) Grad: 93.0499  LR: 0.000002  \n","Epoch: [1][1600/36908] Elapsed 5m 32s (remain 122m 22s) Loss: 0.0368(0.1236) Grad: 1569.3232  LR: 0.000002  \n","Epoch: [1][1700/36908] Elapsed 5m 53s (remain 122m 2s) Loss: 0.0002(0.1165) Grad: 90.0679  LR: 0.000002  \n","Epoch: [1][1800/36908] Elapsed 6m 14s (remain 121m 42s) Loss: 0.0008(0.1105) Grad: 229.7604  LR: 0.000002  \n","Epoch: [1][1900/36908] Elapsed 6m 35s (remain 121m 20s) Loss: 0.0108(0.1049) Grad: 612.0508  LR: 0.000002  \n","Epoch: [1][2000/36908] Elapsed 6m 56s (remain 120m 58s) Loss: 0.0008(0.0998) Grad: 252.1540  LR: 0.000002  \n","Epoch: [1][2100/36908] Elapsed 7m 16s (remain 120m 36s) Loss: 0.0201(0.0955) Grad: 1362.7712  LR: 0.000002  \n","Epoch: [1][2200/36908] Elapsed 7m 37s (remain 120m 14s) Loss: 0.0125(0.0914) Grad: 647.6226  LR: 0.000002  \n","Epoch: [1][2300/36908] Elapsed 7m 58s (remain 119m 53s) Loss: 0.0127(0.0876) Grad: 1277.9033  LR: 0.000002  \n","Epoch: [1][2400/36908] Elapsed 8m 18s (remain 119m 30s) Loss: 0.0001(0.0841) Grad: 65.8323  LR: 0.000003  \n","Epoch: [1][2500/36908] Elapsed 8m 39s (remain 119m 8s) Loss: 0.0008(0.0811) Grad: 233.5876  LR: 0.000003  \n","Epoch: [1][2600/36908] Elapsed 9m 0s (remain 118m 46s) Loss: 0.0002(0.0781) Grad: 84.5309  LR: 0.000003  \n","Epoch: [1][2700/36908] Elapsed 9m 20s (remain 118m 24s) Loss: 0.0001(0.0754) Grad: 55.3759  LR: 0.000003  \n","Epoch: [1][2800/36908] Elapsed 9m 41s (remain 118m 4s) Loss: 0.0009(0.0729) Grad: 285.6168  LR: 0.000003  \n","Epoch: [1][2900/36908] Elapsed 10m 2s (remain 117m 43s) Loss: 0.0334(0.0705) Grad: 1956.8879  LR: 0.000003  \n","Epoch: [1][3000/36908] Elapsed 10m 23s (remain 117m 21s) Loss: 0.0001(0.0684) Grad: 71.9865  LR: 0.000003  \n","Epoch: [1][3100/36908] Elapsed 10m 43s (remain 116m 59s) Loss: 0.0003(0.0664) Grad: 144.5469  LR: 0.000003  \n","Epoch: [1][3200/36908] Elapsed 11m 4s (remain 116m 39s) Loss: 0.0074(0.0644) Grad: 846.1719  LR: 0.000003  \n","Epoch: [1][3300/36908] Elapsed 11m 25s (remain 116m 20s) Loss: 0.0004(0.0627) Grad: 189.0131  LR: 0.000004  \n","Epoch: [1][3400/36908] Elapsed 11m 46s (remain 116m 2s) Loss: 0.0000(0.0609) Grad: 20.1172  LR: 0.000004  \n","Epoch: [1][3500/36908] Elapsed 12m 7s (remain 115m 44s) Loss: 0.0002(0.0593) Grad: 119.3049  LR: 0.000004  \n","Epoch: [1][3600/36908] Elapsed 12m 28s (remain 115m 25s) Loss: 0.0080(0.0578) Grad: 1223.3356  LR: 0.000004  \n","Epoch: [1][3700/36908] Elapsed 12m 49s (remain 115m 6s) Loss: 0.0002(0.0563) Grad: 144.6787  LR: 0.000004  \n","Epoch: [1][3800/36908] Elapsed 13m 10s (remain 114m 46s) Loss: 0.0002(0.0549) Grad: 134.0800  LR: 0.000004  \n","Epoch: [1][3900/36908] Elapsed 13m 31s (remain 114m 27s) Loss: 0.0007(0.0536) Grad: 279.6748  LR: 0.000004  \n","Epoch: [1][4000/36908] Elapsed 13m 52s (remain 114m 7s) Loss: 0.0001(0.0524) Grad: 80.7745  LR: 0.000004  \n","Epoch: [1][4100/36908] Elapsed 14m 13s (remain 113m 47s) Loss: 0.0005(0.0512) Grad: 182.1803  LR: 0.000004  \n","Epoch: [1][4200/36908] Elapsed 14m 34s (remain 113m 28s) Loss: 0.0004(0.0501) Grad: 164.9860  LR: 0.000005  \n","Epoch: [1][4300/36908] Elapsed 14m 55s (remain 113m 8s) Loss: 0.0348(0.0490) Grad: 3505.3240  LR: 0.000005  \n","Epoch: [1][4400/36908] Elapsed 15m 16s (remain 112m 48s) Loss: 0.0001(0.0479) Grad: 139.8380  LR: 0.000005  \n","Epoch: [1][4500/36908] Elapsed 15m 37s (remain 112m 28s) Loss: 0.0001(0.0470) Grad: 115.1803  LR: 0.000005  \n","Epoch: [1][4600/36908] Elapsed 15m 58s (remain 112m 9s) Loss: 0.0003(0.0460) Grad: 332.6380  LR: 0.000005  \n","Epoch: [1][4700/36908] Elapsed 16m 19s (remain 111m 49s) Loss: 0.0001(0.0451) Grad: 113.4478  LR: 0.000005  \n","Epoch: [1][4800/36908] Elapsed 16m 40s (remain 111m 29s) Loss: 0.0001(0.0442) Grad: 50.8211  LR: 0.000005  \n","Epoch: [1][4900/36908] Elapsed 17m 1s (remain 111m 9s) Loss: 0.0003(0.0434) Grad: 217.9770  LR: 0.000005  \n","Epoch: [1][5000/36908] Elapsed 17m 22s (remain 110m 49s) Loss: 0.0001(0.0426) Grad: 77.7986  LR: 0.000005  \n","Epoch: [1][5100/36908] Elapsed 17m 43s (remain 110m 29s) Loss: 0.0133(0.0419) Grad: 3742.2483  LR: 0.000006  \n","Epoch: [1][5200/36908] Elapsed 18m 4s (remain 110m 10s) Loss: 0.0000(0.0411) Grad: 26.9240  LR: 0.000006  \n","Epoch: [1][5300/36908] Elapsed 18m 25s (remain 109m 49s) Loss: 0.0001(0.0404) Grad: 65.6892  LR: 0.000006  \n","Epoch: [1][5400/36908] Elapsed 18m 46s (remain 109m 30s) Loss: 0.0002(0.0397) Grad: 144.4733  LR: 0.000006  \n","Epoch: [1][5500/36908] Elapsed 19m 7s (remain 109m 9s) Loss: 0.0001(0.0390) Grad: 88.4219  LR: 0.000006  \n","Epoch: [1][5600/36908] Elapsed 19m 28s (remain 108m 50s) Loss: 0.0000(0.0384) Grad: 86.7318  LR: 0.000006  \n","Epoch: [1][5700/36908] Elapsed 19m 49s (remain 108m 30s) Loss: 0.0108(0.0378) Grad: 3013.4106  LR: 0.000006  \n","Epoch: [1][5800/36908] Elapsed 20m 10s (remain 108m 10s) Loss: 0.0001(0.0372) Grad: 86.7972  LR: 0.000006  \n","Epoch: [1][5900/36908] Elapsed 20m 31s (remain 107m 50s) Loss: 0.0900(0.0366) Grad: 31009.2168  LR: 0.000006  \n","Epoch: [1][6000/36908] Elapsed 20m 52s (remain 107m 31s) Loss: 0.0001(0.0361) Grad: 89.7890  LR: 0.000007  \n","Epoch: [1][6100/36908] Elapsed 21m 13s (remain 107m 10s) Loss: 0.0024(0.0356) Grad: 1234.2958  LR: 0.000007  \n","Epoch: [1][6200/36908] Elapsed 21m 34s (remain 106m 50s) Loss: 0.0003(0.0351) Grad: 192.3514  LR: 0.000007  \n","Epoch: [1][6300/36908] Elapsed 21m 55s (remain 106m 29s) Loss: 0.0002(0.0346) Grad: 215.4279  LR: 0.000007  \n","Epoch: [1][6400/36908] Elapsed 22m 16s (remain 106m 8s) Loss: 0.0000(0.0342) Grad: 26.2881  LR: 0.000007  \n","Epoch: [1][6500/36908] Elapsed 22m 37s (remain 105m 47s) Loss: 0.0018(0.0337) Grad: 506.3000  LR: 0.000007  \n","Epoch: [1][6600/36908] Elapsed 22m 58s (remain 105m 26s) Loss: 0.0002(0.0332) Grad: 160.4198  LR: 0.000007  \n","Epoch: [1][6700/36908] Elapsed 23m 19s (remain 105m 6s) Loss: 0.0001(0.0328) Grad: 62.8251  LR: 0.000007  \n","Epoch: [1][6800/36908] Elapsed 23m 40s (remain 104m 46s) Loss: 0.0006(0.0324) Grad: 423.2850  LR: 0.000007  \n","Epoch: [1][6900/36908] Elapsed 24m 1s (remain 104m 26s) Loss: 0.0001(0.0320) Grad: 79.8017  LR: 0.000007  \n","Epoch: [1][7000/36908] Elapsed 24m 22s (remain 104m 5s) Loss: 0.0001(0.0316) Grad: 104.7371  LR: 0.000008  \n","Epoch: [1][7100/36908] Elapsed 24m 42s (remain 103m 44s) Loss: 0.0001(0.0312) Grad: 51.8225  LR: 0.000008  \n","Epoch: [1][7200/36908] Elapsed 25m 3s (remain 103m 23s) Loss: 0.0001(0.0308) Grad: 105.6120  LR: 0.000008  \n","Epoch: [1][7300/36908] Elapsed 25m 24s (remain 103m 2s) Loss: 0.0103(0.0305) Grad: 2001.9590  LR: 0.000008  \n","Epoch: [1][7400/36908] Elapsed 25m 45s (remain 102m 42s) Loss: 0.0008(0.0302) Grad: 499.1782  LR: 0.000008  \n","Epoch: [1][7500/36908] Elapsed 26m 6s (remain 102m 21s) Loss: 0.0001(0.0298) Grad: 92.1845  LR: 0.000008  \n","Epoch: [1][7600/36908] Elapsed 26m 27s (remain 102m 0s) Loss: 0.0001(0.0294) Grad: 125.2256  LR: 0.000008  \n","Epoch: [1][7700/36908] Elapsed 26m 48s (remain 101m 39s) Loss: 0.0022(0.0291) Grad: 549.7795  LR: 0.000008  \n","Epoch: [1][7800/36908] Elapsed 27m 9s (remain 101m 19s) Loss: 0.0002(0.0288) Grad: 176.8296  LR: 0.000008  \n","Epoch: [1][7900/36908] Elapsed 27m 30s (remain 100m 58s) Loss: 0.0002(0.0285) Grad: 182.5689  LR: 0.000009  \n","Epoch: [1][8000/36908] Elapsed 27m 50s (remain 100m 37s) Loss: 0.0002(0.0282) Grad: 142.6504  LR: 0.000009  \n","Epoch: [1][8100/36908] Elapsed 28m 11s (remain 100m 16s) Loss: 0.0001(0.0279) Grad: 71.3072  LR: 0.000009  \n","Epoch: [1][8200/36908] Elapsed 28m 32s (remain 99m 55s) Loss: 0.0004(0.0276) Grad: 226.8587  LR: 0.000009  \n","Epoch: [1][8300/36908] Elapsed 28m 53s (remain 99m 34s) Loss: 0.0001(0.0273) Grad: 109.9035  LR: 0.000009  \n","Epoch: [1][8400/36908] Elapsed 29m 14s (remain 99m 13s) Loss: 0.0190(0.0270) Grad: 6317.6934  LR: 0.000009  \n","Epoch: [1][8500/36908] Elapsed 29m 35s (remain 98m 52s) Loss: 0.0002(0.0267) Grad: 225.0082  LR: 0.000009  \n","Epoch: [1][8600/36908] Elapsed 29m 56s (remain 98m 31s) Loss: 0.0000(0.0264) Grad: 197.0037  LR: 0.000009  \n","Epoch: [1][8700/36908] Elapsed 30m 16s (remain 98m 10s) Loss: 0.0002(0.0262) Grad: 247.3961  LR: 0.000009  \n","Epoch: [1][8800/36908] Elapsed 30m 37s (remain 97m 48s) Loss: 0.0001(0.0259) Grad: 149.9283  LR: 0.000010  \n","Epoch: [1][8900/36908] Elapsed 30m 58s (remain 97m 27s) Loss: 0.0003(0.0257) Grad: 402.8043  LR: 0.000010  \n","Epoch: [1][9000/36908] Elapsed 31m 19s (remain 97m 7s) Loss: 0.0138(0.0255) Grad: 5834.6797  LR: 0.000010  \n","Epoch: [1][9100/36908] Elapsed 31m 40s (remain 96m 46s) Loss: 0.0039(0.0253) Grad: 2588.8538  LR: 0.000010  \n","Epoch: [1][9200/36908] Elapsed 32m 1s (remain 96m 25s) Loss: 0.0000(0.0250) Grad: 115.0269  LR: 0.000010  \n","Epoch: [1][9300/36908] Elapsed 32m 22s (remain 96m 4s) Loss: 0.0000(0.0248) Grad: 88.3394  LR: 0.000010  \n","Epoch: [1][9400/36908] Elapsed 32m 43s (remain 95m 43s) Loss: 0.0002(0.0246) Grad: 213.2935  LR: 0.000010  \n","Epoch: [1][9500/36908] Elapsed 33m 4s (remain 95m 23s) Loss: 0.0000(0.0244) Grad: 3.8752  LR: 0.000010  \n","Epoch: [1][9600/36908] Elapsed 33m 25s (remain 95m 2s) Loss: 0.0001(0.0242) Grad: 112.1891  LR: 0.000010  \n","Epoch: [1][9700/36908] Elapsed 33m 46s (remain 94m 42s) Loss: 0.0001(0.0239) Grad: 94.9178  LR: 0.000011  \n","Epoch: [1][9800/36908] Elapsed 34m 7s (remain 94m 21s) Loss: 0.0446(0.0237) Grad: 13736.6250  LR: 0.000011  \n","Epoch: [1][9900/36908] Elapsed 34m 28s (remain 94m 2s) Loss: 0.0000(0.0235) Grad: 42.0396  LR: 0.000011  \n","Epoch: [1][10000/36908] Elapsed 34m 49s (remain 93m 41s) Loss: 0.0000(0.0233) Grad: 37.7268  LR: 0.000011  \n","Epoch: [1][10100/36908] Elapsed 35m 10s (remain 93m 20s) Loss: 0.0154(0.0231) Grad: 5440.5737  LR: 0.000011  \n","Epoch: [1][10200/36908] Elapsed 35m 31s (remain 92m 59s) Loss: 0.0000(0.0229) Grad: 70.9029  LR: 0.000011  \n","Epoch: [1][10300/36908] Elapsed 35m 52s (remain 92m 39s) Loss: 0.0344(0.0227) Grad: 14650.1172  LR: 0.000011  \n","Epoch: [1][10400/36908] Elapsed 36m 13s (remain 92m 18s) Loss: 0.0001(0.0226) Grad: 131.8929  LR: 0.000011  \n","Epoch: [1][10500/36908] Elapsed 36m 33s (remain 91m 57s) Loss: 0.0212(0.0224) Grad: 14754.3740  LR: 0.000011  \n","Epoch: [1][10600/36908] Elapsed 36m 54s (remain 91m 36s) Loss: 0.0000(0.0222) Grad: 34.2786  LR: 0.000011  \n","Epoch: [1][10700/36908] Elapsed 37m 15s (remain 91m 15s) Loss: 0.0001(0.0220) Grad: 257.1389  LR: 0.000012  \n","Epoch: [1][10800/36908] Elapsed 37m 36s (remain 90m 54s) Loss: 0.0001(0.0219) Grad: 89.4791  LR: 0.000012  \n","Epoch: [1][10900/36908] Elapsed 37m 57s (remain 90m 33s) Loss: 0.0087(0.0217) Grad: 2712.6509  LR: 0.000012  \n","Epoch: [1][11000/36908] Elapsed 38m 18s (remain 90m 12s) Loss: 0.0001(0.0215) Grad: 82.6067  LR: 0.000012  \n","Epoch: [1][11100/36908] Elapsed 38m 39s (remain 89m 51s) Loss: 0.0046(0.0214) Grad: 1666.6097  LR: 0.000012  \n","Epoch: [1][11200/36908] Elapsed 39m 0s (remain 89m 30s) Loss: 0.0003(0.0213) Grad: 307.7962  LR: 0.000012  \n","Epoch: [1][11300/36908] Elapsed 39m 21s (remain 89m 10s) Loss: 0.0002(0.0211) Grad: 228.6985  LR: 0.000012  \n","Epoch: [1][11400/36908] Elapsed 39m 41s (remain 88m 48s) Loss: 0.0000(0.0210) Grad: 43.3918  LR: 0.000012  \n","Epoch: [1][11500/36908] Elapsed 40m 2s (remain 88m 27s) Loss: 0.0001(0.0208) Grad: 105.0000  LR: 0.000012  \n","Epoch: [1][11600/36908] Elapsed 40m 23s (remain 88m 6s) Loss: 0.0002(0.0207) Grad: 172.4853  LR: 0.000013  \n","Epoch: [1][11700/36908] Elapsed 40m 44s (remain 87m 45s) Loss: 0.0002(0.0206) Grad: 297.5517  LR: 0.000013  \n","Epoch: [1][11800/36908] Elapsed 41m 5s (remain 87m 24s) Loss: 0.0001(0.0204) Grad: 155.9201  LR: 0.000013  \n","Epoch: [1][11900/36908] Elapsed 41m 26s (remain 87m 3s) Loss: 0.0000(0.0203) Grad: 48.2576  LR: 0.000013  \n","Epoch: [1][12000/36908] Elapsed 41m 47s (remain 86m 43s) Loss: 0.0185(0.0201) Grad: 7860.2705  LR: 0.000013  \n","Epoch: [1][12100/36908] Elapsed 42m 7s (remain 86m 22s) Loss: 0.0001(0.0200) Grad: 81.0799  LR: 0.000013  \n","Epoch: [1][12200/36908] Elapsed 42m 28s (remain 86m 1s) Loss: 0.0001(0.0199) Grad: 178.6798  LR: 0.000013  \n","Epoch: [1][12300/36908] Elapsed 42m 49s (remain 85m 40s) Loss: 0.0000(0.0197) Grad: 14.3322  LR: 0.000013  \n","Epoch: [1][12400/36908] Elapsed 43m 10s (remain 85m 19s) Loss: 0.0137(0.0196) Grad: 7219.1621  LR: 0.000013  \n","Epoch: [1][12500/36908] Elapsed 43m 31s (remain 84m 58s) Loss: 0.0066(0.0195) Grad: 7044.2271  LR: 0.000014  \n","Epoch: [1][12600/36908] Elapsed 43m 52s (remain 84m 37s) Loss: 0.0001(0.0194) Grad: 272.3600  LR: 0.000014  \n","Epoch: [1][12700/36908] Elapsed 44m 13s (remain 84m 17s) Loss: 0.0001(0.0192) Grad: 128.2495  LR: 0.000014  \n","Epoch: [1][12800/36908] Elapsed 44m 34s (remain 83m 56s) Loss: 0.0000(0.0191) Grad: 51.2773  LR: 0.000014  \n","Epoch: [1][12900/36908] Elapsed 44m 55s (remain 83m 35s) Loss: 0.0000(0.0190) Grad: 105.2193  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 45m 15s (remain 83m 14s) Loss: 0.0001(0.0189) Grad: 249.4808  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 45m 36s (remain 82m 53s) Loss: 0.0000(0.0188) Grad: 91.3244  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 45m 57s (remain 82m 32s) Loss: 0.0000(0.0187) Grad: 59.7655  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 46m 18s (remain 82m 10s) Loss: 0.0115(0.0185) Grad: 6782.5596  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 46m 38s (remain 81m 49s) Loss: 0.0515(0.0185) Grad: 28468.8301  LR: 0.000015  \n","Epoch: [1][13500/36908] Elapsed 46m 59s (remain 81m 28s) Loss: 0.0209(0.0184) Grad: 21166.5723  LR: 0.000015  \n","Epoch: [1][13600/36908] Elapsed 47m 20s (remain 81m 7s) Loss: 0.0001(0.0183) Grad: 172.5861  LR: 0.000015  \n","Epoch: [1][13700/36908] Elapsed 47m 41s (remain 80m 46s) Loss: 0.0000(0.0181) Grad: 123.2477  LR: 0.000015  \n","Epoch: [1][13800/36908] Elapsed 48m 1s (remain 80m 25s) Loss: 0.0326(0.0181) Grad: 14146.3926  LR: 0.000015  \n","Epoch: [1][13900/36908] Elapsed 48m 22s (remain 80m 3s) Loss: 0.0000(0.0179) Grad: 51.3238  LR: 0.000015  \n","Epoch: [1][14000/36908] Elapsed 48m 43s (remain 79m 42s) Loss: 0.0069(0.0178) Grad: 4246.6709  LR: 0.000015  \n","Epoch: [1][14100/36908] Elapsed 49m 3s (remain 79m 21s) Loss: 0.0001(0.0177) Grad: 226.1556  LR: 0.000015  \n","Epoch: [1][14200/36908] Elapsed 49m 24s (remain 79m 0s) Loss: 0.0150(0.0177) Grad: 15415.7168  LR: 0.000015  \n","Epoch: [1][14300/36908] Elapsed 49m 45s (remain 78m 39s) Loss: 0.0001(0.0176) Grad: 249.0793  LR: 0.000015  \n","Epoch: [1][14400/36908] Elapsed 50m 6s (remain 78m 18s) Loss: 0.0082(0.0175) Grad: 6926.3013  LR: 0.000016  \n","Epoch: [1][14500/36908] Elapsed 50m 27s (remain 77m 57s) Loss: 0.0000(0.0174) Grad: 82.9883  LR: 0.000016  \n","Epoch: [1][14600/36908] Elapsed 50m 47s (remain 77m 36s) Loss: 0.0000(0.0173) Grad: 85.8027  LR: 0.000016  \n","Epoch: [1][14700/36908] Elapsed 51m 8s (remain 77m 15s) Loss: 0.0001(0.0172) Grad: 174.9068  LR: 0.000016  \n","Epoch: [1][14800/36908] Elapsed 51m 29s (remain 76m 54s) Loss: 0.0000(0.0171) Grad: 115.3926  LR: 0.000016  \n","Epoch: [1][14900/36908] Elapsed 51m 49s (remain 76m 32s) Loss: 0.0000(0.0170) Grad: 81.4719  LR: 0.000016  \n","Epoch: [1][15000/36908] Elapsed 52m 10s (remain 76m 11s) Loss: 0.0000(0.0170) Grad: 37.3457  LR: 0.000016  \n","Epoch: [1][15100/36908] Elapsed 52m 31s (remain 75m 50s) Loss: 0.0000(0.0169) Grad: 101.6665  LR: 0.000016  \n","Epoch: [1][15200/36908] Elapsed 52m 52s (remain 75m 29s) Loss: 0.0001(0.0168) Grad: 294.1507  LR: 0.000016  \n","Epoch: [1][15300/36908] Elapsed 53m 12s (remain 75m 8s) Loss: 0.0000(0.0167) Grad: 89.4254  LR: 0.000017  \n","Epoch: [1][15400/36908] Elapsed 53m 33s (remain 74m 47s) Loss: 0.0002(0.0166) Grad: 633.9365  LR: 0.000017  \n","Epoch: [1][15500/36908] Elapsed 53m 54s (remain 74m 27s) Loss: 0.0000(0.0166) Grad: 26.1502  LR: 0.000017  \n","Epoch: [1][15600/36908] Elapsed 54m 15s (remain 74m 6s) Loss: 0.0000(0.0165) Grad: 74.8063  LR: 0.000017  \n","Epoch: [1][15700/36908] Elapsed 54m 36s (remain 73m 45s) Loss: 0.0041(0.0164) Grad: 7467.6724  LR: 0.000017  \n","Epoch: [1][15800/36908] Elapsed 54m 57s (remain 73m 24s) Loss: 0.0001(0.0163) Grad: 130.1951  LR: 0.000017  \n","Epoch: [1][15900/36908] Elapsed 55m 18s (remain 73m 4s) Loss: 0.0000(0.0163) Grad: 70.7032  LR: 0.000017  \n","Epoch: [1][16000/36908] Elapsed 55m 39s (remain 72m 44s) Loss: 0.0000(0.0162) Grad: 197.1608  LR: 0.000017  \n","Epoch: [1][16100/36908] Elapsed 56m 1s (remain 72m 23s) Loss: 0.0000(0.0161) Grad: 71.1363  LR: 0.000017  \n","Epoch: [1][16200/36908] Elapsed 56m 22s (remain 72m 3s) Loss: 0.0001(0.0160) Grad: 337.6859  LR: 0.000018  \n","Epoch: [1][16300/36908] Elapsed 56m 43s (remain 71m 42s) Loss: 0.0109(0.0159) Grad: 5776.6387  LR: 0.000018  \n","Epoch: [1][16400/36908] Elapsed 57m 4s (remain 71m 21s) Loss: 0.0098(0.0159) Grad: 13606.6748  LR: 0.000018  \n","Epoch: [1][16500/36908] Elapsed 57m 25s (remain 71m 0s) Loss: 0.0000(0.0158) Grad: 125.1939  LR: 0.000018  \n","Epoch: [1][16600/36908] Elapsed 57m 46s (remain 70m 39s) Loss: 0.0001(0.0157) Grad: 236.5020  LR: 0.000018  \n","Epoch: [1][16700/36908] Elapsed 58m 7s (remain 70m 19s) Loss: 0.0000(0.0157) Grad: 129.5334  LR: 0.000018  \n","Epoch: [1][16800/36908] Elapsed 58m 27s (remain 69m 58s) Loss: 0.0000(0.0156) Grad: 236.8689  LR: 0.000018  \n","Epoch: [1][16900/36908] Elapsed 58m 48s (remain 69m 37s) Loss: 0.0000(0.0156) Grad: 60.8745  LR: 0.000018  \n","Epoch: [1][17000/36908] Elapsed 59m 9s (remain 69m 16s) Loss: 0.0002(0.0155) Grad: 856.9421  LR: 0.000018  \n","Epoch: [1][17100/36908] Elapsed 59m 30s (remain 68m 55s) Loss: 0.0000(0.0154) Grad: 144.0940  LR: 0.000019  \n","Epoch: [1][17200/36908] Elapsed 59m 51s (remain 68m 34s) Loss: 0.0000(0.0153) Grad: 85.9580  LR: 0.000019  \n","Epoch: [1][17300/36908] Elapsed 60m 12s (remain 68m 13s) Loss: 0.0000(0.0153) Grad: 196.7087  LR: 0.000019  \n","Epoch: [1][17400/36908] Elapsed 60m 32s (remain 67m 52s) Loss: 0.0000(0.0152) Grad: 134.4138  LR: 0.000019  \n","Epoch: [1][17500/36908] Elapsed 60m 53s (remain 67m 31s) Loss: 0.0001(0.0152) Grad: 490.1926  LR: 0.000019  \n","Epoch: [1][17600/36908] Elapsed 61m 14s (remain 67m 10s) Loss: 0.0000(0.0151) Grad: 183.1138  LR: 0.000019  \n","Epoch: [1][17700/36908] Elapsed 61m 35s (remain 66m 49s) Loss: 0.0232(0.0150) Grad: 16396.1309  LR: 0.000019  \n","Epoch: [1][17800/36908] Elapsed 61m 56s (remain 66m 28s) Loss: 0.0000(0.0150) Grad: 48.8134  LR: 0.000019  \n","Epoch: [1][17900/36908] Elapsed 62m 16s (remain 66m 7s) Loss: 0.0000(0.0149) Grad: 398.6336  LR: 0.000019  \n","Epoch: [1][18000/36908] Elapsed 62m 37s (remain 65m 46s) Loss: 0.0000(0.0149) Grad: 114.6830  LR: 0.000020  \n","Epoch: [1][18100/36908] Elapsed 62m 58s (remain 65m 26s) Loss: 0.0210(0.0148) Grad: 18284.9141  LR: 0.000020  \n","Epoch: [1][18200/36908] Elapsed 63m 19s (remain 65m 5s) Loss: 0.0000(0.0148) Grad: 106.3005  LR: 0.000020  \n","Epoch: [1][18300/36908] Elapsed 63m 40s (remain 64m 44s) Loss: 0.0000(0.0147) Grad: 35.2826  LR: 0.000020  \n","Epoch: [1][18400/36908] Elapsed 64m 1s (remain 64m 23s) Loss: 0.0000(0.0147) Grad: 149.0484  LR: 0.000020  \n","Epoch: [1][18500/36908] Elapsed 64m 22s (remain 64m 2s) Loss: 0.0202(0.0146) Grad: 18119.7012  LR: 0.000020  \n","Epoch: [1][18600/36908] Elapsed 64m 43s (remain 63m 41s) Loss: 0.0000(0.0145) Grad: 127.0672  LR: 0.000020  \n","Epoch: [1][18700/36908] Elapsed 65m 3s (remain 63m 20s) Loss: 0.0000(0.0145) Grad: 239.3386  LR: 0.000020  \n","Epoch: [1][18800/36908] Elapsed 65m 24s (remain 62m 59s) Loss: 0.0000(0.0144) Grad: 25.9270  LR: 0.000020  \n","Epoch: [1][18900/36908] Elapsed 65m 45s (remain 62m 38s) Loss: 0.0022(0.0144) Grad: 4068.0354  LR: 0.000020  \n","Epoch: [1][19000/36908] Elapsed 66m 6s (remain 62m 18s) Loss: 0.0000(0.0143) Grad: 212.2381  LR: 0.000020  \n","Epoch: [1][19100/36908] Elapsed 66m 27s (remain 61m 57s) Loss: 0.0000(0.0143) Grad: 147.4712  LR: 0.000020  \n","Epoch: [1][19200/36908] Elapsed 66m 48s (remain 61m 36s) Loss: 0.0001(0.0142) Grad: 428.1340  LR: 0.000020  \n","Epoch: [1][19300/36908] Elapsed 67m 9s (remain 61m 15s) Loss: 0.0000(0.0142) Grad: 168.7982  LR: 0.000020  \n","Epoch: [1][19400/36908] Elapsed 67m 30s (remain 60m 54s) Loss: 0.0001(0.0141) Grad: 324.3402  LR: 0.000020  \n","Epoch: [1][19500/36908] Elapsed 67m 50s (remain 60m 33s) Loss: 0.0089(0.0140) Grad: 8237.3662  LR: 0.000020  \n","Epoch: [1][19600/36908] Elapsed 68m 11s (remain 60m 12s) Loss: 0.0001(0.0140) Grad: 356.9738  LR: 0.000020  \n","Epoch: [1][19700/36908] Elapsed 68m 32s (remain 59m 51s) Loss: 0.0060(0.0139) Grad: 10729.2881  LR: 0.000020  \n","Epoch: [1][19800/36908] Elapsed 68m 53s (remain 59m 31s) Loss: 0.0000(0.0139) Grad: 91.9193  LR: 0.000020  \n","Epoch: [1][19900/36908] Elapsed 69m 14s (remain 59m 10s) Loss: 0.0001(0.0138) Grad: 334.9313  LR: 0.000020  \n","Epoch: [1][20000/36908] Elapsed 69m 35s (remain 58m 49s) Loss: 0.0001(0.0138) Grad: 253.2626  LR: 0.000020  \n","Epoch: [1][20100/36908] Elapsed 69m 56s (remain 58m 28s) Loss: 0.0000(0.0137) Grad: 128.8394  LR: 0.000020  \n","Epoch: [1][20200/36908] Elapsed 70m 17s (remain 58m 7s) Loss: 0.0000(0.0137) Grad: 173.6584  LR: 0.000020  \n","Epoch: [1][20300/36908] Elapsed 70m 37s (remain 57m 46s) Loss: 0.0000(0.0137) Grad: 38.1246  LR: 0.000020  \n","Epoch: [1][20400/36908] Elapsed 70m 58s (remain 57m 25s) Loss: 0.0555(0.0136) Grad: 127143.6562  LR: 0.000020  \n","Epoch: [1][20500/36908] Elapsed 71m 19s (remain 57m 4s) Loss: 0.0000(0.0136) Grad: 137.5557  LR: 0.000020  \n","Epoch: [1][20600/36908] Elapsed 71m 40s (remain 56m 43s) Loss: 0.0000(0.0135) Grad: 84.7835  LR: 0.000020  \n","Epoch: [1][20700/36908] Elapsed 72m 1s (remain 56m 22s) Loss: 0.0000(0.0135) Grad: 345.4649  LR: 0.000020  \n","Epoch: [1][20800/36908] Elapsed 72m 21s (remain 56m 2s) Loss: 0.0000(0.0135) Grad: 40.7890  LR: 0.000020  \n","Epoch: [1][20900/36908] Elapsed 72m 42s (remain 55m 41s) Loss: 0.0000(0.0134) Grad: 106.4680  LR: 0.000020  \n","Epoch: [1][21000/36908] Elapsed 73m 3s (remain 55m 20s) Loss: 0.0000(0.0134) Grad: 64.6705  LR: 0.000020  \n","Epoch: [1][21100/36908] Elapsed 73m 24s (remain 54m 59s) Loss: 0.0437(0.0133) Grad: 86779.6953  LR: 0.000020  \n","Epoch: [1][21200/36908] Elapsed 73m 44s (remain 54m 38s) Loss: 0.0129(0.0133) Grad: 22980.3965  LR: 0.000020  \n","Epoch: [1][21300/36908] Elapsed 74m 6s (remain 54m 17s) Loss: 0.0000(0.0132) Grad: 198.4479  LR: 0.000020  \n","Epoch: [1][21400/36908] Elapsed 74m 26s (remain 53m 56s) Loss: 0.0000(0.0132) Grad: 31.6357  LR: 0.000020  \n","Epoch: [1][21500/36908] Elapsed 74m 47s (remain 53m 35s) Loss: 0.0000(0.0132) Grad: 283.1880  LR: 0.000020  \n","Epoch: [1][21600/36908] Elapsed 75m 8s (remain 53m 14s) Loss: 0.0000(0.0131) Grad: 321.3425  LR: 0.000020  \n","Epoch: [1][21700/36908] Elapsed 75m 29s (remain 52m 54s) Loss: 0.0000(0.0131) Grad: 123.7177  LR: 0.000020  \n","Epoch: [1][21800/36908] Elapsed 75m 50s (remain 52m 33s) Loss: 0.0000(0.0131) Grad: 161.5940  LR: 0.000020  \n","Epoch: [1][21900/36908] Elapsed 76m 11s (remain 52m 12s) Loss: 0.0047(0.0130) Grad: 10088.9043  LR: 0.000020  \n","Epoch: [1][22000/36908] Elapsed 76m 32s (remain 51m 51s) Loss: 0.0000(0.0130) Grad: 164.1055  LR: 0.000020  \n","Epoch: [1][22100/36908] Elapsed 76m 53s (remain 51m 30s) Loss: 0.0000(0.0129) Grad: 194.7402  LR: 0.000020  \n","Epoch: [1][22200/36908] Elapsed 77m 13s (remain 51m 9s) Loss: 0.0000(0.0129) Grad: 411.1001  LR: 0.000020  \n","Epoch: [1][22300/36908] Elapsed 77m 34s (remain 50m 48s) Loss: 0.0000(0.0129) Grad: 245.9837  LR: 0.000020  \n","Epoch: [1][22400/36908] Elapsed 77m 55s (remain 50m 27s) Loss: 0.0000(0.0128) Grad: 163.7620  LR: 0.000020  \n","Epoch: [1][22500/36908] Elapsed 78m 16s (remain 50m 6s) Loss: 0.0000(0.0128) Grad: 201.6959  LR: 0.000020  \n","Epoch: [1][22600/36908] Elapsed 78m 37s (remain 49m 46s) Loss: 0.0103(0.0128) Grad: 21057.3184  LR: 0.000020  \n","Epoch: [1][22700/36908] Elapsed 78m 58s (remain 49m 25s) Loss: 0.0000(0.0127) Grad: 120.1415  LR: 0.000019  \n","Epoch: [1][22800/36908] Elapsed 79m 19s (remain 49m 4s) Loss: 0.0000(0.0127) Grad: 91.2159  LR: 0.000019  \n","Epoch: [1][22900/36908] Elapsed 79m 40s (remain 48m 43s) Loss: 0.0000(0.0126) Grad: 403.9924  LR: 0.000019  \n","Epoch: [1][23000/36908] Elapsed 80m 0s (remain 48m 22s) Loss: 0.0000(0.0126) Grad: 168.4384  LR: 0.000019  \n","Epoch: [1][23100/36908] Elapsed 80m 21s (remain 48m 1s) Loss: 0.0000(0.0126) Grad: 18.1934  LR: 0.000019  \n","Epoch: [1][23200/36908] Elapsed 80m 42s (remain 47m 40s) Loss: 0.0000(0.0125) Grad: 162.1607  LR: 0.000019  \n","Epoch: [1][23300/36908] Elapsed 81m 3s (remain 47m 20s) Loss: 0.0000(0.0125) Grad: 172.1035  LR: 0.000019  \n","Epoch: [1][23400/36908] Elapsed 81m 24s (remain 46m 59s) Loss: 0.0001(0.0125) Grad: 728.4019  LR: 0.000019  \n","Epoch: [1][23500/36908] Elapsed 81m 45s (remain 46m 38s) Loss: 0.0000(0.0124) Grad: 58.9184  LR: 0.000019  \n","Epoch: [1][23600/36908] Elapsed 82m 5s (remain 46m 17s) Loss: 0.0000(0.0124) Grad: 168.6900  LR: 0.000019  \n","Epoch: [1][23700/36908] Elapsed 82m 26s (remain 45m 56s) Loss: 0.0000(0.0124) Grad: 248.7598  LR: 0.000019  \n","Epoch: [1][23800/36908] Elapsed 82m 47s (remain 45m 35s) Loss: 0.0145(0.0123) Grad: 26532.0293  LR: 0.000019  \n","Epoch: [1][23900/36908] Elapsed 83m 8s (remain 45m 14s) Loss: 0.0000(0.0123) Grad: 56.5829  LR: 0.000019  \n","Epoch: [1][24000/36908] Elapsed 83m 29s (remain 44m 53s) Loss: 0.0000(0.0123) Grad: 18.5269  LR: 0.000019  \n","Epoch: [1][24100/36908] Elapsed 83m 49s (remain 44m 32s) Loss: 0.0000(0.0122) Grad: 91.6492  LR: 0.000019  \n","Epoch: [1][24200/36908] Elapsed 84m 11s (remain 44m 12s) Loss: 0.0000(0.0122) Grad: 269.6036  LR: 0.000019  \n","Epoch: [1][24300/36908] Elapsed 84m 31s (remain 43m 51s) Loss: 0.0000(0.0122) Grad: 4.9411  LR: 0.000019  \n","Epoch: [1][24400/36908] Elapsed 84m 52s (remain 43m 30s) Loss: 0.0000(0.0121) Grad: 170.9452  LR: 0.000019  \n","Epoch: [1][24500/36908] Elapsed 85m 13s (remain 43m 9s) Loss: 0.0000(0.0121) Grad: 115.4821  LR: 0.000019  \n","Epoch: [1][24600/36908] Elapsed 85m 34s (remain 42m 48s) Loss: 0.0554(0.0121) Grad: 241791.6094  LR: 0.000019  \n","Epoch: [1][24700/36908] Elapsed 85m 55s (remain 42m 27s) Loss: 0.0000(0.0121) Grad: 95.6692  LR: 0.000019  \n","Epoch: [1][24800/36908] Elapsed 86m 16s (remain 42m 6s) Loss: 0.0079(0.0120) Grad: 32355.6426  LR: 0.000019  \n","Epoch: [1][24900/36908] Elapsed 86m 37s (remain 41m 46s) Loss: 0.0000(0.0120) Grad: 95.1456  LR: 0.000019  \n","Epoch: [1][25000/36908] Elapsed 86m 58s (remain 41m 25s) Loss: 0.0000(0.0120) Grad: 47.4172  LR: 0.000019  \n","Epoch: [1][25100/36908] Elapsed 87m 19s (remain 41m 4s) Loss: 0.0000(0.0119) Grad: 324.6258  LR: 0.000019  \n","Epoch: [1][25200/36908] Elapsed 87m 39s (remain 40m 43s) Loss: 0.0001(0.0119) Grad: 1222.1884  LR: 0.000019  \n","Epoch: [1][25300/36908] Elapsed 88m 0s (remain 40m 22s) Loss: 0.0000(0.0119) Grad: 166.4027  LR: 0.000019  \n","Epoch: [1][25400/36908] Elapsed 88m 21s (remain 40m 1s) Loss: 0.0000(0.0119) Grad: 241.9385  LR: 0.000019  \n","Epoch: [1][25500/36908] Elapsed 88m 42s (remain 39m 40s) Loss: 0.0000(0.0118) Grad: 68.9495  LR: 0.000019  \n","Epoch: [1][25600/36908] Elapsed 89m 3s (remain 39m 19s) Loss: 0.0248(0.0118) Grad: 180450.2500  LR: 0.000019  \n","Epoch: [1][25700/36908] Elapsed 89m 24s (remain 38m 59s) Loss: 0.0241(0.0118) Grad: 97967.6406  LR: 0.000019  \n","Epoch: [1][25800/36908] Elapsed 89m 45s (remain 38m 38s) Loss: 0.0000(0.0118) Grad: 66.3774  LR: 0.000019  \n","Epoch: [1][25900/36908] Elapsed 90m 5s (remain 38m 17s) Loss: 0.0000(0.0117) Grad: 141.8366  LR: 0.000019  \n","Epoch: [1][26000/36908] Elapsed 90m 26s (remain 37m 56s) Loss: 0.0000(0.0117) Grad: 66.7238  LR: 0.000019  \n","Epoch: [1][26100/36908] Elapsed 90m 47s (remain 37m 35s) Loss: 0.0000(0.0117) Grad: 167.9298  LR: 0.000019  \n","Epoch: [1][26200/36908] Elapsed 91m 8s (remain 37m 14s) Loss: 0.0000(0.0117) Grad: 53.4896  LR: 0.000019  \n","Epoch: [1][26300/36908] Elapsed 91m 29s (remain 36m 53s) Loss: 0.0167(0.0116) Grad: 98244.9375  LR: 0.000019  \n","Epoch: [1][26400/36908] Elapsed 91m 50s (remain 36m 32s) Loss: 0.0125(0.0116) Grad: 46466.3945  LR: 0.000019  \n","Epoch: [1][26500/36908] Elapsed 92m 10s (remain 36m 11s) Loss: 0.0000(0.0116) Grad: 86.6363  LR: 0.000019  \n","Epoch: [1][26600/36908] Elapsed 92m 31s (remain 35m 51s) Loss: 0.0000(0.0116) Grad: 158.9955  LR: 0.000019  \n","Epoch: [1][26700/36908] Elapsed 92m 52s (remain 35m 30s) Loss: 0.0000(0.0115) Grad: 84.3148  LR: 0.000019  \n","Epoch: [1][26800/36908] Elapsed 93m 13s (remain 35m 9s) Loss: 0.0000(0.0115) Grad: 116.3928  LR: 0.000019  \n","Epoch: [1][26900/36908] Elapsed 93m 34s (remain 34m 48s) Loss: 0.0000(0.0115) Grad: 491.6951  LR: 0.000019  \n","Epoch: [1][27000/36908] Elapsed 93m 55s (remain 34m 27s) Loss: 0.0029(0.0115) Grad: 18553.7012  LR: 0.000019  \n","Epoch: [1][27100/36908] Elapsed 94m 16s (remain 34m 6s) Loss: 0.0338(0.0115) Grad: 107901.5781  LR: 0.000019  \n","Epoch: [1][27200/36908] Elapsed 94m 37s (remain 33m 45s) Loss: 0.0000(0.0114) Grad: 138.9080  LR: 0.000019  \n","Epoch: [1][27300/36908] Elapsed 94m 58s (remain 33m 25s) Loss: 0.0000(0.0114) Grad: 29.3574  LR: 0.000019  \n","Epoch: [1][27400/36908] Elapsed 95m 18s (remain 33m 4s) Loss: 0.0000(0.0114) Grad: 143.7503  LR: 0.000019  \n","Epoch: [1][27500/36908] Elapsed 95m 39s (remain 32m 43s) Loss: 0.0000(0.0114) Grad: 228.5176  LR: 0.000019  \n","Epoch: [1][27600/36908] Elapsed 96m 0s (remain 32m 22s) Loss: 0.0000(0.0114) Grad: 250.6565  LR: 0.000019  \n","Epoch: [1][27700/36908] Elapsed 96m 21s (remain 32m 1s) Loss: 0.0000(0.0113) Grad: 142.9743  LR: 0.000019  \n","Epoch: [1][27800/36908] Elapsed 96m 42s (remain 31m 40s) Loss: 0.0000(0.0113) Grad: 148.2980  LR: 0.000019  \n","Epoch: [1][27900/36908] Elapsed 97m 3s (remain 31m 19s) Loss: 0.0000(0.0113) Grad: 652.9310  LR: 0.000019  \n","Epoch: [1][28000/36908] Elapsed 97m 23s (remain 30m 58s) Loss: 0.0000(0.0113) Grad: 288.4577  LR: 0.000019  \n","Epoch: [1][28100/36908] Elapsed 97m 44s (remain 30m 38s) Loss: 0.0000(0.0113) Grad: 161.1494  LR: 0.000019  \n","Epoch: [1][28200/36908] Elapsed 98m 5s (remain 30m 17s) Loss: 0.0000(0.0112) Grad: 214.9696  LR: 0.000019  \n","Epoch: [1][28300/36908] Elapsed 98m 26s (remain 29m 56s) Loss: 0.0000(0.0112) Grad: 153.1177  LR: 0.000019  \n","Epoch: [1][28400/36908] Elapsed 98m 47s (remain 29m 35s) Loss: 0.0000(0.0112) Grad: 203.4627  LR: 0.000019  \n","Epoch: [1][28500/36908] Elapsed 99m 8s (remain 29m 14s) Loss: 0.0000(0.0112) Grad: 138.3239  LR: 0.000019  \n","Epoch: [1][28600/36908] Elapsed 99m 29s (remain 28m 53s) Loss: 0.0000(0.0111) Grad: 69.5051  LR: 0.000019  \n","Epoch: [1][28700/36908] Elapsed 99m 50s (remain 28m 32s) Loss: 0.0000(0.0111) Grad: 60.0186  LR: 0.000019  \n","Epoch: [1][28800/36908] Elapsed 100m 10s (remain 28m 11s) Loss: 0.0000(0.0111) Grad: 121.4951  LR: 0.000019  \n","Epoch: [1][28900/36908] Elapsed 100m 31s (remain 27m 51s) Loss: 0.0000(0.0111) Grad: 122.4756  LR: 0.000019  \n","Epoch: [1][29000/36908] Elapsed 100m 52s (remain 27m 30s) Loss: 0.0000(0.0110) Grad: 88.0700  LR: 0.000019  \n","Epoch: [1][29100/36908] Elapsed 101m 13s (remain 27m 9s) Loss: 0.0000(0.0110) Grad: 75.5341  LR: 0.000019  \n","Epoch: [1][29200/36908] Elapsed 101m 34s (remain 26m 48s) Loss: 0.0000(0.0110) Grad: 148.6572  LR: 0.000019  \n","Epoch: [1][29300/36908] Elapsed 101m 54s (remain 26m 27s) Loss: 0.0000(0.0110) Grad: 427.9861  LR: 0.000019  \n","Epoch: [1][29400/36908] Elapsed 102m 15s (remain 26m 6s) Loss: 0.0000(0.0110) Grad: 252.2560  LR: 0.000019  \n","Epoch: [1][29500/36908] Elapsed 102m 36s (remain 25m 45s) Loss: 0.0000(0.0109) Grad: 367.2014  LR: 0.000019  \n","Epoch: [1][29600/36908] Elapsed 102m 57s (remain 25m 24s) Loss: 0.0000(0.0109) Grad: 144.3554  LR: 0.000019  \n","Epoch: [1][29700/36908] Elapsed 103m 18s (remain 25m 4s) Loss: 0.0000(0.0109) Grad: 198.7894  LR: 0.000019  \n","Epoch: [1][29800/36908] Elapsed 103m 39s (remain 24m 43s) Loss: 0.0199(0.0109) Grad: 86391.7891  LR: 0.000019  \n","Epoch: [1][29900/36908] Elapsed 104m 0s (remain 24m 22s) Loss: 0.0000(0.0109) Grad: 125.1851  LR: 0.000019  \n","Epoch: [1][30000/36908] Elapsed 104m 21s (remain 24m 1s) Loss: 0.0096(0.0109) Grad: 31293.2461  LR: 0.000019  \n","Epoch: [1][30100/36908] Elapsed 104m 41s (remain 23m 40s) Loss: 0.0000(0.0108) Grad: 855.9923  LR: 0.000019  \n","Epoch: [1][30200/36908] Elapsed 105m 2s (remain 23m 19s) Loss: 0.0000(0.0108) Grad: 170.0851  LR: 0.000019  \n","Epoch: [1][30300/36908] Elapsed 105m 23s (remain 22m 58s) Loss: 0.0000(0.0108) Grad: 60.0868  LR: 0.000019  \n","Epoch: [1][30400/36908] Elapsed 105m 44s (remain 22m 37s) Loss: 0.0438(0.0108) Grad: 142309.3281  LR: 0.000019  \n","Epoch: [1][30500/36908] Elapsed 106m 5s (remain 22m 17s) Loss: 0.0000(0.0108) Grad: 132.5720  LR: 0.000019  \n","Epoch: [1][30600/36908] Elapsed 106m 25s (remain 21m 56s) Loss: 0.0000(0.0107) Grad: 119.8674  LR: 0.000019  \n","Epoch: [1][30700/36908] Elapsed 106m 46s (remain 21m 35s) Loss: 0.0000(0.0107) Grad: 50.0786  LR: 0.000019  \n","Epoch: [1][30800/36908] Elapsed 107m 7s (remain 21m 14s) Loss: 0.0000(0.0107) Grad: 149.3756  LR: 0.000019  \n","Epoch: [1][30900/36908] Elapsed 107m 28s (remain 20m 53s) Loss: 0.0046(0.0107) Grad: 20586.1211  LR: 0.000019  \n","Epoch: [1][31000/36908] Elapsed 107m 49s (remain 20m 32s) Loss: 0.0000(0.0107) Grad: 144.0580  LR: 0.000018  \n","Epoch: [1][31100/36908] Elapsed 108m 10s (remain 20m 11s) Loss: 0.0000(0.0106) Grad: 84.1385  LR: 0.000018  \n","Epoch: [1][31200/36908] Elapsed 108m 30s (remain 19m 50s) Loss: 0.0000(0.0106) Grad: 84.0987  LR: 0.000018  \n","Epoch: [1][31300/36908] Elapsed 108m 51s (remain 19m 30s) Loss: 0.0000(0.0106) Grad: 47.4826  LR: 0.000018  \n","Epoch: [1][31400/36908] Elapsed 109m 12s (remain 19m 9s) Loss: 0.0242(0.0106) Grad: 79633.7109  LR: 0.000018  \n","Epoch: [1][31500/36908] Elapsed 109m 33s (remain 18m 48s) Loss: 0.0000(0.0106) Grad: 132.7011  LR: 0.000018  \n","Epoch: [1][31600/36908] Elapsed 109m 54s (remain 18m 27s) Loss: 0.0000(0.0105) Grad: 205.2914  LR: 0.000018  \n","Epoch: [1][31700/36908] Elapsed 110m 14s (remain 18m 6s) Loss: 0.0000(0.0105) Grad: 132.7985  LR: 0.000018  \n","Epoch: [1][31800/36908] Elapsed 110m 35s (remain 17m 45s) Loss: 0.0000(0.0105) Grad: 14.0771  LR: 0.000018  \n","Epoch: [1][31900/36908] Elapsed 110m 56s (remain 17m 24s) Loss: 0.0000(0.0105) Grad: 134.0151  LR: 0.000018  \n","Epoch: [1][32000/36908] Elapsed 111m 17s (remain 17m 3s) Loss: 0.0000(0.0105) Grad: 53.4062  LR: 0.000018  \n","Epoch: [1][32100/36908] Elapsed 111m 38s (remain 16m 43s) Loss: 0.0000(0.0105) Grad: 301.2099  LR: 0.000018  \n","Epoch: [1][32200/36908] Elapsed 111m 59s (remain 16m 22s) Loss: 0.0154(0.0104) Grad: 68908.3672  LR: 0.000018  \n","Epoch: [1][32300/36908] Elapsed 112m 20s (remain 16m 1s) Loss: 0.0000(0.0104) Grad: 159.8111  LR: 0.000018  \n","Epoch: [1][32400/36908] Elapsed 112m 40s (remain 15m 40s) Loss: 0.0000(0.0104) Grad: 86.9996  LR: 0.000018  \n","Epoch: [1][32500/36908] Elapsed 113m 1s (remain 15m 19s) Loss: 0.0423(0.0104) Grad: 323139.3750  LR: 0.000018  \n","Epoch: [1][32600/36908] Elapsed 113m 22s (remain 14m 58s) Loss: 0.0000(0.0104) Grad: 205.9117  LR: 0.000018  \n","Epoch: [1][32700/36908] Elapsed 113m 43s (remain 14m 37s) Loss: 0.0000(0.0104) Grad: 792.2111  LR: 0.000018  \n","Epoch: [1][32800/36908] Elapsed 114m 4s (remain 14m 16s) Loss: 0.0000(0.0103) Grad: 54.8516  LR: 0.000018  \n","Epoch: [1][32900/36908] Elapsed 114m 25s (remain 13m 56s) Loss: 0.0000(0.0103) Grad: 103.0688  LR: 0.000018  \n","Epoch: [1][33000/36908] Elapsed 114m 45s (remain 13m 35s) Loss: 0.0081(0.0103) Grad: 61596.5742  LR: 0.000018  \n","Epoch: [1][33100/36908] Elapsed 115m 6s (remain 13m 14s) Loss: 0.0000(0.0103) Grad: 299.0602  LR: 0.000018  \n","Epoch: [1][33200/36908] Elapsed 115m 27s (remain 12m 53s) Loss: 0.0000(0.0103) Grad: 67.9942  LR: 0.000018  \n","Epoch: [1][33300/36908] Elapsed 115m 48s (remain 12m 32s) Loss: 0.0000(0.0103) Grad: 193.3046  LR: 0.000018  \n","Epoch: [1][33400/36908] Elapsed 116m 9s (remain 12m 11s) Loss: 0.0000(0.0103) Grad: 354.1861  LR: 0.000018  \n","Epoch: [1][33500/36908] Elapsed 116m 30s (remain 11m 50s) Loss: 0.0461(0.0102) Grad: 139513.7969  LR: 0.000018  \n","Epoch: [1][33600/36908] Elapsed 116m 50s (remain 11m 30s) Loss: 0.0000(0.0102) Grad: 112.0596  LR: 0.000018  \n","Epoch: [1][33700/36908] Elapsed 117m 11s (remain 11m 9s) Loss: 0.0000(0.0102) Grad: 207.2577  LR: 0.000018  \n","Epoch: [1][33800/36908] Elapsed 117m 32s (remain 10m 48s) Loss: 0.0000(0.0102) Grad: 102.4244  LR: 0.000018  \n","Epoch: [1][33900/36908] Elapsed 117m 53s (remain 10m 27s) Loss: 0.0000(0.0102) Grad: 55.8351  LR: 0.000018  \n","Epoch: [1][34000/36908] Elapsed 118m 14s (remain 10m 6s) Loss: 0.0000(0.0102) Grad: 63.7542  LR: 0.000018  \n","Epoch: [1][34100/36908] Elapsed 118m 35s (remain 9m 45s) Loss: 0.0000(0.0101) Grad: 63.6357  LR: 0.000018  \n","Epoch: [1][34200/36908] Elapsed 118m 56s (remain 9m 24s) Loss: 0.0088(0.0101) Grad: 7216.4434  LR: 0.000018  \n","Epoch: [1][34300/36908] Elapsed 119m 16s (remain 9m 3s) Loss: 0.0000(0.0101) Grad: 55.4677  LR: 0.000018  \n","Epoch: [1][34400/36908] Elapsed 119m 37s (remain 8m 43s) Loss: 0.0000(0.0101) Grad: 135.6128  LR: 0.000018  \n","Epoch: [1][34500/36908] Elapsed 119m 58s (remain 8m 22s) Loss: 0.0072(0.0101) Grad: 7580.3809  LR: 0.000018  \n","Epoch: [1][34600/36908] Elapsed 120m 19s (remain 8m 1s) Loss: 0.0001(0.0100) Grad: 651.7385  LR: 0.000018  \n","Epoch: [1][34700/36908] Elapsed 120m 40s (remain 7m 40s) Loss: 0.0001(0.0100) Grad: 328.1502  LR: 0.000018  \n","Epoch: [1][34800/36908] Elapsed 121m 0s (remain 7m 19s) Loss: 0.0000(0.0100) Grad: 71.0344  LR: 0.000018  \n","Epoch: [1][34900/36908] Elapsed 121m 21s (remain 6m 58s) Loss: 0.0001(0.0100) Grad: 497.4589  LR: 0.000018  \n","Epoch: [1][35000/36908] Elapsed 121m 42s (remain 6m 37s) Loss: 0.0000(0.0100) Grad: 118.8912  LR: 0.000018  \n","Epoch: [1][35100/36908] Elapsed 122m 3s (remain 6m 17s) Loss: 0.0464(0.0100) Grad: 213826.5156  LR: 0.000018  \n","Epoch: [1][35200/36908] Elapsed 122m 25s (remain 5m 56s) Loss: 0.0000(0.0100) Grad: 87.7642  LR: 0.000018  \n","Epoch: [1][35300/36908] Elapsed 122m 46s (remain 5m 35s) Loss: 0.0000(0.0099) Grad: 200.9327  LR: 0.000018  \n","Epoch: [1][35400/36908] Elapsed 123m 7s (remain 5m 14s) Loss: 0.0000(0.0099) Grad: 140.7635  LR: 0.000018  \n","Epoch: [1][35500/36908] Elapsed 123m 28s (remain 4m 53s) Loss: 0.0148(0.0099) Grad: 36992.5547  LR: 0.000018  \n","Epoch: [1][35600/36908] Elapsed 123m 49s (remain 4m 32s) Loss: 0.0000(0.0099) Grad: 82.6130  LR: 0.000018  \n","Epoch: [1][35700/36908] Elapsed 124m 10s (remain 4m 11s) Loss: 0.0000(0.0099) Grad: 45.5860  LR: 0.000018  \n","Epoch: [1][35800/36908] Elapsed 124m 31s (remain 3m 51s) Loss: 0.0045(0.0099) Grad: 5171.6836  LR: 0.000018  \n","Epoch: [1][35900/36908] Elapsed 124m 52s (remain 3m 30s) Loss: 0.0000(0.0098) Grad: 33.0272  LR: 0.000018  \n","Epoch: [1][36000/36908] Elapsed 125m 13s (remain 3m 9s) Loss: 0.0001(0.0098) Grad: 274.0466  LR: 0.000018  \n","Epoch: [1][36100/36908] Elapsed 125m 34s (remain 2m 48s) Loss: 0.0053(0.0098) Grad: 12411.5391  LR: 0.000018  \n","Epoch: [1][36200/36908] Elapsed 125m 55s (remain 2m 27s) Loss: 0.0000(0.0098) Grad: 140.3805  LR: 0.000018  \n","Epoch: [1][36300/36908] Elapsed 126m 16s (remain 2m 6s) Loss: 0.0000(0.0098) Grad: 150.6205  LR: 0.000018  \n","Epoch: [1][36400/36908] Elapsed 126m 37s (remain 1m 45s) Loss: 0.0000(0.0098) Grad: 71.8594  LR: 0.000018  \n","Epoch: [1][36500/36908] Elapsed 126m 58s (remain 1m 24s) Loss: 0.0001(0.0097) Grad: 538.8766  LR: 0.000018  \n","Epoch: [1][36600/36908] Elapsed 127m 20s (remain 1m 4s) Loss: 0.0001(0.0097) Grad: 274.0489  LR: 0.000018  \n","Epoch: [1][36700/36908] Elapsed 127m 41s (remain 0m 43s) Loss: 0.0001(0.0097) Grad: 216.5071  LR: 0.000018  \n","Epoch: [1][36800/36908] Elapsed 128m 2s (remain 0m 22s) Loss: 0.0000(0.0097) Grad: 30.5655  LR: 0.000018  \n","Epoch: [1][36900/36908] Elapsed 128m 23s (remain 0m 1s) Loss: 0.0001(0.0097) Grad: 229.5970  LR: 0.000018  \n","Epoch: [1][36907/36908] Elapsed 128m 24s (remain 0m 0s) Loss: 0.0000(0.0097) Grad: 881.3210  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 6m 7s) Loss: 0.0150(0.0150) \n","EVAL: [100/1192] Elapsed 0m 5s (remain 1m 0s) Loss: 0.0204(0.0332) \n","EVAL: [200/1192] Elapsed 0m 10s (remain 0m 53s) Loss: 0.0298(0.0310) \n","EVAL: [300/1192] Elapsed 0m 16s (remain 0m 47s) Loss: 0.0618(0.0297) \n","EVAL: [400/1192] Elapsed 0m 21s (remain 0m 41s) Loss: 0.0642(0.0336) \n","EVAL: [500/1192] Elapsed 0m 26s (remain 0m 36s) Loss: 0.0123(0.0368) \n","EVAL: [600/1192] Elapsed 0m 31s (remain 0m 31s) Loss: 0.0352(0.0386) \n","EVAL: [700/1192] Elapsed 0m 36s (remain 0m 25s) Loss: 0.0108(0.0415) \n","EVAL: [800/1192] Elapsed 0m 42s (remain 0m 20s) Loss: 0.0000(0.0413) \n","EVAL: [900/1192] Elapsed 0m 47s (remain 0m 15s) Loss: 0.0517(0.0417) \n","EVAL: [1000/1192] Elapsed 0m 52s (remain 0m 10s) Loss: 0.0371(0.0416) \n","EVAL: [1100/1192] Elapsed 0m 57s (remain 0m 4s) Loss: 0.0591(0.0407) \n","EVAL: [1191/1192] Elapsed 1m 2s (remain 0m 0s) Loss: 0.0331(0.0394) \n","Epoch 1 - avg_train_loss: 0.0097  avg_val_loss: 0.0394  time: 7773s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","========== fold: 3 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_3.npy\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/36908] Elapsed 0m 0s (remain 308m 58s) Loss: 0.3117(0.3117) Grad: 192093.2656  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 21s (remain 131m 14s) Loss: 0.2934(0.3065) Grad: 25597.2305  LR: 0.000000  \n","Epoch: [1][200/36908] Elapsed 0m 42s (remain 129m 44s) Loss: 0.2870(0.2970) Grad: 11703.0215  LR: 0.000000  \n","Epoch: [1][300/36908] Elapsed 1m 3s (remain 128m 58s) Loss: 0.2335(0.2815) Grad: 9988.7061  LR: 0.000000  \n","Epoch: [1][400/36908] Elapsed 1m 24s (remain 128m 31s) Loss: 0.1727(0.2612) Grad: 8449.1914  LR: 0.000000  \n","Epoch: [1][500/36908] Elapsed 1m 45s (remain 128m 3s) Loss: 0.1245(0.2387) Grad: 6614.0146  LR: 0.000001  \n","Epoch: [1][600/36908] Elapsed 2m 6s (remain 127m 35s) Loss: 0.0739(0.2151) Grad: 4202.0874  LR: 0.000001  \n","Epoch: [1][700/36908] Elapsed 2m 27s (remain 127m 11s) Loss: 0.0289(0.1916) Grad: 2035.4617  LR: 0.000001  \n","Epoch: [1][800/36908] Elapsed 2m 48s (remain 126m 48s) Loss: 0.0017(0.1694) Grad: 271.4257  LR: 0.000001  \n","Epoch: [1][900/36908] Elapsed 3m 9s (remain 126m 26s) Loss: 0.0004(0.1511) Grad: 89.1147  LR: 0.000001  \n","Epoch: [1][1000/36908] Elapsed 3m 30s (remain 126m 3s) Loss: 0.0005(0.1367) Grad: 96.9401  LR: 0.000001  \n","Epoch: [1][1100/36908] Elapsed 3m 52s (remain 125m 46s) Loss: 0.0008(0.1249) Grad: 151.0855  LR: 0.000001  \n","Epoch: [1][1200/36908] Elapsed 4m 13s (remain 125m 28s) Loss: 0.0008(0.1149) Grad: 142.9989  LR: 0.000001  \n","Epoch: [1][1300/36908] Elapsed 4m 34s (remain 125m 11s) Loss: 0.0006(0.1066) Grad: 91.6551  LR: 0.000001  \n","Epoch: [1][1400/36908] Elapsed 4m 55s (remain 124m 49s) Loss: 0.0002(0.0992) Grad: 43.8827  LR: 0.000002  \n","Epoch: [1][1500/36908] Elapsed 5m 16s (remain 124m 23s) Loss: 0.0182(0.0931) Grad: 513.0026  LR: 0.000002  \n","Epoch: [1][1600/36908] Elapsed 5m 37s (remain 123m 59s) Loss: 0.0005(0.0876) Grad: 75.0105  LR: 0.000002  \n","Epoch: [1][1700/36908] Elapsed 5m 58s (remain 123m 34s) Loss: 0.0111(0.0827) Grad: 269.4038  LR: 0.000002  \n","Epoch: [1][1800/36908] Elapsed 6m 19s (remain 123m 8s) Loss: 0.0003(0.0783) Grad: 57.0454  LR: 0.000002  \n","Epoch: [1][1900/36908] Elapsed 6m 39s (remain 122m 42s) Loss: 0.0052(0.0745) Grad: 145.7353  LR: 0.000002  \n","Epoch: [1][2000/36908] Elapsed 7m 0s (remain 122m 17s) Loss: 0.0097(0.0711) Grad: 228.6430  LR: 0.000002  \n","Epoch: [1][2100/36908] Elapsed 7m 21s (remain 121m 54s) Loss: 0.0004(0.0680) Grad: 85.7923  LR: 0.000002  \n","Epoch: [1][2200/36908] Elapsed 7m 42s (remain 121m 31s) Loss: 0.0007(0.0651) Grad: 108.9608  LR: 0.000002  \n","Epoch: [1][2300/36908] Elapsed 8m 3s (remain 121m 7s) Loss: 0.0275(0.0625) Grad: 671.9802  LR: 0.000002  \n","Epoch: [1][2400/36908] Elapsed 8m 23s (remain 120m 43s) Loss: 0.0008(0.0601) Grad: 122.0138  LR: 0.000003  \n","Epoch: [1][2500/36908] Elapsed 8m 44s (remain 120m 19s) Loss: 0.0003(0.0579) Grad: 57.4547  LR: 0.000003  \n","Epoch: [1][2600/36908] Elapsed 9m 5s (remain 119m 57s) Loss: 0.0153(0.0558) Grad: 463.8347  LR: 0.000003  \n","Epoch: [1][2700/36908] Elapsed 9m 26s (remain 119m 34s) Loss: 0.0003(0.0539) Grad: 60.3574  LR: 0.000003  \n","Epoch: [1][2800/36908] Elapsed 9m 47s (remain 119m 12s) Loss: 0.0100(0.0521) Grad: 358.9449  LR: 0.000003  \n","Epoch: [1][2900/36908] Elapsed 10m 8s (remain 118m 49s) Loss: 0.0004(0.0505) Grad: 72.5499  LR: 0.000003  \n","Epoch: [1][3000/36908] Elapsed 10m 28s (remain 118m 25s) Loss: 0.0008(0.0490) Grad: 136.7669  LR: 0.000003  \n","Epoch: [1][3100/36908] Elapsed 10m 49s (remain 118m 2s) Loss: 0.0011(0.0476) Grad: 174.8838  LR: 0.000003  \n","Epoch: [1][3200/36908] Elapsed 11m 10s (remain 117m 38s) Loss: 0.0009(0.0463) Grad: 158.7853  LR: 0.000003  \n","Epoch: [1][3300/36908] Elapsed 11m 31s (remain 117m 16s) Loss: 0.0003(0.0450) Grad: 68.9394  LR: 0.000004  \n","Epoch: [1][3400/36908] Elapsed 11m 51s (remain 116m 53s) Loss: 0.0001(0.0438) Grad: 36.5373  LR: 0.000004  \n","Epoch: [1][3500/36908] Elapsed 12m 12s (remain 116m 31s) Loss: 0.0001(0.0426) Grad: 30.4483  LR: 0.000004  \n","Epoch: [1][3600/36908] Elapsed 12m 33s (remain 116m 9s) Loss: 0.0003(0.0415) Grad: 81.3546  LR: 0.000004  \n","Epoch: [1][3700/36908] Elapsed 12m 54s (remain 115m 46s) Loss: 0.0007(0.0406) Grad: 168.8369  LR: 0.000004  \n","Epoch: [1][3800/36908] Elapsed 13m 15s (remain 115m 24s) Loss: 0.0001(0.0396) Grad: 36.5918  LR: 0.000004  \n","Epoch: [1][3900/36908] Elapsed 13m 35s (remain 115m 3s) Loss: 0.0001(0.0386) Grad: 40.3523  LR: 0.000004  \n","Epoch: [1][4000/36908] Elapsed 13m 56s (remain 114m 42s) Loss: 0.0002(0.0378) Grad: 54.1678  LR: 0.000004  \n","Epoch: [1][4100/36908] Elapsed 14m 17s (remain 114m 20s) Loss: 0.0016(0.0370) Grad: 319.9368  LR: 0.000004  \n","Epoch: [1][4200/36908] Elapsed 14m 38s (remain 113m 59s) Loss: 0.0001(0.0362) Grad: 57.8348  LR: 0.000005  \n","Epoch: [1][4300/36908] Elapsed 14m 59s (remain 113m 36s) Loss: 0.0004(0.0354) Grad: 168.8016  LR: 0.000005  \n","Epoch: [1][4400/36908] Elapsed 15m 19s (remain 113m 14s) Loss: 0.0002(0.0347) Grad: 104.7828  LR: 0.000005  \n","Epoch: [1][4500/36908] Elapsed 15m 40s (remain 112m 52s) Loss: 0.0004(0.0340) Grad: 178.4200  LR: 0.000005  \n","Epoch: [1][4600/36908] Elapsed 16m 1s (remain 112m 31s) Loss: 0.0001(0.0333) Grad: 79.7795  LR: 0.000005  \n","Epoch: [1][4700/36908] Elapsed 16m 22s (remain 112m 10s) Loss: 0.0001(0.0327) Grad: 98.7401  LR: 0.000005  \n","Epoch: [1][4800/36908] Elapsed 16m 43s (remain 111m 51s) Loss: 0.0001(0.0321) Grad: 74.8680  LR: 0.000005  \n","Epoch: [1][4900/36908] Elapsed 17m 4s (remain 111m 31s) Loss: 0.0000(0.0315) Grad: 20.2217  LR: 0.000005  \n","Epoch: [1][5000/36908] Elapsed 17m 25s (remain 111m 11s) Loss: 0.0008(0.0310) Grad: 336.5326  LR: 0.000005  \n","Epoch: [1][5100/36908] Elapsed 17m 46s (remain 110m 51s) Loss: 0.0178(0.0304) Grad: 2252.4075  LR: 0.000006  \n","Epoch: [1][5200/36908] Elapsed 18m 7s (remain 110m 31s) Loss: 0.0080(0.0299) Grad: 1184.2527  LR: 0.000006  \n","Epoch: [1][5300/36908] Elapsed 18m 28s (remain 110m 11s) Loss: 0.0041(0.0294) Grad: 426.0490  LR: 0.000006  \n","Epoch: [1][5400/36908] Elapsed 18m 50s (remain 109m 51s) Loss: 0.0002(0.0289) Grad: 77.0901  LR: 0.000006  \n","Epoch: [1][5500/36908] Elapsed 19m 11s (remain 109m 31s) Loss: 0.0001(0.0284) Grad: 43.9606  LR: 0.000006  \n","Epoch: [1][5600/36908] Elapsed 19m 32s (remain 109m 12s) Loss: 0.0005(0.0280) Grad: 149.8021  LR: 0.000006  \n","Epoch: [1][5700/36908] Elapsed 19m 53s (remain 108m 53s) Loss: 0.0029(0.0276) Grad: 391.3912  LR: 0.000006  \n","Epoch: [1][5800/36908] Elapsed 20m 14s (remain 108m 33s) Loss: 0.0004(0.0272) Grad: 144.7863  LR: 0.000006  \n","Epoch: [1][5900/36908] Elapsed 20m 35s (remain 108m 12s) Loss: 0.0001(0.0267) Grad: 29.3030  LR: 0.000006  \n","Epoch: [1][6000/36908] Elapsed 20m 56s (remain 107m 52s) Loss: 0.0111(0.0263) Grad: 1317.8500  LR: 0.000007  \n","Epoch: [1][6100/36908] Elapsed 21m 17s (remain 107m 32s) Loss: 0.0003(0.0260) Grad: 79.1838  LR: 0.000007  \n","Epoch: [1][6200/36908] Elapsed 21m 39s (remain 107m 12s) Loss: 0.0002(0.0256) Grad: 62.4735  LR: 0.000007  \n","Epoch: [1][6300/36908] Elapsed 22m 0s (remain 106m 52s) Loss: 0.0007(0.0252) Grad: 181.5966  LR: 0.000007  \n","Epoch: [1][6400/36908] Elapsed 22m 21s (remain 106m 31s) Loss: 0.0007(0.0249) Grad: 222.1513  LR: 0.000007  \n","Epoch: [1][6500/36908] Elapsed 22m 42s (remain 106m 11s) Loss: 0.0032(0.0246) Grad: 1108.3833  LR: 0.000007  \n","Epoch: [1][6600/36908] Elapsed 23m 3s (remain 105m 50s) Loss: 0.0000(0.0242) Grad: 30.2715  LR: 0.000007  \n","Epoch: [1][6700/36908] Elapsed 23m 24s (remain 105m 29s) Loss: 0.0001(0.0240) Grad: 90.7468  LR: 0.000007  \n","Epoch: [1][6800/36908] Elapsed 23m 45s (remain 105m 9s) Loss: 0.0003(0.0237) Grad: 116.2885  LR: 0.000007  \n","Epoch: [1][6900/36908] Elapsed 24m 6s (remain 104m 48s) Loss: 0.0002(0.0234) Grad: 95.2086  LR: 0.000007  \n","Epoch: [1][7000/36908] Elapsed 24m 27s (remain 104m 28s) Loss: 0.0001(0.0231) Grad: 56.8181  LR: 0.000008  \n","Epoch: [1][7100/36908] Elapsed 24m 48s (remain 104m 8s) Loss: 0.0007(0.0228) Grad: 181.0693  LR: 0.000008  \n","Epoch: [1][7200/36908] Elapsed 25m 9s (remain 103m 47s) Loss: 0.0002(0.0225) Grad: 84.6436  LR: 0.000008  \n","Epoch: [1][7300/36908] Elapsed 25m 30s (remain 103m 27s) Loss: 0.0003(0.0223) Grad: 84.1681  LR: 0.000008  \n","Epoch: [1][7400/36908] Elapsed 25m 51s (remain 103m 6s) Loss: 0.0002(0.0220) Grad: 79.8712  LR: 0.000008  \n","Epoch: [1][7500/36908] Elapsed 26m 12s (remain 102m 45s) Loss: 0.0000(0.0218) Grad: 20.4455  LR: 0.000008  \n","Epoch: [1][7600/36908] Elapsed 26m 33s (remain 102m 24s) Loss: 0.0001(0.0215) Grad: 40.5249  LR: 0.000008  \n","Epoch: [1][7700/36908] Elapsed 26m 54s (remain 102m 4s) Loss: 0.0006(0.0213) Grad: 188.0890  LR: 0.000008  \n","Epoch: [1][7800/36908] Elapsed 27m 15s (remain 101m 43s) Loss: 0.0005(0.0211) Grad: 210.7486  LR: 0.000008  \n","Epoch: [1][7900/36908] Elapsed 27m 36s (remain 101m 23s) Loss: 0.0003(0.0208) Grad: 87.7123  LR: 0.000009  \n","Epoch: [1][8000/36908] Elapsed 27m 57s (remain 101m 2s) Loss: 0.0006(0.0206) Grad: 134.6918  LR: 0.000009  \n","Epoch: [1][8100/36908] Elapsed 28m 18s (remain 100m 41s) Loss: 0.0002(0.0204) Grad: 77.2298  LR: 0.000009  \n","Epoch: [1][8200/36908] Elapsed 28m 40s (remain 100m 20s) Loss: 0.0003(0.0202) Grad: 166.3579  LR: 0.000009  \n","Epoch: [1][8300/36908] Elapsed 29m 1s (remain 100m 0s) Loss: 0.0003(0.0200) Grad: 173.6649  LR: 0.000009  \n","Epoch: [1][8400/36908] Elapsed 29m 22s (remain 99m 40s) Loss: 0.0004(0.0198) Grad: 242.2905  LR: 0.000009  \n","Epoch: [1][8500/36908] Elapsed 29m 43s (remain 99m 20s) Loss: 0.0002(0.0196) Grad: 118.0774  LR: 0.000009  \n","Epoch: [1][8600/36908] Elapsed 30m 4s (remain 98m 59s) Loss: 0.0002(0.0194) Grad: 99.8848  LR: 0.000009  \n","Epoch: [1][8700/36908] Elapsed 30m 25s (remain 98m 38s) Loss: 0.0076(0.0192) Grad: 1394.3561  LR: 0.000009  \n","Epoch: [1][8800/36908] Elapsed 30m 46s (remain 98m 17s) Loss: 0.0001(0.0190) Grad: 75.4298  LR: 0.000010  \n","Epoch: [1][8900/36908] Elapsed 31m 7s (remain 97m 57s) Loss: 0.0001(0.0188) Grad: 94.1637  LR: 0.000010  \n","Epoch: [1][9000/36908] Elapsed 31m 28s (remain 97m 36s) Loss: 0.0002(0.0187) Grad: 126.7427  LR: 0.000010  \n","Epoch: [1][9100/36908] Elapsed 31m 49s (remain 97m 15s) Loss: 0.0003(0.0185) Grad: 192.1197  LR: 0.000010  \n","Epoch: [1][9200/36908] Elapsed 32m 10s (remain 96m 54s) Loss: 0.0001(0.0184) Grad: 70.6192  LR: 0.000010  \n","Epoch: [1][9300/36908] Elapsed 32m 31s (remain 96m 33s) Loss: 0.0002(0.0182) Grad: 91.3700  LR: 0.000010  \n","Epoch: [1][9400/36908] Elapsed 32m 52s (remain 96m 12s) Loss: 0.0059(0.0180) Grad: 1156.8243  LR: 0.000010  \n","Epoch: [1][9500/36908] Elapsed 33m 13s (remain 95m 51s) Loss: 0.0002(0.0179) Grad: 99.6514  LR: 0.000010  \n","Epoch: [1][9600/36908] Elapsed 33m 34s (remain 95m 30s) Loss: 0.0000(0.0177) Grad: 51.0109  LR: 0.000010  \n","Epoch: [1][9700/36908] Elapsed 33m 55s (remain 95m 9s) Loss: 0.0002(0.0176) Grad: 215.1147  LR: 0.000011  \n","Epoch: [1][9800/36908] Elapsed 34m 16s (remain 94m 48s) Loss: 0.0002(0.0174) Grad: 128.2168  LR: 0.000011  \n","Epoch: [1][9900/36908] Elapsed 34m 37s (remain 94m 27s) Loss: 0.0002(0.0173) Grad: 126.1080  LR: 0.000011  \n","Epoch: [1][10000/36908] Elapsed 34m 58s (remain 94m 6s) Loss: 0.0003(0.0172) Grad: 166.7763  LR: 0.000011  \n","Epoch: [1][10100/36908] Elapsed 35m 19s (remain 93m 45s) Loss: 0.0003(0.0170) Grad: 140.4788  LR: 0.000011  \n","Epoch: [1][10200/36908] Elapsed 35m 40s (remain 93m 24s) Loss: 0.0002(0.0169) Grad: 120.9015  LR: 0.000011  \n","Epoch: [1][10300/36908] Elapsed 36m 1s (remain 93m 3s) Loss: 0.0004(0.0168) Grad: 220.0239  LR: 0.000011  \n","Epoch: [1][10400/36908] Elapsed 36m 22s (remain 92m 42s) Loss: 0.0002(0.0166) Grad: 84.3649  LR: 0.000011  \n","Epoch: [1][10500/36908] Elapsed 36m 43s (remain 92m 21s) Loss: 0.0004(0.0165) Grad: 201.2210  LR: 0.000011  \n","Epoch: [1][10600/36908] Elapsed 37m 4s (remain 92m 0s) Loss: 0.0001(0.0164) Grad: 88.0413  LR: 0.000011  \n","Epoch: [1][10700/36908] Elapsed 37m 25s (remain 91m 40s) Loss: 0.0002(0.0163) Grad: 131.2534  LR: 0.000012  \n","Epoch: [1][10800/36908] Elapsed 37m 47s (remain 91m 19s) Loss: 0.0002(0.0162) Grad: 111.6827  LR: 0.000012  \n","Epoch: [1][10900/36908] Elapsed 38m 8s (remain 90m 58s) Loss: 0.0000(0.0160) Grad: 19.0600  LR: 0.000012  \n","Epoch: [1][11000/36908] Elapsed 38m 29s (remain 90m 38s) Loss: 0.0021(0.0159) Grad: 599.1083  LR: 0.000012  \n","Epoch: [1][11100/36908] Elapsed 38m 50s (remain 90m 17s) Loss: 0.0001(0.0158) Grad: 200.5515  LR: 0.000012  \n","Epoch: [1][11200/36908] Elapsed 39m 11s (remain 89m 56s) Loss: 0.0002(0.0157) Grad: 85.8174  LR: 0.000012  \n","Epoch: [1][11300/36908] Elapsed 39m 32s (remain 89m 35s) Loss: 0.0003(0.0156) Grad: 136.5523  LR: 0.000012  \n","Epoch: [1][11400/36908] Elapsed 39m 53s (remain 89m 15s) Loss: 0.0002(0.0155) Grad: 96.8549  LR: 0.000012  \n","Epoch: [1][11500/36908] Elapsed 40m 14s (remain 88m 54s) Loss: 0.0002(0.0154) Grad: 111.8222  LR: 0.000012  \n","Epoch: [1][11600/36908] Elapsed 40m 35s (remain 88m 33s) Loss: 0.0003(0.0153) Grad: 176.7615  LR: 0.000013  \n","Epoch: [1][11700/36908] Elapsed 40m 56s (remain 88m 12s) Loss: 0.0004(0.0152) Grad: 228.4271  LR: 0.000013  \n","Epoch: [1][11800/36908] Elapsed 41m 17s (remain 87m 51s) Loss: 0.0004(0.0151) Grad: 186.1440  LR: 0.000013  \n","Epoch: [1][11900/36908] Elapsed 41m 38s (remain 87m 30s) Loss: 0.0101(0.0150) Grad: 1810.8885  LR: 0.000013  \n","Epoch: [1][12000/36908] Elapsed 41m 59s (remain 87m 9s) Loss: 0.0074(0.0149) Grad: 1211.9895  LR: 0.000013  \n","Epoch: [1][12100/36908] Elapsed 42m 20s (remain 86m 48s) Loss: 0.0002(0.0148) Grad: 83.7763  LR: 0.000013  \n","Epoch: [1][12200/36908] Elapsed 42m 41s (remain 86m 27s) Loss: 0.0007(0.0147) Grad: 821.8017  LR: 0.000013  \n","Epoch: [1][12300/36908] Elapsed 43m 2s (remain 86m 6s) Loss: 0.0001(0.0147) Grad: 202.9758  LR: 0.000013  \n","Epoch: [1][12400/36908] Elapsed 43m 23s (remain 85m 45s) Loss: 0.0026(0.0146) Grad: 1300.4613  LR: 0.000013  \n","Epoch: [1][12500/36908] Elapsed 43m 44s (remain 85m 24s) Loss: 0.0001(0.0145) Grad: 139.5880  LR: 0.000014  \n","Epoch: [1][12600/36908] Elapsed 44m 5s (remain 85m 3s) Loss: 0.0001(0.0144) Grad: 78.2800  LR: 0.000014  \n","Epoch: [1][12700/36908] Elapsed 44m 26s (remain 84m 42s) Loss: 0.0001(0.0143) Grad: 161.7117  LR: 0.000014  \n","Epoch: [1][12800/36908] Elapsed 44m 47s (remain 84m 21s) Loss: 0.0003(0.0142) Grad: 322.6125  LR: 0.000014  \n","Epoch: [1][12900/36908] Elapsed 45m 8s (remain 84m 0s) Loss: 0.0001(0.0142) Grad: 216.1394  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 45m 29s (remain 83m 40s) Loss: 0.0001(0.0141) Grad: 101.4958  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 45m 51s (remain 83m 19s) Loss: 0.0001(0.0140) Grad: 119.1161  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 46m 12s (remain 82m 58s) Loss: 0.1511(0.0140) Grad: 32920.6523  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 46m 33s (remain 82m 37s) Loss: 0.0001(0.0139) Grad: 116.4049  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 46m 54s (remain 82m 16s) Loss: 0.0001(0.0138) Grad: 87.5534  LR: 0.000015  \n","Epoch: [1][13500/36908] Elapsed 47m 15s (remain 81m 55s) Loss: 0.0069(0.0137) Grad: 2381.4500  LR: 0.000015  \n","Epoch: [1][13600/36908] Elapsed 47m 36s (remain 81m 34s) Loss: 0.0000(0.0137) Grad: 52.6269  LR: 0.000015  \n","Epoch: [1][13700/36908] Elapsed 47m 57s (remain 81m 13s) Loss: 0.0003(0.0136) Grad: 291.3459  LR: 0.000015  \n","Epoch: [1][13800/36908] Elapsed 48m 18s (remain 80m 52s) Loss: 0.0001(0.0135) Grad: 140.0768  LR: 0.000015  \n","Epoch: [1][13900/36908] Elapsed 48m 39s (remain 80m 31s) Loss: 0.0002(0.0134) Grad: 177.2793  LR: 0.000015  \n","Epoch: [1][14000/36908] Elapsed 49m 0s (remain 80m 10s) Loss: 0.0002(0.0134) Grad: 227.8231  LR: 0.000015  \n","Epoch: [1][14100/36908] Elapsed 49m 21s (remain 79m 49s) Loss: 0.0005(0.0133) Grad: 458.0353  LR: 0.000015  \n","Epoch: [1][14200/36908] Elapsed 49m 42s (remain 79m 29s) Loss: 0.0002(0.0132) Grad: 284.2196  LR: 0.000015  \n","Epoch: [1][14300/36908] Elapsed 50m 3s (remain 79m 8s) Loss: 0.0001(0.0132) Grad: 111.8641  LR: 0.000015  \n","Epoch: [1][14400/36908] Elapsed 50m 25s (remain 78m 47s) Loss: 0.0062(0.0131) Grad: 2887.0713  LR: 0.000016  \n","Epoch: [1][14500/36908] Elapsed 50m 46s (remain 78m 26s) Loss: 0.0078(0.0130) Grad: 6958.3252  LR: 0.000016  \n","Epoch: [1][14600/36908] Elapsed 51m 7s (remain 78m 5s) Loss: 0.0205(0.0130) Grad: 8747.9639  LR: 0.000016  \n","Epoch: [1][14700/36908] Elapsed 51m 28s (remain 77m 44s) Loss: 0.0002(0.0129) Grad: 175.3397  LR: 0.000016  \n","Epoch: [1][14800/36908] Elapsed 51m 49s (remain 77m 23s) Loss: 0.0000(0.0128) Grad: 45.1919  LR: 0.000016  \n","Epoch: [1][14900/36908] Elapsed 52m 10s (remain 77m 2s) Loss: 0.0002(0.0128) Grad: 156.2305  LR: 0.000016  \n","Epoch: [1][15000/36908] Elapsed 52m 31s (remain 76m 42s) Loss: 0.0001(0.0127) Grad: 149.2694  LR: 0.000016  \n","Epoch: [1][15100/36908] Elapsed 52m 52s (remain 76m 21s) Loss: 0.0001(0.0127) Grad: 78.3486  LR: 0.000016  \n","Epoch: [1][15200/36908] Elapsed 53m 13s (remain 76m 0s) Loss: 0.0001(0.0126) Grad: 89.1929  LR: 0.000016  \n","Epoch: [1][15300/36908] Elapsed 53m 34s (remain 75m 39s) Loss: 0.0003(0.0126) Grad: 336.6290  LR: 0.000017  \n","Epoch: [1][15400/36908] Elapsed 53m 55s (remain 75m 18s) Loss: 0.0001(0.0125) Grad: 122.1691  LR: 0.000017  \n","Epoch: [1][15500/36908] Elapsed 54m 16s (remain 74m 57s) Loss: 0.0002(0.0124) Grad: 273.8166  LR: 0.000017  \n","Epoch: [1][15600/36908] Elapsed 54m 37s (remain 74m 36s) Loss: 0.0267(0.0124) Grad: 5942.0703  LR: 0.000017  \n","Epoch: [1][15700/36908] Elapsed 54m 59s (remain 74m 15s) Loss: 0.0000(0.0123) Grad: 49.1024  LR: 0.000017  \n","Epoch: [1][15800/36908] Elapsed 55m 20s (remain 73m 55s) Loss: 0.0001(0.0123) Grad: 115.5289  LR: 0.000017  \n","Epoch: [1][15900/36908] Elapsed 55m 41s (remain 73m 33s) Loss: 0.0002(0.0122) Grad: 190.6281  LR: 0.000017  \n","Epoch: [1][16000/36908] Elapsed 56m 2s (remain 73m 13s) Loss: 0.0002(0.0122) Grad: 176.4266  LR: 0.000017  \n","Epoch: [1][16100/36908] Elapsed 56m 23s (remain 72m 51s) Loss: 0.0002(0.0121) Grad: 188.2288  LR: 0.000017  \n","Epoch: [1][16200/36908] Elapsed 56m 43s (remain 72m 30s) Loss: 0.0001(0.0121) Grad: 193.5342  LR: 0.000018  \n","Epoch: [1][16300/36908] Elapsed 57m 4s (remain 72m 9s) Loss: 0.0000(0.0120) Grad: 27.1934  LR: 0.000018  \n","Epoch: [1][16400/36908] Elapsed 57m 25s (remain 71m 48s) Loss: 0.0000(0.0120) Grad: 68.9887  LR: 0.000018  \n","Epoch: [1][16500/36908] Elapsed 57m 46s (remain 71m 27s) Loss: 0.0410(0.0120) Grad: 18202.0938  LR: 0.000018  \n","Epoch: [1][16600/36908] Elapsed 58m 7s (remain 71m 6s) Loss: 0.0001(0.0119) Grad: 319.8221  LR: 0.000018  \n","Epoch: [1][16700/36908] Elapsed 58m 28s (remain 70m 44s) Loss: 0.0001(0.0119) Grad: 195.3647  LR: 0.000018  \n","Epoch: [1][16800/36908] Elapsed 58m 49s (remain 70m 23s) Loss: 0.0000(0.0118) Grad: 32.4653  LR: 0.000018  \n","Epoch: [1][16900/36908] Elapsed 59m 10s (remain 70m 2s) Loss: 0.0000(0.0118) Grad: 91.4135  LR: 0.000018  \n","Epoch: [1][17000/36908] Elapsed 59m 30s (remain 69m 41s) Loss: 0.0000(0.0117) Grad: 43.1349  LR: 0.000018  \n","Epoch: [1][17100/36908] Elapsed 59m 51s (remain 69m 20s) Loss: 0.0001(0.0117) Grad: 143.6381  LR: 0.000019  \n","Epoch: [1][17200/36908] Elapsed 60m 13s (remain 68m 59s) Loss: 0.0001(0.0116) Grad: 208.5805  LR: 0.000019  \n","Epoch: [1][17300/36908] Elapsed 60m 33s (remain 68m 38s) Loss: 0.0137(0.0116) Grad: 6032.7007  LR: 0.000019  \n","Epoch: [1][17400/36908] Elapsed 60m 54s (remain 68m 16s) Loss: 0.0001(0.0115) Grad: 201.9072  LR: 0.000019  \n","Epoch: [1][17500/36908] Elapsed 61m 15s (remain 67m 55s) Loss: 0.0001(0.0115) Grad: 228.7634  LR: 0.000019  \n","Epoch: [1][17600/36908] Elapsed 61m 36s (remain 67m 34s) Loss: 0.0025(0.0115) Grad: 2469.7458  LR: 0.000019  \n","Epoch: [1][17700/36908] Elapsed 61m 57s (remain 67m 13s) Loss: 0.0157(0.0114) Grad: 11653.4639  LR: 0.000019  \n","Epoch: [1][17800/36908] Elapsed 62m 18s (remain 66m 52s) Loss: 0.0000(0.0114) Grad: 55.2900  LR: 0.000019  \n","Epoch: [1][17900/36908] Elapsed 62m 38s (remain 66m 31s) Loss: 0.0206(0.0113) Grad: 7753.1123  LR: 0.000019  \n","Epoch: [1][18000/36908] Elapsed 62m 59s (remain 66m 9s) Loss: 0.0085(0.0113) Grad: 4600.5176  LR: 0.000020  \n","Epoch: [1][18100/36908] Elapsed 63m 20s (remain 65m 48s) Loss: 0.0197(0.0112) Grad: 11263.0088  LR: 0.000020  \n","Epoch: [1][18200/36908] Elapsed 63m 41s (remain 65m 27s) Loss: 0.0000(0.0112) Grad: 107.1137  LR: 0.000020  \n","Epoch: [1][18300/36908] Elapsed 64m 2s (remain 65m 6s) Loss: 0.0001(0.0112) Grad: 178.7566  LR: 0.000020  \n","Epoch: [1][18400/36908] Elapsed 64m 23s (remain 64m 45s) Loss: 0.0001(0.0111) Grad: 151.6069  LR: 0.000020  \n","Epoch: [1][18500/36908] Elapsed 64m 44s (remain 64m 24s) Loss: 0.0001(0.0111) Grad: 120.3857  LR: 0.000020  \n","Epoch: [1][18600/36908] Elapsed 65m 5s (remain 64m 3s) Loss: 0.0002(0.0111) Grad: 285.8112  LR: 0.000020  \n","Epoch: [1][18700/36908] Elapsed 65m 26s (remain 63m 42s) Loss: 0.0001(0.0110) Grad: 210.6366  LR: 0.000020  \n","Epoch: [1][18800/36908] Elapsed 65m 47s (remain 63m 21s) Loss: 0.0001(0.0110) Grad: 126.5188  LR: 0.000020  \n","Epoch: [1][18900/36908] Elapsed 66m 8s (remain 63m 0s) Loss: 0.0000(0.0109) Grad: 60.1108  LR: 0.000020  \n","Epoch: [1][19000/36908] Elapsed 66m 28s (remain 62m 39s) Loss: 0.0000(0.0109) Grad: 29.4188  LR: 0.000020  \n","Epoch: [1][19100/36908] Elapsed 66m 49s (remain 62m 17s) Loss: 0.0000(0.0109) Grad: 52.5894  LR: 0.000020  \n","Epoch: [1][19200/36908] Elapsed 67m 10s (remain 61m 56s) Loss: 0.0002(0.0108) Grad: 324.2067  LR: 0.000020  \n","Epoch: [1][19300/36908] Elapsed 67m 30s (remain 61m 35s) Loss: 0.0000(0.0108) Grad: 42.7946  LR: 0.000020  \n","Epoch: [1][19400/36908] Elapsed 67m 51s (remain 61m 14s) Loss: 0.0493(0.0108) Grad: 48066.8242  LR: 0.000020  \n","Epoch: [1][19500/36908] Elapsed 68m 12s (remain 60m 53s) Loss: 0.0108(0.0107) Grad: 5389.0527  LR: 0.000020  \n","Epoch: [1][19600/36908] Elapsed 68m 33s (remain 60m 32s) Loss: 0.0001(0.0107) Grad: 219.6277  LR: 0.000020  \n","Epoch: [1][19700/36908] Elapsed 68m 54s (remain 60m 10s) Loss: 0.0003(0.0106) Grad: 679.3508  LR: 0.000020  \n","Epoch: [1][19800/36908] Elapsed 69m 15s (remain 59m 49s) Loss: 0.0143(0.0106) Grad: 10397.0869  LR: 0.000020  \n","Epoch: [1][19900/36908] Elapsed 69m 35s (remain 59m 28s) Loss: 0.0136(0.0106) Grad: 8211.7920  LR: 0.000020  \n","Epoch: [1][20000/36908] Elapsed 69m 56s (remain 59m 7s) Loss: 0.0001(0.0105) Grad: 212.3095  LR: 0.000020  \n","Epoch: [1][20100/36908] Elapsed 70m 17s (remain 58m 46s) Loss: 0.0000(0.0105) Grad: 6.4692  LR: 0.000020  \n","Epoch: [1][20200/36908] Elapsed 70m 38s (remain 58m 25s) Loss: 0.0000(0.0105) Grad: 187.8415  LR: 0.000020  \n","Epoch: [1][20300/36908] Elapsed 70m 58s (remain 58m 3s) Loss: 0.0092(0.0104) Grad: 11603.8281  LR: 0.000020  \n","Epoch: [1][20400/36908] Elapsed 71m 19s (remain 57m 42s) Loss: 0.0001(0.0104) Grad: 301.3742  LR: 0.000020  \n","Epoch: [1][20500/36908] Elapsed 71m 40s (remain 57m 21s) Loss: 0.0000(0.0104) Grad: 70.4665  LR: 0.000020  \n","Epoch: [1][20600/36908] Elapsed 72m 1s (remain 57m 0s) Loss: 0.0000(0.0103) Grad: 95.2864  LR: 0.000020  \n","Epoch: [1][20700/36908] Elapsed 72m 21s (remain 56m 39s) Loss: 0.0001(0.0103) Grad: 252.7502  LR: 0.000020  \n","Epoch: [1][20800/36908] Elapsed 72m 42s (remain 56m 18s) Loss: 0.0000(0.0103) Grad: 47.1528  LR: 0.000020  \n","Epoch: [1][20900/36908] Elapsed 73m 3s (remain 55m 57s) Loss: 0.0000(0.0102) Grad: 144.8240  LR: 0.000020  \n","Epoch: [1][21000/36908] Elapsed 73m 24s (remain 55m 35s) Loss: 0.0000(0.0102) Grad: 75.7128  LR: 0.000020  \n","Epoch: [1][21100/36908] Elapsed 73m 45s (remain 55m 14s) Loss: 0.0000(0.0102) Grad: 137.2370  LR: 0.000020  \n","Epoch: [1][21200/36908] Elapsed 74m 5s (remain 54m 53s) Loss: 0.0000(0.0102) Grad: 62.9007  LR: 0.000020  \n","Epoch: [1][21300/36908] Elapsed 74m 26s (remain 54m 32s) Loss: 0.0001(0.0101) Grad: 386.0656  LR: 0.000020  \n","Epoch: [1][21400/36908] Elapsed 74m 47s (remain 54m 11s) Loss: 0.0089(0.0101) Grad: 9393.9268  LR: 0.000020  \n","Epoch: [1][21500/36908] Elapsed 75m 8s (remain 53m 50s) Loss: 0.0320(0.0101) Grad: 26330.3203  LR: 0.000020  \n","Epoch: [1][21600/36908] Elapsed 75m 29s (remain 53m 29s) Loss: 0.0000(0.0100) Grad: 94.4895  LR: 0.000020  \n","Epoch: [1][21700/36908] Elapsed 75m 49s (remain 53m 8s) Loss: 0.0001(0.0100) Grad: 251.6564  LR: 0.000020  \n","Epoch: [1][21800/36908] Elapsed 76m 10s (remain 52m 47s) Loss: 0.0000(0.0100) Grad: 47.3879  LR: 0.000020  \n","Epoch: [1][21900/36908] Elapsed 76m 31s (remain 52m 26s) Loss: 0.0000(0.0100) Grad: 134.3898  LR: 0.000020  \n","Epoch: [1][22000/36908] Elapsed 76m 52s (remain 52m 5s) Loss: 0.0001(0.0099) Grad: 251.4615  LR: 0.000020  \n","Epoch: [1][22100/36908] Elapsed 77m 13s (remain 51m 44s) Loss: 0.0000(0.0099) Grad: 116.8803  LR: 0.000020  \n","Epoch: [1][22200/36908] Elapsed 77m 34s (remain 51m 23s) Loss: 0.0000(0.0099) Grad: 186.6471  LR: 0.000020  \n","Epoch: [1][22300/36908] Elapsed 77m 55s (remain 51m 2s) Loss: 0.0000(0.0099) Grad: 191.0955  LR: 0.000020  \n","Epoch: [1][22400/36908] Elapsed 78m 16s (remain 50m 41s) Loss: 0.0001(0.0099) Grad: 332.3216  LR: 0.000020  \n","Epoch: [1][22500/36908] Elapsed 78m 37s (remain 50m 20s) Loss: 0.0000(0.0098) Grad: 61.9871  LR: 0.000020  \n","Epoch: [1][22600/36908] Elapsed 78m 58s (remain 49m 59s) Loss: 0.0131(0.0098) Grad: 14799.4883  LR: 0.000020  \n","Epoch: [1][22700/36908] Elapsed 79m 19s (remain 49m 38s) Loss: 0.0000(0.0098) Grad: 87.1159  LR: 0.000019  \n","Epoch: [1][22800/36908] Elapsed 79m 40s (remain 49m 17s) Loss: 0.0000(0.0098) Grad: 87.4470  LR: 0.000019  \n","Epoch: [1][22900/36908] Elapsed 80m 1s (remain 48m 56s) Loss: 0.0000(0.0098) Grad: 178.4683  LR: 0.000019  \n","Epoch: [1][23000/36908] Elapsed 80m 22s (remain 48m 35s) Loss: 0.0043(0.0097) Grad: 6504.1475  LR: 0.000019  \n","Epoch: [1][23100/36908] Elapsed 80m 43s (remain 48m 14s) Loss: 0.0000(0.0097) Grad: 205.6472  LR: 0.000019  \n","Epoch: [1][23200/36908] Elapsed 81m 4s (remain 47m 54s) Loss: 0.0259(0.0097) Grad: 28548.1250  LR: 0.000019  \n","Epoch: [1][23300/36908] Elapsed 81m 25s (remain 47m 33s) Loss: 0.0000(0.0097) Grad: 66.4694  LR: 0.000019  \n","Epoch: [1][23400/36908] Elapsed 81m 46s (remain 47m 12s) Loss: 0.0000(0.0096) Grad: 80.5172  LR: 0.000019  \n","Epoch: [1][23500/36908] Elapsed 82m 7s (remain 46m 51s) Loss: 0.0001(0.0096) Grad: 409.3233  LR: 0.000019  \n","Epoch: [1][23600/36908] Elapsed 82m 28s (remain 46m 30s) Loss: 0.0000(0.0096) Grad: 150.6955  LR: 0.000019  \n","Epoch: [1][23700/36908] Elapsed 82m 49s (remain 46m 9s) Loss: 0.0000(0.0096) Grad: 66.7686  LR: 0.000019  \n","Epoch: [1][23800/36908] Elapsed 83m 10s (remain 45m 48s) Loss: 0.0000(0.0095) Grad: 174.5086  LR: 0.000019  \n","Epoch: [1][23900/36908] Elapsed 83m 31s (remain 45m 27s) Loss: 0.0115(0.0095) Grad: 10734.6211  LR: 0.000019  \n","Epoch: [1][24000/36908] Elapsed 83m 52s (remain 45m 6s) Loss: 0.0001(0.0095) Grad: 406.5627  LR: 0.000019  \n","Epoch: [1][24100/36908] Elapsed 84m 13s (remain 44m 45s) Loss: 0.0001(0.0095) Grad: 363.5691  LR: 0.000019  \n","Epoch: [1][24200/36908] Elapsed 84m 34s (remain 44m 24s) Loss: 0.0223(0.0094) Grad: 35784.4414  LR: 0.000019  \n","Epoch: [1][24300/36908] Elapsed 84m 55s (remain 44m 3s) Loss: 0.0000(0.0094) Grad: 139.2787  LR: 0.000019  \n","Epoch: [1][24400/36908] Elapsed 85m 16s (remain 43m 42s) Loss: 0.0000(0.0094) Grad: 88.0021  LR: 0.000019  \n","Epoch: [1][24500/36908] Elapsed 85m 37s (remain 43m 21s) Loss: 0.0000(0.0094) Grad: 77.7728  LR: 0.000019  \n","Epoch: [1][24600/36908] Elapsed 85m 58s (remain 43m 0s) Loss: 0.0288(0.0094) Grad: 61231.4180  LR: 0.000019  \n","Epoch: [1][24700/36908] Elapsed 86m 19s (remain 42m 39s) Loss: 0.0000(0.0094) Grad: 167.4603  LR: 0.000019  \n","Epoch: [1][24800/36908] Elapsed 86m 40s (remain 42m 18s) Loss: 0.0000(0.0093) Grad: 74.9169  LR: 0.000019  \n","Epoch: [1][24900/36908] Elapsed 87m 1s (remain 41m 57s) Loss: 0.0000(0.0093) Grad: 69.2370  LR: 0.000019  \n","Epoch: [1][25000/36908] Elapsed 87m 22s (remain 41m 36s) Loss: 0.0193(0.0093) Grad: 33582.8984  LR: 0.000019  \n","Epoch: [1][25100/36908] Elapsed 87m 43s (remain 41m 15s) Loss: 0.0000(0.0093) Grad: 98.5473  LR: 0.000019  \n","Epoch: [1][25200/36908] Elapsed 88m 4s (remain 40m 54s) Loss: 0.0000(0.0093) Grad: 215.1301  LR: 0.000019  \n","Epoch: [1][25300/36908] Elapsed 88m 25s (remain 40m 33s) Loss: 0.0000(0.0092) Grad: 226.8701  LR: 0.000019  \n","Epoch: [1][25400/36908] Elapsed 88m 46s (remain 40m 12s) Loss: 0.0297(0.0092) Grad: 46381.2578  LR: 0.000019  \n","Epoch: [1][25500/36908] Elapsed 89m 6s (remain 39m 51s) Loss: 0.0000(0.0092) Grad: 68.7145  LR: 0.000019  \n","Epoch: [1][25600/36908] Elapsed 89m 27s (remain 39m 30s) Loss: 0.0000(0.0092) Grad: 67.8972  LR: 0.000019  \n","Epoch: [1][25700/36908] Elapsed 89m 48s (remain 39m 9s) Loss: 0.0111(0.0092) Grad: 24522.8262  LR: 0.000019  \n","Epoch: [1][25800/36908] Elapsed 90m 9s (remain 38m 48s) Loss: 0.0000(0.0091) Grad: 129.8961  LR: 0.000019  \n","Epoch: [1][25900/36908] Elapsed 90m 30s (remain 38m 27s) Loss: 0.0000(0.0091) Grad: 106.0275  LR: 0.000019  \n","Epoch: [1][26000/36908] Elapsed 90m 51s (remain 38m 6s) Loss: 0.1135(0.0091) Grad: 275769.6250  LR: 0.000019  \n","Epoch: [1][26100/36908] Elapsed 91m 12s (remain 37m 45s) Loss: 0.0000(0.0091) Grad: 215.2953  LR: 0.000019  \n","Epoch: [1][26200/36908] Elapsed 91m 33s (remain 37m 24s) Loss: 0.0000(0.0091) Grad: 101.2475  LR: 0.000019  \n","Epoch: [1][26300/36908] Elapsed 91m 54s (remain 37m 3s) Loss: 0.0000(0.0091) Grad: 12.3974  LR: 0.000019  \n","Epoch: [1][26400/36908] Elapsed 92m 15s (remain 36m 42s) Loss: 0.0230(0.0091) Grad: 56581.9961  LR: 0.000019  \n","Epoch: [1][26500/36908] Elapsed 92m 36s (remain 36m 21s) Loss: 0.0000(0.0090) Grad: 114.6227  LR: 0.000019  \n","Epoch: [1][26600/36908] Elapsed 92m 57s (remain 36m 1s) Loss: 0.0000(0.0090) Grad: 50.4033  LR: 0.000019  \n","Epoch: [1][26700/36908] Elapsed 93m 18s (remain 35m 40s) Loss: 0.0001(0.0090) Grad: 453.5606  LR: 0.000019  \n","Epoch: [1][26800/36908] Elapsed 93m 39s (remain 35m 19s) Loss: 0.0000(0.0090) Grad: 584.4311  LR: 0.000019  \n","Epoch: [1][26900/36908] Elapsed 94m 0s (remain 34m 58s) Loss: 0.0001(0.0090) Grad: 621.1971  LR: 0.000019  \n","Epoch: [1][27000/36908] Elapsed 94m 21s (remain 34m 37s) Loss: 0.0000(0.0090) Grad: 178.0378  LR: 0.000019  \n","Epoch: [1][27100/36908] Elapsed 94m 42s (remain 34m 16s) Loss: 0.0000(0.0090) Grad: 640.8386  LR: 0.000019  \n","Epoch: [1][27200/36908] Elapsed 95m 3s (remain 33m 55s) Loss: 0.0000(0.0089) Grad: 33.1772  LR: 0.000019  \n","Epoch: [1][27300/36908] Elapsed 95m 24s (remain 33m 34s) Loss: 0.0297(0.0089) Grad: 36478.1445  LR: 0.000019  \n","Epoch: [1][27400/36908] Elapsed 95m 45s (remain 33m 13s) Loss: 0.0000(0.0089) Grad: 29.0617  LR: 0.000019  \n","Epoch: [1][27500/36908] Elapsed 96m 6s (remain 32m 52s) Loss: 0.0000(0.0089) Grad: 125.8660  LR: 0.000019  \n","Epoch: [1][27600/36908] Elapsed 96m 27s (remain 32m 31s) Loss: 0.0000(0.0089) Grad: 122.2494  LR: 0.000019  \n","Epoch: [1][27700/36908] Elapsed 96m 48s (remain 32m 10s) Loss: 0.0291(0.0089) Grad: 81748.6484  LR: 0.000019  \n","Epoch: [1][27800/36908] Elapsed 97m 9s (remain 31m 49s) Loss: 0.1210(0.0088) Grad: 212820.7969  LR: 0.000019  \n","Epoch: [1][27900/36908] Elapsed 97m 30s (remain 31m 28s) Loss: 0.0000(0.0088) Grad: 194.9221  LR: 0.000019  \n","Epoch: [1][28000/36908] Elapsed 97m 51s (remain 31m 7s) Loss: 0.0000(0.0088) Grad: 47.1825  LR: 0.000019  \n","Epoch: [1][28100/36908] Elapsed 98m 12s (remain 30m 46s) Loss: 0.0000(0.0088) Grad: 147.8347  LR: 0.000019  \n","Epoch: [1][28200/36908] Elapsed 98m 33s (remain 30m 25s) Loss: 0.0000(0.0088) Grad: 419.8997  LR: 0.000019  \n","Epoch: [1][28300/36908] Elapsed 98m 55s (remain 30m 4s) Loss: 0.0000(0.0088) Grad: 257.9387  LR: 0.000019  \n","Epoch: [1][28400/36908] Elapsed 99m 16s (remain 29m 44s) Loss: 0.0625(0.0087) Grad: 203715.0000  LR: 0.000019  \n","Epoch: [1][28500/36908] Elapsed 99m 37s (remain 29m 23s) Loss: 0.0177(0.0087) Grad: 68058.7422  LR: 0.000019  \n","Epoch: [1][28600/36908] Elapsed 99m 58s (remain 29m 2s) Loss: 0.0382(0.0087) Grad: 141760.2969  LR: 0.000019  \n","Epoch: [1][28700/36908] Elapsed 100m 19s (remain 28m 41s) Loss: 0.0000(0.0087) Grad: 264.6454  LR: 0.000019  \n","Epoch: [1][28800/36908] Elapsed 100m 40s (remain 28m 20s) Loss: 0.0000(0.0087) Grad: 275.1287  LR: 0.000019  \n","Epoch: [1][28900/36908] Elapsed 101m 1s (remain 27m 59s) Loss: 0.0000(0.0087) Grad: 43.8425  LR: 0.000019  \n","Epoch: [1][29000/36908] Elapsed 101m 22s (remain 27m 38s) Loss: 0.0000(0.0087) Grad: 416.8006  LR: 0.000019  \n","Epoch: [1][29100/36908] Elapsed 101m 43s (remain 27m 17s) Loss: 0.0000(0.0087) Grad: 141.5339  LR: 0.000019  \n","Epoch: [1][29200/36908] Elapsed 102m 4s (remain 26m 56s) Loss: 0.0000(0.0086) Grad: 41.7054  LR: 0.000019  \n","Epoch: [1][29300/36908] Elapsed 102m 25s (remain 26m 35s) Loss: 0.0000(0.0086) Grad: 156.4585  LR: 0.000019  \n","Epoch: [1][29400/36908] Elapsed 102m 46s (remain 26m 14s) Loss: 0.0000(0.0086) Grad: 341.1342  LR: 0.000019  \n","Epoch: [1][29500/36908] Elapsed 103m 7s (remain 25m 53s) Loss: 0.0000(0.0086) Grad: 115.0855  LR: 0.000019  \n","Epoch: [1][29600/36908] Elapsed 103m 28s (remain 25m 32s) Loss: 0.0000(0.0086) Grad: 326.6002  LR: 0.000019  \n","Epoch: [1][29700/36908] Elapsed 103m 49s (remain 25m 11s) Loss: 0.0000(0.0086) Grad: 169.7446  LR: 0.000019  \n","Epoch: [1][29800/36908] Elapsed 104m 10s (remain 24m 50s) Loss: 0.0000(0.0086) Grad: 64.5333  LR: 0.000019  \n","Epoch: [1][29900/36908] Elapsed 104m 31s (remain 24m 29s) Loss: 0.0000(0.0086) Grad: 229.1924  LR: 0.000019  \n","Epoch: [1][30000/36908] Elapsed 104m 52s (remain 24m 8s) Loss: 0.0000(0.0085) Grad: 229.8833  LR: 0.000019  \n","Epoch: [1][30100/36908] Elapsed 105m 13s (remain 23m 47s) Loss: 0.0000(0.0085) Grad: 127.2145  LR: 0.000019  \n","Epoch: [1][30200/36908] Elapsed 105m 34s (remain 23m 26s) Loss: 0.0000(0.0085) Grad: 111.6874  LR: 0.000019  \n","Epoch: [1][30300/36908] Elapsed 105m 55s (remain 23m 5s) Loss: 0.0000(0.0085) Grad: 66.1552  LR: 0.000019  \n","Epoch: [1][30400/36908] Elapsed 106m 16s (remain 22m 44s) Loss: 0.0085(0.0085) Grad: 28745.4434  LR: 0.000019  \n","Epoch: [1][30500/36908] Elapsed 106m 37s (remain 22m 23s) Loss: 0.0000(0.0085) Grad: 189.7457  LR: 0.000019  \n","Epoch: [1][30600/36908] Elapsed 106m 57s (remain 22m 2s) Loss: 0.0000(0.0085) Grad: 24.9726  LR: 0.000019  \n","Epoch: [1][30700/36908] Elapsed 107m 18s (remain 21m 41s) Loss: 0.0000(0.0085) Grad: 309.2901  LR: 0.000019  \n","Epoch: [1][30800/36908] Elapsed 107m 39s (remain 21m 20s) Loss: 0.0000(0.0085) Grad: 247.5661  LR: 0.000019  \n","Epoch: [1][30900/36908] Elapsed 108m 0s (remain 20m 59s) Loss: 0.0000(0.0084) Grad: 320.6779  LR: 0.000019  \n","Epoch: [1][31000/36908] Elapsed 108m 20s (remain 20m 38s) Loss: 0.0000(0.0084) Grad: 265.6726  LR: 0.000018  \n","Epoch: [1][31100/36908] Elapsed 108m 41s (remain 20m 17s) Loss: 0.0000(0.0084) Grad: 397.8977  LR: 0.000018  \n","Epoch: [1][31200/36908] Elapsed 109m 2s (remain 19m 56s) Loss: 0.0000(0.0084) Grad: 147.2133  LR: 0.000018  \n","Epoch: [1][31300/36908] Elapsed 109m 22s (remain 19m 35s) Loss: 0.0000(0.0084) Grad: 150.2261  LR: 0.000018  \n","Epoch: [1][31400/36908] Elapsed 109m 43s (remain 19m 14s) Loss: 0.0000(0.0084) Grad: 194.9477  LR: 0.000018  \n","Epoch: [1][31500/36908] Elapsed 110m 4s (remain 18m 53s) Loss: 0.0000(0.0084) Grad: 233.9850  LR: 0.000018  \n","Epoch: [1][31600/36908] Elapsed 110m 25s (remain 18m 32s) Loss: 0.0000(0.0084) Grad: 354.0576  LR: 0.000018  \n","Epoch: [1][31700/36908] Elapsed 110m 45s (remain 18m 11s) Loss: 0.0073(0.0084) Grad: 28139.8203  LR: 0.000018  \n","Epoch: [1][31800/36908] Elapsed 111m 6s (remain 17m 50s) Loss: 0.0000(0.0084) Grad: 102.2452  LR: 0.000018  \n","Epoch: [1][31900/36908] Elapsed 111m 27s (remain 17m 29s) Loss: 0.0000(0.0084) Grad: 217.7163  LR: 0.000018  \n","Epoch: [1][32000/36908] Elapsed 111m 47s (remain 17m 8s) Loss: 0.0000(0.0083) Grad: 1024.7241  LR: 0.000018  \n","Epoch: [1][32100/36908] Elapsed 112m 8s (remain 16m 47s) Loss: 0.0000(0.0083) Grad: 129.6967  LR: 0.000018  \n","Epoch: [1][32200/36908] Elapsed 112m 29s (remain 16m 26s) Loss: 0.0000(0.0083) Grad: 212.7893  LR: 0.000018  \n","Epoch: [1][32300/36908] Elapsed 112m 50s (remain 16m 5s) Loss: 0.0000(0.0083) Grad: 180.6594  LR: 0.000018  \n","Epoch: [1][32400/36908] Elapsed 113m 10s (remain 15m 44s) Loss: 0.0035(0.0083) Grad: 19391.2520  LR: 0.000018  \n","Epoch: [1][32500/36908] Elapsed 113m 31s (remain 15m 23s) Loss: 0.0000(0.0083) Grad: 141.0581  LR: 0.000018  \n","Epoch: [1][32600/36908] Elapsed 113m 52s (remain 15m 2s) Loss: 0.0000(0.0083) Grad: 52.1543  LR: 0.000018  \n","Epoch: [1][32700/36908] Elapsed 114m 13s (remain 14m 41s) Loss: 0.0000(0.0083) Grad: 73.5985  LR: 0.000018  \n","Epoch: [1][32800/36908] Elapsed 114m 33s (remain 14m 20s) Loss: 0.0000(0.0083) Grad: 82.2617  LR: 0.000018  \n","Epoch: [1][32900/36908] Elapsed 114m 54s (remain 13m 59s) Loss: 0.0000(0.0082) Grad: 35.0412  LR: 0.000018  \n","Epoch: [1][33000/36908] Elapsed 115m 15s (remain 13m 38s) Loss: 0.0000(0.0082) Grad: 157.2646  LR: 0.000018  \n","Epoch: [1][33100/36908] Elapsed 115m 36s (remain 13m 17s) Loss: 0.0000(0.0082) Grad: 1170.4579  LR: 0.000018  \n","Epoch: [1][33200/36908] Elapsed 115m 56s (remain 12m 56s) Loss: 0.0000(0.0082) Grad: 204.5130  LR: 0.000018  \n","Epoch: [1][33300/36908] Elapsed 116m 17s (remain 12m 35s) Loss: 0.0674(0.0082) Grad: 181773.6094  LR: 0.000018  \n","Epoch: [1][33400/36908] Elapsed 116m 38s (remain 12m 14s) Loss: 0.0116(0.0082) Grad: 43184.0938  LR: 0.000018  \n","Epoch: [1][33500/36908] Elapsed 116m 59s (remain 11m 53s) Loss: 0.0000(0.0082) Grad: 94.6730  LR: 0.000018  \n","Epoch: [1][33600/36908] Elapsed 117m 20s (remain 11m 32s) Loss: 0.0000(0.0082) Grad: 60.5585  LR: 0.000018  \n","Epoch: [1][33700/36908] Elapsed 117m 40s (remain 11m 11s) Loss: 0.0000(0.0082) Grad: 131.3687  LR: 0.000018  \n","Epoch: [1][33800/36908] Elapsed 118m 1s (remain 10m 50s) Loss: 0.0240(0.0082) Grad: 82673.6484  LR: 0.000018  \n","Epoch: [1][33900/36908] Elapsed 118m 22s (remain 10m 29s) Loss: 0.0000(0.0082) Grad: 227.7604  LR: 0.000018  \n","Epoch: [1][34000/36908] Elapsed 118m 43s (remain 10m 9s) Loss: 0.0000(0.0082) Grad: 130.4728  LR: 0.000018  \n","Epoch: [1][34100/36908] Elapsed 119m 3s (remain 9m 48s) Loss: 0.0000(0.0082) Grad: 108.1232  LR: 0.000018  \n","Epoch: [1][34200/36908] Elapsed 119m 24s (remain 9m 27s) Loss: 0.0000(0.0082) Grad: 248.8190  LR: 0.000018  \n","Epoch: [1][34300/36908] Elapsed 119m 45s (remain 9m 6s) Loss: 0.0086(0.0082) Grad: 31957.2656  LR: 0.000018  \n","Epoch: [1][34400/36908] Elapsed 120m 5s (remain 8m 45s) Loss: 0.0000(0.0081) Grad: 45.3953  LR: 0.000018  \n","Epoch: [1][34500/36908] Elapsed 120m 26s (remain 8m 24s) Loss: 0.0000(0.0081) Grad: 94.8442  LR: 0.000018  \n","Epoch: [1][34600/36908] Elapsed 120m 47s (remain 8m 3s) Loss: 0.0223(0.0081) Grad: 87718.3359  LR: 0.000018  \n","Epoch: [1][34700/36908] Elapsed 121m 7s (remain 7m 42s) Loss: 0.0000(0.0081) Grad: 138.3308  LR: 0.000018  \n","Epoch: [1][34800/36908] Elapsed 121m 28s (remain 7m 21s) Loss: 0.0000(0.0081) Grad: 118.7579  LR: 0.000018  \n","Epoch: [1][34900/36908] Elapsed 121m 49s (remain 7m 0s) Loss: 0.0000(0.0081) Grad: 144.4227  LR: 0.000018  \n","Epoch: [1][35000/36908] Elapsed 122m 10s (remain 6m 39s) Loss: 0.0000(0.0081) Grad: 39.9345  LR: 0.000018  \n","Epoch: [1][35100/36908] Elapsed 122m 30s (remain 6m 18s) Loss: 0.0280(0.0081) Grad: 90858.1953  LR: 0.000018  \n","Epoch: [1][35200/36908] Elapsed 122m 51s (remain 5m 57s) Loss: 0.0000(0.0080) Grad: 292.4850  LR: 0.000018  \n","Epoch: [1][35300/36908] Elapsed 123m 12s (remain 5m 36s) Loss: 0.0166(0.0080) Grad: 61387.1445  LR: 0.000018  \n","Epoch: [1][35400/36908] Elapsed 123m 33s (remain 5m 15s) Loss: 0.0000(0.0080) Grad: 51.5666  LR: 0.000018  \n","Epoch: [1][35500/36908] Elapsed 123m 53s (remain 4m 54s) Loss: 0.0000(0.0080) Grad: 129.0545  LR: 0.000018  \n","Epoch: [1][35600/36908] Elapsed 124m 14s (remain 4m 33s) Loss: 0.0000(0.0080) Grad: 98.1602  LR: 0.000018  \n","Epoch: [1][35700/36908] Elapsed 124m 35s (remain 4m 12s) Loss: 0.0000(0.0080) Grad: 213.6481  LR: 0.000018  \n","Epoch: [1][35800/36908] Elapsed 124m 56s (remain 3m 51s) Loss: 0.0000(0.0080) Grad: 211.4393  LR: 0.000018  \n","Epoch: [1][35900/36908] Elapsed 125m 17s (remain 3m 30s) Loss: 0.0000(0.0080) Grad: 205.5386  LR: 0.000018  \n","Epoch: [1][36000/36908] Elapsed 125m 37s (remain 3m 9s) Loss: 0.0000(0.0080) Grad: 185.8689  LR: 0.000018  \n","Epoch: [1][36100/36908] Elapsed 125m 58s (remain 2m 48s) Loss: 0.0000(0.0080) Grad: 108.1525  LR: 0.000018  \n","Epoch: [1][36200/36908] Elapsed 126m 19s (remain 2m 28s) Loss: 0.0000(0.0080) Grad: 61.4051  LR: 0.000018  \n","Epoch: [1][36300/36908] Elapsed 126m 40s (remain 2m 7s) Loss: 0.0000(0.0080) Grad: 155.0203  LR: 0.000018  \n","Epoch: [1][36400/36908] Elapsed 127m 1s (remain 1m 46s) Loss: 0.0000(0.0079) Grad: 266.8809  LR: 0.000018  \n","Epoch: [1][36500/36908] Elapsed 127m 22s (remain 1m 25s) Loss: 0.0000(0.0079) Grad: 144.9056  LR: 0.000018  \n","Epoch: [1][36600/36908] Elapsed 127m 43s (remain 1m 4s) Loss: 0.0000(0.0079) Grad: 165.5404  LR: 0.000018  \n","Epoch: [1][36700/36908] Elapsed 128m 3s (remain 0m 43s) Loss: 0.0000(0.0079) Grad: 133.5674  LR: 0.000018  \n","Epoch: [1][36800/36908] Elapsed 128m 24s (remain 0m 22s) Loss: 0.0000(0.0079) Grad: 706.2270  LR: 0.000018  \n","Epoch: [1][36900/36908] Elapsed 128m 45s (remain 0m 1s) Loss: 0.0000(0.0079) Grad: 149.0164  LR: 0.000018  \n","Epoch: [1][36907/36908] Elapsed 128m 46s (remain 0m 0s) Loss: 0.0301(0.0079) Grad: 277317.7812  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 6m 13s) Loss: 0.0689(0.0689) \n","EVAL: [100/1192] Elapsed 0m 5s (remain 0m 59s) Loss: 0.0929(0.0528) \n","EVAL: [200/1192] Elapsed 0m 10s (remain 0m 52s) Loss: 0.0580(0.0483) \n","EVAL: [300/1192] Elapsed 0m 15s (remain 0m 46s) Loss: 0.0264(0.0497) \n","EVAL: [400/1192] Elapsed 0m 20s (remain 0m 41s) Loss: 0.0341(0.0510) \n","EVAL: [500/1192] Elapsed 0m 26s (remain 0m 36s) Loss: 0.1472(0.0537) \n","EVAL: [600/1192] Elapsed 0m 31s (remain 0m 30s) Loss: 0.0697(0.0572) \n","EVAL: [700/1192] Elapsed 0m 36s (remain 0m 25s) Loss: 0.0843(0.0599) \n","EVAL: [800/1192] Elapsed 0m 41s (remain 0m 20s) Loss: 0.0589(0.0587) \n","EVAL: [900/1192] Elapsed 0m 47s (remain 0m 15s) Loss: 0.0730(0.0596) \n","EVAL: [1000/1192] Elapsed 0m 52s (remain 0m 9s) Loss: 0.0159(0.0585) \n","EVAL: [1100/1192] Elapsed 0m 57s (remain 0m 4s) Loss: 0.0259(0.0573) \n","EVAL: [1191/1192] Elapsed 1m 2s (remain 0m 0s) Loss: 0.0554(0.0564) \n","Epoch 1 - avg_train_loss: 0.0079  avg_val_loss: 0.0564  time: 7794s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","Best thres: 0.5, Score: 0.0000\n","Best thres: 0.5, Score: 0.0000\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e431d5dc3af74962ad253b9504b27d79"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e50974b1fd624020aa44630c08bc0917"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"797a8d464b1045b4a79eb77882772602"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"914e794d90fc44f8a8fd9d7f53907f5c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c52a94a7d81d48f49cfa41449fdee377"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp071.ipynb","provenance":[{"file_id":"10yG4L3_nzpdL2CDwqxa9r-KWq6jYkWfl","timestamp":1648963721684}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9fb7f6cc6c7f49299255aab12b7a4446":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38765acbf3e645c9a6fbd735b14ed45d","IPY_MODEL_eb88ab3ce3094c369269c38ef96ba2c0","IPY_MODEL_191feabbe7eb478e82e166ba19fe2c24"],"layout":"IPY_MODEL_9c5784d4767143d093bb24d778309e35"}},"38765acbf3e645c9a6fbd735b14ed45d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9df610d483504972a05ce85213898f1b","placeholder":"​","style":"IPY_MODEL_2e1236bfb05040218ca07b9f1c1b9cec","value":"Downloading: 100%"}},"eb88ab3ce3094c369269c38ef96ba2c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bb882ffb50a43f99f923c2099e0c581","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94a97d42f8f4474b826f29bf29858276","value":52}},"191feabbe7eb478e82e166ba19fe2c24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d7aa6ec98334920aade6a9ac5514ef2","placeholder":"​","style":"IPY_MODEL_dc4a5300f2744199a132fe59d0fd0040","value":" 52.0/52.0 [00:00&lt;00:00, 2.09kB/s]"}},"9c5784d4767143d093bb24d778309e35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9df610d483504972a05ce85213898f1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e1236bfb05040218ca07b9f1c1b9cec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bb882ffb50a43f99f923c2099e0c581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94a97d42f8f4474b826f29bf29858276":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d7aa6ec98334920aade6a9ac5514ef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc4a5300f2744199a132fe59d0fd0040":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9c9fcbac7e544499aaf30c579ccc9e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29becb9692464f6e9da0819107d97312","IPY_MODEL_dffbdf6285ae44259d740d271f2f2230","IPY_MODEL_6e08326d01c44ce9854d9caf54420b40"],"layout":"IPY_MODEL_f32e7ab085c64a25a20e40ec271aa0de"}},"29becb9692464f6e9da0819107d97312":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbea311999444ff991cf827a737045c4","placeholder":"​","style":"IPY_MODEL_6fadcc2535234dc79602b4ff3a239696","value":"Downloading: 100%"}},"dffbdf6285ae44259d740d271f2f2230":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aaa81b3fead463282cae340a1b8b120","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_abf5467703a34442bb4dc9cae1bc5cfe","value":475}},"6e08326d01c44ce9854d9caf54420b40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7bc9fbb51a747f5926f54cdc332eed1","placeholder":"​","style":"IPY_MODEL_e5fba81603a24d339cf764c05971759d","value":" 475/475 [00:00&lt;00:00, 17.9kB/s]"}},"f32e7ab085c64a25a20e40ec271aa0de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbea311999444ff991cf827a737045c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fadcc2535234dc79602b4ff3a239696":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8aaa81b3fead463282cae340a1b8b120":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abf5467703a34442bb4dc9cae1bc5cfe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7bc9fbb51a747f5926f54cdc332eed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5fba81603a24d339cf764c05971759d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ad6c995e3b3478da93be5213e5604cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a37b7a37eda34cbbab753394f67683b5","IPY_MODEL_b82e4f34d5304ed1bef2278383160945","IPY_MODEL_0106fbf194ac4b90868c07c03eeebe83"],"layout":"IPY_MODEL_9ba7ec6669bf42228a4fecdc57b26327"}},"a37b7a37eda34cbbab753394f67683b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b5010681d7f4985b3e2a524c0c0fb60","placeholder":"​","style":"IPY_MODEL_d0dc082a7ae144a8879641b91ffff6f5","value":"Downloading: 100%"}},"b82e4f34d5304ed1bef2278383160945":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7976cea67b0a4fbabc60edcdfa29e0fc","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57905f1975e2425b80b040dbc3256e02","value":898825}},"0106fbf194ac4b90868c07c03eeebe83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b03a196ad68421098e7c3a5eb57abd9","placeholder":"​","style":"IPY_MODEL_54825ae8089f4e129e59eb03a3aa03fe","value":" 878k/878k [00:00&lt;00:00, 6.85MB/s]"}},"9ba7ec6669bf42228a4fecdc57b26327":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b5010681d7f4985b3e2a524c0c0fb60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0dc082a7ae144a8879641b91ffff6f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7976cea67b0a4fbabc60edcdfa29e0fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57905f1975e2425b80b040dbc3256e02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b03a196ad68421098e7c3a5eb57abd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54825ae8089f4e129e59eb03a3aa03fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"812befa2af344c5cb9bace3b72043e41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b304cfc9adb54df58c3f8ec711ff24b6","IPY_MODEL_4bcd248afdf64b338863f5340a96f189","IPY_MODEL_0f703b0c433543f3a889f2d4f295602e"],"layout":"IPY_MODEL_6fe978ac136740148401ceecd7701baa"}},"b304cfc9adb54df58c3f8ec711ff24b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_937ef855282d4323bfb8c0e515243f6e","placeholder":"​","style":"IPY_MODEL_5d75b713791d4b79b96918d0fb92f062","value":"Downloading: 100%"}},"4bcd248afdf64b338863f5340a96f189":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b496d1cb368140e2a89b74552983631b","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80f7b8f9ce7e4931a978da7e2cbcc9de","value":456318}},"0f703b0c433543f3a889f2d4f295602e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc6625c85ecd4110a1b2ecf621c473c1","placeholder":"​","style":"IPY_MODEL_f060b75d46ff448f8a504a64d2bf8278","value":" 446k/446k [00:00&lt;00:00, 4.81MB/s]"}},"6fe978ac136740148401ceecd7701baa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"937ef855282d4323bfb8c0e515243f6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d75b713791d4b79b96918d0fb92f062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b496d1cb368140e2a89b74552983631b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80f7b8f9ce7e4931a978da7e2cbcc9de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc6625c85ecd4110a1b2ecf621c473c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f060b75d46ff448f8a504a64d2bf8278":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f06e1e3490d44e59803c4564f4af278b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca57952ce30b465ca0be1c593f381213","IPY_MODEL_d1a5a386a3e4412b91513277013ef85a","IPY_MODEL_de2ab99046aa4d9f88374de9f3dbc58c"],"layout":"IPY_MODEL_9e1b9cce113548f7996bebbd746cdacc"}},"ca57952ce30b465ca0be1c593f381213":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c1a180a1ff14e3fa2a9dbd87e462075","placeholder":"​","style":"IPY_MODEL_9ac223816b984e1c838e9f49988bc7cc","value":"100%"}},"d1a5a386a3e4412b91513277013ef85a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c253c03d7b3c4615815cc68596c0e3fa","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4e787a7dcd24aa395bcbb90b62ee59b","value":42146}},"de2ab99046aa4d9f88374de9f3dbc58c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4dad4e487e14f9ab77dbdc5e66b62a5","placeholder":"​","style":"IPY_MODEL_938f51f9ee3d45bca42fdabd83d6e219","value":" 42146/42146 [00:21&lt;00:00, 2019.44it/s]"}},"9e1b9cce113548f7996bebbd746cdacc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1a180a1ff14e3fa2a9dbd87e462075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ac223816b984e1c838e9f49988bc7cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c253c03d7b3c4615815cc68596c0e3fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4e787a7dcd24aa395bcbb90b62ee59b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4dad4e487e14f9ab77dbdc5e66b62a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"938f51f9ee3d45bca42fdabd83d6e219":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ca9ebd113134606bfac51f032cf543d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acfba18ac9c54b67815b46edd3227851","IPY_MODEL_27cfc00781224f0784f59f030be9f2f4","IPY_MODEL_886305916d4d4c86ac60d29d41cb453d"],"layout":"IPY_MODEL_244fe41544cc435b82e7928b54d8ca69"}},"acfba18ac9c54b67815b46edd3227851":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_234b7e741d674ccf90e695537820244f","placeholder":"​","style":"IPY_MODEL_d2e5b3bd3fb6466d9cc30e4b32a8b6fa","value":"100%"}},"27cfc00781224f0784f59f030be9f2f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71521173672a4c6fa844875d22f732b7","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c367a1ceb6c434b8ae515be09aca78d","value":143}},"886305916d4d4c86ac60d29d41cb453d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f270441732a94c788275442843caad44","placeholder":"​","style":"IPY_MODEL_4c482939850741dc842ea5a40182cfb2","value":" 143/143 [00:00&lt;00:00, 3333.72it/s]"}},"244fe41544cc435b82e7928b54d8ca69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234b7e741d674ccf90e695537820244f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2e5b3bd3fb6466d9cc30e4b32a8b6fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71521173672a4c6fa844875d22f732b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c367a1ceb6c434b8ae515be09aca78d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f270441732a94c788275442843caad44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c482939850741dc842ea5a40182cfb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e431d5dc3af74962ad253b9504b27d79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db6f0f5f0e5a4dbe92ff94da5cd71834","IPY_MODEL_2ed70549609141c7bd014bc8ff7c3e1d","IPY_MODEL_eb17d941942f47bf9b6f577a20634f28"],"layout":"IPY_MODEL_47ef2cea3cef43d1b2bdf2b1bcd29466"}},"db6f0f5f0e5a4dbe92ff94da5cd71834":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_693495099db44129a3d6e7236eed43e1","placeholder":"​","style":"IPY_MODEL_498181a642224613b3537abae822a7f4","value":"Downloading: 100%"}},"2ed70549609141c7bd014bc8ff7c3e1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f6929bad7b64f8d8a1bca5b6081996e","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a7802b5d9af4e3792d33cd9031f5208","value":1627284589}},"eb17d941942f47bf9b6f577a20634f28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e993a06592e4e11bb2e1eb72bd0346e","placeholder":"​","style":"IPY_MODEL_d1f56e7a77d843d0a7bc3497f8449e5a","value":" 1.52G/1.52G [00:28&lt;00:00, 60.4MB/s]"}},"47ef2cea3cef43d1b2bdf2b1bcd29466":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"693495099db44129a3d6e7236eed43e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"498181a642224613b3537abae822a7f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f6929bad7b64f8d8a1bca5b6081996e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a7802b5d9af4e3792d33cd9031f5208":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e993a06592e4e11bb2e1eb72bd0346e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1f56e7a77d843d0a7bc3497f8449e5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e50974b1fd624020aa44630c08bc0917":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c34c0205a62a4601a49cbbffaa0057e4","IPY_MODEL_2dfa6cf6daf9496cae81ef38a277b6da","IPY_MODEL_dd0d234eef39400fb3ecb25312d0a699"],"layout":"IPY_MODEL_c76b744a848c470ba621bf85b8ea47c1"}},"c34c0205a62a4601a49cbbffaa0057e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6af218a889b642249e2f1bdc88fe71ec","placeholder":"​","style":"IPY_MODEL_61f5e52fe74b4140b73c0c1c415cc04a","value":"100%"}},"2dfa6cf6daf9496cae81ef38a277b6da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b01f6faf0ec54d508a001d5cd799490e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb59759353e94240a7ae2596c62108d8","value":2}},"dd0d234eef39400fb3ecb25312d0a699":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1b0a1a18b15449e9f615dda59ffe10b","placeholder":"​","style":"IPY_MODEL_c76fa15aacaf4bb7b0ba65de85197e30","value":" 2/2 [00:00&lt;00:00,  1.68it/s]"}},"c76b744a848c470ba621bf85b8ea47c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af218a889b642249e2f1bdc88fe71ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61f5e52fe74b4140b73c0c1c415cc04a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b01f6faf0ec54d508a001d5cd799490e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb59759353e94240a7ae2596c62108d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1b0a1a18b15449e9f615dda59ffe10b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c76fa15aacaf4bb7b0ba65de85197e30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"797a8d464b1045b4a79eb77882772602":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5bfe8e3929a419a85d7cead29b50e29","IPY_MODEL_eae738f025ca434ea2d065f3039c6991","IPY_MODEL_16c12f61f69c4b61af7f1f23d2c175ad"],"layout":"IPY_MODEL_7ed479d21fa24c6ca62df63c36f6dab4"}},"b5bfe8e3929a419a85d7cead29b50e29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3524e58f2aa2490392e038d0c3b19dd4","placeholder":"​","style":"IPY_MODEL_90ce5841a6c247c2926b85afed6ec4c5","value":"100%"}},"eae738f025ca434ea2d065f3039c6991":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14c095d88da1446eb50eaebe8ff5b0bd","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f867686e60ec414585f3f74528497769","value":2}},"16c12f61f69c4b61af7f1f23d2c175ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a5c79c3d4ae4aa1b239e4e29fdaa55a","placeholder":"​","style":"IPY_MODEL_15c91f65b7ad40469a42b40b28d9220a","value":" 2/2 [00:00&lt;00:00,  1.43it/s]"}},"7ed479d21fa24c6ca62df63c36f6dab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3524e58f2aa2490392e038d0c3b19dd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90ce5841a6c247c2926b85afed6ec4c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14c095d88da1446eb50eaebe8ff5b0bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f867686e60ec414585f3f74528497769":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a5c79c3d4ae4aa1b239e4e29fdaa55a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15c91f65b7ad40469a42b40b28d9220a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"914e794d90fc44f8a8fd9d7f53907f5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85232a0dd30440e3a02c20dae4b3e109","IPY_MODEL_c2ab9e9f1bf548349bd5fd1935d12a65","IPY_MODEL_33582456a96a4d11808c00e9c1f02b42"],"layout":"IPY_MODEL_714f7875dfdc4ca2bbd29e417a613fe3"}},"85232a0dd30440e3a02c20dae4b3e109":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac5f79056f0f474b97485f41302313ba","placeholder":"​","style":"IPY_MODEL_d8439090e62242b9af305cbae322e924","value":"100%"}},"c2ab9e9f1bf548349bd5fd1935d12a65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_791c9e174a14474ab355c027fb9d0a6e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c20812946f34db39c5c9f8ce557c2c9","value":2}},"33582456a96a4d11808c00e9c1f02b42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97db6ef2bfdc4e1cbd255bfcb71bc3f6","placeholder":"​","style":"IPY_MODEL_f926b0eb4f52486eb08523e79dd44a1d","value":" 2/2 [00:00&lt;00:00,  1.28it/s]"}},"714f7875dfdc4ca2bbd29e417a613fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac5f79056f0f474b97485f41302313ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8439090e62242b9af305cbae322e924":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"791c9e174a14474ab355c027fb9d0a6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c20812946f34db39c5c9f8ce557c2c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97db6ef2bfdc4e1cbd255bfcb71bc3f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f926b0eb4f52486eb08523e79dd44a1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c52a94a7d81d48f49cfa41449fdee377":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3617fd05c6bf493680d1471911a2b4e3","IPY_MODEL_e1c576aa7a30453cbc345a4090ba2306","IPY_MODEL_0e4bfc44810445328ddb62023013c3b5"],"layout":"IPY_MODEL_4170592f14814e549d2cd4db7e0689b8"}},"3617fd05c6bf493680d1471911a2b4e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4bfc64588134d699ff2106291d78cb2","placeholder":"​","style":"IPY_MODEL_eb324daf042e4b44a6406be4e2256396","value":"100%"}},"e1c576aa7a30453cbc345a4090ba2306":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae248e58ab3840d69e7a0ba9ac9fdaf1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cf2c57874f04a809c99e31c9211fc3d","value":2}},"0e4bfc44810445328ddb62023013c3b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c8452b7fa584809b4524edce44d049f","placeholder":"​","style":"IPY_MODEL_2eaa7c2b4cc34566b69b1d2ae1499a3d","value":" 2/2 [00:01&lt;00:00,  1.12it/s]"}},"4170592f14814e549d2cd4db7e0689b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4bfc64588134d699ff2106291d78cb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb324daf042e4b44a6406be4e2256396":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae248e58ab3840d69e7a0ba9ac9fdaf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cf2c57874f04a809c99e31c9211fc3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c8452b7fa584809b4524edce44d049f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eaa7c2b4cc34566b69b1d2ae1499a3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}