{"cells":[{"cell_type":"markdown","metadata":{"id":"aa1f8e80"},"source":["## References"],"id":"aa1f8e80"},{"cell_type":"markdown","metadata":{"id":"c0138fac"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"],"id":"c0138fac"},{"cell_type":"markdown","metadata":{"id":"cf1dfda9"},"source":["## Configurations"],"id":"cf1dfda9"},{"cell_type":"code","execution_count":1,"metadata":{"id":"a7a78d25","executionInfo":{"status":"ok","timestamp":1646221288266,"user_tz":-540,"elapsed":2,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp012\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"],"id":"a7a78d25"},{"cell_type":"code","execution_count":2,"metadata":{"id":"4ecc4e4d","executionInfo":{"status":"ok","timestamp":1646221288266,"user_tz":-540,"elapsed":2,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-base\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=8\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=5\n","    train_fold=[0, 1, 2, 3, 4]\n","    seed=71\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"],"id":"4ecc4e4d"},{"cell_type":"code","execution_count":3,"metadata":{"id":"3894c88b","executionInfo":{"status":"ok","timestamp":1646221288516,"user_tz":-540,"elapsed":252,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"],"id":"3894c88b"},{"cell_type":"markdown","metadata":{"id":"31768c85"},"source":["## Directory Settings"],"id":"31768c85"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4851,"status":"ok","timestamp":1646221293362,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"00e7d967","outputId":"e90ba863-7d92-4253-8706-5f950a55493f"},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"],"id":"00e7d967"},{"cell_type":"code","execution_count":5,"metadata":{"id":"d726b7d9","executionInfo":{"status":"ok","timestamp":1646221296652,"user_tz":-540,"elapsed":3298,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"id":"d726b7d9"},{"cell_type":"markdown","metadata":{"id":"b6d82f71"},"source":["## Utilities"],"id":"b6d82f71"},{"cell_type":"code","execution_count":6,"metadata":{"id":"95abbe2c","executionInfo":{"status":"ok","timestamp":1646221296652,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"],"id":"95abbe2c"},{"cell_type":"code","execution_count":7,"metadata":{"id":"832ee36d","executionInfo":{"status":"ok","timestamp":1646221297020,"user_tz":-540,"elapsed":372,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"],"id":"832ee36d"},{"cell_type":"code","execution_count":8,"metadata":{"id":"918828a7","executionInfo":{"status":"ok","timestamp":1646221297020,"user_tz":-540,"elapsed":2,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"id":"918828a7"},{"cell_type":"code","execution_count":9,"metadata":{"id":"d02a78e1","executionInfo":{"status":"ok","timestamp":1646221297021,"user_tz":-540,"elapsed":3,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"],"id":"d02a78e1"},{"cell_type":"markdown","metadata":{"id":"47266f39"},"source":["## Data Loading"],"id":"47266f39"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1646221297317,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"20fed6da","outputId":"c450d0b4-39c7-4d2d-84eb-c55f2caa1ee3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"],"id":"20fed6da"},{"cell_type":"code","execution_count":11,"metadata":{"id":"e67d0132","executionInfo":{"status":"ok","timestamp":1646221297318,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"],"id":"e67d0132"},{"cell_type":"markdown","metadata":{"id":"47bca11a"},"source":["## Preprocessing"],"id":"47bca11a"},{"cell_type":"code","execution_count":12,"metadata":{"id":"d9c8e9ba","executionInfo":{"status":"ok","timestamp":1646221297318,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"],"id":"d9c8e9ba"},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646221297319,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"7ef41e18","outputId":"e6815872-f4ee-4039-a71c-08c49e3dcd79"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"],"id":"7ef41e18"},{"cell_type":"code","execution_count":14,"metadata":{"id":"8233df16","executionInfo":{"status":"ok","timestamp":1646221297568,"user_tz":-540,"elapsed":253,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"],"id":"8233df16"},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1646221297569,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"e9143e61","outputId":"885f9a44-9eb1-47dd-def5-5fc651342b81"},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"],"id":"e9143e61"},{"cell_type":"markdown","metadata":{"id":"6bdc7949"},"source":["## CV split"],"id":"6bdc7949"},{"cell_type":"code","execution_count":16,"metadata":{"id":"c4acf61d","executionInfo":{"status":"ok","timestamp":1646221297569,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def get_groupkfold(df, group_name):\n","    groups = df[group_name].unique()\n","\n","    kf = KFold(\n","        n_splits=CFG.n_fold,\n","        shuffle=True,\n","        random_state=CFG.seed,\n","    )\n","    folds_ids = []\n","    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n","        val_group = groups[val_group_idx]\n","        is_val = df[group_name].isin(val_group)\n","        val_idx = df[is_val].index\n","        df.loc[val_idx, \"fold\"] = int(i_fold)\n","\n","    df[\"fold\"] = df[\"fold\"].astype(int)\n","    return df"],"id":"c4acf61d"},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1646221297569,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"2ca0c08e","outputId":"cd208dca-7d88-4acf-b6f9-47682a5da5e3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    2902\n","1    2894\n","2    2813\n","3    2791\n","4    2900\n","dtype: int64"]},"metadata":{}}],"source":["train = get_groupkfold(train, \"pn_num\")\n","display(train.groupby(\"fold\").size())"],"id":"2ca0c08e"},{"cell_type":"markdown","metadata":{"id":"a8560070"},"source":["## Setup tokenizer"],"id":"a8560070"},{"cell_type":"code","execution_count":18,"metadata":{"id":"c316b13f","executionInfo":{"status":"ok","timestamp":1646221298920,"user_tz":-540,"elapsed":1356,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"],"id":"c316b13f"},{"cell_type":"markdown","metadata":{"id":"e689a7fc"},"source":["## Create dataset"],"id":"e689a7fc"},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["dc08d28ab4de455e8515bae7b79a6ff8","366c244f9828468eb381ca33a4d57d4b","5f73a4c7a6ce4cdf86ceec75694527d2","c5d2d3ce1df2455bbc7998cf60de2051","d9664db31b384a089f67fb7b9ea11647","74a80f81666545d7b785fe94c2af7c3c","0d1b8577c26f4723875d773da23d0d13","d0ec1014b38d46d0a1a9e05d20548d90","c48f4353ed254cbf9263c9642ff011ab","7b3d19f4b6e2458fb1510dc577d02ed2","f8365d28f3744bc3a98e8611891280f2"]},"executionInfo":{"elapsed":22694,"status":"ok","timestamp":1646221321608,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"df31758e","outputId":"909c45b1-64e9-4240-d8ec-bd9c99791e42"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc08d28ab4de455e8515bae7b79a6ff8","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"],"id":"df31758e"},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["df88eb274e2b4deab95ddfe4739870f7","2c12cb20d86f438f84d8f207838506a9","6b65dc35755d4041a82f6993c3747e90","1677e687dac8414eaf5f0efef3a07036","739582965a6e488dbc716e5b8ec3f5b0","e29b4bb5028a48e6bb9951640a277a12","9dd2073aefe44ff99f840186390fa44e","df0c2c48a5e54daba9205d2a658c5e4f","ce3acb0fbc174ddb8a64c8bc1f57f745","af6c7e7fac534c33ab401702a83d8fd7","4775739b55a44a4ab3a2a298fb0fa3d4"]},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1646221321609,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"3caff24a","outputId":"539cce88-656b-4f2a-b804-838f9feabcf3"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df88eb274e2b4deab95ddfe4739870f7","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"],"id":"3caff24a"},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1646221321609,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"756d83ff","outputId":"47b83aae-f79a-4bb6-d0f5-8eb06ab5e611"},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"],"id":"756d83ff"},{"cell_type":"code","execution_count":22,"metadata":{"id":"054b899a","executionInfo":{"status":"ok","timestamp":1646221321610,"user_tz":-540,"elapsed":17,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.case_nums = self.df[\"case_num\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        case_num = self.case_nums[idx]\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, case_num, label"],"id":"054b899a"},{"cell_type":"code","execution_count":23,"metadata":{"id":"1d58367c","executionInfo":{"status":"ok","timestamp":1646221321610,"user_tz":-540,"elapsed":17,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.case_nums = self.df[\"case_num\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        case_num = self.case_nums[idx]\n","        return input_, case_num"],"id":"1d58367c"},{"cell_type":"markdown","metadata":{"id":"8c57abef"},"source":["## Model"],"id":"8c57abef"},{"cell_type":"code","execution_count":24,"metadata":{"id":"54f92d89","executionInfo":{"status":"ok","timestamp":1646221321610,"user_tz":-540,"elapsed":16,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"],"id":"54f92d89"},{"cell_type":"markdown","metadata":{"id":"91401041"},"source":["## Training"],"id":"91401041"},{"cell_type":"code","source":["labels = create_labels_for_scoring(train)\n","res = []\n","for i in labels:\n","    tot = 0\n","    for j in i:\n","        tot += j[1]-j[0]\n","    res.append(tot)\n","train[\"num_of_chars\"] = res\n","weights = dict((train.groupby('case_num')['num_of_chars'].size()) / (train.groupby('case_num')['num_of_chars'].size()).sum() * 10)\n","weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJWX45WJZcKo","executionInfo":{"status":"ok","timestamp":1646221326782,"user_tz":-540,"elapsed":5188,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"a97dbe9e-1dc9-49c2-cb65-3b30ee130e11"},"id":"kJWX45WJZcKo","execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 0.9090909090909092,\n"," 1: 0.9090909090909092,\n"," 2: 1.1888111888111887,\n"," 3: 1.118881118881119,\n"," 4: 0.6993006993006994,\n"," 5: 1.2587412587412588,\n"," 6: 0.8391608391608392,\n"," 7: 0.6293706293706294,\n"," 8: 1.2587412587412588,\n"," 9: 1.1888111888111887}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":26,"metadata":{"id":"eda8175d","executionInfo":{"status":"ok","timestamp":1646221326783,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, case_nums, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        case_nums = torch.tensor([[num] * CFG.max_len for num in case_nums]).view(-1, 1).to(device)\n","        case_nums = torch.masked_select(case_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for case_num in case_nums:\n","            weight.append(weights[case_num.item()])\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"],"id":"eda8175d"},{"cell_type":"code","execution_count":27,"metadata":{"id":"c44b63a7","executionInfo":{"status":"ok","timestamp":1646221326783,"user_tz":-540,"elapsed":23,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, case_nums, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        case_nums = torch.tensor([[num] * CFG.max_len for num in case_nums]).view(-1, 1).to(device)\n","        case_nums = torch.masked_select(case_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for case_num in case_nums:\n","            weight.append(weights[case_num.item()])\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze().detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"],"id":"c44b63a7"},{"cell_type":"code","execution_count":28,"metadata":{"id":"4219ac38","executionInfo":{"status":"ok","timestamp":1646221326783,"user_tz":-540,"elapsed":22,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for (inputs, case_nums) in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze().detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"],"id":"4219ac38"},{"cell_type":"code","execution_count":29,"metadata":{"id":"014a76b7","executionInfo":{"status":"ok","timestamp":1646221326783,"user_tz":-540,"elapsed":22,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"],"id":"014a76b7"},{"cell_type":"markdown","metadata":{"id":"c38fb834"},"source":["## Main"],"id":"c38fb834"},{"cell_type":"code","execution_count":30,"metadata":{"id":"62d677cd","executionInfo":{"status":"ok","timestamp":1646221326784,"user_tz":-540,"elapsed":22,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        #oof_df.to_csv(CFG.output_dir / \"oof_df.csv\", index=False)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"],"id":"62d677cd"},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["90a2dadeee5d4cb4ba6af4860fe576aa","a85fbf125d55450a8c308f6b9edb4655","a640ac8f4bff4ea990cf17be9fcf45da","cb9754be74a846999089e98a72b9e0de","a7fff4c1a6a04c18a15164c2dd934b24","540402ececad40668f4d9abc5eb6b242","c8a6a95525384218b769ec55192d96d3","68ef69afaf58424b98377a152cc537c3","68d63b3d8c35432bb43912cbbb57d0b2","4131c55bf6a946ca8b0adaf776215b50","b8698bafd0804e2ea59ba3674b998c2b","e83e2c3999ff46f19fa744f209411c0f","6fe09aba0db3458c85e99eccc2fa4b71","b1b60f62e13f4df88dba4ca83e6c180e","b19a59f036a54849a56a25a4a2c6b86f","22f883353bcd4f00839891c39bc40b41","69307e3131664b99ba16ce8cbbcb2c6f","dedda3ce6a8c49fc9aec75c5322b9074","104f1edfadd44922934cc92ee5fcde05","f9805f4ade6f414c9ccd51893ff6063d","a26f140ccf92424da864d30babfa0246","e6605c466a4544d488ee926012fcadee","9ee1ac6a49f34e7c8bfbc87ce82a3ea5","610615cd26764488b43776aea99ec076","f1773bbbe75445148659907842d0c807","b38ea71e8f19422aa6db4efedd017d7b","a4358ad3016b45b98a35407460be45e3","1847689845ec492c91100da5be6a0f84","7e87490510684cb8b4588211901e5677","06a7d16b110a4a7d8b89291fe32b48f1","3d64a12b9d9347be97aad7e956246812","c6a84ebd77654759bec9128aac82d218","7db0a0d259824d34ba7062a0ea25ce98","c2b84eb757524b878fb3c8752dabaab2","77f817d15df64029ab5a5e528af6f1da","ea934ed84a1f44e4abc5fd79db00ecb3","a1ce042e6c56493c87feaf4251e6af58","b9535d5087414384aea1ce819ec6cbce","cf01397a564b4fa5aeb132b3b153c9cd","a01322d1f11943369c09e572f3b09a64","dacfe663f1ba4002a9b2f4d44e3952e7","246b83d3a63b4615849bc5a6581c8b66","691eb99a632e4fcf9b214f115a42ed1d","fbb4f2d6c42649edabacfcdb668ada67","f2480afafca546318889db993bfefb76","31bdec5656bc4ccf86b6dd5d772546e1","c4b97f004dc54b7aac3a9e21ec002886","6efd490a0078413ea07b72b8a29317ae","1a1c4e08b1c34da294155a99afcc0689","79657b26ee3c423b98ccc605490a29db","ca9206d0fc0b404da0b237c5e3a763b6","735706dc57764b2c85a290a54337a053","dc652652304642a4b8ebcd21969da42c","64c42d1e38d14ecd82cdb1f86556ad68","04e8bebf566f4d069bb7b874a543f780","18fc71b27e9d4d00a5e27b93dbfb178a","66d296cbb1384b1ab60784ee3dc46f9f","035b90ea0bf943e6acd78f7d008ce1de","0033236b7f0443fb90a87f6cff1ac5cf","1f1ba0f6b2ac47c5bfcd0aa2e503870d","ea2bee5ceee94a73986ec18c925b64fb","28f2743e386b4393a66e6d3eddf63bf3","0f37d2ed31f941f5ac450fb2e6b0cb71","c0b07ea69dfe48ce86f8ff313e76d222","bbb700c0e7c746949786568d367a0df6","7607294bb4b54b158ddec68fa2df2cc1"]},"id":"1d4fcf7c","outputId":"8470f11d-0e82-46c3-8640-37e4918006d0","executionInfo":{"status":"ok","timestamp":1646230026229,"user_tz":-540,"elapsed":8699090,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1424] Elapsed 0m 0s (remain 13m 14s) Loss: 0.7074(0.7074) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1424] Elapsed 0m 20s (remain 4m 32s) Loss: 0.2257(0.5572) Grad: 29707.4316  LR: 0.000003  \n","Epoch: [1][200/1424] Elapsed 0m 41s (remain 4m 9s) Loss: 0.0973(0.3284) Grad: 2269.7812  LR: 0.000006  \n","Epoch: [1][300/1424] Elapsed 1m 1s (remain 3m 49s) Loss: 0.1137(0.2437) Grad: 4443.4756  LR: 0.000008  \n","Epoch: [1][400/1424] Elapsed 1m 21s (remain 3m 28s) Loss: 0.0186(0.1962) Grad: 2947.8635  LR: 0.000011  \n","Epoch: [1][500/1424] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0594(0.1632) Grad: 7989.8086  LR: 0.000014  \n","Epoch: [1][600/1424] Elapsed 2m 2s (remain 2m 47s) Loss: 0.0117(0.1404) Grad: 4113.4858  LR: 0.000017  \n","Epoch: [1][700/1424] Elapsed 2m 22s (remain 2m 27s) Loss: 0.0126(0.1236) Grad: 3858.4182  LR: 0.000020  \n","Epoch: [1][800/1424] Elapsed 2m 43s (remain 2m 6s) Loss: 0.0066(0.1108) Grad: 2574.6621  LR: 0.000020  \n","Epoch: [1][900/1424] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0231(0.1008) Grad: 4364.0234  LR: 0.000019  \n","Epoch: [1][1000/1424] Elapsed 3m 23s (remain 1m 26s) Loss: 0.0376(0.0927) Grad: 4460.9438  LR: 0.000019  \n","Epoch: [1][1100/1424] Elapsed 3m 44s (remain 1m 5s) Loss: 0.0078(0.0859) Grad: 9186.4121  LR: 0.000019  \n","Epoch: [1][1200/1424] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0052(0.0801) Grad: 3997.5808  LR: 0.000018  \n","Epoch: [1][1300/1424] Elapsed 4m 24s (remain 0m 25s) Loss: 0.0120(0.0750) Grad: 4708.5288  LR: 0.000018  \n","Epoch: [1][1400/1424] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0111(0.0708) Grad: 1525.8210  LR: 0.000018  \n","Epoch: [1][1423/1424] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0150(0.0698) Grad: 5410.8687  LR: 0.000018  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 15s) Loss: 0.0197(0.0197) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0130(0.0134) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0198(0.0162) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0041(0.0145) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0032(0.0133) \n","Epoch 1 - avg_train_loss: 0.0698  avg_val_loss: 0.0133  time: 322s\n","Epoch 1 - Score: 0.8467\n","Epoch 1 - Save Best Score: 0.8467 Model\n","Epoch: [2][0/1424] Elapsed 0m 0s (remain 11m 13s) Loss: 0.0028(0.0028) Grad: 3154.9800  LR: 0.000018  \n","Epoch: [2][100/1424] Elapsed 0m 21s (remain 4m 35s) Loss: 0.0068(0.0117) Grad: 12695.8994  LR: 0.000017  \n","Epoch: [2][200/1424] Elapsed 0m 41s (remain 4m 11s) Loss: 0.0164(0.0113) Grad: 20434.4531  LR: 0.000017  \n","Epoch: [2][300/1424] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0048(0.0110) Grad: 22214.2812  LR: 0.000017  \n","Epoch: [2][400/1424] Elapsed 1m 22s (remain 3m 29s) Loss: 0.0068(0.0115) Grad: 13307.1406  LR: 0.000017  \n","Epoch: [2][500/1424] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0027(0.0116) Grad: 4269.1084  LR: 0.000016  \n","Epoch: [2][600/1424] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0012(0.0115) Grad: 4141.5269  LR: 0.000016  \n","Epoch: [2][700/1424] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0071(0.0116) Grad: 13741.1465  LR: 0.000016  \n","Epoch: [2][800/1424] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0131(0.0115) Grad: 26883.4980  LR: 0.000015  \n","Epoch: [2][900/1424] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0100(0.0113) Grad: 18960.3477  LR: 0.000015  \n","Epoch: [2][1000/1424] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0123(0.0112) Grad: 25210.0078  LR: 0.000015  \n","Epoch: [2][1100/1424] Elapsed 3m 44s (remain 1m 5s) Loss: 0.0096(0.0113) Grad: 10835.5723  LR: 0.000014  \n","Epoch: [2][1200/1424] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0426(0.0114) Grad: 84446.0938  LR: 0.000014  \n","Epoch: [2][1300/1424] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0003(0.0113) Grad: 3171.2383  LR: 0.000014  \n","Epoch: [2][1400/1424] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0108(0.0115) Grad: 57874.5078  LR: 0.000013  \n","Epoch: [2][1423/1424] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0175(0.0115) Grad: 26549.2852  LR: 0.000013  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 51s) Loss: 0.0080(0.0080) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0126(0.0128) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0165(0.0164) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0047(0.0141) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0061(0.0129) \n","Epoch 2 - avg_train_loss: 0.0115  avg_val_loss: 0.0129  time: 320s\n","Epoch 2 - Score: 0.8699\n","Epoch 2 - Save Best Score: 0.8699 Model\n","Epoch: [3][0/1424] Elapsed 0m 0s (remain 11m 32s) Loss: 0.0049(0.0049) Grad: 11459.2402  LR: 0.000013  \n","Epoch: [3][100/1424] Elapsed 0m 20s (remain 4m 32s) Loss: 0.0081(0.0075) Grad: 18218.3301  LR: 0.000013  \n","Epoch: [3][200/1424] Elapsed 0m 41s (remain 4m 11s) Loss: 0.0056(0.0086) Grad: 13725.6094  LR: 0.000013  \n","Epoch: [3][300/1424] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0130(0.0091) Grad: 23334.6777  LR: 0.000012  \n","Epoch: [3][400/1424] Elapsed 1m 21s (remain 3m 29s) Loss: 0.0063(0.0092) Grad: 40426.6992  LR: 0.000012  \n","Epoch: [3][500/1424] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0046(0.0095) Grad: 9368.2344  LR: 0.000012  \n","Epoch: [3][600/1424] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0144(0.0094) Grad: 13932.7764  LR: 0.000011  \n","Epoch: [3][700/1424] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0021(0.0095) Grad: 7647.3467  LR: 0.000011  \n","Epoch: [3][800/1424] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0059(0.0094) Grad: 20109.2656  LR: 0.000011  \n","Epoch: [3][900/1424] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0096(0.0092) Grad: 30041.6387  LR: 0.000011  \n","Epoch: [3][1000/1424] Elapsed 3m 23s (remain 1m 26s) Loss: 0.0020(0.0092) Grad: 7099.0688  LR: 0.000010  \n","Epoch: [3][1100/1424] Elapsed 3m 44s (remain 1m 5s) Loss: 0.0410(0.0090) Grad: 42845.0898  LR: 0.000010  \n","Epoch: [3][1200/1424] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0025(0.0090) Grad: 10820.4336  LR: 0.000010  \n","Epoch: [3][1300/1424] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0269(0.0090) Grad: 27540.7598  LR: 0.000009  \n","Epoch: [3][1400/1424] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0039(0.0089) Grad: 7464.4277  LR: 0.000009  \n","Epoch: [3][1423/1424] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0016(0.0089) Grad: 5885.9453  LR: 0.000009  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 56s) Loss: 0.0089(0.0089) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0151(0.0124) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0059(0.0152) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0039(0.0132) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0046(0.0123) \n","Epoch 3 - avg_train_loss: 0.0089  avg_val_loss: 0.0123  time: 322s\n","Epoch 3 - Score: 0.8786\n","Epoch 3 - Save Best Score: 0.8786 Model\n","Epoch: [4][0/1424] Elapsed 0m 0s (remain 12m 0s) Loss: 0.0022(0.0022) Grad: 6439.8696  LR: 0.000009  \n","Epoch: [4][100/1424] Elapsed 0m 20s (remain 4m 33s) Loss: 0.0085(0.0084) Grad: 14701.7520  LR: 0.000009  \n","Epoch: [4][200/1424] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0001(0.0075) Grad: 517.7063  LR: 0.000008  \n","Epoch: [4][300/1424] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0027(0.0078) Grad: 10883.4570  LR: 0.000008  \n","Epoch: [4][400/1424] Elapsed 1m 22s (remain 3m 29s) Loss: 0.0053(0.0081) Grad: 9339.1904  LR: 0.000008  \n","Epoch: [4][500/1424] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0080(0.0077) Grad: 20503.1230  LR: 0.000007  \n","Epoch: [4][600/1424] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0005(0.0077) Grad: 1722.9990  LR: 0.000007  \n","Epoch: [4][700/1424] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0121(0.0078) Grad: 33631.9180  LR: 0.000007  \n","Epoch: [4][800/1424] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0134(0.0076) Grad: 40280.3867  LR: 0.000006  \n","Epoch: [4][900/1424] Elapsed 3m 3s (remain 1m 46s) Loss: 0.1493(0.0077) Grad: 211629.4062  LR: 0.000006  \n","Epoch: [4][1000/1424] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0088(0.0075) Grad: 57844.5117  LR: 0.000006  \n","Epoch: [4][1100/1424] Elapsed 3m 44s (remain 1m 5s) Loss: 0.0008(0.0074) Grad: 4099.0127  LR: 0.000005  \n","Epoch: [4][1200/1424] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0060(0.0072) Grad: 37725.1172  LR: 0.000005  \n","Epoch: [4][1300/1424] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0012(0.0073) Grad: 4203.5332  LR: 0.000005  \n","Epoch: [4][1400/1424] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0002(0.0073) Grad: 1711.6007  LR: 0.000005  \n","Epoch: [4][1423/1424] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0011(0.0073) Grad: 4904.8672  LR: 0.000004  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 54s) Loss: 0.0034(0.0034) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0142(0.0136) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0143(0.0162) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0020(0.0143) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0058(0.0132) \n","Epoch 4 - avg_train_loss: 0.0073  avg_val_loss: 0.0132  time: 322s\n","Epoch 4 - Score: 0.8753\n","Epoch: [5][0/1424] Elapsed 0m 0s (remain 11m 17s) Loss: 0.0039(0.0039) Grad: 6308.4951  LR: 0.000004  \n","Epoch: [5][100/1424] Elapsed 0m 20s (remain 4m 32s) Loss: 0.0005(0.0049) Grad: 1673.6166  LR: 0.000004  \n","Epoch: [5][200/1424] Elapsed 0m 41s (remain 4m 10s) Loss: 0.0074(0.0054) Grad: 11965.0342  LR: 0.000004  \n","Epoch: [5][300/1424] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0056(0.0059) Grad: 32198.9453  LR: 0.000004  \n","Epoch: [5][400/1424] Elapsed 1m 22s (remain 3m 29s) Loss: 0.0116(0.0062) Grad: 19572.3770  LR: 0.000003  \n","Epoch: [5][500/1424] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0001(0.0061) Grad: 767.3875  LR: 0.000003  \n","Epoch: [5][600/1424] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0026(0.0061) Grad: 9520.0215  LR: 0.000003  \n","Epoch: [5][700/1424] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0027(0.0062) Grad: 20275.3691  LR: 0.000002  \n","Epoch: [5][800/1424] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0005(0.0059) Grad: 1791.3148  LR: 0.000002  \n","Epoch: [5][900/1424] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0124(0.0058) Grad: 13845.2695  LR: 0.000002  \n","Epoch: [5][1000/1424] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0194(0.0060) Grad: 46281.8398  LR: 0.000001  \n","Epoch: [5][1100/1424] Elapsed 3m 44s (remain 1m 5s) Loss: 0.0005(0.0061) Grad: 2074.5173  LR: 0.000001  \n","Epoch: [5][1200/1424] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0117(0.0062) Grad: 50675.5703  LR: 0.000001  \n","Epoch: [5][1300/1424] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0000(0.0061) Grad: 143.9512  LR: 0.000000  \n","Epoch: [5][1400/1424] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0115(0.0061) Grad: 61060.8750  LR: 0.000000  \n","Epoch: [5][1423/1424] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0018(0.0061) Grad: 10565.3154  LR: 0.000000  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 53s) Loss: 0.0042(0.0042) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0174(0.0144) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0187(0.0172) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0056(0.0152) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0054(0.0141) \n","Epoch 5 - avg_train_loss: 0.0061  avg_val_loss: 0.0141  time: 323s\n","Epoch 5 - Score: 0.8784\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1425] Elapsed 0m 0s (remain 11m 3s) Loss: 0.5883(0.5883) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1425] Elapsed 0m 20s (remain 4m 32s) Loss: 0.1997(0.4934) Grad: 23271.3945  LR: 0.000003  \n","Epoch: [1][200/1425] Elapsed 0m 41s (remain 4m 10s) Loss: 0.0514(0.2957) Grad: 1011.7227  LR: 0.000006  \n","Epoch: [1][300/1425] Elapsed 1m 1s (remain 3m 49s) Loss: 0.0683(0.2212) Grad: 1889.4288  LR: 0.000008  \n","Epoch: [1][400/1425] Elapsed 1m 21s (remain 3m 28s) Loss: 0.0289(0.1801) Grad: 3858.6812  LR: 0.000011  \n","Epoch: [1][500/1425] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0320(0.1512) Grad: 8629.3867  LR: 0.000014  \n","Epoch: [1][600/1425] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0092(0.1303) Grad: 1877.0098  LR: 0.000017  \n","Epoch: [1][700/1425] Elapsed 2m 22s (remain 2m 27s) Loss: 0.0219(0.1146) Grad: 5794.6646  LR: 0.000020  \n","Epoch: [1][800/1425] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0297(0.1033) Grad: 8434.8057  LR: 0.000020  \n","Epoch: [1][900/1425] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0253(0.0939) Grad: 7464.6250  LR: 0.000019  \n","Epoch: [1][1000/1425] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0186(0.0865) Grad: 2638.8916  LR: 0.000019  \n","Epoch: [1][1100/1425] Elapsed 3m 44s (remain 1m 6s) Loss: 0.0190(0.0801) Grad: 3844.9429  LR: 0.000019  \n","Epoch: [1][1200/1425] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0029(0.0749) Grad: 1075.9281  LR: 0.000018  \n","Epoch: [1][1300/1425] Elapsed 4m 24s (remain 0m 25s) Loss: 0.0059(0.0702) Grad: 1686.7111  LR: 0.000018  \n","Epoch: [1][1400/1425] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0008(0.0663) Grad: 190.1414  LR: 0.000018  \n","Epoch: [1][1424/1425] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0095(0.0654) Grad: 3711.0464  LR: 0.000018  \n","EVAL: [0/362] Elapsed 0m 0s (remain 1m 54s) Loss: 0.0051(0.0051) \n","EVAL: [100/362] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0037(0.0153) \n","EVAL: [200/362] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0155(0.0138) \n","EVAL: [300/362] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0066(0.0140) \n","EVAL: [361/362] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0050(0.0133) \n","Epoch 1 - avg_train_loss: 0.0654  avg_val_loss: 0.0133  time: 320s\n","Epoch 1 - Score: 0.8447\n","Epoch 1 - Save Best Score: 0.8447 Model\n","Epoch: [2][0/1425] Elapsed 0m 0s (remain 11m 46s) Loss: 0.0023(0.0023) Grad: 4941.7173  LR: 0.000018  \n","Epoch: [2][100/1425] Elapsed 0m 21s (remain 4m 36s) Loss: 0.0046(0.0119) Grad: 14318.4121  LR: 0.000017  \n","Epoch: [2][200/1425] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0155(0.0115) Grad: 30063.9902  LR: 0.000017  \n","Epoch: [2][300/1425] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0080(0.0108) Grad: 16326.9805  LR: 0.000017  \n","Epoch: [2][400/1425] Elapsed 1m 22s (remain 3m 29s) Loss: 0.0121(0.0109) Grad: 26242.9434  LR: 0.000017  \n","Epoch: [2][500/1425] Elapsed 1m 42s (remain 3m 9s) Loss: 0.0217(0.0115) Grad: 38775.8633  LR: 0.000016  \n","Epoch: [2][600/1425] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0525(0.0115) Grad: 57842.7148  LR: 0.000016  \n","Epoch: [2][700/1425] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0125(0.0116) Grad: 18140.8691  LR: 0.000016  \n","Epoch: [2][800/1425] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0139(0.0115) Grad: 15939.8262  LR: 0.000015  \n","Epoch: [2][900/1425] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0091(0.0115) Grad: 19071.6836  LR: 0.000015  \n","Epoch: [2][1000/1425] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0013(0.0114) Grad: 6183.8071  LR: 0.000015  \n","Epoch: [2][1100/1425] Elapsed 3m 44s (remain 1m 6s) Loss: 0.0302(0.0114) Grad: 43548.2734  LR: 0.000014  \n","Epoch: [2][1200/1425] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0026(0.0115) Grad: 5468.5708  LR: 0.000014  \n","Epoch: [2][1300/1425] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0272(0.0116) Grad: 61323.8477  LR: 0.000014  \n","Epoch: [2][1400/1425] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0066(0.0116) Grad: 11287.9463  LR: 0.000013  \n","Epoch: [2][1424/1425] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0082(0.0116) Grad: 27305.3457  LR: 0.000013  \n","EVAL: [0/362] Elapsed 0m 0s (remain 1m 55s) Loss: 0.0016(0.0016) \n","EVAL: [100/362] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0026(0.0122) \n","EVAL: [200/362] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0172(0.0116) \n","EVAL: [300/362] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0025(0.0120) \n","EVAL: [361/362] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0045(0.0111) \n","Epoch 2 - avg_train_loss: 0.0116  avg_val_loss: 0.0111  time: 327s\n","Epoch 2 - Score: 0.8715\n","Epoch 2 - Save Best Score: 0.8715 Model\n","Epoch: [3][0/1425] Elapsed 0m 0s (remain 11m 47s) Loss: 0.0020(0.0020) Grad: 10340.4766  LR: 0.000013  \n","Epoch: [3][100/1425] Elapsed 0m 21s (remain 4m 36s) Loss: 0.0071(0.0085) Grad: 10918.3252  LR: 0.000013  \n","Epoch: [3][200/1425] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0074(0.0083) Grad: 51975.4883  LR: 0.000013  \n","Epoch: [3][300/1425] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0002(0.0089) Grad: 713.1987  LR: 0.000012  \n","Epoch: [3][400/1425] Elapsed 1m 22s (remain 3m 29s) Loss: 0.0192(0.0092) Grad: 27658.8066  LR: 0.000012  \n","Epoch: [3][500/1425] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0026(0.0096) Grad: 7057.9150  LR: 0.000012  \n","Epoch: [3][600/1425] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0024(0.0094) Grad: 4733.0176  LR: 0.000011  \n","Epoch: [3][700/1425] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0115(0.0095) Grad: 29262.8184  LR: 0.000011  \n","Epoch: [3][800/1425] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0277(0.0096) Grad: 53896.1445  LR: 0.000011  \n","Epoch: [3][900/1425] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0053(0.0096) Grad: 9224.5400  LR: 0.000011  \n","Epoch: [3][1000/1425] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0024(0.0096) Grad: 17359.6348  LR: 0.000010  \n","Epoch: [3][1100/1425] Elapsed 3m 44s (remain 1m 6s) Loss: 0.0061(0.0095) Grad: 14093.7627  LR: 0.000010  \n","Epoch: [3][1200/1425] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0076(0.0094) Grad: 23778.4609  LR: 0.000010  \n","Epoch: [3][1300/1425] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0144(0.0093) Grad: 18425.7441  LR: 0.000009  \n","Epoch: [3][1400/1425] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0064(0.0091) Grad: 29378.6387  LR: 0.000009  \n","Epoch: [3][1424/1425] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0042(0.0091) Grad: 15428.2920  LR: 0.000009  \n","EVAL: [0/362] Elapsed 0m 0s (remain 1m 57s) Loss: 0.0007(0.0007) \n","EVAL: [100/362] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0020(0.0147) \n","EVAL: [200/362] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0033(0.0133) \n","EVAL: [300/362] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0016(0.0136) \n","EVAL: [361/362] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0036(0.0126) \n","Epoch 3 - avg_train_loss: 0.0091  avg_val_loss: 0.0126  time: 327s\n","Epoch 3 - Score: 0.8758\n","Epoch 3 - Save Best Score: 0.8758 Model\n","Epoch: [4][0/1425] Elapsed 0m 0s (remain 12m 3s) Loss: 0.0039(0.0039) Grad: 13798.2314  LR: 0.000009  \n","Epoch: [4][100/1425] Elapsed 0m 20s (remain 4m 33s) Loss: 0.0026(0.0056) Grad: 7615.8271  LR: 0.000009  \n","Epoch: [4][200/1425] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0121(0.0061) Grad: 106799.2578  LR: 0.000008  \n","Epoch: [4][300/1425] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0957(0.0066) Grad: 154431.0625  LR: 0.000008  \n","Epoch: [4][400/1425] Elapsed 1m 22s (remain 3m 29s) Loss: 0.0224(0.0072) Grad: 35467.0234  LR: 0.000008  \n","Epoch: [4][500/1425] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0058(0.0071) Grad: 9473.6299  LR: 0.000007  \n","Epoch: [4][600/1425] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0034(0.0071) Grad: 33056.0391  LR: 0.000007  \n","Epoch: [4][700/1425] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0139(0.0073) Grad: 26376.7363  LR: 0.000007  \n","Epoch: [4][800/1425] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0006(0.0075) Grad: 2869.0352  LR: 0.000006  \n","Epoch: [4][900/1425] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0028(0.0074) Grad: 18954.0957  LR: 0.000006  \n","Epoch: [4][1000/1425] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0002(0.0074) Grad: 1222.4631  LR: 0.000006  \n","Epoch: [4][1100/1425] Elapsed 3m 44s (remain 1m 6s) Loss: 0.0035(0.0075) Grad: 5890.8003  LR: 0.000005  \n","Epoch: [4][1200/1425] Elapsed 4m 5s (remain 0m 45s) Loss: 0.0039(0.0073) Grad: 5796.8887  LR: 0.000005  \n","Epoch: [4][1300/1425] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0027(0.0074) Grad: 9049.0596  LR: 0.000005  \n","Epoch: [4][1400/1425] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0021(0.0073) Grad: 7106.5371  LR: 0.000005  \n","Epoch: [4][1424/1425] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0039(0.0073) Grad: 16228.1631  LR: 0.000004  \n","EVAL: [0/362] Elapsed 0m 0s (remain 1m 56s) Loss: 0.0011(0.0011) \n","EVAL: [100/362] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0010(0.0141) \n","EVAL: [200/362] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0015(0.0129) \n","EVAL: [300/362] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0011(0.0137) \n","EVAL: [361/362] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0034(0.0127) \n","Epoch 4 - avg_train_loss: 0.0073  avg_val_loss: 0.0127  time: 327s\n","Epoch 4 - Score: 0.8776\n","Epoch 4 - Save Best Score: 0.8776 Model\n","Epoch: [5][0/1425] Elapsed 0m 0s (remain 11m 25s) Loss: 0.0117(0.0117) Grad: 30694.0059  LR: 0.000004  \n","Epoch: [5][100/1425] Elapsed 0m 20s (remain 4m 33s) Loss: 0.0036(0.0066) Grad: 13222.4316  LR: 0.000004  \n","Epoch: [5][200/1425] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0038(0.0070) Grad: 9200.1191  LR: 0.000004  \n","Epoch: [5][300/1425] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0036(0.0069) Grad: 20324.8809  LR: 0.000004  \n","Epoch: [5][400/1425] Elapsed 1m 22s (remain 3m 29s) Loss: 0.0090(0.0066) Grad: 23470.2383  LR: 0.000003  \n","Epoch: [5][500/1425] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0187(0.0067) Grad: 93607.6797  LR: 0.000003  \n","Epoch: [5][600/1425] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0060(0.0066) Grad: 21102.0098  LR: 0.000003  \n","Epoch: [5][700/1425] Elapsed 2m 23s (remain 2m 27s) Loss: 0.0014(0.0065) Grad: 6645.8481  LR: 0.000002  \n","Epoch: [5][800/1425] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0060(0.0065) Grad: 20764.7285  LR: 0.000002  \n","Epoch: [5][900/1425] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0022(0.0063) Grad: 10755.5811  LR: 0.000002  \n","Epoch: [5][1000/1425] Elapsed 3m 24s (remain 1m 26s) Loss: 0.0022(0.0063) Grad: 11498.9697  LR: 0.000001  \n","Epoch: [5][1100/1425] Elapsed 3m 44s (remain 1m 6s) Loss: 0.0039(0.0062) Grad: 7605.0039  LR: 0.000001  \n","Epoch: [5][1200/1425] Elapsed 4m 5s (remain 0m 45s) Loss: 0.0062(0.0062) Grad: 28073.0664  LR: 0.000001  \n","Epoch: [5][1300/1425] Elapsed 4m 25s (remain 0m 25s) Loss: 0.0264(0.0061) Grad: 45985.5195  LR: 0.000000  \n","Epoch: [5][1400/1425] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0018(0.0061) Grad: 3898.6738  LR: 0.000000  \n","Epoch: [5][1424/1425] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0047(0.0061) Grad: 13875.2363  LR: 0.000000  \n","EVAL: [0/362] Elapsed 0m 0s (remain 2m 0s) Loss: 0.0011(0.0011) \n","EVAL: [100/362] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0009(0.0155) \n","EVAL: [200/362] Elapsed 0m 14s (remain 0m 11s) Loss: 0.0024(0.0139) \n","EVAL: [300/362] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0012(0.0146) \n","EVAL: [361/362] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0037(0.0135) \n","Epoch 5 - avg_train_loss: 0.0061  avg_val_loss: 0.0135  time: 327s\n","Epoch 5 - Score: 0.8793\n","Epoch 5 - Save Best Score: 0.8793 Model\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1435] Elapsed 0m 0s (remain 11m 28s) Loss: 0.8598(0.8598) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1435] Elapsed 0m 20s (remain 4m 36s) Loss: 0.1997(0.6461) Grad: 15136.6826  LR: 0.000003  \n","Epoch: [1][200/1435] Elapsed 0m 41s (remain 4m 13s) Loss: 0.1101(0.3687) Grad: 1590.6539  LR: 0.000006  \n","Epoch: [1][300/1435] Elapsed 1m 1s (remain 3m 51s) Loss: 0.0508(0.2709) Grad: 793.0153  LR: 0.000008  \n","Epoch: [1][400/1435] Elapsed 1m 21s (remain 3m 31s) Loss: 0.0359(0.2168) Grad: 2443.1775  LR: 0.000011  \n","Epoch: [1][500/1435] Elapsed 1m 42s (remain 3m 10s) Loss: 0.0519(0.1806) Grad: 5148.7769  LR: 0.000014  \n","Epoch: [1][600/1435] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0405(0.1551) Grad: 1855.4309  LR: 0.000017  \n","Epoch: [1][700/1435] Elapsed 2m 23s (remain 2m 29s) Loss: 0.0206(0.1364) Grad: 1613.5804  LR: 0.000020  \n","Epoch: [1][800/1435] Elapsed 2m 43s (remain 2m 9s) Loss: 0.0200(0.1215) Grad: 1598.7471  LR: 0.000020  \n","Epoch: [1][900/1435] Elapsed 3m 3s (remain 1m 48s) Loss: 0.0095(0.1098) Grad: 1846.9792  LR: 0.000019  \n","Epoch: [1][1000/1435] Elapsed 3m 24s (remain 1m 28s) Loss: 0.0075(0.1005) Grad: 1142.7808  LR: 0.000019  \n","Epoch: [1][1100/1435] Elapsed 3m 44s (remain 1m 8s) Loss: 0.0135(0.0928) Grad: 1171.0349  LR: 0.000019  \n","Epoch: [1][1200/1435] Elapsed 4m 4s (remain 0m 47s) Loss: 0.0252(0.0864) Grad: 1696.4861  LR: 0.000019  \n","Epoch: [1][1300/1435] Elapsed 4m 25s (remain 0m 27s) Loss: 0.0281(0.0808) Grad: 2432.2168  LR: 0.000018  \n","Epoch: [1][1400/1435] Elapsed 4m 45s (remain 0m 6s) Loss: 0.0095(0.0761) Grad: 1375.0310  LR: 0.000018  \n","Epoch: [1][1434/1435] Elapsed 4m 52s (remain 0m 0s) Loss: 0.0386(0.0747) Grad: 2142.5562  LR: 0.000018  \n","EVAL: [0/352] Elapsed 0m 0s (remain 1m 56s) Loss: 0.0125(0.0125) \n","EVAL: [100/352] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0207(0.0135) \n","EVAL: [200/352] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0217(0.0143) \n","EVAL: [300/352] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0068(0.0150) \n","EVAL: [351/352] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0030(0.0143) \n","Epoch 1 - avg_train_loss: 0.0747  avg_val_loss: 0.0143  time: 321s\n","Epoch 1 - Score: 0.8301\n","Epoch 1 - Save Best Score: 0.8301 Model\n","Epoch: [2][0/1435] Elapsed 0m 0s (remain 11m 36s) Loss: 0.0167(0.0167) Grad: 44315.4727  LR: 0.000018  \n","Epoch: [2][100/1435] Elapsed 0m 21s (remain 4m 39s) Loss: 0.0405(0.0121) Grad: 91101.4766  LR: 0.000017  \n","Epoch: [2][200/1435] Elapsed 0m 41s (remain 4m 14s) Loss: 0.0028(0.0109) Grad: 5774.2236  LR: 0.000017  \n","Epoch: [2][300/1435] Elapsed 1m 1s (remain 3m 52s) Loss: 0.0010(0.0109) Grad: 7312.0088  LR: 0.000017  \n","Epoch: [2][400/1435] Elapsed 1m 21s (remain 3m 31s) Loss: 0.0068(0.0110) Grad: 10294.2383  LR: 0.000017  \n","Epoch: [2][500/1435] Elapsed 1m 42s (remain 3m 10s) Loss: 0.0075(0.0111) Grad: 20303.8906  LR: 0.000016  \n","Epoch: [2][600/1435] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0037(0.0109) Grad: 10931.5264  LR: 0.000016  \n","Epoch: [2][700/1435] Elapsed 2m 23s (remain 2m 29s) Loss: 0.0072(0.0112) Grad: 9515.3926  LR: 0.000016  \n","Epoch: [2][800/1435] Elapsed 2m 43s (remain 2m 9s) Loss: 0.0276(0.0111) Grad: 65741.0625  LR: 0.000015  \n","Epoch: [2][900/1435] Elapsed 3m 3s (remain 1m 48s) Loss: 0.0004(0.0109) Grad: 2189.9785  LR: 0.000015  \n","Epoch: [2][1000/1435] Elapsed 3m 24s (remain 1m 28s) Loss: 0.0062(0.0113) Grad: 9120.3916  LR: 0.000015  \n","Epoch: [2][1100/1435] Elapsed 3m 44s (remain 1m 8s) Loss: 0.0354(0.0114) Grad: 31196.7051  LR: 0.000014  \n","Epoch: [2][1200/1435] Elapsed 4m 4s (remain 0m 47s) Loss: 0.0077(0.0114) Grad: 11895.9512  LR: 0.000014  \n","Epoch: [2][1300/1435] Elapsed 4m 25s (remain 0m 27s) Loss: 0.0020(0.0113) Grad: 4373.0215  LR: 0.000014  \n","Epoch: [2][1400/1435] Elapsed 4m 45s (remain 0m 6s) Loss: 0.0219(0.0114) Grad: 50704.9570  LR: 0.000013  \n","Epoch: [2][1434/1435] Elapsed 4m 52s (remain 0m 0s) Loss: 0.0163(0.0114) Grad: 24482.1426  LR: 0.000013  \n","EVAL: [0/352] Elapsed 0m 0s (remain 1m 54s) Loss: 0.0113(0.0113) \n","EVAL: [100/352] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0159(0.0114) \n","EVAL: [200/352] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0280(0.0123) \n","EVAL: [300/352] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0027(0.0132) \n","EVAL: [351/352] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0006(0.0126) \n","Epoch 2 - avg_train_loss: 0.0114  avg_val_loss: 0.0126  time: 321s\n","Epoch 2 - Score: 0.8601\n","Epoch 2 - Save Best Score: 0.8601 Model\n","Epoch: [3][0/1435] Elapsed 0m 0s (remain 11m 44s) Loss: 0.0055(0.0055) Grad: 12618.5088  LR: 0.000013  \n","Epoch: [3][100/1435] Elapsed 0m 20s (remain 4m 35s) Loss: 0.0241(0.0073) Grad: 65231.1250  LR: 0.000013  \n","Epoch: [3][200/1435] Elapsed 0m 41s (remain 4m 14s) Loss: 0.0083(0.0079) Grad: 12811.1914  LR: 0.000013  \n","Epoch: [3][300/1435] Elapsed 1m 1s (remain 3m 52s) Loss: 0.0137(0.0077) Grad: 22078.1309  LR: 0.000012  \n","Epoch: [3][400/1435] Elapsed 1m 22s (remain 3m 31s) Loss: 0.0112(0.0082) Grad: 57011.3516  LR: 0.000012  \n","Epoch: [3][500/1435] Elapsed 1m 42s (remain 3m 10s) Loss: 0.0043(0.0084) Grad: 8906.2363  LR: 0.000012  \n","Epoch: [3][600/1435] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0014(0.0086) Grad: 5018.0996  LR: 0.000011  \n","Epoch: [3][700/1435] Elapsed 2m 23s (remain 2m 29s) Loss: 0.0132(0.0087) Grad: 23866.6484  LR: 0.000011  \n","Epoch: [3][800/1435] Elapsed 2m 43s (remain 2m 9s) Loss: 0.0029(0.0087) Grad: 12722.6982  LR: 0.000011  \n","Epoch: [3][900/1435] Elapsed 3m 3s (remain 1m 48s) Loss: 0.0141(0.0086) Grad: 29827.9160  LR: 0.000011  \n","Epoch: [3][1000/1435] Elapsed 3m 24s (remain 1m 28s) Loss: 0.0122(0.0086) Grad: 25378.4785  LR: 0.000010  \n","Epoch: [3][1100/1435] Elapsed 3m 44s (remain 1m 8s) Loss: 0.0167(0.0085) Grad: 27922.3398  LR: 0.000010  \n","Epoch: [3][1200/1435] Elapsed 4m 4s (remain 0m 47s) Loss: 0.0124(0.0085) Grad: 15132.3633  LR: 0.000010  \n","Epoch: [3][1300/1435] Elapsed 4m 25s (remain 0m 27s) Loss: 0.0004(0.0087) Grad: 1688.0493  LR: 0.000009  \n","Epoch: [3][1400/1435] Elapsed 4m 45s (remain 0m 6s) Loss: 0.0090(0.0088) Grad: 14971.8164  LR: 0.000009  \n","Epoch: [3][1434/1435] Elapsed 4m 52s (remain 0m 0s) Loss: 0.0142(0.0088) Grad: 44571.6562  LR: 0.000009  \n","EVAL: [0/352] Elapsed 0m 0s (remain 1m 56s) Loss: 0.0016(0.0016) \n","EVAL: [100/352] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0139(0.0115) \n","EVAL: [200/352] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0242(0.0123) \n","EVAL: [300/352] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0032(0.0132) \n","EVAL: [351/352] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0001(0.0129) \n","Epoch 3 - avg_train_loss: 0.0088  avg_val_loss: 0.0129  time: 321s\n","Epoch 3 - Score: 0.8669\n","Epoch 3 - Save Best Score: 0.8669 Model\n","Epoch: [4][0/1435] Elapsed 0m 0s (remain 11m 45s) Loss: 0.0041(0.0041) Grad: 36609.0117  LR: 0.000009  \n","Epoch: [4][100/1435] Elapsed 0m 20s (remain 4m 35s) Loss: 0.0030(0.0054) Grad: 9448.3232  LR: 0.000009  \n","Epoch: [4][200/1435] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0183(0.0064) Grad: 35300.0469  LR: 0.000008  \n","Epoch: [4][300/1435] Elapsed 1m 1s (remain 3m 51s) Loss: 0.0016(0.0067) Grad: 7231.4907  LR: 0.000008  \n","Epoch: [4][400/1435] Elapsed 1m 21s (remain 3m 31s) Loss: 0.0284(0.0071) Grad: 49638.1445  LR: 0.000008  \n","Epoch: [4][500/1435] Elapsed 1m 42s (remain 3m 10s) Loss: 0.0055(0.0069) Grad: 12476.8770  LR: 0.000007  \n","Epoch: [4][600/1435] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0016(0.0071) Grad: 5638.6143  LR: 0.000007  \n","Epoch: [4][700/1435] Elapsed 2m 22s (remain 2m 29s) Loss: 0.0007(0.0070) Grad: 2470.4746  LR: 0.000007  \n","Epoch: [4][800/1435] Elapsed 2m 43s (remain 2m 9s) Loss: 0.0030(0.0071) Grad: 10851.1895  LR: 0.000006  \n","Epoch: [4][900/1435] Elapsed 3m 3s (remain 1m 48s) Loss: 0.0002(0.0070) Grad: 1714.0209  LR: 0.000006  \n","Epoch: [4][1000/1435] Elapsed 3m 24s (remain 1m 28s) Loss: 0.0057(0.0070) Grad: 17333.7383  LR: 0.000006  \n","Epoch: [4][1100/1435] Elapsed 3m 44s (remain 1m 8s) Loss: 0.0013(0.0072) Grad: 6513.3813  LR: 0.000005  \n","Epoch: [4][1200/1435] Elapsed 4m 4s (remain 0m 47s) Loss: 0.0104(0.0073) Grad: 35008.1914  LR: 0.000005  \n","Epoch: [4][1300/1435] Elapsed 4m 25s (remain 0m 27s) Loss: 0.0031(0.0072) Grad: 6270.8159  LR: 0.000005  \n","Epoch: [4][1400/1435] Elapsed 4m 45s (remain 0m 6s) Loss: 0.0059(0.0072) Grad: 11267.4785  LR: 0.000005  \n","Epoch: [4][1434/1435] Elapsed 4m 52s (remain 0m 0s) Loss: 0.0002(0.0072) Grad: 1246.7485  LR: 0.000004  \n","EVAL: [0/352] Elapsed 0m 0s (remain 1m 56s) Loss: 0.0054(0.0054) \n","EVAL: [100/352] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0131(0.0132) \n","EVAL: [200/352] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0277(0.0136) \n","EVAL: [300/352] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0013(0.0149) \n","EVAL: [351/352] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0004(0.0144) \n","Epoch 4 - avg_train_loss: 0.0072  avg_val_loss: 0.0144  time: 321s\n","Epoch 4 - Score: 0.8623\n","Epoch: [5][0/1435] Elapsed 0m 0s (remain 12m 7s) Loss: 0.0284(0.0284) Grad: 34518.7969  LR: 0.000004  \n","Epoch: [5][100/1435] Elapsed 0m 20s (remain 4m 35s) Loss: 0.0024(0.0047) Grad: 5597.4580  LR: 0.000004  \n","Epoch: [5][200/1435] Elapsed 0m 41s (remain 4m 13s) Loss: 0.0008(0.0050) Grad: 3829.9851  LR: 0.000004  \n","Epoch: [5][300/1435] Elapsed 1m 1s (remain 3m 52s) Loss: 0.0167(0.0052) Grad: 13958.6406  LR: 0.000004  \n","Epoch: [5][400/1435] Elapsed 1m 21s (remain 3m 31s) Loss: 0.0025(0.0055) Grad: 10307.1963  LR: 0.000003  \n","Epoch: [5][500/1435] Elapsed 1m 42s (remain 3m 10s) Loss: 0.0047(0.0056) Grad: 15077.1064  LR: 0.000003  \n","Epoch: [5][600/1435] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0001(0.0058) Grad: 158.9595  LR: 0.000003  \n","Epoch: [5][700/1435] Elapsed 2m 22s (remain 2m 29s) Loss: 0.0008(0.0059) Grad: 5358.2988  LR: 0.000002  \n","Epoch: [5][800/1435] Elapsed 2m 43s (remain 2m 9s) Loss: 0.0053(0.0059) Grad: 16603.9980  LR: 0.000002  \n","Epoch: [5][900/1435] Elapsed 3m 3s (remain 1m 48s) Loss: 0.0067(0.0058) Grad: 23518.6660  LR: 0.000002  \n","Epoch: [5][1000/1435] Elapsed 3m 23s (remain 1m 28s) Loss: 0.0040(0.0059) Grad: 42681.5977  LR: 0.000001  \n","Epoch: [5][1100/1435] Elapsed 3m 44s (remain 1m 7s) Loss: 0.0324(0.0059) Grad: 51536.0039  LR: 0.000001  \n","Epoch: [5][1200/1435] Elapsed 4m 4s (remain 0m 47s) Loss: 0.0146(0.0059) Grad: 8635.3145  LR: 0.000001  \n","Epoch: [5][1300/1435] Elapsed 4m 24s (remain 0m 27s) Loss: 0.0043(0.0059) Grad: 21819.7520  LR: 0.000000  \n","Epoch: [5][1400/1435] Elapsed 4m 44s (remain 0m 6s) Loss: 0.0040(0.0061) Grad: 16446.4824  LR: 0.000000  \n","Epoch: [5][1434/1435] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0012(0.0061) Grad: 3982.6829  LR: 0.000000  \n","EVAL: [0/352] Elapsed 0m 0s (remain 1m 53s) Loss: 0.0046(0.0046) \n","EVAL: [100/352] Elapsed 0m 7s (remain 0m 17s) Loss: 0.0144(0.0139) \n","EVAL: [200/352] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0349(0.0145) \n","EVAL: [300/352] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0013(0.0157) \n","EVAL: [351/352] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0003(0.0153) \n","Epoch 5 - avg_train_loss: 0.0061  avg_val_loss: 0.0153  time: 320s\n","Epoch 5 - Score: 0.8653\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1438] Elapsed 0m 0s (remain 11m 18s) Loss: 0.6504(0.6504) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1438] Elapsed 0m 20s (remain 4m 34s) Loss: 0.1693(0.4911) Grad: 26246.2695  LR: 0.000003  \n","Epoch: [1][200/1438] Elapsed 0m 41s (remain 4m 12s) Loss: 0.1367(0.2910) Grad: 4501.1245  LR: 0.000006  \n","Epoch: [1][300/1438] Elapsed 1m 1s (remain 3m 51s) Loss: 0.0406(0.2187) Grad: 1269.9617  LR: 0.000008  \n","Epoch: [1][400/1438] Elapsed 1m 21s (remain 3m 30s) Loss: 0.0299(0.1799) Grad: 2540.0471  LR: 0.000011  \n","Epoch: [1][500/1438] Elapsed 1m 41s (remain 3m 10s) Loss: 0.0182(0.1512) Grad: 4961.0283  LR: 0.000014  \n","Epoch: [1][600/1438] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0087(0.1307) Grad: 3250.4673  LR: 0.000017  \n","Epoch: [1][700/1438] Elapsed 2m 22s (remain 2m 29s) Loss: 0.0280(0.1154) Grad: 5883.6597  LR: 0.000019  \n","Epoch: [1][800/1438] Elapsed 2m 42s (remain 2m 9s) Loss: 0.0102(0.1035) Grad: 2838.1917  LR: 0.000020  \n","Epoch: [1][900/1438] Elapsed 3m 2s (remain 1m 49s) Loss: 0.0070(0.0943) Grad: 2547.8325  LR: 0.000019  \n","Epoch: [1][1000/1438] Elapsed 3m 23s (remain 1m 28s) Loss: 0.0159(0.0867) Grad: 3031.2136  LR: 0.000019  \n","Epoch: [1][1100/1438] Elapsed 3m 43s (remain 1m 8s) Loss: 0.0127(0.0802) Grad: 3346.2075  LR: 0.000019  \n","Epoch: [1][1200/1438] Elapsed 4m 3s (remain 0m 48s) Loss: 0.0318(0.0747) Grad: 3348.8069  LR: 0.000019  \n","Epoch: [1][1300/1438] Elapsed 4m 24s (remain 0m 27s) Loss: 0.0273(0.0702) Grad: 3237.4185  LR: 0.000018  \n","Epoch: [1][1400/1438] Elapsed 4m 44s (remain 0m 7s) Loss: 0.0083(0.0662) Grad: 1717.0989  LR: 0.000018  \n","Epoch: [1][1437/1438] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0105(0.0649) Grad: 2406.3406  LR: 0.000018  \n","EVAL: [0/349] Elapsed 0m 0s (remain 1m 51s) Loss: 0.0046(0.0046) \n","EVAL: [100/349] Elapsed 0m 7s (remain 0m 17s) Loss: 0.0273(0.0124) \n","EVAL: [200/349] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0144(0.0135) \n","EVAL: [300/349] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0134(0.0151) \n","EVAL: [348/349] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0019(0.0147) \n","Epoch 1 - avg_train_loss: 0.0649  avg_val_loss: 0.0147  time: 320s\n","Epoch 1 - Score: 0.8314\n","Epoch 1 - Save Best Score: 0.8314 Model\n","Epoch: [2][0/1438] Elapsed 0m 0s (remain 11m 47s) Loss: 0.0098(0.0098) Grad: 23453.8633  LR: 0.000018  \n","Epoch: [2][100/1438] Elapsed 0m 20s (remain 4m 36s) Loss: 0.0031(0.0122) Grad: 6855.4741  LR: 0.000017  \n","Epoch: [2][200/1438] Elapsed 0m 41s (remain 4m 14s) Loss: 0.0133(0.0127) Grad: 31598.1016  LR: 0.000017  \n","Epoch: [2][300/1438] Elapsed 1m 1s (remain 3m 52s) Loss: 0.0035(0.0122) Grad: 14177.5459  LR: 0.000017  \n","Epoch: [2][400/1438] Elapsed 1m 21s (remain 3m 31s) Loss: 0.0078(0.0119) Grad: 19226.9688  LR: 0.000017  \n","Epoch: [2][500/1438] Elapsed 1m 42s (remain 3m 11s) Loss: 0.0004(0.0116) Grad: 2039.7114  LR: 0.000016  \n","Epoch: [2][600/1438] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0066(0.0114) Grad: 14605.8271  LR: 0.000016  \n","Epoch: [2][700/1438] Elapsed 2m 22s (remain 2m 30s) Loss: 0.0063(0.0116) Grad: 10297.4307  LR: 0.000016  \n","Epoch: [2][800/1438] Elapsed 2m 43s (remain 2m 9s) Loss: 0.0172(0.0117) Grad: 19130.0156  LR: 0.000015  \n","Epoch: [2][900/1438] Elapsed 3m 3s (remain 1m 49s) Loss: 0.0106(0.0116) Grad: 15853.7705  LR: 0.000015  \n","Epoch: [2][1000/1438] Elapsed 3m 23s (remain 1m 28s) Loss: 0.0080(0.0116) Grad: 27470.9727  LR: 0.000015  \n","Epoch: [2][1100/1438] Elapsed 3m 44s (remain 1m 8s) Loss: 0.0074(0.0114) Grad: 9966.9570  LR: 0.000014  \n","Epoch: [2][1200/1438] Elapsed 4m 4s (remain 0m 48s) Loss: 0.0284(0.0115) Grad: 54542.8281  LR: 0.000014  \n","Epoch: [2][1300/1438] Elapsed 4m 24s (remain 0m 27s) Loss: 0.0161(0.0114) Grad: 14863.7754  LR: 0.000014  \n","Epoch: [2][1400/1438] Elapsed 4m 44s (remain 0m 7s) Loss: 0.0065(0.0114) Grad: 11780.7705  LR: 0.000013  \n","Epoch: [2][1437/1438] Elapsed 4m 52s (remain 0m 0s) Loss: 0.0087(0.0114) Grad: 24930.9727  LR: 0.000013  \n","EVAL: [0/349] Elapsed 0m 0s (remain 1m 53s) Loss: 0.0097(0.0097) \n","EVAL: [100/349] Elapsed 0m 7s (remain 0m 17s) Loss: 0.0252(0.0116) \n","EVAL: [200/349] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0167(0.0122) \n","EVAL: [300/349] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0070(0.0125) \n","EVAL: [348/349] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0005(0.0121) \n","Epoch 2 - avg_train_loss: 0.0114  avg_val_loss: 0.0121  time: 321s\n","Epoch 2 - Score: 0.8703\n","Epoch 2 - Save Best Score: 0.8703 Model\n","Epoch: [3][0/1438] Elapsed 0m 0s (remain 11m 43s) Loss: 0.0234(0.0234) Grad: 27880.5000  LR: 0.000013  \n","Epoch: [3][100/1438] Elapsed 0m 20s (remain 4m 35s) Loss: 0.0032(0.0108) Grad: 5045.4585  LR: 0.000013  \n","Epoch: [3][200/1438] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0033(0.0093) Grad: 27488.6055  LR: 0.000013  \n","Epoch: [3][300/1438] Elapsed 1m 1s (remain 3m 52s) Loss: 0.0064(0.0089) Grad: 25332.4434  LR: 0.000012  \n","Epoch: [3][400/1438] Elapsed 1m 21s (remain 3m 31s) Loss: 0.0064(0.0095) Grad: 9874.4404  LR: 0.000012  \n","Epoch: [3][500/1438] Elapsed 1m 42s (remain 3m 10s) Loss: 0.0158(0.0095) Grad: 40504.8594  LR: 0.000012  \n","Epoch: [3][600/1438] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0120(0.0095) Grad: 18421.3867  LR: 0.000011  \n","Epoch: [3][700/1438] Elapsed 2m 22s (remain 2m 30s) Loss: 0.0066(0.0093) Grad: 12724.2383  LR: 0.000011  \n","Epoch: [3][800/1438] Elapsed 2m 43s (remain 2m 9s) Loss: 0.0022(0.0094) Grad: 15685.9297  LR: 0.000011  \n","Epoch: [3][900/1438] Elapsed 3m 3s (remain 1m 49s) Loss: 0.0124(0.0094) Grad: 46207.8945  LR: 0.000011  \n","Epoch: [3][1000/1438] Elapsed 3m 23s (remain 1m 28s) Loss: 0.0100(0.0093) Grad: 20465.1953  LR: 0.000010  \n","Epoch: [3][1100/1438] Elapsed 3m 43s (remain 1m 8s) Loss: 0.0008(0.0093) Grad: 2953.5271  LR: 0.000010  \n","Epoch: [3][1200/1438] Elapsed 4m 4s (remain 0m 48s) Loss: 0.0152(0.0093) Grad: 25670.4355  LR: 0.000010  \n","Epoch: [3][1300/1438] Elapsed 4m 24s (remain 0m 27s) Loss: 0.0129(0.0091) Grad: 20722.5117  LR: 0.000009  \n","Epoch: [3][1400/1438] Elapsed 4m 44s (remain 0m 7s) Loss: 0.0049(0.0091) Grad: 15706.2422  LR: 0.000009  \n","Epoch: [3][1437/1438] Elapsed 4m 52s (remain 0m 0s) Loss: 0.0232(0.0092) Grad: 21907.9121  LR: 0.000009  \n","EVAL: [0/349] Elapsed 0m 0s (remain 1m 52s) Loss: 0.0093(0.0093) \n","EVAL: [100/349] Elapsed 0m 7s (remain 0m 17s) Loss: 0.0118(0.0118) \n","EVAL: [200/349] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0230(0.0128) \n","EVAL: [300/349] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0055(0.0129) \n","EVAL: [348/349] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0005(0.0127) \n","Epoch 3 - avg_train_loss: 0.0092  avg_val_loss: 0.0127  time: 321s\n","Epoch 3 - Score: 0.8713\n","Epoch 3 - Save Best Score: 0.8713 Model\n","Epoch: [4][0/1438] Elapsed 0m 0s (remain 11m 51s) Loss: 0.0028(0.0028) Grad: 11131.6357  LR: 0.000009  \n","Epoch: [4][100/1438] Elapsed 0m 20s (remain 4m 35s) Loss: 0.0039(0.0066) Grad: 9502.6729  LR: 0.000009  \n","Epoch: [4][200/1438] Elapsed 0m 41s (remain 4m 12s) Loss: 0.0024(0.0077) Grad: 7898.5918  LR: 0.000008  \n","Epoch: [4][300/1438] Elapsed 1m 1s (remain 3m 51s) Loss: 0.0011(0.0073) Grad: 5350.7183  LR: 0.000008  \n","Epoch: [4][400/1438] Elapsed 1m 21s (remain 3m 31s) Loss: 0.0060(0.0073) Grad: 12834.4473  LR: 0.000008  \n","Epoch: [4][500/1438] Elapsed 1m 42s (remain 3m 10s) Loss: 0.0050(0.0071) Grad: 11219.5117  LR: 0.000007  \n","Epoch: [4][600/1438] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0112(0.0071) Grad: 31617.4375  LR: 0.000007  \n","Epoch: [4][700/1438] Elapsed 2m 22s (remain 2m 29s) Loss: 0.0015(0.0071) Grad: 8687.7461  LR: 0.000007  \n","Epoch: [4][800/1438] Elapsed 2m 42s (remain 2m 9s) Loss: 0.0024(0.0071) Grad: 31526.9883  LR: 0.000006  \n","Epoch: [4][900/1438] Elapsed 3m 3s (remain 1m 49s) Loss: 0.0017(0.0073) Grad: 3519.5906  LR: 0.000006  \n","Epoch: [4][1000/1438] Elapsed 3m 23s (remain 1m 28s) Loss: 0.0042(0.0073) Grad: 5862.1411  LR: 0.000006  \n","Epoch: [4][1100/1438] Elapsed 3m 43s (remain 1m 8s) Loss: 0.0121(0.0073) Grad: 22897.0293  LR: 0.000005  \n","Epoch: [4][1200/1438] Elapsed 4m 3s (remain 0m 48s) Loss: 0.0030(0.0074) Grad: 7052.7993  LR: 0.000005  \n","Epoch: [4][1300/1438] Elapsed 4m 24s (remain 0m 27s) Loss: 0.0046(0.0073) Grad: 19962.2051  LR: 0.000005  \n","Epoch: [4][1400/1438] Elapsed 4m 44s (remain 0m 7s) Loss: 0.0020(0.0074) Grad: 10591.7070  LR: 0.000005  \n","Epoch: [4][1437/1438] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0110(0.0074) Grad: 11577.3125  LR: 0.000004  \n","EVAL: [0/349] Elapsed 0m 0s (remain 1m 55s) Loss: 0.0087(0.0087) \n","EVAL: [100/349] Elapsed 0m 7s (remain 0m 17s) Loss: 0.0169(0.0120) \n","EVAL: [200/349] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0259(0.0131) \n","EVAL: [300/349] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0050(0.0133) \n","EVAL: [348/349] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0001(0.0130) \n","Epoch 4 - avg_train_loss: 0.0074  avg_val_loss: 0.0130  time: 320s\n","Epoch 4 - Score: 0.8791\n","Epoch 4 - Save Best Score: 0.8791 Model\n","Epoch: [5][0/1438] Elapsed 0m 0s (remain 11m 51s) Loss: 0.0016(0.0016) Grad: 5741.9722  LR: 0.000004  \n","Epoch: [5][100/1438] Elapsed 0m 20s (remain 4m 34s) Loss: 0.0045(0.0068) Grad: 19719.0352  LR: 0.000004  \n","Epoch: [5][200/1438] Elapsed 0m 40s (remain 4m 12s) Loss: 0.0025(0.0065) Grad: 18055.2559  LR: 0.000004  \n","Epoch: [5][300/1438] Elapsed 1m 1s (remain 3m 51s) Loss: 0.0012(0.0062) Grad: 5607.1982  LR: 0.000004  \n","Epoch: [5][400/1438] Elapsed 1m 21s (remain 3m 30s) Loss: 0.0256(0.0062) Grad: 39868.8516  LR: 0.000003  \n","Epoch: [5][500/1438] Elapsed 1m 41s (remain 3m 10s) Loss: 0.0003(0.0060) Grad: 2008.4971  LR: 0.000003  \n","Epoch: [5][600/1438] Elapsed 2m 2s (remain 2m 50s) Loss: 0.0210(0.0060) Grad: 17169.0254  LR: 0.000003  \n","Epoch: [5][700/1438] Elapsed 2m 22s (remain 2m 29s) Loss: 0.0034(0.0060) Grad: 16009.0801  LR: 0.000002  \n","Epoch: [5][800/1438] Elapsed 2m 42s (remain 2m 9s) Loss: 0.0039(0.0060) Grad: 16594.1426  LR: 0.000002  \n","Epoch: [5][900/1438] Elapsed 3m 2s (remain 1m 48s) Loss: 0.0002(0.0060) Grad: 2530.9536  LR: 0.000002  \n","Epoch: [5][1000/1438] Elapsed 3m 23s (remain 1m 28s) Loss: 0.0008(0.0061) Grad: 5679.1230  LR: 0.000001  \n","Epoch: [5][1100/1438] Elapsed 3m 43s (remain 1m 8s) Loss: 0.0009(0.0061) Grad: 4117.0127  LR: 0.000001  \n","Epoch: [5][1200/1438] Elapsed 4m 3s (remain 0m 48s) Loss: 0.0048(0.0060) Grad: 10258.4961  LR: 0.000001  \n","Epoch: [5][1300/1438] Elapsed 4m 23s (remain 0m 27s) Loss: 0.0068(0.0061) Grad: 37205.1289  LR: 0.000000  \n","Epoch: [5][1400/1438] Elapsed 4m 44s (remain 0m 7s) Loss: 0.0102(0.0061) Grad: 11093.3037  LR: 0.000000  \n","Epoch: [5][1437/1438] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0019(0.0061) Grad: 4883.0752  LR: 0.000000  \n","EVAL: [0/349] Elapsed 0m 0s (remain 1m 50s) Loss: 0.0111(0.0111) \n","EVAL: [100/349] Elapsed 0m 7s (remain 0m 17s) Loss: 0.0182(0.0129) \n","EVAL: [200/349] Elapsed 0m 14s (remain 0m 10s) Loss: 0.0302(0.0141) \n","EVAL: [300/349] Elapsed 0m 21s (remain 0m 3s) Loss: 0.0051(0.0145) \n","EVAL: [348/349] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0001(0.0141) \n","Epoch 5 - avg_train_loss: 0.0061  avg_val_loss: 0.0141  time: 320s\n","Epoch 5 - Score: 0.8792\n","Epoch 5 - Save Best Score: 0.8792 Model\n","========== fold: 4 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1425] Elapsed 0m 0s (remain 11m 10s) Loss: 0.7517(0.7517) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1425] Elapsed 0m 20s (remain 4m 31s) Loss: 0.2127(0.6662) Grad: 12476.9443  LR: 0.000003  \n","Epoch: [1][200/1425] Elapsed 0m 40s (remain 4m 9s) Loss: 0.0564(0.3797) Grad: 1092.4041  LR: 0.000006  \n","Epoch: [1][300/1425] Elapsed 1m 1s (remain 3m 48s) Loss: 0.0430(0.2768) Grad: 704.5568  LR: 0.000008  \n","Epoch: [1][400/1425] Elapsed 1m 21s (remain 3m 28s) Loss: 0.0727(0.2206) Grad: 3339.1987  LR: 0.000011  \n","Epoch: [1][500/1425] Elapsed 1m 41s (remain 3m 7s) Loss: 0.0242(0.1827) Grad: 1390.3187  LR: 0.000014  \n","Epoch: [1][600/1425] Elapsed 2m 2s (remain 2m 47s) Loss: 0.0159(0.1565) Grad: 1826.2001  LR: 0.000017  \n","Epoch: [1][700/1425] Elapsed 2m 22s (remain 2m 27s) Loss: 0.0192(0.1371) Grad: 3824.9463  LR: 0.000020  \n","Epoch: [1][800/1425] Elapsed 2m 42s (remain 2m 6s) Loss: 0.0154(0.1226) Grad: 1162.9303  LR: 0.000020  \n","Epoch: [1][900/1425] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0133(0.1112) Grad: 1432.8684  LR: 0.000019  \n","Epoch: [1][1000/1425] Elapsed 3m 23s (remain 1m 26s) Loss: 0.0114(0.1019) Grad: 816.6900  LR: 0.000019  \n","Epoch: [1][1100/1425] Elapsed 3m 43s (remain 1m 5s) Loss: 0.0147(0.0942) Grad: 3577.2375  LR: 0.000019  \n","Epoch: [1][1200/1425] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0170(0.0875) Grad: 1042.3860  LR: 0.000018  \n","Epoch: [1][1300/1425] Elapsed 4m 24s (remain 0m 25s) Loss: 0.0245(0.0820) Grad: 1467.2793  LR: 0.000018  \n","Epoch: [1][1400/1425] Elapsed 4m 44s (remain 0m 4s) Loss: 0.0128(0.0772) Grad: 1203.8553  LR: 0.000018  \n","Epoch: [1][1424/1425] Elapsed 4m 49s (remain 0m 0s) Loss: 0.0071(0.0761) Grad: 881.0887  LR: 0.000018  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 59s) Loss: 0.0195(0.0195) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0102(0.0143) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.1743(0.0159) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0077(0.0161) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0095(0.0147) \n","Epoch 1 - avg_train_loss: 0.0761  avg_val_loss: 0.0147  time: 319s\n","Epoch 1 - Score: 0.8368\n","Epoch 1 - Save Best Score: 0.8368 Model\n","Epoch: [2][0/1425] Elapsed 0m 0s (remain 11m 39s) Loss: 0.0057(0.0057) Grad: 9573.6309  LR: 0.000018  \n","Epoch: [2][100/1425] Elapsed 0m 21s (remain 4m 35s) Loss: 0.0046(0.0139) Grad: 15377.7803  LR: 0.000017  \n","Epoch: [2][200/1425] Elapsed 0m 41s (remain 4m 11s) Loss: 0.0041(0.0127) Grad: 13926.3848  LR: 0.000017  \n","Epoch: [2][300/1425] Elapsed 1m 1s (remain 3m 50s) Loss: 0.0059(0.0120) Grad: 17181.8691  LR: 0.000017  \n","Epoch: [2][400/1425] Elapsed 1m 21s (remain 3m 29s) Loss: 0.0101(0.0119) Grad: 25712.1211  LR: 0.000017  \n","Epoch: [2][500/1425] Elapsed 1m 42s (remain 3m 8s) Loss: 0.0027(0.0121) Grad: 15732.5439  LR: 0.000016  \n","Epoch: [2][600/1425] Elapsed 2m 2s (remain 2m 48s) Loss: 0.0039(0.0116) Grad: 10806.4014  LR: 0.000016  \n","Epoch: [2][700/1425] Elapsed 2m 22s (remain 2m 27s) Loss: 0.0057(0.0117) Grad: 15076.3018  LR: 0.000016  \n","Epoch: [2][800/1425] Elapsed 2m 43s (remain 2m 7s) Loss: 0.0016(0.0117) Grad: 4769.2266  LR: 0.000015  \n","Epoch: [2][900/1425] Elapsed 3m 3s (remain 1m 46s) Loss: 0.0045(0.0116) Grad: 8432.2744  LR: 0.000015  \n","Epoch: [2][1000/1425] Elapsed 3m 23s (remain 1m 26s) Loss: 0.0213(0.0116) Grad: 49241.2617  LR: 0.000015  \n","Epoch: [2][1100/1425] Elapsed 3m 44s (remain 1m 5s) Loss: 0.0027(0.0115) Grad: 16892.2012  LR: 0.000014  \n","Epoch: [2][1200/1425] Elapsed 4m 4s (remain 0m 45s) Loss: 0.0103(0.0116) Grad: 43153.3516  LR: 0.000014  \n","Epoch: [2][1300/1425] Elapsed 4m 24s (remain 0m 25s) Loss: 0.0365(0.0116) Grad: 41219.3398  LR: 0.000014  \n","Epoch: [2][1400/1425] Elapsed 4m 45s (remain 0m 4s) Loss: 0.0038(0.0115) Grad: 14269.2480  LR: 0.000013  \n","Epoch: [2][1424/1425] Elapsed 4m 49s (remain 0m 0s) Loss: 0.0012(0.0115) Grad: 6123.1802  LR: 0.000013  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 51s) Loss: 0.0174(0.0174) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 19s) Loss: 0.0145(0.0143) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.1161(0.0140) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0070(0.0137) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0108(0.0125) \n","Epoch 2 - avg_train_loss: 0.0115  avg_val_loss: 0.0125  time: 320s\n","Epoch 2 - Score: 0.8697\n","Epoch 2 - Save Best Score: 0.8697 Model\n","Epoch: [3][0/1425] Elapsed 0m 0s (remain 11m 45s) Loss: 0.0064(0.0064) Grad: 24128.6836  LR: 0.000013  \n","Epoch: [3][100/1425] Elapsed 0m 20s (remain 4m 31s) Loss: 0.0055(0.0082) Grad: 20147.3848  LR: 0.000013  \n","Epoch: [3][200/1425] Elapsed 0m 41s (remain 4m 9s) Loss: 0.0014(0.0081) Grad: 8317.1006  LR: 0.000013  \n","Epoch: [3][300/1425] Elapsed 1m 1s (remain 3m 48s) Loss: 0.0082(0.0090) Grad: 20781.0195  LR: 0.000012  \n","Epoch: [3][400/1425] Elapsed 1m 21s (remain 3m 27s) Loss: 0.0129(0.0088) Grad: 36260.4531  LR: 0.000012  \n","Epoch: [3][500/1425] Elapsed 1m 41s (remain 3m 6s) Loss: 0.0204(0.0084) Grad: 31678.9746  LR: 0.000012  \n","Epoch: [3][600/1425] Elapsed 2m 1s (remain 2m 46s) Loss: 0.0079(0.0086) Grad: 13552.3096  LR: 0.000011  \n","Epoch: [3][700/1425] Elapsed 2m 21s (remain 2m 26s) Loss: 0.0046(0.0086) Grad: 11060.4004  LR: 0.000011  \n","Epoch: [3][800/1425] Elapsed 2m 41s (remain 2m 6s) Loss: 0.0097(0.0086) Grad: 20341.2852  LR: 0.000011  \n","Epoch: [3][900/1425] Elapsed 3m 2s (remain 1m 45s) Loss: 0.0082(0.0087) Grad: 12681.9033  LR: 0.000011  \n","Epoch: [3][1000/1425] Elapsed 3m 22s (remain 1m 25s) Loss: 0.0162(0.0088) Grad: 26267.1250  LR: 0.000010  \n","Epoch: [3][1100/1425] Elapsed 3m 42s (remain 1m 5s) Loss: 0.0015(0.0088) Grad: 4395.9966  LR: 0.000010  \n","Epoch: [3][1200/1425] Elapsed 4m 2s (remain 0m 45s) Loss: 0.0134(0.0087) Grad: 12634.6797  LR: 0.000010  \n","Epoch: [3][1300/1425] Elapsed 4m 23s (remain 0m 25s) Loss: 0.0001(0.0088) Grad: 303.8754  LR: 0.000009  \n","Epoch: [3][1400/1425] Elapsed 4m 43s (remain 0m 4s) Loss: 0.0004(0.0089) Grad: 1738.1113  LR: 0.000009  \n","Epoch: [3][1424/1425] Elapsed 4m 48s (remain 0m 0s) Loss: 0.0013(0.0089) Grad: 3686.4688  LR: 0.000009  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 53s) Loss: 0.0181(0.0181) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0118(0.0134) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.1769(0.0146) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0114(0.0143) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0112(0.0130) \n","Epoch 3 - avg_train_loss: 0.0089  avg_val_loss: 0.0130  time: 318s\n","Epoch 3 - Score: 0.8698\n","Epoch 3 - Save Best Score: 0.8698 Model\n","Epoch: [4][0/1425] Elapsed 0m 0s (remain 11m 41s) Loss: 0.0009(0.0009) Grad: 4241.8032  LR: 0.000009  \n","Epoch: [4][100/1425] Elapsed 0m 20s (remain 4m 32s) Loss: 0.0042(0.0067) Grad: 11988.0938  LR: 0.000009  \n","Epoch: [4][200/1425] Elapsed 0m 41s (remain 4m 9s) Loss: 0.0045(0.0069) Grad: 10749.9727  LR: 0.000008  \n","Epoch: [4][300/1425] Elapsed 1m 1s (remain 3m 49s) Loss: 0.0050(0.0069) Grad: 18965.3672  LR: 0.000008  \n","Epoch: [4][400/1425] Elapsed 1m 21s (remain 3m 28s) Loss: 0.0092(0.0069) Grad: 53844.9336  LR: 0.000008  \n","Epoch: [4][500/1425] Elapsed 1m 41s (remain 3m 7s) Loss: 0.0064(0.0071) Grad: 15221.3604  LR: 0.000007  \n","Epoch: [4][600/1425] Elapsed 2m 1s (remain 2m 47s) Loss: 0.0034(0.0071) Grad: 21455.3438  LR: 0.000007  \n","Epoch: [4][700/1425] Elapsed 2m 22s (remain 2m 26s) Loss: 0.0326(0.0069) Grad: 82087.5781  LR: 0.000007  \n","Epoch: [4][800/1425] Elapsed 2m 42s (remain 2m 6s) Loss: 0.0071(0.0070) Grad: 11497.3311  LR: 0.000006  \n","Epoch: [4][900/1425] Elapsed 3m 2s (remain 1m 46s) Loss: 0.0046(0.0070) Grad: 23368.7227  LR: 0.000006  \n","Epoch: [4][1000/1425] Elapsed 3m 22s (remain 1m 25s) Loss: 0.0007(0.0071) Grad: 9116.1729  LR: 0.000006  \n","Epoch: [4][1100/1425] Elapsed 3m 42s (remain 1m 5s) Loss: 0.0017(0.0071) Grad: 5021.1992  LR: 0.000005  \n","Epoch: [4][1200/1425] Elapsed 4m 3s (remain 0m 45s) Loss: 0.0007(0.0071) Grad: 2762.9314  LR: 0.000005  \n","Epoch: [4][1300/1425] Elapsed 4m 23s (remain 0m 25s) Loss: 0.0057(0.0072) Grad: 19816.3906  LR: 0.000005  \n","Epoch: [4][1400/1425] Elapsed 4m 43s (remain 0m 4s) Loss: 0.0115(0.0072) Grad: 46013.5000  LR: 0.000005  \n","Epoch: [4][1424/1425] Elapsed 4m 48s (remain 0m 0s) Loss: 0.0187(0.0072) Grad: 37370.5391  LR: 0.000004  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 51s) Loss: 0.0303(0.0303) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0104(0.0150) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.1268(0.0149) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0197(0.0148) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0110(0.0134) \n","Epoch 4 - avg_train_loss: 0.0072  avg_val_loss: 0.0134  time: 318s\n","Epoch 4 - Score: 0.8770\n","Epoch 4 - Save Best Score: 0.8770 Model\n","Epoch: [5][0/1425] Elapsed 0m 0s (remain 11m 38s) Loss: 0.0002(0.0002) Grad: 1798.9476  LR: 0.000004  \n","Epoch: [5][100/1425] Elapsed 0m 20s (remain 4m 32s) Loss: 0.0032(0.0061) Grad: 11442.6406  LR: 0.000004  \n","Epoch: [5][200/1425] Elapsed 0m 40s (remain 4m 9s) Loss: 0.0023(0.0058) Grad: 16424.9727  LR: 0.000004  \n","Epoch: [5][300/1425] Elapsed 1m 1s (remain 3m 48s) Loss: 0.0020(0.0063) Grad: 5683.0146  LR: 0.000004  \n","Epoch: [5][400/1425] Elapsed 1m 21s (remain 3m 28s) Loss: 0.0023(0.0060) Grad: 12946.2969  LR: 0.000003  \n","Epoch: [5][500/1425] Elapsed 1m 41s (remain 3m 7s) Loss: 0.0008(0.0059) Grad: 10891.0352  LR: 0.000003  \n","Epoch: [5][600/1425] Elapsed 2m 1s (remain 2m 47s) Loss: 0.0000(0.0059) Grad: 92.4117  LR: 0.000003  \n","Epoch: [5][700/1425] Elapsed 2m 21s (remain 2m 26s) Loss: 0.0019(0.0059) Grad: 11104.6689  LR: 0.000002  \n","Epoch: [5][800/1425] Elapsed 2m 42s (remain 2m 6s) Loss: 0.0017(0.0059) Grad: 7769.0571  LR: 0.000002  \n","Epoch: [5][900/1425] Elapsed 3m 2s (remain 1m 46s) Loss: 0.0014(0.0059) Grad: 3756.0969  LR: 0.000002  \n","Epoch: [5][1000/1425] Elapsed 3m 22s (remain 1m 25s) Loss: 0.0110(0.0058) Grad: 24964.6719  LR: 0.000001  \n","Epoch: [5][1100/1425] Elapsed 3m 42s (remain 1m 5s) Loss: 0.0149(0.0059) Grad: 40572.7500  LR: 0.000001  \n","Epoch: [5][1200/1425] Elapsed 4m 3s (remain 0m 45s) Loss: 0.0005(0.0058) Grad: 2498.5408  LR: 0.000001  \n","Epoch: [5][1300/1425] Elapsed 4m 23s (remain 0m 25s) Loss: 0.0041(0.0059) Grad: 7759.8730  LR: 0.000000  \n","Epoch: [5][1400/1425] Elapsed 4m 43s (remain 0m 4s) Loss: 0.0026(0.0060) Grad: 6023.1509  LR: 0.000000  \n","Epoch: [5][1424/1425] Elapsed 4m 48s (remain 0m 0s) Loss: 0.0010(0.0060) Grad: 3294.6787  LR: 0.000000  \n","EVAL: [0/363] Elapsed 0m 0s (remain 1m 49s) Loss: 0.0392(0.0392) \n","EVAL: [100/363] Elapsed 0m 7s (remain 0m 18s) Loss: 0.0101(0.0159) \n","EVAL: [200/363] Elapsed 0m 14s (remain 0m 11s) Loss: 0.1775(0.0162) \n","EVAL: [300/363] Elapsed 0m 21s (remain 0m 4s) Loss: 0.0209(0.0159) \n","EVAL: [362/363] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0116(0.0144) \n","Epoch 5 - avg_train_loss: 0.0060  avg_val_loss: 0.0144  time: 318s\n","Epoch 5 - Score: 0.8791\n","Epoch 5 - Save Best Score: 0.8791 Model\n","Best thres: 0.5, Score: 0.8766\n","Best thres: 0.5092773437499999, Score: 0.8767\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90a2dadeee5d4cb4ba6af4860fe576aa","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/533M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e83e2c3999ff46f19fa744f209411c0f","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _ConnectionBase.__del__ at 0x7fe40a24b680>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ee1ac6a49f34e7c8bfbc87ce82a3ea5","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _ConnectionBase.__del__ at 0x7fe40a24b680>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2b84eb757524b878fb3c8752dabaab2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2480afafca546318889db993bfefb76","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18fc71b27e9d4d00a5e27b93dbfb178a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"],"id":"1d4fcf7c"}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","name":"nbme-exp012.ipynb","provenance":[{"file_id":"1v3I41Ql3KDNAvGIfYb7iRVxyrfNb1VXn","timestamp":1646219594965}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dc08d28ab4de455e8515bae7b79a6ff8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_366c244f9828468eb381ca33a4d57d4b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f73a4c7a6ce4cdf86ceec75694527d2","IPY_MODEL_c5d2d3ce1df2455bbc7998cf60de2051","IPY_MODEL_d9664db31b384a089f67fb7b9ea11647"]}},"366c244f9828468eb381ca33a4d57d4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f73a4c7a6ce4cdf86ceec75694527d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_74a80f81666545d7b785fe94c2af7c3c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d1b8577c26f4723875d773da23d0d13"}},"c5d2d3ce1df2455bbc7998cf60de2051":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d0ec1014b38d46d0a1a9e05d20548d90","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":42146,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":42146,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c48f4353ed254cbf9263c9642ff011ab"}},"d9664db31b384a089f67fb7b9ea11647":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7b3d19f4b6e2458fb1510dc577d02ed2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 42146/42146 [00:22&lt;00:00, 2030.85it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8365d28f3744bc3a98e8611891280f2"}},"74a80f81666545d7b785fe94c2af7c3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0d1b8577c26f4723875d773da23d0d13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0ec1014b38d46d0a1a9e05d20548d90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c48f4353ed254cbf9263c9642ff011ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b3d19f4b6e2458fb1510dc577d02ed2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f8365d28f3744bc3a98e8611891280f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df88eb274e2b4deab95ddfe4739870f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c12cb20d86f438f84d8f207838506a9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b65dc35755d4041a82f6993c3747e90","IPY_MODEL_1677e687dac8414eaf5f0efef3a07036","IPY_MODEL_739582965a6e488dbc716e5b8ec3f5b0"]}},"2c12cb20d86f438f84d8f207838506a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b65dc35755d4041a82f6993c3747e90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e29b4bb5028a48e6bb9951640a277a12","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9dd2073aefe44ff99f840186390fa44e"}},"1677e687dac8414eaf5f0efef3a07036":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_df0c2c48a5e54daba9205d2a658c5e4f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":143,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":143,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce3acb0fbc174ddb8a64c8bc1f57f745"}},"739582965a6e488dbc716e5b8ec3f5b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_af6c7e7fac534c33ab401702a83d8fd7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 143/143 [00:00&lt;00:00, 2840.14it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4775739b55a44a4ab3a2a298fb0fa3d4"}},"e29b4bb5028a48e6bb9951640a277a12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9dd2073aefe44ff99f840186390fa44e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df0c2c48a5e54daba9205d2a658c5e4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce3acb0fbc174ddb8a64c8bc1f57f745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af6c7e7fac534c33ab401702a83d8fd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4775739b55a44a4ab3a2a298fb0fa3d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90a2dadeee5d4cb4ba6af4860fe576aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a85fbf125d55450a8c308f6b9edb4655","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a640ac8f4bff4ea990cf17be9fcf45da","IPY_MODEL_cb9754be74a846999089e98a72b9e0de","IPY_MODEL_a7fff4c1a6a04c18a15164c2dd934b24"]}},"a85fbf125d55450a8c308f6b9edb4655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a640ac8f4bff4ea990cf17be9fcf45da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_540402ececad40668f4d9abc5eb6b242","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8a6a95525384218b769ec55192d96d3"}},"cb9754be74a846999089e98a72b9e0de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_68ef69afaf58424b98377a152cc537c3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":558614189,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":558614189,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68d63b3d8c35432bb43912cbbb57d0b2"}},"a7fff4c1a6a04c18a15164c2dd934b24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4131c55bf6a946ca8b0adaf776215b50","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 533M/533M [00:09&lt;00:00, 58.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8698bafd0804e2ea59ba3674b998c2b"}},"540402ececad40668f4d9abc5eb6b242":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c8a6a95525384218b769ec55192d96d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68ef69afaf58424b98377a152cc537c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"68d63b3d8c35432bb43912cbbb57d0b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4131c55bf6a946ca8b0adaf776215b50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b8698bafd0804e2ea59ba3674b998c2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e83e2c3999ff46f19fa744f209411c0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6fe09aba0db3458c85e99eccc2fa4b71","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b1b60f62e13f4df88dba4ca83e6c180e","IPY_MODEL_b19a59f036a54849a56a25a4a2c6b86f","IPY_MODEL_22f883353bcd4f00839891c39bc40b41"]}},"6fe09aba0db3458c85e99eccc2fa4b71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1b60f62e13f4df88dba4ca83e6c180e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69307e3131664b99ba16ce8cbbcb2c6f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dedda3ce6a8c49fc9aec75c5322b9074"}},"b19a59f036a54849a56a25a4a2c6b86f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_104f1edfadd44922934cc92ee5fcde05","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9805f4ade6f414c9ccd51893ff6063d"}},"22f883353bcd4f00839891c39bc40b41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a26f140ccf92424da864d30babfa0246","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  1.83it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6605c466a4544d488ee926012fcadee"}},"69307e3131664b99ba16ce8cbbcb2c6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dedda3ce6a8c49fc9aec75c5322b9074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"104f1edfadd44922934cc92ee5fcde05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f9805f4ade6f414c9ccd51893ff6063d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a26f140ccf92424da864d30babfa0246":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e6605c466a4544d488ee926012fcadee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ee1ac6a49f34e7c8bfbc87ce82a3ea5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_610615cd26764488b43776aea99ec076","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1773bbbe75445148659907842d0c807","IPY_MODEL_b38ea71e8f19422aa6db4efedd017d7b","IPY_MODEL_a4358ad3016b45b98a35407460be45e3"]}},"610615cd26764488b43776aea99ec076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1773bbbe75445148659907842d0c807":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1847689845ec492c91100da5be6a0f84","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e87490510684cb8b4588211901e5677"}},"b38ea71e8f19422aa6db4efedd017d7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_06a7d16b110a4a7d8b89291fe32b48f1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d64a12b9d9347be97aad7e956246812"}},"a4358ad3016b45b98a35407460be45e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6a84ebd77654759bec9128aac82d218","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  1.82it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7db0a0d259824d34ba7062a0ea25ce98"}},"1847689845ec492c91100da5be6a0f84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7e87490510684cb8b4588211901e5677":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06a7d16b110a4a7d8b89291fe32b48f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3d64a12b9d9347be97aad7e956246812":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6a84ebd77654759bec9128aac82d218":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7db0a0d259824d34ba7062a0ea25ce98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2b84eb757524b878fb3c8752dabaab2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_77f817d15df64029ab5a5e528af6f1da","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ea934ed84a1f44e4abc5fd79db00ecb3","IPY_MODEL_a1ce042e6c56493c87feaf4251e6af58","IPY_MODEL_b9535d5087414384aea1ce819ec6cbce"]}},"77f817d15df64029ab5a5e528af6f1da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea934ed84a1f44e4abc5fd79db00ecb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cf01397a564b4fa5aeb132b3b153c9cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a01322d1f11943369c09e572f3b09a64"}},"a1ce042e6c56493c87feaf4251e6af58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dacfe663f1ba4002a9b2f4d44e3952e7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_246b83d3a63b4615849bc5a6581c8b66"}},"b9535d5087414384aea1ce819ec6cbce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_691eb99a632e4fcf9b214f115a42ed1d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  1.83it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fbb4f2d6c42649edabacfcdb668ada67"}},"cf01397a564b4fa5aeb132b3b153c9cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a01322d1f11943369c09e572f3b09a64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dacfe663f1ba4002a9b2f4d44e3952e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"246b83d3a63b4615849bc5a6581c8b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"691eb99a632e4fcf9b214f115a42ed1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fbb4f2d6c42649edabacfcdb668ada67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2480afafca546318889db993bfefb76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_31bdec5656bc4ccf86b6dd5d772546e1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c4b97f004dc54b7aac3a9e21ec002886","IPY_MODEL_6efd490a0078413ea07b72b8a29317ae","IPY_MODEL_1a1c4e08b1c34da294155a99afcc0689"]}},"31bdec5656bc4ccf86b6dd5d772546e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4b97f004dc54b7aac3a9e21ec002886":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_79657b26ee3c423b98ccc605490a29db","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ca9206d0fc0b404da0b237c5e3a763b6"}},"6efd490a0078413ea07b72b8a29317ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_735706dc57764b2c85a290a54337a053","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc652652304642a4b8ebcd21969da42c"}},"1a1c4e08b1c34da294155a99afcc0689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64c42d1e38d14ecd82cdb1f86556ad68","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  1.70it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04e8bebf566f4d069bb7b874a543f780"}},"79657b26ee3c423b98ccc605490a29db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ca9206d0fc0b404da0b237c5e3a763b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"735706dc57764b2c85a290a54337a053":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dc652652304642a4b8ebcd21969da42c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64c42d1e38d14ecd82cdb1f86556ad68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04e8bebf566f4d069bb7b874a543f780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"18fc71b27e9d4d00a5e27b93dbfb178a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_66d296cbb1384b1ab60784ee3dc46f9f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_035b90ea0bf943e6acd78f7d008ce1de","IPY_MODEL_0033236b7f0443fb90a87f6cff1ac5cf","IPY_MODEL_1f1ba0f6b2ac47c5bfcd0aa2e503870d"]}},"66d296cbb1384b1ab60784ee3dc46f9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"035b90ea0bf943e6acd78f7d008ce1de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea2bee5ceee94a73986ec18c925b64fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_28f2743e386b4393a66e6d3eddf63bf3"}},"0033236b7f0443fb90a87f6cff1ac5cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0f37d2ed31f941f5ac450fb2e6b0cb71","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0b07ea69dfe48ce86f8ff313e76d222"}},"1f1ba0f6b2ac47c5bfcd0aa2e503870d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bbb700c0e7c746949786568d367a0df6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  1.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7607294bb4b54b158ddec68fa2df2cc1"}},"ea2bee5ceee94a73986ec18c925b64fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"28f2743e386b4393a66e6d3eddf63bf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f37d2ed31f941f5ac450fb2e6b0cb71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c0b07ea69dfe48ce86f8ff313e76d222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bbb700c0e7c746949786568d367a0df6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7607294bb4b54b158ddec68fa2df2cc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":5}