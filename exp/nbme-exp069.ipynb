{"cells":[{"cell_type":"markdown","metadata":{"id":"colored-security"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"educational-operator"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","metadata":{"id":"incorrect-greek"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1648688885036,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"alive-granny"},"outputs":[],"source":["EXP_NAME = \"nbme-exp069\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1648688885037,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"heavy-prophet"},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    max_char_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0]  # [0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1648688885038,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"vocational-coating"},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","metadata":{"id":"private-moderator"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30694,"status":"ok","timestamp":1648688915723,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"married-tokyo","outputId":"fc2255a4-e66e-4e26-c396-8cc0f53eb4bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["colab\n","Mounted at /content/drive\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 5.1 MB/s \n","\u001b[?25hCollecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,\u003e=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 74.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Collecting pyyaml\u003e=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 69.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 62.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.16.2) (3.7.0)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8073,"status":"ok","timestamp":1648688923790,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"blank-pierre"},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"sound-still"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1648688923790,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"surprised-commercial"},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688924178,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"interstate-accident"},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -\u003e [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) \u003e 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        # result = np.where(char_prob \u003e= th)[0] + 1\n","        result = np.where(char_prob \u003e= th)[0]\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        # result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = [f\"{min(r)} {max(r) + 1}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5, use_token_prob=True):\n","    labels = create_labels_for_scoring(df)\n","\n","    if use_token_prob:\n","        token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","        char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    else:\n","        char_probs = df[[str(i) for i in range(CFG.max_char_len)]].values\n","        char_probs = [char_probs[i] for i in range(len(char_probs))]\n","\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688924179,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"coated-pioneer"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1648688924179,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"nervous-delaware"},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","metadata":{"id":"functioning-destruction"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2383,"status":"ok","timestamp":1648688926558,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"global-monte","outputId":"ccf5d89d-24ab-404c-c8a5-5081e947814a"},"outputs":[{"data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1648688926559,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"independent-airfare"},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","metadata":{"id":"silent-locator"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648688926559,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"unusual-fifty"},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1648688926830,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"decreased-mustang","outputId":"25af362a-76aa-498d-b3a6-75d30c7c8c2e"},"outputs":[{"data":{"text/plain":["((14300, 8), (5, 6))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1648688926830,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"boolean-trade"},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1648688926831,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"accomplished-dakota","outputId":"73281bf6-d9f1-4b67-a759-f8f70fc1675e"},"outputs":[{"data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","metadata":{"id":"funded-elizabeth"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1648688926831,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"unexpected-columbia","outputId":"5781c937-b5b5-4db9-cc3d-07f29ccb0c7f"},"outputs":[{"data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"critical-archive"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"elapsed":2226,"status":"ok","timestamp":1648688929050,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"broken-generator","outputId":"04af37e3-9d82-4a6b-9e3e-c0a000f6acb3"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d294e635ddf14ec0831f4a6cdc3a7f80","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff4aef2d05a540ebb260439490c49170","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/475 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b77229ea506442c9abe6edd4f15ccd2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea110d1497a04a1c9b0ac7162dc4de15","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"compatible-lincoln"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":22161,"status":"ok","timestamp":1648688951203,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"fluid-nancy","outputId":"dac7b05b-954f-4893-e041-e62fb7f71013"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e585ba85b464611b206bfb9286d63ac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42146 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951203,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"posted-humidity","outputId":"2a32b9f6-d151-401d-b76b-1aadd9d0c356"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb0f7af76c204ab99b31f53fbceb8ade","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648688951203,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"resistant-amount","outputId":"9b51aeae-b7c3-4f9d-8354-b8a917f44d80"},"outputs":[{"name":"stdout","output_type":"stream","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls \u0026 sep \u0026 sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1648688951691,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"be6XpsR0aIWS","outputId":"a3752c0b-be1d-4899-cbd5-29856399d167"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f8fc355f6794bf2912c92f647599f04","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42146 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 950\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(text)\n","    pn_history_lengths.append(length)\n","\n","CFG.max_char_len = max(pn_history_lengths)\n","\n","print(\"max length:\", CFG.max_char_len)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951692,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"fIzpppqiaMRn"},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df, pseudo_label=None):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.max_char_len = self.cfg.max_char_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","        if \"pseudo_idx\" in df.columns:\n","            self.pseudo_idx = self.df[\"pseudo_idx\"].values\n","            self.pseudo_label = pseudo_label\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        label = np.zeros(self.max_char_len)\n","        label[len(pn_history):] = -1\n","        if annotation_length \u003e 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    label[start:end] = 1\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        if not np.isnan(self.annotation_lengths[idx]):\n","            label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        else:\n","            p_idx = int(self.pseudo_idx[idx])\n","            label = torch.tensor(self.pseudo_label[p_idx], dtype=torch.float)\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, label, mapping_from_token_to_char"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951692,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"weird-interaction"},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.max_char_len = self.cfg.max_char_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, mapping_from_token_to_char"]},{"cell_type":"markdown","metadata":{"id":"upper-mobility"},"source":["## Model"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1648688951692,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"spanish-destruction"},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.lstm = nn.GRU(\n","            input_size=self.model_config.hidden_size,\n","            bidirectional=True,\n","            hidden_size=self.model_config.hidden_size // 2,\n","            num_layers=4,\n","            dropout=self.cfg.dropout,\n","            batch_first=True,\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs, mappings_from_token_to_char):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]  # [batch, seq_len, d_model]\n","        mappings_from_token_to_char = mappings_from_token_to_char.unsqueeze(2).expand(-1, -1, self.model_config.hidden_size)\n","        h = torch.gather(h, 1, mappings_from_token_to_char)    # [batch, seq_len, d_model]\n","        h, _ = self.lstm(h)\n","        output = self.fc(h)\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"chronic-bullet"},"source":["## Training"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951693,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"biological-hunger"},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    del output, loss, inputs, labels, mappings_from_token_to_char, scaler, grad_norm; gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951693,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"satisfied-sterling"},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","    \n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951693,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"incorporate-viking"},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for (inputs, mappings_from_token_to_char) in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.no_grad():\n","            output = model(inputs, mappings_from_token_to_char)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951693,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"dental-sunset"},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    pseudo_plain_path = './drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl'\n","    pseudo_plain = pd.read_pickle(pseudo_plain_path)\n","    pseudo_label_path = f'./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_{i_fold}.npy'\n","    pseudo_label = np.load(pseudo_label_path)\n","    print(f\"get pseudo plain from {pseudo_plain_path}\")\n","    print(f\"get pseudo labels from {pseudo_label_path}\")\n","    print(pseudo_plain.shape, pseudo_label.shape)\n","    pseudo_plain[\"pseudo_idx\"] = np.arange(len(pseudo_plain))\n","    pseudo_plain = pseudo_plain.sample(n=300000, random_state=i_fold)\n","    print(pseudo_plain.shape)\n","    train_folds = pd.concat([train_folds, pseudo_plain], axis=0, ignore_index=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds, pseudo_label)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_char_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5, use_token_prob=False)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score \u003e best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","        ##################################### debug #####################################\n","        break\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_char_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","metadata":{"id":"brazilian-graphics"},"source":["## Main"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648688951694,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"},"user_tz":-540},"id":"connected-protein"},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    best_thres = 0.5\n","    best_score = 0.\n","    for th in np.arange(0.45, 0.55, 0.01):\n","        th = np.round(th, 2)\n","        score = scoring(oof_df, th=th, use_token_prob=False)\n","        if best_score \u003c score:\n","            best_thres = th\n","            best_score = score\n","    print(f\"best_thres: {best_thres}  score: {best_score:.5f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            print(f\"load weights from {path}\")\n","            test_char_probs = inference_fn(test_dataloader, model, device)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_char_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"serious-bunny"},"outputs":[{"name":"stdout","output_type":"stream","text":["========== fold: 0 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_0.npy\n","(612602, 6) (612602, 950)\n","(300000, 7)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/103575] Elapsed 0m 1s (remain 2115m 50s) Loss: 0.3522(0.3522) Grad: 99220.9375  LR: 0.000000  \n","Epoch: [1][100/103575] Elapsed 1m 3s (remain 1088m 36s) Loss: 0.3478(0.3518) Grad: 47061.5312  LR: 0.000000  \n","Epoch: [1][200/103575] Elapsed 2m 6s (remain 1082m 26s) Loss: 0.3507(0.3504) Grad: 47360.5312  LR: 0.000000  \n","Epoch: [1][300/103575] Elapsed 3m 8s (remain 1077m 42s) Loss: 0.3374(0.3473) Grad: 24149.7383  LR: 0.000000  \n","Epoch: [1][400/103575] Elapsed 4m 10s (remain 1074m 45s) Loss: 0.3183(0.3426) Grad: 22420.4609  LR: 0.000000  \n","Epoch: [1][500/103575] Elapsed 5m 12s (remain 1073m 11s) Loss: 0.3048(0.3366) Grad: 21540.5977  LR: 0.000000  \n","Epoch: [1][600/103575] Elapsed 6m 15s (remain 1071m 9s) Loss: 0.2754(0.3295) Grad: 21773.5566  LR: 0.000000  \n","Epoch: [1][700/103575] Elapsed 7m 17s (remain 1069m 40s) Loss: 0.2629(0.3215) Grad: 19780.0605  LR: 0.000000  \n","Epoch: [1][800/103575] Elapsed 8m 19s (remain 1068m 11s) Loss: 0.2355(0.3125) Grad: 19994.5430  LR: 0.000000  \n","Epoch: [1][900/103575] Elapsed 9m 21s (remain 1067m 3s) Loss: 0.2107(0.3027) Grad: 17937.7520  LR: 0.000000  \n","Epoch: [1][1000/103575] Elapsed 10m 24s (remain 1065m 42s) Loss: 0.1746(0.2920) Grad: 17931.0957  LR: 0.000000  \n","Epoch: [1][1100/103575] Elapsed 11m 26s (remain 1064m 31s) Loss: 0.1423(0.2807) Grad: 16317.8223  LR: 0.000000  \n","Epoch: [1][1200/103575] Elapsed 12m 28s (remain 1063m 49s) Loss: 0.1154(0.2689) Grad: 13899.4766  LR: 0.000000  \n","Epoch: [1][1300/103575] Elapsed 13m 31s (remain 1063m 3s) Loss: 0.1004(0.2567) Grad: 11369.9062  LR: 0.000001  \n","Epoch: [1][1400/103575] Elapsed 14m 33s (remain 1062m 4s) Loss: 0.0658(0.2442) Grad: 4042.2012  LR: 0.000001  \n","Epoch: [1][1500/103575] Elapsed 15m 36s (remain 1061m 10s) Loss: 0.0547(0.2319) Grad: 2045.4319  LR: 0.000001  \n","Epoch: [1][1600/103575] Elapsed 16m 38s (remain 1060m 18s) Loss: 0.0871(0.2203) Grad: 789.5290  LR: 0.000001  \n","Epoch: [1][1700/103575] Elapsed 17m 41s (remain 1059m 50s) Loss: 0.0117(0.2096) Grad: 1162.5232  LR: 0.000001  \n","Epoch: [1][1800/103575] Elapsed 18m 44s (remain 1059m 15s) Loss: 0.0254(0.2000) Grad: 396.3381  LR: 0.000001  \n","Epoch: [1][1900/103575] Elapsed 19m 47s (remain 1058m 28s) Loss: 0.0490(0.1914) Grad: 494.0608  LR: 0.000001  \n","Epoch: [1][2000/103575] Elapsed 20m 50s (remain 1057m 33s) Loss: 0.0366(0.1835) Grad: 272.3146  LR: 0.000001  \n","Epoch: [1][2100/103575] Elapsed 21m 53s (remain 1056m 56s) Loss: 0.0664(0.1765) Grad: 1093.5383  LR: 0.000001  \n","Epoch: [1][2200/103575] Elapsed 22m 55s (remain 1055m 47s) Loss: 0.0133(0.1701) Grad: 644.6237  LR: 0.000001  \n","Epoch: [1][2300/103575] Elapsed 23m 57s (remain 1054m 31s) Loss: 0.0314(0.1644) Grad: 542.8251  LR: 0.000001  \n","Epoch: [1][2400/103575] Elapsed 25m 0s (remain 1053m 29s) Loss: 0.0293(0.1592) Grad: 535.5516  LR: 0.000001  \n","Epoch: [1][2500/103575] Elapsed 26m 1s (remain 1052m 5s) Loss: 0.0178(0.1542) Grad: 591.2119  LR: 0.000001  \n","Epoch: [1][2600/103575] Elapsed 27m 4s (remain 1050m 50s) Loss: 0.0266(0.1495) Grad: 935.6912  LR: 0.000001  \n","Epoch: [1][2700/103575] Elapsed 28m 6s (remain 1049m 41s) Loss: 0.0300(0.1453) Grad: 1210.8838  LR: 0.000001  \n","Epoch: [1][2800/103575] Elapsed 29m 8s (remain 1048m 41s) Loss: 0.0147(0.1411) Grad: 971.7159  LR: 0.000001  \n","Epoch: [1][2900/103575] Elapsed 30m 11s (remain 1047m 37s) Loss: 0.0250(0.1371) Grad: 3631.7874  LR: 0.000001  \n","Epoch: [1][3000/103575] Elapsed 31m 13s (remain 1046m 33s) Loss: 0.0336(0.1333) Grad: 2955.4890  LR: 0.000001  \n","Epoch: [1][3100/103575] Elapsed 32m 16s (remain 1045m 40s) Loss: 0.0093(0.1297) Grad: 4966.2358  LR: 0.000001  \n","Epoch: [1][3200/103575] Elapsed 33m 19s (remain 1044m 46s) Loss: 0.0167(0.1263) Grad: 5081.0879  LR: 0.000001  \n","Epoch: [1][3300/103575] Elapsed 34m 21s (remain 1043m 35s) Loss: 0.0039(0.1230) Grad: 103.3891  LR: 0.000001  \n","Epoch: [1][3400/103575] Elapsed 35m 23s (remain 1042m 28s) Loss: 0.0073(0.1200) Grad: 556.7313  LR: 0.000001  \n","Epoch: [1][3500/103575] Elapsed 36m 25s (remain 1041m 23s) Loss: 0.0058(0.1171) Grad: 701.1356  LR: 0.000001  \n","Epoch: [1][3600/103575] Elapsed 37m 28s (remain 1040m 18s) Loss: 0.0140(0.1143) Grad: 2617.4006  LR: 0.000001  \n","Epoch: [1][3700/103575] Elapsed 38m 30s (remain 1039m 8s) Loss: 0.0511(0.1117) Grad: 1888.3518  LR: 0.000001  \n","Epoch: [1][3800/103575] Elapsed 39m 32s (remain 1038m 2s) Loss: 0.0122(0.1092) Grad: 1160.3860  LR: 0.000001  \n","Epoch: [1][3900/103575] Elapsed 40m 35s (remain 1036m 56s) Loss: 0.0056(0.1067) Grad: 374.4210  LR: 0.000002  \n","Epoch: [1][4000/103575] Elapsed 41m 37s (remain 1035m 44s) Loss: 0.0045(0.1044) Grad: 265.1309  LR: 0.000002  \n","Epoch: [1][4100/103575] Elapsed 42m 39s (remain 1034m 40s) Loss: 0.0094(0.1022) Grad: 270.6099  LR: 0.000002  \n","Epoch: [1][4200/103575] Elapsed 43m 41s (remain 1033m 33s) Loss: 0.0007(0.1001) Grad: 61.2586  LR: 0.000002  \n","Epoch: [1][4300/103575] Elapsed 44m 43s (remain 1032m 27s) Loss: 0.0145(0.0981) Grad: 678.2711  LR: 0.000002  \n","Epoch: [1][4400/103575] Elapsed 45m 46s (remain 1031m 23s) Loss: 0.0020(0.0961) Grad: 172.6290  LR: 0.000002  \n","Epoch: [1][4500/103575] Elapsed 46m 48s (remain 1030m 27s) Loss: 0.0095(0.0943) Grad: 464.9246  LR: 0.000002  \n","Epoch: [1][4600/103575] Elapsed 47m 51s (remain 1029m 25s) Loss: 0.0127(0.0925) Grad: 823.9638  LR: 0.000002  \n","Epoch: [1][4700/103575] Elapsed 48m 53s (remain 1028m 26s) Loss: 0.0108(0.0907) Grad: 1039.1591  LR: 0.000002  \n","Epoch: [1][4800/103575] Elapsed 49m 56s (remain 1027m 22s) Loss: 0.0064(0.0891) Grad: 738.2568  LR: 0.000002  \n","Epoch: [1][4900/103575] Elapsed 50m 58s (remain 1026m 20s) Loss: 0.0062(0.0874) Grad: 1007.4619  LR: 0.000002  \n","Epoch: [1][5000/103575] Elapsed 52m 0s (remain 1025m 17s) Loss: 0.0058(0.0859) Grad: 143.6897  LR: 0.000002  \n","Epoch: [1][5100/103575] Elapsed 53m 3s (remain 1024m 11s) Loss: 0.0113(0.0844) Grad: 707.1419  LR: 0.000002  \n","Epoch: [1][5200/103575] Elapsed 54m 6s (remain 1023m 22s) Loss: 0.0064(0.0830) Grad: 229.3253  LR: 0.000002  \n","Epoch: [1][5300/103575] Elapsed 55m 9s (remain 1022m 37s) Loss: 0.0027(0.0815) Grad: 314.4016  LR: 0.000002  \n","Epoch: [1][5400/103575] Elapsed 56m 11s (remain 1021m 30s) Loss: 0.0215(0.0802) Grad: 1050.9723  LR: 0.000002  \n","Epoch: [1][5500/103575] Elapsed 57m 14s (remain 1020m 26s) Loss: 0.0165(0.0789) Grad: 1349.5304  LR: 0.000002  \n","Epoch: [1][5600/103575] Elapsed 58m 16s (remain 1019m 19s) Loss: 0.0235(0.0777) Grad: 4812.7046  LR: 0.000002  \n","Epoch: [1][5700/103575] Elapsed 59m 18s (remain 1018m 13s) Loss: 0.0210(0.0765) Grad: 1756.8224  LR: 0.000002  \n","Epoch: [1][5800/103575] Elapsed 60m 21s (remain 1017m 12s) Loss: 0.0028(0.0753) Grad: 500.6354  LR: 0.000002  \n","Epoch: [1][5900/103575] Elapsed 61m 23s (remain 1016m 9s) Loss: 0.0117(0.0741) Grad: 489.2494  LR: 0.000002  \n","Epoch: [1][6000/103575] Elapsed 62m 25s (remain 1015m 6s) Loss: 0.0055(0.0730) Grad: 179.2806  LR: 0.000002  \n","Epoch: [1][6100/103575] Elapsed 63m 28s (remain 1014m 3s) Loss: 0.0066(0.0720) Grad: 612.8975  LR: 0.000002  \n","Epoch: [1][6200/103575] Elapsed 64m 30s (remain 1012m 56s) Loss: 0.0114(0.0709) Grad: 878.1706  LR: 0.000002  \n","Epoch: [1][6300/103575] Elapsed 65m 32s (remain 1011m 53s) Loss: 0.0059(0.0699) Grad: 536.6089  LR: 0.000002  \n","Epoch: [1][6400/103575] Elapsed 66m 34s (remain 1010m 47s) Loss: 0.0013(0.0689) Grad: 79.8281  LR: 0.000002  \n","Epoch: [1][6500/103575] Elapsed 67m 37s (remain 1009m 40s) Loss: 0.0070(0.0679) Grad: 236.4893  LR: 0.000003  \n","Epoch: [1][6600/103575] Elapsed 68m 39s (remain 1008m 34s) Loss: 0.0046(0.0670) Grad: 658.1313  LR: 0.000003  \n","Epoch: [1][6700/103575] Elapsed 69m 41s (remain 1007m 27s) Loss: 0.0032(0.0661) Grad: 246.8035  LR: 0.000003  \n","Epoch: [1][6800/103575] Elapsed 70m 43s (remain 1006m 21s) Loss: 0.0104(0.0652) Grad: 704.9092  LR: 0.000003  \n","Epoch: [1][6900/103575] Elapsed 71m 46s (remain 1005m 22s) Loss: 0.0008(0.0644) Grad: 65.3438  LR: 0.000003  \n","Epoch: [1][7000/103575] Elapsed 72m 48s (remain 1004m 22s) Loss: 0.0140(0.0636) Grad: 2048.6121  LR: 0.000003  \n","Epoch: [1][7100/103575] Elapsed 73m 51s (remain 1003m 24s) Loss: 0.0011(0.0627) Grad: 62.2272  LR: 0.000003  \n","Epoch: [1][7200/103575] Elapsed 74m 53s (remain 1002m 24s) Loss: 0.0102(0.0620) Grad: 999.4974  LR: 0.000003  \n","Epoch: [1][7300/103575] Elapsed 75m 56s (remain 1001m 23s) Loss: 0.0025(0.0612) Grad: 141.1375  LR: 0.000003  \n","Epoch: [1][7400/103575] Elapsed 76m 58s (remain 1000m 18s) Loss: 0.0044(0.0605) Grad: 196.4494  LR: 0.000003  \n","Epoch: [1][7500/103575] Elapsed 78m 0s (remain 999m 13s) Loss: 0.0008(0.0597) Grad: 28.7256  LR: 0.000003  \n","Epoch: [1][7600/103575] Elapsed 79m 3s (remain 998m 10s) Loss: 0.0005(0.0590) Grad: 25.4829  LR: 0.000003  \n","Epoch: [1][7700/103575] Elapsed 80m 5s (remain 997m 5s) Loss: 0.0047(0.0583) Grad: 846.0035  LR: 0.000003  \n","Epoch: [1][7800/103575] Elapsed 81m 7s (remain 996m 1s) Loss: 0.0053(0.0576) Grad: 906.7896  LR: 0.000003  \n","Epoch: [1][7900/103575] Elapsed 82m 10s (remain 994m 58s) Loss: 0.0048(0.0570) Grad: 576.1157  LR: 0.000003  \n","Epoch: [1][8000/103575] Elapsed 83m 12s (remain 993m 56s) Loss: 0.0095(0.0563) Grad: 851.4602  LR: 0.000003  \n","Epoch: [1][8100/103575] Elapsed 84m 14s (remain 992m 54s) Loss: 0.0065(0.0557) Grad: 936.9659  LR: 0.000003  \n","Epoch: [1][8200/103575] Elapsed 85m 17s (remain 991m 50s) Loss: 0.0022(0.0551) Grad: 300.0188  LR: 0.000003  \n","Epoch: [1][8300/103575] Elapsed 86m 19s (remain 990m 49s) Loss: 0.0050(0.0545) Grad: 1281.5564  LR: 0.000003  \n","Epoch: [1][8400/103575] Elapsed 87m 22s (remain 989m 46s) Loss: 0.0034(0.0539) Grad: 925.9254  LR: 0.000003  \n","Epoch: [1][8500/103575] Elapsed 88m 24s (remain 988m 45s) Loss: 0.0128(0.0534) Grad: 1614.9315  LR: 0.000003  \n","Epoch: [1][8600/103575] Elapsed 89m 26s (remain 987m 42s) Loss: 0.0022(0.0528) Grad: 794.9501  LR: 0.000003  \n","Epoch: [1][8700/103575] Elapsed 90m 29s (remain 986m 40s) Loss: 0.0004(0.0523) Grad: 65.6561  LR: 0.000003  \n","Epoch: [1][8800/103575] Elapsed 91m 31s (remain 985m 37s) Loss: 0.0083(0.0517) Grad: 1316.1876  LR: 0.000003  \n","Epoch: [1][8900/103575] Elapsed 92m 33s (remain 984m 32s) Loss: 0.0049(0.0512) Grad: 724.2059  LR: 0.000003  \n","Epoch: [1][9000/103575] Elapsed 93m 35s (remain 983m 25s) Loss: 0.0052(0.0507) Grad: 925.9177  LR: 0.000003  \n","Epoch: [1][9100/103575] Elapsed 94m 38s (remain 982m 22s) Loss: 0.0169(0.0502) Grad: 2525.4714  LR: 0.000004  \n","Epoch: [1][9200/103575] Elapsed 95m 40s (remain 981m 20s) Loss: 0.0021(0.0497) Grad: 108.3786  LR: 0.000004  \n","Epoch: [1][9300/103575] Elapsed 96m 42s (remain 980m 16s) Loss: 0.0035(0.0493) Grad: 1446.3629  LR: 0.000004  \n","Epoch: [1][9400/103575] Elapsed 97m 45s (remain 979m 13s) Loss: 0.0026(0.0488) Grad: 414.7004  LR: 0.000004  \n","Epoch: [1][9500/103575] Elapsed 98m 47s (remain 978m 8s) Loss: 0.0027(0.0483) Grad: 654.2157  LR: 0.000004  \n","Epoch: [1][9600/103575] Elapsed 99m 49s (remain 977m 3s) Loss: 0.0068(0.0479) Grad: 1213.6533  LR: 0.000004  \n","Epoch: [1][9700/103575] Elapsed 100m 51s (remain 976m 0s) Loss: 0.0021(0.0474) Grad: 552.9415  LR: 0.000004  \n","Epoch: [1][9800/103575] Elapsed 101m 54s (remain 975m 0s) Loss: 0.0056(0.0470) Grad: 3115.0544  LR: 0.000004  \n","Epoch: [1][9900/103575] Elapsed 102m 57s (remain 974m 3s) Loss: 0.0011(0.0466) Grad: 90.4227  LR: 0.000004  \n","Epoch: [1][10000/103575] Elapsed 104m 0s (remain 973m 13s) Loss: 0.0063(0.0461) Grad: 2351.5598  LR: 0.000004  \n","Epoch: [1][10100/103575] Elapsed 105m 4s (remain 972m 21s) Loss: 0.0008(0.0457) Grad: 1131.5565  LR: 0.000004  \n","Epoch: [1][10200/103575] Elapsed 106m 7s (remain 971m 22s) Loss: 0.0066(0.0453) Grad: 850.8511  LR: 0.000004  \n","Epoch: [1][10300/103575] Elapsed 107m 9s (remain 970m 20s) Loss: 0.0047(0.0449) Grad: 211.4009  LR: 0.000004  \n","Epoch: [1][10400/103575] Elapsed 108m 12s (remain 969m 20s) Loss: 0.0016(0.0445) Grad: 53.4879  LR: 0.000004  \n","Epoch: [1][10500/103575] Elapsed 109m 14s (remain 968m 15s) Loss: 0.0136(0.0442) Grad: 4865.1621  LR: 0.000004  \n","Epoch: [1][10600/103575] Elapsed 110m 16s (remain 967m 12s) Loss: 0.0005(0.0438) Grad: 20.3018  LR: 0.000004  \n","Epoch: [1][10700/103575] Elapsed 111m 19s (remain 966m 10s) Loss: 0.0036(0.0434) Grad: 591.0505  LR: 0.000004  \n","Epoch: [1][10800/103575] Elapsed 112m 21s (remain 965m 7s) Loss: 0.0013(0.0430) Grad: 184.8254  LR: 0.000004  \n","Epoch: [1][10900/103575] Elapsed 113m 23s (remain 964m 3s) Loss: 0.0018(0.0427) Grad: 331.6818  LR: 0.000004  \n","Epoch: [1][11000/103575] Elapsed 114m 26s (remain 962m 58s) Loss: 0.0034(0.0423) Grad: 1446.5856  LR: 0.000004  \n","Epoch: [1][11100/103575] Elapsed 115m 28s (remain 961m 53s) Loss: 0.0025(0.0420) Grad: 180.5977  LR: 0.000004  \n","Epoch: [1][11200/103575] Elapsed 116m 30s (remain 960m 49s) Loss: 0.0037(0.0417) Grad: 958.1434  LR: 0.000004  \n","Epoch: [1][11300/103575] Elapsed 117m 32s (remain 959m 46s) Loss: 0.0140(0.0413) Grad: 3908.7749  LR: 0.000004  \n","Epoch: [1][11400/103575] Elapsed 118m 35s (remain 958m 44s) Loss: 0.0032(0.0410) Grad: 306.9183  LR: 0.000004  \n","Epoch: [1][11500/103575] Elapsed 119m 37s (remain 957m 41s) Loss: 0.0031(0.0407) Grad: 192.1862  LR: 0.000004  \n","Epoch: [1][11600/103575] Elapsed 120m 39s (remain 956m 37s) Loss: 0.0084(0.0404) Grad: 3475.6804  LR: 0.000004  \n","Epoch: [1][11700/103575] Elapsed 121m 42s (remain 955m 35s) Loss: 0.0003(0.0400) Grad: 159.0677  LR: 0.000005  \n","Epoch: [1][11800/103575] Elapsed 122m 44s (remain 954m 33s) Loss: 0.0009(0.0397) Grad: 69.3386  LR: 0.000005  \n","Epoch: [1][11900/103575] Elapsed 123m 46s (remain 953m 30s) Loss: 0.0025(0.0394) Grad: 529.9146  LR: 0.000005  \n","Epoch: [1][12000/103575] Elapsed 124m 49s (remain 952m 25s) Loss: 0.0005(0.0391) Grad: 56.3243  LR: 0.000005  \n","Epoch: [1][12100/103575] Elapsed 125m 51s (remain 951m 24s) Loss: 0.0015(0.0388) Grad: 707.1875  LR: 0.000005  \n","Epoch: [1][12200/103575] Elapsed 126m 54s (remain 950m 23s) Loss: 0.0008(0.0386) Grad: 1494.3584  LR: 0.000005  \n","Epoch: [1][12300/103575] Elapsed 127m 56s (remain 949m 23s) Loss: 0.0105(0.0383) Grad: 2224.0193  LR: 0.000005  \n","Epoch: [1][12400/103575] Elapsed 128m 59s (remain 948m 21s) Loss: 0.0050(0.0380) Grad: 2218.2639  LR: 0.000005  \n","Epoch: [1][12500/103575] Elapsed 130m 1s (remain 947m 19s) Loss: 0.0002(0.0377) Grad: 51.7712  LR: 0.000005  \n","Epoch: [1][12600/103575] Elapsed 131m 4s (remain 946m 16s) Loss: 0.0027(0.0375) Grad: 3522.2646  LR: 0.000005  \n","Epoch: [1][12700/103575] Elapsed 132m 6s (remain 945m 13s) Loss: 0.0020(0.0372) Grad: 410.3629  LR: 0.000005  \n","Epoch: [1][12800/103575] Elapsed 133m 8s (remain 944m 11s) Loss: 0.0018(0.0369) Grad: 558.0236  LR: 0.000005  \n","Epoch: [1][12900/103575] Elapsed 134m 11s (remain 943m 7s) Loss: 0.0004(0.0367) Grad: 148.9866  LR: 0.000005  \n","Epoch: [1][13000/103575] Elapsed 135m 13s (remain 942m 4s) Loss: 0.0004(0.0364) Grad: 47.6944  LR: 0.000005  \n","Epoch: [1][13100/103575] Elapsed 136m 15s (remain 941m 1s) Loss: 0.0086(0.0362) Grad: 3316.1577  LR: 0.000005  \n","Epoch: [1][13200/103575] Elapsed 137m 17s (remain 939m 57s) Loss: 0.0002(0.0359) Grad: 14.7991  LR: 0.000005  \n","Epoch: [1][13300/103575] Elapsed 138m 20s (remain 938m 53s) Loss: 0.0019(0.0357) Grad: 2138.1887  LR: 0.000005  \n","Epoch: [1][13400/103575] Elapsed 139m 22s (remain 937m 50s) Loss: 0.0008(0.0355) Grad: 286.4907  LR: 0.000005  \n","Epoch: [1][13500/103575] Elapsed 140m 24s (remain 936m 47s) Loss: 0.0022(0.0352) Grad: 1049.7471  LR: 0.000005  \n","Epoch: [1][13600/103575] Elapsed 141m 27s (remain 935m 44s) Loss: 0.0003(0.0350) Grad: 22.5903  LR: 0.000005  \n","Epoch: [1][13700/103575] Elapsed 142m 29s (remain 934m 43s) Loss: 0.0038(0.0348) Grad: 1200.8524  LR: 0.000005  \n","Epoch: [1][13800/103575] Elapsed 143m 32s (remain 933m 44s) Loss: 0.0000(0.0345) Grad: 5.4173  LR: 0.000005  \n","Epoch: [1][13900/103575] Elapsed 144m 35s (remain 932m 43s) Loss: 0.0000(0.0343) Grad: 4.2960  LR: 0.000005  \n","Epoch: [1][14000/103575] Elapsed 145m 37s (remain 931m 42s) Loss: 0.0005(0.0341) Grad: 598.3511  LR: 0.000005  \n","Epoch: [1][14100/103575] Elapsed 146m 40s (remain 930m 44s) Loss: 0.0011(0.0339) Grad: 644.6160  LR: 0.000005  \n","Epoch: [1][14200/103575] Elapsed 147m 43s (remain 929m 44s) Loss: 0.0038(0.0337) Grad: 2999.7151  LR: 0.000005  \n","Epoch: [1][14300/103575] Elapsed 148m 46s (remain 928m 41s) Loss: 0.0003(0.0335) Grad: 53.4477  LR: 0.000006  \n","Epoch: [1][14400/103575] Elapsed 149m 48s (remain 927m 38s) Loss: 0.0001(0.0332) Grad: 11.3709  LR: 0.000006  \n","Epoch: [1][14500/103575] Elapsed 150m 50s (remain 926m 36s) Loss: 0.0013(0.0330) Grad: 758.0577  LR: 0.000006  \n","Epoch: [1][14600/103575] Elapsed 151m 53s (remain 925m 32s) Loss: 0.0038(0.0328) Grad: 3912.8845  LR: 0.000006  \n","Epoch: [1][14700/103575] Elapsed 152m 55s (remain 924m 31s) Loss: 0.0007(0.0326) Grad: 52.8003  LR: 0.000006  \n","Epoch: [1][14800/103575] Elapsed 153m 58s (remain 923m 29s) Loss: 0.0042(0.0324) Grad: 1949.4774  LR: 0.000006  \n","Epoch: [1][14900/103575] Elapsed 155m 0s (remain 922m 25s) Loss: 0.0002(0.0322) Grad: 18.5038  LR: 0.000006  \n","Epoch: [1][15000/103575] Elapsed 156m 2s (remain 921m 22s) Loss: 0.0057(0.0320) Grad: 2048.0278  LR: 0.000006  \n","Epoch: [1][15100/103575] Elapsed 157m 4s (remain 920m 18s) Loss: 0.0046(0.0318) Grad: 2122.1934  LR: 0.000006  \n","Epoch: [1][15200/103575] Elapsed 158m 7s (remain 919m 14s) Loss: 0.0109(0.0317) Grad: 12297.2695  LR: 0.000006  \n","Epoch: [1][15300/103575] Elapsed 159m 9s (remain 918m 12s) Loss: 0.0310(0.0315) Grad: 11569.8311  LR: 0.000006  \n","Epoch: [1][15400/103575] Elapsed 160m 11s (remain 917m 9s) Loss: 0.0154(0.0313) Grad: 8079.2563  LR: 0.000006  \n","Epoch: [1][15500/103575] Elapsed 161m 14s (remain 916m 7s) Loss: 0.0044(0.0311) Grad: 1424.6990  LR: 0.000006  \n","Epoch: [1][15600/103575] Elapsed 162m 16s (remain 915m 5s) Loss: 0.0007(0.0309) Grad: 899.6111  LR: 0.000006  \n","Epoch: [1][15700/103575] Elapsed 163m 19s (remain 914m 2s) Loss: 0.0002(0.0307) Grad: 126.0648  LR: 0.000006  \n","Epoch: [1][15800/103575] Elapsed 164m 21s (remain 912m 59s) Loss: 0.0029(0.0306) Grad: 2430.2693  LR: 0.000006  \n","Epoch: [1][15900/103575] Elapsed 165m 23s (remain 911m 55s) Loss: 0.0093(0.0304) Grad: 5615.6821  LR: 0.000006  \n","Epoch: [1][16000/103575] Elapsed 166m 25s (remain 910m 52s) Loss: 0.0016(0.0302) Grad: 1727.4651  LR: 0.000006  \n","Epoch: [1][16100/103575] Elapsed 167m 28s (remain 909m 49s) Loss: 0.0035(0.0301) Grad: 7695.8271  LR: 0.000006  \n","Epoch: [1][16200/103575] Elapsed 168m 30s (remain 908m 46s) Loss: 0.0000(0.0299) Grad: 5.6031  LR: 0.000006  \n","Epoch: [1][16300/103575] Elapsed 169m 32s (remain 907m 42s) Loss: 0.0086(0.0297) Grad: 3444.8616  LR: 0.000006  \n","Epoch: [1][16400/103575] Elapsed 170m 34s (remain 906m 39s) Loss: 0.0006(0.0296) Grad: 803.4059  LR: 0.000006  \n","Epoch: [1][16500/103575] Elapsed 171m 37s (remain 905m 36s) Loss: 0.0029(0.0294) Grad: 1450.2932  LR: 0.000006  \n","Epoch: [1][16600/103575] Elapsed 172m 39s (remain 904m 35s) Loss: 0.0066(0.0292) Grad: 4561.0352  LR: 0.000006  \n","Epoch: [1][16700/103575] Elapsed 173m 42s (remain 903m 33s) Loss: 0.0003(0.0291) Grad: 292.0533  LR: 0.000006  \n","Epoch: [1][16800/103575] Elapsed 174m 44s (remain 902m 31s) Loss: 0.0037(0.0289) Grad: 2071.6372  LR: 0.000006  \n","Epoch: [1][16900/103575] Elapsed 175m 47s (remain 901m 29s) Loss: 0.0037(0.0288) Grad: 1757.0504  LR: 0.000007  \n","Epoch: [1][17000/103575] Elapsed 176m 50s (remain 900m 30s) Loss: 0.0001(0.0286) Grad: 19.9428  LR: 0.000007  \n","Epoch: [1][17100/103575] Elapsed 177m 52s (remain 899m 29s) Loss: 0.0034(0.0285) Grad: 1184.2510  LR: 0.000007  \n","Epoch: [1][17200/103575] Elapsed 178m 55s (remain 898m 27s) Loss: 0.0011(0.0283) Grad: 4928.7471  LR: 0.000007  \n","Epoch: [1][17300/103575] Elapsed 179m 58s (remain 897m 26s) Loss: 0.0012(0.0282) Grad: 649.8891  LR: 0.000007  \n","Epoch: [1][17400/103575] Elapsed 181m 0s (remain 896m 24s) Loss: 0.0007(0.0280) Grad: 300.5210  LR: 0.000007  \n","Epoch: [1][17500/103575] Elapsed 182m 3s (remain 895m 22s) Loss: 0.0001(0.0279) Grad: 20.4314  LR: 0.000007  \n","Epoch: [1][17600/103575] Elapsed 183m 5s (remain 894m 20s) Loss: 0.0003(0.0278) Grad: 162.0395  LR: 0.000007  \n","Epoch: [1][17700/103575] Elapsed 184m 8s (remain 893m 18s) Loss: 0.0001(0.0276) Grad: 57.3340  LR: 0.000007  \n","Epoch: [1][17800/103575] Elapsed 185m 10s (remain 892m 16s) Loss: 0.0025(0.0275) Grad: 1235.6917  LR: 0.000007  \n","Epoch: [1][17900/103575] Elapsed 186m 13s (remain 891m 15s) Loss: 0.0106(0.0273) Grad: 17080.8047  LR: 0.000007  \n","Epoch: [1][18000/103575] Elapsed 187m 15s (remain 890m 13s) Loss: 0.0000(0.0272) Grad: 13.1919  LR: 0.000007  \n","Epoch: [1][18100/103575] Elapsed 188m 18s (remain 889m 11s) Loss: 0.0089(0.0271) Grad: 6799.5493  LR: 0.000007  \n","Epoch: [1][18200/103575] Elapsed 189m 21s (remain 888m 10s) Loss: 0.0006(0.0270) Grad: 112.7596  LR: 0.000007  \n","Epoch: [1][18300/103575] Elapsed 190m 23s (remain 887m 10s) Loss: 0.0000(0.0268) Grad: 5.5729  LR: 0.000007  \n","Epoch: [1][18400/103575] Elapsed 191m 26s (remain 886m 10s) Loss: 0.0066(0.0267) Grad: 5306.3379  LR: 0.000007  \n","Epoch: [1][18500/103575] Elapsed 192m 29s (remain 885m 8s) Loss: 0.0005(0.0266) Grad: 70.7265  LR: 0.000007  \n","Epoch: [1][18600/103575] Elapsed 193m 31s (remain 884m 6s) Loss: 0.0004(0.0264) Grad: 282.3859  LR: 0.000007  \n","Epoch: [1][18700/103575] Elapsed 194m 34s (remain 883m 4s) Loss: 0.0001(0.0263) Grad: 9.3553  LR: 0.000007  \n","Epoch: [1][18800/103575] Elapsed 195m 37s (remain 882m 3s) Loss: 0.0017(0.0262) Grad: 1223.7252  LR: 0.000007  \n","Epoch: [1][18900/103575] Elapsed 196m 39s (remain 881m 1s) Loss: 0.0001(0.0261) Grad: 39.2860  LR: 0.000007  \n","Epoch: [1][19000/103575] Elapsed 197m 42s (remain 879m 59s) Loss: 0.0055(0.0259) Grad: 3327.2336  LR: 0.000007  \n","Epoch: [1][19100/103575] Elapsed 198m 45s (remain 878m 58s) Loss: 0.0004(0.0258) Grad: 75.1849  LR: 0.000007  \n","Epoch: [1][19200/103575] Elapsed 199m 47s (remain 877m 56s) Loss: 0.0043(0.0257) Grad: 2480.9163  LR: 0.000007  \n","Epoch: [1][19300/103575] Elapsed 200m 50s (remain 876m 55s) Loss: 0.0002(0.0256) Grad: 85.7475  LR: 0.000007  \n","Epoch: [1][19400/103575] Elapsed 201m 53s (remain 875m 55s) Loss: 0.0024(0.0255) Grad: 240.6042  LR: 0.000007  \n","Epoch: [1][19500/103575] Elapsed 202m 57s (remain 874m 58s) Loss: 0.0001(0.0253) Grad: 24.0103  LR: 0.000008  \n","Epoch: [1][19600/103575] Elapsed 204m 0s (remain 874m 0s) Loss: 0.0001(0.0252) Grad: 29.4306  LR: 0.000008  \n","Epoch: [1][19700/103575] Elapsed 205m 4s (remain 873m 3s) Loss: 0.0043(0.0251) Grad: 2725.2839  LR: 0.000008  \n","Epoch: [1][19800/103575] Elapsed 206m 7s (remain 872m 4s) Loss: 0.0094(0.0250) Grad: 17211.6992  LR: 0.000008  \n","Epoch: [1][19900/103575] Elapsed 207m 11s (remain 871m 6s) Loss: 0.0001(0.0249) Grad: 8.6263  LR: 0.000008  \n","Epoch: [1][20000/103575] Elapsed 208m 13s (remain 870m 5s) Loss: 0.0001(0.0248) Grad: 19.1503  LR: 0.000008  \n","Epoch: [1][20100/103575] Elapsed 209m 16s (remain 869m 3s) Loss: 0.0001(0.0247) Grad: 32.3017  LR: 0.000008  \n","Epoch: [1][20200/103575] Elapsed 210m 19s (remain 868m 3s) Loss: 0.0024(0.0245) Grad: 5019.3638  LR: 0.000008  \n","Epoch: [1][20300/103575] Elapsed 211m 23s (remain 867m 7s) Loss: 0.0003(0.0244) Grad: 94.0835  LR: 0.000008  \n","Epoch: [1][20400/103575] Elapsed 212m 26s (remain 866m 8s) Loss: 0.0001(0.0243) Grad: 47.4623  LR: 0.000008  \n","Epoch: [1][20500/103575] Elapsed 213m 30s (remain 865m 9s) Loss: 0.0004(0.0242) Grad: 131.7341  LR: 0.000008  \n","Epoch: [1][20600/103575] Elapsed 214m 33s (remain 864m 10s) Loss: 0.0018(0.0241) Grad: 2777.3362  LR: 0.000008  \n","Epoch: [1][20700/103575] Elapsed 215m 36s (remain 863m 9s) Loss: 0.0013(0.0240) Grad: 5495.7476  LR: 0.000008  \n","Epoch: [1][20800/103575] Elapsed 216m 39s (remain 862m 7s) Loss: 0.0001(0.0239) Grad: 20.7187  LR: 0.000008  \n","Epoch: [1][20900/103575] Elapsed 217m 41s (remain 861m 4s) Loss: 0.0043(0.0238) Grad: 2262.6052  LR: 0.000008  \n","Epoch: [1][21000/103575] Elapsed 218m 44s (remain 860m 2s) Loss: 0.0003(0.0237) Grad: 846.0903  LR: 0.000008  \n","Epoch: [1][21100/103575] Elapsed 219m 47s (remain 859m 1s) Loss: 0.0001(0.0236) Grad: 139.8580  LR: 0.000008  \n","Epoch: [1][21200/103575] Elapsed 220m 49s (remain 858m 1s) Loss: 0.0027(0.0235) Grad: 15289.0742  LR: 0.000008  \n","Epoch: [1][21300/103575] Elapsed 221m 52s (remain 856m 58s) Loss: 0.0001(0.0234) Grad: 95.2776  LR: 0.000008  \n","Epoch: [1][21400/103575] Elapsed 222m 55s (remain 855m 57s) Loss: 0.0003(0.0233) Grad: 98.5276  LR: 0.000008  \n","Epoch: [1][21500/103575] Elapsed 223m 57s (remain 854m 55s) Loss: 0.0002(0.0232) Grad: 155.6348  LR: 0.000008  \n","Epoch: [1][21600/103575] Elapsed 225m 0s (remain 853m 53s) Loss: 0.0049(0.0231) Grad: 3997.0654  LR: 0.000008  \n","Epoch: [1][21700/103575] Elapsed 226m 4s (remain 852m 58s) Loss: 0.0012(0.0230) Grad: 1146.6678  LR: 0.000008  \n","Epoch: [1][21800/103575] Elapsed 227m 8s (remain 851m 59s) Loss: 0.0003(0.0230) Grad: 51.7283  LR: 0.000008  \n","Epoch: [1][21900/103575] Elapsed 228m 12s (remain 851m 2s) Loss: 0.0065(0.0229) Grad: 15304.7822  LR: 0.000008  \n","Epoch: [1][22000/103575] Elapsed 229m 16s (remain 850m 4s) Loss: 0.0031(0.0228) Grad: 3067.7795  LR: 0.000008  \n","Epoch: [1][22100/103575] Elapsed 230m 19s (remain 849m 5s) Loss: 0.0045(0.0227) Grad: 11526.0615  LR: 0.000009  \n","Epoch: [1][22200/103575] Elapsed 231m 22s (remain 848m 4s) Loss: 0.0031(0.0226) Grad: 5524.8018  LR: 0.000009  \n","Epoch: [1][22300/103575] Elapsed 232m 25s (remain 847m 1s) Loss: 0.0066(0.0225) Grad: 7655.9165  LR: 0.000009  \n","Epoch: [1][22400/103575] Elapsed 233m 27s (remain 845m 59s) Loss: 0.0034(0.0224) Grad: 3513.7163  LR: 0.000009  \n","Epoch: [1][22500/103575] Elapsed 234m 30s (remain 844m 56s) Loss: 0.0013(0.0223) Grad: 8684.6816  LR: 0.000009  \n","Epoch: [1][22600/103575] Elapsed 235m 33s (remain 843m 55s) Loss: 0.0034(0.0222) Grad: 14849.5430  LR: 0.000009  \n","Epoch: [1][22700/103575] Elapsed 236m 35s (remain 842m 53s) Loss: 0.0041(0.0222) Grad: 2548.4185  LR: 0.000009  \n","Epoch: [1][22800/103575] Elapsed 237m 38s (remain 841m 52s) Loss: 0.0037(0.0221) Grad: 1687.6757  LR: 0.000009  \n","Epoch: [1][22900/103575] Elapsed 238m 41s (remain 840m 50s) Loss: 0.0037(0.0220) Grad: 1416.9650  LR: 0.000009  \n","Epoch: [1][23000/103575] Elapsed 239m 44s (remain 839m 50s) Loss: 0.0009(0.0219) Grad: 502.3185  LR: 0.000009  \n","Epoch: [1][23100/103575] Elapsed 240m 48s (remain 838m 51s) Loss: 0.0049(0.0218) Grad: 11129.5547  LR: 0.000009  \n","Epoch: [1][23200/103575] Elapsed 241m 51s (remain 837m 50s) Loss: 0.0001(0.0218) Grad: 3.9591  LR: 0.000009  \n","Epoch: [1][23300/103575] Elapsed 242m 54s (remain 836m 51s) Loss: 0.0001(0.0217) Grad: 13.6063  LR: 0.000009  \n","Epoch: [1][23400/103575] Elapsed 243m 57s (remain 835m 48s) Loss: 0.0102(0.0216) Grad: 8036.1919  LR: 0.000009  \n","Epoch: [1][23500/103575] Elapsed 244m 59s (remain 834m 45s) Loss: 0.0078(0.0215) Grad: 7505.6494  LR: 0.000009  \n","Epoch: [1][23600/103575] Elapsed 246m 2s (remain 833m 44s) Loss: 0.0072(0.0214) Grad: 13041.4873  LR: 0.000009  \n","Epoch: [1][23700/103575] Elapsed 247m 5s (remain 832m 42s) Loss: 0.0025(0.0213) Grad: 19638.3340  LR: 0.000009  \n","Epoch: [1][23800/103575] Elapsed 248m 7s (remain 831m 39s) Loss: 0.0025(0.0213) Grad: 10439.7139  LR: 0.000009  \n","Epoch: [1][23900/103575] Elapsed 249m 10s (remain 830m 36s) Loss: 0.0007(0.0212) Grad: 266.7095  LR: 0.000009  \n","Epoch: [1][24000/103575] Elapsed 250m 12s (remain 829m 34s) Loss: 0.0001(0.0211) Grad: 908.6534  LR: 0.000009  \n","Epoch: [1][24100/103575] Elapsed 251m 15s (remain 828m 32s) Loss: 0.0143(0.0210) Grad: 37353.8672  LR: 0.000009  \n","Epoch: [1][24200/103575] Elapsed 252m 18s (remain 827m 30s) Loss: 0.0103(0.0210) Grad: 52632.8516  LR: 0.000009  \n","Epoch: [1][24300/103575] Elapsed 253m 20s (remain 826m 27s) Loss: 0.0001(0.0209) Grad: 26.4651  LR: 0.000009  \n","Epoch: [1][24400/103575] Elapsed 254m 23s (remain 825m 25s) Loss: 0.0005(0.0208) Grad: 3183.1389  LR: 0.000009  \n","Epoch: [1][24500/103575] Elapsed 255m 26s (remain 824m 22s) Loss: 0.0001(0.0207) Grad: 55.1038  LR: 0.000009  \n","Epoch: [1][24600/103575] Elapsed 256m 28s (remain 823m 20s) Loss: 0.0002(0.0207) Grad: 600.0305  LR: 0.000010  \n","Epoch: [1][24700/103575] Elapsed 257m 31s (remain 822m 17s) Loss: 0.0015(0.0206) Grad: 2327.0737  LR: 0.000010  \n","Epoch: [1][24800/103575] Elapsed 258m 33s (remain 821m 16s) Loss: 0.0001(0.0205) Grad: 130.2307  LR: 0.000010  \n","Epoch: [1][24900/103575] Elapsed 259m 37s (remain 820m 17s) Loss: 0.0060(0.0204) Grad: 61553.3633  LR: 0.000010  \n","Epoch: [1][25000/103575] Elapsed 260m 40s (remain 819m 16s) Loss: 0.0001(0.0204) Grad: 138.8236  LR: 0.000010  \n","Epoch: [1][25100/103575] Elapsed 261m 44s (remain 818m 16s) Loss: 0.0005(0.0203) Grad: 154.3344  LR: 0.000010  \n","Epoch: [1][25200/103575] Elapsed 262m 46s (remain 817m 13s) Loss: 0.0034(0.0202) Grad: 8611.3848  LR: 0.000010  \n","Epoch: [1][25300/103575] Elapsed 263m 49s (remain 816m 11s) Loss: 0.0110(0.0202) Grad: 158291.9062  LR: 0.000010  \n","Epoch: [1][25400/103575] Elapsed 264m 51s (remain 815m 8s) Loss: 0.0001(0.0201) Grad: 24.1765  LR: 0.000010  \n","Epoch: [1][25500/103575] Elapsed 265m 54s (remain 814m 6s) Loss: 0.0028(0.0200) Grad: 4135.2090  LR: 0.000010  \n","Epoch: [1][25600/103575] Elapsed 266m 56s (remain 813m 3s) Loss: 0.0073(0.0200) Grad: 15056.6533  LR: 0.000010  \n","Epoch: [1][25700/103575] Elapsed 267m 59s (remain 812m 0s) Loss: 0.0005(0.0199) Grad: 2469.1140  LR: 0.000010  \n","Epoch: [1][25800/103575] Elapsed 269m 1s (remain 810m 57s) Loss: 0.0011(0.0198) Grad: 1918.9497  LR: 0.000010  \n","Epoch: [1][25900/103575] Elapsed 270m 4s (remain 809m 54s) Loss: 0.0008(0.0198) Grad: 5062.0615  LR: 0.000010  \n","Epoch: [1][26000/103575] Elapsed 271m 6s (remain 808m 52s) Loss: 0.0028(0.0197) Grad: 1954.4165  LR: 0.000010  \n","Epoch: [1][26100/103575] Elapsed 272m 9s (remain 807m 50s) Loss: 0.0001(0.0196) Grad: 45.3685  LR: 0.000010  \n","Epoch: [1][26200/103575] Elapsed 273m 12s (remain 806m 47s) Loss: 0.0148(0.0196) Grad: 39249.8867  LR: 0.000010  \n","Epoch: [1][26300/103575] Elapsed 274m 14s (remain 805m 45s) Loss: 0.0017(0.0195) Grad: 8081.7666  LR: 0.000010  \n","Epoch: [1][26400/103575] Elapsed 275m 17s (remain 804m 43s) Loss: 0.0008(0.0194) Grad: 505.2416  LR: 0.000010  \n","Epoch: [1][26500/103575] Elapsed 276m 20s (remain 803m 41s) Loss: 0.0093(0.0194) Grad: 112936.3906  LR: 0.000010  \n","Epoch: [1][26600/103575] Elapsed 277m 22s (remain 802m 38s) Loss: 0.0118(0.0193) Grad: 99477.0000  LR: 0.000010  \n","Epoch: [1][26700/103575] Elapsed 278m 25s (remain 801m 35s) Loss: 0.0041(0.0192) Grad: 23875.6602  LR: 0.000010  \n","Epoch: [1][26800/103575] Elapsed 279m 27s (remain 800m 32s) Loss: 0.0233(0.0192) Grad: 62645.4023  LR: 0.000010  \n","Epoch: [1][26900/103575] Elapsed 280m 30s (remain 799m 30s) Loss: 0.0013(0.0191) Grad: 1008.6277  LR: 0.000010  \n","Epoch: [1][27000/103575] Elapsed 281m 33s (remain 798m 29s) Loss: 0.0009(0.0191) Grad: 3962.9680  LR: 0.000010  \n","Epoch: [1][27100/103575] Elapsed 282m 36s (remain 797m 27s) Loss: 0.0006(0.0190) Grad: 1260.6644  LR: 0.000010  \n","Epoch: [1][27200/103575] Elapsed 283m 38s (remain 796m 25s) Loss: 0.0000(0.0189) Grad: 2.9484  LR: 0.000011  \n","Epoch: [1][27300/103575] Elapsed 284m 41s (remain 795m 22s) Loss: 0.0002(0.0189) Grad: 37.9732  LR: 0.000011  \n","Epoch: [1][27400/103575] Elapsed 285m 43s (remain 794m 19s) Loss: 0.0003(0.0188) Grad: 405.3967  LR: 0.000011  \n","Epoch: [1][27500/103575] Elapsed 286m 46s (remain 793m 17s) Loss: 0.0001(0.0187) Grad: 71.5693  LR: 0.000011  \n","Epoch: [1][27600/103575] Elapsed 287m 49s (remain 792m 15s) Loss: 0.0001(0.0187) Grad: 24.1680  LR: 0.000011  \n","Epoch: [1][27700/103575] Elapsed 288m 51s (remain 791m 12s) Loss: 0.0035(0.0186) Grad: 31500.0273  LR: 0.000011  \n","Epoch: [1][27800/103575] Elapsed 289m 54s (remain 790m 10s) Loss: 0.0001(0.0186) Grad: 304.8394  LR: 0.000011  \n","Epoch: [1][27900/103575] Elapsed 290m 57s (remain 789m 8s) Loss: 0.0001(0.0185) Grad: 328.2633  LR: 0.000011  \n","Epoch: [1][28000/103575] Elapsed 292m 0s (remain 788m 6s) Loss: 0.0007(0.0185) Grad: 5002.2334  LR: 0.000011  \n","Epoch: [1][28100/103575] Elapsed 293m 2s (remain 787m 3s) Loss: 0.0023(0.0184) Grad: 13059.6260  LR: 0.000011  \n","Epoch: [1][28200/103575] Elapsed 294m 5s (remain 786m 0s) Loss: 0.0017(0.0183) Grad: 13563.6562  LR: 0.000011  \n","Epoch: [1][28300/103575] Elapsed 295m 7s (remain 784m 57s) Loss: 0.0002(0.0183) Grad: 585.7264  LR: 0.000011  \n","Epoch: [1][28400/103575] Elapsed 296m 9s (remain 783m 54s) Loss: 0.0011(0.0182) Grad: 5334.6611  LR: 0.000011  \n","Epoch: [1][28500/103575] Elapsed 297m 12s (remain 782m 53s) Loss: 0.0002(0.0182) Grad: 1154.0658  LR: 0.000011  \n","Epoch: [1][28600/103575] Elapsed 298m 15s (remain 781m 50s) Loss: 0.0006(0.0181) Grad: 3763.6011  LR: 0.000011  \n","Epoch: [1][28700/103575] Elapsed 299m 18s (remain 780m 48s) Loss: 0.0003(0.0181) Grad: 183.6007  LR: 0.000011  \n","Epoch: [1][28800/103575] Elapsed 300m 20s (remain 779m 45s) Loss: 0.0013(0.0180) Grad: 3289.0122  LR: 0.000011  \n","Epoch: [1][28900/103575] Elapsed 301m 23s (remain 778m 43s) Loss: 0.0006(0.0180) Grad: 8287.1572  LR: 0.000011  \n","Epoch: [1][29000/103575] Elapsed 302m 26s (remain 777m 42s) Loss: 0.0047(0.0179) Grad: 17793.1465  LR: 0.000011  \n","Epoch: [1][29100/103575] Elapsed 303m 29s (remain 776m 39s) Loss: 0.0005(0.0179) Grad: 7517.8340  LR: 0.000011  \n","Epoch: [1][29200/103575] Elapsed 304m 31s (remain 775m 37s) Loss: 0.0001(0.0178) Grad: 132.4234  LR: 0.000011  \n","Epoch: [1][29300/103575] Elapsed 305m 34s (remain 774m 35s) Loss: 0.0027(0.0177) Grad: 68168.5703  LR: 0.000011  \n","Epoch: [1][29400/103575] Elapsed 306m 37s (remain 773m 33s) Loss: 0.0001(0.0177) Grad: 63.1101  LR: 0.000011  \n","Epoch: [1][29500/103575] Elapsed 307m 39s (remain 772m 30s) Loss: 0.0012(0.0176) Grad: 8532.7871  LR: 0.000011  \n","Epoch: [1][29600/103575] Elapsed 308m 42s (remain 771m 28s) Loss: 0.0119(0.0176) Grad: 63543.7734  LR: 0.000011  \n","Epoch: [1][29700/103575] Elapsed 309m 44s (remain 770m 25s) Loss: 0.0009(0.0175) Grad: 2781.0991  LR: 0.000011  \n","Epoch: [1][29800/103575] Elapsed 310m 47s (remain 769m 23s) Loss: 0.0019(0.0175) Grad: 11250.7598  LR: 0.000012  \n","Epoch: [1][29900/103575] Elapsed 311m 49s (remain 768m 19s) Loss: 0.0037(0.0174) Grad: 11192.0000  LR: 0.000012  \n","Epoch: [1][30000/103575] Elapsed 312m 52s (remain 767m 17s) Loss: 0.0038(0.0174) Grad: 26858.0117  LR: 0.000012  \n","Epoch: [1][30100/103575] Elapsed 313m 55s (remain 766m 14s) Loss: 0.0125(0.0173) Grad: 91092.1875  LR: 0.000012  \n","Epoch: [1][30200/103575] Elapsed 314m 57s (remain 765m 12s) Loss: 0.0074(0.0173) Grad: 68953.8125  LR: 0.000012  \n","Epoch: [1][30300/103575] Elapsed 316m 0s (remain 764m 9s) Loss: 0.0002(0.0172) Grad: 33.4705  LR: 0.000012  \n","Epoch: [1][30400/103575] Elapsed 317m 3s (remain 763m 7s) Loss: 0.0001(0.0172) Grad: 226.7673  LR: 0.000012  \n","Epoch: [1][30500/103575] Elapsed 318m 5s (remain 762m 5s) Loss: 0.0089(0.0171) Grad: 24691.5508  LR: 0.000012  \n","Epoch: [1][30600/103575] Elapsed 319m 8s (remain 761m 2s) Loss: 0.0001(0.0171) Grad: 496.2433  LR: 0.000012  \n","Epoch: [1][30700/103575] Elapsed 320m 11s (remain 760m 0s) Loss: 0.0060(0.0171) Grad: 35278.1445  LR: 0.000012  \n","Epoch: [1][30800/103575] Elapsed 321m 13s (remain 758m 58s) Loss: 0.0052(0.0170) Grad: 28969.9434  LR: 0.000012  \n","Epoch: [1][30900/103575] Elapsed 322m 16s (remain 757m 56s) Loss: 0.0034(0.0170) Grad: 50119.0508  LR: 0.000012  \n","Epoch: [1][31000/103575] Elapsed 323m 18s (remain 756m 53s) Loss: 0.0071(0.0169) Grad: 62087.2656  LR: 0.000012  \n","Epoch: [1][31100/103575] Elapsed 324m 21s (remain 755m 51s) Loss: 0.0002(0.0169) Grad: 312.0695  LR: 0.000012  \n","Epoch: [1][31200/103575] Elapsed 325m 24s (remain 754m 49s) Loss: 0.0000(0.0168) Grad: 7.9776  LR: 0.000012  \n","Epoch: [1][31300/103575] Elapsed 326m 27s (remain 753m 47s) Loss: 0.0162(0.0168) Grad: 104966.7656  LR: 0.000012  \n","Epoch: [1][31400/103575] Elapsed 327m 29s (remain 752m 44s) Loss: 0.0008(0.0167) Grad: 2934.2158  LR: 0.000012  \n","Epoch: [1][31500/103575] Elapsed 328m 32s (remain 751m 41s) Loss: 0.0004(0.0167) Grad: 2265.6814  LR: 0.000012  \n","Epoch: [1][31600/103575] Elapsed 329m 34s (remain 750m 38s) Loss: 0.0001(0.0166) Grad: 97.9424  LR: 0.000012  \n","Epoch: [1][31700/103575] Elapsed 330m 37s (remain 749m 36s) Loss: 0.0001(0.0166) Grad: 66.9436  LR: 0.000012  \n","Epoch: [1][31800/103575] Elapsed 331m 40s (remain 748m 35s) Loss: 0.0051(0.0165) Grad: 174248.8281  LR: 0.000012  \n","Epoch: [1][31900/103575] Elapsed 332m 44s (remain 747m 34s) Loss: 0.0005(0.0165) Grad: 4289.4219  LR: 0.000012  \n","Epoch: [1][32000/103575] Elapsed 333m 46s (remain 746m 32s) Loss: 0.0001(0.0164) Grad: 28.9214  LR: 0.000012  \n","Epoch: [1][32100/103575] Elapsed 334m 49s (remain 745m 30s) Loss: 0.0000(0.0164) Grad: 27.5837  LR: 0.000012  \n","Epoch: [1][32200/103575] Elapsed 335m 52s (remain 744m 28s) Loss: 0.0002(0.0164) Grad: 1569.5294  LR: 0.000012  \n","Epoch: [1][32300/103575] Elapsed 336m 55s (remain 743m 26s) Loss: 0.0000(0.0163) Grad: 28.7226  LR: 0.000012  \n","Epoch: [1][32400/103575] Elapsed 337m 57s (remain 742m 23s) Loss: 0.0001(0.0163) Grad: 101.5831  LR: 0.000013  \n","Epoch: [1][32500/103575] Elapsed 339m 1s (remain 741m 22s) Loss: 0.0002(0.0162) Grad: 59.7719  LR: 0.000013  \n","Epoch: [1][32600/103575] Elapsed 340m 4s (remain 740m 21s) Loss: 0.0001(0.0162) Grad: 414.9691  LR: 0.000013  \n","Epoch: [1][32700/103575] Elapsed 341m 7s (remain 739m 19s) Loss: 0.0000(0.0161) Grad: 6.2356  LR: 0.000013  \n","Epoch: [1][32800/103575] Elapsed 342m 9s (remain 738m 16s) Loss: 0.0013(0.0161) Grad: 3037.5161  LR: 0.000013  \n","Epoch: [1][32900/103575] Elapsed 343m 12s (remain 737m 14s) Loss: 0.0007(0.0161) Grad: 2161.1589  LR: 0.000013  \n","Epoch: [1][33000/103575] Elapsed 344m 15s (remain 736m 12s) Loss: 0.0002(0.0160) Grad: 780.3112  LR: 0.000013  \n","Epoch: [1][33100/103575] Elapsed 345m 18s (remain 735m 11s) Loss: 0.0189(0.0160) Grad: 67275.4844  LR: 0.000013  \n","Epoch: [1][33200/103575] Elapsed 346m 21s (remain 734m 9s) Loss: 0.0003(0.0159) Grad: 304.9780  LR: 0.000013  \n","Epoch: [1][33300/103575] Elapsed 347m 24s (remain 733m 8s) Loss: 0.0011(0.0159) Grad: 5428.4062  LR: 0.000013  \n","Epoch: [1][33400/103575] Elapsed 348m 27s (remain 732m 6s) Loss: 0.0079(0.0159) Grad: 19596.4258  LR: 0.000013  \n","Epoch: [1][33500/103575] Elapsed 349m 30s (remain 731m 4s) Loss: 0.0001(0.0158) Grad: 204.1026  LR: 0.000013  \n","Epoch: [1][33600/103575] Elapsed 350m 33s (remain 730m 2s) Loss: 0.0076(0.0158) Grad: 40127.8398  LR: 0.000013  \n","Epoch: [1][33700/103575] Elapsed 351m 36s (remain 729m 1s) Loss: 0.0001(0.0157) Grad: 37.5209  LR: 0.000013  \n","Epoch: [1][33800/103575] Elapsed 352m 39s (remain 727m 59s) Loss: 0.0001(0.0157) Grad: 147.0997  LR: 0.000013  \n","Epoch: [1][33900/103575] Elapsed 353m 42s (remain 726m 57s) Loss: 0.0056(0.0157) Grad: 35355.4336  LR: 0.000013  \n","Epoch: [1][34000/103575] Elapsed 354m 45s (remain 725m 56s) Loss: 0.0033(0.0156) Grad: 11516.1084  LR: 0.000013  \n","Epoch: [1][34100/103575] Elapsed 355m 48s (remain 724m 54s) Loss: 0.0002(0.0156) Grad: 1053.3015  LR: 0.000013  \n","Epoch: [1][34200/103575] Elapsed 356m 51s (remain 723m 52s) Loss: 0.0004(0.0155) Grad: 582.2280  LR: 0.000013  \n","Epoch: [1][34300/103575] Elapsed 357m 54s (remain 722m 50s) Loss: 0.0043(0.0155) Grad: 18786.9824  LR: 0.000013  \n","Epoch: [1][34400/103575] Elapsed 358m 57s (remain 721m 47s) Loss: 0.0210(0.0155) Grad: 191772.9219  LR: 0.000013  \n","Epoch: [1][34500/103575] Elapsed 360m 0s (remain 720m 45s) Loss: 0.0013(0.0154) Grad: 9125.5332  LR: 0.000013  \n","Epoch: [1][34600/103575] Elapsed 361m 2s (remain 719m 42s) Loss: 0.0006(0.0154) Grad: 1641.4579  LR: 0.000013  \n","Epoch: [1][34700/103575] Elapsed 362m 5s (remain 718m 40s) Loss: 0.0001(0.0154) Grad: 75.4303  LR: 0.000013  \n","Epoch: [1][34800/103575] Elapsed 363m 8s (remain 717m 37s) Loss: 0.0083(0.0153) Grad: 16090.7490  LR: 0.000013  \n","Epoch: [1][34900/103575] Elapsed 364m 10s (remain 716m 34s) Loss: 0.0028(0.0153) Grad: 25369.5742  LR: 0.000013  \n","Epoch: [1][35000/103575] Elapsed 365m 13s (remain 715m 32s) Loss: 0.0000(0.0152) Grad: 69.1606  LR: 0.000014  \n","Epoch: [1][35100/103575] Elapsed 366m 15s (remain 714m 29s) Loss: 0.0028(0.0152) Grad: 27619.2754  LR: 0.000014  \n","Epoch: [1][35200/103575] Elapsed 367m 18s (remain 713m 26s) Loss: 0.0066(0.0152) Grad: 36008.4922  LR: 0.000014  \n","Epoch: [1][35300/103575] Elapsed 368m 20s (remain 712m 24s) Loss: 0.0010(0.0151) Grad: 1404.8650  LR: 0.000014  \n","Epoch: [1][35400/103575] Elapsed 369m 23s (remain 711m 21s) Loss: 0.0000(0.0151) Grad: 9.5080  LR: 0.000014  \n","Epoch: [1][35500/103575] Elapsed 370m 25s (remain 710m 18s) Loss: 0.0009(0.0151) Grad: 2637.2075  LR: 0.000014  \n","Epoch: [1][35600/103575] Elapsed 371m 28s (remain 709m 15s) Loss: 0.0002(0.0150) Grad: 389.8859  LR: 0.000014  \n","Epoch: [1][35700/103575] Elapsed 372m 31s (remain 708m 13s) Loss: 0.0036(0.0150) Grad: 6270.4033  LR: 0.000014  \n","Epoch: [1][35800/103575] Elapsed 373m 33s (remain 707m 11s) Loss: 0.0032(0.0150) Grad: 9972.8311  LR: 0.000014  \n","Epoch: [1][35900/103575] Elapsed 374m 36s (remain 706m 8s) Loss: 0.0003(0.0149) Grad: 1396.6045  LR: 0.000014  \n","Epoch: [1][36000/103575] Elapsed 375m 39s (remain 705m 5s) Loss: 0.0026(0.0149) Grad: 9129.3496  LR: 0.000014  \n","Epoch: [1][36100/103575] Elapsed 376m 41s (remain 704m 3s) Loss: 0.0001(0.0148) Grad: 289.9096  LR: 0.000014  \n","Epoch: [1][36200/103575] Elapsed 377m 45s (remain 703m 2s) Loss: 0.0002(0.0148) Grad: 845.1487  LR: 0.000014  \n","Epoch: [1][36300/103575] Elapsed 378m 48s (remain 702m 1s) Loss: 0.0004(0.0148) Grad: 427.7890  LR: 0.000014  \n","Epoch: [1][36400/103575] Elapsed 379m 51s (remain 700m 59s) Loss: 0.0000(0.0147) Grad: 0.1167  LR: 0.000014  \n","Epoch: [1][36500/103575] Elapsed 380m 54s (remain 699m 57s) Loss: 0.0001(0.0147) Grad: 14.4803  LR: 0.000014  \n","Epoch: [1][36600/103575] Elapsed 381m 58s (remain 698m 57s) Loss: 0.0000(0.0147) Grad: 96.3471  LR: 0.000014  \n","Epoch: [1][36700/103575] Elapsed 383m 1s (remain 697m 55s) Loss: 0.0062(0.0146) Grad: 17408.4980  LR: 0.000014  \n","Epoch: [1][36800/103575] Elapsed 384m 4s (remain 696m 53s) Loss: 0.0134(0.0146) Grad: 24502.2832  LR: 0.000014  \n","Epoch: [1][36900/103575] Elapsed 385m 7s (remain 695m 50s) Loss: 0.0003(0.0146) Grad: 61.1820  LR: 0.000014  \n","Epoch: [1][37000/103575] Elapsed 386m 9s (remain 694m 48s) Loss: 0.0036(0.0145) Grad: 14325.3125  LR: 0.000014  \n","Epoch: [1][37100/103575] Elapsed 387m 12s (remain 693m 46s) Loss: 0.0061(0.0145) Grad: 28942.4531  LR: 0.000014  \n","Epoch: [1][37200/103575] Elapsed 388m 15s (remain 692m 43s) Loss: 0.0000(0.0145) Grad: 8.4240  LR: 0.000014  \n","Epoch: [1][37300/103575] Elapsed 389m 18s (remain 691m 41s) Loss: 0.0057(0.0144) Grad: 17637.6250  LR: 0.000014  \n","Epoch: [1][37400/103575] Elapsed 390m 21s (remain 690m 39s) Loss: 0.0009(0.0144) Grad: 3240.2029  LR: 0.000014  \n","Epoch: [1][37500/103575] Elapsed 391m 23s (remain 689m 36s) Loss: 0.0003(0.0144) Grad: 713.7278  LR: 0.000014  \n","Epoch: [1][37600/103575] Elapsed 392m 27s (remain 688m 35s) Loss: 0.0001(0.0144) Grad: 247.8734  LR: 0.000015  \n","Epoch: [1][37700/103575] Elapsed 393m 29s (remain 687m 33s) Loss: 0.0005(0.0143) Grad: 422.9712  LR: 0.000015  \n","Epoch: [1][37800/103575] Elapsed 394m 32s (remain 686m 30s) Loss: 0.0021(0.0143) Grad: 5446.3271  LR: 0.000015  \n","Epoch: [1][37900/103575] Elapsed 395m 36s (remain 685m 29s) Loss: 0.0018(0.0143) Grad: 7664.9316  LR: 0.000015  \n","Epoch: [1][38000/103575] Elapsed 396m 39s (remain 684m 27s) Loss: 0.0068(0.0142) Grad: 9413.8643  LR: 0.000015  \n","Epoch: [1][38100/103575] Elapsed 397m 42s (remain 683m 25s) Loss: 0.0049(0.0142) Grad: 21285.8145  LR: 0.000015  \n","Epoch: [1][38200/103575] Elapsed 398m 44s (remain 682m 22s) Loss: 0.0001(0.0142) Grad: 12.9570  LR: 0.000015  \n","Epoch: [1][38300/103575] Elapsed 399m 47s (remain 681m 20s) Loss: 0.0002(0.0141) Grad: 996.8630  LR: 0.000015  \n","Epoch: [1][38400/103575] Elapsed 400m 50s (remain 680m 17s) Loss: 0.0007(0.0141) Grad: 1161.5167  LR: 0.000015  \n","Epoch: [1][38500/103575] Elapsed 401m 52s (remain 679m 15s) Loss: 0.0046(0.0141) Grad: 13411.5273  LR: 0.000015  \n","Epoch: [1][38600/103575] Elapsed 402m 55s (remain 678m 12s) Loss: 0.0021(0.0140) Grad: 9925.1318  LR: 0.000015  \n","Epoch: [1][38700/103575] Elapsed 403m 57s (remain 677m 9s) Loss: 0.0004(0.0140) Grad: 2079.2317  LR: 0.000015  \n","Epoch: [1][38800/103575] Elapsed 405m 0s (remain 676m 6s) Loss: 0.0001(0.0140) Grad: 28.9419  LR: 0.000015  \n","Epoch: [1][38900/103575] Elapsed 406m 2s (remain 675m 3s) Loss: 0.0056(0.0140) Grad: 15596.2412  LR: 0.000015  \n","Epoch: [1][39000/103575] Elapsed 407m 5s (remain 674m 0s) Loss: 0.0003(0.0139) Grad: 174.3412  LR: 0.000015  \n","Epoch: [1][39100/103575] Elapsed 408m 7s (remain 672m 57s) Loss: 0.0014(0.0139) Grad: 6174.6968  LR: 0.000015  \n","Epoch: [1][39200/103575] Elapsed 409m 10s (remain 671m 54s) Loss: 0.0001(0.0139) Grad: 18.1442  LR: 0.000015  \n","Epoch: [1][39300/103575] Elapsed 410m 12s (remain 670m 52s) Loss: 0.0001(0.0138) Grad: 18.7528  LR: 0.000015  \n","Epoch: [1][39400/103575] Elapsed 411m 15s (remain 669m 49s) Loss: 0.0001(0.0138) Grad: 123.5935  LR: 0.000015  \n","Epoch: [1][39500/103575] Elapsed 412m 17s (remain 668m 47s) Loss: 0.0033(0.0138) Grad: 5917.4326  LR: 0.000015  \n","Epoch: [1][39600/103575] Elapsed 413m 20s (remain 667m 44s) Loss: 0.0013(0.0138) Grad: 11302.1729  LR: 0.000015  \n","Epoch: [1][39700/103575] Elapsed 414m 22s (remain 666m 40s) Loss: 0.0005(0.0137) Grad: 7982.7969  LR: 0.000015  \n","Epoch: [1][39800/103575] Elapsed 415m 25s (remain 665m 38s) Loss: 0.0004(0.0137) Grad: 3771.9448  LR: 0.000015  \n","Epoch: [1][39900/103575] Elapsed 416m 27s (remain 664m 35s) Loss: 0.0090(0.0137) Grad: 25345.4883  LR: 0.000015  \n","Epoch: [1][40000/103575] Elapsed 417m 30s (remain 663m 32s) Loss: 0.0004(0.0136) Grad: 5939.7964  LR: 0.000015  \n","Epoch: [1][40100/103575] Elapsed 418m 33s (remain 662m 30s) Loss: 0.0003(0.0136) Grad: 12513.8799  LR: 0.000015  \n","Epoch: [1][40200/103575] Elapsed 419m 35s (remain 661m 27s) Loss: 0.0032(0.0136) Grad: 18238.5312  LR: 0.000016  \n","Epoch: [1][40300/103575] Elapsed 420m 38s (remain 660m 25s) Loss: 0.0001(0.0136) Grad: 7.2417  LR: 0.000016  \n","Epoch: [1][40400/103575] Elapsed 421m 41s (remain 659m 22s) Loss: 0.0030(0.0135) Grad: 3898.8320  LR: 0.000016  \n","Epoch: [1][40500/103575] Elapsed 422m 43s (remain 658m 19s) Loss: 0.0005(0.0135) Grad: 949.3287  LR: 0.000016  \n","Epoch: [1][40600/103575] Elapsed 423m 46s (remain 657m 17s) Loss: 0.0001(0.0135) Grad: 11.4496  LR: 0.000016  \n","Epoch: [1][40700/103575] Elapsed 424m 49s (remain 656m 15s) Loss: 0.0003(0.0134) Grad: 171.2191  LR: 0.000016  \n","Epoch: [1][40800/103575] Elapsed 425m 51s (remain 655m 12s) Loss: 0.0001(0.0134) Grad: 17.1799  LR: 0.000016  \n","Epoch: [1][40900/103575] Elapsed 426m 54s (remain 654m 10s) Loss: 0.0011(0.0134) Grad: 2078.5474  LR: 0.000016  \n","Epoch: [1][41000/103575] Elapsed 427m 57s (remain 653m 8s) Loss: 0.0003(0.0134) Grad: 1343.2203  LR: 0.000016  \n","Epoch: [1][41100/103575] Elapsed 429m 0s (remain 652m 5s) Loss: 0.0004(0.0133) Grad: 456.4424  LR: 0.000016  \n","Epoch: [1][41200/103575] Elapsed 430m 3s (remain 651m 3s) Loss: 0.0033(0.0133) Grad: 6210.6191  LR: 0.000016  \n","Epoch: [1][41300/103575] Elapsed 431m 6s (remain 650m 1s) Loss: 0.0001(0.0133) Grad: 23.6155  LR: 0.000016  \n","Epoch: [1][41400/103575] Elapsed 432m 9s (remain 648m 59s) Loss: 0.0011(0.0133) Grad: 6508.6440  LR: 0.000016  \n","Epoch: [1][41500/103575] Elapsed 433m 12s (remain 647m 57s) Loss: 0.0001(0.0132) Grad: 13.6582  LR: 0.000016  \n","Epoch: [1][41600/103575] Elapsed 434m 15s (remain 646m 55s) Loss: 0.0009(0.0132) Grad: 321.5596  LR: 0.000016  \n","Epoch: [1][41700/103575] Elapsed 435m 18s (remain 645m 52s) Loss: 0.0086(0.0132) Grad: 2246.1909  LR: 0.000016  \n","Epoch: [1][41800/103575] Elapsed 436m 21s (remain 644m 50s) Loss: 0.0005(0.0132) Grad: 124.0006  LR: 0.000016  \n","Epoch: [1][41900/103575] Elapsed 437m 23s (remain 643m 48s) Loss: 0.0007(0.0131) Grad: 200.6095  LR: 0.000016  \n","Epoch: [1][42000/103575] Elapsed 438m 26s (remain 642m 45s) Loss: 0.0174(0.0131) Grad: 7512.5122  LR: 0.000016  \n","Epoch: [1][42100/103575] Elapsed 439m 29s (remain 641m 43s) Loss: 0.0002(0.0131) Grad: 21.0989  LR: 0.000016  \n","Epoch: [1][42200/103575] Elapsed 440m 32s (remain 640m 41s) Loss: 0.0027(0.0131) Grad: 2804.3198  LR: 0.000016  \n","Epoch: [1][42300/103575] Elapsed 441m 35s (remain 639m 39s) Loss: 0.0001(0.0130) Grad: 15.0349  LR: 0.000016  \n","Epoch: [1][42400/103575] Elapsed 442m 39s (remain 638m 38s) Loss: 0.0015(0.0130) Grad: 1009.2983  LR: 0.000016  \n","Epoch: [1][42500/103575] Elapsed 443m 42s (remain 637m 36s) Loss: 0.0042(0.0130) Grad: 2652.4426  LR: 0.000016  \n","Epoch: [1][42600/103575] Elapsed 444m 45s (remain 636m 34s) Loss: 0.0027(0.0130) Grad: 856.1562  LR: 0.000016  \n","Epoch: [1][42700/103575] Elapsed 445m 48s (remain 635m 32s) Loss: 0.0003(0.0129) Grad: 202.5152  LR: 0.000016  \n","Epoch: [1][42800/103575] Elapsed 446m 51s (remain 634m 30s) Loss: 0.0040(0.0129) Grad: 1164.3002  LR: 0.000017  \n","Epoch: [1][42900/103575] Elapsed 447m 54s (remain 633m 28s) Loss: 0.0001(0.0129) Grad: 35.0886  LR: 0.000017  \n","Epoch: [1][43000/103575] Elapsed 448m 57s (remain 632m 26s) Loss: 0.0003(0.0129) Grad: 30.2659  LR: 0.000017  \n","Epoch: [1][43100/103575] Elapsed 450m 1s (remain 631m 24s) Loss: 0.0079(0.0128) Grad: 9005.9961  LR: 0.000017  \n","Epoch: [1][43200/103575] Elapsed 451m 4s (remain 630m 22s) Loss: 0.0045(0.0128) Grad: 5023.0244  LR: 0.000017  \n","Epoch: [1][43300/103575] Elapsed 452m 7s (remain 629m 20s) Loss: 0.0000(0.0128) Grad: 2.7923  LR: 0.000017  \n","Epoch: [1][43400/103575] Elapsed 453m 10s (remain 628m 18s) Loss: 0.0005(0.0128) Grad: 466.7604  LR: 0.000017  \n","Epoch: [1][43500/103575] Elapsed 454m 13s (remain 627m 16s) Loss: 0.0020(0.0128) Grad: 1322.0575  LR: 0.000017  \n","Epoch: [1][43600/103575] Elapsed 455m 16s (remain 626m 14s) Loss: 0.0010(0.0127) Grad: 193.3095  LR: 0.000017  \n","Epoch: [1][43700/103575] Elapsed 456m 19s (remain 625m 12s) Loss: 0.0025(0.0127) Grad: 2405.8220  LR: 0.000017  \n","Epoch: [1][43800/103575] Elapsed 457m 22s (remain 624m 9s) Loss: 0.0003(0.0127) Grad: 178.7818  LR: 0.000017  \n","Epoch: [1][43900/103575] Elapsed 458m 25s (remain 623m 7s) Loss: 0.0045(0.0127) Grad: 3876.0823  LR: 0.000017  \n","Epoch: [1][44000/103575] Elapsed 459m 28s (remain 622m 5s) Loss: 0.0012(0.0126) Grad: 1618.8007  LR: 0.000017  \n","Epoch: [1][44100/103575] Elapsed 460m 31s (remain 621m 3s) Loss: 0.0019(0.0126) Grad: 3190.3435  LR: 0.000017  \n","Epoch: [1][44200/103575] Elapsed 461m 34s (remain 620m 0s) Loss: 0.0068(0.0126) Grad: 3812.6628  LR: 0.000017  \n","Epoch: [1][44300/103575] Elapsed 462m 36s (remain 618m 58s) Loss: 0.0079(0.0126) Grad: 4454.6455  LR: 0.000017  \n","Epoch: [1][44400/103575] Elapsed 463m 39s (remain 617m 55s) Loss: 0.0003(0.0125) Grad: 138.9419  LR: 0.000017  \n","Epoch: [1][44500/103575] Elapsed 464m 42s (remain 616m 53s) Loss: 0.0008(0.0125) Grad: 1119.1414  LR: 0.000017  \n","Epoch: [1][44600/103575] Elapsed 465m 45s (remain 615m 51s) Loss: 0.0011(0.0125) Grad: 2765.4851  LR: 0.000017  \n","Epoch: [1][44700/103575] Elapsed 466m 48s (remain 614m 48s) Loss: 0.0007(0.0125) Grad: 146.1578  LR: 0.000017  \n","Epoch: [1][44800/103575] Elapsed 467m 51s (remain 613m 46s) Loss: 0.0003(0.0125) Grad: 337.1268  LR: 0.000017  \n","Epoch: [1][44900/103575] Elapsed 468m 54s (remain 612m 44s) Loss: 0.0001(0.0124) Grad: 25.6961  LR: 0.000017  \n","Epoch: [1][45000/103575] Elapsed 469m 57s (remain 611m 41s) Loss: 0.0033(0.0124) Grad: 6727.6187  LR: 0.000017  \n","Epoch: [1][45100/103575] Elapsed 471m 0s (remain 610m 39s) Loss: 0.0064(0.0124) Grad: 2329.0220  LR: 0.000017  \n","Epoch: [1][45200/103575] Elapsed 472m 3s (remain 609m 37s) Loss: 0.0004(0.0124) Grad: 159.4217  LR: 0.000017  \n","Epoch: [1][45300/103575] Elapsed 473m 6s (remain 608m 35s) Loss: 0.0007(0.0124) Grad: 830.6756  LR: 0.000017  \n","Epoch: [1][45400/103575] Elapsed 474m 9s (remain 607m 33s) Loss: 0.0021(0.0123) Grad: 603.2397  LR: 0.000018  \n","Epoch: [1][45500/103575] Elapsed 475m 12s (remain 606m 30s) Loss: 0.0002(0.0123) Grad: 53.3345  LR: 0.000018  \n","Epoch: [1][45600/103575] Elapsed 476m 15s (remain 605m 28s) Loss: 0.0022(0.0123) Grad: 2098.6365  LR: 0.000018  \n","Epoch: [1][45700/103575] Elapsed 477m 18s (remain 604m 26s) Loss: 0.0002(0.0123) Grad: 94.1997  LR: 0.000018  \n","Epoch: [1][45800/103575] Elapsed 478m 21s (remain 603m 24s) Loss: 0.0003(0.0123) Grad: 585.0328  LR: 0.000018  \n","Epoch: [1][45900/103575] Elapsed 479m 24s (remain 602m 21s) Loss: 0.0000(0.0122) Grad: 8.8588  LR: 0.000018  \n","Epoch: [1][46000/103575] Elapsed 480m 26s (remain 601m 19s) Loss: 0.0070(0.0122) Grad: 4444.8604  LR: 0.000018  \n","Epoch: [1][46100/103575] Elapsed 481m 29s (remain 600m 16s) Loss: 0.0048(0.0122) Grad: 4571.2729  LR: 0.000018  \n","Epoch: [1][46200/103575] Elapsed 482m 32s (remain 599m 14s) Loss: 0.0004(0.0122) Grad: 609.0538  LR: 0.000018  \n","Epoch: [1][46300/103575] Elapsed 483m 35s (remain 598m 12s) Loss: 0.0029(0.0121) Grad: 8376.5439  LR: 0.000018  \n","Epoch: [1][46400/103575] Elapsed 484m 38s (remain 597m 9s) Loss: 0.0016(0.0121) Grad: 709.2302  LR: 0.000018  \n","Epoch: [1][46500/103575] Elapsed 485m 41s (remain 596m 7s) Loss: 0.0000(0.0121) Grad: 10.9876  LR: 0.000018  \n","Epoch: [1][46600/103575] Elapsed 486m 44s (remain 595m 4s) Loss: 0.0001(0.0121) Grad: 13.9355  LR: 0.000018  \n","Epoch: [1][46700/103575] Elapsed 487m 47s (remain 594m 2s) Loss: 0.0000(0.0121) Grad: 17.6726  LR: 0.000018  \n","Epoch: [1][46800/103575] Elapsed 488m 50s (remain 593m 0s) Loss: 0.0049(0.0120) Grad: 6338.0103  LR: 0.000018  \n","Epoch: [1][46900/103575] Elapsed 489m 52s (remain 591m 57s) Loss: 0.0013(0.0120) Grad: 5428.4976  LR: 0.000018  \n","Epoch: [1][47000/103575] Elapsed 490m 55s (remain 590m 55s) Loss: 0.0009(0.0120) Grad: 1670.9744  LR: 0.000018  \n","Epoch: [1][47100/103575] Elapsed 491m 58s (remain 589m 52s) Loss: 0.0059(0.0120) Grad: 3924.2217  LR: 0.000018  \n","Epoch: [1][47200/103575] Elapsed 493m 1s (remain 588m 49s) Loss: 0.0001(0.0120) Grad: 7.7547  LR: 0.000018  \n","Epoch: [1][47300/103575] Elapsed 494m 3s (remain 587m 47s) Loss: 0.0002(0.0119) Grad: 13.8114  LR: 0.000018  \n","Epoch: [1][47400/103575] Elapsed 495m 6s (remain 586m 44s) Loss: 0.0000(0.0119) Grad: 4.3480  LR: 0.000018  \n","Epoch: [1][47500/103575] Elapsed 496m 9s (remain 585m 42s) Loss: 0.0018(0.0119) Grad: 2156.6482  LR: 0.000018  \n","Epoch: [1][47600/103575] Elapsed 497m 12s (remain 584m 40s) Loss: 0.0135(0.0119) Grad: 9338.2305  LR: 0.000018  \n","Epoch: [1][47700/103575] Elapsed 498m 15s (remain 583m 37s) Loss: 0.0012(0.0119) Grad: 14547.4980  LR: 0.000018  \n","Epoch: [1][47800/103575] Elapsed 499m 18s (remain 582m 35s) Loss: 0.0006(0.0119) Grad: 656.6927  LR: 0.000018  \n","Epoch: [1][47900/103575] Elapsed 500m 21s (remain 581m 33s) Loss: 0.0003(0.0118) Grad: 280.9687  LR: 0.000018  \n","Epoch: [1][48000/103575] Elapsed 501m 25s (remain 580m 31s) Loss: 0.0030(0.0118) Grad: 12480.4717  LR: 0.000019  \n","Epoch: [1][48100/103575] Elapsed 502m 28s (remain 579m 29s) Loss: 0.0002(0.0118) Grad: 25.9556  LR: 0.000019  \n","Epoch: [1][48200/103575] Elapsed 503m 31s (remain 578m 27s) Loss: 0.0041(0.0118) Grad: 10122.3896  LR: 0.000019  \n","Epoch: [1][48300/103575] Elapsed 504m 34s (remain 577m 24s) Loss: 0.0019(0.0118) Grad: 2449.9255  LR: 0.000019  \n","Epoch: [1][48400/103575] Elapsed 505m 37s (remain 576m 22s) Loss: 0.0003(0.0117) Grad: 2403.0964  LR: 0.000019  \n","Epoch: [1][48500/103575] Elapsed 506m 39s (remain 575m 19s) Loss: 0.0006(0.0117) Grad: 3808.7178  LR: 0.000019  \n","Epoch: [1][48600/103575] Elapsed 507m 42s (remain 574m 17s) Loss: 0.0000(0.0117) Grad: 5.6819  LR: 0.000019  \n","Epoch: [1][48700/103575] Elapsed 508m 45s (remain 573m 15s) Loss: 0.0006(0.0117) Grad: 719.9879  LR: 0.000019  \n","Epoch: [1][48800/103575] Elapsed 509m 48s (remain 572m 12s) Loss: 0.0000(0.0117) Grad: 7.5520  LR: 0.000019  \n","Epoch: [1][48900/103575] Elapsed 510m 51s (remain 571m 9s) Loss: 0.0024(0.0116) Grad: 1477.6421  LR: 0.000019  \n","Epoch: [1][49000/103575] Elapsed 511m 54s (remain 570m 7s) Loss: 0.0004(0.0116) Grad: 281.6095  LR: 0.000019  \n","Epoch: [1][49100/103575] Elapsed 512m 56s (remain 569m 4s) Loss: 0.0006(0.0116) Grad: 175.4572  LR: 0.000019  \n","Epoch: [1][49200/103575] Elapsed 513m 59s (remain 568m 2s) Loss: 0.0013(0.0116) Grad: 1682.7877  LR: 0.000019  \n","Epoch: [1][49300/103575] Elapsed 515m 2s (remain 566m 59s) Loss: 0.0000(0.0116) Grad: 11.2359  LR: 0.000019  \n","Epoch: [1][49400/103575] Elapsed 516m 5s (remain 565m 56s) Loss: 0.0002(0.0115) Grad: 199.6474  LR: 0.000019  \n","Epoch: [1][49500/103575] Elapsed 517m 7s (remain 564m 54s) Loss: 0.0068(0.0115) Grad: 18912.7266  LR: 0.000019  \n","Epoch: [1][49600/103575] Elapsed 518m 10s (remain 563m 51s) Loss: 0.0037(0.0115) Grad: 6666.7993  LR: 0.000019  \n","Epoch: [1][49700/103575] Elapsed 519m 13s (remain 562m 49s) Loss: 0.0000(0.0115) Grad: 23.6717  LR: 0.000019  \n","Epoch: [1][49800/103575] Elapsed 520m 16s (remain 561m 46s) Loss: 0.0003(0.0115) Grad: 479.7634  LR: 0.000019  \n","Epoch: [1][49900/103575] Elapsed 521m 18s (remain 560m 43s) Loss: 0.0201(0.0115) Grad: 81824.0156  LR: 0.000019  \n","Epoch: [1][50000/103575] Elapsed 522m 21s (remain 559m 41s) Loss: 0.0028(0.0114) Grad: 2624.1252  LR: 0.000019  \n","Epoch: [1][50100/103575] Elapsed 523m 24s (remain 558m 38s) Loss: 0.0079(0.0114) Grad: 50107.4219  LR: 0.000019  \n","Epoch: [1][50200/103575] Elapsed 524m 27s (remain 557m 35s) Loss: 0.0000(0.0114) Grad: 28.8906  LR: 0.000019  \n","Epoch: [1][50300/103575] Elapsed 525m 29s (remain 556m 33s) Loss: 0.0013(0.0114) Grad: 1642.3683  LR: 0.000019  \n","Epoch: [1][50400/103575] Elapsed 526m 32s (remain 555m 30s) Loss: 0.0035(0.0114) Grad: 3485.6135  LR: 0.000019  \n","Epoch: [1][50500/103575] Elapsed 527m 35s (remain 554m 28s) Loss: 0.0067(0.0114) Grad: 8146.4365  LR: 0.000020  \n","Epoch: [1][50600/103575] Elapsed 528m 37s (remain 553m 25s) Loss: 0.0038(0.0113) Grad: 9617.4209  LR: 0.000020  \n","Epoch: [1][50700/103575] Elapsed 529m 40s (remain 552m 22s) Loss: 0.0004(0.0113) Grad: 66.9284  LR: 0.000020  \n","Epoch: [1][50800/103575] Elapsed 530m 43s (remain 551m 19s) Loss: 0.0000(0.0113) Grad: 14.0290  LR: 0.000020  \n","Epoch: [1][50900/103575] Elapsed 531m 45s (remain 550m 17s) Loss: 0.0058(0.0113) Grad: 3175.6377  LR: 0.000020  \n","Epoch: [1][51000/103575] Elapsed 532m 48s (remain 549m 14s) Loss: 0.0002(0.0113) Grad: 99.7106  LR: 0.000020  \n","Epoch: [1][51100/103575] Elapsed 533m 51s (remain 548m 11s) Loss: 0.0002(0.0112) Grad: 398.2298  LR: 0.000020  \n","Epoch: [1][51200/103575] Elapsed 534m 53s (remain 547m 9s) Loss: 0.0050(0.0112) Grad: 2797.5593  LR: 0.000020  \n","Epoch: [1][51300/103575] Elapsed 535m 56s (remain 546m 6s) Loss: 0.0000(0.0112) Grad: 158.5688  LR: 0.000020  \n","Epoch: [1][51400/103575] Elapsed 536m 59s (remain 545m 3s) Loss: 0.0000(0.0112) Grad: 77.3306  LR: 0.000020  \n","Epoch: [1][51500/103575] Elapsed 538m 2s (remain 544m 1s) Loss: 0.0003(0.0112) Grad: 1263.7294  LR: 0.000020  \n","Epoch: [1][51600/103575] Elapsed 539m 4s (remain 542m 58s) Loss: 0.0002(0.0112) Grad: 152.8598  LR: 0.000020  \n","Epoch: [1][51700/103575] Elapsed 540m 7s (remain 541m 55s) Loss: 0.0007(0.0111) Grad: 226.3916  LR: 0.000020  \n","Epoch: [1][51800/103575] Elapsed 541m 11s (remain 540m 54s) Loss: 0.0134(0.0111) Grad: 16444.0957  LR: 0.000020  \n","Epoch: [1][51900/103575] Elapsed 542m 14s (remain 539m 51s) Loss: 0.0034(0.0111) Grad: 19146.1543  LR: 0.000020  \n","Epoch: [1][52000/103575] Elapsed 543m 17s (remain 538m 49s) Loss: 0.0007(0.0111) Grad: 568.6189  LR: 0.000020  \n","Epoch: [1][52100/103575] Elapsed 544m 20s (remain 537m 47s) Loss: 0.0025(0.0111) Grad: 2814.4399  LR: 0.000020  \n","Epoch: [1][52200/103575] Elapsed 545m 24s (remain 536m 46s) Loss: 0.0122(0.0111) Grad: 32617.2461  LR: 0.000020  \n","Epoch: [1][52300/103575] Elapsed 546m 28s (remain 535m 44s) Loss: 0.0001(0.0110) Grad: 16.1826  LR: 0.000020  \n","Epoch: [1][52400/103575] Elapsed 547m 32s (remain 534m 42s) Loss: 0.0000(0.0110) Grad: 10.0064  LR: 0.000020  \n","Epoch: [1][52500/103575] Elapsed 548m 34s (remain 533m 40s) Loss: 0.0001(0.0110) Grad: 24.5884  LR: 0.000020  \n","Epoch: [1][52600/103575] Elapsed 549m 37s (remain 532m 37s) Loss: 0.0009(0.0110) Grad: 2504.0020  LR: 0.000020  \n","Epoch: [1][52700/103575] Elapsed 550m 40s (remain 531m 34s) Loss: 0.0012(0.0110) Grad: 222.5469  LR: 0.000020  \n","Epoch: [1][52800/103575] Elapsed 551m 43s (remain 530m 32s) Loss: 0.0024(0.0110) Grad: 1110.7189  LR: 0.000020  \n","Epoch: [1][52900/103575] Elapsed 552m 45s (remain 529m 29s) Loss: 0.0003(0.0109) Grad: 370.9653  LR: 0.000020  \n","Epoch: [1][53000/103575] Elapsed 553m 48s (remain 528m 27s) Loss: 0.0207(0.0109) Grad: 17963.7832  LR: 0.000020  \n","Epoch: [1][53100/103575] Elapsed 554m 51s (remain 527m 24s) Loss: 0.0103(0.0109) Grad: 10694.8613  LR: 0.000020  \n","Epoch: [1][53200/103575] Elapsed 555m 54s (remain 526m 22s) Loss: 0.0000(0.0109) Grad: 5.9780  LR: 0.000020  \n","Epoch: [1][53300/103575] Elapsed 556m 57s (remain 525m 19s) Loss: 0.0002(0.0109) Grad: 43.5321  LR: 0.000020  \n","Epoch: [1][53400/103575] Elapsed 558m 0s (remain 524m 16s) Loss: 0.0005(0.0109) Grad: 199.3024  LR: 0.000020  \n","Epoch: [1][53500/103575] Elapsed 559m 3s (remain 523m 14s) Loss: 0.0026(0.0108) Grad: 3783.5208  LR: 0.000020  \n","Epoch: [1][53600/103575] Elapsed 560m 6s (remain 522m 12s) Loss: 0.0000(0.0108) Grad: 7.6325  LR: 0.000020  \n","Epoch: [1][53700/103575] Elapsed 561m 8s (remain 521m 9s) Loss: 0.0001(0.0108) Grad: 72.0118  LR: 0.000020  \n","Epoch: [1][53800/103575] Elapsed 562m 11s (remain 520m 6s) Loss: 0.0002(0.0108) Grad: 293.7224  LR: 0.000020  \n","Epoch: [1][53900/103575] Elapsed 563m 14s (remain 519m 4s) Loss: 0.0023(0.0108) Grad: 1443.3929  LR: 0.000020  \n","Epoch: [1][54000/103575] Elapsed 564m 17s (remain 518m 1s) Loss: 0.0013(0.0108) Grad: 4868.7520  LR: 0.000020  \n","Epoch: [1][54100/103575] Elapsed 565m 19s (remain 516m 58s) Loss: 0.0012(0.0108) Grad: 976.3892  LR: 0.000020  \n","Epoch: [1][54200/103575] Elapsed 566m 22s (remain 515m 56s) Loss: 0.0001(0.0107) Grad: 6.0344  LR: 0.000020  \n","Epoch: [1][54300/103575] Elapsed 567m 25s (remain 514m 53s) Loss: 0.0001(0.0107) Grad: 11.6804  LR: 0.000020  \n","Epoch: [1][54400/103575] Elapsed 568m 28s (remain 513m 50s) Loss: 0.0006(0.0107) Grad: 504.4256  LR: 0.000020  \n","Epoch: [1][54500/103575] Elapsed 569m 30s (remain 512m 48s) Loss: 0.0002(0.0107) Grad: 313.6120  LR: 0.000020  \n","Epoch: [1][54600/103575] Elapsed 570m 33s (remain 511m 45s) Loss: 0.0004(0.0107) Grad: 143.1227  LR: 0.000020  \n","Epoch: [1][54700/103575] Elapsed 571m 36s (remain 510m 43s) Loss: 0.0001(0.0107) Grad: 98.2901  LR: 0.000020  \n","Epoch: [1][54800/103575] Elapsed 572m 39s (remain 509m 40s) Loss: 0.0044(0.0106) Grad: 4244.0601  LR: 0.000020  \n","Epoch: [1][54900/103575] Elapsed 573m 42s (remain 508m 38s) Loss: 0.0033(0.0106) Grad: 6196.1646  LR: 0.000020  \n","Epoch: [1][55000/103575] Elapsed 574m 45s (remain 507m 35s) Loss: 0.0005(0.0106) Grad: 326.1715  LR: 0.000020  \n","Epoch: [1][55100/103575] Elapsed 575m 48s (remain 506m 33s) Loss: 0.0001(0.0106) Grad: 93.5313  LR: 0.000020  \n","Epoch: [1][55200/103575] Elapsed 576m 51s (remain 505m 30s) Loss: 0.0000(0.0106) Grad: 9.8902  LR: 0.000020  \n","Epoch: [1][55300/103575] Elapsed 577m 54s (remain 504m 28s) Loss: 0.0002(0.0106) Grad: 25.4365  LR: 0.000020  \n","Epoch: [1][55400/103575] Elapsed 578m 56s (remain 503m 25s) Loss: 0.0014(0.0106) Grad: 451.7979  LR: 0.000020  \n","Epoch: [1][55500/103575] Elapsed 579m 59s (remain 502m 22s) Loss: 0.0002(0.0105) Grad: 704.9753  LR: 0.000020  \n","Epoch: [1][55600/103575] Elapsed 581m 2s (remain 501m 20s) Loss: 0.0095(0.0105) Grad: 12564.9600  LR: 0.000020  \n","Epoch: [1][55700/103575] Elapsed 582m 5s (remain 500m 17s) Loss: 0.0001(0.0105) Grad: 20.4996  LR: 0.000020  \n","Epoch: [1][55800/103575] Elapsed 583m 8s (remain 499m 14s) Loss: 0.0019(0.0105) Grad: 1754.9191  LR: 0.000020  \n","Epoch: [1][55900/103575] Elapsed 584m 11s (remain 498m 12s) Loss: 0.0027(0.0105) Grad: 4024.6577  LR: 0.000020  \n","Epoch: [1][56000/103575] Elapsed 585m 13s (remain 497m 10s) Loss: 0.0002(0.0105) Grad: 111.7978  LR: 0.000020  \n","Epoch: [1][56100/103575] Elapsed 586m 16s (remain 496m 7s) Loss: 0.0019(0.0105) Grad: 2660.6875  LR: 0.000020  \n","Epoch: [1][56200/103575] Elapsed 587m 19s (remain 495m 4s) Loss: 0.0008(0.0104) Grad: 2192.4524  LR: 0.000020  \n","Epoch: [1][56300/103575] Elapsed 588m 22s (remain 494m 2s) Loss: 0.0000(0.0104) Grad: 16.1008  LR: 0.000020  \n","Epoch: [1][56400/103575] Elapsed 589m 25s (remain 492m 59s) Loss: 0.0005(0.0104) Grad: 1244.1621  LR: 0.000020  \n","Epoch: [1][56500/103575] Elapsed 590m 28s (remain 491m 57s) Loss: 0.0078(0.0104) Grad: 8340.8916  LR: 0.000020  \n","Epoch: [1][56600/103575] Elapsed 591m 31s (remain 490m 54s) Loss: 0.0011(0.0104) Grad: 1745.8378  LR: 0.000020  \n","Epoch: [1][56700/103575] Elapsed 592m 34s (remain 489m 52s) Loss: 0.0005(0.0104) Grad: 1644.0391  LR: 0.000020  \n","Epoch: [1][56800/103575] Elapsed 593m 36s (remain 488m 49s) Loss: 0.0003(0.0104) Grad: 516.2541  LR: 0.000020  \n","Epoch: [1][56900/103575] Elapsed 594m 39s (remain 487m 46s) Loss: 0.0001(0.0103) Grad: 56.4420  LR: 0.000020  \n","Epoch: [1][57000/103575] Elapsed 595m 42s (remain 486m 44s) Loss: 0.0087(0.0103) Grad: 30040.9883  LR: 0.000020  \n","Epoch: [1][57100/103575] Elapsed 596m 45s (remain 485m 41s) Loss: 0.0001(0.0103) Grad: 37.8428  LR: 0.000020  \n","Epoch: [1][57200/103575] Elapsed 597m 48s (remain 484m 39s) Loss: 0.0001(0.0103) Grad: 79.4709  LR: 0.000020  \n","Epoch: [1][57300/103575] Elapsed 598m 51s (remain 483m 36s) Loss: 0.0002(0.0103) Grad: 798.5023  LR: 0.000020  \n","Epoch: [1][57400/103575] Elapsed 599m 54s (remain 482m 34s) Loss: 0.0257(0.0103) Grad: 43642.6914  LR: 0.000020  \n","Epoch: [1][57500/103575] Elapsed 600m 57s (remain 481m 31s) Loss: 0.0003(0.0103) Grad: 379.1072  LR: 0.000020  \n","Epoch: [1][57600/103575] Elapsed 602m 0s (remain 480m 29s) Loss: 0.0006(0.0102) Grad: 336.5920  LR: 0.000020  \n","Epoch: [1][57700/103575] Elapsed 603m 2s (remain 479m 26s) Loss: 0.0032(0.0102) Grad: 3526.5051  LR: 0.000020  \n","Epoch: [1][57800/103575] Elapsed 604m 5s (remain 478m 23s) Loss: 0.0006(0.0102) Grad: 2156.2783  LR: 0.000020  \n","Epoch: [1][57900/103575] Elapsed 605m 8s (remain 477m 21s) Loss: 0.0006(0.0102) Grad: 365.1957  LR: 0.000020  \n","Epoch: [1][58000/103575] Elapsed 606m 11s (remain 476m 18s) Loss: 0.0027(0.0102) Grad: 3109.6411  LR: 0.000020  \n","Epoch: [1][58100/103575] Elapsed 607m 14s (remain 475m 16s) Loss: 0.0007(0.0102) Grad: 866.9841  LR: 0.000020  \n","Epoch: [1][58200/103575] Elapsed 608m 17s (remain 474m 13s) Loss: 0.0004(0.0102) Grad: 488.7358  LR: 0.000020  \n","Epoch: [1][58300/103575] Elapsed 609m 20s (remain 473m 11s) Loss: 0.0052(0.0102) Grad: 5508.7412  LR: 0.000020  \n","Epoch: [1][58400/103575] Elapsed 610m 23s (remain 472m 8s) Loss: 0.0028(0.0101) Grad: 2473.3538  LR: 0.000020  \n","Epoch: [1][58500/103575] Elapsed 611m 26s (remain 471m 6s) Loss: 0.0031(0.0101) Grad: 3719.1218  LR: 0.000020  \n","Epoch: [1][58600/103575] Elapsed 612m 29s (remain 470m 3s) Loss: 0.0002(0.0101) Grad: 932.9332  LR: 0.000020  \n","Epoch: [1][58700/103575] Elapsed 613m 32s (remain 469m 1s) Loss: 0.0146(0.0101) Grad: 47234.6016  LR: 0.000020  \n","Epoch: [1][58800/103575] Elapsed 614m 35s (remain 467m 58s) Loss: 0.0001(0.0101) Grad: 185.0276  LR: 0.000020  \n","Epoch: [1][58900/103575] Elapsed 615m 38s (remain 466m 56s) Loss: 0.0028(0.0101) Grad: 12828.8652  LR: 0.000020  \n","Epoch: [1][59000/103575] Elapsed 616m 41s (remain 465m 53s) Loss: 0.0001(0.0101) Grad: 325.8158  LR: 0.000020  \n","Epoch: [1][59100/103575] Elapsed 617m 43s (remain 464m 50s) Loss: 0.0001(0.0100) Grad: 41.9482  LR: 0.000020  \n","Epoch: [1][59200/103575] Elapsed 618m 46s (remain 463m 48s) Loss: 0.0001(0.0100) Grad: 39.3578  LR: 0.000020  \n","Epoch: [1][59300/103575] Elapsed 619m 49s (remain 462m 45s) Loss: 0.0075(0.0100) Grad: 39130.0195  LR: 0.000020  \n","Epoch: [1][59400/103575] Elapsed 620m 52s (remain 461m 42s) Loss: 0.0078(0.0100) Grad: 32000.2051  LR: 0.000020  \n","Epoch: [1][59500/103575] Elapsed 621m 55s (remain 460m 40s) Loss: 0.0013(0.0100) Grad: 1605.2000  LR: 0.000020  \n","Epoch: [1][59600/103575] Elapsed 622m 57s (remain 459m 37s) Loss: 0.0008(0.0100) Grad: 3587.4983  LR: 0.000020  \n","Epoch: [1][59700/103575] Elapsed 624m 0s (remain 458m 35s) Loss: 0.0004(0.0100) Grad: 1123.7258  LR: 0.000020  \n","Epoch: [1][59800/103575] Elapsed 625m 3s (remain 457m 32s) Loss: 0.0068(0.0100) Grad: 16534.9941  LR: 0.000020  \n","Epoch: [1][59900/103575] Elapsed 626m 6s (remain 456m 29s) Loss: 0.0007(0.0099) Grad: 2010.9189  LR: 0.000020  \n","Epoch: [1][60000/103575] Elapsed 627m 9s (remain 455m 27s) Loss: 0.0003(0.0099) Grad: 1085.9545  LR: 0.000020  \n","Epoch: [1][60100/103575] Elapsed 628m 11s (remain 454m 24s) Loss: 0.0002(0.0099) Grad: 556.5507  LR: 0.000020  \n","Epoch: [1][60200/103575] Elapsed 629m 14s (remain 453m 21s) Loss: 0.0003(0.0099) Grad: 115.0990  LR: 0.000020  \n","Epoch: [1][60300/103575] Elapsed 630m 17s (remain 452m 18s) Loss: 0.0001(0.0099) Grad: 10.2399  LR: 0.000020  \n","Epoch: [1][60400/103575] Elapsed 631m 20s (remain 451m 16s) Loss: 0.0019(0.0099) Grad: 2188.5820  LR: 0.000020  \n","Epoch: [1][60500/103575] Elapsed 632m 23s (remain 450m 13s) Loss: 0.0124(0.0099) Grad: 35359.7266  LR: 0.000020  \n","Epoch: [1][60600/103575] Elapsed 633m 25s (remain 449m 11s) Loss: 0.0055(0.0099) Grad: 24690.6953  LR: 0.000020  \n","Epoch: [1][60700/103575] Elapsed 634m 28s (remain 448m 8s) Loss: 0.0081(0.0098) Grad: 59067.9375  LR: 0.000020  \n","Epoch: [1][60800/103575] Elapsed 635m 31s (remain 447m 5s) Loss: 0.0002(0.0098) Grad: 37.5371  LR: 0.000020  \n","Epoch: [1][60900/103575] Elapsed 636m 34s (remain 446m 3s) Loss: 0.0000(0.0098) Grad: 24.1253  LR: 0.000020  \n","Epoch: [1][61000/103575] Elapsed 637m 37s (remain 445m 0s) Loss: 0.0012(0.0098) Grad: 3000.2852  LR: 0.000020  \n","Epoch: [1][61100/103575] Elapsed 638m 40s (remain 443m 57s) Loss: 0.0005(0.0098) Grad: 778.2030  LR: 0.000020  \n","Epoch: [1][61200/103575] Elapsed 639m 42s (remain 442m 55s) Loss: 0.0008(0.0098) Grad: 4046.4065  LR: 0.000020  \n","Epoch: [1][61300/103575] Elapsed 640m 45s (remain 441m 52s) Loss: 0.0001(0.0098) Grad: 266.9408  LR: 0.000020  \n","Epoch: [1][61400/103575] Elapsed 641m 48s (remain 440m 49s) Loss: 0.0005(0.0098) Grad: 513.0827  LR: 0.000020  \n","Epoch: [1][61500/103575] Elapsed 642m 51s (remain 439m 47s) Loss: 0.0004(0.0097) Grad: 1000.0052  LR: 0.000020  \n","Epoch: [1][61600/103575] Elapsed 643m 53s (remain 438m 44s) Loss: 0.0031(0.0097) Grad: 8280.4678  LR: 0.000020  \n","Epoch: [1][61700/103575] Elapsed 644m 56s (remain 437m 42s) Loss: 0.0005(0.0097) Grad: 568.8867  LR: 0.000020  \n","Epoch: [1][61800/103575] Elapsed 645m 59s (remain 436m 39s) Loss: 0.0007(0.0097) Grad: 2130.3918  LR: 0.000020  \n","Epoch: [1][61900/103575] Elapsed 647m 2s (remain 435m 37s) Loss: 0.0011(0.0097) Grad: 15053.8037  LR: 0.000020  \n","Epoch: [1][62000/103575] Elapsed 648m 5s (remain 434m 34s) Loss: 0.0045(0.0097) Grad: 26276.4922  LR: 0.000020  \n","Epoch: [1][62100/103575] Elapsed 649m 8s (remain 433m 31s) Loss: 0.0000(0.0097) Grad: 13.9143  LR: 0.000020  \n","Epoch: [1][62200/103575] Elapsed 650m 11s (remain 432m 28s) Loss: 0.0123(0.0097) Grad: 149280.6250  LR: 0.000020  \n","Epoch: [1][62300/103575] Elapsed 651m 14s (remain 431m 26s) Loss: 0.0015(0.0096) Grad: 45289.0195  LR: 0.000020  \n","Epoch: [1][62400/103575] Elapsed 652m 17s (remain 430m 23s) Loss: 0.0007(0.0096) Grad: 2361.8806  LR: 0.000020  \n","Epoch: [1][62500/103575] Elapsed 653m 20s (remain 429m 21s) Loss: 0.0011(0.0096) Grad: 8615.0918  LR: 0.000020  \n","Epoch: [1][62600/103575] Elapsed 654m 23s (remain 428m 18s) Loss: 0.0031(0.0096) Grad: 22317.2676  LR: 0.000020  \n","Epoch: [1][62700/103575] Elapsed 655m 26s (remain 427m 16s) Loss: 0.0010(0.0096) Grad: 7709.4546  LR: 0.000020  \n","Epoch: [1][62800/103575] Elapsed 656m 28s (remain 426m 13s) Loss: 0.0001(0.0096) Grad: 664.6656  LR: 0.000020  \n","Epoch: [1][62900/103575] Elapsed 657m 31s (remain 425m 10s) Loss: 0.0090(0.0096) Grad: 22799.6875  LR: 0.000020  \n","Epoch: [1][63000/103575] Elapsed 658m 34s (remain 424m 8s) Loss: 0.0002(0.0096) Grad: 100.3718  LR: 0.000020  \n","Epoch: [1][63100/103575] Elapsed 659m 37s (remain 423m 5s) Loss: 0.0017(0.0096) Grad: 9942.9482  LR: 0.000020  \n","Epoch: [1][63200/103575] Elapsed 660m 39s (remain 422m 2s) Loss: 0.0001(0.0095) Grad: 96.7704  LR: 0.000020  \n","Epoch: [1][63300/103575] Elapsed 661m 42s (remain 421m 0s) Loss: 0.0033(0.0095) Grad: 31012.0117  LR: 0.000020  \n","Epoch: [1][63400/103575] Elapsed 662m 45s (remain 419m 57s) Loss: 0.0002(0.0095) Grad: 167.3355  LR: 0.000020  \n","Epoch: [1][63500/103575] Elapsed 663m 48s (remain 418m 54s) Loss: 0.0013(0.0095) Grad: 30288.5195  LR: 0.000019  \n","Epoch: [1][63600/103575] Elapsed 664m 51s (remain 417m 52s) Loss: 0.0008(0.0095) Grad: 1649.0896  LR: 0.000019  \n","Epoch: [1][63700/103575] Elapsed 665m 54s (remain 416m 49s) Loss: 0.0007(0.0095) Grad: 1701.0072  LR: 0.000019  \n","Epoch: [1][63800/103575] Elapsed 666m 57s (remain 415m 47s) Loss: 0.0024(0.0095) Grad: 50194.9414  LR: 0.000019  \n","Epoch: [1][63900/103575] Elapsed 668m 0s (remain 414m 44s) Loss: 0.0004(0.0095) Grad: 10002.8740  LR: 0.000019  \n","Epoch: [1][64000/103575] Elapsed 669m 3s (remain 413m 41s) Loss: 0.0017(0.0094) Grad: 14030.4502  LR: 0.000019  \n","Epoch: [1][64100/103575] Elapsed 670m 5s (remain 412m 39s) Loss: 0.0003(0.0094) Grad: 456.3472  LR: 0.000019  \n","Epoch: [1][64200/103575] Elapsed 671m 8s (remain 411m 36s) Loss: 0.0019(0.0094) Grad: 13793.9961  LR: 0.000019  \n","Epoch: [1][64300/103575] Elapsed 672m 11s (remain 410m 33s) Loss: 0.0047(0.0094) Grad: 35139.2383  LR: 0.000019  \n","Epoch: [1][64400/103575] Elapsed 673m 14s (remain 409m 30s) Loss: 0.0000(0.0094) Grad: 72.7506  LR: 0.000019  \n","Epoch: [1][64500/103575] Elapsed 674m 16s (remain 408m 28s) Loss: 0.0012(0.0094) Grad: 3314.3799  LR: 0.000019  \n","Epoch: [1][64600/103575] Elapsed 675m 19s (remain 407m 25s) Loss: 0.0001(0.0094) Grad: 24.5940  LR: 0.000019  \n","Epoch: [1][64700/103575] Elapsed 676m 22s (remain 406m 22s) Loss: 0.0006(0.0094) Grad: 4875.6855  LR: 0.000019  \n","Epoch: [1][64800/103575] Elapsed 677m 24s (remain 405m 20s) Loss: 0.0038(0.0094) Grad: 22092.8730  LR: 0.000019  \n","Epoch: [1][64900/103575] Elapsed 678m 27s (remain 404m 17s) Loss: 0.0008(0.0093) Grad: 1919.8164  LR: 0.000019  \n","Epoch: [1][65000/103575] Elapsed 679m 30s (remain 403m 14s) Loss: 0.0000(0.0093) Grad: 198.6696  LR: 0.000019  \n","Epoch: [1][65100/103575] Elapsed 680m 32s (remain 402m 11s) Loss: 0.0021(0.0093) Grad: 20782.5723  LR: 0.000019  \n","Epoch: [1][65200/103575] Elapsed 681m 35s (remain 401m 8s) Loss: 0.0002(0.0093) Grad: 54.6644  LR: 0.000019  \n","Epoch: [1][65300/103575] Elapsed 682m 37s (remain 400m 6s) Loss: 0.0003(0.0093) Grad: 520.5933  LR: 0.000019  \n","Epoch: [1][65400/103575] Elapsed 683m 40s (remain 399m 3s) Loss: 0.0002(0.0093) Grad: 3574.2627  LR: 0.000019  \n","Epoch: [1][65500/103575] Elapsed 684m 43s (remain 398m 0s) Loss: 0.0013(0.0093) Grad: 11188.9482  LR: 0.000019  \n","Epoch: [1][65600/103575] Elapsed 685m 46s (remain 396m 58s) Loss: 0.0001(0.0093) Grad: 31.5669  LR: 0.000019  \n","Epoch: [1][65700/103575] Elapsed 686m 49s (remain 395m 55s) Loss: 0.0128(0.0093) Grad: 52358.3711  LR: 0.000019  \n","Epoch: [1][65800/103575] Elapsed 687m 52s (remain 394m 53s) Loss: 0.0001(0.0092) Grad: 73.9982  LR: 0.000019  \n","Epoch: [1][65900/103575] Elapsed 688m 55s (remain 393m 50s) Loss: 0.0030(0.0092) Grad: 22088.4160  LR: 0.000019  \n","Epoch: [1][66000/103575] Elapsed 689m 58s (remain 392m 47s) Loss: 0.0041(0.0092) Grad: 30320.0820  LR: 0.000019  \n","Epoch: [1][66100/103575] Elapsed 691m 1s (remain 391m 45s) Loss: 0.0003(0.0092) Grad: 1456.2347  LR: 0.000019  \n","Epoch: [1][66200/103575] Elapsed 692m 4s (remain 390m 42s) Loss: 0.0022(0.0092) Grad: 148258.5938  LR: 0.000019  \n","Epoch: [1][66300/103575] Elapsed 693m 7s (remain 389m 39s) Loss: 0.0003(0.0092) Grad: 8451.0215  LR: 0.000019  \n","Epoch: [1][66400/103575] Elapsed 694m 9s (remain 388m 37s) Loss: 0.0004(0.0092) Grad: 1882.8264  LR: 0.000019  \n","Epoch: [1][66500/103575] Elapsed 695m 12s (remain 387m 34s) Loss: 0.0006(0.0092) Grad: 6612.4766  LR: 0.000019  \n","Epoch: [1][66600/103575] Elapsed 696m 15s (remain 386m 31s) Loss: 0.0012(0.0092) Grad: 26133.4668  LR: 0.000019  \n","Epoch: [1][66700/103575] Elapsed 697m 18s (remain 385m 29s) Loss: 0.0012(0.0092) Grad: 16643.1855  LR: 0.000019  \n","Epoch: [1][66800/103575] Elapsed 698m 21s (remain 384m 26s) Loss: 0.0003(0.0091) Grad: 3313.3030  LR: 0.000019  \n","Epoch: [1][66900/103575] Elapsed 699m 24s (remain 383m 23s) Loss: 0.0171(0.0091) Grad: 1005397.1250  LR: 0.000019  \n","Epoch: [1][67000/103575] Elapsed 700m 26s (remain 382m 21s) Loss: 0.0004(0.0091) Grad: 1107.9780  LR: 0.000019  \n","Epoch: [1][67100/103575] Elapsed 701m 29s (remain 381m 18s) Loss: 0.0061(0.0091) Grad: 157721.9375  LR: 0.000019  \n","Epoch: [1][67200/103575] Elapsed 702m 32s (remain 380m 15s) Loss: 0.0223(0.0091) Grad: 248904.7500  LR: 0.000019  \n","Epoch: [1][67300/103575] Elapsed 703m 35s (remain 379m 13s) Loss: 0.0024(0.0091) Grad: 6339.5835  LR: 0.000019  \n","Epoch: [1][67400/103575] Elapsed 704m 37s (remain 378m 10s) Loss: 0.0000(0.0091) Grad: 3.6078  LR: 0.000019  \n","Epoch: [1][67500/103575] Elapsed 705m 40s (remain 377m 7s) Loss: 0.0000(0.0091) Grad: 43.6288  LR: 0.000019  \n","Epoch: [1][67600/103575] Elapsed 706m 42s (remain 376m 4s) Loss: 0.0017(0.0091) Grad: 25102.6387  LR: 0.000019  \n","Epoch: [1][67700/103575] Elapsed 707m 45s (remain 375m 1s) Loss: 0.0003(0.0090) Grad: 683.5028  LR: 0.000019  \n","Epoch: [1][67800/103575] Elapsed 708m 47s (remain 373m 59s) Loss: 0.0012(0.0090) Grad: 19518.5527  LR: 0.000019  \n","Epoch: [1][67900/103575] Elapsed 709m 50s (remain 372m 56s) Loss: 0.0019(0.0090) Grad: 19414.2773  LR: 0.000019  \n","Epoch: [1][68000/103575] Elapsed 710m 53s (remain 371m 53s) Loss: 0.0055(0.0090) Grad: 102532.7578  LR: 0.000019  \n","Epoch: [1][68100/103575] Elapsed 711m 55s (remain 370m 50s) Loss: 0.0065(0.0090) Grad: 93444.1641  LR: 0.000019  \n","Epoch: [1][68200/103575] Elapsed 712m 58s (remain 369m 48s) Loss: 0.0009(0.0090) Grad: 3593.9207  LR: 0.000019  \n","Epoch: [1][68300/103575] Elapsed 714m 1s (remain 368m 45s) Loss: 0.0001(0.0090) Grad: 37.7939  LR: 0.000019  \n","Epoch: [1][68400/103575] Elapsed 715m 4s (remain 367m 42s) Loss: 0.0001(0.0090) Grad: 125.0792  LR: 0.000019  \n","Epoch: [1][68500/103575] Elapsed 716m 7s (remain 366m 40s) Loss: 0.0015(0.0090) Grad: 26312.4473  LR: 0.000019  \n","Epoch: [1][68600/103575] Elapsed 717m 10s (remain 365m 37s) Loss: 0.0003(0.0090) Grad: 1229.5179  LR: 0.000019  \n","Epoch: [1][68700/103575] Elapsed 718m 13s (remain 364m 34s) Loss: 0.0127(0.0089) Grad: 107071.6719  LR: 0.000019  \n","Epoch: [1][68800/103575] Elapsed 719m 16s (remain 363m 32s) Loss: 0.0001(0.0089) Grad: 36.3834  LR: 0.000019  \n","Epoch: [1][68900/103575] Elapsed 720m 18s (remain 362m 29s) Loss: 0.0047(0.0089) Grad: 229370.8281  LR: 0.000019  \n","Epoch: [1][69000/103575] Elapsed 721m 21s (remain 361m 26s) Loss: 0.0001(0.0089) Grad: 2786.1814  LR: 0.000019  \n","Epoch: [1][69100/103575] Elapsed 722m 24s (remain 360m 24s) Loss: 0.0002(0.0089) Grad: 495.5499  LR: 0.000019  \n","Epoch: [1][69200/103575] Elapsed 723m 27s (remain 359m 21s) Loss: 0.0004(0.0089) Grad: 12863.6211  LR: 0.000019  \n","Epoch: [1][69300/103575] Elapsed 724m 29s (remain 358m 18s) Loss: 0.0020(0.0089) Grad: 4574.8018  LR: 0.000019  \n","Epoch: [1][69400/103575] Elapsed 725m 32s (remain 357m 15s) Loss: 0.0002(0.0089) Grad: 288.9615  LR: 0.000019  \n","Epoch: [1][69500/103575] Elapsed 726m 34s (remain 356m 12s) Loss: 0.0007(0.0089) Grad: 16488.7324  LR: 0.000019  \n","Epoch: [1][69600/103575] Elapsed 727m 37s (remain 355m 10s) Loss: 0.0002(0.0089) Grad: 558.1357  LR: 0.000019  \n","Epoch: [1][69700/103575] Elapsed 728m 40s (remain 354m 7s) Loss: 0.0019(0.0088) Grad: 43930.1836  LR: 0.000019  \n","Epoch: [1][69800/103575] Elapsed 729m 42s (remain 353m 4s) Loss: 0.0010(0.0088) Grad: 1236.5995  LR: 0.000019  \n","Epoch: [1][69900/103575] Elapsed 730m 45s (remain 352m 2s) Loss: 0.0001(0.0088) Grad: 83.3161  LR: 0.000019  \n","Epoch: [1][70000/103575] Elapsed 731m 48s (remain 350m 59s) Loss: 0.0003(0.0088) Grad: 25366.2812  LR: 0.000019  \n","Epoch: [1][70100/103575] Elapsed 732m 50s (remain 349m 56s) Loss: 0.0001(0.0088) Grad: 916.7026  LR: 0.000019  \n","Epoch: [1][70200/103575] Elapsed 733m 53s (remain 348m 53s) Loss: 0.0002(0.0088) Grad: 1324.2393  LR: 0.000019  \n","Epoch: [1][70300/103575] Elapsed 734m 56s (remain 347m 51s) Loss: 0.0010(0.0088) Grad: 56474.1641  LR: 0.000019  \n","Epoch: [1][70400/103575] Elapsed 735m 59s (remain 346m 48s) Loss: 0.0000(0.0088) Grad: 50.6799  LR: 0.000019  \n","Epoch: [1][70500/103575] Elapsed 737m 1s (remain 345m 45s) Loss: 0.0013(0.0088) Grad: 118640.6875  LR: 0.000019  \n","Epoch: [1][70600/103575] Elapsed 738m 4s (remain 344m 42s) Loss: 0.0001(0.0088) Grad: 51.7095  LR: 0.000019  \n","Epoch: [1][70700/103575] Elapsed 739m 7s (remain 343m 40s) Loss: 0.0001(0.0087) Grad: 96.6896  LR: 0.000019  \n","Epoch: [1][70800/103575] Elapsed 740m 10s (remain 342m 37s) Loss: 0.0024(0.0087) Grad: 28841.1035  LR: 0.000019  \n","Epoch: [1][70900/103575] Elapsed 741m 12s (remain 341m 34s) Loss: 0.0004(0.0087) Grad: 1654.5994  LR: 0.000019  \n","Epoch: [1][71000/103575] Elapsed 742m 15s (remain 340m 32s) Loss: 0.0004(0.0087) Grad: 736.6613  LR: 0.000019  \n","Epoch: [1][71100/103575] Elapsed 743m 18s (remain 339m 29s) Loss: 0.0074(0.0087) Grad: 239246.5000  LR: 0.000019  \n","Epoch: [1][71200/103575] Elapsed 744m 21s (remain 338m 26s) Loss: 0.0000(0.0087) Grad: 66.3664  LR: 0.000019  \n","Epoch: [1][71300/103575] Elapsed 745m 23s (remain 337m 23s) Loss: 0.0001(0.0087) Grad: 41.0475  LR: 0.000019  \n","Epoch: [1][71400/103575] Elapsed 746m 26s (remain 336m 21s) Loss: 0.0006(0.0087) Grad: 1989.7207  LR: 0.000019  \n","Epoch: [1][71500/103575] Elapsed 747m 29s (remain 335m 18s) Loss: 0.0003(0.0087) Grad: 669.9785  LR: 0.000019  \n","Epoch: [1][71600/103575] Elapsed 748m 31s (remain 334m 15s) Loss: 0.0000(0.0087) Grad: 29.4327  LR: 0.000019  \n","Epoch: [1][71700/103575] Elapsed 749m 34s (remain 333m 13s) Loss: 0.0000(0.0086) Grad: 14.4253  LR: 0.000019  \n","Epoch: [1][71800/103575] Elapsed 750m 37s (remain 332m 10s) Loss: 0.0165(0.0086) Grad: 189848.9844  LR: 0.000019  \n","Epoch: [1][71900/103575] Elapsed 751m 39s (remain 331m 7s) Loss: 0.0021(0.0086) Grad: 45317.6406  LR: 0.000019  \n","Epoch: [1][72000/103575] Elapsed 752m 42s (remain 330m 4s) Loss: 0.0001(0.0086) Grad: 129.5171  LR: 0.000019  \n","Epoch: [1][72100/103575] Elapsed 753m 45s (remain 329m 2s) Loss: 0.0002(0.0086) Grad: 2572.1392  LR: 0.000019  \n","Epoch: [1][72200/103575] Elapsed 754m 48s (remain 327m 59s) Loss: 0.0004(0.0086) Grad: 1778.7266  LR: 0.000019  \n","Epoch: [1][72300/103575] Elapsed 755m 50s (remain 326m 56s) Loss: 0.0005(0.0086) Grad: 12618.9453  LR: 0.000019  \n","Epoch: [1][72400/103575] Elapsed 756m 53s (remain 325m 53s) Loss: 0.0001(0.0086) Grad: 20.9594  LR: 0.000019  \n","Epoch: [1][72500/103575] Elapsed 757m 56s (remain 324m 51s) Loss: 0.0000(0.0086) Grad: 5.2059  LR: 0.000019  \n","Epoch: [1][72600/103575] Elapsed 758m 59s (remain 323m 48s) Loss: 0.0007(0.0086) Grad: 3518.0325  LR: 0.000019  \n","Epoch: [1][72700/103575] Elapsed 760m 2s (remain 322m 45s) Loss: 0.0079(0.0086) Grad: 170808.6875  LR: 0.000019  \n","Epoch: [1][72800/103575] Elapsed 761m 4s (remain 321m 43s) Loss: 0.0010(0.0085) Grad: 22582.7266  LR: 0.000019  \n","Epoch: [1][72900/103575] Elapsed 762m 7s (remain 320m 40s) Loss: 0.0002(0.0085) Grad: 13221.8936  LR: 0.000019  \n","Epoch: [1][73000/103575] Elapsed 763m 10s (remain 319m 37s) Loss: 0.0040(0.0085) Grad: 73032.0078  LR: 0.000019  \n","Epoch: [1][73100/103575] Elapsed 764m 12s (remain 318m 34s) Loss: 0.0035(0.0085) Grad: 280667.1875  LR: 0.000019  \n","Epoch: [1][73200/103575] Elapsed 765m 15s (remain 317m 32s) Loss: 0.0004(0.0085) Grad: 2616.6899  LR: 0.000019  \n","Epoch: [1][73300/103575] Elapsed 766m 18s (remain 316m 29s) Loss: 0.0001(0.0085) Grad: 69.1549  LR: 0.000019  \n","Epoch: [1][73400/103575] Elapsed 767m 20s (remain 315m 26s) Loss: 0.0035(0.0085) Grad: 28433.5762  LR: 0.000019  \n","Epoch: [1][73500/103575] Elapsed 768m 23s (remain 314m 23s) Loss: 0.0000(0.0085) Grad: 51.8545  LR: 0.000019  \n","Epoch: [1][73600/103575] Elapsed 769m 26s (remain 313m 21s) Loss: 0.0004(0.0085) Grad: 1532.0520  LR: 0.000019  \n","Epoch: [1][73700/103575] Elapsed 770m 28s (remain 312m 18s) Loss: 0.0002(0.0085) Grad: 108.7196  LR: 0.000019  \n","Epoch: [1][73800/103575] Elapsed 771m 31s (remain 311m 15s) Loss: 0.0003(0.0085) Grad: 1819.4093  LR: 0.000019  \n","Epoch: [1][73900/103575] Elapsed 772m 34s (remain 310m 12s) Loss: 0.0002(0.0085) Grad: 239.9525  LR: 0.000019  \n","Epoch: [1][74000/103575] Elapsed 773m 36s (remain 309m 10s) Loss: 0.0003(0.0084) Grad: 16104.7949  LR: 0.000019  \n","Epoch: [1][74100/103575] Elapsed 774m 39s (remain 308m 7s) Loss: 0.0002(0.0084) Grad: 533.0363  LR: 0.000019  \n","Epoch: [1][74200/103575] Elapsed 775m 42s (remain 307m 4s) Loss: 0.0046(0.0084) Grad: 208904.2188  LR: 0.000019  \n","Epoch: [1][74300/103575] Elapsed 776m 45s (remain 306m 2s) Loss: 0.0003(0.0084) Grad: 1051.4534  LR: 0.000019  \n","Epoch: [1][74400/103575] Elapsed 777m 48s (remain 304m 59s) Loss: 0.0005(0.0084) Grad: 8435.8682  LR: 0.000019  \n","Epoch: [1][74500/103575] Elapsed 778m 50s (remain 303m 56s) Loss: 0.0005(0.0084) Grad: 4084.9348  LR: 0.000019  \n","Epoch: [1][74600/103575] Elapsed 779m 53s (remain 302m 53s) Loss: 0.0002(0.0084) Grad: 329.5268  LR: 0.000019  \n","Epoch: [1][74700/103575] Elapsed 780m 56s (remain 301m 51s) Loss: 0.0059(0.0084) Grad: 54842.7266  LR: 0.000019  \n","Epoch: [1][74800/103575] Elapsed 781m 58s (remain 300m 48s) Loss: 0.0013(0.0084) Grad: 4768.5527  LR: 0.000019  \n","Epoch: [1][74900/103575] Elapsed 783m 1s (remain 299m 45s) Loss: 0.0001(0.0084) Grad: 1893.8049  LR: 0.000019  \n","Epoch: [1][75000/103575] Elapsed 784m 3s (remain 298m 42s) Loss: 0.0001(0.0084) Grad: 62.5185  LR: 0.000019  \n","Epoch: [1][75100/103575] Elapsed 785m 6s (remain 297m 39s) Loss: 0.0001(0.0083) Grad: 81.9372  LR: 0.000019  \n","Epoch: [1][75200/103575] Elapsed 786m 8s (remain 296m 37s) Loss: 0.0024(0.0083) Grad: 560629.8125  LR: 0.000019  \n","Epoch: [1][75300/103575] Elapsed 787m 11s (remain 295m 34s) Loss: 0.0016(0.0083) Grad: 11574.8809  LR: 0.000019  \n","Epoch: [1][75400/103575] Elapsed 788m 14s (remain 294m 31s) Loss: 0.0023(0.0083) Grad: 50265.3594  LR: 0.000019  \n","Epoch: [1][75500/103575] Elapsed 789m 17s (remain 293m 29s) Loss: 0.0083(0.0083) Grad: 286982.1562  LR: 0.000019  \n","Epoch: [1][75600/103575] Elapsed 790m 20s (remain 292m 26s) Loss: 0.0000(0.0083) Grad: 77.5099  LR: 0.000019  \n","Epoch: [1][75700/103575] Elapsed 791m 22s (remain 291m 23s) Loss: 0.0012(0.0083) Grad: 12565.4355  LR: 0.000019  \n","Epoch: [1][75800/103575] Elapsed 792m 25s (remain 290m 20s) Loss: 0.0000(0.0083) Grad: 48.8648  LR: 0.000019  \n","Epoch: [1][75900/103575] Elapsed 793m 27s (remain 289m 18s) Loss: 0.0015(0.0083) Grad: 36549.3750  LR: 0.000019  \n","Epoch: [1][76000/103575] Elapsed 794m 30s (remain 288m 15s) Loss: 0.0219(0.0083) Grad: 274935.6875  LR: 0.000019  \n","Epoch: [1][76100/103575] Elapsed 795m 33s (remain 287m 12s) Loss: 0.0002(0.0083) Grad: 4946.5205  LR: 0.000019  \n","Epoch: [1][76200/103575] Elapsed 796m 36s (remain 286m 10s) Loss: 0.0008(0.0083) Grad: 15183.4658  LR: 0.000019  \n","Epoch: [1][76300/103575] Elapsed 797m 40s (remain 285m 7s) Loss: 0.0023(0.0082) Grad: 32779.8398  LR: 0.000019  \n","Epoch: [1][76400/103575] Elapsed 798m 43s (remain 284m 5s) Loss: 0.0003(0.0082) Grad: 281.0087  LR: 0.000019  \n","Epoch: [1][76500/103575] Elapsed 799m 46s (remain 283m 2s) Loss: 0.0000(0.0082) Grad: 36.4811  LR: 0.000019  \n","Epoch: [1][76600/103575] Elapsed 800m 48s (remain 281m 59s) Loss: 0.0019(0.0082) Grad: 11530.8418  LR: 0.000019  \n","Epoch: [1][76700/103575] Elapsed 801m 51s (remain 280m 57s) Loss: 0.0198(0.0082) Grad: 229704.6719  LR: 0.000019  \n","Epoch: [1][76800/103575] Elapsed 802m 54s (remain 279m 54s) Loss: 0.0055(0.0082) Grad: 119442.0312  LR: 0.000019  \n","Epoch: [1][76900/103575] Elapsed 803m 57s (remain 278m 51s) Loss: 0.0003(0.0082) Grad: 500.2746  LR: 0.000019  \n","Epoch: [1][77000/103575] Elapsed 805m 0s (remain 277m 48s) Loss: 0.0001(0.0082) Grad: 544.7404  LR: 0.000019  \n","Epoch: [1][77100/103575] Elapsed 806m 2s (remain 276m 46s) Loss: 0.0003(0.0082) Grad: 555.4622  LR: 0.000019  \n","Epoch: [1][77200/103575] Elapsed 807m 5s (remain 275m 43s) Loss: 0.0129(0.0082) Grad: 158822.3750  LR: 0.000019  \n","Epoch: [1][77300/103575] Elapsed 808m 8s (remain 274m 40s) Loss: 0.0006(0.0082) Grad: 4829.3545  LR: 0.000019  \n","Epoch: [1][77400/103575] Elapsed 809m 11s (remain 273m 38s) Loss: 0.0058(0.0082) Grad: 124840.0938  LR: 0.000019  \n","Epoch: [1][77500/103575] Elapsed 810m 13s (remain 272m 35s) Loss: 0.0001(0.0081) Grad: 783.4272  LR: 0.000019  \n","Epoch: [1][77600/103575] Elapsed 811m 16s (remain 271m 32s) Loss: 0.0025(0.0081) Grad: 19330.7422  LR: 0.000019  \n","Epoch: [1][77700/103575] Elapsed 812m 19s (remain 270m 29s) Loss: 0.0000(0.0081) Grad: 13.9360  LR: 0.000019  \n","Epoch: [1][77800/103575] Elapsed 813m 21s (remain 269m 27s) Loss: 0.0013(0.0081) Grad: 10287.3867  LR: 0.000019  \n","Epoch: [1][77900/103575] Elapsed 814m 24s (remain 268m 24s) Loss: 0.0028(0.0081) Grad: 68565.1875  LR: 0.000019  \n","Epoch: [1][78000/103575] Elapsed 815m 27s (remain 267m 21s) Loss: 0.0000(0.0081) Grad: 150.5338  LR: 0.000019  \n","Epoch: [1][78100/103575] Elapsed 816m 30s (remain 266m 19s) Loss: 0.0002(0.0081) Grad: 1078.0034  LR: 0.000019  \n","Epoch: [1][78200/103575] Elapsed 817m 32s (remain 265m 16s) Loss: 0.0000(0.0081) Grad: 55.9462  LR: 0.000019  \n","Epoch: [1][78300/103575] Elapsed 818m 35s (remain 264m 13s) Loss: 0.0001(0.0081) Grad: 121.8657  LR: 0.000019  \n","Epoch: [1][78400/103575] Elapsed 819m 38s (remain 263m 10s) Loss: 0.0030(0.0081) Grad: 13121.2070  LR: 0.000019  \n","Epoch: [1][78500/103575] Elapsed 820m 41s (remain 262m 8s) Loss: 0.0005(0.0081) Grad: 1542.2777  LR: 0.000019  \n","Epoch: [1][78600/103575] Elapsed 821m 45s (remain 261m 5s) Loss: 0.0037(0.0081) Grad: 11073.5283  LR: 0.000019  \n","Epoch: [1][78700/103575] Elapsed 822m 48s (remain 260m 3s) Loss: 0.0006(0.0080) Grad: 2726.9590  LR: 0.000019  \n","Epoch: [1][78800/103575] Elapsed 823m 51s (remain 259m 0s) Loss: 0.0022(0.0080) Grad: 35072.0508  LR: 0.000019  \n","Epoch: [1][78900/103575] Elapsed 824m 54s (remain 257m 57s) Loss: 0.0001(0.0080) Grad: 59.6842  LR: 0.000019  \n","Epoch: [1][79000/103575] Elapsed 825m 56s (remain 256m 55s) Loss: 0.0086(0.0080) Grad: 307643.9688  LR: 0.000019  \n","Epoch: [1][79100/103575] Elapsed 826m 59s (remain 255m 52s) Loss: 0.0001(0.0080) Grad: 125.6836  LR: 0.000019  \n","Epoch: [1][79200/103575] Elapsed 828m 2s (remain 254m 49s) Loss: 0.0009(0.0080) Grad: 9817.7705  LR: 0.000019  \n","Epoch: [1][79300/103575] Elapsed 829m 5s (remain 253m 46s) Loss: 0.0002(0.0080) Grad: 264.7902  LR: 0.000019  \n","Epoch: [1][79400/103575] Elapsed 830m 7s (remain 252m 44s) Loss: 0.0001(0.0080) Grad: 308.4397  LR: 0.000019  \n","Epoch: [1][79500/103575] Elapsed 831m 10s (remain 251m 41s) Loss: 0.0018(0.0080) Grad: 8568.7227  LR: 0.000019  \n","Epoch: [1][79600/103575] Elapsed 832m 13s (remain 250m 38s) Loss: 0.0008(0.0080) Grad: 2167.8750  LR: 0.000019  \n","Epoch: [1][79700/103575] Elapsed 833m 15s (remain 249m 35s) Loss: 0.0033(0.0080) Grad: 23977.1445  LR: 0.000019  \n","Epoch: [1][79800/103575] Elapsed 834m 18s (remain 248m 33s) Loss: 0.0029(0.0080) Grad: 39971.3320  LR: 0.000019  \n","Epoch: [1][79900/103575] Elapsed 835m 20s (remain 247m 30s) Loss: 0.0031(0.0080) Grad: 34707.5469  LR: 0.000019  \n","Epoch: [1][80000/103575] Elapsed 836m 23s (remain 246m 27s) Loss: 0.0046(0.0079) Grad: 30084.4062  LR: 0.000019  \n","Epoch: [1][80100/103575] Elapsed 837m 26s (remain 245m 25s) Loss: 0.0085(0.0079) Grad: 97087.0859  LR: 0.000019  \n","Epoch: [1][80200/103575] Elapsed 838m 29s (remain 244m 22s) Loss: 0.0017(0.0079) Grad: 10943.9141  LR: 0.000019  \n","Epoch: [1][80300/103575] Elapsed 839m 32s (remain 243m 19s) Loss: 0.0003(0.0079) Grad: 744.1581  LR: 0.000019  \n","Epoch: [1][80400/103575] Elapsed 840m 35s (remain 242m 17s) Loss: 0.0002(0.0079) Grad: 330.0525  LR: 0.000019  \n","Epoch: [1][80500/103575] Elapsed 841m 38s (remain 241m 14s) Loss: 0.0001(0.0079) Grad: 440.7469  LR: 0.000019  \n","Epoch: [1][80600/103575] Elapsed 842m 42s (remain 240m 12s) Loss: 0.0048(0.0079) Grad: 227866.1562  LR: 0.000019  \n","Epoch: [1][80700/103575] Elapsed 843m 46s (remain 239m 9s) Loss: 0.0002(0.0079) Grad: 379.5438  LR: 0.000019  \n","Epoch: [1][80800/103575] Elapsed 844m 48s (remain 238m 6s) Loss: 0.0000(0.0079) Grad: 72.2260  LR: 0.000019  \n","Epoch: [1][80900/103575] Elapsed 845m 51s (remain 237m 4s) Loss: 0.0004(0.0079) Grad: 763.7269  LR: 0.000019  \n","Epoch: [1][81000/103575] Elapsed 846m 54s (remain 236m 1s) Loss: 0.0001(0.0079) Grad: 100.3883  LR: 0.000019  \n","Epoch: [1][81100/103575] Elapsed 847m 57s (remain 234m 58s) Loss: 0.0004(0.0079) Grad: 544.6672  LR: 0.000019  \n","Epoch: [1][81200/103575] Elapsed 849m 0s (remain 233m 56s) Loss: 0.0068(0.0079) Grad: 177422.9531  LR: 0.000019  \n","Epoch: [1][81300/103575] Elapsed 850m 3s (remain 232m 53s) Loss: 0.0041(0.0079) Grad: 73717.6094  LR: 0.000019  \n","Epoch: [1][81400/103575] Elapsed 851m 5s (remain 231m 50s) Loss: 0.0007(0.0078) Grad: 3351.9773  LR: 0.000019  \n","Epoch: [1][81500/103575] Elapsed 852m 8s (remain 230m 47s) Loss: 0.0000(0.0078) Grad: 41.8985  LR: 0.000019  \n","Epoch: [1][81600/103575] Elapsed 853m 12s (remain 229m 45s) Loss: 0.0007(0.0078) Grad: 11547.7334  LR: 0.000019  \n","Epoch: [1][81700/103575] Elapsed 854m 15s (remain 228m 42s) Loss: 0.0000(0.0078) Grad: 217.0384  LR: 0.000019  \n","Epoch: [1][81800/103575] Elapsed 855m 19s (remain 227m 40s) Loss: 0.0015(0.0078) Grad: 51535.2891  LR: 0.000019  \n","Epoch: [1][81900/103575] Elapsed 856m 22s (remain 226m 37s) Loss: 0.0002(0.0078) Grad: 205.1816  LR: 0.000019  \n","Epoch: [1][82000/103575] Elapsed 857m 26s (remain 225m 35s) Loss: 0.0030(0.0078) Grad: 35055.1211  LR: 0.000019  \n","Epoch: [1][82100/103575] Elapsed 858m 30s (remain 224m 32s) Loss: 0.0057(0.0078) Grad: 55143.2070  LR: 0.000019  \n","Epoch: [1][82200/103575] Elapsed 859m 33s (remain 223m 30s) Loss: 0.0003(0.0078) Grad: 761.4720  LR: 0.000019  \n","Epoch: [1][82300/103575] Elapsed 860m 37s (remain 222m 27s) Loss: 0.0000(0.0078) Grad: 289.3838  LR: 0.000019  \n","Epoch: [1][82400/103575] Elapsed 861m 40s (remain 221m 25s) Loss: 0.0034(0.0078) Grad: 134906.9844  LR: 0.000019  \n","Epoch: [1][82500/103575] Elapsed 862m 44s (remain 220m 22s) Loss: 0.0002(0.0078) Grad: 879.5253  LR: 0.000019  \n","Epoch: [1][82600/103575] Elapsed 863m 47s (remain 219m 20s) Loss: 0.0023(0.0078) Grad: 10447.9414  LR: 0.000019  \n","Epoch: [1][82700/103575] Elapsed 864m 51s (remain 218m 17s) Loss: 0.0009(0.0078) Grad: 2556.3813  LR: 0.000019  \n","Epoch: [1][82800/103575] Elapsed 865m 55s (remain 217m 15s) Loss: 0.0024(0.0077) Grad: 20900.4180  LR: 0.000019  \n","Epoch: [1][82900/103575] Elapsed 866m 58s (remain 216m 12s) Loss: 0.0119(0.0077) Grad: 56502.2812  LR: 0.000019  \n","Epoch: [1][83000/103575] Elapsed 868m 2s (remain 215m 10s) Loss: 0.0018(0.0077) Grad: 33440.8242  LR: 0.000019  \n","Epoch: [1][83100/103575] Elapsed 869m 6s (remain 214m 7s) Loss: 0.0004(0.0077) Grad: 3318.8167  LR: 0.000019  \n","Epoch: [1][83200/103575] Elapsed 870m 9s (remain 213m 4s) Loss: 0.0032(0.0077) Grad: 17970.5879  LR: 0.000019  \n","Epoch: [1][83300/103575] Elapsed 871m 13s (remain 212m 2s) Loss: 0.0001(0.0077) Grad: 43.1345  LR: 0.000019  \n","Epoch: [1][83400/103575] Elapsed 872m 16s (remain 210m 59s) Loss: 0.0011(0.0077) Grad: 4859.3818  LR: 0.000019  \n","Epoch: [1][83500/103575] Elapsed 873m 20s (remain 209m 57s) Loss: 0.0008(0.0077) Grad: 13142.0332  LR: 0.000019  \n","Epoch: [1][83600/103575] Elapsed 874m 24s (remain 208m 54s) Loss: 0.0011(0.0077) Grad: 24622.6289  LR: 0.000019  \n","Epoch: [1][83700/103575] Elapsed 875m 27s (remain 207m 52s) Loss: 0.0001(0.0077) Grad: 753.3003  LR: 0.000019  \n","Epoch: [1][83800/103575] Elapsed 876m 31s (remain 206m 49s) Loss: 0.0001(0.0077) Grad: 62.9925  LR: 0.000019  \n","Epoch: [1][83900/103575] Elapsed 877m 34s (remain 205m 47s) Loss: 0.0000(0.0077) Grad: 118.5018  LR: 0.000019  \n","Epoch: [1][84000/103575] Elapsed 878m 38s (remain 204m 44s) Loss: 0.0001(0.0077) Grad: 508.4158  LR: 0.000019  \n","Epoch: [1][84100/103575] Elapsed 879m 41s (remain 203m 41s) Loss: 0.0003(0.0077) Grad: 4547.9995  LR: 0.000019  \n","Epoch: [1][84200/103575] Elapsed 880m 45s (remain 202m 39s) Loss: 0.0001(0.0076) Grad: 210.7036  LR: 0.000019  \n","Epoch: [1][84300/103575] Elapsed 881m 49s (remain 201m 36s) Loss: 0.0000(0.0076) Grad: 186.6146  LR: 0.000019  \n","Epoch: [1][84400/103575] Elapsed 882m 52s (remain 200m 34s) Loss: 0.0006(0.0076) Grad: 77482.0938  LR: 0.000019  \n","Epoch: [1][84500/103575] Elapsed 883m 56s (remain 199m 31s) Loss: 0.0003(0.0076) Grad: 842.4637  LR: 0.000019  \n","Epoch: [1][84600/103575] Elapsed 885m 0s (remain 198m 29s) Loss: 0.0005(0.0076) Grad: 25641.8828  LR: 0.000019  \n","Epoch: [1][84700/103575] Elapsed 886m 4s (remain 197m 26s) Loss: 0.0007(0.0076) Grad: 55076.0664  LR: 0.000019  \n","Epoch: [1][84800/103575] Elapsed 887m 7s (remain 196m 23s) Loss: 0.0020(0.0076) Grad: 12987.4072  LR: 0.000019  \n","Epoch: [1][84900/103575] Elapsed 888m 11s (remain 195m 21s) Loss: 0.0014(0.0076) Grad: 40792.7305  LR: 0.000019  \n","Epoch: [1][85000/103575] Elapsed 889m 14s (remain 194m 18s) Loss: 0.0037(0.0076) Grad: 79965.6250  LR: 0.000019  \n","Epoch: [1][85100/103575] Elapsed 890m 18s (remain 193m 16s) Loss: 0.0032(0.0076) Grad: 30526.5430  LR: 0.000019  \n","Epoch: [1][85200/103575] Elapsed 891m 22s (remain 192m 13s) Loss: 0.0006(0.0076) Grad: 70870.6953  LR: 0.000019  \n","Epoch: [1][85300/103575] Elapsed 892m 25s (remain 191m 11s) Loss: 0.0023(0.0076) Grad: 107970.6641  LR: 0.000019  \n","Epoch: [1][85400/103575] Elapsed 893m 29s (remain 190m 8s) Loss: 0.0031(0.0076) Grad: 99124.5000  LR: 0.000019  \n","Epoch: [1][85500/103575] Elapsed 894m 32s (remain 189m 5s) Loss: 0.0002(0.0076) Grad: 595.5235  LR: 0.000019  \n","Epoch: [1][85600/103575] Elapsed 895m 36s (remain 188m 3s) Loss: 0.0001(0.0076) Grad: 397.2177  LR: 0.000019  \n","Epoch: [1][85700/103575] Elapsed 896m 40s (remain 187m 0s) Loss: 0.0001(0.0075) Grad: 94.3317  LR: 0.000019  \n","Epoch: [1][85800/103575] Elapsed 897m 43s (remain 185m 58s) Loss: 0.0027(0.0075) Grad: 39354.5195  LR: 0.000019  \n","Epoch: [1][85900/103575] Elapsed 898m 47s (remain 184m 55s) Loss: 0.0007(0.0075) Grad: 17595.8848  LR: 0.000019  \n","Epoch: [1][86000/103575] Elapsed 899m 50s (remain 183m 52s) Loss: 0.0013(0.0075) Grad: 25538.0156  LR: 0.000019  \n","Epoch: [1][86100/103575] Elapsed 900m 54s (remain 182m 50s) Loss: 0.0001(0.0075) Grad: 90.6303  LR: 0.000019  \n","Epoch: [1][86200/103575] Elapsed 901m 58s (remain 181m 47s) Loss: 0.0021(0.0075) Grad: 21863.6797  LR: 0.000019  \n","Epoch: [1][86300/103575] Elapsed 903m 1s (remain 180m 45s) Loss: 0.0010(0.0075) Grad: 8392.8594  LR: 0.000019  \n","Epoch: [1][86400/103575] Elapsed 904m 5s (remain 179m 42s) Loss: 0.0001(0.0075) Grad: 270.2481  LR: 0.000019  \n","Epoch: [1][86500/103575] Elapsed 905m 9s (remain 178m 39s) Loss: 0.0000(0.0075) Grad: 116.7004  LR: 0.000019  \n","Epoch: [1][86600/103575] Elapsed 906m 12s (remain 177m 37s) Loss: 0.0003(0.0075) Grad: 1255.8927  LR: 0.000019  \n","Epoch: [1][86700/103575] Elapsed 907m 16s (remain 176m 34s) Loss: 0.0006(0.0075) Grad: 18613.0840  LR: 0.000019  \n","Epoch: [1][86800/103575] Elapsed 908m 19s (remain 175m 31s) Loss: 0.0029(0.0075) Grad: 99862.1797  LR: 0.000018  \n","Epoch: [1][86900/103575] Elapsed 909m 23s (remain 174m 29s) Loss: 0.0026(0.0075) Grad: 76888.5156  LR: 0.000018  \n","Epoch: [1][87000/103575] Elapsed 910m 26s (remain 173m 26s) Loss: 0.0032(0.0075) Grad: 50558.3125  LR: 0.000018  \n","Epoch: [1][87100/103575] Elapsed 911m 30s (remain 172m 23s) Loss: 0.0000(0.0075) Grad: 387.4971  LR: 0.000018  \n","Epoch: [1][87200/103575] Elapsed 912m 33s (remain 171m 21s) Loss: 0.0004(0.0074) Grad: 923.3123  LR: 0.000018  \n","Epoch: [1][87300/103575] Elapsed 913m 37s (remain 170m 18s) Loss: 0.0040(0.0074) Grad: 98442.3828  LR: 0.000018  \n","Epoch: [1][87400/103575] Elapsed 914m 41s (remain 169m 16s) Loss: 0.0000(0.0074) Grad: 38.8268  LR: 0.000018  \n","Epoch: [1][87500/103575] Elapsed 915m 44s (remain 168m 13s) Loss: 0.0002(0.0074) Grad: 2574.8723  LR: 0.000018  \n","Epoch: [1][87600/103575] Elapsed 916m 49s (remain 167m 10s) Loss: 0.0017(0.0074) Grad: 49440.3047  LR: 0.000018  \n","Epoch: [1][87700/103575] Elapsed 917m 53s (remain 166m 8s) Loss: 0.0005(0.0074) Grad: 41824.8789  LR: 0.000018  \n","Epoch: [1][87800/103575] Elapsed 918m 57s (remain 165m 5s) Loss: 0.0012(0.0074) Grad: 42525.6953  LR: 0.000018  \n","Epoch: [1][87900/103575] Elapsed 920m 0s (remain 164m 3s) Loss: 0.0013(0.0074) Grad: 173111.8281  LR: 0.000018  \n","Epoch: [1][88000/103575] Elapsed 921m 4s (remain 163m 0s) Loss: 0.0028(0.0074) Grad: 72196.7266  LR: 0.000018  \n","Epoch: [1][88100/103575] Elapsed 922m 7s (remain 161m 57s) Loss: 0.0026(0.0074) Grad: 56357.2578  LR: 0.000018  \n","Epoch: [1][88200/103575] Elapsed 923m 11s (remain 160m 55s) Loss: 0.0053(0.0074) Grad: 520238.0938  LR: 0.000018  \n","Epoch: [1][88300/103575] Elapsed 924m 14s (remain 159m 52s) Loss: 0.0098(0.0074) Grad: 159761.0000  LR: 0.000018  \n","Epoch: [1][88400/103575] Elapsed 925m 17s (remain 158m 49s) Loss: 0.0096(0.0074) Grad: 511056.8438  LR: 0.000018  \n","Epoch: [1][88500/103575] Elapsed 926m 21s (remain 157m 46s) Loss: 0.0002(0.0074) Grad: 335.7315  LR: 0.000018  \n","Epoch: [1][88600/103575] Elapsed 927m 24s (remain 156m 44s) Loss: 0.0022(0.0074) Grad: 45946.4609  LR: 0.000018  \n","Epoch: [1][88700/103575] Elapsed 928m 28s (remain 155m 41s) Loss: 0.0049(0.0074) Grad: 158796.9688  LR: 0.000018  \n","Epoch: [1][88800/103575] Elapsed 929m 31s (remain 154m 38s) Loss: 0.0041(0.0073) Grad: 22281.8535  LR: 0.000018  \n","Epoch: [1][88900/103575] Elapsed 930m 35s (remain 153m 36s) Loss: 0.0002(0.0073) Grad: 2824.8247  LR: 0.000018  \n","Epoch: [1][89000/103575] Elapsed 931m 39s (remain 152m 33s) Loss: 0.0001(0.0073) Grad: 635.7733  LR: 0.000018  \n","Epoch: [1][89100/103575] Elapsed 932m 42s (remain 151m 30s) Loss: 0.0047(0.0073) Grad: 82514.2891  LR: 0.000018  \n","Epoch: [1][89200/103575] Elapsed 933m 46s (remain 150m 28s) Loss: 0.0001(0.0073) Grad: 20.1746  LR: 0.000018  \n","Epoch: [1][89300/103575] Elapsed 934m 49s (remain 149m 25s) Loss: 0.0064(0.0073) Grad: 75546.6641  LR: 0.000018  \n","Epoch: [1][89400/103575] Elapsed 935m 52s (remain 148m 22s) Loss: 0.0016(0.0073) Grad: 50925.2695  LR: 0.000018  \n","Epoch: [1][89500/103575] Elapsed 936m 56s (remain 147m 19s) Loss: 0.0003(0.0073) Grad: 906.0987  LR: 0.000018  \n","Epoch: [1][89600/103575] Elapsed 937m 59s (remain 146m 17s) Loss: 0.0003(0.0073) Grad: 417.6588  LR: 0.000018  \n","Epoch: [1][89700/103575] Elapsed 939m 3s (remain 145m 14s) Loss: 0.0005(0.0073) Grad: 8995.7432  LR: 0.000018  \n","Epoch: [1][89800/103575] Elapsed 940m 6s (remain 144m 11s) Loss: 0.0001(0.0073) Grad: 241.4813  LR: 0.000018  \n","Epoch: [1][89900/103575] Elapsed 941m 10s (remain 143m 9s) Loss: 0.0041(0.0073) Grad: 63748.7734  LR: 0.000018  \n","Epoch: [1][90000/103575] Elapsed 942m 14s (remain 142m 6s) Loss: 0.0093(0.0073) Grad: 392961.1562  LR: 0.000018  \n","Epoch: [1][90100/103575] Elapsed 943m 17s (remain 141m 3s) Loss: 0.0016(0.0073) Grad: 3613.1777  LR: 0.000018  \n","Epoch: [1][90200/103575] Elapsed 944m 21s (remain 140m 1s) Loss: 0.0002(0.0073) Grad: 9332.9678  LR: 0.000018  \n","Epoch: [1][90300/103575] Elapsed 945m 24s (remain 138m 58s) Loss: 0.0032(0.0073) Grad: 22980.9863  LR: 0.000018  \n","Epoch: [1][90400/103575] Elapsed 946m 28s (remain 137m 55s) Loss: 0.0007(0.0073) Grad: 23555.7090  LR: 0.000018  \n","Epoch: [1][90500/103575] Elapsed 947m 32s (remain 136m 53s) Loss: 0.0003(0.0072) Grad: 2102.9307  LR: 0.000018  \n","Epoch: [1][90600/103575] Elapsed 948m 36s (remain 135m 50s) Loss: 0.0021(0.0072) Grad: 36696.2617  LR: 0.000018  \n","Epoch: [1][90700/103575] Elapsed 949m 39s (remain 134m 47s) Loss: 0.0076(0.0072) Grad: 38282.5898  LR: 0.000018  \n","Epoch: [1][90800/103575] Elapsed 950m 43s (remain 133m 44s) Loss: 0.0037(0.0072) Grad: 21318.4473  LR: 0.000018  \n","Epoch: [1][90900/103575] Elapsed 951m 47s (remain 132m 42s) Loss: 0.0001(0.0072) Grad: 125.7856  LR: 0.000018  \n","Epoch: [1][91000/103575] Elapsed 952m 50s (remain 131m 39s) Loss: 0.0003(0.0072) Grad: 2369.9077  LR: 0.000018  \n","Epoch: [1][91100/103575] Elapsed 953m 54s (remain 130m 36s) Loss: 0.0025(0.0072) Grad: 16592.8203  LR: 0.000018  \n","Epoch: [1][91200/103575] Elapsed 954m 58s (remain 129m 34s) Loss: 0.0001(0.0072) Grad: 12.9153  LR: 0.000018  \n","Epoch: [1][91300/103575] Elapsed 956m 1s (remain 128m 31s) Loss: 0.0000(0.0072) Grad: 33.9783  LR: 0.000018  \n","Epoch: [1][91400/103575] Elapsed 957m 4s (remain 127m 28s) Loss: 0.0001(0.0072) Grad: 158.7015  LR: 0.000018  \n","Epoch: [1][91500/103575] Elapsed 958m 8s (remain 126m 25s) Loss: 0.0001(0.0072) Grad: 157.6934  LR: 0.000018  \n","Epoch: [1][91600/103575] Elapsed 959m 11s (remain 125m 23s) Loss: 0.0003(0.0072) Grad: 1774.1395  LR: 0.000018  \n","Epoch: [1][91700/103575] Elapsed 960m 14s (remain 124m 20s) Loss: 0.0001(0.0072) Grad: 159.4603  LR: 0.000018  \n","Epoch: [1][91800/103575] Elapsed 961m 18s (remain 123m 17s) Loss: 0.0013(0.0072) Grad: 21181.9004  LR: 0.000018  \n","Epoch: [1][91900/103575] Elapsed 962m 22s (remain 122m 14s) Loss: 0.0053(0.0072) Grad: 93509.6094  LR: 0.000018  \n","Epoch: [1][92000/103575] Elapsed 963m 25s (remain 121m 12s) Loss: 0.0001(0.0072) Grad: 99.8414  LR: 0.000018  \n","Epoch: [1][92100/103575] Elapsed 964m 29s (remain 120m 9s) Loss: 0.0005(0.0072) Grad: 3232.7537  LR: 0.000018  \n","Epoch: [1][92200/103575] Elapsed 965m 32s (remain 119m 6s) Loss: 0.0022(0.0071) Grad: 28421.8320  LR: 0.000018  \n","Epoch: [1][92300/103575] Elapsed 966m 36s (remain 118m 3s) Loss: 0.0002(0.0071) Grad: 564.7369  LR: 0.000018  \n","Epoch: [1][92400/103575] Elapsed 967m 40s (remain 117m 1s) Loss: 0.0069(0.0071) Grad: 36795.2383  LR: 0.000018  \n","Epoch: [1][92500/103575] Elapsed 968m 43s (remain 115m 58s) Loss: 0.0033(0.0071) Grad: 45998.0664  LR: 0.000018  \n","Epoch: [1][92600/103575] Elapsed 969m 47s (remain 114m 55s) Loss: 0.0009(0.0071) Grad: 6750.4209  LR: 0.000018  \n","Epoch: [1][92700/103575] Elapsed 970m 50s (remain 113m 52s) Loss: 0.0002(0.0071) Grad: 2555.0798  LR: 0.000018  \n","Epoch: [1][92800/103575] Elapsed 971m 54s (remain 112m 50s) Loss: 0.0074(0.0071) Grad: 66171.2578  LR: 0.000018  \n","Epoch: [1][92900/103575] Elapsed 972m 57s (remain 111m 47s) Loss: 0.0001(0.0071) Grad: 24.0421  LR: 0.000018  \n","Epoch: [1][93000/103575] Elapsed 974m 0s (remain 110m 44s) Loss: 0.0001(0.0071) Grad: 104.9054  LR: 0.000018  \n","Epoch: [1][93100/103575] Elapsed 975m 4s (remain 109m 41s) Loss: 0.0017(0.0071) Grad: 20228.8262  LR: 0.000018  \n","Epoch: [1][93200/103575] Elapsed 976m 7s (remain 108m 39s) Loss: 0.0013(0.0071) Grad: 7140.5356  LR: 0.000018  \n","Epoch: [1][93300/103575] Elapsed 977m 11s (remain 107m 36s) Loss: 0.0001(0.0071) Grad: 452.6819  LR: 0.000018  \n","Epoch: [1][93400/103575] Elapsed 978m 14s (remain 106m 33s) Loss: 0.0013(0.0071) Grad: 11245.0098  LR: 0.000018  \n","Epoch: [1][93500/103575] Elapsed 979m 18s (remain 105m 30s) Loss: 0.0006(0.0071) Grad: 5435.1875  LR: 0.000018  \n","Epoch: [1][93600/103575] Elapsed 980m 21s (remain 104m 27s) Loss: 0.0001(0.0071) Grad: 144.9413  LR: 0.000018  \n","Epoch: [1][93700/103575] Elapsed 981m 25s (remain 103m 25s) Loss: 0.0029(0.0071) Grad: 56551.0664  LR: 0.000018  \n","Epoch: [1][93800/103575] Elapsed 982m 28s (remain 102m 22s) Loss: 0.0109(0.0071) Grad: 84316.8125  LR: 0.000018  \n","Epoch: [1][93900/103575] Elapsed 983m 32s (remain 101m 19s) Loss: 0.0001(0.0071) Grad: 106.3342  LR: 0.000018  \n","Epoch: [1][94000/103575] Elapsed 984m 35s (remain 100m 16s) Loss: 0.0009(0.0070) Grad: 3875.1501  LR: 0.000018  \n","Epoch: [1][94100/103575] Elapsed 985m 39s (remain 99m 14s) Loss: 0.0001(0.0070) Grad: 46.0814  LR: 0.000018  \n","Epoch: [1][94200/103575] Elapsed 986m 42s (remain 98m 11s) Loss: 0.0001(0.0070) Grad: 369.5825  LR: 0.000018  \n","Epoch: [1][94300/103575] Elapsed 987m 45s (remain 97m 8s) Loss: 0.0052(0.0070) Grad: 24995.4668  LR: 0.000018  \n","Epoch: [1][94400/103575] Elapsed 988m 49s (remain 96m 5s) Loss: 0.0008(0.0070) Grad: 1588.8280  LR: 0.000018  \n","Epoch: [1][94500/103575] Elapsed 989m 53s (remain 95m 2s) Loss: 0.0016(0.0070) Grad: 217453.3125  LR: 0.000018  \n","Epoch: [1][94600/103575] Elapsed 990m 56s (remain 94m 0s) Loss: 0.0001(0.0070) Grad: 67.4165  LR: 0.000018  \n","Epoch: [1][94700/103575] Elapsed 992m 0s (remain 92m 57s) Loss: 0.0028(0.0070) Grad: 299160.8750  LR: 0.000018  \n","Epoch: [1][94800/103575] Elapsed 993m 3s (remain 91m 54s) Loss: 0.0011(0.0070) Grad: 42199.1406  LR: 0.000018  \n","Epoch: [1][94900/103575] Elapsed 994m 7s (remain 90m 51s) Loss: 0.0007(0.0070) Grad: 8180.8535  LR: 0.000018  \n","Epoch: [1][95000/103575] Elapsed 995m 10s (remain 89m 48s) Loss: 0.0004(0.0070) Grad: 2228.4385  LR: 0.000018  \n","Epoch: [1][95100/103575] Elapsed 996m 14s (remain 88m 46s) Loss: 0.0001(0.0070) Grad: 56.0765  LR: 0.000018  \n","Epoch: [1][95200/103575] Elapsed 997m 17s (remain 87m 43s) Loss: 0.0001(0.0070) Grad: 122.4728  LR: 0.000018  \n","Epoch: [1][95300/103575] Elapsed 998m 21s (remain 86m 40s) Loss: 0.0021(0.0070) Grad: 153918.4375  LR: 0.000018  \n","Epoch: [1][95400/103575] Elapsed 999m 24s (remain 85m 37s) Loss: 0.0006(0.0070) Grad: 5268.1348  LR: 0.000018  \n","Epoch: [1][95500/103575] Elapsed 1000m 28s (remain 84m 35s) Loss: 0.0002(0.0070) Grad: 790.1159  LR: 0.000018  \n","Epoch: [1][95600/103575] Elapsed 1001m 31s (remain 83m 32s) Loss: 0.0015(0.0070) Grad: 24519.9980  LR: 0.000018  \n","Epoch: [1][95700/103575] Elapsed 1002m 35s (remain 82m 29s) Loss: 0.0062(0.0070) Grad: 19674.9023  LR: 0.000018  \n","Epoch: [1][95800/103575] Elapsed 1003m 38s (remain 81m 26s) Loss: 0.0000(0.0069) Grad: 24.8352  LR: 0.000018  \n","Epoch: [1][95900/103575] Elapsed 1004m 42s (remain 80m 23s) Loss: 0.0000(0.0069) Grad: 88.2868  LR: 0.000018  \n","Epoch: [1][96000/103575] Elapsed 1005m 45s (remain 79m 20s) Loss: 0.0004(0.0069) Grad: 13822.7793  LR: 0.000018  \n","Epoch: [1][96100/103575] Elapsed 1006m 48s (remain 78m 18s) Loss: 0.0011(0.0069) Grad: 7008.2466  LR: 0.000018  \n","Epoch: [1][96200/103575] Elapsed 1007m 52s (remain 77m 15s) Loss: 0.0003(0.0069) Grad: 110.0211  LR: 0.000018  \n","Epoch: [1][96300/103575] Elapsed 1008m 55s (remain 76m 12s) Loss: 0.0006(0.0069) Grad: 856.3978  LR: 0.000018  \n","Epoch: [1][96400/103575] Elapsed 1009m 59s (remain 75m 9s) Loss: 0.0199(0.0069) Grad: 218010.3750  LR: 0.000018  \n","Epoch: [1][96500/103575] Elapsed 1011m 2s (remain 74m 6s) Loss: 0.0020(0.0069) Grad: 2533.5017  LR: 0.000018  \n","Epoch: [1][96600/103575] Elapsed 1012m 5s (remain 73m 4s) Loss: 0.0014(0.0069) Grad: 30460.1484  LR: 0.000018  \n","Epoch: [1][96700/103575] Elapsed 1013m 9s (remain 72m 1s) Loss: 0.0027(0.0069) Grad: 41729.4023  LR: 0.000018  \n","Epoch: [1][96800/103575] Elapsed 1014m 13s (remain 70m 58s) Loss: 0.0032(0.0069) Grad: 110021.4141  LR: 0.000018  \n","Epoch: [1][96900/103575] Elapsed 1015m 16s (remain 69m 55s) Loss: 0.0000(0.0069) Grad: 899.6193  LR: 0.000018  \n","Epoch: [1][97000/103575] Elapsed 1016m 20s (remain 68m 52s) Loss: 0.0051(0.0069) Grad: 707972.0625  LR: 0.000018  \n","Epoch: [1][97100/103575] Elapsed 1017m 23s (remain 67m 49s) Loss: 0.0001(0.0069) Grad: 202.5287  LR: 0.000018  \n","Epoch: [1][97200/103575] Elapsed 1018m 27s (remain 66m 47s) Loss: 0.0000(0.0069) Grad: 72.4385  LR: 0.000018  \n","Epoch: [1][97300/103575] Elapsed 1019m 30s (remain 65m 44s) Loss: 0.0046(0.0069) Grad: 521414.5938  LR: 0.000018  \n","Epoch: [1][97400/103575] Elapsed 1020m 34s (remain 64m 41s) Loss: 0.0054(0.0069) Grad: 98877.9844  LR: 0.000018  \n","Epoch: [1][97500/103575] Elapsed 1021m 37s (remain 63m 38s) Loss: 0.0001(0.0069) Grad: 445.0073  LR: 0.000018  \n","Epoch: [1][97600/103575] Elapsed 1022m 41s (remain 62m 35s) Loss: 0.0003(0.0069) Grad: 19336.9258  LR: 0.000018  \n","Epoch: [1][97700/103575] Elapsed 1023m 44s (remain 61m 33s) Loss: 0.0001(0.0068) Grad: 40.5219  LR: 0.000018  \n","Epoch: [1][97800/103575] Elapsed 1024m 48s (remain 60m 30s) Loss: 0.0057(0.0068) Grad: 147639.7969  LR: 0.000018  \n","Epoch: [1][97900/103575] Elapsed 1025m 51s (remain 59m 27s) Loss: 0.0081(0.0068) Grad: 92718.8672  LR: 0.000018  \n","Epoch: [1][98000/103575] Elapsed 1026m 55s (remain 58m 24s) Loss: 0.0002(0.0068) Grad: 108.4551  LR: 0.000018  \n","Epoch: [1][98100/103575] Elapsed 1027m 58s (remain 57m 21s) Loss: 0.0011(0.0068) Grad: 13599.4219  LR: 0.000018  \n","Epoch: [1][98200/103575] Elapsed 1029m 1s (remain 56m 18s) Loss: 0.0002(0.0068) Grad: 566.1067  LR: 0.000018  \n","Epoch: [1][98300/103575] Elapsed 1030m 5s (remain 55m 15s) Loss: 0.0014(0.0068) Grad: 23232.5410  LR: 0.000018  \n","Epoch: [1][98400/103575] Elapsed 1031m 8s (remain 54m 13s) Loss: 0.0003(0.0068) Grad: 1700.4362  LR: 0.000018  \n","Epoch: [1][98500/103575] Elapsed 1032m 11s (remain 53m 10s) Loss: 0.0026(0.0068) Grad: 50125.9688  LR: 0.000018  \n","Epoch: [1][98600/103575] Elapsed 1033m 15s (remain 52m 7s) Loss: 0.0013(0.0068) Grad: 4999.0142  LR: 0.000018  \n","Epoch: [1][98700/103575] Elapsed 1034m 19s (remain 51m 4s) Loss: 0.0063(0.0068) Grad: 254066.0625  LR: 0.000018  \n","Epoch: [1][98800/103575] Elapsed 1035m 23s (remain 50m 1s) Loss: 0.0003(0.0068) Grad: 631.1779  LR: 0.000018  \n","Epoch: [1][98900/103575] Elapsed 1036m 26s (remain 48m 58s) Loss: 0.0003(0.0068) Grad: 1619.3870  LR: 0.000018  \n","Epoch: [1][99000/103575] Elapsed 1037m 30s (remain 47m 56s) Loss: 0.0001(0.0068) Grad: 21.2754  LR: 0.000018  \n","Epoch: [1][99100/103575] Elapsed 1038m 34s (remain 46m 53s) Loss: 0.0003(0.0068) Grad: 456.8258  LR: 0.000018  \n","Epoch: [1][99200/103575] Elapsed 1039m 37s (remain 45m 50s) Loss: 0.0001(0.0068) Grad: 62.0079  LR: 0.000018  \n","Epoch: [1][99300/103575] Elapsed 1040m 41s (remain 44m 47s) Loss: 0.0001(0.0068) Grad: 1870.8646  LR: 0.000018  \n","Epoch: [1][99400/103575] Elapsed 1041m 44s (remain 43m 44s) Loss: 0.0117(0.0068) Grad: 87978.0156  LR: 0.000018  \n","Epoch: [1][99500/103575] Elapsed 1042m 48s (remain 42m 41s) Loss: 0.0001(0.0068) Grad: 261.6619  LR: 0.000018  \n","Epoch: [1][99600/103575] Elapsed 1043m 51s (remain 41m 38s) Loss: 0.0021(0.0068) Grad: 46729.1055  LR: 0.000018  \n","Epoch: [1][99700/103575] Elapsed 1044m 55s (remain 40m 36s) Loss: 0.0002(0.0067) Grad: 671.6450  LR: 0.000018  \n","Epoch: [1][99800/103575] Elapsed 1045m 58s (remain 39m 33s) Loss: 0.0025(0.0067) Grad: 49713.7812  LR: 0.000018  \n","Epoch: [1][99900/103575] Elapsed 1047m 2s (remain 38m 30s) Loss: 0.0012(0.0067) Grad: 5049.5527  LR: 0.000018  \n","Epoch: [1][100000/103575] Elapsed 1048m 5s (remain 37m 27s) Loss: 0.0001(0.0067) Grad: 147.6990  LR: 0.000018  \n","Epoch: [1][100100/103575] Elapsed 1049m 9s (remain 36m 24s) Loss: 0.0026(0.0067) Grad: 52859.7344  LR: 0.000018  \n","Epoch: [1][100200/103575] Elapsed 1050m 12s (remain 35m 21s) Loss: 0.0003(0.0067) Grad: 342.5952  LR: 0.000018  \n","Epoch: [1][100300/103575] Elapsed 1051m 16s (remain 34m 18s) Loss: 0.0001(0.0067) Grad: 98.3615  LR: 0.000018  \n","Epoch: [1][100400/103575] Elapsed 1052m 19s (remain 33m 16s) Loss: 0.0004(0.0067) Grad: 924.4631  LR: 0.000018  \n","Epoch: [1][100500/103575] Elapsed 1053m 23s (remain 32m 13s) Loss: 0.0064(0.0067) Grad: 105528.9375  LR: 0.000018  \n","Epoch: [1][100600/103575] Elapsed 1054m 26s (remain 31m 10s) Loss: 0.0003(0.0067) Grad: 3060.0586  LR: 0.000018  \n","Epoch: [1][100700/103575] Elapsed 1055m 29s (remain 30m 7s) Loss: 0.0067(0.0067) Grad: 90960.6641  LR: 0.000018  \n","Epoch: [1][100800/103575] Elapsed 1056m 33s (remain 29m 4s) Loss: 0.0000(0.0067) Grad: 65.6280  LR: 0.000018  \n","Epoch: [1][100900/103575] Elapsed 1057m 36s (remain 28m 1s) Loss: 0.0011(0.0067) Grad: 6237.1890  LR: 0.000018  \n","Epoch: [1][101000/103575] Elapsed 1058m 40s (remain 26m 58s) Loss: 0.0020(0.0067) Grad: 29242.1191  LR: 0.000018  \n","Epoch: [1][101100/103575] Elapsed 1059m 43s (remain 25m 55s) Loss: 0.0009(0.0067) Grad: 12370.3164  LR: 0.000018  \n","Epoch: [1][101200/103575] Elapsed 1060m 47s (remain 24m 53s) Loss: 0.0009(0.0067) Grad: 1395.0598  LR: 0.000018  \n","Epoch: [1][101300/103575] Elapsed 1061m 50s (remain 23m 50s) Loss: 0.0022(0.0067) Grad: 54938.2969  LR: 0.000018  \n","Epoch: [1][101400/103575] Elapsed 1062m 54s (remain 22m 47s) Loss: 0.0014(0.0067) Grad: 19801.5605  LR: 0.000018  \n","Epoch: [1][101500/103575] Elapsed 1063m 57s (remain 21m 44s) Loss: 0.0002(0.0067) Grad: 4204.0083  LR: 0.000018  \n","Epoch: [1][101600/103575] Elapsed 1065m 1s (remain 20m 41s) Loss: 0.0000(0.0067) Grad: 22.4127  LR: 0.000018  \n","Epoch: [1][101700/103575] Elapsed 1066m 4s (remain 19m 38s) Loss: 0.0004(0.0067) Grad: 1312.8992  LR: 0.000018  \n","Epoch: [1][101800/103575] Elapsed 1067m 8s (remain 18m 35s) Loss: 0.0013(0.0066) Grad: 13013.7412  LR: 0.000018  \n","Epoch: [1][101900/103575] Elapsed 1068m 11s (remain 17m 32s) Loss: 0.0010(0.0066) Grad: 13568.6631  LR: 0.000018  \n","Epoch: [1][102000/103575] Elapsed 1069m 15s (remain 16m 29s) Loss: 0.0003(0.0066) Grad: 2975.0051  LR: 0.000018  \n","Epoch: [1][102100/103575] Elapsed 1070m 18s (remain 15m 27s) Loss: 0.0000(0.0066) Grad: 87.9475  LR: 0.000018  \n","Epoch: [1][102200/103575] Elapsed 1071m 21s (remain 14m 24s) Loss: 0.0014(0.0066) Grad: 51798.9531  LR: 0.000018  \n","Epoch: [1][102300/103575] Elapsed 1072m 25s (remain 13m 21s) Loss: 0.0004(0.0066) Grad: 5436.8467  LR: 0.000018  \n","Epoch: [1][102400/103575] Elapsed 1073m 28s (remain 12m 18s) Loss: 0.0000(0.0066) Grad: 14.5222  LR: 0.000018  \n","Epoch: [1][102500/103575] Elapsed 1074m 32s (remain 11m 15s) Loss: 0.0001(0.0066) Grad: 87.2157  LR: 0.000018  \n","Epoch: [1][102600/103575] Elapsed 1075m 35s (remain 10m 12s) Loss: 0.0000(0.0066) Grad: 5.5973  LR: 0.000018  \n","Epoch: [1][102700/103575] Elapsed 1076m 39s (remain 9m 9s) Loss: 0.0042(0.0066) Grad: 122483.1172  LR: 0.000018  \n","Epoch: [1][102800/103575] Elapsed 1077m 42s (remain 8m 6s) Loss: 0.0011(0.0066) Grad: 13276.1221  LR: 0.000018  \n","Epoch: [1][102900/103575] Elapsed 1078m 46s (remain 7m 3s) Loss: 0.0038(0.0066) Grad: 35342.9062  LR: 0.000018  \n","Epoch: [1][103000/103575] Elapsed 1079m 49s (remain 6m 1s) Loss: 0.0002(0.0066) Grad: 978.7740  LR: 0.000018  \n","Epoch: [1][103100/103575] Elapsed 1080m 53s (remain 4m 58s) Loss: 0.0003(0.0066) Grad: 764.5800  LR: 0.000018  \n","Epoch: [1][103200/103575] Elapsed 1081m 57s (remain 3m 55s) Loss: 0.0008(0.0066) Grad: 65832.3750  LR: 0.000018  \n","Epoch: [1][103300/103575] Elapsed 1083m 0s (remain 2m 52s) Loss: 0.0008(0.0066) Grad: 10103.2422  LR: 0.000018  \n","Epoch: [1][103400/103575] Elapsed 1084m 4s (remain 1m 49s) Loss: 0.0000(0.0066) Grad: 6.2523  LR: 0.000018  \n","Epoch: [1][103500/103575] Elapsed 1085m 7s (remain 0m 46s) Loss: 0.0008(0.0066) Grad: 22988.8008  LR: 0.000018  \n","Epoch: [1][103574/103575] Elapsed 1085m 54s (remain 0m 0s) Loss: 0.0013(0.0066) Grad: 10241.1875  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 11m 14s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 23s (remain 4m 15s) Loss: 0.0192(0.0068) \n","EVAL: [200/1192] Elapsed 0m 46s (remain 3m 49s) Loss: 0.0100(0.0077) \n","EVAL: [300/1192] Elapsed 1m 9s (remain 3m 26s) Loss: 0.0033(0.0077) \n","EVAL: [400/1192] Elapsed 1m 32s (remain 3m 2s) Loss: 0.0062(0.0081) \n","EVAL: [500/1192] Elapsed 1m 55s (remain 2m 39s) Loss: 0.0153(0.0075) \n","EVAL: [600/1192] Elapsed 2m 18s (remain 2m 16s) Loss: 0.0037(0.0077) \n","EVAL: [700/1192] Elapsed 2m 41s (remain 1m 53s) Loss: 0.0967(0.0093) \n","EVAL: [800/1192] Elapsed 3m 4s (remain 1m 30s) Loss: 0.0039(0.0095) \n","EVAL: [900/1192] Elapsed 3m 27s (remain 1m 6s) Loss: 0.0044(0.0094) \n","EVAL: [1000/1192] Elapsed 3m 50s (remain 0m 43s) Loss: 0.0000(0.0093) \n","EVAL: [1100/1192] Elapsed 4m 13s (remain 0m 20s) Loss: 0.0016(0.0089) \n","EVAL: [1191/1192] Elapsed 4m 34s (remain 0m 0s) Loss: 0.0000(0.0086) \n","Epoch 1 - avg_train_loss: 0.0066  avg_val_loss: 0.0086  time: 65431s\n","Epoch 1 - Score: 0.8826\n","Epoch 1 - Save Best Score: 0.8826 Model\n","best_thres: 0.45  score: 0.88289\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69adc51fcc8d445fb5a21fb339795daa","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Load weight from pretrained\n","load weights from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp069/fold0_best.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3112e4e87589446ead5fb4ea7383a251","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp069.ipynb","provenance":[{"file_id":"1ccXu8iO1l7SQ6twuglCgmgPzQPuO9S_w","timestamp":1648688763199},{"file_id":"10yG4L3_nzpdL2CDwqxa9r-KWq6jYkWfl","timestamp":1648467991163}],"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00f918c6575a47a2b2fe0278c0ed2882":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5906d5bf72e0468f8bba9821e117278e","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c2c2eeadead44258ce81be4ad8bb90b","value":42146}},"0992aeaa0a464a3a8dd0d0e03cd6be04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a9ceb324ce94115a0ab8b0ac5394ab1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d0bbe7135be4c918cc8981b0766d209":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16fa1fc3eb6449de8437119c1ff6da9b","placeholder":"​","style":"IPY_MODEL_d2776b97ce9342a6a3e04041c376fc3b","value":"Downloading: 100%"}},"0d50ef5dab194e4d9357b2e4c6bb2d50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16fa1fc3eb6449de8437119c1ff6da9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"184027e6726346bcb105910dea9199a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18f1ae07e39c4dc1811a62c988680c4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a8fa74b94d74a73b820e44dd7140bfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d75e53ad69a4ff38da7eddd670a364f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7cf31e7f2dd45b199d4dd744e47d5b8","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca13c38351e64ec6ad2b93801c70679e","value":456318}},"1e585ba85b464611b206bfb9286d63ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c04f78ff8ca240878c89718fbcb900b6","IPY_MODEL_b701c914933c44978871afae9e5033d8","IPY_MODEL_f29a1fc9d4414fd58d2568f3b5dd80d4"],"layout":"IPY_MODEL_90b084fe14aa4c15a5fe1226c1830753"}},"2511f5a5e07f4e3ca4482a4ee2436d7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28887eebb04340f7b70fdf2673a64771":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f0391e668ad4a23a04e60ecd1782e4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36869aa9f8734cd9b83869d8d7462048":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a8b0a70edb64b7c95d93ac5c5836e16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dedaf1f030d4952b085e3157700712f","placeholder":"​","style":"IPY_MODEL_efc4ee52ade746c0af162d103c02841f","value":" 475/475 [00:00\u0026lt;00:00, 18.5kB/s]"}},"3d4faa57e18c450bae607a2eba9434c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e4b6670999f48e5a2de36ee9babf729":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b9ab1642c1e4c798efbab72df85594d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f18d64fabf584625b0dea8061dbed3bf","placeholder":"​","style":"IPY_MODEL_5626b96fc6f14e1d84b9e7acb5f5c3ba","value":" 143/143 [00:00\u0026lt;00:00, 3109.76it/s]"}},"4efb593df01844fd8f82de141b78fa5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53845e74ef0240f29f3eaa0db13bf9be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5626b96fc6f14e1d84b9e7acb5f5c3ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5906d5bf72e0468f8bba9821e117278e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db0144137d941d9979538b523931927":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddabd31a92844517aa638c36bef36bf5","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4efb593df01844fd8f82de141b78fa5e","value":898825}},"63c5cd944af24bd889b5b7f699c82cd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"667a67fd104d4d04857f6bdab801b44d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a05f6dffd744d998304a5ad4324a06e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9b01a70c567472d98ea75a7b115c676","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d50ef5dab194e4d9357b2e4c6bb2d50","value":143}},"7f2ed825c8d042c985b276e6376ff914":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f8fc355f6794bf2912c92f647599f04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e25c7a7d08bd4582a078824b4a76235f","IPY_MODEL_00f918c6575a47a2b2fe0278c0ed2882","IPY_MODEL_a5f49987457c4897b9466daa8f70d8ba"],"layout":"IPY_MODEL_b160c493e2b9489884d31f0469ab761d"}},"8274b67b4ec048b7a8d20b9ed7044a7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88e3dd992d3440989115ef3e4b22fcbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b084fe14aa4c15a5fe1226c1830753":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"912986677a384b1b87dd74210e468aed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"920619b8965242678e0b358b12466f2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3f223d2240247899815a5314a9f4961","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0992aeaa0a464a3a8dd0d0e03cd6be04","value":475}},"92c28e81109b4d60a7d1380c6474b82a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93ea5e2c3961479394013d9dbe92141f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"988ff97b332d4c8189289825963a828f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b77229ea506442c9abe6edd4f15ccd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da19e1e387494578b464f72474913290","IPY_MODEL_5db0144137d941d9979538b523931927","IPY_MODEL_baaabae2d3c64c529fca468bb99367a9"],"layout":"IPY_MODEL_88e3dd992d3440989115ef3e4b22fcbc"}},"9c2c2eeadead44258ce81be4ad8bb90b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d229a230bb1412a8370112b97ec873d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9dedaf1f030d4952b085e3157700712f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e025008b8f6453f8b8cb21296c9f56a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a133b0096ab74968bd3ab0ca33f0b58d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5f49987457c4897b9466daa8f70d8ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bec9af5842d64b3199c8b7c409462367","placeholder":"​","style":"IPY_MODEL_184027e6726346bcb105910dea9199a2","value":" 42146/42146 [00:00\u0026lt;00:00, 765218.55it/s]"}},"a9b01a70c567472d98ea75a7b115c676":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac3e21fa1699417a847687dbb1fc3671":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b08e2b8ec3804ed7ad8aae201b52e882":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b160c493e2b9489884d31f0469ab761d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3f223d2240247899815a5314a9f4961":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5a445f8b2f5431ca790b36bcb926631":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_912986677a384b1b87dd74210e468aed","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d229a230bb1412a8370112b97ec873d","value":52}},"b701c914933c44978871afae9e5033d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28887eebb04340f7b70fdf2673a64771","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8274b67b4ec048b7a8d20b9ed7044a7c","value":42146}},"b86aee6f21ae4c8abdbbb308de637c38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bde3d893ead44c1fabeed082691f972e","placeholder":"​","style":"IPY_MODEL_a133b0096ab74968bd3ab0ca33f0b58d","value":" 52.0/52.0 [00:00\u0026lt;00:00, 2.08kB/s]"}},"baaabae2d3c64c529fca468bb99367a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e4b6670999f48e5a2de36ee9babf729","placeholder":"​","style":"IPY_MODEL_bfe971cc24fa42d98272cf3e6278568e","value":" 878k/878k [00:00\u0026lt;00:00, 4.73MB/s]"}},"bca5d8bfc2fc4d0aa5aa0a1fe818724c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a9ceb324ce94115a0ab8b0ac5394ab1","placeholder":"​","style":"IPY_MODEL_988ff97b332d4c8189289825963a828f","value":"100%"}},"bde3d893ead44c1fabeed082691f972e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be759c6a6f8840b2ad8765916e7a70c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53845e74ef0240f29f3eaa0db13bf9be","placeholder":"​","style":"IPY_MODEL_1a8fa74b94d74a73b820e44dd7140bfd","value":" 446k/446k [00:00\u0026lt;00:00, 2.91MB/s]"}},"bec9af5842d64b3199c8b7c409462367":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfe971cc24fa42d98272cf3e6278568e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c04f78ff8ca240878c89718fbcb900b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac3e21fa1699417a847687dbb1fc3671","placeholder":"​","style":"IPY_MODEL_eaf70366fb1f418ebd1dc016bbf7589c","value":"100%"}},"c7cf31e7f2dd45b199d4dd744e47d5b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca13c38351e64ec6ad2b93801c70679e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbb542fc30f64442ba23ac9349f733ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2776b97ce9342a6a3e04041c376fc3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d294e635ddf14ec0831f4a6cdc3a7f80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d0bbe7135be4c918cc8981b0766d209","IPY_MODEL_b5a445f8b2f5431ca790b36bcb926631","IPY_MODEL_b86aee6f21ae4c8abdbbb308de637c38"],"layout":"IPY_MODEL_36869aa9f8734cd9b83869d8d7462048"}},"d65a7be6a5c4427c86e22c911fda70e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8cdc2a1cd8542c3a51fb96dbc55a962":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b08e2b8ec3804ed7ad8aae201b52e882","placeholder":"​","style":"IPY_MODEL_2511f5a5e07f4e3ca4482a4ee2436d7b","value":"Downloading: 100%"}},"da126e1200c14a6cbc86405cd374f83d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f2ed825c8d042c985b276e6376ff914","placeholder":"​","style":"IPY_MODEL_9e025008b8f6453f8b8cb21296c9f56a","value":"Downloading: 100%"}},"da19e1e387494578b464f72474913290":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_667a67fd104d4d04857f6bdab801b44d","placeholder":"​","style":"IPY_MODEL_63c5cd944af24bd889b5b7f699c82cd9","value":"Downloading: 100%"}},"ddabd31a92844517aa638c36bef36bf5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e25c7a7d08bd4582a078824b4a76235f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f0391e668ad4a23a04e60ecd1782e4f","placeholder":"​","style":"IPY_MODEL_93ea5e2c3961479394013d9dbe92141f","value":"100%"}},"ea110d1497a04a1c9b0ac7162dc4de15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8cdc2a1cd8542c3a51fb96dbc55a962","IPY_MODEL_1d75e53ad69a4ff38da7eddd670a364f","IPY_MODEL_be759c6a6f8840b2ad8765916e7a70c0"],"layout":"IPY_MODEL_92c28e81109b4d60a7d1380c6474b82a"}},"eaf70366fb1f418ebd1dc016bbf7589c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efc4ee52ade746c0af162d103c02841f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f18d64fabf584625b0dea8061dbed3bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f29a1fc9d4414fd58d2568f3b5dd80d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbb542fc30f64442ba23ac9349f733ee","placeholder":"​","style":"IPY_MODEL_18f1ae07e39c4dc1811a62c988680c4e","value":" 42146/42146 [00:22\u0026lt;00:00, 2029.98it/s]"}},"fb0f7af76c204ab99b31f53fbceb8ade":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bca5d8bfc2fc4d0aa5aa0a1fe818724c","IPY_MODEL_7a05f6dffd744d998304a5ad4324a06e","IPY_MODEL_4b9ab1642c1e4c798efbab72df85594d"],"layout":"IPY_MODEL_d65a7be6a5c4427c86e22c911fda70e4"}},"ff4aef2d05a540ebb260439490c49170":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da126e1200c14a6cbc86405cd374f83d","IPY_MODEL_920619b8965242678e0b358b12466f2a","IPY_MODEL_3a8b0a70edb64b7c95d93ac5c5836e16"],"layout":"IPY_MODEL_3d4faa57e18c450bae607a2eba9434c2"}}}}},"nbformat":4,"nbformat_minor":5}