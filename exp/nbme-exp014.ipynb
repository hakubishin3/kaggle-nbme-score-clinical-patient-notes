{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "filled-swing",
   "metadata": {
    "id": "aa1f8e80"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-blind",
   "metadata": {
    "id": "c0138fac"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-alpha",
   "metadata": {
    "id": "cf1dfda9"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "stable-miracle",
   "metadata": {
    "id": "a7a78d25"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp014\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "balanced-video",
   "metadata": {
    "id": "4ecc4e4d"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "occupational-violence",
   "metadata": {
    "id": "3894c88b"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-recipe",
   "metadata": {
    "id": "31768c85"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "incorporated-surfing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4693,
     "status": "ok",
     "timestamp": 1646023773081,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "00e7d967",
    "outputId": "d56a483d-9171-44e6-856a-a90dfe8e0ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "accepted-transsexual",
   "metadata": {
    "id": "d726b7d9"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-profile",
   "metadata": {
    "id": "b6d82f71"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "advance-ladder",
   "metadata": {
    "id": "95abbe2c"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "described-spread",
   "metadata": {
    "id": "832ee36d"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "national-broadcasting",
   "metadata": {
    "id": "918828a7"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cross-prague",
   "metadata": {
    "id": "d02a78e1"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-router",
   "metadata": {
    "id": "47266f39"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "patient-bride",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1646023777557,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "20fed6da",
    "outputId": "64d3e7ad-0986-4799-f9df-f0242c1977a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "double-arabic",
   "metadata": {
    "id": "e67d0132"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-dispatch",
   "metadata": {
    "id": "47bca11a"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "biological-controversy",
   "metadata": {
    "id": "d9c8e9ba"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "challenging-price",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646023777558,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "7ef41e18",
    "outputId": "31edaa7d-c088-495a-95ee-f0d56f97074c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "important-florist",
   "metadata": {
    "id": "8233df16"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "simple-outside",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646023778018,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "e9143e61",
    "outputId": "cf45e2d7-5f66-4d96-c6e2-da79c888bcc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-chuck",
   "metadata": {
    "id": "6bdc7949"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "framed-character",
   "metadata": {
    "id": "c4acf61d"
   },
   "outputs": [],
   "source": [
    "def get_groupkfold(df, group_name):\n",
    "    groups = df[group_name].unique()\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=CFG.n_fold,\n",
    "        shuffle=True,\n",
    "        random_state=CFG.seed,\n",
    "    )\n",
    "    folds_ids = []\n",
    "    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n",
    "        val_group = groups[val_group_idx]\n",
    "        is_val = df[group_name].isin(val_group)\n",
    "        val_idx = df[is_val].index\n",
    "        df.loc[val_idx, \"fold\"] = int(i_fold)\n",
    "\n",
    "    df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "collect-bhutan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646023778018,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "2ca0c08e",
    "outputId": "cfc9c06e-e30c-4cb5-a072-d0cfcfa5fdc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    2902\n",
       "1    2894\n",
       "2    2813\n",
       "3    2791\n",
       "4    2900\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_groupkfold(train, \"pn_num\")\n",
    "display(train.groupby(\"fold\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-strengthening",
   "metadata": {
    "id": "a8560070"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "coated-saskatchewan",
   "metadata": {
    "id": "c316b13f"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-scanning",
   "metadata": {
    "id": "e689a7fc"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "frequent-chaos",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "a31c60ff4dab48e08d2ef9293d85df6d",
      "c40d970496ff447a8c0b80d787b07a4d",
      "40e6583408c447199ff5b94d23601936",
      "1141ae38bc6f473aab89db14fa4eeacf",
      "47b8a7f3d0544d79b30ad02e4222082e",
      "0260998578564385a0b5b9425a0a5ca1",
      "428ca357bd284d199e2558b1f577d79a",
      "2e32fee744ef42e0aaa89a7b03e82427",
      "d51d3aa414db4aa8b0ccae896e671152",
      "ad49cbf6b6e84ccaab873458182f22a1",
      "5375de82ce3a41a8b5550e0a6b4316c1"
     ]
    },
    "executionInfo": {
     "elapsed": 37449,
     "status": "ok",
     "timestamp": 1646023819498,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "df31758e",
    "outputId": "e3ee6910-2896-413b-9bb7-1e1dd630166c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dacb786ef55488d930e2f3a5b149359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 433\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "modern-depression",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "8a503d1abd884514a1e23101e03c6781",
      "e06e5e9eb0414b6fad63bdc99b44a313",
      "6b04b019813e458080f02bc9111433a6",
      "2e3818222bab4603a896be5976cb8409",
      "eeb468dbb94943fcb30219d4dd98fcab",
      "5e66444e9c714134bd2765cb3b6d1f15",
      "220f78b6119042af8729543465e1234e",
      "7f1d7796e2174485a0d1b1e9a71d7ade",
      "e72cad76f875451a8e2479e2df237575",
      "9754a5f1e61d49c8972df40ee9290375",
      "25bf78e432e641e0a435dc3626c3ee8a"
     ]
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1646023819500,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "3caff24a",
    "outputId": "09841871-9f3a-4e70-a528-07122a0ebba2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ddd44b29e24d889078c88c756e4d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 30\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "charming-income",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1646023819500,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "756d83ff",
    "outputId": "02d1e748-4ce8-4d68-f2a2-175f08316e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 466\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dying-campbell",
   "metadata": {
    "id": "054b899a"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "empirical-studio",
   "metadata": {
    "id": "1d58367c"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-sullivan",
   "metadata": {
    "id": "8c57abef"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "professional-homework",
   "metadata": {
    "id": "54f92d89"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n",
    "            state_dict = torch.load(path)\n",
    "            itpt.load_state_dict(state_dict)\n",
    "            self.backbone = itpt.deberta\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-season",
   "metadata": {
    "id": "91401041"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "impossible-superintendent",
   "metadata": {
    "id": "eda8175d"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "accessory-cartoon",
   "metadata": {
    "id": "c44b63a7"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "spatial-printer",
   "metadata": {
    "id": "4219ac38"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "behavioral-verification",
   "metadata": {
    "id": "014a76b7"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    best_score = -1 * np.inf\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "    \"\"\"\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-apartment",
   "metadata": {
    "id": "c38fb834"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "functioning-navigator",
   "metadata": {
    "id": "62d677cd"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    score = scoring(oof_df, th=0.5)\n",
    "    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n",
    "    best_thres = get_best_thres(oof_df)\n",
    "    score = scoring(oof_df, th=best_thres)\n",
    "    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            test_token_probs = inference_fn(test_dataloader, model, device)\n",
    "            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n",
    "            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_token_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-european",
   "metadata": {},
   "source": [
    "========== fold: 0 training ==========\n",
    "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n",
    "Epoch: [1][0/2849] Elapsed 0m 1s (remain 57m 11s) Loss: 0.3151(0.3151) Grad: 197880.7969  LR: 0.000000  \n",
    "Epoch: [1][100/2849] Elapsed 0m 43s (remain 19m 54s) Loss: 0.2384(0.2924) Grad: 77975.1328  LR: 0.000001  \n",
    "Epoch: [1][200/2849] Elapsed 1m 26s (remain 19m 3s) Loss: 0.1058(0.2348) Grad: 16965.8301  LR: 0.000003  \n",
    "Epoch: [1][300/2849] Elapsed 2m 10s (remain 18m 21s) Loss: 0.0317(0.1741) Grad: 1877.3456  LR: 0.000004  \n",
    "Epoch: [1][400/2849] Elapsed 2m 53s (remain 17m 39s) Loss: 0.0808(0.1406) Grad: 5765.3096  LR: 0.000006  \n",
    "Epoch: [1][500/2849] Elapsed 3m 36s (remain 16m 55s) Loss: 0.0402(0.1196) Grad: 3003.1406  LR: 0.000007  \n",
    "Epoch: [1][600/2849] Elapsed 4m 19s (remain 16m 12s) Loss: 0.0390(0.1037) Grad: 9670.9375  LR: 0.000008  \n",
    "Epoch: [1][700/2849] Elapsed 5m 3s (remain 15m 29s) Loss: 0.0769(0.0918) Grad: 15728.8750  LR: 0.000010  \n",
    "Epoch: [1][800/2849] Elapsed 5m 46s (remain 14m 46s) Loss: 0.0083(0.0823) Grad: 4873.8574  LR: 0.000011  \n",
    "Epoch: [1][900/2849] Elapsed 6m 30s (remain 14m 3s) Loss: 0.0058(0.0746) Grad: 3241.6628  LR: 0.000013  \n",
    "Epoch: [1][1000/2849] Elapsed 7m 13s (remain 13m 20s) Loss: 0.0059(0.0684) Grad: 2390.3203  LR: 0.000014  \n",
    "Epoch: [1][1100/2849] Elapsed 7m 57s (remain 12m 37s) Loss: 0.0143(0.0631) Grad: 11790.8125  LR: 0.000015  \n",
    "Epoch: [1][1200/2849] Elapsed 8m 40s (remain 11m 53s) Loss: 0.0071(0.0587) Grad: 3858.2175  LR: 0.000017  \n",
    "Epoch: [1][1300/2849] Elapsed 9m 23s (remain 11m 10s) Loss: 0.0151(0.0549) Grad: 20028.5469  LR: 0.000018  \n",
    "Epoch: [1][1400/2849] Elapsed 10m 7s (remain 10m 27s) Loss: 0.0092(0.0515) Grad: 5077.8594  LR: 0.000020  \n",
    "Epoch: [1][1500/2849] Elapsed 10m 50s (remain 9m 44s) Loss: 0.0036(0.0487) Grad: 1275.7528  LR: 0.000020  \n",
    "Epoch: [1][1600/2849] Elapsed 11m 33s (remain 9m 0s) Loss: 0.0092(0.0462) Grad: 2933.0239  LR: 0.000020  \n",
    "Epoch: [1][1700/2849] Elapsed 12m 17s (remain 8m 17s) Loss: 0.0050(0.0440) Grad: 2224.7229  LR: 0.000020  \n",
    "Epoch: [1][1800/2849] Elapsed 13m 0s (remain 7m 34s) Loss: 0.0012(0.0420) Grad: 770.3402  LR: 0.000019  \n",
    "Epoch: [1][1900/2849] Elapsed 13m 43s (remain 6m 50s) Loss: 0.0001(0.0401) Grad: 125.5079  LR: 0.000019  \n",
    "Epoch: [1][2000/2849] Elapsed 14m 27s (remain 6m 7s) Loss: 0.0118(0.0385) Grad: 9037.4229  LR: 0.000019  \n",
    "Epoch: [1][2100/2849] Elapsed 15m 11s (remain 5m 24s) Loss: 0.0152(0.0370) Grad: 15561.3965  LR: 0.000019  \n",
    "Epoch: [1][2200/2849] Elapsed 15m 54s (remain 4m 41s) Loss: 0.0001(0.0356) Grad: 132.8673  LR: 0.000019  \n",
    "Epoch: [1][2300/2849] Elapsed 16m 37s (remain 3m 57s) Loss: 0.0687(0.0344) Grad: 10559.9092  LR: 0.000019  \n",
    "Epoch: [1][2400/2849] Elapsed 17m 21s (remain 3m 14s) Loss: 0.0054(0.0332) Grad: 2685.0435  LR: 0.000018  \n",
    "Epoch: [1][2500/2849] Elapsed 18m 4s (remain 2m 30s) Loss: 0.0058(0.0321) Grad: 3165.1885  LR: 0.000018  \n",
    "Epoch: [1][2600/2849] Elapsed 18m 47s (remain 1m 47s) Loss: 0.0007(0.0312) Grad: 365.9367  LR: 0.000018  \n",
    "Epoch: [1][2700/2849] Elapsed 19m 31s (remain 1m 4s) Loss: 0.0010(0.0303) Grad: 587.4985  LR: 0.000018  \n",
    "Epoch: [1][2800/2849] Elapsed 20m 14s (remain 0m 20s) Loss: 0.0017(0.0294) Grad: 1027.0442  LR: 0.000018  \n",
    "Epoch: [1][2848/2849] Elapsed 20m 34s (remain 0m 0s) Loss: 0.0062(0.0291) Grad: 3010.7744  LR: 0.000018  \n",
    "EVAL: [0/726] Elapsed 0m 0s (remain 5m 2s) Loss: 0.0027(0.0027) \n",
    "EVAL: [100/726] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0026(0.0055) \n",
    "EVAL: [200/726] Elapsed 0m 41s (remain 1m 49s) Loss: 0.0003(0.0068) \n",
    "EVAL: [300/726] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0020(0.0063) \n",
    "EVAL: [400/726] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0032(0.0072) \n",
    "EVAL: [500/726] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0240(0.0072) \n",
    "EVAL: [600/726] Elapsed 2m 5s (remain 0m 26s) Loss: 0.0015(0.0068) \n",
    "EVAL: [700/726] Elapsed 2m 26s (remain 0m 5s) Loss: 0.0009(0.0064) \n",
    "EVAL: [725/726] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0002(0.0063) \n",
    "Epoch 1 - avg_train_loss: 0.0291  avg_val_loss: 0.0063  time: 1392s\n",
    "Epoch 1 - Score: 0.8566\n",
    "Epoch 1 - Save Best Score: 0.8566 Model\n",
    "Epoch: [2][0/2849] Elapsed 0m 0s (remain 29m 0s) Loss: 0.0080(0.0080) Grad: 7312.4053  LR: 0.000018  \n",
    "Epoch: [2][100/2849] Elapsed 0m 43s (remain 19m 52s) Loss: 0.0007(0.0050) Grad: 3881.3765  LR: 0.000018  \n",
    "Epoch: [2][200/2849] Elapsed 1m 27s (remain 19m 12s) Loss: 0.0001(0.0062) Grad: 1052.9917  LR: 0.000017  \n",
    "Epoch: [2][300/2849] Elapsed 2m 11s (remain 18m 30s) Loss: 0.0017(0.0056) Grad: 5146.1035  LR: 0.000017  \n",
    "Epoch: [2][400/2849] Elapsed 2m 54s (remain 17m 44s) Loss: 0.0063(0.0056) Grad: 9386.4141  LR: 0.000017  \n",
    "Epoch: [2][500/2849] Elapsed 3m 37s (remain 17m 0s) Loss: 0.0034(0.0057) Grad: 19834.1211  LR: 0.000017  \n",
    "Epoch: [2][600/2849] Elapsed 4m 21s (remain 16m 17s) Loss: 0.0002(0.0055) Grad: 850.4203  LR: 0.000017  \n",
    "Epoch: [2][700/2849] Elapsed 5m 4s (remain 15m 33s) Loss: 0.0000(0.0054) Grad: 139.1904  LR: 0.000017  \n",
    "Epoch: [2][800/2849] Elapsed 5m 47s (remain 14m 49s) Loss: 0.0002(0.0053) Grad: 1595.8861  LR: 0.000017  \n",
    "Epoch: [2][900/2849] Elapsed 6m 31s (remain 14m 5s) Loss: 0.0151(0.0054) Grad: 23033.5664  LR: 0.000016  \n",
    "Epoch: [2][1000/2849] Elapsed 7m 14s (remain 13m 22s) Loss: 0.0160(0.0055) Grad: 14913.0352  LR: 0.000016  \n",
    "Epoch: [2][1100/2849] Elapsed 7m 57s (remain 12m 38s) Loss: 0.0023(0.0054) Grad: 11077.8105  LR: 0.000016  \n",
    "Epoch: [2][1200/2849] Elapsed 8m 41s (remain 11m 54s) Loss: 0.0231(0.0054) Grad: 54241.1680  LR: 0.000016  \n",
    "Epoch: [2][1300/2849] Elapsed 9m 24s (remain 11m 11s) Loss: 0.0015(0.0055) Grad: 6194.8848  LR: 0.000016  \n",
    "Epoch: [2][1400/2849] Elapsed 10m 8s (remain 10m 28s) Loss: 0.0001(0.0055) Grad: 496.7228  LR: 0.000016  \n",
    "Epoch: [2][1500/2849] Elapsed 10m 51s (remain 9m 45s) Loss: 0.0030(0.0056) Grad: 9482.0635  LR: 0.000015  \n",
    "Epoch: [2][1600/2849] Elapsed 11m 34s (remain 9m 1s) Loss: 0.0495(0.0056) Grad: 180490.6875  LR: 0.000015  \n",
    "Epoch: [2][1700/2849] Elapsed 12m 18s (remain 8m 18s) Loss: 0.0038(0.0056) Grad: 8194.7188  LR: 0.000015  \n",
    "Epoch: [2][1800/2849] Elapsed 13m 1s (remain 7m 34s) Loss: 0.0042(0.0056) Grad: 7641.6826  LR: 0.000015  \n",
    "Epoch: [2][1900/2849] Elapsed 13m 44s (remain 6m 51s) Loss: 0.0017(0.0057) Grad: 5601.8315  LR: 0.000015  \n",
    "Epoch: [2][2000/2849] Elapsed 14m 27s (remain 6m 7s) Loss: 0.0015(0.0056) Grad: 4040.9968  LR: 0.000015  \n",
    "Epoch: [2][2100/2849] Elapsed 15m 11s (remain 5m 24s) Loss: 0.0011(0.0056) Grad: 3570.0239  LR: 0.000014  \n",
    "Epoch: [2][2200/2849] Elapsed 15m 54s (remain 4m 41s) Loss: 0.0202(0.0056) Grad: 36663.6250  LR: 0.000014  \n",
    "Epoch: [2][2300/2849] Elapsed 16m 38s (remain 3m 57s) Loss: 0.0027(0.0055) Grad: 8051.5073  LR: 0.000014  \n",
    "Epoch: [2][2400/2849] Elapsed 17m 22s (remain 3m 14s) Loss: 0.0186(0.0055) Grad: 54086.9453  LR: 0.000014  \n",
    "Epoch: [2][2500/2849] Elapsed 18m 5s (remain 2m 31s) Loss: 0.0005(0.0055) Grad: 3878.3972  LR: 0.000014  \n",
    "Epoch: [2][2600/2849] Elapsed 18m 49s (remain 1m 47s) Loss: 0.0074(0.0054) Grad: 6154.3813  LR: 0.000014  \n",
    "Epoch: [2][2700/2849] Elapsed 19m 32s (remain 1m 4s) Loss: 0.0029(0.0054) Grad: 9037.5771  LR: 0.000014  \n",
    "Epoch: [2][2800/2849] Elapsed 20m 16s (remain 0m 20s) Loss: 0.0003(0.0054) Grad: 2393.7598  LR: 0.000013  \n",
    "Epoch: [2][2848/2849] Elapsed 20m 37s (remain 0m 0s) Loss: 0.0001(0.0055) Grad: 264.5609  LR: 0.000013  \n",
    "EVAL: [0/726] Elapsed 0m 0s (remain 4m 54s) Loss: 0.0011(0.0011) \n",
    "EVAL: [100/726] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0081(0.0061) \n",
    "EVAL: [200/726] Elapsed 0m 41s (remain 1m 49s) Loss: 0.0001(0.0062) \n",
    "EVAL: [300/726] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0001(0.0060) \n",
    "EVAL: [400/726] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0030(0.0071) \n",
    "EVAL: [500/726] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0256(0.0071) \n",
    "EVAL: [600/726] Elapsed 2m 5s (remain 0m 26s) Loss: 0.0034(0.0066) \n",
    "EVAL: [700/726] Elapsed 2m 26s (remain 0m 5s) Loss: 0.0008(0.0062) \n",
    "EVAL: [725/726] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0061) \n",
    "Epoch 2 - avg_train_loss: 0.0055  avg_val_loss: 0.0061  time: 1394s\n",
    "Epoch 2 - Score: 0.8763\n",
    "Epoch 2 - Save Best Score: 0.8763 Model\n",
    "Epoch: [3][0/2849] Elapsed 0m 0s (remain 32m 12s) Loss: 0.0007(0.0007) Grad: 4067.4443  LR: 0.000013  \n",
    "Epoch: [3][100/2849] Elapsed 0m 44s (remain 20m 0s) Loss: 0.0001(0.0038) Grad: 564.6037  LR: 0.000013  \n",
    "Epoch: [3][200/2849] Elapsed 1m 27s (remain 19m 9s) Loss: 0.0126(0.0039) Grad: 20890.8145  LR: 0.000013  \n",
    "Epoch: [3][300/2849] Elapsed 2m 10s (remain 18m 23s) Loss: 0.0000(0.0038) Grad: 105.4964  LR: 0.000013  \n",
    "Epoch: [3][400/2849] Elapsed 2m 53s (remain 17m 38s) Loss: 0.0000(0.0037) Grad: 211.3320  LR: 0.000013  \n",
    "Epoch: [3][500/2849] Elapsed 3m 36s (remain 16m 56s) Loss: 0.0091(0.0036) Grad: 13103.7900  LR: 0.000013  \n",
    "Epoch: [3][600/2849] Elapsed 4m 20s (remain 16m 13s) Loss: 0.0117(0.0039) Grad: 7003.4312  LR: 0.000012  \n",
    "Epoch: [3][700/2849] Elapsed 5m 3s (remain 15m 29s) Loss: 0.0073(0.0040) Grad: 16121.0410  LR: 0.000012  \n",
    "Epoch: [3][800/2849] Elapsed 5m 46s (remain 14m 45s) Loss: 0.0000(0.0039) Grad: 108.9366  LR: 0.000012  \n",
    "Epoch: [3][900/2849] Elapsed 6m 29s (remain 14m 2s) Loss: 0.0028(0.0040) Grad: 7211.7100  LR: 0.000012  \n",
    "Epoch: [3][1000/2849] Elapsed 7m 12s (remain 13m 19s) Loss: 0.0036(0.0040) Grad: 11712.3447  LR: 0.000012  \n",
    "Epoch: [3][1100/2849] Elapsed 7m 56s (remain 12m 36s) Loss: 0.0071(0.0040) Grad: 18848.7539  LR: 0.000012  \n",
    "Epoch: [3][1200/2849] Elapsed 8m 39s (remain 11m 53s) Loss: 0.0000(0.0041) Grad: 33.9751  LR: 0.000011  \n",
    "Epoch: [3][1300/2849] Elapsed 9m 22s (remain 11m 9s) Loss: 0.0002(0.0043) Grad: 902.3162  LR: 0.000011  \n",
    "Epoch: [3][1400/2849] Elapsed 10m 6s (remain 10m 26s) Loss: 0.0051(0.0043) Grad: 6878.7690  LR: 0.000011  \n",
    "Epoch: [3][1500/2849] Elapsed 10m 49s (remain 9m 43s) Loss: 0.0000(0.0042) Grad: 84.8286  LR: 0.000011  \n",
    "Epoch: [3][1600/2849] Elapsed 11m 32s (remain 8m 59s) Loss: 0.0017(0.0042) Grad: 4392.9805  LR: 0.000011  \n",
    "Epoch: [3][1700/2849] Elapsed 12m 15s (remain 8m 16s) Loss: 0.0107(0.0042) Grad: 22398.0273  LR: 0.000011  \n",
    "Epoch: [3][1800/2849] Elapsed 12m 58s (remain 7m 32s) Loss: 0.0028(0.0042) Grad: 17426.3242  LR: 0.000011  \n",
    "Epoch: [3][1900/2849] Elapsed 13m 41s (remain 6m 49s) Loss: 0.0034(0.0042) Grad: 9815.8613  LR: 0.000010  \n",
    "Epoch: [3][2000/2849] Elapsed 14m 24s (remain 6m 6s) Loss: 0.0000(0.0042) Grad: 40.7478  LR: 0.000010  \n",
    "Epoch: [3][2100/2849] Elapsed 15m 8s (remain 5m 23s) Loss: 0.0000(0.0041) Grad: 216.9669  LR: 0.000010  \n",
    "Epoch: [3][2200/2849] Elapsed 15m 51s (remain 4m 40s) Loss: 0.0000(0.0042) Grad: 50.4579  LR: 0.000010  \n",
    "Epoch: [3][2300/2849] Elapsed 16m 34s (remain 3m 56s) Loss: 0.0005(0.0042) Grad: 2121.1982  LR: 0.000010  \n",
    "Epoch: [3][2400/2849] Elapsed 17m 17s (remain 3m 13s) Loss: 0.0044(0.0042) Grad: 12142.9717  LR: 0.000010  \n",
    "Epoch: [3][2500/2849] Elapsed 18m 1s (remain 2m 30s) Loss: 0.0032(0.0042) Grad: 10789.1357  LR: 0.000009  \n",
    "Epoch: [3][2600/2849] Elapsed 18m 44s (remain 1m 47s) Loss: 0.0263(0.0042) Grad: 34410.6016  LR: 0.000009  \n",
    "Epoch: [3][2700/2849] Elapsed 19m 28s (remain 1m 4s) Loss: 0.0000(0.0042) Grad: 92.4404  LR: 0.000009  \n",
    "Epoch: [3][2800/2849] Elapsed 20m 11s (remain 0m 20s) Loss: 0.0072(0.0042) Grad: 8229.0195  LR: 0.000009  \n",
    "Epoch: [3][2848/2849] Elapsed 20m 32s (remain 0m 0s) Loss: 0.0000(0.0042) Grad: 110.1534  LR: 0.000009  \n",
    "EVAL: [0/726] Elapsed 0m 0s (remain 4m 59s) Loss: 0.0008(0.0008) \n",
    "EVAL: [100/726] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0014(0.0061) \n",
    "EVAL: [200/726] Elapsed 0m 41s (remain 1m 49s) Loss: 0.0000(0.0070) \n",
    "EVAL: [300/726] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0000(0.0066) \n",
    "EVAL: [400/726] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0033(0.0080) \n",
    "EVAL: [500/726] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0234(0.0077) \n",
    "EVAL: [600/726] Elapsed 2m 5s (remain 0m 26s) Loss: 0.0053(0.0071) \n",
    "EVAL: [700/726] Elapsed 2m 26s (remain 0m 5s) Loss: 0.0025(0.0067) \n",
    "EVAL: [725/726] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0066) \n",
    "Epoch 3 - avg_train_loss: 0.0042  avg_val_loss: 0.0066  time: 1389s\n",
    "Epoch 3 - Score: 0.8805\n",
    "Epoch 3 - Save Best Score: 0.8805 Model\n",
    "Epoch: [4][0/2849] Elapsed 0m 0s (remain 32m 20s) Loss: 0.0011(0.0011) Grad: 5811.2661  LR: 0.000009  \n",
    "Epoch: [4][100/2849] Elapsed 0m 44s (remain 20m 0s) Loss: 0.0119(0.0030) Grad: 39226.1445  LR: 0.000009  \n",
    "Epoch: [4][200/2849] Elapsed 1m 27s (remain 19m 12s) Loss: 0.0031(0.0032) Grad: 12208.1074  LR: 0.000009  \n",
    "Epoch: [4][300/2849] Elapsed 2m 10s (remain 18m 23s) Loss: 0.0020(0.0031) Grad: 8131.5825  LR: 0.000008  \n",
    "Epoch: [4][400/2849] Elapsed 2m 53s (remain 17m 38s) Loss: 0.0014(0.0029) Grad: 4776.4668  LR: 0.000008  \n",
    "Epoch: [4][500/2849] Elapsed 3m 36s (remain 16m 54s) Loss: 0.0000(0.0029) Grad: 106.5332  LR: 0.000008  \n",
    "Epoch: [4][600/2849] Elapsed 4m 19s (remain 16m 11s) Loss: 0.0001(0.0031) Grad: 227.4460  LR: 0.000008  \n",
    "Epoch: [4][700/2849] Elapsed 5m 2s (remain 15m 27s) Loss: 0.0013(0.0030) Grad: 6058.5527  LR: 0.000008  \n",
    "Epoch: [4][800/2849] Elapsed 5m 45s (remain 14m 44s) Loss: 0.0070(0.0029) Grad: 19759.0176  LR: 0.000008  \n",
    "Epoch: [4][900/2849] Elapsed 6m 29s (remain 14m 1s) Loss: 0.0009(0.0030) Grad: 10906.0391  LR: 0.000007  \n",
    "Epoch: [4][1000/2849] Elapsed 7m 12s (remain 13m 18s) Loss: 0.0354(0.0031) Grad: 40945.7305  LR: 0.000007  \n",
    "Epoch: [4][1100/2849] Elapsed 7m 55s (remain 12m 35s) Loss: 0.0072(0.0031) Grad: 17045.0996  LR: 0.000007  \n",
    "Epoch: [4][1200/2849] Elapsed 8m 38s (remain 11m 52s) Loss: 0.0016(0.0032) Grad: 6983.1626  LR: 0.000007  \n",
    "Epoch: [4][1300/2849] Elapsed 9m 21s (remain 11m 8s) Loss: 0.0001(0.0031) Grad: 726.7953  LR: 0.000007  \n",
    "Epoch: [4][1400/2849] Elapsed 10m 5s (remain 10m 25s) Loss: 0.0029(0.0032) Grad: 11627.6162  LR: 0.000007  \n",
    "Epoch: [4][1500/2849] Elapsed 10m 48s (remain 9m 42s) Loss: 0.0002(0.0033) Grad: 4452.9839  LR: 0.000007  \n",
    "Epoch: [4][1600/2849] Elapsed 11m 31s (remain 8m 59s) Loss: 0.0003(0.0033) Grad: 2435.6809  LR: 0.000006  \n",
    "Epoch: [4][1700/2849] Elapsed 12m 14s (remain 8m 16s) Loss: 0.0101(0.0033) Grad: 87587.8750  LR: 0.000006  \n",
    "Epoch: [4][1800/2849] Elapsed 12m 58s (remain 7m 32s) Loss: 0.0026(0.0032) Grad: 18695.4004  LR: 0.000006  \n",
    "Epoch: [4][1900/2849] Elapsed 13m 41s (remain 6m 49s) Loss: 0.0001(0.0033) Grad: 519.3492  LR: 0.000006  \n",
    "Epoch: [4][2000/2849] Elapsed 14m 24s (remain 6m 6s) Loss: 0.0035(0.0033) Grad: 5416.2241  LR: 0.000006  \n",
    "Epoch: [4][2100/2849] Elapsed 15m 7s (remain 5m 23s) Loss: 0.0008(0.0034) Grad: 18018.2227  LR: 0.000006  \n",
    "Epoch: [4][2200/2849] Elapsed 15m 51s (remain 4m 39s) Loss: 0.0012(0.0033) Grad: 17542.5215  LR: 0.000005  \n",
    "Epoch: [4][2300/2849] Elapsed 16m 34s (remain 3m 56s) Loss: 0.0000(0.0033) Grad: 79.2980  LR: 0.000005  \n",
    "Epoch: [4][2400/2849] Elapsed 17m 17s (remain 3m 13s) Loss: 0.0098(0.0034) Grad: 17310.6621  LR: 0.000005  \n",
    "Epoch: [4][2500/2849] Elapsed 18m 1s (remain 2m 30s) Loss: 0.0001(0.0034) Grad: 643.1182  LR: 0.000005  \n",
    "Epoch: [4][2600/2849] Elapsed 18m 44s (remain 1m 47s) Loss: 0.0100(0.0034) Grad: 23739.8086  LR: 0.000005  \n",
    "Epoch: [4][2700/2849] Elapsed 19m 27s (remain 1m 3s) Loss: 0.0000(0.0033) Grad: 115.4078  LR: 0.000005  \n",
    "Epoch: [4][2800/2849] Elapsed 20m 10s (remain 0m 20s) Loss: 0.0000(0.0034) Grad: 293.7319  LR: 0.000005  \n",
    "Epoch: [4][2848/2849] Elapsed 20m 30s (remain 0m 0s) Loss: 0.0001(0.0034) Grad: 273.1033  LR: 0.000004  \n",
    "EVAL: [0/726] Elapsed 0m 0s (remain 5m 24s) Loss: 0.0003(0.0003) \n",
    "EVAL: [100/726] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0055(0.0065) \n",
    "EVAL: [200/726] Elapsed 0m 41s (remain 1m 49s) Loss: 0.0000(0.0069) \n",
    "EVAL: [300/726] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0000(0.0066) \n",
    "EVAL: [400/726] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0014(0.0081) \n",
    "EVAL: [500/726] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0294(0.0079) \n",
    "EVAL: [600/726] Elapsed 2m 5s (remain 0m 26s) Loss: 0.0032(0.0072) \n",
    "EVAL: [700/726] Elapsed 2m 26s (remain 0m 5s) Loss: 0.0004(0.0069) \n",
    "EVAL: [725/726] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0068) \n",
    "Epoch 4 - avg_train_loss: 0.0034  avg_val_loss: 0.0068  time: 1388s\n",
    "Epoch 4 - Score: 0.8869\n",
    "Epoch 4 - Save Best Score: 0.8869 Model\n",
    "Epoch: [5][0/2849] Elapsed 0m 0s (remain 33m 0s) Loss: 0.0000(0.0000) Grad: 277.0902  LR: 0.000004  \n",
    "Epoch: [5][100/2849] Elapsed 0m 43s (remain 19m 43s) Loss: 0.0007(0.0026) Grad: 4136.5483  LR: 0.000004  \n",
    "Epoch: [5][200/2849] Elapsed 1m 26s (remain 19m 0s) Loss: 0.0001(0.0029) Grad: 607.3643  LR: 0.000004  \n",
    "Epoch: [5][300/2849] Elapsed 2m 10s (remain 18m 21s) Loss: 0.0001(0.0028) Grad: 477.9574  LR: 0.000004  \n",
    "Epoch: [5][400/2849] Elapsed 2m 53s (remain 17m 36s) Loss: 0.0000(0.0027) Grad: 23.4805  LR: 0.000004  \n",
    "Epoch: [5][500/2849] Elapsed 3m 36s (remain 16m 52s) Loss: 0.0001(0.0026) Grad: 671.1517  LR: 0.000004  \n",
    "Epoch: [5][600/2849] Elapsed 4m 19s (remain 16m 10s) Loss: 0.0000(0.0027) Grad: 21.2969  LR: 0.000004  \n",
    "Epoch: [5][700/2849] Elapsed 5m 2s (remain 15m 26s) Loss: 0.0023(0.0025) Grad: 20411.8281  LR: 0.000003  \n",
    "Epoch: [5][800/2849] Elapsed 5m 45s (remain 14m 43s) Loss: 0.0002(0.0025) Grad: 1166.5641  LR: 0.000003  \n",
    "Epoch: [5][900/2849] Elapsed 6m 28s (remain 14m 0s) Loss: 0.0120(0.0026) Grad: 20248.7129  LR: 0.000003  \n",
    "Epoch: [5][1000/2849] Elapsed 7m 11s (remain 13m 17s) Loss: 0.0120(0.0025) Grad: 16661.0547  LR: 0.000003  \n",
    "Epoch: [5][1100/2849] Elapsed 7m 55s (remain 12m 34s) Loss: 0.0002(0.0026) Grad: 891.5912  LR: 0.000003  \n",
    "Epoch: [5][1200/2849] Elapsed 8m 38s (remain 11m 51s) Loss: 0.0337(0.0026) Grad: 26300.3691  LR: 0.000003  \n",
    "Epoch: [5][1300/2849] Elapsed 9m 22s (remain 11m 8s) Loss: 0.0000(0.0026) Grad: 4.8858  LR: 0.000002  \n",
    "Epoch: [5][1400/2849] Elapsed 10m 4s (remain 10m 25s) Loss: 0.0026(0.0027) Grad: 9827.9209  LR: 0.000002  \n",
    "Epoch: [5][1500/2849] Elapsed 10m 47s (remain 9m 41s) Loss: 0.0043(0.0027) Grad: 26296.8457  LR: 0.000002  \n",
    "Epoch: [5][1600/2849] Elapsed 11m 31s (remain 8m 58s) Loss: 0.0494(0.0027) Grad: 63786.0156  LR: 0.000002  \n",
    "Epoch: [5][1700/2849] Elapsed 12m 14s (remain 8m 15s) Loss: 0.0000(0.0027) Grad: 11.7317  LR: 0.000002  \n",
    "Epoch: [5][1800/2849] Elapsed 12m 58s (remain 7m 32s) Loss: 0.0132(0.0027) Grad: 13353.3291  LR: 0.000002  \n",
    "Epoch: [5][1900/2849] Elapsed 13m 41s (remain 6m 49s) Loss: 0.0000(0.0028) Grad: 12.7526  LR: 0.000001  \n",
    "Epoch: [5][2000/2849] Elapsed 14m 25s (remain 6m 6s) Loss: 0.0000(0.0027) Grad: 11.1150  LR: 0.000001  \n",
    "Epoch: [5][2100/2849] Elapsed 15m 8s (remain 5m 23s) Loss: 0.0030(0.0027) Grad: 12698.0322  LR: 0.000001  \n",
    "Epoch: [5][2200/2849] Elapsed 15m 51s (remain 4m 40s) Loss: 0.0000(0.0028) Grad: 27.7720  LR: 0.000001  \n",
    "Epoch: [5][2300/2849] Elapsed 16m 34s (remain 3m 56s) Loss: 0.0007(0.0028) Grad: 6377.6455  LR: 0.000001  \n",
    "Epoch: [5][2400/2849] Elapsed 17m 17s (remain 3m 13s) Loss: 0.0008(0.0028) Grad: 4949.7466  LR: 0.000001  \n",
    "Epoch: [5][2500/2849] Elapsed 18m 0s (remain 2m 30s) Loss: 0.0022(0.0028) Grad: 67140.3047  LR: 0.000001  \n",
    "Epoch: [5][2600/2849] Elapsed 18m 43s (remain 1m 47s) Loss: 0.0000(0.0028) Grad: 10.3882  LR: 0.000000  \n",
    "Epoch: [5][2700/2849] Elapsed 19m 26s (remain 1m 3s) Loss: 0.0000(0.0028) Grad: 8.8045  LR: 0.000000  \n",
    "Epoch: [5][2800/2849] Elapsed 20m 9s (remain 0m 20s) Loss: 0.0000(0.0028) Grad: 75.6704  LR: 0.000000  \n",
    "Epoch: [5][2848/2849] Elapsed 20m 29s (remain 0m 0s) Loss: 0.0002(0.0028) Grad: 1135.4016  LR: 0.000000  \n",
    "EVAL: [0/726] Elapsed 0m 0s (remain 5m 16s) Loss: 0.0003(0.0003) \n",
    "EVAL: [100/726] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0059(0.0070) \n",
    "EVAL: [200/726] Elapsed 0m 42s (remain 1m 49s) Loss: 0.0000(0.0076) \n",
    "EVAL: [300/726] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0000(0.0073) \n",
    "EVAL: [400/726] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0016(0.0088) \n",
    "EVAL: [500/726] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0286(0.0086) \n",
    "EVAL: [600/726] Elapsed 2m 5s (remain 0m 26s) Loss: 0.0044(0.0079) \n",
    "EVAL: [700/726] Elapsed 2m 26s (remain 0m 5s) Loss: 0.0002(0.0075) \n",
    "EVAL: [725/726] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0074) \n",
    "Epoch 5 - avg_train_loss: 0.0028  avg_val_loss: 0.0074  time: 1387s\n",
    "Epoch 5 - Score: 0.8852\n",
    "========== fold: 1 training ==========\n",
    "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n",
    "Epoch: [1][0/2851] Elapsed 0m 0s (remain 29m 59s) Loss: 0.3465(0.3465) Grad: 204467.4062  LR: 0.000000  \n",
    "Epoch: [1][100/2851] Elapsed 0m 44s (remain 20m 16s) Loss: 0.3152(0.3376) Grad: 228724.4219  LR: 0.000001  \n",
    "Epoch: [1][200/2851] Elapsed 1m 27s (remain 19m 19s) Loss: 0.1813(0.2896) Grad: 58470.9922  LR: 0.000003  \n",
    "Epoch: [1][300/2851] Elapsed 2m 11s (remain 18m 31s) Loss: 0.0349(0.2212) Grad: 2396.7236  LR: 0.000004  \n",
    "Epoch: [1][400/2851] Elapsed 2m 55s (remain 17m 49s) Loss: 0.0660(0.1756) Grad: 4492.5952  LR: 0.000006  \n",
    "Epoch: [1][500/2851] Elapsed 3m 38s (remain 17m 5s) Loss: 0.0365(0.1475) Grad: 1857.1151  LR: 0.000007  \n",
    "Epoch: [1][600/2851] Elapsed 4m 22s (remain 16m 21s) Loss: 0.0212(0.1279) Grad: 5222.0479  LR: 0.000008  \n",
    "Epoch: [1][700/2851] Elapsed 5m 5s (remain 15m 36s) Loss: 0.0090(0.1123) Grad: 1762.0983  LR: 0.000010  \n",
    "Epoch: [1][800/2851] Elapsed 5m 48s (remain 14m 52s) Loss: 0.0047(0.1005) Grad: 1236.7269  LR: 0.000011  \n",
    "Epoch: [1][900/2851] Elapsed 6m 32s (remain 14m 9s) Loss: 0.0092(0.0908) Grad: 1665.8403  LR: 0.000013  \n",
    "Epoch: [1][1000/2851] Elapsed 7m 15s (remain 13m 25s) Loss: 0.0015(0.0828) Grad: 502.2487  LR: 0.000014  \n",
    "Epoch: [1][1100/2851] Elapsed 7m 59s (remain 12m 41s) Loss: 0.0015(0.0761) Grad: 927.5496  LR: 0.000015  \n",
    "Epoch: [1][1200/2851] Elapsed 8m 42s (remain 11m 57s) Loss: 0.0209(0.0704) Grad: 3168.2468  LR: 0.000017  \n",
    "Epoch: [1][1300/2851] Elapsed 9m 25s (remain 11m 13s) Loss: 0.0008(0.0657) Grad: 293.7862  LR: 0.000018  \n",
    "Epoch: [1][1400/2851] Elapsed 10m 8s (remain 10m 29s) Loss: 0.0036(0.0617) Grad: 696.6323  LR: 0.000020  \n",
    "Epoch: [1][1500/2851] Elapsed 10m 51s (remain 9m 46s) Loss: 0.0021(0.0582) Grad: 710.2718  LR: 0.000020  \n",
    "Epoch: [1][1600/2851] Elapsed 11m 35s (remain 9m 2s) Loss: 0.0034(0.0551) Grad: 744.0278  LR: 0.000020  \n",
    "Epoch: [1][1700/2851] Elapsed 12m 18s (remain 8m 19s) Loss: 0.0049(0.0524) Grad: 1398.2842  LR: 0.000020  \n",
    "Epoch: [1][1800/2851] Elapsed 13m 1s (remain 7m 35s) Loss: 0.0131(0.0498) Grad: 4879.5508  LR: 0.000019  \n",
    "Epoch: [1][1900/2851] Elapsed 13m 44s (remain 6m 52s) Loss: 0.0046(0.0476) Grad: 1275.6598  LR: 0.000019  \n",
    "Epoch: [1][2000/2851] Elapsed 14m 27s (remain 6m 8s) Loss: 0.0029(0.0456) Grad: 543.2283  LR: 0.000019  \n",
    "Epoch: [1][2100/2851] Elapsed 15m 10s (remain 5m 25s) Loss: 0.0051(0.0437) Grad: 1368.8165  LR: 0.000019  \n",
    "Epoch: [1][2200/2851] Elapsed 15m 53s (remain 4m 41s) Loss: 0.0017(0.0420) Grad: 419.8411  LR: 0.000019  \n",
    "Epoch: [1][2300/2851] Elapsed 16m 36s (remain 3m 58s) Loss: 0.0098(0.0406) Grad: 4453.2266  LR: 0.000019  \n",
    "Epoch: [1][2400/2851] Elapsed 17m 19s (remain 3m 14s) Loss: 0.0135(0.0392) Grad: 1847.0735  LR: 0.000018  \n",
    "Epoch: [1][2500/2851] Elapsed 18m 3s (remain 2m 31s) Loss: 0.0016(0.0379) Grad: 412.2578  LR: 0.000018  \n",
    "Epoch: [1][2600/2851] Elapsed 18m 46s (remain 1m 48s) Loss: 0.0039(0.0367) Grad: 704.8419  LR: 0.000018  \n",
    "Epoch: [1][2700/2851] Elapsed 19m 28s (remain 1m 4s) Loss: 0.0047(0.0355) Grad: 850.6146  LR: 0.000018  \n",
    "Epoch: [1][2800/2851] Elapsed 20m 11s (remain 0m 21s) Loss: 0.0082(0.0344) Grad: 1364.6437  LR: 0.000018  \n",
    "Epoch: [1][2850/2851] Elapsed 20m 33s (remain 0m 0s) Loss: 0.0032(0.0339) Grad: 1912.3817  LR: 0.000018  \n",
    "EVAL: [0/724] Elapsed 0m 0s (remain 5m 15s) Loss: 0.0014(0.0014) \n",
    "EVAL: [100/724] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0023(0.0050) \n",
    "EVAL: [200/724] Elapsed 0m 41s (remain 1m 49s) Loss: 0.0017(0.0063) \n",
    "EVAL: [300/724] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0010(0.0062) \n",
    "EVAL: [400/724] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0001(0.0064) \n",
    "EVAL: [500/724] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0116(0.0067) \n",
    "EVAL: [600/724] Elapsed 2m 5s (remain 0m 25s) Loss: 0.0026(0.0065) \n",
    "EVAL: [700/724] Elapsed 2m 26s (remain 0m 4s) Loss: 0.0001(0.0060) \n",
    "EVAL: [723/724] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0008(0.0060) \n",
    "Epoch 1 - avg_train_loss: 0.0339  avg_val_loss: 0.0060  time: 1390s\n",
    "Epoch 1 - Score: 0.8504\n",
    "Epoch 1 - Save Best Score: 0.8504 Model\n",
    "Epoch: [2][0/2851] Elapsed 0m 0s (remain 30m 53s) Loss: 0.0008(0.0008) Grad: 1906.1155  LR: 0.000018  \n",
    "Epoch: [2][100/2851] Elapsed 0m 44s (remain 20m 6s) Loss: 0.0046(0.0046) Grad: 13039.7061  LR: 0.000018  \n",
    "Epoch: [2][200/2851] Elapsed 1m 27s (remain 19m 18s) Loss: 0.0004(0.0049) Grad: 1738.7960  LR: 0.000017  \n",
    "Epoch: [2][300/2851] Elapsed 2m 11s (remain 18m 30s) Loss: 0.0019(0.0054) Grad: 5689.4839  LR: 0.000017  \n",
    "Epoch: [2][400/2851] Elapsed 2m 54s (remain 17m 45s) Loss: 0.0005(0.0050) Grad: 2241.6653  LR: 0.000017  \n",
    "Epoch: [2][500/2851] Elapsed 3m 37s (remain 17m 2s) Loss: 0.0145(0.0052) Grad: 11512.6787  LR: 0.000017  \n",
    "Epoch: [2][600/2851] Elapsed 4m 21s (remain 16m 19s) Loss: 0.0019(0.0051) Grad: 6138.7495  LR: 0.000017  \n",
    "Epoch: [2][700/2851] Elapsed 5m 5s (remain 15m 36s) Loss: 0.0008(0.0052) Grad: 3717.0415  LR: 0.000017  \n",
    "Epoch: [2][800/2851] Elapsed 5m 48s (remain 14m 52s) Loss: 0.0001(0.0052) Grad: 261.6287  LR: 0.000017  \n",
    "Epoch: [2][900/2851] Elapsed 6m 32s (remain 14m 8s) Loss: 0.0001(0.0054) Grad: 1197.3711  LR: 0.000016  \n",
    "Epoch: [2][1000/2851] Elapsed 7m 15s (remain 13m 24s) Loss: 0.0110(0.0055) Grad: 81412.9297  LR: 0.000016  \n",
    "Epoch: [2][1100/2851] Elapsed 7m 58s (remain 12m 40s) Loss: 0.0002(0.0055) Grad: 640.3331  LR: 0.000016  \n",
    "Epoch: [2][1200/2851] Elapsed 8m 41s (remain 11m 56s) Loss: 0.0037(0.0055) Grad: 4818.8833  LR: 0.000016  \n",
    "Epoch: [2][1300/2851] Elapsed 9m 25s (remain 11m 13s) Loss: 0.0000(0.0054) Grad: 50.7537  LR: 0.000016  \n",
    "Epoch: [2][1400/2851] Elapsed 10m 8s (remain 10m 29s) Loss: 0.0024(0.0054) Grad: 3364.3904  LR: 0.000016  \n",
    "Epoch: [2][1500/2851] Elapsed 10m 51s (remain 9m 46s) Loss: 0.0030(0.0054) Grad: 13003.8076  LR: 0.000015  \n",
    "Epoch: [2][1600/2851] Elapsed 11m 34s (remain 9m 2s) Loss: 0.0003(0.0054) Grad: 495.2165  LR: 0.000015  \n",
    "Epoch: [2][1700/2851] Elapsed 12m 18s (remain 8m 19s) Loss: 0.0007(0.0054) Grad: 1308.0134  LR: 0.000015  \n",
    "Epoch: [2][1800/2851] Elapsed 13m 1s (remain 7m 35s) Loss: 0.0001(0.0054) Grad: 275.3367  LR: 0.000015  \n",
    "Epoch: [2][1900/2851] Elapsed 13m 44s (remain 6m 52s) Loss: 0.0104(0.0054) Grad: 8233.1436  LR: 0.000015  \n",
    "Epoch: [2][2000/2851] Elapsed 14m 27s (remain 6m 8s) Loss: 0.0036(0.0054) Grad: 8519.0186  LR: 0.000015  \n",
    "Epoch: [2][2100/2851] Elapsed 15m 11s (remain 5m 25s) Loss: 0.0000(0.0053) Grad: 3.6904  LR: 0.000015  \n",
    "Epoch: [2][2200/2851] Elapsed 15m 54s (remain 4m 41s) Loss: 0.0030(0.0052) Grad: 7958.4575  LR: 0.000014  \n",
    "Epoch: [2][2300/2851] Elapsed 16m 38s (remain 3m 58s) Loss: 0.0026(0.0052) Grad: 2311.8394  LR: 0.000014  \n",
    "Epoch: [2][2400/2851] Elapsed 17m 21s (remain 3m 15s) Loss: 0.0000(0.0052) Grad: 62.0075  LR: 0.000014  \n",
    "Epoch: [2][2500/2851] Elapsed 18m 5s (remain 2m 31s) Loss: 0.0088(0.0053) Grad: 19682.8047  LR: 0.000014  \n",
    "Epoch: [2][2600/2851] Elapsed 18m 49s (remain 1m 48s) Loss: 0.0008(0.0052) Grad: 1186.3380  LR: 0.000014  \n",
    "Epoch: [2][2700/2851] Elapsed 19m 32s (remain 1m 5s) Loss: 0.0003(0.0053) Grad: 553.4240  LR: 0.000014  \n",
    "Epoch: [2][2800/2851] Elapsed 20m 15s (remain 0m 21s) Loss: 0.0008(0.0052) Grad: 954.4187  LR: 0.000013  \n",
    "Epoch: [2][2850/2851] Elapsed 20m 37s (remain 0m 0s) Loss: 0.0000(0.0052) Grad: 7.9962  LR: 0.000013  \n",
    "EVAL: [0/724] Elapsed 0m 0s (remain 5m 17s) Loss: 0.0010(0.0010) \n",
    "EVAL: [100/724] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0009(0.0047) \n",
    "EVAL: [200/724] Elapsed 0m 42s (remain 1m 49s) Loss: 0.0000(0.0068) \n",
    "EVAL: [300/724] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0004(0.0062) \n",
    "EVAL: [400/724] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0000(0.0063) \n",
    "EVAL: [500/724] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0106(0.0069) \n",
    "EVAL: [600/724] Elapsed 2m 5s (remain 0m 25s) Loss: 0.0013(0.0067) \n",
    "EVAL: [700/724] Elapsed 2m 26s (remain 0m 4s) Loss: 0.0000(0.0062) \n",
    "EVAL: [723/724] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0002(0.0062) \n",
    "Epoch 2 - avg_train_loss: 0.0052  avg_val_loss: 0.0062  time: 1394s\n",
    "Epoch 2 - Score: 0.8674\n",
    "Epoch 2 - Save Best Score: 0.8674 Model\n",
    "Epoch: [3][0/2851] Elapsed 0m 0s (remain 34m 14s) Loss: 0.0008(0.0008) Grad: 10763.8809  LR: 0.000013  \n",
    "Epoch: [3][100/2851] Elapsed 0m 44s (remain 20m 4s) Loss: 0.0037(0.0037) Grad: 6687.5073  LR: 0.000013  \n",
    "Epoch: [3][200/2851] Elapsed 1m 27s (remain 19m 16s) Loss: 0.0011(0.0038) Grad: 6494.1211  LR: 0.000013  \n",
    "Epoch: [3][300/2851] Elapsed 2m 11s (remain 18m 31s) Loss: 0.0009(0.0040) Grad: 3113.8872  LR: 0.000013  \n",
    "Epoch: [3][400/2851] Elapsed 2m 54s (remain 17m 45s) Loss: 0.0000(0.0040) Grad: 12.3376  LR: 0.000013  \n",
    "Epoch: [3][500/2851] Elapsed 3m 37s (remain 17m 0s) Loss: 0.0024(0.0040) Grad: 19309.5312  LR: 0.000013  \n",
    "Epoch: [3][600/2851] Elapsed 4m 20s (remain 16m 15s) Loss: 0.0001(0.0039) Grad: 1207.3245  LR: 0.000012  \n",
    "Epoch: [3][700/2851] Elapsed 5m 4s (remain 15m 32s) Loss: 0.0000(0.0040) Grad: 83.0510  LR: 0.000012  \n",
    "Epoch: [3][800/2851] Elapsed 5m 47s (remain 14m 48s) Loss: 0.0000(0.0040) Grad: 22.0785  LR: 0.000012  \n",
    "Epoch: [3][900/2851] Elapsed 6m 30s (remain 14m 5s) Loss: 0.0000(0.0040) Grad: 77.5542  LR: 0.000012  \n",
    "Epoch: [3][1000/2851] Elapsed 7m 14s (remain 13m 22s) Loss: 0.0041(0.0040) Grad: 6978.5083  LR: 0.000012  \n",
    "Epoch: [3][1100/2851] Elapsed 7m 57s (remain 12m 39s) Loss: 0.0000(0.0040) Grad: 150.2409  LR: 0.000012  \n",
    "Epoch: [3][1200/2851] Elapsed 8m 41s (remain 11m 56s) Loss: 0.0000(0.0039) Grad: 18.8023  LR: 0.000011  \n",
    "Epoch: [3][1300/2851] Elapsed 9m 24s (remain 11m 12s) Loss: 0.0002(0.0039) Grad: 732.1606  LR: 0.000011  \n",
    "Epoch: [3][1400/2851] Elapsed 10m 7s (remain 10m 29s) Loss: 0.0136(0.0041) Grad: 32969.6680  LR: 0.000011  \n",
    "Epoch: [3][1500/2851] Elapsed 10m 50s (remain 9m 45s) Loss: 0.0058(0.0040) Grad: 9186.9834  LR: 0.000011  \n",
    "Epoch: [3][1600/2851] Elapsed 11m 34s (remain 9m 2s) Loss: 0.0004(0.0040) Grad: 11648.7764  LR: 0.000011  \n",
    "Epoch: [3][1700/2851] Elapsed 12m 17s (remain 8m 18s) Loss: 0.0019(0.0040) Grad: 6553.5430  LR: 0.000011  \n",
    "Epoch: [3][1800/2851] Elapsed 13m 1s (remain 7m 35s) Loss: 0.0003(0.0040) Grad: 1967.8130  LR: 0.000011  \n",
    "Epoch: [3][1900/2851] Elapsed 13m 44s (remain 6m 51s) Loss: 0.0135(0.0040) Grad: 9758.5381  LR: 0.000010  \n",
    "Epoch: [3][2000/2851] Elapsed 14m 27s (remain 6m 8s) Loss: 0.0000(0.0040) Grad: 241.2142  LR: 0.000010  \n",
    "Epoch: [3][2100/2851] Elapsed 15m 10s (remain 5m 25s) Loss: 0.0004(0.0040) Grad: 1374.7668  LR: 0.000010  \n",
    "Epoch: [3][2200/2851] Elapsed 15m 54s (remain 4m 41s) Loss: 0.0052(0.0040) Grad: 9497.1279  LR: 0.000010  \n",
    "Epoch: [3][2300/2851] Elapsed 16m 37s (remain 3m 58s) Loss: 0.0104(0.0039) Grad: 19310.5840  LR: 0.000010  \n",
    "Epoch: [3][2400/2851] Elapsed 17m 21s (remain 3m 15s) Loss: 0.0105(0.0040) Grad: 12752.3438  LR: 0.000010  \n",
    "Epoch: [3][2500/2851] Elapsed 18m 4s (remain 2m 31s) Loss: 0.0014(0.0039) Grad: 13741.3301  LR: 0.000009  \n",
    "Epoch: [3][2600/2851] Elapsed 18m 47s (remain 1m 48s) Loss: 0.0015(0.0039) Grad: 8623.0625  LR: 0.000009  \n",
    "Epoch: [3][2700/2851] Elapsed 19m 31s (remain 1m 5s) Loss: 0.0139(0.0039) Grad: 33197.9219  LR: 0.000009  \n",
    "Epoch: [3][2800/2851] Elapsed 20m 14s (remain 0m 21s) Loss: 0.0072(0.0039) Grad: 23131.1094  LR: 0.000009  \n",
    "Epoch: [3][2850/2851] Elapsed 20m 35s (remain 0m 0s) Loss: 0.0035(0.0039) Grad: 26111.8965  LR: 0.000009  \n",
    "EVAL: [0/724] Elapsed 0m 0s (remain 5m 14s) Loss: 0.0012(0.0012) \n",
    "EVAL: [100/724] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0018(0.0054) \n",
    "EVAL: [200/724] Elapsed 0m 41s (remain 1m 49s) Loss: 0.0000(0.0071) \n",
    "EVAL: [300/724] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0002(0.0064) \n",
    "EVAL: [400/724] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0000(0.0063) \n",
    "EVAL: [500/724] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0126(0.0071) \n",
    "EVAL: [600/724] Elapsed 2m 5s (remain 0m 25s) Loss: 0.0013(0.0069) \n",
    "EVAL: [700/724] Elapsed 2m 26s (remain 0m 4s) Loss: 0.0000(0.0063) \n",
    "EVAL: [723/724] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0063) \n",
    "Epoch 3 - avg_train_loss: 0.0039  avg_val_loss: 0.0063  time: 1392s\n",
    "Epoch 3 - Score: 0.8856\n",
    "Epoch 3 - Save Best Score: 0.8856 Model\n",
    "Epoch: [4][0/2851] Elapsed 0m 0s (remain 35m 31s) Loss: 0.0005(0.0005) Grad: 2259.9712  LR: 0.000009  \n",
    "Epoch: [4][100/2851] Elapsed 0m 43s (remain 19m 56s) Loss: 0.0010(0.0030) Grad: 2411.9326  LR: 0.000009  \n",
    "Epoch: [4][200/2851] Elapsed 1m 26s (remain 19m 5s) Loss: 0.0033(0.0028) Grad: 15176.5283  LR: 0.000009  \n",
    "Epoch: [4][300/2851] Elapsed 2m 10s (remain 18m 22s) Loss: 0.0007(0.0032) Grad: 5301.3037  LR: 0.000008  \n",
    "Epoch: [4][400/2851] Elapsed 2m 53s (remain 17m 40s) Loss: 0.0208(0.0032) Grad: 36567.1445  LR: 0.000008  \n",
    "Epoch: [4][500/2851] Elapsed 3m 36s (remain 16m 56s) Loss: 0.0009(0.0032) Grad: 5816.9473  LR: 0.000008  \n",
    "Epoch: [4][600/2851] Elapsed 4m 19s (remain 16m 12s) Loss: 0.0027(0.0032) Grad: 9889.6885  LR: 0.000008  \n",
    "Epoch: [4][700/2851] Elapsed 5m 3s (remain 15m 29s) Loss: 0.0001(0.0033) Grad: 357.5256  LR: 0.000008  \n",
    "Epoch: [4][800/2851] Elapsed 5m 46s (remain 14m 47s) Loss: 0.0000(0.0032) Grad: 70.1443  LR: 0.000008  \n",
    "Epoch: [4][900/2851] Elapsed 6m 29s (remain 14m 3s) Loss: 0.0183(0.0031) Grad: 33551.7969  LR: 0.000007  \n",
    "Epoch: [4][1000/2851] Elapsed 7m 12s (remain 13m 20s) Loss: 0.0010(0.0032) Grad: 4935.8389  LR: 0.000007  \n",
    "Epoch: [4][1100/2851] Elapsed 7m 55s (remain 12m 36s) Loss: 0.0275(0.0032) Grad: 21660.4102  LR: 0.000007  \n",
    "Epoch: [4][1200/2851] Elapsed 8m 39s (remain 11m 53s) Loss: 0.0002(0.0032) Grad: 1629.5698  LR: 0.000007  \n",
    "Epoch: [4][1300/2851] Elapsed 9m 22s (remain 11m 10s) Loss: 0.0078(0.0032) Grad: 51846.8750  LR: 0.000007  \n",
    "Epoch: [4][1400/2851] Elapsed 10m 6s (remain 10m 27s) Loss: 0.0006(0.0032) Grad: 2201.4275  LR: 0.000007  \n",
    "Epoch: [4][1500/2851] Elapsed 10m 49s (remain 9m 43s) Loss: 0.0000(0.0033) Grad: 17.0025  LR: 0.000007  \n",
    "Epoch: [4][1600/2851] Elapsed 11m 32s (remain 9m 0s) Loss: 0.0001(0.0032) Grad: 1333.6726  LR: 0.000006  \n",
    "Epoch: [4][1700/2851] Elapsed 12m 15s (remain 8m 17s) Loss: 0.0000(0.0032) Grad: 147.2238  LR: 0.000006  \n",
    "Epoch: [4][1800/2851] Elapsed 12m 58s (remain 7m 34s) Loss: 0.0037(0.0032) Grad: 13139.6484  LR: 0.000006  \n",
    "Epoch: [4][1900/2851] Elapsed 13m 41s (remain 6m 50s) Loss: 0.0010(0.0033) Grad: 3705.9448  LR: 0.000006  \n",
    "Epoch: [4][2000/2851] Elapsed 14m 25s (remain 6m 7s) Loss: 0.0051(0.0033) Grad: 40057.1055  LR: 0.000006  \n",
    "Epoch: [4][2100/2851] Elapsed 15m 8s (remain 5m 24s) Loss: 0.0002(0.0033) Grad: 1812.7024  LR: 0.000006  \n",
    "Epoch: [4][2200/2851] Elapsed 15m 51s (remain 4m 41s) Loss: 0.0005(0.0032) Grad: 6290.8804  LR: 0.000005  \n",
    "Epoch: [4][2300/2851] Elapsed 16m 35s (remain 3m 57s) Loss: 0.0000(0.0032) Grad: 81.8823  LR: 0.000005  \n",
    "Epoch: [4][2400/2851] Elapsed 17m 18s (remain 3m 14s) Loss: 0.0309(0.0032) Grad: 29732.0625  LR: 0.000005  \n",
    "Epoch: [4][2500/2851] Elapsed 18m 1s (remain 2m 31s) Loss: 0.0054(0.0032) Grad: 10044.0879  LR: 0.000005  \n",
    "Epoch: [4][2600/2851] Elapsed 18m 45s (remain 1m 48s) Loss: 0.0015(0.0031) Grad: 5492.8687  LR: 0.000005  \n",
    "Epoch: [4][2700/2851] Elapsed 19m 28s (remain 1m 4s) Loss: 0.0048(0.0031) Grad: 7724.6943  LR: 0.000005  \n",
    "Epoch: [4][2800/2851] Elapsed 20m 11s (remain 0m 21s) Loss: 0.0108(0.0031) Grad: 9939.3916  LR: 0.000005  \n",
    "Epoch: [4][2850/2851] Elapsed 20m 32s (remain 0m 0s) Loss: 0.0000(0.0031) Grad: 387.3120  LR: 0.000004  \n",
    "EVAL: [0/724] Elapsed 0m 0s (remain 5m 4s) Loss: 0.0005(0.0005) \n",
    "EVAL: [100/724] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0023(0.0059) \n",
    "EVAL: [200/724] Elapsed 0m 42s (remain 1m 49s) Loss: 0.0000(0.0077) \n",
    "EVAL: [300/724] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0007(0.0069) \n",
    "EVAL: [400/724] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0000(0.0068) \n",
    "EVAL: [500/724] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0113(0.0077) \n",
    "EVAL: [600/724] Elapsed 2m 5s (remain 0m 25s) Loss: 0.0015(0.0075) \n",
    "EVAL: [700/724] Elapsed 2m 26s (remain 0m 4s) Loss: 0.0000(0.0069) \n",
    "EVAL: [723/724] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0069) \n",
    "Epoch 4 - avg_train_loss: 0.0031  avg_val_loss: 0.0069  time: 1390s\n",
    "Epoch 4 - Score: 0.8845\n",
    "Epoch: [5][0/2851] Elapsed 0m 0s (remain 30m 50s) Loss: 0.0125(0.0125) Grad: 14903.7529  LR: 0.000004  \n",
    "Epoch: [5][100/2851] Elapsed 0m 44s (remain 20m 4s) Loss: 0.0004(0.0028) Grad: 4639.6431  LR: 0.000004  \n",
    "Epoch: [5][200/2851] Elapsed 1m 27s (remain 19m 10s) Loss: 0.0002(0.0024) Grad: 3665.4402  LR: 0.000004  \n",
    "Epoch: [5][300/2851] Elapsed 2m 10s (remain 18m 21s) Loss: 0.0004(0.0024) Grad: 7950.5488  LR: 0.000004  \n",
    "Epoch: [5][400/2851] Elapsed 2m 52s (remain 17m 36s) Loss: 0.0148(0.0025) Grad: 20103.8574  LR: 0.000004  \n",
    "Epoch: [5][500/2851] Elapsed 3m 36s (remain 16m 54s) Loss: 0.0029(0.0026) Grad: 12255.2412  LR: 0.000004  \n",
    "Epoch: [5][600/2851] Elapsed 4m 19s (remain 16m 11s) Loss: 0.0001(0.0027) Grad: 539.7539  LR: 0.000004  \n",
    "Epoch: [5][700/2851] Elapsed 5m 2s (remain 15m 27s) Loss: 0.0152(0.0026) Grad: 28115.6602  LR: 0.000003  \n",
    "Epoch: [5][800/2851] Elapsed 5m 45s (remain 14m 44s) Loss: 0.0057(0.0027) Grad: 15851.1162  LR: 0.000003  \n",
    "Epoch: [5][900/2851] Elapsed 6m 28s (remain 14m 1s) Loss: 0.0022(0.0027) Grad: 7730.7046  LR: 0.000003  \n",
    "Epoch: [5][1000/2851] Elapsed 7m 11s (remain 13m 18s) Loss: 0.0030(0.0026) Grad: 9275.9609  LR: 0.000003  \n",
    "Epoch: [5][1100/2851] Elapsed 7m 55s (remain 12m 35s) Loss: 0.0073(0.0026) Grad: 24938.4883  LR: 0.000003  \n",
    "Epoch: [5][1200/2851] Elapsed 8m 38s (remain 11m 52s) Loss: 0.0016(0.0026) Grad: 4339.9609  LR: 0.000003  \n",
    "Epoch: [5][1300/2851] Elapsed 9m 21s (remain 11m 9s) Loss: 0.0000(0.0026) Grad: 40.1037  LR: 0.000002  \n",
    "Epoch: [5][1400/2851] Elapsed 10m 5s (remain 10m 26s) Loss: 0.0000(0.0026) Grad: 25.2733  LR: 0.000002  \n",
    "Epoch: [5][1500/2851] Elapsed 10m 48s (remain 9m 43s) Loss: 0.0000(0.0026) Grad: 119.2565  LR: 0.000002  \n",
    "Epoch: [5][1600/2851] Elapsed 11m 32s (remain 9m 0s) Loss: 0.0116(0.0026) Grad: 39435.6680  LR: 0.000002  \n",
    "Epoch: [5][1700/2851] Elapsed 12m 15s (remain 8m 17s) Loss: 0.0000(0.0026) Grad: 13.8637  LR: 0.000002  \n",
    "Epoch: [5][1800/2851] Elapsed 12m 58s (remain 7m 33s) Loss: 0.0000(0.0026) Grad: 18.8631  LR: 0.000002  \n",
    "Epoch: [5][1900/2851] Elapsed 13m 41s (remain 6m 50s) Loss: 0.0000(0.0026) Grad: 9.4319  LR: 0.000001  \n",
    "Epoch: [5][2000/2851] Elapsed 14m 24s (remain 6m 7s) Loss: 0.0008(0.0026) Grad: 19903.5098  LR: 0.000001  \n",
    "Epoch: [5][2100/2851] Elapsed 15m 7s (remain 5m 24s) Loss: 0.0042(0.0026) Grad: 19385.8770  LR: 0.000001  \n",
    "Epoch: [5][2200/2851] Elapsed 15m 51s (remain 4m 40s) Loss: 0.0000(0.0026) Grad: 6.0979  LR: 0.000001  \n",
    "Epoch: [5][2300/2851] Elapsed 16m 34s (remain 3m 57s) Loss: 0.0053(0.0026) Grad: 33444.4258  LR: 0.000001  \n",
    "Epoch: [5][2400/2851] Elapsed 17m 17s (remain 3m 14s) Loss: 0.0005(0.0027) Grad: 7382.8896  LR: 0.000001  \n",
    "Epoch: [5][2500/2851] Elapsed 18m 0s (remain 2m 31s) Loss: 0.0562(0.0027) Grad: 63682.2500  LR: 0.000001  \n",
    "Epoch: [5][2600/2851] Elapsed 18m 43s (remain 1m 47s) Loss: 0.0002(0.0027) Grad: 1873.1287  LR: 0.000000  \n",
    "Epoch: [5][2700/2851] Elapsed 19m 27s (remain 1m 4s) Loss: 0.0001(0.0027) Grad: 463.9747  LR: 0.000000  \n",
    "Epoch: [5][2800/2851] Elapsed 20m 10s (remain 0m 21s) Loss: 0.0002(0.0026) Grad: 9337.2783  LR: 0.000000  \n",
    "Epoch: [5][2850/2851] Elapsed 20m 31s (remain 0m 0s) Loss: 0.0012(0.0026) Grad: 6785.6362  LR: 0.000000  \n",
    "EVAL: [0/724] Elapsed 0m 0s (remain 5m 44s) Loss: 0.0007(0.0007) \n",
    "EVAL: [100/724] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0024(0.0059) \n",
    "EVAL: [200/724] Elapsed 0m 42s (remain 1m 49s) Loss: 0.0000(0.0077) \n",
    "EVAL: [300/724] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0022(0.0069) \n",
    "EVAL: [400/724] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0000(0.0070) \n",
    "EVAL: [500/724] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0128(0.0080) \n",
    "EVAL: [600/724] Elapsed 2m 5s (remain 0m 25s) Loss: 0.0006(0.0078) \n",
    "EVAL: [700/724] Elapsed 2m 26s (remain 0m 4s) Loss: 0.0000(0.0073) \n",
    "EVAL: [723/724] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0072) \n",
    "Epoch 5 - avg_train_loss: 0.0026  avg_val_loss: 0.0072  time: 1389s\n",
    "Epoch 5 - Score: 0.8845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "soviet-electric",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5a00641beddc46eb8da430f2d9999490",
      "04966868d2974cb8b3215a50572c2c94",
      "5a5c41748cba4234a6a6f9aabddfa861",
      "72044a7dbe7d4b5f839f38f6e827ec63",
      "bed6a691643a46d5bd25e03cdc5b73f7",
      "b4d0bd0dea5341a9b03f0092fe3cba39"
     ]
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1646034258180,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "1d4fcf7c",
    "outputId": "1362d223-3d70-4ba7-daa5-14b7300eef5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n",
      "========== fold: 1 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n",
      "========== fold: 2 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n",
      "========== fold: 3 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n",
      "========== fold: 4 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n",
      "Best thres: 0.5, Score: 0.8844\n",
      "Best thres: 0.4453125, Score: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8a55de991142bdbe38952e63e0bafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e05c336f37454582110eaa4303bcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a623605f94b74919a7c594efa6721fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1229aad44bb243fe9f21f82470c5f3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9beaa571e37a445f9913f00f99ca2301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-cruise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "name": "nbme-exp011.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0260998578564385a0b5b9425a0a5ca1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1141ae38bc6f473aab89db14fa4eeacf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad49cbf6b6e84ccaab873458182f22a1",
      "placeholder": "​",
      "style": "IPY_MODEL_5375de82ce3a41a8b5550e0a6b4316c1",
      "value": " 42146/42146 [00:36&lt;00:00, 2019.05it/s]"
     }
    },
    "220f78b6119042af8729543465e1234e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25bf78e432e641e0a435dc3626c3ee8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e32fee744ef42e0aaa89a7b03e82427": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e3818222bab4603a896be5976cb8409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9754a5f1e61d49c8972df40ee9290375",
      "placeholder": "​",
      "style": "IPY_MODEL_25bf78e432e641e0a435dc3626c3ee8a",
      "value": " 143/143 [00:00&lt;00:00, 2166.88it/s]"
     }
    },
    "40e6583408c447199ff5b94d23601936": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e32fee744ef42e0aaa89a7b03e82427",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d51d3aa414db4aa8b0ccae896e671152",
      "value": 42146
     }
    },
    "428ca357bd284d199e2558b1f577d79a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47b8a7f3d0544d79b30ad02e4222082e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5375de82ce3a41a8b5550e0a6b4316c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e66444e9c714134bd2765cb3b6d1f15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b04b019813e458080f02bc9111433a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f1d7796e2174485a0d1b1e9a71d7ade",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e72cad76f875451a8e2479e2df237575",
      "value": 143
     }
    },
    "7f1d7796e2174485a0d1b1e9a71d7ade": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a503d1abd884514a1e23101e03c6781": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e06e5e9eb0414b6fad63bdc99b44a313",
       "IPY_MODEL_6b04b019813e458080f02bc9111433a6",
       "IPY_MODEL_2e3818222bab4603a896be5976cb8409"
      ],
      "layout": "IPY_MODEL_eeb468dbb94943fcb30219d4dd98fcab"
     }
    },
    "9754a5f1e61d49c8972df40ee9290375": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a31c60ff4dab48e08d2ef9293d85df6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c40d970496ff447a8c0b80d787b07a4d",
       "IPY_MODEL_40e6583408c447199ff5b94d23601936",
       "IPY_MODEL_1141ae38bc6f473aab89db14fa4eeacf"
      ],
      "layout": "IPY_MODEL_47b8a7f3d0544d79b30ad02e4222082e"
     }
    },
    "ad49cbf6b6e84ccaab873458182f22a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c40d970496ff447a8c0b80d787b07a4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0260998578564385a0b5b9425a0a5ca1",
      "placeholder": "​",
      "style": "IPY_MODEL_428ca357bd284d199e2558b1f577d79a",
      "value": "100%"
     }
    },
    "d51d3aa414db4aa8b0ccae896e671152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e06e5e9eb0414b6fad63bdc99b44a313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e66444e9c714134bd2765cb3b6d1f15",
      "placeholder": "​",
      "style": "IPY_MODEL_220f78b6119042af8729543465e1234e",
      "value": "100%"
     }
    },
    "e72cad76f875451a8e2479e2df237575": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eeb468dbb94943fcb30219d4dd98fcab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
