{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brave-teach",
   "metadata": {
    "id": "blind-kingdom"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-toilet",
   "metadata": {
    "id": "antique-glenn"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-sending",
   "metadata": {
    "id": "bored-ministry"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "august-providence",
   "metadata": {
    "id": "deadly-confidence"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp066\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cathedral-horror",
   "metadata": {
    "id": "aware-worcester"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-xlarge\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=4\n",
    "    train_fold=[0, 1, 2, 3]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "armed-norfolk",
   "metadata": {
    "id": "personalized-death"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-warrant",
   "metadata": {
    "id": "cardiovascular-neutral"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "federal-marsh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "checked-boards",
    "outputId": "cea3ff7c-73cb-479b-82dc-d4ad1b7d6719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb57094-29ae-432f-a7e2-675589c2aa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recent-harrison",
   "metadata": {
    "id": "vital-mexico"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-story",
   "metadata": {
    "id": "economic-ladder"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understanding-trial",
   "metadata": {
    "id": "desperate-keyboard"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pursuant-lover",
   "metadata": {
    "id": "flexible-wednesday"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "matched-hollow",
   "metadata": {
    "id": "logical-chemistry"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "weighted-screw",
   "metadata": {
    "id": "gorgeous-record"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-passport",
   "metadata": {
    "id": "frozen-africa"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "absent-performance",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shaped-metallic",
    "outputId": "c2e09677-e2ae-4b51-b411-f1a0634026d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "automated-proportion",
   "metadata": {
    "id": "visible-australia"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-january",
   "metadata": {
    "id": "hydraulic-gibson"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "monetary-camera",
   "metadata": {
    "id": "interpreted-northeast"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fitted-current",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "martial-blind",
    "outputId": "5e7f2195-15c6-4e13-fc35-359b478f2af2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "australian-vehicle",
   "metadata": {
    "id": "electoral-favor"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "devoted-peter",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "reported-parade",
    "outputId": "bf29b91f-33b5-4aea-ce84-2e4fb8e9bf40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-honey",
   "metadata": {
    "id": "enabling-relevance"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adjacent-antibody",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "mature-coalition",
    "outputId": "ed39702e-822c-408e-ad92-eccd51f61c97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    3575\n",
       "1    3575\n",
       "2    3575\n",
       "3    3575\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "groups = train['pn_num'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-state",
   "metadata": {
    "id": "subjective-entrance"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "former-beast",
   "metadata": {
    "id": "dramatic-afghanistan"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1540d7b-13b2-41e1-958c-6b0fd0b10e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'', 0, 0\n",
      "'dad', 0, 3\n",
      "' with', 3, 8\n",
      "' recent', 8, 15\n",
      "' heart', 15, 21\n",
      "' attack', 21, 28\n",
      "'', 0, 0\n",
      "ans\n",
      "\n",
      "'', 0, 0\n",
      "'dad', 0, 3\n",
      "' with', 3, 8\n",
      "' recent', 8, 15\n",
      "' heart', 15, 21\n",
      "' attack', 21, 28\n",
      "'', 0, 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = 'dad with recent heart attack'\n",
    "encode = tokenizer(tmp, return_offsets_mapping=True)\n",
    "for (start,end) in encode['offset_mapping']:\n",
    "    print(f\"'{tmp[start:end]}', {start}, {end}\")\n",
    "\n",
    "print(\"ans\")\n",
    "print(\"\"\"\n",
    "'', 0, 0\n",
    "'dad', 0, 3\n",
    "' with', 3, 8\n",
    "' recent', 8, 15\n",
    "' heart', 15, 21\n",
    "' attack', 21, 28\n",
    "'', 0, 0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-foster",
   "metadata": {
    "id": "divided-arrow"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "biblical-mailing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "8c7eb508782d4253af8cbff0a39e5d19",
      "33e4f48f7c8f40f48081c34bc992f215",
      "0c70395dca6341349fc883dc6b95090a",
      "0dfe4d3aa0354d95bb5d019420b510a9",
      "e6775e6fc2ad4b14b473b8a07e27426d",
      "40ae5d1c9e9f4feaa4207599ef17a1ec",
      "8cd3352e5e9342e4a814e9958ea6dc1d",
      "5a92171cb3d34fc8b1ed5119e32951ac",
      "a202501b76a748fe80180604dff32c7b",
      "c3d9ac191d9b4772ae4bca323a34ddd7",
      "9deae6afbd4740df8eb0289bc5f53ae7"
     ]
    },
    "id": "immune-campbell",
    "outputId": "dbda74a8-5a58-49cf-b86a-3e05c265f758"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aae99e092504826a212f7283887c543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 433\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "renewable-mercury",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "47e8d82f628f4bd7b8b0ef0aa96852a5",
      "cc9a4ba21d664dafb8ae32a4e0a1c5e0",
      "f4421d3b3a844dbcb003f11902ee1898",
      "d02f186539954463873bb560b775894e",
      "14efac00edd349898e9fa95a63a2773d",
      "83d1b90076dc431893e0ab1c87e35f9c",
      "0b503e832e57492291cbf6e9ae66e343",
      "625abc68d2fb4fd4b8556c7cc1ae514a",
      "d2581946e9fd4f9a8dc56b3453cc70bd",
      "1f6c8df95c7845818253189f2e365ba9",
      "5e29db6be6284caa978ee223047f23c5"
     ]
    },
    "id": "northern-branch",
    "outputId": "e2c62ebe-aae9-413d-d424-6850759224a2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391c8bb3bf64a278b5969ef71b71a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 30\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "latin-burlington",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oriental-jacksonville",
    "outputId": "293b5e4d-a369-433b-a5af-fbfd35f411a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 466\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "minor-stock",
   "metadata": {
    "id": "flexible-trainer"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "decimal-schema",
   "metadata": {
    "id": "stock-robertson"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-vertical",
   "metadata": {
    "id": "chemical-lucas"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "449f03cc-fbac-4d2f-b109-ae63dc83180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class MaskedModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(\n",
    "                cfg.pretrained_model_name,\n",
    "                output_hidden_states=False\n",
    "                )\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.pretrained_model_name, config=self.config)\n",
    "            self.lm_head = AutoModelForMaskedLM.from_pretrained(cfg.pretrained_model_name, config=self.config).cls # [cls, lm_head]\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "            self.lm_head = AutoModelForMaskedLM(self.config).cls # [cls, lm_head]\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            input_ids=None,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            #position_ids=None,\n",
    "            inputs_embeds=None,\n",
    "            labels=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None):\n",
    "        \n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            #position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,)\n",
    "        \n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.lm_head(sequence_output)\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        return MaskedLMOutput(loss=masked_lm_loss,\n",
    "                              logits=prediction_scores,\n",
    "                              hidden_states=outputs.hidden_states,\n",
    "                              attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dynamic-fifteen",
   "metadata": {
    "id": "animated-array"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            # itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n",
    "            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n",
    "            # state_dict = torch.load(path)\n",
    "            # itpt.load_state_dict(state_dict)\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\"\n",
    "            masked_model = MaskedModel(CFG, config_path=None, pretrained=True)\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            masked_model.load_state_dict(state)\n",
    "            self.backbone = masked_model.model\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-commercial",
   "metadata": {
    "id": "thorough-bristol"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cathedral-component",
   "metadata": {
    "id": "talented-quantity"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "expired-wilson",
   "metadata": {
    "id": "figured-cooperative"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "chinese-sympathy",
   "metadata": {
    "id": "played-pointer"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "healthy-sleep",
   "metadata": {
    "id": "brazilian-nigeria"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    #model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    best_score = -1 * np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-novel",
   "metadata": {
    "id": "bearing-switch"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sound-silly",
   "metadata": {
    "id": "desperate-crime"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    best_thres = 0.5\n",
    "    best_score = 0.\n",
    "    for th in np.arange(0.45, 0.55, 0.01):\n",
    "        th = np.round(th, 2)\n",
    "        score = scoring(oof_df, th=th)\n",
    "        if best_score < score:\n",
    "            best_thres = th\n",
    "            best_score = score\n",
    "    print(f\"best_thres: {best_thres}  score: {best_score:.5f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            test_token_probs = inference_fn(test_dataloader, model, device)\n",
    "            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n",
    "            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_token_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "reduced-indication",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "graduate-vision",
    "outputId": "90d56101-1cd3-4eac-8d44-5be254003857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n",
      "Epoch: [1][0/2681] Elapsed 0m 0s (remain 39m 58s) Loss: 0.8121(0.8121) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 0m 56s (remain 24m 0s) Loss: 0.1963(0.5512) Grad: 78507.8281  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 1m 51s (remain 23m 0s) Loss: 0.0881(0.3240) Grad: 17285.6797  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 2m 47s (remain 22m 3s) Loss: 0.1075(0.2371) Grad: 50321.4961  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 3m 43s (remain 21m 8s) Loss: 0.0379(0.1863) Grad: 31640.4727  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 4m 38s (remain 20m 12s) Loss: 0.0057(0.1542) Grad: 5957.8691  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 5m 34s (remain 19m 16s) Loss: 0.0009(0.1314) Grad: 2949.3943  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 6m 29s (remain 18m 20s) Loss: 0.0116(0.1154) Grad: 6106.6758  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 7m 25s (remain 17m 24s) Loss: 0.0027(0.1036) Grad: 3539.7988  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 8m 20s (remain 16m 28s) Loss: 0.0180(0.0946) Grad: 20100.7480  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 9m 15s (remain 15m 33s) Loss: 0.0045(0.0867) Grad: 5614.5029  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 10m 11s (remain 14m 37s) Loss: 0.0090(0.0811) Grad: 6335.6201  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 11m 7s (remain 13m 41s) Loss: 0.0103(0.0758) Grad: 9774.1865  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 12m 2s (remain 12m 46s) Loss: 0.0085(0.0714) Grad: 18850.9883  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 12m 57s (remain 11m 50s) Loss: 0.0377(0.0677) Grad: 52306.6250  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 13m 53s (remain 10m 55s) Loss: 0.0006(0.0645) Grad: 697.7756  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 14m 48s (remain 9m 59s) Loss: 0.0044(0.0616) Grad: 1063.6981  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 15m 44s (remain 9m 3s) Loss: 0.0096(0.0588) Grad: 2807.6255  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 16m 39s (remain 8m 8s) Loss: 0.0073(0.0564) Grad: 5332.6914  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 17m 34s (remain 7m 12s) Loss: 0.0201(0.0542) Grad: 5091.7358  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 18m 29s (remain 6m 17s) Loss: 0.0067(0.0524) Grad: 2838.9443  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 19m 25s (remain 5m 21s) Loss: 0.0015(0.0507) Grad: 455.1265  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 20m 20s (remain 4m 26s) Loss: 0.0115(0.0491) Grad: 3967.1660  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 21m 16s (remain 3m 30s) Loss: 0.0005(0.0475) Grad: 373.9628  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 22m 11s (remain 2m 35s) Loss: 0.0217(0.0462) Grad: 4704.3896  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 23m 6s (remain 1m 39s) Loss: 0.0211(0.0451) Grad: 6162.2490  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 24m 1s (remain 0m 44s) Loss: 0.0011(0.0440) Grad: 363.7807  LR: 0.000018  \n",
      "Epoch: [1][2680/2681] Elapsed 24m 46s (remain 0m 0s) Loss: 0.0142(0.0431) Grad: 2245.8584  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 4m 57s) Loss: 0.0030(0.0030) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0001(0.0113) \n",
      "EVAL: [200/894] Elapsed 0m 25s (remain 1m 29s) Loss: 0.0090(0.0118) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0056(0.0121) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0187(0.0117) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0066(0.0133) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0060(0.0142) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0035(0.0143) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0024(0.0137) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0003(0.0131) \n",
      "Epoch 1 - avg_train_loss: 0.0431  avg_val_loss: 0.0131  time: 1606s\n",
      "Epoch 1 - Score: 0.8491\n",
      "Epoch 1 - Save Best Score: 0.8491 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 0s (remain 35m 55s) Loss: 0.0023(0.0023) Grad: 4122.7847  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 0m 56s (remain 23m 51s) Loss: 0.0001(0.0112) Grad: 706.4938  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 1m 51s (remain 22m 52s) Loss: 0.0001(0.0110) Grad: 367.2842  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 2m 46s (remain 21m 57s) Loss: 0.0004(0.0105) Grad: 1455.3451  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 3m 42s (remain 21m 2s) Loss: 0.0048(0.0110) Grad: 15592.0850  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 4m 37s (remain 20m 6s) Loss: 0.0224(0.0111) Grad: 17369.6094  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 5m 32s (remain 19m 11s) Loss: 0.0009(0.0109) Grad: 1748.6824  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 6m 27s (remain 18m 15s) Loss: 0.0001(0.0108) Grad: 99.1142  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 7m 23s (remain 17m 20s) Loss: 0.0158(0.0113) Grad: 6521.2417  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 8m 18s (remain 16m 24s) Loss: 0.0016(0.0114) Grad: 3380.6174  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 9m 13s (remain 15m 29s) Loss: 0.0014(0.0114) Grad: 2719.3672  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 10m 9s (remain 14m 34s) Loss: 0.0116(0.0115) Grad: 26003.0586  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 11m 4s (remain 13m 38s) Loss: 0.0003(0.0115) Grad: 400.3749  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 11m 59s (remain 12m 43s) Loss: 0.0069(0.0114) Grad: 12034.5439  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 12m 55s (remain 11m 48s) Loss: 0.0031(0.0115) Grad: 4373.1904  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 13m 50s (remain 10m 52s) Loss: 0.0000(0.0115) Grad: 84.1387  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 14m 45s (remain 9m 57s) Loss: 0.0028(0.0115) Grad: 4250.5269  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 15m 41s (remain 9m 2s) Loss: 0.0058(0.0115) Grad: 7178.7700  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 16m 36s (remain 8m 6s) Loss: 0.0087(0.0115) Grad: 10542.1523  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 17m 31s (remain 7m 11s) Loss: 0.0025(0.0115) Grad: 3865.2769  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 18m 27s (remain 6m 16s) Loss: 0.0003(0.0115) Grad: 4841.1860  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 19m 22s (remain 5m 20s) Loss: 0.0120(0.0114) Grad: 15233.1826  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 20m 17s (remain 4m 25s) Loss: 0.0194(0.0113) Grad: 69810.0703  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 21m 12s (remain 3m 30s) Loss: 0.0144(0.0112) Grad: 25496.6074  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 22m 8s (remain 2m 34s) Loss: 0.0043(0.0112) Grad: 8237.5527  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 23m 3s (remain 1m 39s) Loss: 0.0279(0.0112) Grad: 40700.9883  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 23m 58s (remain 0m 44s) Loss: 0.0136(0.0111) Grad: 13300.8779  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2680/2681] Elapsed 24m 43s (remain 0m 0s) Loss: 0.0001(0.0112) Grad: 210.3608  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 4m 52s) Loss: 0.0027(0.0027) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0000(0.0098) \n",
      "EVAL: [200/894] Elapsed 0m 25s (remain 1m 29s) Loss: 0.0087(0.0112) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0130(0.0118) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0360(0.0111) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0012(0.0128) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0029(0.0147) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0206(0.0148) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0021(0.0142) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0000(0.0135) \n",
      "Epoch 2 - avg_train_loss: 0.0112  avg_val_loss: 0.0135  time: 1603s\n",
      "Epoch 2 - Score: 0.8734\n",
      "Epoch 2 - Save Best Score: 0.8734 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 0s (remain 36m 6s) Loss: 0.0000(0.0000) Grad: 277.6299  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 0m 55s (remain 23m 50s) Loss: 0.0124(0.0094) Grad: 19807.5820  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 1m 51s (remain 22m 52s) Loss: 0.0110(0.0081) Grad: 31514.4199  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 2m 46s (remain 21m 56s) Loss: 0.0616(0.0085) Grad: 15892.6191  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 3m 41s (remain 21m 0s) Loss: 0.0011(0.0082) Grad: 6826.9429  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 4m 36s (remain 20m 4s) Loss: 0.0009(0.0088) Grad: 2027.2095  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 5m 32s (remain 19m 9s) Loss: 0.0063(0.0089) Grad: 9560.1406  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 6m 27s (remain 18m 14s) Loss: 0.0002(0.0090) Grad: 378.4389  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 7m 22s (remain 17m 18s) Loss: 0.0060(0.0089) Grad: 9074.1523  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 8m 17s (remain 16m 23s) Loss: 0.0111(0.0088) Grad: 18837.4883  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 9m 13s (remain 15m 28s) Loss: 0.0122(0.0086) Grad: 9583.5449  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 10m 8s (remain 14m 32s) Loss: 0.0060(0.0084) Grad: 23659.2441  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 11m 3s (remain 13m 37s) Loss: 0.0002(0.0084) Grad: 407.1447  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 11m 58s (remain 12m 42s) Loss: 0.0000(0.0083) Grad: 90.5801  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 12m 53s (remain 11m 47s) Loss: 0.0080(0.0083) Grad: 31546.2363  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 13m 49s (remain 10m 51s) Loss: 0.0009(0.0083) Grad: 107421.8281  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 14m 44s (remain 9m 56s) Loss: 0.0204(0.0083) Grad: 15940.9463  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 15m 39s (remain 9m 1s) Loss: 0.0210(0.0083) Grad: 17034.6367  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 16m 34s (remain 8m 6s) Loss: 0.0319(0.0082) Grad: 21831.7227  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 17m 30s (remain 7m 10s) Loss: 0.0094(0.0083) Grad: 8284.6934  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 18m 25s (remain 6m 15s) Loss: 0.0158(0.0082) Grad: 11598.8193  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 19m 20s (remain 5m 20s) Loss: 0.0178(0.0082) Grad: 16154.3564  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 20m 15s (remain 4m 25s) Loss: 0.0000(0.0082) Grad: 12.0170  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 21m 11s (remain 3m 29s) Loss: 0.0480(0.0083) Grad: 318807.4688  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 22m 6s (remain 2m 34s) Loss: 0.0044(0.0083) Grad: 11412.5771  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 23m 1s (remain 1m 39s) Loss: 0.0036(0.0082) Grad: 6179.1646  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 23m 56s (remain 0m 44s) Loss: 0.0000(0.0082) Grad: 42.9218  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2680/2681] Elapsed 24m 41s (remain 0m 0s) Loss: 0.0029(0.0082) Grad: 11715.0078  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 4m 58s) Loss: 0.0011(0.0011) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0000(0.0117) \n",
      "EVAL: [200/894] Elapsed 0m 25s (remain 1m 29s) Loss: 0.0100(0.0120) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0077(0.0119) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0437(0.0108) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0008(0.0129) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0006(0.0147) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0003(0.0145) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0006(0.0140) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0000(0.0134) \n",
      "Epoch 3 - avg_train_loss: 0.0082  avg_val_loss: 0.0134  time: 1601s\n",
      "Epoch 3 - Score: 0.8798\n",
      "Epoch 3 - Save Best Score: 0.8798 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 0s (remain 36m 2s) Loss: 0.0058(0.0058) Grad: 26790.1504  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 0m 55s (remain 23m 48s) Loss: 0.0005(0.0053) Grad: 1699.7330  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 1m 51s (remain 22m 52s) Loss: 0.0031(0.0054) Grad: 28456.4043  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 2m 46s (remain 21m 56s) Loss: 0.0267(0.0055) Grad: 125925.1328  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 3m 41s (remain 21m 0s) Loss: 0.0000(0.0061) Grad: 92.0513  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 4m 36s (remain 20m 4s) Loss: 0.0131(0.0063) Grad: 26497.2617  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 5m 32s (remain 19m 9s) Loss: 0.0000(0.0061) Grad: 52.4845  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 6m 27s (remain 18m 13s) Loss: 0.0000(0.0058) Grad: 29.7766  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 7m 22s (remain 17m 18s) Loss: 0.0000(0.0058) Grad: 56.8544  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 8m 17s (remain 16m 23s) Loss: 0.0086(0.0058) Grad: 20149.8047  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 9m 12s (remain 15m 27s) Loss: 0.0000(0.0060) Grad: 84.9684  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 10m 7s (remain 14m 32s) Loss: 0.0000(0.0059) Grad: 7.5668  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 11m 3s (remain 13m 37s) Loss: 0.0000(0.0059) Grad: 54.0244  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 11m 58s (remain 12m 41s) Loss: 0.0002(0.0058) Grad: 539.5690  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 12m 53s (remain 11m 46s) Loss: 0.0042(0.0058) Grad: 7305.1660  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 13m 48s (remain 10m 51s) Loss: 0.0001(0.0058) Grad: 236.4856  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 14m 43s (remain 9m 56s) Loss: 0.0000(0.0059) Grad: 63.8897  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 15m 38s (remain 9m 0s) Loss: 0.0000(0.0059) Grad: 127.8738  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 16m 34s (remain 8m 5s) Loss: 0.0013(0.0059) Grad: 8779.2422  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 17m 29s (remain 7m 10s) Loss: 0.0047(0.0059) Grad: 3874.7793  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 18m 24s (remain 6m 15s) Loss: 0.0015(0.0059) Grad: 3915.7817  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 19m 19s (remain 5m 20s) Loss: 0.0000(0.0058) Grad: 10.9954  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 20m 14s (remain 4m 24s) Loss: 0.0015(0.0059) Grad: 4048.1384  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 21m 9s (remain 3m 29s) Loss: 0.0000(0.0058) Grad: 91.2061  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 22m 5s (remain 2m 34s) Loss: 0.0031(0.0058) Grad: 5719.0151  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 23m 0s (remain 1m 39s) Loss: 0.0121(0.0058) Grad: 60218.5625  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 23m 55s (remain 0m 44s) Loss: 0.0000(0.0058) Grad: 4.2026  LR: 0.000005  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2680/2681] Elapsed 24m 39s (remain 0m 0s) Loss: 0.0001(0.0058) Grad: 345.6910  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 5m 1s) Loss: 0.0003(0.0003) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0000(0.0121) \n",
      "EVAL: [200/894] Elapsed 0m 25s (remain 1m 29s) Loss: 0.0118(0.0139) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0141(0.0142) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0394(0.0129) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0017(0.0154) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0033(0.0173) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0001(0.0173) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0036(0.0167) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0000(0.0161) \n",
      "Epoch 4 - avg_train_loss: 0.0058  avg_val_loss: 0.0161  time: 1600s\n",
      "Epoch 4 - Score: 0.8811\n",
      "Epoch 4 - Save Best Score: 0.8811 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 0s (remain 35m 58s) Loss: 0.0003(0.0003) Grad: 2742.3743  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 0m 55s (remain 23m 47s) Loss: 0.0103(0.0033) Grad: 15999.1748  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 1m 50s (remain 22m 49s) Loss: 0.0102(0.0037) Grad: 79884.3594  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 2m 46s (remain 21m 52s) Loss: 0.0062(0.0039) Grad: 28205.1133  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 3m 40s (remain 20m 56s) Loss: 0.0000(0.0039) Grad: 4.6683  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 4m 36s (remain 20m 1s) Loss: 0.0044(0.0039) Grad: 11876.0615  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 5m 31s (remain 19m 5s) Loss: 0.0187(0.0039) Grad: 18578.6426  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 6m 26s (remain 18m 10s) Loss: 0.0000(0.0039) Grad: 37.0401  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 7m 21s (remain 17m 15s) Loss: 0.0016(0.0040) Grad: 10262.4854  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 8m 16s (remain 16m 20s) Loss: 0.0047(0.0041) Grad: 6630.9917  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 9m 11s (remain 15m 25s) Loss: 0.0007(0.0041) Grad: 8375.3818  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 10m 6s (remain 14m 30s) Loss: 0.0000(0.0039) Grad: 7.3987  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 11m 1s (remain 13m 34s) Loss: 0.0000(0.0039) Grad: 64.1048  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 11m 56s (remain 12m 39s) Loss: 0.0091(0.0040) Grad: 9135.4727  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 12m 51s (remain 11m 44s) Loss: 0.0000(0.0040) Grad: 21.4271  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 13m 46s (remain 10m 49s) Loss: 0.0000(0.0039) Grad: 66.4350  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 14m 41s (remain 9m 54s) Loss: 0.0000(0.0039) Grad: 34.0179  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 15m 36s (remain 8m 59s) Loss: 0.0027(0.0038) Grad: 11906.5645  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 16m 31s (remain 8m 4s) Loss: 0.0001(0.0038) Grad: 134.5454  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 17m 26s (remain 7m 9s) Loss: 0.0102(0.0037) Grad: 29026.7441  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 18m 21s (remain 6m 14s) Loss: 0.0000(0.0038) Grad: 9.6250  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 19m 16s (remain 5m 19s) Loss: 0.0491(0.0038) Grad: 14277.1699  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 20m 11s (remain 4m 24s) Loss: 0.0002(0.0038) Grad: 827.4921  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 21m 6s (remain 3m 29s) Loss: 0.0002(0.0038) Grad: 2415.6580  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 22m 1s (remain 2m 34s) Loss: 0.0000(0.0037) Grad: 84.9446  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 22m 56s (remain 1m 39s) Loss: 0.0000(0.0037) Grad: 293.0796  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 23m 51s (remain 0m 44s) Loss: 0.0005(0.0038) Grad: 10155.1904  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][2680/2681] Elapsed 24m 35s (remain 0m 0s) Loss: 0.0685(0.0038) Grad: 260267.9219  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 5m 1s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0000(0.0137) \n",
      "EVAL: [200/894] Elapsed 0m 25s (remain 1m 29s) Loss: 0.0122(0.0154) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0184(0.0161) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0543(0.0149) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0066(0.0180) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0040(0.0198) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0001(0.0202) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0018(0.0196) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0000(0.0188) \n",
      "Epoch 5 - avg_train_loss: 0.0038  avg_val_loss: 0.0188  time: 1596s\n",
      "Epoch 5 - Score: 0.8827\n",
      "Epoch 5 - Save Best Score: 0.8827 Model\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2681] Elapsed 0m 0s (remain 43m 33s) Loss: 0.7146(0.7146) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 0m 56s (remain 24m 4s) Loss: 0.1598(0.5036) Grad: 68297.2500  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 1m 52s (remain 23m 2s) Loss: 0.0539(0.2960) Grad: 8778.4893  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 2m 47s (remain 22m 6s) Loss: 0.0497(0.2160) Grad: 168020.9062  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 3m 43s (remain 21m 9s) Loss: 0.0374(0.1692) Grad: 98323.3516  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 4m 38s (remain 20m 13s) Loss: 0.0092(0.1407) Grad: 17929.8379  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 5m 34s (remain 19m 17s) Loss: 0.0008(0.1208) Grad: 2721.0647  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 6m 30s (remain 18m 21s) Loss: 0.0463(0.1064) Grad: 59968.2578  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 7m 25s (remain 17m 26s) Loss: 0.0090(0.0957) Grad: 22609.2285  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 8m 21s (remain 16m 30s) Loss: 0.0222(0.0873) Grad: 110165.3516  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 9m 16s (remain 15m 34s) Loss: 0.0323(0.0805) Grad: 43509.1250  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 10m 12s (remain 14m 38s) Loss: 0.0058(0.0749) Grad: 17462.2598  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 11m 8s (remain 13m 43s) Loss: 0.0087(0.0703) Grad: 7399.5054  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 12m 3s (remain 12m 47s) Loss: 0.0320(0.0663) Grad: 41936.2266  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 12m 59s (remain 11m 51s) Loss: 0.0058(0.0630) Grad: 11039.0205  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 13m 54s (remain 10m 56s) Loss: 0.0142(0.0600) Grad: 17912.0098  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 14m 50s (remain 10m 0s) Loss: 0.0154(0.0573) Grad: 16609.4570  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 15m 45s (remain 9m 4s) Loss: 0.0086(0.0547) Grad: 15369.3398  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 16m 41s (remain 8m 9s) Loss: 0.0091(0.0527) Grad: 33705.6641  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 17m 36s (remain 7m 13s) Loss: 0.0000(0.0509) Grad: 137.4332  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 18m 32s (remain 6m 18s) Loss: 0.0678(0.0490) Grad: 109849.5234  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 19m 27s (remain 5m 22s) Loss: 0.0327(0.0475) Grad: 92941.2109  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 20m 23s (remain 4m 26s) Loss: 0.0119(0.0459) Grad: 27691.9863  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 21m 18s (remain 3m 31s) Loss: 0.0002(0.0445) Grad: 648.1701  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 22m 14s (remain 2m 35s) Loss: 0.0340(0.0433) Grad: 70761.2734  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 23m 9s (remain 1m 40s) Loss: 0.0001(0.0420) Grad: 1240.6893  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 24m 5s (remain 0m 44s) Loss: 0.0002(0.0409) Grad: 752.8910  LR: 0.000018  \n",
      "Epoch: [1][2680/2681] Elapsed 24m 49s (remain 0m 0s) Loss: 0.0140(0.0401) Grad: 31165.6602  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 4s) Loss: 0.0225(0.0225) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 44s) Loss: 0.0011(0.0112) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0368(0.0159) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0193(0.0169) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0014(0.0161) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0196(0.0172) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0072(0.0173) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0000(0.0167) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0088(0.0158) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0272(0.0146) \n",
      "Epoch 1 - avg_train_loss: 0.0401  avg_val_loss: 0.0146  time: 1611s\n",
      "Epoch 1 - Score: 0.8563\n",
      "Epoch 1 - Save Best Score: 0.8563 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 1s (remain 45m 45s) Loss: 0.0004(0.0004) Grad: 1550.2314  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 0m 56s (remain 24m 2s) Loss: 0.0000(0.0098) Grad: 14.5993  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 1m 52s (remain 23m 2s) Loss: 0.0002(0.0105) Grad: 707.6400  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 2m 47s (remain 22m 4s) Loss: 0.0051(0.0112) Grad: 9073.1914  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 3m 42s (remain 21m 7s) Loss: 0.0261(0.0112) Grad: 67889.3672  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 4m 38s (remain 20m 10s) Loss: 0.0002(0.0112) Grad: 841.0383  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 5m 33s (remain 19m 15s) Loss: 0.0038(0.0115) Grad: 3589.9844  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 6m 29s (remain 18m 19s) Loss: 0.0015(0.0116) Grad: 12262.4463  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 7m 24s (remain 17m 23s) Loss: 0.0045(0.0115) Grad: 3677.6150  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 8m 20s (remain 16m 27s) Loss: 0.0002(0.0116) Grad: 309.3462  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 9m 15s (remain 15m 32s) Loss: 0.0006(0.0116) Grad: 436.1895  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 10m 10s (remain 14m 36s) Loss: 0.0102(0.0117) Grad: 3543.9988  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 11m 6s (remain 13m 41s) Loss: 0.0127(0.0114) Grad: 7658.1167  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 12m 1s (remain 12m 45s) Loss: 0.0156(0.0113) Grad: 14592.3848  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 12m 57s (remain 11m 49s) Loss: 0.0149(0.0114) Grad: 23969.4492  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 13m 52s (remain 10m 54s) Loss: 0.0451(0.0114) Grad: 29649.6113  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 14m 47s (remain 9m 58s) Loss: 0.0240(0.0115) Grad: 16585.8770  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 15m 43s (remain 9m 3s) Loss: 0.0027(0.0115) Grad: 1703.4696  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 16m 38s (remain 8m 7s) Loss: 0.0427(0.0114) Grad: 18366.4102  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 17m 34s (remain 7m 12s) Loss: 0.0005(0.0115) Grad: 499.1622  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 18m 29s (remain 6m 17s) Loss: 0.0347(0.0115) Grad: 14540.8281  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 19m 24s (remain 5m 21s) Loss: 0.0002(0.0115) Grad: 115.3078  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 20m 20s (remain 4m 26s) Loss: 0.0144(0.0115) Grad: 24632.2852  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 21m 15s (remain 3m 30s) Loss: 0.0030(0.0116) Grad: 2648.7129  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 22m 11s (remain 2m 35s) Loss: 0.0091(0.0117) Grad: 6153.5820  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 23m 6s (remain 1m 39s) Loss: 0.0000(0.0118) Grad: 17.1615  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 24m 1s (remain 0m 44s) Loss: 0.0267(0.0118) Grad: 12622.3398  LR: 0.000013  \n",
      "Epoch: [2][2680/2681] Elapsed 24m 46s (remain 0m 0s) Loss: 0.0186(0.0118) Grad: 14260.3262  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 7s) Loss: 0.0232(0.0232) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0035(0.0096) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0375(0.0147) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0288(0.0155) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0016(0.0149) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0130(0.0158) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0192(0.0161) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0001(0.0155) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0130(0.0147) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0257(0.0135) \n",
      "Epoch 2 - avg_train_loss: 0.0118  avg_val_loss: 0.0135  time: 1607s\n",
      "Epoch 2 - Score: 0.8630\n",
      "Epoch 2 - Save Best Score: 0.8630 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 1s (remain 45m 25s) Loss: 0.0188(0.0188) Grad: 17611.8418  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 0m 56s (remain 24m 6s) Loss: 0.0085(0.0105) Grad: 25125.0195  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 1m 51s (remain 23m 1s) Loss: 0.0000(0.0088) Grad: 597.4589  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 2m 47s (remain 22m 2s) Loss: 0.0375(0.0091) Grad: 49659.6680  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 3m 42s (remain 21m 6s) Loss: 0.0008(0.0090) Grad: 3150.3855  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 4m 38s (remain 20m 10s) Loss: 0.0008(0.0088) Grad: 3423.0784  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 5m 33s (remain 19m 14s) Loss: 0.0029(0.0086) Grad: 7466.3555  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 6m 28s (remain 18m 18s) Loss: 0.0209(0.0084) Grad: 30629.4824  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 7m 24s (remain 17m 22s) Loss: 0.0102(0.0086) Grad: 31126.9004  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 8m 19s (remain 16m 26s) Loss: 0.0263(0.0085) Grad: 107073.5938  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 9m 14s (remain 15m 31s) Loss: 0.0001(0.0085) Grad: 1405.1654  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 10m 10s (remain 14m 35s) Loss: 0.0359(0.0086) Grad: 33257.2500  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 11m 5s (remain 13m 40s) Loss: 0.0000(0.0085) Grad: 52.4421  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 12m 0s (remain 12m 44s) Loss: 0.0040(0.0084) Grad: 11169.2373  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 12m 56s (remain 11m 49s) Loss: 0.0215(0.0084) Grad: 38165.7852  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 13m 51s (remain 10m 53s) Loss: 0.0000(0.0084) Grad: 135.6201  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 14m 46s (remain 9m 58s) Loss: 0.0103(0.0085) Grad: 26686.0664  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 15m 42s (remain 9m 2s) Loss: 0.0072(0.0084) Grad: 20635.8789  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 16m 37s (remain 8m 7s) Loss: 0.0160(0.0083) Grad: 37558.9102  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 17m 32s (remain 7m 11s) Loss: 0.0002(0.0082) Grad: 584.9208  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 18m 28s (remain 6m 16s) Loss: 0.0258(0.0082) Grad: 67001.1562  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 19m 23s (remain 5m 21s) Loss: 0.0134(0.0082) Grad: 41096.2500  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 20m 18s (remain 4m 25s) Loss: 0.0017(0.0083) Grad: 23669.9297  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 21m 14s (remain 3m 30s) Loss: 0.0000(0.0083) Grad: 30.7764  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 22m 9s (remain 2m 35s) Loss: 0.0004(0.0083) Grad: 3493.0767  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 23m 4s (remain 1m 39s) Loss: 0.0024(0.0082) Grad: 25785.6328  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 24m 0s (remain 0m 44s) Loss: 0.0137(0.0082) Grad: 40114.1836  LR: 0.000009  \n",
      "Epoch: [3][2680/2681] Elapsed 24m 44s (remain 0m 0s) Loss: 0.0000(0.0082) Grad: 38.1356  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 16s) Loss: 0.0251(0.0251) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0153(0.0123) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0473(0.0188) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0383(0.0202) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0002(0.0191) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0264(0.0197) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0290(0.0199) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0000(0.0188) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0534(0.0179) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0135(0.0165) \n",
      "Epoch 3 - avg_train_loss: 0.0082  avg_val_loss: 0.0165  time: 1605s\n",
      "Epoch 3 - Score: 0.8786\n",
      "Epoch 3 - Save Best Score: 0.8786 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 1s (remain 44m 57s) Loss: 0.0101(0.0101) Grad: 25467.9590  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 0m 56s (remain 24m 1s) Loss: 0.0003(0.0070) Grad: 4099.1211  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 1m 51s (remain 22m 58s) Loss: 0.0128(0.0069) Grad: 15409.0771  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 2m 46s (remain 22m 0s) Loss: 0.0074(0.0061) Grad: 32531.3047  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 3m 42s (remain 21m 3s) Loss: 0.0001(0.0058) Grad: 261.2540  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 4m 37s (remain 20m 7s) Loss: 0.0526(0.0059) Grad: 64010.9102  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 5m 32s (remain 19m 11s) Loss: 0.0196(0.0062) Grad: 10959.7969  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 6m 27s (remain 18m 15s) Loss: 0.0036(0.0062) Grad: 29576.1055  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 7m 23s (remain 17m 19s) Loss: 0.0000(0.0060) Grad: 29.5572  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 8m 18s (remain 16m 24s) Loss: 0.0106(0.0059) Grad: 73115.6406  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 9m 13s (remain 15m 29s) Loss: 0.0008(0.0060) Grad: 8550.1377  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 10m 9s (remain 14m 33s) Loss: 0.0143(0.0060) Grad: 22867.0430  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 11m 4s (remain 13m 38s) Loss: 0.0121(0.0059) Grad: 89881.5312  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 11m 59s (remain 12m 43s) Loss: 0.0013(0.0059) Grad: 3196.7527  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 12m 54s (remain 11m 47s) Loss: 0.0001(0.0059) Grad: 223.2399  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 13m 49s (remain 10m 52s) Loss: 0.0001(0.0060) Grad: 321.3542  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 14m 45s (remain 9m 57s) Loss: 0.0056(0.0059) Grad: 19263.1270  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 15m 40s (remain 9m 1s) Loss: 0.0020(0.0060) Grad: 9365.8926  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 16m 35s (remain 8m 6s) Loss: 0.0003(0.0061) Grad: 7259.4780  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 17m 30s (remain 7m 11s) Loss: 0.0007(0.0061) Grad: 5355.5625  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 18m 25s (remain 6m 15s) Loss: 0.0435(0.0060) Grad: 99481.8828  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 19m 21s (remain 5m 20s) Loss: 0.0225(0.0060) Grad: 95421.0469  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 20m 16s (remain 4m 25s) Loss: 0.0193(0.0060) Grad: 29225.2129  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 21m 11s (remain 3m 30s) Loss: 0.0000(0.0061) Grad: 202.4156  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 22m 7s (remain 2m 34s) Loss: 0.0000(0.0060) Grad: 709.2631  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 23m 2s (remain 1m 39s) Loss: 0.0000(0.0061) Grad: 164.9581  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 23m 57s (remain 0m 44s) Loss: 0.0078(0.0061) Grad: 39058.4648  LR: 0.000005  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2680/2681] Elapsed 24m 41s (remain 0m 0s) Loss: 0.0026(0.0061) Grad: 83775.5938  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 11s) Loss: 0.0328(0.0328) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0130(0.0142) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0586(0.0219) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0452(0.0238) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0000(0.0223) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0300(0.0237) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0452(0.0241) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0000(0.0232) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0360(0.0221) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0108(0.0204) \n",
      "Epoch 4 - avg_train_loss: 0.0061  avg_val_loss: 0.0204  time: 1603s\n",
      "Epoch 4 - Score: 0.8776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 1s (remain 45m 41s) Loss: 0.0000(0.0000) Grad: 451.9927  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 0m 56s (remain 23m 55s) Loss: 0.0003(0.0032) Grad: 1609.8801  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 1m 51s (remain 22m 53s) Loss: 0.0215(0.0041) Grad: 248607.5000  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 2m 46s (remain 21m 55s) Loss: 0.0000(0.0045) Grad: 23.2836  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 3m 41s (remain 20m 59s) Loss: 0.0123(0.0044) Grad: 61439.9297  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 4m 36s (remain 20m 4s) Loss: 0.0075(0.0044) Grad: 62357.4844  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 5m 31s (remain 19m 8s) Loss: 0.0000(0.0043) Grad: 115.9431  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 6m 27s (remain 18m 13s) Loss: 0.0089(0.0042) Grad: 234015.5469  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 7m 22s (remain 17m 17s) Loss: 0.0630(0.0042) Grad: 23240.2773  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 8m 17s (remain 16m 22s) Loss: 0.0002(0.0042) Grad: 567.8729  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 9m 12s (remain 15m 27s) Loss: 0.0003(0.0042) Grad: 2353.8320  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 10m 7s (remain 14m 31s) Loss: 0.0012(0.0042) Grad: 13746.9453  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 11m 2s (remain 13m 36s) Loss: 0.0077(0.0042) Grad: 23247.1816  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 11m 57s (remain 12m 41s) Loss: 0.0000(0.0043) Grad: 122.6128  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 12m 52s (remain 11m 46s) Loss: 0.0000(0.0045) Grad: 19.4935  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 13m 48s (remain 10m 50s) Loss: 0.0001(0.0044) Grad: 130.4864  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 14m 43s (remain 9m 55s) Loss: 0.0000(0.0043) Grad: 14.0469  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 15m 38s (remain 9m 0s) Loss: 0.0066(0.0044) Grad: 38842.7695  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 16m 33s (remain 8m 5s) Loss: 0.0000(0.0043) Grad: 57.0740  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 17m 28s (remain 7m 10s) Loss: 0.0010(0.0042) Grad: 7697.7485  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 18m 23s (remain 6m 15s) Loss: 0.0014(0.0041) Grad: 18496.2109  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 19m 18s (remain 5m 19s) Loss: 0.0062(0.0043) Grad: 8212.7510  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 20m 13s (remain 4m 24s) Loss: 0.0000(0.0042) Grad: 35.4803  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 21m 9s (remain 3m 29s) Loss: 0.0000(0.0042) Grad: 35.8937  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 22m 4s (remain 2m 34s) Loss: 0.0030(0.0042) Grad: 45781.1797  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 22m 59s (remain 1m 39s) Loss: 0.0050(0.0043) Grad: 5501.3682  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 23m 54s (remain 0m 44s) Loss: 0.0140(0.0043) Grad: 6986.0107  LR: 0.000000  \n",
      "Epoch: [5][2680/2681] Elapsed 24m 38s (remain 0m 0s) Loss: 0.0031(0.0042) Grad: 5048.7446  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 10s) Loss: 0.0339(0.0339) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0048(0.0136) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0489(0.0210) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0448(0.0229) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0000(0.0216) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0210(0.0229) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0362(0.0232) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0000(0.0222) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0427(0.0211) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0095(0.0195) \n",
      "Epoch 5 - avg_train_loss: 0.0042  avg_val_loss: 0.0195  time: 1599s\n",
      "Epoch 5 - Score: 0.8761\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2681] Elapsed 0m 0s (remain 44m 26s) Loss: 0.7507(0.7507) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 0m 56s (remain 24m 3s) Loss: 0.1411(0.5086) Grad: 28175.8906  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 1m 51s (remain 23m 0s) Loss: 0.0538(0.2940) Grad: 3730.4683  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 2m 47s (remain 22m 4s) Loss: 0.0229(0.2122) Grad: 10768.3203  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 3m 43s (remain 21m 8s) Loss: 0.0063(0.1674) Grad: 4831.8120  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 4m 38s (remain 20m 12s) Loss: 0.0108(0.1391) Grad: 4893.3076  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 5m 34s (remain 19m 16s) Loss: 0.0173(0.1199) Grad: 6388.0977  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 6m 29s (remain 18m 20s) Loss: 0.0005(0.1058) Grad: 253.4816  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 7m 25s (remain 17m 25s) Loss: 0.0045(0.0953) Grad: 1686.4609  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 8m 20s (remain 16m 29s) Loss: 0.0031(0.0866) Grad: 2295.3206  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 9m 16s (remain 15m 33s) Loss: 0.0123(0.0798) Grad: 3643.2751  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 10m 11s (remain 14m 37s) Loss: 0.0007(0.0741) Grad: 582.9297  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 11m 7s (remain 13m 42s) Loss: 0.0231(0.0697) Grad: 3982.9163  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 12m 2s (remain 12m 46s) Loss: 0.0509(0.0657) Grad: 7831.0537  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 12m 58s (remain 11m 50s) Loss: 0.0047(0.0622) Grad: 1173.3115  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 13m 53s (remain 10m 55s) Loss: 0.0261(0.0592) Grad: 3081.9924  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 14m 48s (remain 9m 59s) Loss: 0.0048(0.0564) Grad: 3469.2942  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 15m 44s (remain 9m 4s) Loss: 0.0137(0.0540) Grad: 2072.1472  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 16m 39s (remain 8m 8s) Loss: 0.0870(0.0519) Grad: 8426.5527  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 17m 35s (remain 7m 13s) Loss: 0.0010(0.0500) Grad: 440.2885  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 18m 30s (remain 6m 17s) Loss: 0.0134(0.0485) Grad: 7661.8501  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 19m 26s (remain 5m 21s) Loss: 0.0058(0.0468) Grad: 1563.6670  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 20m 21s (remain 4m 26s) Loss: 0.0138(0.0452) Grad: 5765.3477  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 21m 17s (remain 3m 30s) Loss: 0.0126(0.0438) Grad: 10990.7559  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 22m 12s (remain 2m 35s) Loss: 0.0356(0.0425) Grad: 10386.0928  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 23m 7s (remain 1m 39s) Loss: 0.0081(0.0414) Grad: 2925.8318  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 24m 3s (remain 0m 44s) Loss: 0.0014(0.0405) Grad: 1467.4316  LR: 0.000018  \n",
      "Epoch: [1][2680/2681] Elapsed 24m 47s (remain 0m 0s) Loss: 0.0303(0.0398) Grad: 9322.2705  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 38s) Loss: 0.0027(0.0027) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0061(0.0129) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0006(0.0123) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0030(0.0130) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0016(0.0117) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0047(0.0123) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0091(0.0129) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0386(0.0137) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0025(0.0130) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0007(0.0124) \n",
      "Epoch 1 - avg_train_loss: 0.0398  avg_val_loss: 0.0124  time: 1609s\n",
      "Epoch 1 - Score: 0.8603\n",
      "Epoch 1 - Save Best Score: 0.8603 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 1s (remain 46m 44s) Loss: 0.0006(0.0006) Grad: 2377.9453  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 0m 56s (remain 24m 5s) Loss: 0.0050(0.0089) Grad: 11827.9912  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 1m 52s (remain 23m 2s) Loss: 0.0002(0.0093) Grad: 553.0225  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 2m 47s (remain 22m 4s) Loss: 0.0007(0.0108) Grad: 2944.2153  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 3m 42s (remain 21m 7s) Loss: 0.0295(0.0108) Grad: 64155.1523  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 4m 38s (remain 20m 10s) Loss: 0.0249(0.0107) Grad: 49751.2734  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 5m 33s (remain 19m 15s) Loss: 0.0005(0.0115) Grad: 1894.0925  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 6m 29s (remain 18m 19s) Loss: 0.0236(0.0113) Grad: 40425.8633  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 7m 24s (remain 17m 23s) Loss: 0.0113(0.0115) Grad: 70418.1406  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 8m 20s (remain 16m 27s) Loss: 0.0116(0.0114) Grad: 10186.6611  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 9m 15s (remain 15m 32s) Loss: 0.0048(0.0116) Grad: 19732.3008  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 10m 10s (remain 14m 36s) Loss: 0.0132(0.0114) Grad: 62594.7227  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 11m 6s (remain 13m 41s) Loss: 0.0197(0.0113) Grad: 34999.4414  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 12m 1s (remain 12m 45s) Loss: 0.0050(0.0113) Grad: 8737.5566  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 12m 57s (remain 11m 50s) Loss: 0.0025(0.0113) Grad: 7967.5576  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 13m 52s (remain 10m 54s) Loss: 0.0001(0.0115) Grad: 236.5217  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 14m 48s (remain 9m 59s) Loss: 0.0003(0.0114) Grad: 1135.6626  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 15m 43s (remain 9m 3s) Loss: 0.0000(0.0113) Grad: 109.0336  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 16m 38s (remain 8m 7s) Loss: 0.0042(0.0113) Grad: 12755.8701  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 17m 34s (remain 7m 12s) Loss: 0.0062(0.0113) Grad: 116597.1875  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 18m 29s (remain 6m 17s) Loss: 0.0002(0.0112) Grad: 2513.7615  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 19m 24s (remain 5m 21s) Loss: 0.0002(0.0111) Grad: 3455.7483  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 20m 20s (remain 4m 26s) Loss: 0.0128(0.0111) Grad: 19601.0254  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 21m 15s (remain 3m 30s) Loss: 0.0099(0.0112) Grad: 60792.4062  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 22m 11s (remain 2m 35s) Loss: 0.0214(0.0111) Grad: 26611.0781  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 23m 6s (remain 1m 39s) Loss: 0.0004(0.0111) Grad: 13672.9727  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 24m 2s (remain 0m 44s) Loss: 0.0000(0.0111) Grad: 64.5460  LR: 0.000013  \n",
      "Epoch: [2][2680/2681] Elapsed 24m 46s (remain 0m 0s) Loss: 0.0004(0.0110) Grad: 6435.3296  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 36s) Loss: 0.0014(0.0014) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0056(0.0151) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0028(0.0129) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0024(0.0142) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0002(0.0127) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0027(0.0139) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0000(0.0151) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0585(0.0156) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0049(0.0148) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0000(0.0140) \n",
      "Epoch 2 - avg_train_loss: 0.0110  avg_val_loss: 0.0140  time: 1607s\n",
      "Epoch 2 - Score: 0.8806\n",
      "Epoch 2 - Save Best Score: 0.8806 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 1s (remain 46m 47s) Loss: 0.0008(0.0008) Grad: 2382.3699  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 0m 56s (remain 24m 0s) Loss: 0.0041(0.0068) Grad: 9214.9492  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 1m 51s (remain 22m 59s) Loss: 0.0007(0.0071) Grad: 6656.0083  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 2m 47s (remain 22m 1s) Loss: 0.0184(0.0078) Grad: 865916.5625  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 3m 42s (remain 21m 5s) Loss: 0.0018(0.0077) Grad: 21942.4316  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 4m 37s (remain 20m 8s) Loss: 0.0000(0.0076) Grad: 107.0134  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 5m 33s (remain 19m 13s) Loss: 0.0001(0.0075) Grad: 718.5249  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 6m 28s (remain 18m 17s) Loss: 0.0002(0.0080) Grad: 769.9167  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 7m 23s (remain 17m 21s) Loss: 0.0049(0.0082) Grad: 20779.7871  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 8m 19s (remain 16m 25s) Loss: 0.0139(0.0083) Grad: 16275.0732  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 9m 14s (remain 15m 30s) Loss: 0.0000(0.0083) Grad: 26.2891  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 10m 9s (remain 14m 35s) Loss: 0.0006(0.0084) Grad: 4383.9902  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 11m 5s (remain 13m 39s) Loss: 0.0067(0.0084) Grad: 68415.1406  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 12m 0s (remain 12m 44s) Loss: 0.0005(0.0084) Grad: 2831.9836  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 12m 55s (remain 11m 48s) Loss: 0.0091(0.0084) Grad: 20604.8125  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 13m 51s (remain 10m 53s) Loss: 0.0005(0.0084) Grad: 2600.6489  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 14m 46s (remain 9m 57s) Loss: 0.0033(0.0088) Grad: 6572.7095  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 15m 41s (remain 9m 2s) Loss: 0.0176(0.0087) Grad: 15039.8799  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 16m 37s (remain 8m 7s) Loss: 0.0001(0.0088) Grad: 340.7709  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 17m 32s (remain 7m 11s) Loss: 0.0035(0.0087) Grad: 5668.9775  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 18m 27s (remain 6m 16s) Loss: 0.0131(0.0086) Grad: 39280.2500  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 19m 23s (remain 5m 21s) Loss: 0.0235(0.0085) Grad: 8985.6807  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 20m 18s (remain 4m 25s) Loss: 0.0779(0.0084) Grad: 17140.6035  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 21m 13s (remain 3m 30s) Loss: 0.0002(0.0084) Grad: 309.8260  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 22m 8s (remain 2m 34s) Loss: 0.0001(0.0083) Grad: 144.3280  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 23m 4s (remain 1m 39s) Loss: 0.0001(0.0084) Grad: 96.6366  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 23m 59s (remain 0m 44s) Loss: 0.0006(0.0083) Grad: 897.9409  LR: 0.000009  \n",
      "Epoch: [3][2680/2681] Elapsed 24m 43s (remain 0m 0s) Loss: 0.0002(0.0084) Grad: 314.9710  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 36s) Loss: 0.0023(0.0023) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0004(0.0115) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0086(0.0113) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 17s) Loss: 0.0013(0.0124) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0000(0.0109) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0029(0.0118) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0000(0.0125) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0504(0.0128) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0029(0.0123) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0001(0.0117) \n",
      "Epoch 3 - avg_train_loss: 0.0084  avg_val_loss: 0.0117  time: 1605s\n",
      "Epoch 3 - Score: 0.8820\n",
      "Epoch 3 - Save Best Score: 0.8820 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 1s (remain 46m 56s) Loss: 0.0294(0.0294) Grad: 112462.6953  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 0m 56s (remain 23m 57s) Loss: 0.0012(0.0058) Grad: 23168.2715  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 1m 51s (remain 22m 57s) Loss: 0.0000(0.0058) Grad: 76.3402  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 2m 46s (remain 21m 58s) Loss: 0.0016(0.0058) Grad: 23473.5449  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 3m 42s (remain 21m 2s) Loss: 0.0000(0.0059) Grad: 48.1605  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 4m 37s (remain 20m 6s) Loss: 0.0000(0.0059) Grad: 28.3536  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 5m 32s (remain 19m 10s) Loss: 0.0001(0.0056) Grad: 3474.8064  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 6m 27s (remain 18m 15s) Loss: 0.0612(0.0058) Grad: 95647.9219  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 7m 22s (remain 17m 19s) Loss: 0.0000(0.0059) Grad: 11.3833  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 8m 18s (remain 16m 24s) Loss: 0.0093(0.0057) Grad: 307369.1875  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 9m 13s (remain 15m 28s) Loss: 0.1344(0.0058) Grad: 137179.9688  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 10m 8s (remain 14m 33s) Loss: 0.0013(0.0059) Grad: 37394.5039  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 11m 3s (remain 13m 38s) Loss: 0.0183(0.0057) Grad: 37169.7656  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 11m 59s (remain 12m 42s) Loss: 0.0000(0.0058) Grad: 8.7260  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 12m 54s (remain 11m 47s) Loss: 0.0076(0.0059) Grad: 10814.6953  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 13m 49s (remain 10m 52s) Loss: 0.0001(0.0061) Grad: 401.0011  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 14m 44s (remain 9m 56s) Loss: 0.0000(0.0061) Grad: 120.0301  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 15m 40s (remain 9m 1s) Loss: 0.0050(0.0061) Grad: 7718.4219  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 16m 35s (remain 8m 6s) Loss: 0.0000(0.0061) Grad: 5.3672  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 17m 30s (remain 7m 11s) Loss: 0.0034(0.0062) Grad: 13758.2871  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 18m 25s (remain 6m 15s) Loss: 0.0001(0.0062) Grad: 881.6835  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 19m 20s (remain 5m 20s) Loss: 0.0042(0.0062) Grad: 36658.2031  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 20m 16s (remain 4m 25s) Loss: 0.0004(0.0062) Grad: 2567.8867  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 21m 11s (remain 3m 29s) Loss: 0.0038(0.0063) Grad: 17168.2031  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 22m 6s (remain 2m 34s) Loss: 0.0101(0.0062) Grad: 88206.5625  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 23m 1s (remain 1m 39s) Loss: 0.0016(0.0062) Grad: 19595.2012  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 23m 57s (remain 0m 44s) Loss: 0.0000(0.0062) Grad: 698.0870  LR: 0.000005  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2680/2681] Elapsed 24m 41s (remain 0m 0s) Loss: 0.0001(0.0062) Grad: 2911.8994  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 35s) Loss: 0.0008(0.0008) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0001(0.0168) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0059(0.0150) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0002(0.0158) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0000(0.0141) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0026(0.0150) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0000(0.0158) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0772(0.0168) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0039(0.0163) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0000(0.0154) \n",
      "Epoch 4 - avg_train_loss: 0.0062  avg_val_loss: 0.0154  time: 1602s\n",
      "Epoch 4 - Score: 0.8863\n",
      "Epoch 4 - Save Best Score: 0.8863 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 1s (remain 46m 57s) Loss: 0.0001(0.0001) Grad: 726.1271  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 0m 56s (remain 23m 54s) Loss: 0.0086(0.0050) Grad: 9268.3154  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 1m 51s (remain 22m 56s) Loss: 0.0037(0.0052) Grad: 17326.9023  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 2m 46s (remain 21m 57s) Loss: 0.0073(0.0050) Grad: 34676.6172  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 3m 41s (remain 21m 0s) Loss: 0.0000(0.0050) Grad: 143.7717  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 4m 36s (remain 20m 5s) Loss: 0.0000(0.0048) Grad: 659.5748  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 5m 32s (remain 19m 9s) Loss: 0.0101(0.0045) Grad: 51952.4102  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 6m 27s (remain 18m 13s) Loss: 0.0000(0.0043) Grad: 217.1687  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 7m 22s (remain 17m 18s) Loss: 0.0000(0.0042) Grad: 233.8797  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 8m 17s (remain 16m 22s) Loss: 0.0262(0.0044) Grad: 71895.9688  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 9m 12s (remain 15m 27s) Loss: 0.0000(0.0043) Grad: 77.1326  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 10m 7s (remain 14m 32s) Loss: 0.0000(0.0044) Grad: 70.1467  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 11m 3s (remain 13m 37s) Loss: 0.0250(0.0044) Grad: 285544.5938  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 11m 58s (remain 12m 41s) Loss: 0.0000(0.0044) Grad: 30.3741  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 12m 53s (remain 11m 46s) Loss: 0.0000(0.0044) Grad: 6.7443  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 13m 48s (remain 10m 51s) Loss: 0.0001(0.0044) Grad: 788.4736  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 14m 43s (remain 9m 55s) Loss: 0.0001(0.0043) Grad: 555.0593  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 15m 38s (remain 9m 0s) Loss: 0.0000(0.0043) Grad: 17.8222  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 16m 33s (remain 8m 5s) Loss: 0.0011(0.0043) Grad: 12470.5547  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 17m 28s (remain 7m 10s) Loss: 0.0059(0.0043) Grad: 35672.0352  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 18m 23s (remain 6m 15s) Loss: 0.0012(0.0042) Grad: 41484.2461  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 19m 19s (remain 5m 19s) Loss: 0.0000(0.0042) Grad: 30.3344  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 20m 14s (remain 4m 24s) Loss: 0.0000(0.0044) Grad: 286.0662  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 21m 9s (remain 3m 29s) Loss: 0.0039(0.0044) Grad: 60362.0195  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 22m 4s (remain 2m 34s) Loss: 0.0004(0.0045) Grad: 12006.6113  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 22m 59s (remain 1m 39s) Loss: 0.0000(0.0045) Grad: 167.3996  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 23m 54s (remain 0m 44s) Loss: 0.0000(0.0045) Grad: 20.4922  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][2680/2681] Elapsed 24m 38s (remain 0m 0s) Loss: 0.0001(0.0044) Grad: 3057.0549  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 43s) Loss: 0.0006(0.0006) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0000(0.0188) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0091(0.0173) \n",
      "EVAL: [300/894] Elapsed 0m 39s (remain 1m 16s) Loss: 0.0001(0.0186) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0000(0.0166) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0003(0.0180) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0000(0.0188) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0943(0.0199) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0004(0.0193) \n",
      "EVAL: [893/894] Elapsed 1m 55s (remain 0m 0s) Loss: 0.0000(0.0183) \n",
      "Epoch 5 - avg_train_loss: 0.0044  avg_val_loss: 0.0183  time: 1600s\n",
      "Epoch 5 - Score: 0.8862\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2681] Elapsed 0m 0s (remain 44m 13s) Loss: 0.7411(0.7411) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 0m 56s (remain 24m 2s) Loss: 0.1134(0.4952) Grad: 23757.6484  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 1m 51s (remain 23m 1s) Loss: 0.0252(0.2888) Grad: 5953.7939  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 2m 47s (remain 22m 5s) Loss: 0.0088(0.2080) Grad: 2198.9417  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 3m 43s (remain 21m 8s) Loss: 0.0512(0.1645) Grad: 27917.3906  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 4m 38s (remain 20m 11s) Loss: 0.0071(0.1361) Grad: 5406.4727  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 5m 33s (remain 19m 15s) Loss: 0.1107(0.1168) Grad: 19078.9434  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 6m 29s (remain 18m 20s) Loss: 0.0221(0.1036) Grad: 5209.6406  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 7m 24s (remain 17m 24s) Loss: 0.0164(0.0932) Grad: 5312.4653  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 8m 20s (remain 16m 28s) Loss: 0.0203(0.0846) Grad: 7713.5205  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 9m 15s (remain 15m 32s) Loss: 0.0043(0.0782) Grad: 7964.6001  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 10m 11s (remain 14m 37s) Loss: 0.0030(0.0727) Grad: 2659.4937  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 11m 6s (remain 13m 41s) Loss: 0.0625(0.0688) Grad: 26171.5566  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 12m 2s (remain 12m 45s) Loss: 0.0883(0.0649) Grad: 17030.3848  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 12m 57s (remain 11m 50s) Loss: 0.0014(0.0614) Grad: 490.7664  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 13m 52s (remain 10m 54s) Loss: 0.0303(0.0587) Grad: 3911.3860  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 14m 48s (remain 9m 59s) Loss: 0.0001(0.0562) Grad: 86.9879  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 15m 43s (remain 9m 3s) Loss: 0.0421(0.0539) Grad: 12705.6270  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 16m 38s (remain 8m 7s) Loss: 0.0018(0.0519) Grad: 3628.5276  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 17m 33s (remain 7m 12s) Loss: 0.0093(0.0500) Grad: 2613.5515  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 18m 28s (remain 6m 16s) Loss: 0.0071(0.0485) Grad: 2911.8245  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 19m 23s (remain 5m 21s) Loss: 0.0131(0.0469) Grad: 6310.5605  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 20m 19s (remain 4m 25s) Loss: 0.0035(0.0454) Grad: 2247.0295  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 21m 14s (remain 3m 30s) Loss: 0.0326(0.0441) Grad: 25403.3242  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 22m 9s (remain 2m 35s) Loss: 0.0025(0.0430) Grad: 2662.9009  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 23m 4s (remain 1m 39s) Loss: 0.0058(0.0419) Grad: 3133.6589  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 23m 59s (remain 0m 44s) Loss: 0.0032(0.0407) Grad: 2753.8188  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2680/2681] Elapsed 24m 44s (remain 0m 0s) Loss: 0.0089(0.0399) Grad: 2051.2898  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 40s) Loss: 0.0121(0.0121) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0006(0.0131) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0557(0.0132) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0217(0.0120) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0119(0.0113) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0140(0.0129) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0144(0.0129) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0135(0.0131) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0076(0.0126) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0006(0.0119) \n",
      "Epoch 1 - avg_train_loss: 0.0399  avg_val_loss: 0.0119  time: 1604s\n",
      "Epoch 1 - Score: 0.8516\n",
      "Epoch 1 - Save Best Score: 0.8516 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 1s (remain 46m 27s) Loss: 0.0168(0.0168) Grad: 14606.9951  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 0m 56s (remain 23m 56s) Loss: 0.0002(0.0111) Grad: 439.2554  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 1m 51s (remain 22m 54s) Loss: 0.0026(0.0122) Grad: 15461.7295  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 2m 46s (remain 22m 0s) Loss: 0.0293(0.0121) Grad: 38778.6641  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 3m 42s (remain 21m 4s) Loss: 0.0001(0.0120) Grad: 237.7211  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 4m 37s (remain 20m 7s) Loss: 0.0012(0.0119) Grad: 5995.9980  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 5m 32s (remain 19m 10s) Loss: 0.0009(0.0119) Grad: 11387.6348  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 6m 27s (remain 18m 15s) Loss: 0.0199(0.0125) Grad: 61467.6641  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 7m 22s (remain 17m 19s) Loss: 0.0199(0.0123) Grad: 72969.8984  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 8m 18s (remain 16m 24s) Loss: 0.0000(0.0121) Grad: 402.2088  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 9m 13s (remain 15m 29s) Loss: 0.0017(0.0119) Grad: 7036.5688  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 10m 8s (remain 14m 33s) Loss: 0.0205(0.0116) Grad: 48168.1250  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 11m 4s (remain 13m 38s) Loss: 0.0001(0.0116) Grad: 276.5941  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 11m 59s (remain 12m 42s) Loss: 0.0004(0.0115) Grad: 652.4716  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 12m 54s (remain 11m 47s) Loss: 0.0304(0.0115) Grad: 14838.9961  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 13m 49s (remain 10m 52s) Loss: 0.0049(0.0114) Grad: 11478.4531  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 14m 44s (remain 9m 56s) Loss: 0.0007(0.0113) Grad: 768.7584  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 15m 39s (remain 9m 1s) Loss: 0.0270(0.0113) Grad: 8833.0000  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 16m 34s (remain 8m 6s) Loss: 0.0242(0.0113) Grad: 5950.5767  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 17m 30s (remain 7m 10s) Loss: 0.0083(0.0114) Grad: 3763.7288  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 18m 25s (remain 6m 15s) Loss: 0.0032(0.0115) Grad: 6440.5830  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 19m 20s (remain 5m 20s) Loss: 0.0142(0.0114) Grad: 18968.1230  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 20m 15s (remain 4m 25s) Loss: 0.0004(0.0113) Grad: 850.6377  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 21m 11s (remain 3m 29s) Loss: 0.0040(0.0114) Grad: 1773.2327  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 22m 6s (remain 2m 34s) Loss: 0.0238(0.0114) Grad: 39714.2500  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 23m 1s (remain 1m 39s) Loss: 0.0000(0.0114) Grad: 91.2480  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 23m 57s (remain 0m 44s) Loss: 0.0030(0.0114) Grad: 1961.1169  LR: 0.000013  \n",
      "Epoch: [2][2680/2681] Elapsed 24m 41s (remain 0m 0s) Loss: 0.0256(0.0114) Grad: 9022.9766  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 39s) Loss: 0.0039(0.0039) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0004(0.0112) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0536(0.0128) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0108(0.0116) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0105(0.0106) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0176(0.0126) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0177(0.0130) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0153(0.0128) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0042(0.0122) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0002(0.0117) \n",
      "Epoch 2 - avg_train_loss: 0.0114  avg_val_loss: 0.0117  time: 1601s\n",
      "Epoch 2 - Score: 0.8782\n",
      "Epoch 2 - Save Best Score: 0.8782 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 1s (remain 46m 13s) Loss: 0.0021(0.0021) Grad: 23223.8438  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 0m 56s (remain 23m 59s) Loss: 0.0092(0.0091) Grad: 36351.5078  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 1m 51s (remain 22m 56s) Loss: 0.0000(0.0096) Grad: 122.2657  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 2m 46s (remain 22m 0s) Loss: 0.0000(0.0091) Grad: 15.3984  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 3m 42s (remain 21m 3s) Loss: 0.0026(0.0090) Grad: 7705.3242  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 4m 37s (remain 20m 7s) Loss: 0.0001(0.0088) Grad: 581.9245  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 5m 32s (remain 19m 11s) Loss: 0.0015(0.0087) Grad: 14233.3369  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 6m 28s (remain 18m 16s) Loss: 0.0000(0.0086) Grad: 131.0315  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 7m 23s (remain 17m 20s) Loss: 0.0172(0.0085) Grad: 472017.7188  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 8m 18s (remain 16m 25s) Loss: 0.0206(0.0084) Grad: 64787.5000  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 9m 13s (remain 15m 29s) Loss: 0.0013(0.0085) Grad: 5226.6782  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 10m 9s (remain 14m 34s) Loss: 0.0001(0.0086) Grad: 449.5867  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 11m 4s (remain 13m 38s) Loss: 0.0168(0.0087) Grad: 66276.5859  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 11m 59s (remain 12m 43s) Loss: 0.1214(0.0088) Grad: 36666.8242  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 12m 54s (remain 11m 47s) Loss: 0.0020(0.0086) Grad: 8565.0635  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 13m 50s (remain 10m 52s) Loss: 0.0137(0.0087) Grad: 87599.0547  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 14m 45s (remain 9m 57s) Loss: 0.0080(0.0088) Grad: 110754.9688  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 15m 40s (remain 9m 2s) Loss: 0.0007(0.0088) Grad: 2572.2417  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 16m 36s (remain 8m 6s) Loss: 0.0001(0.0088) Grad: 254.3627  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 17m 31s (remain 7m 11s) Loss: 0.0046(0.0088) Grad: 14643.0605  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 18m 26s (remain 6m 16s) Loss: 0.0001(0.0087) Grad: 1008.3563  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 19m 21s (remain 5m 20s) Loss: 0.0426(0.0088) Grad: 170649.1562  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 20m 17s (remain 4m 25s) Loss: 0.0122(0.0088) Grad: 56989.6250  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 21m 12s (remain 3m 30s) Loss: 0.0007(0.0087) Grad: 19380.1309  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 22m 7s (remain 2m 34s) Loss: 0.0019(0.0087) Grad: 46951.0234  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 23m 2s (remain 1m 39s) Loss: 0.0000(0.0086) Grad: 64.1092  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 23m 57s (remain 0m 44s) Loss: 0.0000(0.0086) Grad: 80.7886  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2680/2681] Elapsed 24m 42s (remain 0m 0s) Loss: 0.0000(0.0087) Grad: 66.1255  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 46s) Loss: 0.0040(0.0040) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0003(0.0127) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0420(0.0143) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0096(0.0136) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0335(0.0127) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0188(0.0151) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0151(0.0156) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0101(0.0154) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0004(0.0148) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0000(0.0141) \n",
      "Epoch 3 - avg_train_loss: 0.0087  avg_val_loss: 0.0141  time: 1603s\n",
      "Epoch 3 - Score: 0.8840\n",
      "Epoch 3 - Save Best Score: 0.8840 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 1s (remain 46m 22s) Loss: 0.0004(0.0004) Grad: 74854.2578  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 0m 56s (remain 23m 54s) Loss: 0.0001(0.0058) Grad: 175.7405  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 1m 51s (remain 22m 53s) Loss: 0.0145(0.0053) Grad: 4866.7734  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 2m 46s (remain 21m 57s) Loss: 0.0006(0.0054) Grad: 9997.1826  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 3m 41s (remain 21m 0s) Loss: 0.0031(0.0059) Grad: 8991.8428  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 4m 37s (remain 20m 5s) Loss: 0.0156(0.0061) Grad: 19278.6465  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 5m 32s (remain 19m 9s) Loss: 0.0001(0.0062) Grad: 777.4606  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 6m 27s (remain 18m 14s) Loss: 0.0096(0.0063) Grad: 32794.4375  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 7m 22s (remain 17m 18s) Loss: 0.0000(0.0062) Grad: 30.7857  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 8m 17s (remain 16m 23s) Loss: 0.0027(0.0064) Grad: 7475.6152  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 9m 12s (remain 15m 27s) Loss: 0.0001(0.0064) Grad: 157.9924  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 10m 8s (remain 14m 32s) Loss: 0.0003(0.0065) Grad: 552.9495  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 11m 3s (remain 13m 37s) Loss: 0.0000(0.0065) Grad: 17.7821  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 11m 58s (remain 12m 42s) Loss: 0.0001(0.0065) Grad: 146.9782  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 12m 53s (remain 11m 46s) Loss: 0.0115(0.0066) Grad: 22851.5645  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 13m 48s (remain 10m 51s) Loss: 0.0046(0.0066) Grad: 14137.2148  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 14m 44s (remain 9m 56s) Loss: 0.0000(0.0064) Grad: 26.2142  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 15m 39s (remain 9m 1s) Loss: 0.0211(0.0064) Grad: 30768.5566  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 16m 34s (remain 8m 5s) Loss: 0.0002(0.0064) Grad: 1077.5383  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 17m 29s (remain 7m 10s) Loss: 0.0000(0.0064) Grad: 55.0945  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 18m 24s (remain 6m 15s) Loss: 0.0008(0.0064) Grad: 3593.4084  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 19m 19s (remain 5m 20s) Loss: 0.0004(0.0064) Grad: 565.4746  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 20m 15s (remain 4m 24s) Loss: 0.0047(0.0064) Grad: 12145.7539  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 21m 10s (remain 3m 29s) Loss: 0.0001(0.0064) Grad: 135.9179  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 22m 5s (remain 2m 34s) Loss: 0.0044(0.0063) Grad: 3525.7534  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 23m 0s (remain 1m 39s) Loss: 0.0050(0.0063) Grad: 6670.1006  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 23m 55s (remain 0m 44s) Loss: 0.0155(0.0062) Grad: 17973.6406  LR: 0.000005  \n",
      "Epoch: [4][2680/2681] Elapsed 24m 39s (remain 0m 0s) Loss: 0.0117(0.0062) Grad: 33001.8477  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 32s) Loss: 0.0034(0.0034) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 45s) Loss: 0.0001(0.0115) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0442(0.0129) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0212(0.0127) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0240(0.0120) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0168(0.0138) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0154(0.0142) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0105(0.0141) \n",
      "EVAL: [800/894] Elapsed 1m 43s (remain 0m 11s) Loss: 0.0008(0.0138) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0000(0.0131) \n",
      "Epoch 4 - avg_train_loss: 0.0062  avg_val_loss: 0.0131  time: 1600s\n",
      "Epoch 4 - Score: 0.8860\n",
      "Epoch 4 - Save Best Score: 0.8860 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 1s (remain 46m 20s) Loss: 0.0000(0.0000) Grad: 113.7476  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 0m 56s (remain 23m 54s) Loss: 0.0000(0.0032) Grad: 10.7630  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 1m 51s (remain 22m 52s) Loss: 0.0549(0.0039) Grad: 109082.3203  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 2m 46s (remain 21m 55s) Loss: 0.0001(0.0043) Grad: 627.6280  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 3m 41s (remain 21m 0s) Loss: 0.0000(0.0044) Grad: 20.6574  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 4m 36s (remain 20m 3s) Loss: 0.0029(0.0041) Grad: 11976.1914  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 5m 31s (remain 19m 7s) Loss: 0.0026(0.0041) Grad: 6724.9102  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 6m 26s (remain 18m 12s) Loss: 0.0001(0.0039) Grad: 278.9788  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 7m 21s (remain 17m 16s) Loss: 0.0005(0.0040) Grad: 2624.7629  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 8m 16s (remain 16m 21s) Loss: 0.0000(0.0041) Grad: 11.5284  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 9m 11s (remain 15m 26s) Loss: 0.0360(0.0041) Grad: 95387.2188  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 10m 7s (remain 14m 31s) Loss: 0.0000(0.0041) Grad: 6.3859  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 11m 2s (remain 13m 35s) Loss: 0.0158(0.0041) Grad: 20687.0488  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 11m 57s (remain 12m 40s) Loss: 0.0066(0.0043) Grad: 11468.0430  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 12m 52s (remain 11m 45s) Loss: 0.0262(0.0044) Grad: 42836.1914  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 13m 47s (remain 10m 50s) Loss: 0.0000(0.0046) Grad: 21.0727  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 14m 42s (remain 9m 55s) Loss: 0.0028(0.0045) Grad: 5448.4780  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 15m 37s (remain 9m 0s) Loss: 0.0000(0.0045) Grad: 28.9509  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 16m 32s (remain 8m 5s) Loss: 0.0005(0.0046) Grad: 8742.2139  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 17m 28s (remain 7m 10s) Loss: 0.0002(0.0045) Grad: 486.1584  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 18m 23s (remain 6m 14s) Loss: 0.0003(0.0045) Grad: 2870.5066  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 19m 18s (remain 5m 19s) Loss: 0.0044(0.0044) Grad: 5563.6362  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 20m 12s (remain 4m 24s) Loss: 0.0056(0.0044) Grad: 13288.6787  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 21m 7s (remain 3m 29s) Loss: 0.0043(0.0044) Grad: 7398.5264  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 22m 2s (remain 2m 34s) Loss: 0.0574(0.0045) Grad: 71911.2656  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 22m 58s (remain 1m 39s) Loss: 0.0002(0.0044) Grad: 457.4064  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 23m 53s (remain 0m 44s) Loss: 0.0012(0.0044) Grad: 7590.6157  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][2680/2681] Elapsed 24m 37s (remain 0m 0s) Loss: 0.0112(0.0044) Grad: 15123.7021  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 29s) Loss: 0.0033(0.0033) \n",
      "EVAL: [100/894] Elapsed 0m 13s (remain 1m 44s) Loss: 0.0002(0.0145) \n",
      "EVAL: [200/894] Elapsed 0m 26s (remain 1m 30s) Loss: 0.0537(0.0160) \n",
      "EVAL: [300/894] Elapsed 0m 38s (remain 1m 16s) Loss: 0.0171(0.0156) \n",
      "EVAL: [400/894] Elapsed 0m 51s (remain 1m 3s) Loss: 0.0262(0.0147) \n",
      "EVAL: [500/894] Elapsed 1m 4s (remain 0m 50s) Loss: 0.0197(0.0166) \n",
      "EVAL: [600/894] Elapsed 1m 17s (remain 0m 37s) Loss: 0.0204(0.0169) \n",
      "EVAL: [700/894] Elapsed 1m 30s (remain 0m 24s) Loss: 0.0181(0.0168) \n",
      "EVAL: [800/894] Elapsed 1m 42s (remain 0m 11s) Loss: 0.0003(0.0163) \n",
      "EVAL: [893/894] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0000(0.0155) \n",
      "Epoch 5 - avg_train_loss: 0.0044  avg_val_loss: 0.0155  time: 1598s\n",
      "Epoch 5 - Score: 0.8855\n",
      "best_thres: 0.45  score: 0.88374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f9752d03a047cf9df84ed844554b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7f790992e430>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 132, in __del__\n",
      "    close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "        self._close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "self._close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "        _close(self._handle)\n",
      "_close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba14bc56a47e4c25b3ce8814d325fd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e587407cd340b4a07216132c6c6e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7f790992e430>Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "\n",
      "Traceback (most recent call last):\n",
      "    close()  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 132, in __del__\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "_close(self._handle)    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    \n",
      "self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4f4d1e008744c8b0a17aa070b488dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "        self._close()self._close()\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)    _close(self._handle)\n",
      "OSError\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      ":     [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "ValueError: semaphore or lock released too many times\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp043.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b503e832e57492291cbf6e9ae66e343": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c70395dca6341349fc883dc6b95090a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a92171cb3d34fc8b1ed5119e32951ac",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a202501b76a748fe80180604dff32c7b",
      "value": 42146
     }
    },
    "0dfe4d3aa0354d95bb5d019420b510a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3d9ac191d9b4772ae4bca323a34ddd7",
      "placeholder": "​",
      "style": "IPY_MODEL_9deae6afbd4740df8eb0289bc5f53ae7",
      "value": " 42146/42146 [00:35&lt;00:00, 2027.81it/s]"
     }
    },
    "14efac00edd349898e9fa95a63a2773d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f6c8df95c7845818253189f2e365ba9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33e4f48f7c8f40f48081c34bc992f215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40ae5d1c9e9f4feaa4207599ef17a1ec",
      "placeholder": "​",
      "style": "IPY_MODEL_8cd3352e5e9342e4a814e9958ea6dc1d",
      "value": "100%"
     }
    },
    "40ae5d1c9e9f4feaa4207599ef17a1ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47e8d82f628f4bd7b8b0ef0aa96852a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc9a4ba21d664dafb8ae32a4e0a1c5e0",
       "IPY_MODEL_f4421d3b3a844dbcb003f11902ee1898",
       "IPY_MODEL_d02f186539954463873bb560b775894e"
      ],
      "layout": "IPY_MODEL_14efac00edd349898e9fa95a63a2773d"
     }
    },
    "5a92171cb3d34fc8b1ed5119e32951ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e29db6be6284caa978ee223047f23c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "625abc68d2fb4fd4b8556c7cc1ae514a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83d1b90076dc431893e0ab1c87e35f9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c7eb508782d4253af8cbff0a39e5d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33e4f48f7c8f40f48081c34bc992f215",
       "IPY_MODEL_0c70395dca6341349fc883dc6b95090a",
       "IPY_MODEL_0dfe4d3aa0354d95bb5d019420b510a9"
      ],
      "layout": "IPY_MODEL_e6775e6fc2ad4b14b473b8a07e27426d"
     }
    },
    "8cd3352e5e9342e4a814e9958ea6dc1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9deae6afbd4740df8eb0289bc5f53ae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a202501b76a748fe80180604dff32c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3d9ac191d9b4772ae4bca323a34ddd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc9a4ba21d664dafb8ae32a4e0a1c5e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83d1b90076dc431893e0ab1c87e35f9c",
      "placeholder": "​",
      "style": "IPY_MODEL_0b503e832e57492291cbf6e9ae66e343",
      "value": "100%"
     }
    },
    "d02f186539954463873bb560b775894e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f6c8df95c7845818253189f2e365ba9",
      "placeholder": "​",
      "style": "IPY_MODEL_5e29db6be6284caa978ee223047f23c5",
      "value": " 143/143 [00:00&lt;00:00, 2361.05it/s]"
     }
    },
    "d2581946e9fd4f9a8dc56b3453cc70bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6775e6fc2ad4b14b473b8a07e27426d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4421d3b3a844dbcb003f11902ee1898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_625abc68d2fb4fd4b8556c7cc1ae514a",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d2581946e9fd4f9a8dc56b3453cc70bd",
      "value": 143
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
