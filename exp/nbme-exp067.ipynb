{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legitimate-volume",
   "metadata": {
    "id": "national-fancy"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-settle",
   "metadata": {
    "id": "copyrighted-centre"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-triumph",
   "metadata": {
    "id": "imported-offset"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedicated-multiple",
   "metadata": {
    "id": "complimentary-wyoming"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp067\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-offense",
   "metadata": {
    "id": "allied-circuit"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-xlarge\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    max_char_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=4\n",
    "    train_fold=[0, 1, 2, 3]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prescription-absence",
   "metadata": {
    "id": "geographic-hindu"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-chemistry",
   "metadata": {
    "id": "confident-fifth"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifth-observation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miniature-greeting",
    "outputId": "08ac8fa6-ea33-4a63-98f5-a1a0dc6b6c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers==4.16.2\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technological-framework",
   "metadata": {
    "id": "guilty-filename"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "usual-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"]= \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-slovakia",
   "metadata": {
    "id": "cubic-designation"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seeing-customer",
   "metadata": {
    "id": "opposite-plasma"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "handled-pixel",
   "metadata": {
    "id": "multiple-poland"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        # result = np.where(char_prob >= th)[0] + 1\n",
    "        result = np.where(char_prob >= th)[0]\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        # result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = [f\"{min(r)} {max(r) + 1}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5, use_token_prob=True):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    if use_token_prob:\n",
    "        token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "        char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    else:\n",
    "        char_probs = df[[str(i) for i in range(CFG.max_char_len)]].values\n",
    "        char_probs = [char_probs[i] for i in range(len(char_probs))]\n",
    "\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minute-middle",
   "metadata": {
    "id": "seventh-fighter"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "digital-diary",
   "metadata": {
    "id": "fifty-boundary"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hotel",
   "metadata": {
    "id": "unlimited-hotel"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "resistant-swiss",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "classical-machine",
    "outputId": "43c50ebf-fa21-42ee-ca76-e0e3e5da96bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spread-annotation",
   "metadata": {
    "id": "vanilla-iceland"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-newsletter",
   "metadata": {
    "id": "convenient-plant"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "muslim-sphere",
   "metadata": {
    "id": "convertible-thunder"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "southwest-break",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "charitable-memphis",
    "outputId": "c4b24bdc-38ac-441c-d6c8-f543be7a6668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "automated-external",
   "metadata": {
    "id": "governing-election"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "damaged-biography",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "negative-provincial",
    "outputId": "3a2729b4-a092-4a5b-964b-2aa98fbda037"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-insert",
   "metadata": {
    "id": "arbitrary-beatles"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "gothic-blind",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "important-murray",
    "outputId": "4e611f40-0e28-41b0-b143-0df43238be33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    3575\n",
       "1    3575\n",
       "2    3575\n",
       "3    3575\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "groups = train['pn_num'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-percentage",
   "metadata": {
    "id": "configured-chemistry"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "threaded-connecticut",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "40581063d44b4eb392f534138ae5d2cb",
      "7e64f8626bbf4daba50cf499d4adc6f4",
      "44e6de0ebd2a4ef58a586ef14c21cbb1",
      "2f68cae6212b46af8a195ee3b7011546",
      "ab1aca1c8d8b4c4a80c10482ce30fb0b",
      "aeb1dc88817e4c9f80e7e9af10116468",
      "840fd42b736e4a368a021d9372362709",
      "37e26fb7433847f5a99ba2228fe2551b",
      "a0cf3cdeef694167b9641c1fa4131746",
      "bae123ba33dc490ebb5419355fdddedb",
      "74c044535cb345809273b1724907c736",
      "5fcb7d1794054cf190fad1a98905c063",
      "7976633024c64c9b8eb73f719392b663",
      "429e4e00e8b2409993a3fc8d88cbd8a4",
      "e2c7eb205b5e49da89d8aec82fdaf076",
      "037c7090db304999a1101d9e2e5a4174",
      "518a4dae6e9440d4a5c08d3072789185",
      "2f52fd0cd6a74daabf24b771a497e17d",
      "d078b771963249d1b3061804258dcf16",
      "9164887b3ee24c99bbf60652fd1b5c32",
      "e6fc1c67116248b288adde889a689193",
      "4f374a11ffa3408791f9d8a4acd13eba",
      "f33aa873d8654f18b67df7995dbcb71e",
      "293383a7075940e3afbfb11b17dcb0bc",
      "d5fef2adb9d747c6bd487b40e3b809cb",
      "78e822ad4e1a4e01974ed07340353a5d",
      "5036ba2cf1d14c43a3e1d82fa3cb8853",
      "c419f9f3f6d44830b1685d75cb27344e",
      "18b08cf3579d45368f654d76b94bde98",
      "6f27a875918e49778dc71b4c2dbb72e8",
      "2111e9eb51a144569ff012d84e83d7a1",
      "e41e8330b9f24c90b75c1a6e6e699fd3",
      "3d0006900ef744a7a5171ec2932c488e",
      "96d9a1b6233f44c0a94e73aeec99e9cf",
      "1ac1c449974e49d2a5ca44923c8c7c2f",
      "38acebf8e4e24912a40d15ff423b82b5",
      "9e1f40698b1640a791d47f5535c2195e",
      "e8fe4cfe66dd4d638144738444a255dc",
      "184eb6da09c746e5bc0a1795e63d9ca0",
      "36a6535e0d4246d295f0c4040f58c44a",
      "8cd7e4275e784665902cc5f4930e875a",
      "30c61e5a6dff40088c1b6ac7cce7e1ce",
      "295c5dd71a3b40729c0cfa8f4b9e739c",
      "17cdfeae485f4cdd9602211051e4d8cc"
     ]
    },
    "id": "hindu-contest",
    "outputId": "824f3c50-64be-4177-931d-254afd935b7b"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-fishing",
   "metadata": {
    "id": "alleged-protein"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rotary-patch",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "d8a0630ab85242a2964952e8d01d0aa0",
      "6ae57745545e41e8af94dba3d3cab972",
      "60c41f7069544093bc03c7eca22eb103",
      "ca10a5382123481da26efdbc3517aaa5",
      "cec25d0ed87a480384676eee910c5ef6",
      "29b82ceb3d7e4f25a45b0a01b0a9b331",
      "9f7532640efe4accb279b1a1fe06cbf8",
      "defedb7dd63045df973acbc933b9762f",
      "9772a88a338347909cada09e8d2082e5",
      "eddea6b1941646a98d2946cc0b95e7f6",
      "7478819134434d33bbc38feeac11c88a"
     ]
    },
    "id": "composed-stroke",
    "outputId": "1b00ea8f-3e17-4031-8b82-316363dfe0bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bef98a53b7d48d28a9da0a6d659c24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 433\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minor-screen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "05899ddeb69f42e19a6a4f2e8e58d1a3",
      "79874640551f423882aa448bc2cf852a",
      "e5a6f08db13d4b3897310578958b756c",
      "dc98eacd6dc14b65951354be55896f95",
      "8afeb9769ec1438fa590a2f55898d33c",
      "52017694880f40efb76ed78fffe936a6",
      "c3063e2f2f074591b1a94abe4ba25ea2",
      "2b71730a985e49babde4e34a72e97dc8",
      "a2209d4bb35842509ec9c618a4baf91f",
      "767bec79de264f869d9a95d88e9fd8f5",
      "ae111ebaf27e477784490dda702602be"
     ]
    },
    "id": "emotional-region",
    "outputId": "1b30456b-3c31-49a8-ed4b-43a136bb94d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0a03130eaa474d901622da564215d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 30\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "occupational-argument",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrong-leisure",
    "outputId": "0819a380-0200-4bb5-dda0-fdf1baf89fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 466\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "reserved-vancouver",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "ea2c108b9852466c96e9f139fb7b86c0",
      "fd4193c79e8a41cfa08b2ac6e95c1f81",
      "5fc780deb9bd4005badbd8613d0dcd09",
      "3da621183b0f4d488b1150d0fd4ab44e",
      "6b51934ee3df452da196cf89bb5e6958",
      "4f26f3e1f9e545e8a1f83fe4307e3857",
      "10dc1b43c16f4bfea6b6bcb7322ec3cd",
      "4c2225dd49ae4dffac171b940fd503fe",
      "2d0e66a3deb04a898bb3c766d2a4d4bd",
      "db746b1ed1d6485881ea9d1a89204363",
      "7f61f28890dd4c519cb602ef9deead90"
     ]
    },
    "id": "convenient-gospel",
    "outputId": "4afacb37-0880-43e2-9904-e8fa59462e22"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee31b0e082e45d5be86972337ce26b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 950\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(text)\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "CFG.max_char_len = max(pn_history_lengths)\n",
    "\n",
    "print(\"max length:\", CFG.max_char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "viral-scholar",
   "metadata": {
    "id": "representative-contributor"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.max_char_len = self.cfg.max_char_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_mapping_from_token_to_char(self, pn_history):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        mapping_from_token_to_char = np.zeros(self.max_char_len)\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        for i, offset in enumerate(offset_mapping):\n",
    "            start_idx, end_idx = offset\n",
    "            mapping_from_token_to_char[start_idx:end_idx] = i\n",
    "        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        label = np.zeros(self.max_char_len)\n",
    "        label[len(pn_history):] = -1\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    label[start:end] = 1\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n",
    "        return input_, label, mapping_from_token_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "authorized-cheese",
   "metadata": {
    "id": "decent-johnson"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.max_char_len = self.cfg.max_char_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_mapping_from_token_to_char(self, pn_history):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        mapping_from_token_to_char = np.zeros(self.max_char_len)\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        for i, offset in enumerate(offset_mapping):\n",
    "            start_idx, end_idx = offset\n",
    "            mapping_from_token_to_char[start_idx:end_idx] = i\n",
    "        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n",
    "        return input_, mapping_from_token_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-insertion",
   "metadata": {
    "id": "arctic-joint"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "statutory-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class MaskedModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(\n",
    "                cfg.pretrained_model_name,\n",
    "                output_hidden_states=False\n",
    "                )\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.pretrained_model_name, config=self.config)\n",
    "            self.lm_head = AutoModelForMaskedLM.from_pretrained(cfg.pretrained_model_name, config=self.config).cls # [cls, lm_head]\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "            self.lm_head = AutoModelForMaskedLM(self.config).cls # [cls, lm_head]\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            input_ids=None,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            #position_ids=None,\n",
    "            inputs_embeds=None,\n",
    "            labels=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None):\n",
    "        \n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            #position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,)\n",
    "        \n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.lm_head(sequence_output)\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        return MaskedLMOutput(loss=masked_lm_loss,\n",
    "                              logits=prediction_scores,\n",
    "                              hidden_states=outputs.hidden_states,\n",
    "                              attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "collected-commissioner",
   "metadata": {
    "id": "UtM7nYFm333y"
   },
   "outputs": [],
   "source": [
    "class Exp066Model(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            # itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n",
    "            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n",
    "            # state_dict = torch.load(path)\n",
    "            # itpt.load_state_dict(state_dict)\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\"\n",
    "            masked_model = MaskedModel(CFG, config_path=None, pretrained=True)\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            masked_model.load_state_dict(state)\n",
    "            self.backbone = masked_model.model\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "announced-bottom",
   "metadata": {
    "id": "alternative-malawi"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False, i_fold=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "\n",
    "            model = Exp066Model(cfg, model_config_path=None, pretrained=False)\n",
    "            # path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp066\" /  f\"fold{i_fold}_best.pth\")\n",
    "            path = f\"../output/nbme-score-clinical-patient-notes/nbme-exp066/fold{i_fold}_best.pth\"\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            self.backbone = model.backbone\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.model_config.hidden_size,\n",
    "            bidirectional=True,\n",
    "            hidden_size=self.model_config.hidden_size // 2,\n",
    "            num_layers=4,\n",
    "            dropout=self.cfg.dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, mappings_from_token_to_char):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]  # [batch, seq_len, d_model]\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.unsqueeze(2).expand(-1, -1, self.model_config.hidden_size)\n",
    "        h = torch.gather(h, 1, mappings_from_token_to_char)    # [batch, seq_len, d_model]\n",
    "        h, _ = self.lstm(h)\n",
    "        output = self.fc(h)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-ownership",
   "metadata": {
    "id": "therapeutic-assembly"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "funny-breed",
   "metadata": {
    "id": "going-conversion"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device) \n",
    "        batch_size = labels.size(0)\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs, mappings_from_token_to_char)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "owned-italic",
   "metadata": {
    "id": "alleged-commonwealth"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device) \n",
    "        batch_size = labels.size(0)\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs, mappings_from_token_to_char)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "        loss = loss.mean()\n",
    "    \n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "funny-approval",
   "metadata": {
    "id": "middle-determination"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for (inputs, mappings_from_token_to_char) in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs, mappings_from_token_to_char)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "incorporated-humor",
   "metadata": {
    "id": "familiar-participation"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False, i_fold=i_fold)   # itptを使うため\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    # freeze\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    best_score = -1 * np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_char_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5, use_token_prob=False)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_char_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-system",
   "metadata": {
    "id": "coated-cameroon"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "molecular-hopkins",
   "metadata": {
    "id": "quality-expansion"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    best_thres = 0.5\n",
    "    best_score = 0.\n",
    "    for th in np.arange(0.45, 0.55, 0.01):\n",
    "        th = np.round(th, 2)\n",
    "        score = scoring(oof_df, th=th, use_token_prob=False)\n",
    "        if best_score < score:\n",
    "            best_thres = th\n",
    "            best_score = score\n",
    "    print(f\"best_thres: {best_thres}  score: {best_score:.5f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            print(f\"load weights from {path}\")\n",
    "            test_char_probs = inference_fn(test_dataloader, model, device)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_char_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "weighted-overhead",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e02b42eec984434baf61fc2f03030a05",
      "0a1370ce38a04112931ddb9e98e0681d",
      "e0cf2e2638884464aa945f949afb580e",
      "192e369ce01f4056bb9e8cb9c1f58fb9",
      "49d75d7c4cf34990a659483f4d4caeee",
      "97f866a7b47044c6b13b510364db0936",
      "0a9ded7de82b4e05966e232fa1f2c787",
      "1da67dda0fcd4e30801d258ce5b94dcc",
      "2ee84c25ddbd4dafac1dfe5c85bdaa0f",
      "1c636a002bc649a89f18438cc014060b",
      "9e43b827da0d430389152133415c8597",
      "7b5a579308f3471a8233cb83c140a661",
      "8a88ce37e03a4557bc114cfbc4713717",
      "ea2f58f8a37b432da4bb669b59c131e4",
      "d35405c96d2e4009bd853115c097bd86",
      "f6b30ed009ce46279f1f23a732caa920",
      "8fa8cd67d0214aeba9c9159beec33b2d",
      "7af068350d6e4480bdc816cb7b5719f1",
      "fd7421cac7834be09bf821fcff9e5295",
      "1fe2a3a2e3c24cebab36756c281a53b8",
      "111571ccdbaa4cc2930a5879301e8e0f",
      "70c2506df3db4c9fb0433dc01c86244d"
     ]
    },
    "id": "proprietary-civilian",
    "outputId": "91f1bb20-bf49-4645-a799-b6c0a2ee6740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp066/fold0_best.pth\n",
      "Epoch: [1][0/2681] Elapsed 0m 1s (remain 46m 4s) Loss: 0.6844(0.6844) Grad: 52778.6680  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 1m 4s (remain 27m 15s) Loss: 0.6441(0.6718) Grad: 52420.0938  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 2m 7s (remain 26m 7s) Loss: 0.4969(0.6271) Grad: 57028.8516  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 3m 10s (remain 25m 2s) Loss: 0.1881(0.5360) Grad: 50494.0430  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 4m 13s (remain 23m 58s) Loss: 0.0330(0.4242) Grad: 6636.1689  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 5m 16s (remain 22m 55s) Loss: 0.0066(0.3430) Grad: 1146.6115  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 6m 19s (remain 21m 51s) Loss: 0.0048(0.2873) Grad: 484.9509  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 7m 22s (remain 20m 48s) Loss: 0.0080(0.2471) Grad: 1602.9169  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 8m 25s (remain 19m 45s) Loss: 0.0067(0.2172) Grad: 1065.4896  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 9m 27s (remain 18m 42s) Loss: 0.0009(0.1939) Grad: 195.3271  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 10m 30s (remain 17m 38s) Loss: 0.0014(0.1752) Grad: 326.3656  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 11m 33s (remain 16m 35s) Loss: 0.0019(0.1597) Grad: 409.3768  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 12m 36s (remain 15m 32s) Loss: 0.0008(0.1468) Grad: 244.1877  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 13m 39s (remain 14m 29s) Loss: 0.0087(0.1359) Grad: 904.0803  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 14m 42s (remain 13m 26s) Loss: 0.0005(0.1265) Grad: 107.0324  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 15m 45s (remain 12m 23s) Loss: 0.0016(0.1183) Grad: 251.6308  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 16m 48s (remain 11m 20s) Loss: 0.0029(0.1112) Grad: 365.4921  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 17m 51s (remain 10m 17s) Loss: 0.0005(0.1049) Grad: 194.0356  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 18m 54s (remain 9m 14s) Loss: 0.0003(0.0993) Grad: 95.0468  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 19m 57s (remain 8m 11s) Loss: 0.0005(0.0943) Grad: 216.0556  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 21m 0s (remain 7m 8s) Loss: 0.0007(0.0897) Grad: 605.4346  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 22m 3s (remain 6m 5s) Loss: 0.0023(0.0857) Grad: 704.8538  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 23m 6s (remain 5m 2s) Loss: 0.0006(0.0820) Grad: 668.6606  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 24m 9s (remain 3m 59s) Loss: 0.0014(0.0786) Grad: 981.9985  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 25m 12s (remain 2m 56s) Loss: 0.0154(0.0755) Grad: 8496.1914  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 26m 15s (remain 1m 53s) Loss: 0.0002(0.0726) Grad: 321.0359  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 27m 18s (remain 0m 50s) Loss: 0.0006(0.0700) Grad: 614.8641  LR: 0.000018  \n",
      "Epoch: [1][2680/2681] Elapsed 28m 9s (remain 0m 0s) Loss: 0.0007(0.0680) Grad: 492.1575  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 49s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/894] Elapsed 0m 32s (remain 4m 18s) Loss: 0.0001(0.0161) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 44s) Loss: 0.0019(0.0186) \n",
      "EVAL: [300/894] Elapsed 1m 37s (remain 3m 12s) Loss: 0.0123(0.0197) \n",
      "EVAL: [400/894] Elapsed 2m 9s (remain 2m 39s) Loss: 0.0531(0.0186) \n",
      "EVAL: [500/894] Elapsed 2m 42s (remain 2m 7s) Loss: 0.0126(0.0223) \n",
      "EVAL: [600/894] Elapsed 3m 14s (remain 1m 34s) Loss: 0.0076(0.0244) \n",
      "EVAL: [700/894] Elapsed 3m 47s (remain 1m 2s) Loss: 0.0001(0.0247) \n",
      "EVAL: [800/894] Elapsed 4m 19s (remain 0m 30s) Loss: 0.0025(0.0240) \n",
      "EVAL: [893/894] Elapsed 4m 49s (remain 0m 0s) Loss: 0.0001(0.0228) \n",
      "Epoch 1 - avg_train_loss: 0.0680  avg_val_loss: 0.0228  time: 1981s\n",
      "Epoch 1 - Score: 0.8814\n",
      "Epoch 1 - Save Best Score: 0.8814 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 0s (remain 43m 0s) Loss: 0.0472(0.0472) Grad: 7530.2241  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 1m 4s (remain 27m 16s) Loss: 0.0011(0.0027) Grad: 423.0115  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 2m 7s (remain 26m 8s) Loss: 0.0006(0.0027) Grad: 324.5608  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 3m 10s (remain 25m 3s) Loss: 0.0050(0.0026) Grad: 1471.2389  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 4m 13s (remain 23m 59s) Loss: 0.0001(0.0029) Grad: 61.3083  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 5m 16s (remain 22m 56s) Loss: 0.0006(0.0027) Grad: 360.2280  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 6m 19s (remain 21m 52s) Loss: 0.0000(0.0028) Grad: 39.6150  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 7m 22s (remain 20m 49s) Loss: 0.0002(0.0028) Grad: 128.0180  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 8m 25s (remain 19m 46s) Loss: 0.0033(0.0029) Grad: 1406.2792  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 9m 28s (remain 18m 43s) Loss: 0.0015(0.0031) Grad: 899.4877  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 10m 31s (remain 17m 40s) Loss: 0.0065(0.0031) Grad: 1456.4655  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 11m 34s (remain 16m 36s) Loss: 0.0036(0.0033) Grad: 1016.3141  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 12m 37s (remain 15m 33s) Loss: 0.0002(0.0034) Grad: 117.8691  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 13m 40s (remain 14m 30s) Loss: 0.0000(0.0034) Grad: 39.5323  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 14m 43s (remain 13m 27s) Loss: 0.0004(0.0035) Grad: 195.1463  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 15m 46s (remain 12m 24s) Loss: 0.0001(0.0034) Grad: 41.9181  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 16m 50s (remain 11m 21s) Loss: 0.0012(0.0034) Grad: 815.5895  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 17m 53s (remain 10m 18s) Loss: 0.0001(0.0034) Grad: 36.5413  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 18m 56s (remain 9m 15s) Loss: 0.0112(0.0035) Grad: 3241.0027  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 19m 59s (remain 8m 12s) Loss: 0.0005(0.0035) Grad: 472.8831  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 21m 2s (remain 7m 9s) Loss: 0.0445(0.0035) Grad: 26934.6523  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 22m 5s (remain 6m 5s) Loss: 0.0000(0.0035) Grad: 7.6006  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 23m 8s (remain 5m 2s) Loss: 0.0002(0.0035) Grad: 504.4583  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 24m 11s (remain 3m 59s) Loss: 0.0041(0.0036) Grad: 3236.6250  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 25m 14s (remain 2m 56s) Loss: 0.0001(0.0035) Grad: 227.4883  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 26m 17s (remain 1m 53s) Loss: 0.0005(0.0036) Grad: 1035.5656  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 27m 21s (remain 0m 50s) Loss: 0.0372(0.0036) Grad: 23678.2500  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2680/2681] Elapsed 28m 11s (remain 0m 0s) Loss: 0.0000(0.0035) Grad: 53.2582  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 43s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 19s) Loss: 0.0000(0.0171) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 45s) Loss: 0.0022(0.0196) \n",
      "EVAL: [300/894] Elapsed 1m 37s (remain 3m 12s) Loss: 0.0150(0.0207) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0537(0.0197) \n",
      "EVAL: [500/894] Elapsed 2m 42s (remain 2m 7s) Loss: 0.0130(0.0238) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0087(0.0262) \n",
      "EVAL: [700/894] Elapsed 3m 47s (remain 1m 2s) Loss: 0.0001(0.0265) \n",
      "EVAL: [800/894] Elapsed 4m 19s (remain 0m 30s) Loss: 0.0016(0.0258) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0000(0.0245) \n",
      "Epoch 2 - avg_train_loss: 0.0035  avg_val_loss: 0.0245  time: 1983s\n",
      "Epoch 2 - Score: 0.8824\n",
      "Epoch 2 - Save Best Score: 0.8824 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 0s (remain 42m 42s) Loss: 0.0002(0.0002) Grad: 109.8384  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 1m 4s (remain 27m 17s) Loss: 0.0008(0.0029) Grad: 737.4916  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 2m 7s (remain 26m 9s) Loss: 0.0005(0.0028) Grad: 309.4971  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 3m 10s (remain 25m 4s) Loss: 0.0006(0.0030) Grad: 399.4721  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 4m 13s (remain 24m 0s) Loss: 0.0052(0.0034) Grad: 2635.2759  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 5m 16s (remain 22m 56s) Loss: 0.0002(0.0036) Grad: 204.2128  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 6m 19s (remain 21m 53s) Loss: 0.0001(0.0035) Grad: 66.1801  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 7m 22s (remain 20m 50s) Loss: 0.0004(0.0039) Grad: 597.8340  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 8m 25s (remain 19m 47s) Loss: 0.0003(0.0038) Grad: 319.8338  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 9m 28s (remain 18m 43s) Loss: 0.0003(0.0037) Grad: 280.1931  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 10m 31s (remain 17m 40s) Loss: 0.0002(0.0035) Grad: 233.1025  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 11m 35s (remain 16m 37s) Loss: 0.0001(0.0035) Grad: 42.8803  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 12m 38s (remain 15m 34s) Loss: 0.0002(0.0034) Grad: 137.5429  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0000(0.0033) Grad: 68.2022  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 14m 44s (remain 13m 27s) Loss: 0.0003(0.0033) Grad: 206.5878  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 15m 47s (remain 12m 24s) Loss: 0.0007(0.0033) Grad: 671.2377  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 16m 50s (remain 11m 21s) Loss: 0.0007(0.0033) Grad: 399.3556  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 17m 53s (remain 10m 18s) Loss: 0.0123(0.0033) Grad: 3456.4631  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 18m 56s (remain 9m 15s) Loss: 0.0004(0.0035) Grad: 328.6389  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 19m 59s (remain 8m 12s) Loss: 0.0000(0.0034) Grad: 24.2479  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 21m 2s (remain 7m 9s) Loss: 0.0015(0.0035) Grad: 632.2169  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0047(0.0034) Grad: 4531.7729  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 23m 9s (remain 5m 2s) Loss: 0.0053(0.0034) Grad: 5854.0776  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 24m 12s (remain 3m 59s) Loss: 0.0000(0.0035) Grad: 87.7109  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 25m 15s (remain 2m 56s) Loss: 0.0005(0.0035) Grad: 964.7691  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 26m 18s (remain 1m 53s) Loss: 0.0002(0.0035) Grad: 453.7486  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 27m 21s (remain 0m 50s) Loss: 0.0036(0.0034) Grad: 3329.6404  LR: 0.000009  \n",
      "Epoch: [3][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0001(0.0034) Grad: 171.3602  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 47s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/894] Elapsed 0m 32s (remain 4m 18s) Loss: 0.0000(0.0163) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 45s) Loss: 0.0024(0.0184) \n",
      "EVAL: [300/894] Elapsed 1m 37s (remain 3m 12s) Loss: 0.0145(0.0194) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 39s) Loss: 0.0494(0.0185) \n",
      "EVAL: [500/894] Elapsed 2m 42s (remain 2m 7s) Loss: 0.0106(0.0223) \n",
      "EVAL: [600/894] Elapsed 3m 14s (remain 1m 35s) Loss: 0.0083(0.0247) \n",
      "EVAL: [700/894] Elapsed 3m 47s (remain 1m 2s) Loss: 0.0001(0.0250) \n",
      "EVAL: [800/894] Elapsed 4m 19s (remain 0m 30s) Loss: 0.0014(0.0243) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 49s (remain 0m 0s) Loss: 0.0000(0.0232) \n",
      "Epoch 3 - avg_train_loss: 0.0034  avg_val_loss: 0.0232  time: 1984s\n",
      "Epoch 3 - Score: 0.8835\n",
      "Epoch 3 - Save Best Score: 0.8835 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 0s (remain 43m 23s) Loss: 0.0000(0.0000) Grad: 36.9130  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 1m 4s (remain 27m 16s) Loss: 0.0000(0.0025) Grad: 16.8867  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 2m 7s (remain 26m 8s) Loss: 0.0081(0.0028) Grad: 1915.0236  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 3m 10s (remain 25m 4s) Loss: 0.0016(0.0033) Grad: 435.2961  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 4m 13s (remain 24m 0s) Loss: 0.0043(0.0032) Grad: 1731.4443  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 5m 16s (remain 22m 56s) Loss: 0.0055(0.0032) Grad: 2495.4966  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 6m 19s (remain 21m 53s) Loss: 0.0004(0.0031) Grad: 434.3258  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 7m 22s (remain 20m 49s) Loss: 0.0001(0.0034) Grad: 158.1666  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 8m 25s (remain 19m 46s) Loss: 0.0000(0.0034) Grad: 19.7404  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 9m 28s (remain 18m 43s) Loss: 0.0000(0.0033) Grad: 32.8470  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 10m 31s (remain 17m 40s) Loss: 0.0000(0.0034) Grad: 24.6589  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 11m 34s (remain 16m 37s) Loss: 0.0013(0.0034) Grad: 1288.5253  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 12m 37s (remain 15m 33s) Loss: 0.0000(0.0034) Grad: 31.6463  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 13m 40s (remain 14m 30s) Loss: 0.0014(0.0033) Grad: 1101.4249  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 14m 43s (remain 13m 27s) Loss: 0.0001(0.0032) Grad: 74.3587  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 15m 47s (remain 12m 24s) Loss: 0.0001(0.0032) Grad: 69.0303  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 16m 50s (remain 11m 21s) Loss: 0.0001(0.0032) Grad: 61.4411  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 17m 53s (remain 10m 18s) Loss: 0.0001(0.0033) Grad: 65.5557  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 18m 56s (remain 9m 15s) Loss: 0.0000(0.0033) Grad: 18.9880  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 19m 59s (remain 8m 12s) Loss: 0.0067(0.0033) Grad: 1641.1128  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 21m 2s (remain 7m 8s) Loss: 0.0000(0.0033) Grad: 78.3714  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 22m 5s (remain 6m 5s) Loss: 0.0000(0.0032) Grad: 14.2580  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 23m 8s (remain 5m 2s) Loss: 0.0016(0.0033) Grad: 1866.2163  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 24m 11s (remain 3m 59s) Loss: 0.0000(0.0033) Grad: 65.7736  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 25m 14s (remain 2m 56s) Loss: 0.0048(0.0033) Grad: 4407.3579  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 26m 17s (remain 1m 53s) Loss: 0.0002(0.0033) Grad: 811.4301  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 27m 20s (remain 0m 50s) Loss: 0.0001(0.0034) Grad: 146.1232  LR: 0.000005  \n",
      "Epoch: [4][2680/2681] Elapsed 28m 11s (remain 0m 0s) Loss: 0.0000(0.0033) Grad: 23.8364  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 22s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/894] Elapsed 0m 32s (remain 4m 18s) Loss: 0.0000(0.0164) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 45s) Loss: 0.0025(0.0189) \n",
      "EVAL: [300/894] Elapsed 1m 37s (remain 3m 12s) Loss: 0.0146(0.0201) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0503(0.0192) \n",
      "EVAL: [500/894] Elapsed 2m 42s (remain 2m 7s) Loss: 0.0109(0.0232) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0075(0.0257) \n",
      "EVAL: [700/894] Elapsed 3m 47s (remain 1m 2s) Loss: 0.0000(0.0260) \n",
      "EVAL: [800/894] Elapsed 4m 19s (remain 0m 30s) Loss: 0.0018(0.0253) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0000(0.0242) \n",
      "Epoch 4 - avg_train_loss: 0.0033  avg_val_loss: 0.0242  time: 1983s\n",
      "Epoch 4 - Score: 0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 0s (remain 40m 36s) Loss: 0.0002(0.0002) Grad: 191.7501  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 1m 3s (remain 27m 14s) Loss: 0.0000(0.0047) Grad: 28.4498  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 2m 7s (remain 26m 7s) Loss: 0.0000(0.0043) Grad: 13.0859  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 3m 10s (remain 25m 3s) Loss: 0.0001(0.0042) Grad: 151.8632  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 4m 13s (remain 23m 59s) Loss: 0.0000(0.0041) Grad: 15.6246  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 5m 16s (remain 22m 56s) Loss: 0.0004(0.0038) Grad: 335.6844  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 6m 19s (remain 21m 52s) Loss: 0.0004(0.0035) Grad: 938.1263  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 7m 22s (remain 20m 49s) Loss: 0.0001(0.0034) Grad: 166.6261  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 8m 25s (remain 19m 46s) Loss: 0.0009(0.0032) Grad: 590.3839  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 9m 28s (remain 18m 43s) Loss: 0.0001(0.0036) Grad: 87.1128  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 10m 31s (remain 17m 40s) Loss: 0.0001(0.0035) Grad: 39.5634  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 11m 34s (remain 16m 36s) Loss: 0.0000(0.0034) Grad: 12.8139  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 12m 37s (remain 15m 33s) Loss: 0.0000(0.0034) Grad: 20.5520  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 13m 40s (remain 14m 30s) Loss: 0.0101(0.0034) Grad: 4297.5645  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 14m 44s (remain 13m 27s) Loss: 0.0000(0.0033) Grad: 11.4242  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 15m 47s (remain 12m 24s) Loss: 0.0023(0.0034) Grad: 1178.2911  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 16m 50s (remain 11m 21s) Loss: 0.0000(0.0034) Grad: 11.4944  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 17m 53s (remain 10m 18s) Loss: 0.0131(0.0034) Grad: 3181.2749  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0000(0.0035) Grad: 24.6689  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0001(0.0035) Grad: 77.7514  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0001(0.0035) Grad: 142.7133  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0000(0.0034) Grad: 61.2678  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 23m 9s (remain 5m 3s) Loss: 0.0033(0.0034) Grad: 4688.0254  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 24m 12s (remain 3m 59s) Loss: 0.0354(0.0033) Grad: 30453.3105  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 25m 15s (remain 2m 56s) Loss: 0.0002(0.0034) Grad: 252.7388  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 26m 18s (remain 1m 53s) Loss: 0.0000(0.0034) Grad: 30.7475  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0001(0.0034) Grad: 350.7735  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0009(0.0033) Grad: 2211.1179  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 8m 27s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 19s) Loss: 0.0000(0.0158) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 46s) Loss: 0.0025(0.0181) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0147(0.0192) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0485(0.0183) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0097(0.0221) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0075(0.0245) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0001(0.0248) \n",
      "EVAL: [800/894] Elapsed 4m 20s (remain 0m 30s) Loss: 0.0016(0.0242) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0000(0.0231) \n",
      "Epoch 5 - avg_train_loss: 0.0033  avg_val_loss: 0.0231  time: 1985s\n",
      "Epoch 5 - Score: 0.8833\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp066/fold1_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2681] Elapsed 0m 1s (remain 52m 12s) Loss: 0.6821(0.6821) Grad: 55009.8164  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 1m 4s (remain 27m 23s) Loss: 0.6377(0.6677) Grad: 53870.3477  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 2m 7s (remain 26m 12s) Loss: 0.4821(0.6194) Grad: 57921.1094  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.1812(0.5236) Grad: 47428.1016  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 4m 13s (remain 24m 2s) Loss: 0.0286(0.4132) Grad: 7014.2153  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 5m 16s (remain 22m 58s) Loss: 0.0079(0.3347) Grad: 1353.7759  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 6m 20s (remain 21m 55s) Loss: 0.0035(0.2809) Grad: 574.4606  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 7m 23s (remain 20m 51s) Loss: 0.0080(0.2420) Grad: 934.3875  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 8m 26s (remain 19m 48s) Loss: 0.0026(0.2130) Grad: 560.3124  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 9m 29s (remain 18m 45s) Loss: 0.0216(0.1907) Grad: 2205.2256  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0095(0.1725) Grad: 1273.5709  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 11m 35s (remain 16m 38s) Loss: 0.0150(0.1577) Grad: 3325.3291  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 12m 38s (remain 15m 35s) Loss: 0.0063(0.1451) Grad: 1913.4390  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0075(0.1344) Grad: 1637.2754  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 14m 45s (remain 13m 28s) Loss: 0.0076(0.1253) Grad: 1250.5486  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0018(0.1176) Grad: 610.5401  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0041(0.1106) Grad: 895.8466  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 17m 54s (remain 10m 19s) Loss: 0.0006(0.1046) Grad: 395.4868  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0295(0.0991) Grad: 7491.9360  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0067(0.0942) Grad: 895.0821  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0256(0.0898) Grad: 10289.8613  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0009(0.0858) Grad: 607.4300  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 23m 10s (remain 5m 3s) Loss: 0.0008(0.0822) Grad: 484.3894  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 24m 13s (remain 3m 59s) Loss: 0.0027(0.0789) Grad: 3275.1226  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0044(0.0759) Grad: 2865.0659  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0003(0.0731) Grad: 233.5649  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0049(0.0706) Grad: 2314.3074  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0039(0.0687) Grad: 1556.4785  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 37s) Loss: 0.0199(0.0199) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0105(0.0145) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 46s) Loss: 0.0718(0.0241) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0383(0.0251) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0004(0.0229) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0263(0.0235) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0144(0.0237) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0002(0.0221) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0607(0.0214) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0122(0.0198) \n",
      "Epoch 1 - avg_train_loss: 0.0687  avg_val_loss: 0.0198  time: 1986s\n",
      "Epoch 1 - Score: 0.8780\n",
      "Epoch 1 - Save Best Score: 0.8780 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 1s (remain 50m 34s) Loss: 0.0014(0.0014) Grad: 606.6125  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 1m 4s (remain 27m 21s) Loss: 0.0001(0.0077) Grad: 85.1166  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 2m 7s (remain 26m 12s) Loss: 0.0031(0.0071) Grad: 1478.6708  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 3m 10s (remain 25m 6s) Loss: 0.0001(0.0065) Grad: 52.7685  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 4m 13s (remain 24m 2s) Loss: 0.0397(0.0069) Grad: 9213.5947  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 5m 16s (remain 22m 58s) Loss: 0.0054(0.0066) Grad: 1303.5679  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 6m 19s (remain 21m 54s) Loss: 0.0018(0.0063) Grad: 692.8738  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 7m 22s (remain 20m 51s) Loss: 0.0002(0.0064) Grad: 85.6409  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 8m 26s (remain 19m 47s) Loss: 0.0010(0.0064) Grad: 478.8583  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 9m 29s (remain 18m 44s) Loss: 0.0194(0.0062) Grad: 4050.4744  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0002(0.0062) Grad: 115.5532  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 11m 35s (remain 16m 37s) Loss: 0.0012(0.0062) Grad: 550.1560  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 12m 38s (remain 15m 34s) Loss: 0.0533(0.0064) Grad: 16258.1553  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0019(0.0065) Grad: 675.4739  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 14m 44s (remain 13m 28s) Loss: 0.0002(0.0064) Grad: 94.2505  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 15m 47s (remain 12m 25s) Loss: 0.0098(0.0063) Grad: 2657.4956  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0001(0.0063) Grad: 69.5193  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 17m 54s (remain 10m 18s) Loss: 0.0012(0.0062) Grad: 560.7323  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0228(0.0062) Grad: 7291.2935  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0006(0.0061) Grad: 210.2769  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0062(0.0061) Grad: 4321.6045  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0011(0.0061) Grad: 942.8590  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 23m 9s (remain 5m 3s) Loss: 0.0003(0.0062) Grad: 345.6515  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 24m 12s (remain 3m 59s) Loss: 0.0000(0.0061) Grad: 43.8178  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 25m 15s (remain 2m 56s) Loss: 0.0001(0.0062) Grad: 149.6393  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 26m 18s (remain 1m 53s) Loss: 0.0001(0.0062) Grad: 107.3484  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0004(0.0062) Grad: 480.9967  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0093(0.0062) Grad: 3270.8147  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 31s) Loss: 0.0235(0.0235) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0093(0.0157) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 46s) Loss: 0.0787(0.0270) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0502(0.0285) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0001(0.0258) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0367(0.0267) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0201(0.0271) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0000(0.0252) \n",
      "EVAL: [800/894] Elapsed 4m 20s (remain 0m 30s) Loss: 0.0729(0.0244) \n",
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0131(0.0225) \n",
      "Epoch 2 - avg_train_loss: 0.0062  avg_val_loss: 0.0225  time: 1986s\n",
      "Epoch 2 - Score: 0.8795\n",
      "Epoch 2 - Save Best Score: 0.8795 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 1s (remain 51m 13s) Loss: 0.0092(0.0092) Grad: 1721.4969  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 1m 4s (remain 27m 23s) Loss: 0.0015(0.0073) Grad: 1052.8585  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 2m 7s (remain 26m 13s) Loss: 0.0138(0.0068) Grad: 4112.2520  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.0000(0.0063) Grad: 42.6391  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 4m 13s (remain 24m 3s) Loss: 0.0000(0.0062) Grad: 35.8916  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 5m 16s (remain 22m 59s) Loss: 0.0002(0.0062) Grad: 165.2703  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 6m 20s (remain 21m 55s) Loss: 0.0003(0.0064) Grad: 358.2878  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 7m 23s (remain 20m 52s) Loss: 0.0001(0.0064) Grad: 71.4236  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 8m 26s (remain 19m 48s) Loss: 0.0094(0.0064) Grad: 3211.1172  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 9m 29s (remain 18m 45s) Loss: 0.0006(0.0063) Grad: 550.3937  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0003(0.0063) Grad: 233.3567  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 11m 35s (remain 16m 38s) Loss: 0.0235(0.0062) Grad: 7965.6318  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 12m 38s (remain 15m 35s) Loss: 0.0021(0.0061) Grad: 815.3467  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0269(0.0060) Grad: 3497.8501  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 14m 45s (remain 13m 28s) Loss: 0.0001(0.0061) Grad: 98.7758  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0165(0.0060) Grad: 4008.4409  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0015(0.0059) Grad: 554.7765  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 17m 54s (remain 10m 19s) Loss: 0.0002(0.0060) Grad: 482.8834  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0004(0.0059) Grad: 490.9110  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0003(0.0060) Grad: 179.9828  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0003(0.0060) Grad: 648.3099  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0002(0.0060) Grad: 423.4786  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 23m 10s (remain 5m 3s) Loss: 0.0000(0.0060) Grad: 60.4509  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 24m 13s (remain 3m 59s) Loss: 0.0011(0.0059) Grad: 1287.3578  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0007(0.0059) Grad: 831.8759  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0002(0.0059) Grad: 272.0384  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0004(0.0059) Grad: 416.8046  LR: 0.000009  \n",
      "Epoch: [3][2680/2681] Elapsed 28m 13s (remain 0m 0s) Loss: 0.0001(0.0059) Grad: 161.7724  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 41s) Loss: 0.0231(0.0231) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0066(0.0140) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 46s) Loss: 0.0662(0.0236) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0484(0.0248) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0001(0.0224) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0341(0.0234) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0157(0.0238) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0000(0.0222) \n",
      "EVAL: [800/894] Elapsed 4m 20s (remain 0m 30s) Loss: 0.0601(0.0215) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 50s (remain 0m 0s) Loss: 0.0125(0.0198) \n",
      "Epoch 3 - avg_train_loss: 0.0059  avg_val_loss: 0.0198  time: 1986s\n",
      "Epoch 3 - Score: 0.8817\n",
      "Epoch 3 - Save Best Score: 0.8817 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 1s (remain 50m 30s) Loss: 0.0074(0.0074) Grad: 2951.3618  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 1m 4s (remain 27m 23s) Loss: 0.0000(0.0067) Grad: 16.3995  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 2m 7s (remain 26m 13s) Loss: 0.0001(0.0070) Grad: 70.1462  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.0001(0.0066) Grad: 101.0886  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 4m 13s (remain 24m 3s) Loss: 0.0345(0.0061) Grad: 4745.8628  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 5m 17s (remain 22m 59s) Loss: 0.0022(0.0062) Grad: 777.3861  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 6m 20s (remain 21m 56s) Loss: 0.0001(0.0065) Grad: 161.8965  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 7m 23s (remain 20m 52s) Loss: 0.0000(0.0061) Grad: 31.0137  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 8m 26s (remain 19m 49s) Loss: 0.0014(0.0061) Grad: 782.1714  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 9m 29s (remain 18m 45s) Loss: 0.0027(0.0063) Grad: 1775.4785  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 10m 32s (remain 17m 42s) Loss: 0.0000(0.0061) Grad: 38.6069  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 11m 36s (remain 16m 39s) Loss: 0.0000(0.0060) Grad: 14.7664  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 12m 39s (remain 15m 35s) Loss: 0.0038(0.0061) Grad: 2203.7456  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 13m 42s (remain 14m 32s) Loss: 0.0011(0.0060) Grad: 674.1598  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 14m 45s (remain 13m 29s) Loss: 0.0115(0.0060) Grad: 4117.4966  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0039(0.0060) Grad: 2461.4766  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 16m 52s (remain 11m 22s) Loss: 0.0057(0.0060) Grad: 1241.4178  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 17m 55s (remain 10m 19s) Loss: 0.0031(0.0059) Grad: 1893.8174  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 18m 58s (remain 9m 16s) Loss: 0.0000(0.0058) Grad: 21.8011  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 20m 1s (remain 8m 13s) Loss: 0.0000(0.0058) Grad: 5.0183  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 21m 4s (remain 7m 9s) Loss: 0.0001(0.0058) Grad: 294.9811  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 22m 7s (remain 6m 6s) Loss: 0.0032(0.0058) Grad: 4380.7109  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 23m 11s (remain 5m 3s) Loss: 0.0000(0.0059) Grad: 40.4151  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 24m 14s (remain 4m 0s) Loss: 0.0001(0.0059) Grad: 136.4930  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 25m 17s (remain 2m 56s) Loss: 0.0190(0.0059) Grad: 8160.1265  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 26m 20s (remain 1m 53s) Loss: 0.0000(0.0059) Grad: 80.6425  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 27m 23s (remain 0m 50s) Loss: 0.0001(0.0059) Grad: 183.2500  LR: 0.000005  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2680/2681] Elapsed 28m 14s (remain 0m 0s) Loss: 0.0183(0.0059) Grad: 17305.7246  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 40s) Loss: 0.0245(0.0245) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 22s) Loss: 0.0053(0.0139) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0622(0.0229) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 14s) Loss: 0.0510(0.0241) \n",
      "EVAL: [400/894] Elapsed 2m 11s (remain 2m 41s) Loss: 0.0001(0.0218) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0349(0.0229) \n",
      "EVAL: [600/894] Elapsed 3m 16s (remain 1m 35s) Loss: 0.0144(0.0233) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 3s) Loss: 0.0000(0.0218) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0576(0.0210) \n",
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0129(0.0194) \n",
      "Epoch 4 - avg_train_loss: 0.0059  avg_val_loss: 0.0194  time: 1988s\n",
      "Epoch 4 - Score: 0.8822\n",
      "Epoch 4 - Save Best Score: 0.8822 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 1s (remain 51m 13s) Loss: 0.0014(0.0014) Grad: 888.1537  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 1m 4s (remain 27m 23s) Loss: 0.0027(0.0061) Grad: 1519.3555  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 2m 7s (remain 26m 13s) Loss: 0.0299(0.0058) Grad: 6733.7290  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.0002(0.0054) Grad: 396.6176  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 4m 13s (remain 24m 3s) Loss: 0.0001(0.0057) Grad: 42.3447  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 5m 17s (remain 22m 59s) Loss: 0.0003(0.0058) Grad: 298.6197  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 6m 20s (remain 21m 55s) Loss: 0.0054(0.0061) Grad: 2146.9014  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 7m 23s (remain 20m 52s) Loss: 0.0001(0.0060) Grad: 118.7149  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 8m 26s (remain 19m 49s) Loss: 0.0024(0.0059) Grad: 705.7523  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 9m 29s (remain 18m 45s) Loss: 0.0063(0.0059) Grad: 2906.1133  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 10m 32s (remain 17m 42s) Loss: 0.0001(0.0058) Grad: 46.9053  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 11m 36s (remain 16m 39s) Loss: 0.0006(0.0058) Grad: 452.2343  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 12m 39s (remain 15m 35s) Loss: 0.0001(0.0058) Grad: 64.7435  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 13m 42s (remain 14m 32s) Loss: 0.0035(0.0058) Grad: 3172.7300  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 14m 45s (remain 13m 29s) Loss: 0.0223(0.0057) Grad: 5973.6582  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0003(0.0057) Grad: 273.5464  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 16m 52s (remain 11m 22s) Loss: 0.0030(0.0057) Grad: 1592.0840  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 17m 55s (remain 10m 19s) Loss: 0.0065(0.0058) Grad: 3008.5042  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 18m 58s (remain 9m 16s) Loss: 0.0163(0.0058) Grad: 7208.1489  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 20m 1s (remain 8m 13s) Loss: 0.0001(0.0058) Grad: 61.8632  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 21m 4s (remain 7m 9s) Loss: 0.0016(0.0057) Grad: 3414.3450  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 22m 8s (remain 6m 6s) Loss: 0.0004(0.0057) Grad: 415.4761  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 23m 11s (remain 5m 3s) Loss: 0.0001(0.0057) Grad: 212.2930  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 24m 14s (remain 4m 0s) Loss: 0.0000(0.0056) Grad: 45.1129  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 25m 17s (remain 2m 56s) Loss: 0.0001(0.0057) Grad: 102.5101  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 26m 20s (remain 1m 53s) Loss: 0.0072(0.0057) Grad: 9945.8955  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 27m 24s (remain 0m 50s) Loss: 0.0001(0.0057) Grad: 217.6983  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][2680/2681] Elapsed 28m 14s (remain 0m 0s) Loss: 0.0016(0.0057) Grad: 2283.4485  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 28s) Loss: 0.0243(0.0243) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0057(0.0144) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0686(0.0242) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0515(0.0256) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0001(0.0232) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0393(0.0242) \n",
      "EVAL: [600/894] Elapsed 3m 16s (remain 1m 35s) Loss: 0.0168(0.0246) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0000(0.0230) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0653(0.0222) \n",
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0130(0.0205) \n",
      "Epoch 5 - avg_train_loss: 0.0057  avg_val_loss: 0.0205  time: 1988s\n",
      "Epoch 5 - Score: 0.8816\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp066/fold2_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2681] Elapsed 0m 1s (remain 51m 24s) Loss: 0.7173(0.7173) Grad: 54956.4492  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 1m 4s (remain 27m 20s) Loss: 0.6746(0.7032) Grad: 54148.2070  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 2m 7s (remain 26m 11s) Loss: 0.5225(0.6576) Grad: 58934.8828  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 3m 10s (remain 25m 6s) Loss: 0.2048(0.5631) Grad: 52431.2227  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 4m 13s (remain 24m 2s) Loss: 0.0249(0.4457) Grad: 7687.8608  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 5m 16s (remain 22m 58s) Loss: 0.0204(0.3602) Grad: 1833.6693  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 6m 19s (remain 21m 54s) Loss: 0.0074(0.3019) Grad: 1257.7811  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 7m 23s (remain 20m 51s) Loss: 0.0209(0.2599) Grad: 2816.8013  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 8m 26s (remain 19m 48s) Loss: 0.0136(0.2285) Grad: 4161.6362  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 9m 29s (remain 18m 44s) Loss: 0.0022(0.2040) Grad: 481.4867  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0013(0.1843) Grad: 257.6485  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 11m 35s (remain 16m 38s) Loss: 0.0033(0.1681) Grad: 544.4966  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 12m 38s (remain 15m 34s) Loss: 0.0019(0.1548) Grad: 461.6330  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0033(0.1434) Grad: 271.3703  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 14m 44s (remain 13m 28s) Loss: 0.0104(0.1336) Grad: 2006.0432  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 15m 47s (remain 12m 25s) Loss: 0.0003(0.1250) Grad: 111.7618  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0108(0.1176) Grad: 2661.4070  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 17m 54s (remain 10m 18s) Loss: 0.0009(0.1110) Grad: 271.1160  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0004(0.1051) Grad: 153.9507  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0019(0.0997) Grad: 854.5206  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0009(0.0951) Grad: 736.9203  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0005(0.0908) Grad: 571.2308  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 23m 9s (remain 5m 3s) Loss: 0.0137(0.0869) Grad: 6398.9873  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 24m 12s (remain 3m 59s) Loss: 0.0007(0.0833) Grad: 704.0878  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 25m 15s (remain 2m 56s) Loss: 0.0005(0.0800) Grad: 400.2627  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 26m 18s (remain 1m 53s) Loss: 0.0155(0.0770) Grad: 5697.6221  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 27m 21s (remain 0m 50s) Loss: 0.0689(0.0742) Grad: 37648.3008  LR: 0.000018  \n",
      "Epoch: [1][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0005(0.0722) Grad: 318.3269  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 54s) Loss: 0.0017(0.0017) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0003(0.0195) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 46s) Loss: 0.0035(0.0172) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0003(0.0184) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0001(0.0165) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0036(0.0178) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0000(0.0188) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.1022(0.0198) \n",
      "EVAL: [800/894] Elapsed 4m 20s (remain 0m 30s) Loss: 0.0026(0.0193) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0001(0.0181) \n",
      "Epoch 1 - avg_train_loss: 0.0722  avg_val_loss: 0.0181  time: 1986s\n",
      "Epoch 1 - Score: 0.8862\n",
      "Epoch 1 - Save Best Score: 0.8862 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 1s (remain 52m 25s) Loss: 0.0004(0.0004) Grad: 186.0639  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 1m 4s (remain 27m 23s) Loss: 0.0070(0.0048) Grad: 2853.3518  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 2m 7s (remain 26m 12s) Loss: 0.0002(0.0052) Grad: 126.7569  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 3m 10s (remain 25m 6s) Loss: 0.0000(0.0048) Grad: 46.2562  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 4m 13s (remain 24m 2s) Loss: 0.0001(0.0051) Grad: 69.8260  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 5m 16s (remain 22m 58s) Loss: 0.0004(0.0052) Grad: 152.5297  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 6m 19s (remain 21m 54s) Loss: 0.0244(0.0050) Grad: 6481.2188  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 7m 23s (remain 20m 51s) Loss: 0.0109(0.0050) Grad: 3548.2593  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 8m 26s (remain 19m 47s) Loss: 0.0004(0.0048) Grad: 176.9986  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 9m 29s (remain 18m 44s) Loss: 0.0000(0.0046) Grad: 33.4919  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0001(0.0047) Grad: 32.2275  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 11m 35s (remain 16m 38s) Loss: 0.0000(0.0046) Grad: 24.0858  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 12m 38s (remain 15m 35s) Loss: 0.0003(0.0048) Grad: 194.3862  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0004(0.0047) Grad: 163.3259  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 14m 45s (remain 13m 28s) Loss: 0.0011(0.0047) Grad: 535.6127  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0083(0.0047) Grad: 2957.3140  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0007(0.0046) Grad: 384.9328  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 17m 54s (remain 10m 18s) Loss: 0.0080(0.0046) Grad: 2743.4670  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0034(0.0046) Grad: 1383.3197  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0000(0.0046) Grad: 28.7346  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0029(0.0046) Grad: 1826.9728  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0008(0.0046) Grad: 825.9738  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 23m 10s (remain 5m 3s) Loss: 0.0006(0.0046) Grad: 719.4374  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 24m 13s (remain 3m 59s) Loss: 0.0026(0.0045) Grad: 2215.1990  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0043(0.0046) Grad: 2227.4041  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0001(0.0046) Grad: 128.8860  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0008(0.0046) Grad: 1299.8218  LR: 0.000013  \n",
      "Epoch: [2][2680/2681] Elapsed 28m 13s (remain 0m 0s) Loss: 0.0065(0.0047) Grad: 3346.5537  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 59s) Loss: 0.0012(0.0012) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0001(0.0195) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 46s) Loss: 0.0029(0.0173) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0002(0.0185) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0000(0.0166) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0028(0.0178) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0000(0.0188) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.1046(0.0199) \n",
      "EVAL: [800/894] Elapsed 4m 20s (remain 0m 30s) Loss: 0.0029(0.0194) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0001(0.0182) \n",
      "Epoch 2 - avg_train_loss: 0.0047  avg_val_loss: 0.0182  time: 1986s\n",
      "Epoch 2 - Score: 0.8877\n",
      "Epoch 2 - Save Best Score: 0.8877 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 1s (remain 51m 52s) Loss: 0.0021(0.0021) Grad: 1240.9869  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 1m 4s (remain 27m 21s) Loss: 0.0000(0.0030) Grad: 65.6331  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 2m 7s (remain 26m 11s) Loss: 0.0001(0.0035) Grad: 83.8684  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 3m 10s (remain 25m 6s) Loss: 0.0034(0.0040) Grad: 1545.6168  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 4m 13s (remain 24m 1s) Loss: 0.0000(0.0039) Grad: 38.4622  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 5m 16s (remain 22m 57s) Loss: 0.0013(0.0039) Grad: 365.9211  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 6m 19s (remain 21m 54s) Loss: 0.0212(0.0041) Grad: 4587.3901  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 7m 22s (remain 20m 50s) Loss: 0.0099(0.0045) Grad: 3879.4707  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 8m 26s (remain 19m 47s) Loss: 0.0001(0.0046) Grad: 102.5259  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 9m 29s (remain 18m 44s) Loss: 0.0013(0.0047) Grad: 554.4148  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0007(0.0048) Grad: 402.5878  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 11m 35s (remain 16m 37s) Loss: 0.0188(0.0048) Grad: 4940.8491  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 12m 38s (remain 15m 34s) Loss: 0.0332(0.0048) Grad: 10772.5420  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0006(0.0048) Grad: 216.0736  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 14m 44s (remain 13m 28s) Loss: 0.0013(0.0047) Grad: 905.9605  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 15m 47s (remain 12m 25s) Loss: 0.0002(0.0046) Grad: 136.8479  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0000(0.0047) Grad: 29.6736  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 17m 54s (remain 10m 18s) Loss: 0.0001(0.0047) Grad: 74.7066  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0000(0.0046) Grad: 14.3345  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0009(0.0046) Grad: 631.7391  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0000(0.0045) Grad: 28.1930  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0012(0.0045) Grad: 1322.1343  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 23m 9s (remain 5m 3s) Loss: 0.0000(0.0045) Grad: 91.8535  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 24m 12s (remain 3m 59s) Loss: 0.0188(0.0046) Grad: 10043.9307  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0398(0.0047) Grad: 17630.9863  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0018(0.0047) Grad: 2485.1584  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0002(0.0046) Grad: 549.1208  LR: 0.000009  \n",
      "Epoch: [3][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0000(0.0046) Grad: 53.2823  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 12m 2s) Loss: 0.0010(0.0010) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0001(0.0205) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 46s) Loss: 0.0032(0.0182) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0001(0.0197) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0000(0.0176) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0022(0.0189) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0000(0.0199) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.1084(0.0211) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0036(0.0206) \n",
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0000(0.0194) \n",
      "Epoch 3 - avg_train_loss: 0.0046  avg_val_loss: 0.0194  time: 1986s\n",
      "Epoch 3 - Score: 0.8881\n",
      "Epoch 3 - Save Best Score: 0.8881 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 1s (remain 52m 25s) Loss: 0.0096(0.0096) Grad: 3180.8752  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 1m 4s (remain 27m 23s) Loss: 0.0009(0.0028) Grad: 486.4574  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 2m 7s (remain 26m 13s) Loss: 0.0200(0.0041) Grad: 6091.1392  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 3m 10s (remain 25m 8s) Loss: 0.0008(0.0040) Grad: 505.4217  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 4m 13s (remain 24m 3s) Loss: 0.0088(0.0042) Grad: 3200.5654  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 5m 17s (remain 22m 59s) Loss: 0.0000(0.0041) Grad: 60.3278  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 6m 20s (remain 21m 56s) Loss: 0.0002(0.0044) Grad: 144.9449  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 7m 23s (remain 20m 52s) Loss: 0.0005(0.0043) Grad: 341.0161  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 8m 26s (remain 19m 49s) Loss: 0.0001(0.0042) Grad: 144.4004  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 9m 29s (remain 18m 45s) Loss: 0.0009(0.0041) Grad: 833.3759  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 10m 33s (remain 17m 42s) Loss: 0.0234(0.0041) Grad: 7986.4170  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 11m 36s (remain 16m 39s) Loss: 0.0004(0.0040) Grad: 406.8702  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 12m 39s (remain 15m 35s) Loss: 0.0001(0.0040) Grad: 160.9014  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 13m 42s (remain 14m 32s) Loss: 0.0001(0.0041) Grad: 63.6274  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 14m 45s (remain 13m 29s) Loss: 0.0015(0.0041) Grad: 874.5695  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0213(0.0042) Grad: 6518.1357  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 16m 52s (remain 11m 22s) Loss: 0.0006(0.0042) Grad: 406.1591  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 17m 55s (remain 10m 19s) Loss: 0.0011(0.0043) Grad: 602.1980  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 18m 58s (remain 9m 16s) Loss: 0.0269(0.0042) Grad: 3741.9163  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 20m 1s (remain 8m 13s) Loss: 0.0006(0.0043) Grad: 551.1014  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 21m 4s (remain 7m 9s) Loss: 0.0001(0.0043) Grad: 174.4794  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 22m 8s (remain 6m 6s) Loss: 0.0001(0.0043) Grad: 168.1872  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 23m 11s (remain 5m 3s) Loss: 0.0001(0.0042) Grad: 544.5795  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 24m 14s (remain 4m 0s) Loss: 0.0001(0.0043) Grad: 144.1642  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 25m 17s (remain 2m 56s) Loss: 0.0044(0.0042) Grad: 3158.1909  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 26m 20s (remain 1m 53s) Loss: 0.0198(0.0043) Grad: 6679.8765  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 27m 24s (remain 0m 50s) Loss: 0.0052(0.0043) Grad: 4696.2827  LR: 0.000005  \n",
      "Epoch: [4][2680/2681] Elapsed 28m 14s (remain 0m 0s) Loss: 0.0199(0.0044) Grad: 10756.7158  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 58s) Loss: 0.0010(0.0010) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0001(0.0203) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0033(0.0180) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 14s) Loss: 0.0002(0.0195) \n",
      "EVAL: [400/894] Elapsed 2m 11s (remain 2m 41s) Loss: 0.0000(0.0175) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0021(0.0188) \n",
      "EVAL: [600/894] Elapsed 3m 16s (remain 1m 35s) Loss: 0.0000(0.0198) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.1117(0.0210) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0035(0.0205) \n",
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0000(0.0193) \n",
      "Epoch 4 - avg_train_loss: 0.0044  avg_val_loss: 0.0193  time: 1988s\n",
      "Epoch 4 - Score: 0.8876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 1s (remain 52m 27s) Loss: 0.0001(0.0001) Grad: 44.5397  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 1m 4s (remain 27m 25s) Loss: 0.0105(0.0046) Grad: 4741.7988  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 2m 7s (remain 26m 13s) Loss: 0.0053(0.0039) Grad: 2232.1726  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.0007(0.0042) Grad: 719.7734  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 4m 13s (remain 24m 3s) Loss: 0.0004(0.0048) Grad: 617.2029  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 5m 17s (remain 22m 59s) Loss: 0.0087(0.0047) Grad: 3688.8933  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 6m 20s (remain 21m 55s) Loss: 0.0383(0.0048) Grad: 7587.3511  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 7m 23s (remain 20m 52s) Loss: 0.0091(0.0046) Grad: 4943.7700  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 8m 26s (remain 19m 48s) Loss: 0.0004(0.0044) Grad: 454.5786  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 9m 29s (remain 18m 45s) Loss: 0.0002(0.0045) Grad: 317.6691  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0000(0.0045) Grad: 92.3631  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 11m 35s (remain 16m 38s) Loss: 0.0003(0.0045) Grad: 260.5174  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 12m 39s (remain 15m 35s) Loss: 0.0494(0.0045) Grad: 10492.6895  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 13m 42s (remain 14m 32s) Loss: 0.0022(0.0045) Grad: 857.1214  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 14m 45s (remain 13m 28s) Loss: 0.0138(0.0045) Grad: 6667.8613  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0008(0.0046) Grad: 784.1184  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0003(0.0046) Grad: 347.8777  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 17m 54s (remain 10m 19s) Loss: 0.0002(0.0046) Grad: 271.3598  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 18m 57s (remain 9m 16s) Loss: 0.0006(0.0046) Grad: 698.2736  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 20m 1s (remain 8m 12s) Loss: 0.0035(0.0045) Grad: 1829.6686  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 21m 4s (remain 7m 9s) Loss: 0.0066(0.0045) Grad: 8984.7676  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 22m 7s (remain 6m 6s) Loss: 0.0013(0.0045) Grad: 1454.7913  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 23m 10s (remain 5m 3s) Loss: 0.0000(0.0045) Grad: 3.0511  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 24m 13s (remain 4m 0s) Loss: 0.0069(0.0045) Grad: 5341.5073  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0006(0.0045) Grad: 832.1214  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0192(0.0045) Grad: 10022.4668  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 27m 23s (remain 0m 50s) Loss: 0.0105(0.0044) Grad: 9669.7861  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][2680/2681] Elapsed 28m 13s (remain 0m 0s) Loss: 0.0003(0.0043) Grad: 731.5002  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 12m 6s) Loss: 0.0010(0.0010) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0001(0.0203) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0031(0.0180) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0001(0.0195) \n",
      "EVAL: [400/894] Elapsed 2m 11s (remain 2m 41s) Loss: 0.0000(0.0174) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0018(0.0187) \n",
      "EVAL: [600/894] Elapsed 3m 16s (remain 1m 35s) Loss: 0.0000(0.0197) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.1073(0.0210) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0034(0.0205) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0000(0.0193) \n",
      "Epoch 5 - avg_train_loss: 0.0043  avg_val_loss: 0.0193  time: 1987s\n",
      "Epoch 5 - Score: 0.8876\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xlarge and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp045/microsoft-deberta-xlarge-mlm-epoch-v4.bin\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp066/fold3_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2681] Elapsed 0m 1s (remain 53m 18s) Loss: 0.7141(0.7141) Grad: 55104.5938  LR: 0.000000  \n",
      "Epoch: [1][100/2681] Elapsed 1m 4s (remain 27m 22s) Loss: 0.6717(0.7004) Grad: 52545.5469  LR: 0.000002  \n",
      "Epoch: [1][200/2681] Elapsed 2m 7s (remain 26m 12s) Loss: 0.5214(0.6542) Grad: 58449.2422  LR: 0.000003  \n",
      "Epoch: [1][300/2681] Elapsed 3m 10s (remain 25m 6s) Loss: 0.2022(0.5592) Grad: 53201.7812  LR: 0.000004  \n",
      "Epoch: [1][400/2681] Elapsed 4m 13s (remain 24m 2s) Loss: 0.0278(0.4425) Grad: 7518.7617  LR: 0.000006  \n",
      "Epoch: [1][500/2681] Elapsed 5m 16s (remain 22m 58s) Loss: 0.0088(0.3577) Grad: 1086.3611  LR: 0.000007  \n",
      "Epoch: [1][600/2681] Elapsed 6m 19s (remain 21m 54s) Loss: 0.0269(0.3000) Grad: 1419.2355  LR: 0.000009  \n",
      "Epoch: [1][700/2681] Elapsed 7m 22s (remain 20m 51s) Loss: 0.0057(0.2584) Grad: 974.1198  LR: 0.000010  \n",
      "Epoch: [1][800/2681] Elapsed 8m 26s (remain 19m 47s) Loss: 0.0019(0.2272) Grad: 468.8759  LR: 0.000012  \n",
      "Epoch: [1][900/2681] Elapsed 9m 29s (remain 18m 44s) Loss: 0.0011(0.2028) Grad: 285.7745  LR: 0.000013  \n",
      "Epoch: [1][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0035(0.1835) Grad: 833.8464  LR: 0.000015  \n",
      "Epoch: [1][1100/2681] Elapsed 11m 35s (remain 16m 37s) Loss: 0.0024(0.1673) Grad: 406.6422  LR: 0.000016  \n",
      "Epoch: [1][1200/2681] Elapsed 12m 38s (remain 15m 34s) Loss: 0.0021(0.1540) Grad: 702.7490  LR: 0.000018  \n",
      "Epoch: [1][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0019(0.1427) Grad: 455.3439  LR: 0.000019  \n",
      "Epoch: [1][1400/2681] Elapsed 14m 44s (remain 13m 28s) Loss: 0.0015(0.1329) Grad: 599.2297  LR: 0.000020  \n",
      "Epoch: [1][1500/2681] Elapsed 15m 47s (remain 12m 25s) Loss: 0.0116(0.1245) Grad: 2182.5574  LR: 0.000020  \n",
      "Epoch: [1][1600/2681] Elapsed 16m 50s (remain 11m 21s) Loss: 0.0058(0.1170) Grad: 2075.0247  LR: 0.000020  \n",
      "Epoch: [1][1700/2681] Elapsed 17m 54s (remain 10m 18s) Loss: 0.0015(0.1105) Grad: 764.8910  LR: 0.000019  \n",
      "Epoch: [1][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0018(0.1047) Grad: 538.3041  LR: 0.000019  \n",
      "Epoch: [1][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0015(0.0995) Grad: 535.3778  LR: 0.000019  \n",
      "Epoch: [1][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0008(0.0947) Grad: 1088.0999  LR: 0.000019  \n",
      "Epoch: [1][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0003(0.0905) Grad: 201.4153  LR: 0.000019  \n",
      "Epoch: [1][2200/2681] Elapsed 23m 9s (remain 5m 3s) Loss: 0.0042(0.0866) Grad: 2014.2268  LR: 0.000019  \n",
      "Epoch: [1][2300/2681] Elapsed 24m 13s (remain 3m 59s) Loss: 0.0083(0.0830) Grad: 5469.7202  LR: 0.000018  \n",
      "Epoch: [1][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0004(0.0798) Grad: 499.0516  LR: 0.000018  \n",
      "Epoch: [1][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0030(0.0768) Grad: 1783.5181  LR: 0.000018  \n",
      "Epoch: [1][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0253(0.0740) Grad: 9480.5684  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0003(0.0719) Grad: 386.3389  LR: 0.000018  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 12m 24s) Loss: 0.0057(0.0057) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0004(0.0144) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0646(0.0170) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0442(0.0166) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0222(0.0158) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0179(0.0182) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0255(0.0186) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0204(0.0186) \n",
      "EVAL: [800/894] Elapsed 4m 20s (remain 0m 30s) Loss: 0.0016(0.0182) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0002(0.0173) \n",
      "Epoch 1 - avg_train_loss: 0.0719  avg_val_loss: 0.0173  time: 1986s\n",
      "Epoch 1 - Score: 0.8853\n",
      "Epoch 1 - Save Best Score: 0.8853 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2681] Elapsed 0m 1s (remain 52m 2s) Loss: 0.0001(0.0001) Grad: 41.7841  LR: 0.000018  \n",
      "Epoch: [2][100/2681] Elapsed 1m 4s (remain 27m 24s) Loss: 0.0007(0.0058) Grad: 399.2690  LR: 0.000018  \n",
      "Epoch: [2][200/2681] Elapsed 2m 7s (remain 26m 12s) Loss: 0.0077(0.0053) Grad: 2753.3420  LR: 0.000017  \n",
      "Epoch: [2][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.0084(0.0052) Grad: 2699.6711  LR: 0.000017  \n",
      "Epoch: [2][400/2681] Elapsed 4m 13s (remain 24m 2s) Loss: 0.0013(0.0053) Grad: 588.5737  LR: 0.000017  \n",
      "Epoch: [2][500/2681] Elapsed 5m 16s (remain 22m 58s) Loss: 0.0001(0.0049) Grad: 51.5795  LR: 0.000017  \n",
      "Epoch: [2][600/2681] Elapsed 6m 19s (remain 21m 54s) Loss: 0.0070(0.0047) Grad: 1872.7284  LR: 0.000017  \n",
      "Epoch: [2][700/2681] Elapsed 7m 23s (remain 20m 51s) Loss: 0.0065(0.0046) Grad: 1863.8700  LR: 0.000017  \n",
      "Epoch: [2][800/2681] Elapsed 8m 26s (remain 19m 47s) Loss: 0.0003(0.0046) Grad: 117.3682  LR: 0.000016  \n",
      "Epoch: [2][900/2681] Elapsed 9m 29s (remain 18m 44s) Loss: 0.0003(0.0047) Grad: 154.3731  LR: 0.000016  \n",
      "Epoch: [2][1000/2681] Elapsed 10m 32s (remain 17m 41s) Loss: 0.0130(0.0046) Grad: 2438.2595  LR: 0.000016  \n",
      "Epoch: [2][1100/2681] Elapsed 11m 35s (remain 16m 38s) Loss: 0.0001(0.0046) Grad: 32.4958  LR: 0.000016  \n",
      "Epoch: [2][1200/2681] Elapsed 12m 38s (remain 15m 34s) Loss: 0.0001(0.0047) Grad: 97.2435  LR: 0.000016  \n",
      "Epoch: [2][1300/2681] Elapsed 13m 41s (remain 14m 31s) Loss: 0.0002(0.0046) Grad: 110.8435  LR: 0.000016  \n",
      "Epoch: [2][1400/2681] Elapsed 14m 44s (remain 13m 28s) Loss: 0.0002(0.0047) Grad: 94.4696  LR: 0.000015  \n",
      "Epoch: [2][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0037(0.0047) Grad: 1350.9883  LR: 0.000015  \n",
      "Epoch: [2][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0011(0.0046) Grad: 761.9070  LR: 0.000015  \n",
      "Epoch: [2][1700/2681] Elapsed 17m 54s (remain 10m 18s) Loss: 0.0009(0.0047) Grad: 427.5804  LR: 0.000015  \n",
      "Epoch: [2][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0002(0.0048) Grad: 152.0701  LR: 0.000015  \n",
      "Epoch: [2][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0054(0.0048) Grad: 1351.3754  LR: 0.000015  \n",
      "Epoch: [2][2000/2681] Elapsed 21m 3s (remain 7m 9s) Loss: 0.0001(0.0048) Grad: 158.1812  LR: 0.000014  \n",
      "Epoch: [2][2100/2681] Elapsed 22m 6s (remain 6m 6s) Loss: 0.0063(0.0048) Grad: 4263.7676  LR: 0.000014  \n",
      "Epoch: [2][2200/2681] Elapsed 23m 9s (remain 5m 3s) Loss: 0.0000(0.0048) Grad: 18.8376  LR: 0.000014  \n",
      "Epoch: [2][2300/2681] Elapsed 24m 13s (remain 3m 59s) Loss: 0.0002(0.0048) Grad: 340.4636  LR: 0.000014  \n",
      "Epoch: [2][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0000(0.0048) Grad: 82.9437  LR: 0.000014  \n",
      "Epoch: [2][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0230(0.0049) Grad: 13969.7031  LR: 0.000014  \n",
      "Epoch: [2][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0101(0.0049) Grad: 5670.3281  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2680/2681] Elapsed 28m 12s (remain 0m 0s) Loss: 0.0000(0.0049) Grad: 44.3579  LR: 0.000013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 58s) Loss: 0.0052(0.0052) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0003(0.0163) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0746(0.0193) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0447(0.0189) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0219(0.0181) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0196(0.0208) \n",
      "EVAL: [600/894] Elapsed 3m 15s (remain 1m 35s) Loss: 0.0274(0.0214) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0245(0.0214) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0010(0.0209) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0000(0.0198) \n",
      "Epoch 2 - avg_train_loss: 0.0049  avg_val_loss: 0.0198  time: 1986s\n",
      "Epoch 2 - Score: 0.8861\n",
      "Epoch 2 - Save Best Score: 0.8861 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2681] Elapsed 0m 1s (remain 52m 54s) Loss: 0.0011(0.0011) Grad: 805.2070  LR: 0.000013  \n",
      "Epoch: [3][100/2681] Elapsed 1m 4s (remain 27m 25s) Loss: 0.0003(0.0062) Grad: 229.0934  LR: 0.000013  \n",
      "Epoch: [3][200/2681] Elapsed 2m 7s (remain 26m 13s) Loss: 0.0004(0.0055) Grad: 318.5094  LR: 0.000013  \n",
      "Epoch: [3][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.0029(0.0055) Grad: 1486.9294  LR: 0.000013  \n",
      "Epoch: [3][400/2681] Elapsed 4m 13s (remain 24m 3s) Loss: 0.0002(0.0055) Grad: 132.7601  LR: 0.000013  \n",
      "Epoch: [3][500/2681] Elapsed 5m 17s (remain 22m 59s) Loss: 0.0013(0.0052) Grad: 1099.1113  LR: 0.000013  \n",
      "Epoch: [3][600/2681] Elapsed 6m 20s (remain 21m 56s) Loss: 0.0025(0.0051) Grad: 1439.1260  LR: 0.000012  \n",
      "Epoch: [3][700/2681] Elapsed 7m 23s (remain 20m 52s) Loss: 0.0002(0.0051) Grad: 130.7961  LR: 0.000012  \n",
      "Epoch: [3][800/2681] Elapsed 8m 26s (remain 19m 49s) Loss: 0.0006(0.0048) Grad: 445.6460  LR: 0.000012  \n",
      "Epoch: [3][900/2681] Elapsed 9m 29s (remain 18m 45s) Loss: 0.0002(0.0047) Grad: 147.3341  LR: 0.000012  \n",
      "Epoch: [3][1000/2681] Elapsed 10m 32s (remain 17m 42s) Loss: 0.0170(0.0046) Grad: 4038.5952  LR: 0.000012  \n",
      "Epoch: [3][1100/2681] Elapsed 11m 36s (remain 16m 38s) Loss: 0.0006(0.0045) Grad: 682.1049  LR: 0.000012  \n",
      "Epoch: [3][1200/2681] Elapsed 12m 39s (remain 15m 35s) Loss: 0.0001(0.0044) Grad: 96.2547  LR: 0.000011  \n",
      "Epoch: [3][1300/2681] Elapsed 13m 42s (remain 14m 32s) Loss: 0.0429(0.0045) Grad: 9459.4844  LR: 0.000011  \n",
      "Epoch: [3][1400/2681] Elapsed 14m 45s (remain 13m 28s) Loss: 0.0607(0.0045) Grad: 17311.3281  LR: 0.000011  \n",
      "Epoch: [3][1500/2681] Elapsed 15m 48s (remain 12m 25s) Loss: 0.0003(0.0045) Grad: 259.0358  LR: 0.000011  \n",
      "Epoch: [3][1600/2681] Elapsed 16m 51s (remain 11m 22s) Loss: 0.0243(0.0046) Grad: 4891.8364  LR: 0.000011  \n",
      "Epoch: [3][1700/2681] Elapsed 17m 54s (remain 10m 19s) Loss: 0.0001(0.0046) Grad: 170.2266  LR: 0.000011  \n",
      "Epoch: [3][1800/2681] Elapsed 18m 57s (remain 9m 15s) Loss: 0.0001(0.0046) Grad: 153.2298  LR: 0.000010  \n",
      "Epoch: [3][1900/2681] Elapsed 20m 0s (remain 8m 12s) Loss: 0.0017(0.0047) Grad: 1159.8964  LR: 0.000010  \n",
      "Epoch: [3][2000/2681] Elapsed 21m 4s (remain 7m 9s) Loss: 0.0027(0.0047) Grad: 2900.5911  LR: 0.000010  \n",
      "Epoch: [3][2100/2681] Elapsed 22m 7s (remain 6m 6s) Loss: 0.0323(0.0047) Grad: 19404.0586  LR: 0.000010  \n",
      "Epoch: [3][2200/2681] Elapsed 23m 10s (remain 5m 3s) Loss: 0.0184(0.0047) Grad: 8641.5977  LR: 0.000010  \n",
      "Epoch: [3][2300/2681] Elapsed 24m 13s (remain 4m 0s) Loss: 0.0001(0.0046) Grad: 117.9479  LR: 0.000010  \n",
      "Epoch: [3][2400/2681] Elapsed 25m 16s (remain 2m 56s) Loss: 0.0002(0.0047) Grad: 141.6364  LR: 0.000009  \n",
      "Epoch: [3][2500/2681] Elapsed 26m 19s (remain 1m 53s) Loss: 0.0000(0.0047) Grad: 28.4844  LR: 0.000009  \n",
      "Epoch: [3][2600/2681] Elapsed 27m 22s (remain 0m 50s) Loss: 0.0023(0.0047) Grad: 4492.6919  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2680/2681] Elapsed 28m 13s (remain 0m 0s) Loss: 0.0001(0.0047) Grad: 106.3244  LR: 0.000009  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 12m 1s) Loss: 0.0041(0.0041) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 21s) Loss: 0.0004(0.0143) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0569(0.0169) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 13s) Loss: 0.0423(0.0167) \n",
      "EVAL: [400/894] Elapsed 2m 10s (remain 2m 40s) Loss: 0.0168(0.0160) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0171(0.0184) \n",
      "EVAL: [600/894] Elapsed 3m 16s (remain 1m 35s) Loss: 0.0242(0.0190) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0231(0.0189) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0007(0.0184) \n",
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0001(0.0175) \n",
      "Epoch 3 - avg_train_loss: 0.0047  avg_val_loss: 0.0175  time: 1987s\n",
      "Epoch 3 - Score: 0.8869\n",
      "Epoch 3 - Save Best Score: 0.8869 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2681] Elapsed 0m 1s (remain 52m 3s) Loss: 0.0051(0.0051) Grad: 2655.7786  LR: 0.000009  \n",
      "Epoch: [4][100/2681] Elapsed 1m 4s (remain 27m 23s) Loss: 0.0000(0.0043) Grad: 15.8979  LR: 0.000009  \n",
      "Epoch: [4][200/2681] Elapsed 2m 7s (remain 26m 13s) Loss: 0.0001(0.0042) Grad: 129.9810  LR: 0.000009  \n",
      "Epoch: [4][300/2681] Elapsed 3m 10s (remain 25m 7s) Loss: 0.0010(0.0045) Grad: 840.8720  LR: 0.000008  \n",
      "Epoch: [4][400/2681] Elapsed 4m 13s (remain 24m 3s) Loss: 0.0001(0.0042) Grad: 88.7952  LR: 0.000008  \n",
      "Epoch: [4][500/2681] Elapsed 5m 17s (remain 22m 59s) Loss: 0.0001(0.0043) Grad: 93.2377  LR: 0.000008  \n",
      "Epoch: [4][600/2681] Elapsed 6m 20s (remain 21m 56s) Loss: 0.0039(0.0046) Grad: 2002.0087  LR: 0.000008  \n",
      "Epoch: [4][700/2681] Elapsed 7m 23s (remain 20m 52s) Loss: 0.0093(0.0047) Grad: 4676.5293  LR: 0.000008  \n",
      "Epoch: [4][800/2681] Elapsed 8m 26s (remain 19m 49s) Loss: 0.0271(0.0047) Grad: 5822.5156  LR: 0.000008  \n",
      "Epoch: [4][900/2681] Elapsed 9m 30s (remain 18m 46s) Loss: 0.0816(0.0049) Grad: 35179.8750  LR: 0.000007  \n",
      "Epoch: [4][1000/2681] Elapsed 10m 33s (remain 17m 42s) Loss: 0.0001(0.0047) Grad: 49.8545  LR: 0.000007  \n",
      "Epoch: [4][1100/2681] Elapsed 11m 36s (remain 16m 39s) Loss: 0.0002(0.0047) Grad: 432.2402  LR: 0.000007  \n",
      "Epoch: [4][1200/2681] Elapsed 12m 39s (remain 15m 36s) Loss: 0.0135(0.0047) Grad: 7866.1631  LR: 0.000007  \n",
      "Epoch: [4][1300/2681] Elapsed 13m 43s (remain 14m 33s) Loss: 0.0001(0.0047) Grad: 95.9658  LR: 0.000007  \n",
      "Epoch: [4][1400/2681] Elapsed 14m 46s (remain 13m 29s) Loss: 0.0073(0.0046) Grad: 2465.4785  LR: 0.000007  \n",
      "Epoch: [4][1500/2681] Elapsed 15m 49s (remain 12m 26s) Loss: 0.0000(0.0047) Grad: 16.4416  LR: 0.000006  \n",
      "Epoch: [4][1600/2681] Elapsed 16m 52s (remain 11m 23s) Loss: 0.0000(0.0048) Grad: 23.4411  LR: 0.000006  \n",
      "Epoch: [4][1700/2681] Elapsed 17m 55s (remain 10m 19s) Loss: 0.0003(0.0047) Grad: 358.3818  LR: 0.000006  \n",
      "Epoch: [4][1800/2681] Elapsed 18m 59s (remain 9m 16s) Loss: 0.0001(0.0047) Grad: 74.9258  LR: 0.000006  \n",
      "Epoch: [4][1900/2681] Elapsed 20m 2s (remain 8m 13s) Loss: 0.0007(0.0046) Grad: 619.1531  LR: 0.000006  \n",
      "Epoch: [4][2000/2681] Elapsed 21m 5s (remain 7m 10s) Loss: 0.0001(0.0047) Grad: 72.6379  LR: 0.000006  \n",
      "Epoch: [4][2100/2681] Elapsed 22m 8s (remain 6m 6s) Loss: 0.0000(0.0047) Grad: 36.0156  LR: 0.000005  \n",
      "Epoch: [4][2200/2681] Elapsed 23m 11s (remain 5m 3s) Loss: 0.0000(0.0047) Grad: 80.1036  LR: 0.000005  \n",
      "Epoch: [4][2300/2681] Elapsed 24m 15s (remain 4m 0s) Loss: 0.0000(0.0047) Grad: 170.9085  LR: 0.000005  \n",
      "Epoch: [4][2400/2681] Elapsed 25m 18s (remain 2m 57s) Loss: 0.0000(0.0046) Grad: 99.6727  LR: 0.000005  \n",
      "Epoch: [4][2500/2681] Elapsed 26m 21s (remain 1m 53s) Loss: 0.0001(0.0047) Grad: 114.7507  LR: 0.000005  \n",
      "Epoch: [4][2600/2681] Elapsed 27m 24s (remain 0m 50s) Loss: 0.0002(0.0046) Grad: 340.4337  LR: 0.000005  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2680/2681] Elapsed 28m 15s (remain 0m 0s) Loss: 0.0078(0.0046) Grad: 8292.4180  LR: 0.000004  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 45s) Loss: 0.0056(0.0056) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 22s) Loss: 0.0003(0.0155) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0645(0.0184) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 14s) Loss: 0.0455(0.0180) \n",
      "EVAL: [400/894] Elapsed 2m 11s (remain 2m 41s) Loss: 0.0193(0.0171) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0166(0.0198) \n",
      "EVAL: [600/894] Elapsed 3m 16s (remain 1m 35s) Loss: 0.0263(0.0203) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0248(0.0203) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0006(0.0198) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0000(0.0188) \n",
      "Epoch 4 - avg_train_loss: 0.0046  avg_val_loss: 0.0188  time: 1989s\n",
      "Epoch 4 - Score: 0.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2681] Elapsed 0m 1s (remain 52m 9s) Loss: 0.0040(0.0040) Grad: 3136.3979  LR: 0.000004  \n",
      "Epoch: [5][100/2681] Elapsed 1m 4s (remain 27m 26s) Loss: 0.0004(0.0042) Grad: 355.4073  LR: 0.000004  \n",
      "Epoch: [5][200/2681] Elapsed 2m 7s (remain 26m 15s) Loss: 0.0001(0.0045) Grad: 140.7210  LR: 0.000004  \n",
      "Epoch: [5][300/2681] Elapsed 3m 10s (remain 25m 9s) Loss: 0.0033(0.0044) Grad: 2360.5388  LR: 0.000004  \n",
      "Epoch: [5][400/2681] Elapsed 4m 14s (remain 24m 4s) Loss: 0.0004(0.0044) Grad: 520.1922  LR: 0.000004  \n",
      "Epoch: [5][500/2681] Elapsed 5m 17s (remain 23m 0s) Loss: 0.0001(0.0044) Grad: 56.7684  LR: 0.000004  \n",
      "Epoch: [5][600/2681] Elapsed 6m 20s (remain 21m 56s) Loss: 0.0010(0.0047) Grad: 1157.1301  LR: 0.000003  \n",
      "Epoch: [5][700/2681] Elapsed 7m 23s (remain 20m 53s) Loss: 0.0000(0.0048) Grad: 14.9413  LR: 0.000003  \n",
      "Epoch: [5][800/2681] Elapsed 8m 27s (remain 19m 50s) Loss: 0.0010(0.0049) Grad: 1175.1434  LR: 0.000003  \n",
      "Epoch: [5][900/2681] Elapsed 9m 30s (remain 18m 46s) Loss: 0.0005(0.0048) Grad: 825.7285  LR: 0.000003  \n",
      "Epoch: [5][1000/2681] Elapsed 10m 33s (remain 17m 43s) Loss: 0.0001(0.0049) Grad: 46.7358  LR: 0.000003  \n",
      "Epoch: [5][1100/2681] Elapsed 11m 36s (remain 16m 39s) Loss: 0.0000(0.0049) Grad: 21.7264  LR: 0.000003  \n",
      "Epoch: [5][1200/2681] Elapsed 12m 39s (remain 15m 36s) Loss: 0.0003(0.0048) Grad: 652.3251  LR: 0.000002  \n",
      "Epoch: [5][1300/2681] Elapsed 13m 43s (remain 14m 33s) Loss: 0.0003(0.0048) Grad: 311.1794  LR: 0.000002  \n",
      "Epoch: [5][1400/2681] Elapsed 14m 46s (remain 13m 29s) Loss: 0.0001(0.0047) Grad: 100.0254  LR: 0.000002  \n",
      "Epoch: [5][1500/2681] Elapsed 15m 49s (remain 12m 26s) Loss: 0.0000(0.0048) Grad: 21.5734  LR: 0.000002  \n",
      "Epoch: [5][1600/2681] Elapsed 16m 52s (remain 11m 23s) Loss: 0.0000(0.0047) Grad: 42.9249  LR: 0.000002  \n",
      "Epoch: [5][1700/2681] Elapsed 17m 55s (remain 10m 19s) Loss: 0.0001(0.0046) Grad: 57.6742  LR: 0.000002  \n",
      "Epoch: [5][1800/2681] Elapsed 18m 58s (remain 9m 16s) Loss: 0.0049(0.0045) Grad: 2880.3179  LR: 0.000001  \n",
      "Epoch: [5][1900/2681] Elapsed 20m 2s (remain 8m 13s) Loss: 0.0016(0.0046) Grad: 1594.8762  LR: 0.000001  \n",
      "Epoch: [5][2000/2681] Elapsed 21m 5s (remain 7m 9s) Loss: 0.0004(0.0045) Grad: 1144.1833  LR: 0.000001  \n",
      "Epoch: [5][2100/2681] Elapsed 22m 8s (remain 6m 6s) Loss: 0.0046(0.0045) Grad: 4817.7490  LR: 0.000001  \n",
      "Epoch: [5][2200/2681] Elapsed 23m 11s (remain 5m 3s) Loss: 0.0008(0.0045) Grad: 1381.3861  LR: 0.000001  \n",
      "Epoch: [5][2300/2681] Elapsed 24m 14s (remain 4m 0s) Loss: 0.0000(0.0045) Grad: 76.0529  LR: 0.000001  \n",
      "Epoch: [5][2400/2681] Elapsed 25m 18s (remain 2m 57s) Loss: 0.0004(0.0045) Grad: 858.5745  LR: 0.000000  \n",
      "Epoch: [5][2500/2681] Elapsed 26m 21s (remain 1m 53s) Loss: 0.0000(0.0046) Grad: 62.8148  LR: 0.000000  \n",
      "Epoch: [5][2600/2681] Elapsed 27m 24s (remain 0m 50s) Loss: 0.0000(0.0046) Grad: 87.3331  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][2680/2681] Elapsed 28m 15s (remain 0m 0s) Loss: 0.0000(0.0046) Grad: 29.2244  LR: 0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/894] Elapsed 0m 0s (remain 11m 56s) Loss: 0.0053(0.0053) \n",
      "EVAL: [100/894] Elapsed 0m 33s (remain 4m 22s) Loss: 0.0003(0.0153) \n",
      "EVAL: [200/894] Elapsed 1m 5s (remain 3m 47s) Loss: 0.0633(0.0182) \n",
      "EVAL: [300/894] Elapsed 1m 38s (remain 3m 14s) Loss: 0.0445(0.0178) \n",
      "EVAL: [400/894] Elapsed 2m 11s (remain 2m 41s) Loss: 0.0192(0.0169) \n",
      "EVAL: [500/894] Elapsed 2m 43s (remain 2m 8s) Loss: 0.0162(0.0195) \n",
      "EVAL: [600/894] Elapsed 3m 16s (remain 1m 35s) Loss: 0.0261(0.0201) \n",
      "EVAL: [700/894] Elapsed 3m 48s (remain 1m 2s) Loss: 0.0244(0.0201) \n",
      "EVAL: [800/894] Elapsed 4m 21s (remain 0m 30s) Loss: 0.0006(0.0195) \n",
      "EVAL: [893/894] Elapsed 4m 51s (remain 0m 0s) Loss: 0.0000(0.0185) \n",
      "Epoch 5 - avg_train_loss: 0.0046  avg_val_loss: 0.0185  time: 1989s\n",
      "Epoch 5 - Score: 0.8869\n",
      "best_thres: 0.49  score: 0.88520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp067/fold0_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd602fa7301c471a988e0b9dcee228e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "    close()  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "        self._close()\n",
      "self._close()  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "        self.run()self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "        queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp067/fold1_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326a0454c58c41c89c9dae9a5c5e0c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "        close()close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "        _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self._close()self.run()\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "        self._target(*self._args, **self._kwargs)_close(self._handle)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp067/fold2_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf925ecfa51f4c2a862194d630c16504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()    self._close()\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "        _close(self._handle)\n",
      "_close(self._handle)\n",
      "OSErrorOSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      ": [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "        self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "        self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "        queue_sem.release()queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "ValueError: semaphore or lock released too many times\n",
      "Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp067/fold3_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7bd63049ec4bb5adeddd91dc2cb052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "        close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "        self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "self._close()    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "        queue_sem.release()\n",
      "ValueError_close(self._handle)\n",
      ": semaphore or lock released too many times\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-brazil",
   "metadata": {
    "id": "N5kZWfSSfJMf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp060.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "037c7090db304999a1101d9e2e5a4174": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05899ddeb69f42e19a6a4f2e8e58d1a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79874640551f423882aa448bc2cf852a",
       "IPY_MODEL_e5a6f08db13d4b3897310578958b756c",
       "IPY_MODEL_dc98eacd6dc14b65951354be55896f95"
      ],
      "layout": "IPY_MODEL_8afeb9769ec1438fa590a2f55898d33c"
     }
    },
    "0a1370ce38a04112931ddb9e98e0681d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97f866a7b47044c6b13b510364db0936",
      "placeholder": "​",
      "style": "IPY_MODEL_0a9ded7de82b4e05966e232fa1f2c787",
      "value": "Downloading: 100%"
     }
    },
    "0a9ded7de82b4e05966e232fa1f2c787": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10dc1b43c16f4bfea6b6bcb7322ec3cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "111571ccdbaa4cc2930a5879301e8e0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cdfeae485f4cdd9602211051e4d8cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "184eb6da09c746e5bc0a1795e63d9ca0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18b08cf3579d45368f654d76b94bde98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "192e369ce01f4056bb9e8cb9c1f58fb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c636a002bc649a89f18438cc014060b",
      "placeholder": "​",
      "style": "IPY_MODEL_9e43b827da0d430389152133415c8597",
      "value": " 1.52G/1.52G [00:33&lt;00:00, 52.3MB/s]"
     }
    },
    "1ac1c449974e49d2a5ca44923c8c7c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_184eb6da09c746e5bc0a1795e63d9ca0",
      "placeholder": "​",
      "style": "IPY_MODEL_36a6535e0d4246d295f0c4040f58c44a",
      "value": "Downloading: 100%"
     }
    },
    "1c636a002bc649a89f18438cc014060b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1da67dda0fcd4e30801d258ce5b94dcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fe2a3a2e3c24cebab36756c281a53b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2111e9eb51a144569ff012d84e83d7a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "293383a7075940e3afbfb11b17dcb0bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c419f9f3f6d44830b1685d75cb27344e",
      "placeholder": "​",
      "style": "IPY_MODEL_18b08cf3579d45368f654d76b94bde98",
      "value": "Downloading: 100%"
     }
    },
    "295c5dd71a3b40729c0cfa8f4b9e739c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29b82ceb3d7e4f25a45b0a01b0a9b331": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b71730a985e49babde4e34a72e97dc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d0e66a3deb04a898bb3c766d2a4d4bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ee84c25ddbd4dafac1dfe5c85bdaa0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f52fd0cd6a74daabf24b771a497e17d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f68cae6212b46af8a195ee3b7011546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bae123ba33dc490ebb5419355fdddedb",
      "placeholder": "​",
      "style": "IPY_MODEL_74c044535cb345809273b1724907c736",
      "value": " 52.0/52.0 [00:00&lt;00:00, 1.49kB/s]"
     }
    },
    "30c61e5a6dff40088c1b6ac7cce7e1ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36a6535e0d4246d295f0c4040f58c44a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37e26fb7433847f5a99ba2228fe2551b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38acebf8e4e24912a40d15ff423b82b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cd7e4275e784665902cc5f4930e875a",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30c61e5a6dff40088c1b6ac7cce7e1ce",
      "value": 456318
     }
    },
    "3d0006900ef744a7a5171ec2932c488e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3da621183b0f4d488b1150d0fd4ab44e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db746b1ed1d6485881ea9d1a89204363",
      "placeholder": "​",
      "style": "IPY_MODEL_7f61f28890dd4c519cb602ef9deead90",
      "value": " 42146/42146 [00:00&lt;00:00, 545387.37it/s]"
     }
    },
    "40581063d44b4eb392f534138ae5d2cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e64f8626bbf4daba50cf499d4adc6f4",
       "IPY_MODEL_44e6de0ebd2a4ef58a586ef14c21cbb1",
       "IPY_MODEL_2f68cae6212b46af8a195ee3b7011546"
      ],
      "layout": "IPY_MODEL_ab1aca1c8d8b4c4a80c10482ce30fb0b"
     }
    },
    "429e4e00e8b2409993a3fc8d88cbd8a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d078b771963249d1b3061804258dcf16",
      "max": 475,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9164887b3ee24c99bbf60652fd1b5c32",
      "value": 475
     }
    },
    "44e6de0ebd2a4ef58a586ef14c21cbb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37e26fb7433847f5a99ba2228fe2551b",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0cf3cdeef694167b9641c1fa4131746",
      "value": 52
     }
    },
    "49d75d7c4cf34990a659483f4d4caeee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c2225dd49ae4dffac171b940fd503fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f26f3e1f9e545e8a1f83fe4307e3857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f374a11ffa3408791f9d8a4acd13eba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5036ba2cf1d14c43a3e1d82fa3cb8853": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "518a4dae6e9440d4a5c08d3072789185": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52017694880f40efb76ed78fffe936a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fc780deb9bd4005badbd8613d0dcd09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c2225dd49ae4dffac171b940fd503fe",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d0e66a3deb04a898bb3c766d2a4d4bd",
      "value": 42146
     }
    },
    "5fcb7d1794054cf190fad1a98905c063": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7976633024c64c9b8eb73f719392b663",
       "IPY_MODEL_429e4e00e8b2409993a3fc8d88cbd8a4",
       "IPY_MODEL_e2c7eb205b5e49da89d8aec82fdaf076"
      ],
      "layout": "IPY_MODEL_037c7090db304999a1101d9e2e5a4174"
     }
    },
    "60c41f7069544093bc03c7eca22eb103": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_defedb7dd63045df973acbc933b9762f",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9772a88a338347909cada09e8d2082e5",
      "value": 42146
     }
    },
    "6ae57745545e41e8af94dba3d3cab972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29b82ceb3d7e4f25a45b0a01b0a9b331",
      "placeholder": "​",
      "style": "IPY_MODEL_9f7532640efe4accb279b1a1fe06cbf8",
      "value": "100%"
     }
    },
    "6b51934ee3df452da196cf89bb5e6958": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f27a875918e49778dc71b4c2dbb72e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70c2506df3db4c9fb0433dc01c86244d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7478819134434d33bbc38feeac11c88a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74c044535cb345809273b1724907c736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "767bec79de264f869d9a95d88e9fd8f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78e822ad4e1a4e01974ed07340353a5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e41e8330b9f24c90b75c1a6e6e699fd3",
      "placeholder": "​",
      "style": "IPY_MODEL_3d0006900ef744a7a5171ec2932c488e",
      "value": " 878k/878k [00:00&lt;00:00, 1.55MB/s]"
     }
    },
    "7976633024c64c9b8eb73f719392b663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_518a4dae6e9440d4a5c08d3072789185",
      "placeholder": "​",
      "style": "IPY_MODEL_2f52fd0cd6a74daabf24b771a497e17d",
      "value": "Downloading: 100%"
     }
    },
    "79874640551f423882aa448bc2cf852a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52017694880f40efb76ed78fffe936a6",
      "placeholder": "​",
      "style": "IPY_MODEL_c3063e2f2f074591b1a94abe4ba25ea2",
      "value": "100%"
     }
    },
    "7af068350d6e4480bdc816cb7b5719f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b5a579308f3471a8233cb83c140a661": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a88ce37e03a4557bc114cfbc4713717",
       "IPY_MODEL_ea2f58f8a37b432da4bb669b59c131e4",
       "IPY_MODEL_d35405c96d2e4009bd853115c097bd86"
      ],
      "layout": "IPY_MODEL_f6b30ed009ce46279f1f23a732caa920"
     }
    },
    "7e64f8626bbf4daba50cf499d4adc6f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aeb1dc88817e4c9f80e7e9af10116468",
      "placeholder": "​",
      "style": "IPY_MODEL_840fd42b736e4a368a021d9372362709",
      "value": "Downloading: 100%"
     }
    },
    "7f61f28890dd4c519cb602ef9deead90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "840fd42b736e4a368a021d9372362709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a88ce37e03a4557bc114cfbc4713717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fa8cd67d0214aeba9c9159beec33b2d",
      "placeholder": "​",
      "style": "IPY_MODEL_7af068350d6e4480bdc816cb7b5719f1",
      "value": "  0%"
     }
    },
    "8afeb9769ec1438fa590a2f55898d33c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cd7e4275e784665902cc5f4930e875a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fa8cd67d0214aeba9c9159beec33b2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9164887b3ee24c99bbf60652fd1b5c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96d9a1b6233f44c0a94e73aeec99e9cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ac1c449974e49d2a5ca44923c8c7c2f",
       "IPY_MODEL_38acebf8e4e24912a40d15ff423b82b5",
       "IPY_MODEL_9e1f40698b1640a791d47f5535c2195e"
      ],
      "layout": "IPY_MODEL_e8fe4cfe66dd4d638144738444a255dc"
     }
    },
    "9772a88a338347909cada09e8d2082e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97f866a7b47044c6b13b510364db0936": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1f40698b1640a791d47f5535c2195e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_295c5dd71a3b40729c0cfa8f4b9e739c",
      "placeholder": "​",
      "style": "IPY_MODEL_17cdfeae485f4cdd9602211051e4d8cc",
      "value": " 446k/446k [00:00&lt;00:00, 472kB/s]"
     }
    },
    "9e43b827da0d430389152133415c8597": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f7532640efe4accb279b1a1fe06cbf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0cf3cdeef694167b9641c1fa4131746": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a2209d4bb35842509ec9c618a4baf91f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab1aca1c8d8b4c4a80c10482ce30fb0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae111ebaf27e477784490dda702602be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aeb1dc88817e4c9f80e7e9af10116468": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bae123ba33dc490ebb5419355fdddedb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3063e2f2f074591b1a94abe4ba25ea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c419f9f3f6d44830b1685d75cb27344e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca10a5382123481da26efdbc3517aaa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eddea6b1941646a98d2946cc0b95e7f6",
      "placeholder": "​",
      "style": "IPY_MODEL_7478819134434d33bbc38feeac11c88a",
      "value": " 42146/42146 [00:31&lt;00:00, 2003.33it/s]"
     }
    },
    "cec25d0ed87a480384676eee910c5ef6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d078b771963249d1b3061804258dcf16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d35405c96d2e4009bd853115c097bd86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_111571ccdbaa4cc2930a5879301e8e0f",
      "placeholder": "​",
      "style": "IPY_MODEL_70c2506df3db4c9fb0433dc01c86244d",
      "value": " 0/2 [00:01&lt;?, ?it/s]"
     }
    },
    "d5fef2adb9d747c6bd487b40e3b809cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f27a875918e49778dc71b4c2dbb72e8",
      "max": 898825,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2111e9eb51a144569ff012d84e83d7a1",
      "value": 898825
     }
    },
    "d8a0630ab85242a2964952e8d01d0aa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6ae57745545e41e8af94dba3d3cab972",
       "IPY_MODEL_60c41f7069544093bc03c7eca22eb103",
       "IPY_MODEL_ca10a5382123481da26efdbc3517aaa5"
      ],
      "layout": "IPY_MODEL_cec25d0ed87a480384676eee910c5ef6"
     }
    },
    "db746b1ed1d6485881ea9d1a89204363": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc98eacd6dc14b65951354be55896f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_767bec79de264f869d9a95d88e9fd8f5",
      "placeholder": "​",
      "style": "IPY_MODEL_ae111ebaf27e477784490dda702602be",
      "value": " 143/143 [00:00&lt;00:00, 2407.24it/s]"
     }
    },
    "defedb7dd63045df973acbc933b9762f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e02b42eec984434baf61fc2f03030a05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a1370ce38a04112931ddb9e98e0681d",
       "IPY_MODEL_e0cf2e2638884464aa945f949afb580e",
       "IPY_MODEL_192e369ce01f4056bb9e8cb9c1f58fb9"
      ],
      "layout": "IPY_MODEL_49d75d7c4cf34990a659483f4d4caeee"
     }
    },
    "e0cf2e2638884464aa945f949afb580e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1da67dda0fcd4e30801d258ce5b94dcc",
      "max": 1627284589,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ee84c25ddbd4dafac1dfe5c85bdaa0f",
      "value": 1627284589
     }
    },
    "e2c7eb205b5e49da89d8aec82fdaf076": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6fc1c67116248b288adde889a689193",
      "placeholder": "​",
      "style": "IPY_MODEL_4f374a11ffa3408791f9d8a4acd13eba",
      "value": " 475/475 [00:00&lt;00:00, 6.30kB/s]"
     }
    },
    "e41e8330b9f24c90b75c1a6e6e699fd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5a6f08db13d4b3897310578958b756c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b71730a985e49babde4e34a72e97dc8",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2209d4bb35842509ec9c618a4baf91f",
      "value": 143
     }
    },
    "e6fc1c67116248b288adde889a689193": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8fe4cfe66dd4d638144738444a255dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea2c108b9852466c96e9f139fb7b86c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd4193c79e8a41cfa08b2ac6e95c1f81",
       "IPY_MODEL_5fc780deb9bd4005badbd8613d0dcd09",
       "IPY_MODEL_3da621183b0f4d488b1150d0fd4ab44e"
      ],
      "layout": "IPY_MODEL_6b51934ee3df452da196cf89bb5e6958"
     }
    },
    "ea2f58f8a37b432da4bb669b59c131e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd7421cac7834be09bf821fcff9e5295",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fe2a3a2e3c24cebab36756c281a53b8",
      "value": 0
     }
    },
    "eddea6b1941646a98d2946cc0b95e7f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f33aa873d8654f18b67df7995dbcb71e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_293383a7075940e3afbfb11b17dcb0bc",
       "IPY_MODEL_d5fef2adb9d747c6bd487b40e3b809cb",
       "IPY_MODEL_78e822ad4e1a4e01974ed07340353a5d"
      ],
      "layout": "IPY_MODEL_5036ba2cf1d14c43a3e1d82fa3cb8853"
     }
    },
    "f6b30ed009ce46279f1f23a732caa920": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd4193c79e8a41cfa08b2ac6e95c1f81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f26f3e1f9e545e8a1f83fe4307e3857",
      "placeholder": "​",
      "style": "IPY_MODEL_10dc1b43c16f4bfea6b6bcb7322ec3cd",
      "value": "100%"
     }
    },
    "fd7421cac7834be09bf821fcff9e5295": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
