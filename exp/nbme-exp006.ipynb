{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adolescent-image",
   "metadata": {
    "id": "incredible-principle"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-wealth",
   "metadata": {
    "id": "simplified-tract"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n",
    "- https://www.kaggle.com/abebe9849/nbmeexp019?select=itpt.py\n",
    "- https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-itpt\n",
    "- https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-starter",
   "metadata": {
    "id": "boolean-shame"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-panama",
   "metadata": {
    "id": "needed-consistency"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp006\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rational-administration",
   "metadata": {
    "id": "operational-trader"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-base\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=8\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spanish-mistress",
   "metadata": {
    "id": "g6Cc8fDp2Nle"
   },
   "outputs": [],
   "source": [
    "class CFG_For_MLM:\n",
    "    epochs = 15 # adjust\n",
    "    learning_rate = 5e-05\n",
    "    train_batch_size = 16\n",
    "    gradient_accum_steps = 2\n",
    "    eval_batch_size = 16\n",
    "    eval_steps = 6940 # adjust\n",
    "    block_size = 466 # tokenizerのmax_length\n",
    "    mlm_prob = 0.15\n",
    "    fp16 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-notebook",
   "metadata": {
    "id": "seasonal-consistency"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-sample",
   "metadata": {
    "id": "billion-composite"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "national-third",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "desperate-collect",
    "outputId": "5fe1bfad-5d36-4201-a4a2-f84d8a7d809d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "married-geneva",
   "metadata": {
    "id": "acute-pregnancy"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informative-assault",
   "metadata": {
    "id": "IW4rCfxa1wyC"
   },
   "outputs": [],
   "source": [
    "from transformers import (AutoModel, \n",
    "                          AutoModelForMaskedLM,\n",
    "                          AutoTokenizer,\n",
    "                          AutoConfig,\n",
    "                          AdamW,\n",
    "                          LineByLineTextDataset,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          Trainer,\n",
    "                          TrainingArguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-daughter",
   "metadata": {
    "id": "generous-raleigh"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rocky-multiple",
   "metadata": {
    "id": "mmZHVaPkh0Qc"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "driving-defensive",
   "metadata": {
    "id": "IydDnpFyh4PX"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-trader",
   "metadata": {
    "id": "formed-handbook"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stupid-evaluation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vanilla-register",
    "outputId": "21d382a3-c203-4855-f7fd-e0f08cfaf2f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incomplete-kennedy",
   "metadata": {
    "id": "approximate-transmission"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-remark",
   "metadata": {
    "id": "civic-advisory"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coordinated-sister",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPHRME1x0a6j",
    "outputId": "a33b6872-352f-4fd9-fe39-de92cdf40a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42146\n",
      "33716 8430\n"
     ]
    }
   ],
   "source": [
    "patient_notes = patient_notes.sample(frac=1.0, random_state=71)   # random shuffle\n",
    "n_train = int(len(patient_notes) * 0.8)\n",
    "\n",
    "pretrain_texts = patient_notes[\"pn_history\"].unique()\n",
    "print(len(pretrain_texts))\n",
    "\n",
    "train_pretrain_texts = pretrain_texts[:n_train]\n",
    "valid_pretrain_texts = pretrain_texts[n_train:]\n",
    "print(len(train_pretrain_texts), len(valid_pretrain_texts))\n",
    "\n",
    "with open(CFG.output_dir / \"train_text.txt\", \"w\") as f:\n",
    "    texts  = \"\\n\".join(train_pretrain_texts.tolist())\n",
    "    f.write(texts)\n",
    "with open(CFG.output_dir / \"valid_text.txt\", \"w\") as f:\n",
    "    texts  = \"\\n\".join(valid_pretrain_texts.tolist())\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-tenant",
   "metadata": {
    "id": "senior-wichita"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nearby-anniversary",
   "metadata": {
    "id": "thrown-theology"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-penguin",
   "metadata": {
    "id": "ZbXou2dp152b"
   },
   "source": [
    "## Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "referenced-parcel",
   "metadata": {
    "id": "a-o-wrnz1n-a"
   },
   "outputs": [],
   "source": [
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer=CFG.tokenizer,\n",
    "    file_path=CFG.output_dir / \"train_text.txt\",\n",
    "    block_size=CFG_For_MLM.block_size)\n",
    "\n",
    "valid_dataset = LineByLineTextDataset(\n",
    "    tokenizer=CFG.tokenizer,\n",
    "    file_path=CFG.output_dir / \"valid_text.txt\",\n",
    "    block_size=CFG_For_MLM.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "comparable-tactics",
   "metadata": {
    "id": "o-XhXXOx2z4d"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=CFG.tokenizer, \n",
    "    mlm=True, \n",
    "    mlm_probability=CFG_For_MLM.mlm_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-garage",
   "metadata": {
    "id": "JaGyEd0r3i0W"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "under-paraguay",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6v9UUtX3h8m",
    "outputId": "fe951334-cb48-4681-eed2-c065e2691367"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForMaskedLM: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(CFG.pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-secondary",
   "metadata": {
    "id": "seventh-configuration"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cooked-nicholas",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rocky-lexington",
    "outputId": "226f954d-8f15-43d4-dcc2-a96035789085"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=CFG.output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=CFG_For_MLM.epochs,\n",
    "    per_device_train_batch_size=CFG_For_MLM.train_batch_size,\n",
    "    per_device_eval_batch_size=CFG_For_MLM.eval_batch_size,\n",
    "    learning_rate=CFG_For_MLM.learning_rate,\n",
    "    gradient_accumulation_steps=CFG_For_MLM.gradient_accum_steps,\n",
    "    fp16=CFG_For_MLM.fp16,\n",
    "    eval_steps=CFG_For_MLM.eval_steps,\n",
    "    save_steps=CFG_For_MLM.eval_steps,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    "    prediction_loss_only=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "competitive-alarm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "LmU2Kx_p3qGh",
    "outputId": "af2949ed-2e87-4fc6-f76d-ec502ad1ea4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 222180\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 104145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='104145' max='104145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [104145/104145 11:16:46, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6940</td>\n",
       "      <td>1.201600</td>\n",
       "      <td>1.114726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13880</td>\n",
       "      <td>1.038100</td>\n",
       "      <td>0.989183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20820</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.922088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27760</td>\n",
       "      <td>0.904200</td>\n",
       "      <td>0.889698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34700</td>\n",
       "      <td>0.876100</td>\n",
       "      <td>0.862807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41640</td>\n",
       "      <td>0.834800</td>\n",
       "      <td>0.841693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48580</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>0.823397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55520</td>\n",
       "      <td>0.782800</td>\n",
       "      <td>0.803339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62460</td>\n",
       "      <td>0.764100</td>\n",
       "      <td>0.785638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69400</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>0.774078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76340</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>0.757124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83280</td>\n",
       "      <td>0.722400</td>\n",
       "      <td>0.745748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90220</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.738113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97160</td>\n",
       "      <td>0.695500</td>\n",
       "      <td>0.736439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104100</td>\n",
       "      <td>0.679500</td>\n",
       "      <td>0.725386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-6940\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-6940/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-6940/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-41640] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-13880\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-13880/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-13880/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-48580] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-20820\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-20820/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-20820/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-6940] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-27760\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-27760/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-27760/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-13880] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-34700\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-34700/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-34700/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-20820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-41640\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-41640/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-41640/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-27760] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-48580\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-48580/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-48580/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-34700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-55520\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-55520/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-55520/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-41640] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-62460\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-62460/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-62460/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-48580] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-69400\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-69400/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-69400/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-55520] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-76340\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-76340/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-76340/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-62460] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-83280\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-83280/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-83280/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-69400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-90220\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-90220/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-90220/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-76340] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-97160\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-97160/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-97160/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-83280] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 55562\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-104100\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-104100/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-104100/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-90220] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../output/nbme-score-clinical-patient-notes/nbme-exp006/checkpoint-104100 (score: 0.7253860831260681).\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp006\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp006/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(CFG.output_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp004.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
