{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "permanent-wichita",
   "metadata": {
    "id": "colored-security"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-protest",
   "metadata": {
    "id": "educational-operator"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-wayne",
   "metadata": {
    "id": "incorrect-greek"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extraordinary-grain",
   "metadata": {
    "id": "alive-granny"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp072\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controversial-undergraduate",
   "metadata": {
    "id": "heavy-prophet"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    max_char_len=None\n",
    "    pseudo_plain_path='../output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl'\n",
    "    n_pseudo_labels=100000\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=3\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=1\n",
    "    n_fold=4\n",
    "    train_fold=[0, 1, 2, 3]  # [0, 1, 2, 3]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incident-compiler",
   "metadata": {
    "id": "vocational-coating"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-labor",
   "metadata": {
    "id": "private-moderator"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "danish-semiconductor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "married-tokyo",
    "outputId": "9c0fba66-759b-4354-898f-1afb47256d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers==4.16.2\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coordinate-catch",
   "metadata": {
    "id": "blank-pierre"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-matthew",
   "metadata": {
    "id": "sound-still"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "whole-background",
   "metadata": {
    "id": "surprised-commercial"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informed-rebate",
   "metadata": {
    "id": "interstate-accident"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        # result = np.where(char_prob >= th)[0] + 1\n",
    "        result = np.where(char_prob >= th)[0]\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        # result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = [f\"{min(r)} {max(r) + 1}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5, use_token_prob=True):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    if use_token_prob:\n",
    "        token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "        char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    else:\n",
    "        char_probs = df[[str(i) for i in range(CFG.max_char_len)]].values\n",
    "        char_probs = [char_probs[i] for i in range(len(char_probs))]\n",
    "\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collectible-ferry",
   "metadata": {
    "id": "coated-pioneer"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "answering-white",
   "metadata": {
    "id": "nervous-delaware"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-greeting",
   "metadata": {
    "id": "functioning-destruction"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inside-israeli",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "global-monte",
    "outputId": "77675ef9-9cb4-44a4-ebeb-ae9e74d7ebd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "technological-harvard",
   "metadata": {
    "id": "independent-airfare"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-fleet",
   "metadata": {
    "id": "silent-locator"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "willing-rough",
   "metadata": {
    "id": "unusual-fifty"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "funny-concentration",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "decreased-mustang",
    "outputId": "61c7d744-fde7-4d3c-e0c2-8393e24159b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dutch-transformation",
   "metadata": {
    "id": "boolean-trade"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "frozen-union",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "accomplished-dakota",
    "outputId": "0c1b9ec8-3c61-4a44-bafe-fb9ea649d668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-replication",
   "metadata": {
    "id": "funded-elizabeth"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "inner-treatment",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "unexpected-columbia",
    "outputId": "e4b2bd12-a470-45e9-89f8-18f01bfb8836"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    3575\n",
       "1    3575\n",
       "2    3575\n",
       "3    3575\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "groups = train['pn_num'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-dispatch",
   "metadata": {
    "id": "critical-archive"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loaded-warning",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "9826121100004ec49f1cd7ed26023d9f",
      "cfc527e5b7e84c45af32ba7e49275790",
      "33bbf6ff0a9847fc9900a16ea8247120",
      "1c64feffa14d4a56b3bf4c25f6d05c51",
      "b42a1221467e43648126dc9432be0b28",
      "1c619fc144a44ae8ba6d091c236a20f6",
      "f3dcb10079874c84a85896aae581b1dc",
      "61d290b99d78422494bd99ba7f4ce0b4",
      "511fe7d1f0db48f5848e3539ddb29fff",
      "1fc34ac85840429e8d5d62785817dd03",
      "c7dbd264bb804aabbb9a3a3922cdcc00",
      "a2fc47910e5a4b158eddf7faa455d683",
      "808441188c1a4b5788ae84fa3edf27db",
      "638cf831bc0443658b4b455200f9b990",
      "c5ad324c87914e26ad665efcc418f354",
      "8254bfa8a6fa47dba57db5ba29dccaeb",
      "3d505cf1fb134928953da8d79d68665a",
      "81714296902f4d26a32aa05da8890693",
      "8f0a30d22d004fd6866556696346fb74",
      "5504bc5bee8c4c189614fd398d1b7fef",
      "5a47b531ee814b1eba201f0aa79212db",
      "7c1442db3949418184bfb68266910d91",
      "f61172e130474199999fe10c8470b1e8",
      "530069c0165e4b3d8e077e9c6a4a1d21",
      "323239c2e16449c088afd6eb5eeaa73f",
      "263650ffbf3145048f331827b49ef11b",
      "7ebb3f8b10154ef4badb2d6856140d18",
      "2c0468cceac144b890d30b510202deba",
      "b4c22ff3f7064b5c82b501058fa367a6",
      "b5f8f50bdaf843f1a938f6129848cd83",
      "0f0864ef340b49aaa9b4596e032163a7",
      "886eee1754fd42e185a7548aa44871f1",
      "ec232b9c334c4987b35fde837fac77da",
      "0c748174ece64ca6992b434a2d92e1e4",
      "827b5e8189d242c9b62bb8d6a084de72",
      "0f910e441d334b10bc666e6ef47de941",
      "09da6c904a3344ad9d7d0f17c646c8b1",
      "d6ba1f9a002c49268799fc4a17f793ee",
      "dc036c5ffc0a4a0fb2d0f504cf4264f3",
      "80be6bc8b1c8454187599fe6f05cdcba",
      "760cf6427cdc4b05affb72378d92a0f3",
      "9a660863781b487392504ab3302a5f93",
      "66daca2dd30d44efbcd88adcbb1c2725",
      "02633c7de1ea4b7ca2fd899ae0c6d209"
     ]
    },
    "id": "broken-generator",
    "outputId": "9ed5f1df-2a6b-4b0d-bbfb-dd49474e17ea"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-split",
   "metadata": {
    "id": "compatible-lincoln"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "married-maker",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "8e1aca2f17c6476a855cbe11a1d661a9",
      "aa1104924af9458eb0d5443fd617cf29",
      "b94dd392dc874911b1deeb39f77b342f",
      "be8e2f5fc8eb4029a4aece3d1776054d",
      "032d2a594c45472e9681d2d7557ab93d",
      "cd01049905654fe6bee6c4c602b89ed9",
      "66a3685d05e1493c987e6cb1d9ed00a1",
      "13133c559d1b4a14ba19c157c169b532",
      "7e01c08e3af148f580fcdc6ef6ebf5b4",
      "e464d1ba21a1489183fda5c01bbc0cca",
      "5bb3e7fc97c64d59a20a7ebb29a39800"
     ]
    },
    "id": "fluid-nancy",
    "outputId": "9b844ea4-2568-4dea-dd39-867dcb402cfe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff94656c332401c80109c7a8361bdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 433\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "international-blood",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "6639cae9d2844ea3b7d9a777b43b2181",
      "6e5be1d244794198afee6c8fefd3a191",
      "2df59efc32cf4642a4cfff7db709db5a",
      "72d201f9470a4d04b1e89f7d0018c0d7",
      "cebcd629be2340bfa4ca1780d70dd364",
      "da9bce59ac4845cda340d840b79be311",
      "323befd254f741a7b041d124d4073817",
      "eb191fc8e771447ab389bbb57fe22d2f",
      "ced0845b868342c29d4e2d830a48f203",
      "13873604cb644df0b4b5e8e9ea57d645",
      "f129267b3ae6422e8d345c28b73f5516"
     ]
    },
    "id": "posted-humidity",
    "outputId": "c23cdcb5-4093-47d7-d95c-a35eaf72ea9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495062fb208942a09669a35fde60a56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 30\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "identical-relations",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "resistant-amount",
    "outputId": "8bc2659a-d25a-40a1-f85d-37d57b1f3fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 466\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "plain-williams",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "4c276b71af2f4301b4048e4f8dad36d3",
      "563519b534874ec8a145d292258b2dad",
      "535a8156a6da43928fd0d7a33c624540",
      "ef3dd8c9fb4a46bfa6c30489d2d75b02",
      "5d985ee5c7d84bf9a135972d46830ad0",
      "5bc25dd928614ba999cefcde5efa9197",
      "5ccb74cb082845d7ade9962f741a2910",
      "8fa83fd7255f43ff9126aa633ed1b663",
      "9febd109d3a24bef886c8d24808347ba",
      "811a7f7f9bc34108b113d084a7d488f4",
      "ecfdf18519e34e2d9a0b112b0815cba5"
     ]
    },
    "id": "be6XpsR0aIWS",
    "outputId": "1af87d7f-23bc-4035-d4c2-08d1f778e070"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c36c123778b447c9fd3ca6af01636e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 950\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(text)\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "CFG.max_char_len = max(pn_history_lengths)\n",
    "\n",
    "print(\"max length:\", CFG.max_char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "variable-fisher",
   "metadata": {
    "id": "fIzpppqiaMRn"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df, pseudo_label=None):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.max_char_len = self.cfg.max_char_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "        if \"pseudo_idx\" in df.columns:\n",
    "            self.pseudo_idx = self.df[\"pseudo_idx\"].values\n",
    "            self.pseudo_label = pseudo_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_mapping_from_token_to_char(self, pn_history):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        mapping_from_token_to_char = np.zeros(self.max_char_len)\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        for i, offset in enumerate(offset_mapping):\n",
    "            start_idx, end_idx = offset\n",
    "            mapping_from_token_to_char[start_idx:end_idx] = i\n",
    "        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        label = np.zeros(self.max_char_len)\n",
    "        label[len(pn_history):] = -1\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    label[start:end] = 1\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        if not np.isnan(self.annotation_lengths[idx]):\n",
    "            label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        else:\n",
    "            p_idx = int(self.pseudo_idx[idx])\n",
    "            label = torch.tensor(self.pseudo_label[p_idx], dtype=torch.float)\n",
    "        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n",
    "        return input_, label, mapping_from_token_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "coastal-respondent",
   "metadata": {
    "id": "weird-interaction"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.max_char_len = self.cfg.max_char_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_mapping_from_token_to_char(self, pn_history):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        mapping_from_token_to_char = np.zeros(self.max_char_len)\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        for i, offset in enumerate(offset_mapping):\n",
    "            start_idx, end_idx = offset\n",
    "            mapping_from_token_to_char[start_idx:end_idx] = i\n",
    "        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n",
    "        return input_, mapping_from_token_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-realtor",
   "metadata": {
    "id": "upper-mobility"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "simple-finding",
   "metadata": {
    "id": "spanish-destruction"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            # path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n",
    "            state_dict = torch.load(path)\n",
    "            itpt.load_state_dict(state_dict)\n",
    "            self.backbone = itpt.deberta\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.lstm = nn.GRU(\n",
    "            input_size=self.model_config.hidden_size,\n",
    "            bidirectional=True,\n",
    "            hidden_size=self.model_config.hidden_size // 2,\n",
    "            num_layers=4,\n",
    "            dropout=self.cfg.dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, mappings_from_token_to_char):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]  # [batch, seq_len, d_model]\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.unsqueeze(2).expand(-1, -1, self.model_config.hidden_size)\n",
    "        h = torch.gather(h, 1, mappings_from_token_to_char)    # [batch, seq_len, d_model]\n",
    "        h, _ = self.lstm(h)\n",
    "        output = self.fc(h)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-produce",
   "metadata": {
    "id": "chronic-bullet"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coastal-seating",
   "metadata": {
    "id": "biological-hunger"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device) \n",
    "        batch_size = labels.size(0)\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs, mappings_from_token_to_char)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    del output, loss, inputs, labels, mappings_from_token_to_char, scaler, grad_norm; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "described-durham",
   "metadata": {
    "id": "satisfied-sterling"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device) \n",
    "        batch_size = labels.size(0)\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs, mappings_from_token_to_char)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "        loss = loss.mean()\n",
    "    \n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "valid-supervision",
   "metadata": {
    "id": "incorporate-viking"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for (inputs, mappings_from_token_to_char) in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs, mappings_from_token_to_char)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "monthly-malawi",
   "metadata": {
    "id": "dental-sunset"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    if CFG.pseudo_plain_path is not None:\n",
    "        pseudo_plain = pd.read_pickle(CFG.pseudo_plain_path)\n",
    "        print(f\"get pseudo plain from {CFG.pseudo_plain_path}\")\n",
    "        pseudo_label_list = []\n",
    "        for exp_name in [\"nbme-exp060\", \"nbme-exp067\"]:\n",
    "            pseudo_label_path = f'../output/nbme-score-clinical-patient-notes/{exp_name}/pseudo_labels_{i_fold}.npy'\n",
    "            pseudo_label = np.load(pseudo_label_path)\n",
    "            print(f\"get pseudo labels from {pseudo_label_path}\")\n",
    "            pseudo_label_list.append(pseudo_label)\n",
    "    \n",
    "        pseudo_label = 0.5 * pseudo_label_list[0] + 0.5 * pseudo_label_list[1]\n",
    "        print(pseudo_plain.shape, pseudo_label.shape)\n",
    "\n",
    "        pseudo_plain[\"pseudo_idx\"] = np.arange(len(pseudo_plain))\n",
    "        pseudo_plain = pseudo_plain.sample(n=CFG.n_pseudo_labels, random_state=i_fold+100)\n",
    "        print(pseudo_plain.shape)\n",
    "        train_folds = pd.concat([train_folds, pseudo_plain], axis=0, ignore_index=True)\n",
    "        print(train_folds.shape)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds, pseudo_label)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    # model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    path = f\"../output/nbme-score-clinical-patient-notes/nbme-exp070/fold{i_fold}_best.pth\"\n",
    "    state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    best_score = -1 * np.inf\n",
    "    \n",
    "    if i_fold == 3:\n",
    "        for epoch in range(CFG.epochs):\n",
    "            start_time = time.time()\n",
    "            avg_loss = train_fn(\n",
    "                train_dataloader,\n",
    "                model,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                epoch,\n",
    "                scheduler,\n",
    "                device,\n",
    "            )\n",
    "            avg_val_loss, val_preds = valid_fn(\n",
    "                val_dataloader,\n",
    "                model,\n",
    "                criterion,\n",
    "                device,\n",
    "            )\n",
    "\n",
    "            if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "                scheduler.step()\n",
    "\n",
    "            # scoring\n",
    "            val_folds[[str(i) for i in range(CFG.max_char_len)]] = val_preds\n",
    "            score = scoring(val_folds, th=0.5, use_token_prob=False)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "            print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "                torch.save({\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"predictions\": val_preds,\n",
    "                    },\n",
    "                    CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "                )\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_char_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-memory",
   "metadata": {
    "id": "brazilian-graphics"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fourth-wilson",
   "metadata": {
    "id": "connected-protein"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    best_thres = 0.5\n",
    "    best_score = 0.\n",
    "    for th in np.arange(0.45, 0.55, 0.01):\n",
    "        th = np.round(th, 2)\n",
    "        score = scoring(oof_df, th=th, use_token_prob=False)\n",
    "        if best_score < score:\n",
    "            best_thres = th\n",
    "            best_score = score\n",
    "    print(f\"best_thres: {best_thres}  score: {best_score:.5f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            print(f\"load weights from {path}\")\n",
    "            test_char_probs = inference_fn(test_dataloader, model, device)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_char_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "individual-evidence",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "64961f62c5f94c3991e2b9f09c7c4782",
      "8cc41478e6584c039ec440aa3c314e6d",
      "5a5fdc30f42646058b9162b0e0974e3d",
      "c74b2e0635904f98920a922b26b6541d"
     ]
    },
    "id": "serious-bunny",
    "outputId": "be850b3e-328a-47cf-b797-2d51d289e13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "get pseudo plain from ../output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_0.npy\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_0.npy\n",
      "(612602, 6) (612602, 950)\n",
      "(100000, 7)\n",
      "(110725, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "========== fold: 1 training ==========\n",
      "get pseudo plain from ../output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_1.npy\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_1.npy\n",
      "(612602, 6) (612602, 950)\n",
      "(100000, 7)\n",
      "(110725, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "========== fold: 2 training ==========\n",
      "get pseudo plain from ../output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_2.npy\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_2.npy\n",
      "(612602, 6) (612602, 950)\n",
      "(100000, 7)\n",
      "(110725, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "========== fold: 3 training ==========\n",
      "get pseudo plain from ../output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_3.npy\n",
      "get pseudo labels from ../output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_3.npy\n",
      "(612602, 6) (612602, 950)\n",
      "(100000, 7)\n",
      "(110725, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "Epoch: [1][0/36908] Elapsed 0m 1s (remain 912m 38s) Loss: 0.0010(0.0010) Grad: 450.4889  LR: 0.000000  \n",
      "Epoch: [1][100/36908] Elapsed 1m 23s (remain 505m 41s) Loss: 0.0002(0.0026) Grad: 404.0653  LR: 0.000001  \n",
      "Epoch: [1][200/36908] Elapsed 2m 45s (remain 503m 23s) Loss: 0.0006(0.0023) Grad: 1369.2100  LR: 0.000001  \n",
      "Epoch: [1][300/36908] Elapsed 4m 8s (remain 502m 46s) Loss: 0.0011(0.0023) Grad: 530.5303  LR: 0.000002  \n",
      "Epoch: [1][400/36908] Elapsed 5m 29s (remain 500m 17s) Loss: 0.0006(0.0023) Grad: 1042.7704  LR: 0.000002  \n",
      "Epoch: [1][500/36908] Elapsed 6m 52s (remain 499m 30s) Loss: 0.0002(0.0024) Grad: 157.3147  LR: 0.000003  \n",
      "Epoch: [1][600/36908] Elapsed 8m 15s (remain 499m 3s) Loss: 0.0041(0.0023) Grad: 4724.8784  LR: 0.000003  \n",
      "Epoch: [1][700/36908] Elapsed 9m 38s (remain 498m 14s) Loss: 0.0004(0.0023) Grad: 281.9441  LR: 0.000004  \n",
      "Epoch: [1][800/36908] Elapsed 11m 1s (remain 496m 51s) Loss: 0.0002(0.0023) Grad: 35.8569  LR: 0.000004  \n",
      "Epoch: [1][900/36908] Elapsed 12m 23s (remain 495m 28s) Loss: 0.0003(0.0023) Grad: 100.5352  LR: 0.000005  \n",
      "Epoch: [1][1000/36908] Elapsed 13m 47s (remain 494m 47s) Loss: 0.0115(0.0023) Grad: 28766.1934  LR: 0.000005  \n",
      "Epoch: [1][1100/36908] Elapsed 15m 10s (remain 493m 46s) Loss: 0.0005(0.0023) Grad: 438.7683  LR: 0.000006  \n",
      "Epoch: [1][1200/36908] Elapsed 16m 35s (remain 493m 14s) Loss: 0.0001(0.0024) Grad: 191.2978  LR: 0.000007  \n",
      "Epoch: [1][1300/36908] Elapsed 17m 58s (remain 492m 1s) Loss: 0.0031(0.0024) Grad: 4794.8882  LR: 0.000007  \n",
      "Epoch: [1][1400/36908] Elapsed 19m 21s (remain 490m 46s) Loss: 0.0007(0.0024) Grad: 809.3721  LR: 0.000008  \n",
      "Epoch: [1][1500/36908] Elapsed 20m 46s (remain 489m 54s) Loss: 0.0005(0.0024) Grad: 381.7194  LR: 0.000008  \n",
      "Epoch: [1][1600/36908] Elapsed 22m 9s (remain 488m 44s) Loss: 0.0001(0.0024) Grad: 22.3561  LR: 0.000009  \n",
      "Epoch: [1][1700/36908] Elapsed 23m 34s (remain 487m 58s) Loss: 0.0040(0.0024) Grad: 6412.8633  LR: 0.000009  \n",
      "Epoch: [1][1800/36908] Elapsed 24m 58s (remain 486m 47s) Loss: 0.0001(0.0024) Grad: 238.8336  LR: 0.000010  \n",
      "Epoch: [1][1900/36908] Elapsed 26m 21s (remain 485m 24s) Loss: 0.0001(0.0024) Grad: 127.3954  LR: 0.000010  \n",
      "Epoch: [1][2000/36908] Elapsed 27m 44s (remain 484m 0s) Loss: 0.0023(0.0024) Grad: 1666.9125  LR: 0.000011  \n",
      "Epoch: [1][2100/36908] Elapsed 29m 9s (remain 482m 58s) Loss: 0.0005(0.0024) Grad: 209.2914  LR: 0.000011  \n",
      "Epoch: [1][2200/36908] Elapsed 30m 32s (remain 481m 39s) Loss: 0.0010(0.0024) Grad: 701.0945  LR: 0.000012  \n",
      "Epoch: [1][2300/36908] Elapsed 31m 55s (remain 480m 14s) Loss: 0.0001(0.0024) Grad: 27.1995  LR: 0.000012  \n",
      "Epoch: [1][2400/36908] Elapsed 33m 19s (remain 478m 50s) Loss: 0.0029(0.0025) Grad: 5463.7969  LR: 0.000013  \n",
      "Epoch: [1][2500/36908] Elapsed 34m 42s (remain 477m 35s) Loss: 0.0011(0.0025) Grad: 923.7213  LR: 0.000014  \n",
      "Epoch: [1][2600/36908] Elapsed 36m 5s (remain 476m 9s) Loss: 0.0028(0.0025) Grad: 7132.6641  LR: 0.000014  \n",
      "Epoch: [1][2700/36908] Elapsed 37m 28s (remain 474m 42s) Loss: 0.0021(0.0025) Grad: 12133.2764  LR: 0.000015  \n",
      "Epoch: [1][2800/36908] Elapsed 38m 53s (remain 473m 31s) Loss: 0.0007(0.0025) Grad: 956.1152  LR: 0.000015  \n",
      "Epoch: [1][2900/36908] Elapsed 40m 17s (remain 472m 16s) Loss: 0.0002(0.0025) Grad: 316.1862  LR: 0.000016  \n",
      "Epoch: [1][3000/36908] Elapsed 41m 40s (remain 470m 53s) Loss: 0.0023(0.0025) Grad: 4261.4780  LR: 0.000016  \n",
      "Epoch: [1][3100/36908] Elapsed 43m 3s (remain 469m 23s) Loss: 0.0014(0.0025) Grad: 1919.2844  LR: 0.000017  \n",
      "Epoch: [1][3200/36908] Elapsed 44m 26s (remain 468m 3s) Loss: 0.0006(0.0025) Grad: 248.9264  LR: 0.000017  \n",
      "Epoch: [1][3300/36908] Elapsed 45m 49s (remain 466m 36s) Loss: 0.0024(0.0025) Grad: 2276.3430  LR: 0.000018  \n",
      "Epoch: [1][3400/36908] Elapsed 47m 13s (remain 465m 13s) Loss: 0.0007(0.0026) Grad: 424.8277  LR: 0.000018  \n",
      "Epoch: [1][3500/36908] Elapsed 48m 37s (remain 464m 0s) Loss: 0.0018(0.0026) Grad: 1162.7007  LR: 0.000019  \n",
      "Epoch: [1][3600/36908] Elapsed 50m 1s (remain 462m 40s) Loss: 0.0129(0.0026) Grad: 43882.1406  LR: 0.000020  \n",
      "Epoch: [1][3700/36908] Elapsed 51m 23s (remain 461m 10s) Loss: 0.0001(0.0026) Grad: 176.3756  LR: 0.000020  \n",
      "Epoch: [1][3800/36908] Elapsed 52m 47s (remain 459m 45s) Loss: 0.0006(0.0026) Grad: 7821.1548  LR: 0.000020  \n",
      "Epoch: [1][3900/36908] Elapsed 54m 11s (remain 458m 27s) Loss: 0.0013(0.0025) Grad: 1783.8444  LR: 0.000020  \n",
      "Epoch: [1][4000/36908] Elapsed 55m 33s (remain 456m 58s) Loss: 0.0014(0.0025) Grad: 22486.5684  LR: 0.000020  \n",
      "Epoch: [1][4100/36908] Elapsed 56m 56s (remain 455m 29s) Loss: 0.0039(0.0026) Grad: 24481.9082  LR: 0.000020  \n",
      "Epoch: [1][4200/36908] Elapsed 58m 19s (remain 454m 2s) Loss: 0.0009(0.0026) Grad: 4658.4814  LR: 0.000020  \n",
      "Epoch: [1][4300/36908] Elapsed 59m 43s (remain 452m 47s) Loss: 0.0003(0.0026) Grad: 121.5576  LR: 0.000020  \n",
      "Epoch: [1][4400/36908] Elapsed 61m 7s (remain 451m 29s) Loss: 0.0008(0.0026) Grad: 688.7643  LR: 0.000020  \n",
      "Epoch: [1][4500/36908] Elapsed 62m 30s (remain 450m 5s) Loss: 0.0028(0.0026) Grad: 31578.6797  LR: 0.000020  \n",
      "Epoch: [1][4600/36908] Elapsed 63m 54s (remain 448m 47s) Loss: 0.0007(0.0026) Grad: 454.6711  LR: 0.000019  \n",
      "Epoch: [1][4700/36908] Elapsed 65m 18s (remain 447m 28s) Loss: 0.0066(0.0026) Grad: 9496.9531  LR: 0.000019  \n",
      "Epoch: [1][4800/36908] Elapsed 66m 42s (remain 446m 6s) Loss: 0.0036(0.0026) Grad: 17493.3125  LR: 0.000019  \n",
      "Epoch: [1][4900/36908] Elapsed 68m 5s (remain 444m 39s) Loss: 0.0095(0.0026) Grad: 20776.3652  LR: 0.000019  \n",
      "Epoch: [1][5000/36908] Elapsed 69m 27s (remain 443m 11s) Loss: 0.0000(0.0026) Grad: 59.2372  LR: 0.000019  \n",
      "Epoch: [1][5100/36908] Elapsed 70m 51s (remain 441m 51s) Loss: 0.0013(0.0026) Grad: 6444.2983  LR: 0.000019  \n",
      "Epoch: [1][5200/36908] Elapsed 72m 15s (remain 440m 33s) Loss: 0.0000(0.0026) Grad: 15.9463  LR: 0.000019  \n",
      "Epoch: [1][5300/36908] Elapsed 73m 39s (remain 439m 8s) Loss: 0.0058(0.0026) Grad: 5100.0161  LR: 0.000019  \n",
      "Epoch: [1][5400/36908] Elapsed 75m 3s (remain 437m 49s) Loss: 0.0012(0.0026) Grad: 3333.0271  LR: 0.000019  \n",
      "Epoch: [1][5500/36908] Elapsed 76m 26s (remain 436m 27s) Loss: 0.0014(0.0026) Grad: 15314.8057  LR: 0.000019  \n",
      "Epoch: [1][5600/36908] Elapsed 77m 49s (remain 434m 58s) Loss: 0.0049(0.0026) Grad: 24354.5234  LR: 0.000019  \n",
      "Epoch: [1][5700/36908] Elapsed 79m 12s (remain 433m 33s) Loss: 0.0004(0.0026) Grad: 929.8456  LR: 0.000019  \n",
      "Epoch: [1][5800/36908] Elapsed 80m 34s (remain 432m 6s) Loss: 0.0019(0.0026) Grad: 1964.6022  LR: 0.000019  \n",
      "Epoch: [1][5900/36908] Elapsed 81m 58s (remain 430m 45s) Loss: 0.0006(0.0026) Grad: 1295.2213  LR: 0.000019  \n",
      "Epoch: [1][6000/36908] Elapsed 83m 22s (remain 429m 25s) Loss: 0.0036(0.0026) Grad: 1306.0640  LR: 0.000019  \n",
      "Epoch: [1][6100/36908] Elapsed 84m 46s (remain 428m 2s) Loss: 0.0051(0.0026) Grad: 26111.8047  LR: 0.000019  \n",
      "Epoch: [1][6200/36908] Elapsed 86m 9s (remain 426m 38s) Loss: 0.0003(0.0026) Grad: 485.5301  LR: 0.000018  \n",
      "Epoch: [1][6300/36908] Elapsed 87m 32s (remain 425m 14s) Loss: 0.0029(0.0026) Grad: 12893.0605  LR: 0.000018  \n",
      "Epoch: [1][6400/36908] Elapsed 88m 55s (remain 423m 48s) Loss: 0.0002(0.0026) Grad: 379.2093  LR: 0.000018  \n",
      "Epoch: [1][6500/36908] Elapsed 90m 18s (remain 422m 22s) Loss: 0.0007(0.0026) Grad: 2994.1672  LR: 0.000018  \n",
      "Epoch: [1][6600/36908] Elapsed 91m 42s (remain 421m 2s) Loss: 0.0014(0.0026) Grad: 5543.6865  LR: 0.000018  \n",
      "Epoch: [1][6700/36908] Elapsed 93m 5s (remain 419m 39s) Loss: 0.0008(0.0026) Grad: 1656.4868  LR: 0.000018  \n",
      "Epoch: [1][6800/36908] Elapsed 94m 28s (remain 418m 14s) Loss: 0.0030(0.0026) Grad: 7057.1216  LR: 0.000018  \n",
      "Epoch: [1][6900/36908] Elapsed 95m 51s (remain 416m 47s) Loss: 0.0002(0.0026) Grad: 1571.3457  LR: 0.000018  \n",
      "Epoch: [1][7000/36908] Elapsed 97m 14s (remain 415m 22s) Loss: 0.0019(0.0026) Grad: 6722.7881  LR: 0.000018  \n",
      "Epoch: [1][7100/36908] Elapsed 98m 38s (remain 414m 4s) Loss: 0.0021(0.0026) Grad: 18171.9141  LR: 0.000018  \n",
      "Epoch: [1][7200/36908] Elapsed 100m 1s (remain 412m 38s) Loss: 0.0011(0.0026) Grad: 3981.9741  LR: 0.000018  \n",
      "Epoch: [1][7300/36908] Elapsed 101m 24s (remain 411m 12s) Loss: 0.0242(0.0026) Grad: 27412.6602  LR: 0.000018  \n",
      "Epoch: [1][7400/36908] Elapsed 102m 48s (remain 409m 51s) Loss: 0.0022(0.0026) Grad: 7821.4927  LR: 0.000018  \n",
      "Epoch: [1][7500/36908] Elapsed 104m 10s (remain 408m 25s) Loss: 0.0000(0.0026) Grad: 11.8552  LR: 0.000018  \n",
      "Epoch: [1][7600/36908] Elapsed 105m 34s (remain 407m 4s) Loss: 0.0028(0.0026) Grad: 7757.2515  LR: 0.000018  \n",
      "Epoch: [1][7700/36908] Elapsed 106m 57s (remain 405m 39s) Loss: 0.0059(0.0026) Grad: 10959.6602  LR: 0.000018  \n",
      "Epoch: [1][7800/36908] Elapsed 108m 19s (remain 404m 11s) Loss: 0.0062(0.0026) Grad: 14830.9717  LR: 0.000018  \n",
      "Epoch: [1][7900/36908] Elapsed 109m 44s (remain 402m 53s) Loss: 0.0007(0.0026) Grad: 137.3183  LR: 0.000017  \n",
      "Epoch: [1][8000/36908] Elapsed 111m 8s (remain 401m 32s) Loss: 0.0001(0.0026) Grad: 20.5770  LR: 0.000017  \n",
      "Epoch: [1][8100/36908] Elapsed 112m 30s (remain 400m 5s) Loss: 0.0020(0.0026) Grad: 21191.8164  LR: 0.000017  \n",
      "Epoch: [1][8200/36908] Elapsed 113m 53s (remain 398m 39s) Loss: 0.0019(0.0026) Grad: 34046.4805  LR: 0.000017  \n",
      "Epoch: [1][8300/36908] Elapsed 115m 16s (remain 397m 17s) Loss: 0.0054(0.0026) Grad: 36930.1367  LR: 0.000017  \n",
      "Epoch: [1][8400/36908] Elapsed 116m 40s (remain 395m 54s) Loss: 0.0023(0.0026) Grad: 50691.1328  LR: 0.000017  \n",
      "Epoch: [1][8500/36908] Elapsed 118m 2s (remain 394m 28s) Loss: 0.0012(0.0026) Grad: 4940.3657  LR: 0.000017  \n",
      "Epoch: [1][8600/36908] Elapsed 119m 25s (remain 393m 3s) Loss: 0.0001(0.0026) Grad: 38.2771  LR: 0.000017  \n",
      "Epoch: [1][8700/36908] Elapsed 120m 48s (remain 391m 38s) Loss: 0.0043(0.0026) Grad: 16661.3066  LR: 0.000017  \n",
      "Epoch: [1][8800/36908] Elapsed 122m 12s (remain 390m 17s) Loss: 0.0093(0.0026) Grad: 15095.5000  LR: 0.000017  \n",
      "Epoch: [1][8900/36908] Elapsed 123m 35s (remain 388m 52s) Loss: 0.0002(0.0026) Grad: 2437.2451  LR: 0.000017  \n",
      "Epoch: [1][9000/36908] Elapsed 124m 58s (remain 387m 27s) Loss: 0.0036(0.0026) Grad: 29766.6621  LR: 0.000017  \n",
      "Epoch: [1][9100/36908] Elapsed 126m 22s (remain 386m 6s) Loss: 0.0026(0.0026) Grad: 6860.2061  LR: 0.000017  \n",
      "Epoch: [1][9200/36908] Elapsed 127m 45s (remain 384m 42s) Loss: 0.0004(0.0026) Grad: 3544.0657  LR: 0.000017  \n",
      "Epoch: [1][9300/36908] Elapsed 129m 9s (remain 383m 21s) Loss: 0.0015(0.0026) Grad: 27587.9355  LR: 0.000017  \n",
      "Epoch: [1][9400/36908] Elapsed 130m 33s (remain 382m 0s) Loss: 0.0002(0.0026) Grad: 2323.5344  LR: 0.000017  \n",
      "Epoch: [1][9500/36908] Elapsed 131m 57s (remain 380m 39s) Loss: 0.0019(0.0026) Grad: 7107.3086  LR: 0.000017  \n",
      "Epoch: [1][9600/36908] Elapsed 133m 20s (remain 379m 14s) Loss: 0.0001(0.0026) Grad: 147.7118  LR: 0.000016  \n",
      "Epoch: [1][9700/36908] Elapsed 134m 43s (remain 377m 49s) Loss: 0.0010(0.0026) Grad: 15817.7012  LR: 0.000016  \n",
      "Epoch: [1][9800/36908] Elapsed 136m 5s (remain 376m 23s) Loss: 0.0068(0.0026) Grad: 17114.0312  LR: 0.000016  \n",
      "Epoch: [1][9900/36908] Elapsed 137m 29s (remain 375m 1s) Loss: 0.0032(0.0026) Grad: 6142.4790  LR: 0.000016  \n",
      "Epoch: [1][10000/36908] Elapsed 138m 52s (remain 373m 38s) Loss: 0.0050(0.0026) Grad: 21633.9961  LR: 0.000016  \n",
      "Epoch: [1][10100/36908] Elapsed 140m 15s (remain 372m 14s) Loss: 0.0003(0.0026) Grad: 52.6425  LR: 0.000016  \n",
      "Epoch: [1][10200/36908] Elapsed 141m 39s (remain 370m 53s) Loss: 0.0003(0.0026) Grad: 1454.3115  LR: 0.000016  \n",
      "Epoch: [1][10300/36908] Elapsed 143m 2s (remain 369m 28s) Loss: 0.0008(0.0026) Grad: 1448.7004  LR: 0.000016  \n",
      "Epoch: [1][10400/36908] Elapsed 144m 25s (remain 368m 5s) Loss: 0.0016(0.0026) Grad: 53658.5508  LR: 0.000016  \n",
      "Epoch: [1][10500/36908] Elapsed 145m 49s (remain 366m 42s) Loss: 0.0044(0.0026) Grad: 39323.8477  LR: 0.000016  \n",
      "Epoch: [1][10600/36908] Elapsed 147m 12s (remain 365m 18s) Loss: 0.0001(0.0026) Grad: 28.7457  LR: 0.000016  \n",
      "Epoch: [1][10700/36908] Elapsed 148m 36s (remain 363m 56s) Loss: 0.0009(0.0026) Grad: 977.8738  LR: 0.000016  \n",
      "Epoch: [1][10800/36908] Elapsed 149m 59s (remain 362m 33s) Loss: 0.0001(0.0026) Grad: 936.5151  LR: 0.000016  \n",
      "Epoch: [1][10900/36908] Elapsed 151m 22s (remain 361m 7s) Loss: 0.0001(0.0026) Grad: 51.8715  LR: 0.000016  \n",
      "Epoch: [1][11000/36908] Elapsed 152m 45s (remain 359m 43s) Loss: 0.0043(0.0026) Grad: 15713.6201  LR: 0.000016  \n",
      "Epoch: [1][11100/36908] Elapsed 154m 7s (remain 358m 18s) Loss: 0.0033(0.0026) Grad: 20372.2871  LR: 0.000016  \n",
      "Epoch: [1][11200/36908] Elapsed 155m 31s (remain 356m 55s) Loss: 0.0022(0.0026) Grad: 2469.9102  LR: 0.000015  \n",
      "Epoch: [1][11300/36908] Elapsed 156m 53s (remain 355m 30s) Loss: 0.0023(0.0026) Grad: 44229.7617  LR: 0.000015  \n",
      "Epoch: [1][11400/36908] Elapsed 158m 17s (remain 354m 7s) Loss: 0.0003(0.0026) Grad: 942.6193  LR: 0.000015  \n",
      "Epoch: [1][11500/36908] Elapsed 159m 39s (remain 352m 42s) Loss: 0.0000(0.0026) Grad: 471.8043  LR: 0.000015  \n",
      "Epoch: [1][11600/36908] Elapsed 161m 2s (remain 351m 17s) Loss: 0.0001(0.0026) Grad: 252.0172  LR: 0.000015  \n",
      "Epoch: [1][11700/36908] Elapsed 162m 26s (remain 349m 56s) Loss: 0.0009(0.0026) Grad: 248.2387  LR: 0.000015  \n",
      "Epoch: [1][11800/36908] Elapsed 163m 50s (remain 348m 35s) Loss: 0.0002(0.0026) Grad: 249.9060  LR: 0.000015  \n",
      "Epoch: [1][11900/36908] Elapsed 165m 13s (remain 347m 11s) Loss: 0.0023(0.0026) Grad: 5328.8779  LR: 0.000015  \n",
      "Epoch: [1][12000/36908] Elapsed 166m 37s (remain 345m 48s) Loss: 0.0000(0.0026) Grad: 33.4794  LR: 0.000015  \n",
      "Epoch: [1][12100/36908] Elapsed 168m 1s (remain 344m 26s) Loss: 0.0001(0.0026) Grad: 62.0786  LR: 0.000015  \n",
      "Epoch: [1][12200/36908] Elapsed 169m 24s (remain 343m 3s) Loss: 0.0026(0.0026) Grad: 28682.2715  LR: 0.000015  \n",
      "Epoch: [1][12300/36908] Elapsed 170m 47s (remain 341m 39s) Loss: 0.0012(0.0026) Grad: 9003.2148  LR: 0.000015  \n",
      "Epoch: [1][12400/36908] Elapsed 172m 11s (remain 340m 17s) Loss: 0.0004(0.0026) Grad: 3794.6367  LR: 0.000015  \n",
      "Epoch: [1][12500/36908] Elapsed 173m 35s (remain 338m 55s) Loss: 0.0012(0.0026) Grad: 5221.1743  LR: 0.000015  \n",
      "Epoch: [1][12600/36908] Elapsed 174m 58s (remain 337m 30s) Loss: 0.0006(0.0026) Grad: 6411.0532  LR: 0.000015  \n",
      "Epoch: [1][12700/36908] Elapsed 176m 21s (remain 336m 7s) Loss: 0.0035(0.0026) Grad: 27335.6855  LR: 0.000015  \n",
      "Epoch: [1][12800/36908] Elapsed 177m 46s (remain 334m 46s) Loss: 0.0000(0.0026) Grad: 57.8853  LR: 0.000015  \n",
      "Epoch: [1][12900/36908] Elapsed 179m 10s (remain 333m 25s) Loss: 0.0018(0.0026) Grad: 16003.9863  LR: 0.000014  \n",
      "Epoch: [1][13000/36908] Elapsed 180m 34s (remain 332m 2s) Loss: 0.0001(0.0026) Grad: 101.0914  LR: 0.000014  \n",
      "Epoch: [1][13100/36908] Elapsed 181m 56s (remain 330m 38s) Loss: 0.0000(0.0026) Grad: 218.5536  LR: 0.000014  \n",
      "Epoch: [1][13200/36908] Elapsed 183m 20s (remain 329m 15s) Loss: 0.0010(0.0026) Grad: 7257.3423  LR: 0.000014  \n",
      "Epoch: [1][13300/36908] Elapsed 184m 45s (remain 327m 54s) Loss: 0.0038(0.0026) Grad: 44628.3242  LR: 0.000014  \n",
      "Epoch: [1][13400/36908] Elapsed 186m 8s (remain 326m 31s) Loss: 0.0039(0.0026) Grad: 54677.3945  LR: 0.000014  \n",
      "Epoch: [1][13500/36908] Elapsed 187m 31s (remain 325m 6s) Loss: 0.0002(0.0026) Grad: 3451.6160  LR: 0.000014  \n",
      "Epoch: [1][13600/36908] Elapsed 188m 54s (remain 323m 43s) Loss: 0.0001(0.0026) Grad: 205.7417  LR: 0.000014  \n",
      "Epoch: [1][13700/36908] Elapsed 190m 18s (remain 322m 20s) Loss: 0.0036(0.0026) Grad: 26348.1523  LR: 0.000014  \n",
      "Epoch: [1][13800/36908] Elapsed 191m 41s (remain 320m 56s) Loss: 0.0001(0.0026) Grad: 93.4092  LR: 0.000014  \n",
      "Epoch: [1][13900/36908] Elapsed 193m 5s (remain 319m 35s) Loss: 0.0001(0.0026) Grad: 156.6330  LR: 0.000014  \n",
      "Epoch: [1][14000/36908] Elapsed 194m 29s (remain 318m 12s) Loss: 0.0098(0.0026) Grad: 343576.4375  LR: 0.000014  \n",
      "Epoch: [1][14100/36908] Elapsed 195m 53s (remain 316m 50s) Loss: 0.0003(0.0026) Grad: 132.0962  LR: 0.000014  \n",
      "Epoch: [1][14200/36908] Elapsed 197m 18s (remain 315m 28s) Loss: 0.0200(0.0026) Grad: 459867.5000  LR: 0.000014  \n",
      "Epoch: [1][14300/36908] Elapsed 198m 41s (remain 314m 5s) Loss: 0.0001(0.0026) Grad: 72.6685  LR: 0.000014  \n",
      "Epoch: [1][14400/36908] Elapsed 200m 5s (remain 312m 43s) Loss: 0.0000(0.0026) Grad: 6.5569  LR: 0.000014  \n",
      "Epoch: [1][14500/36908] Elapsed 201m 29s (remain 311m 20s) Loss: 0.0001(0.0026) Grad: 81.7249  LR: 0.000013  \n",
      "Epoch: [1][14600/36908] Elapsed 202m 52s (remain 309m 57s) Loss: 0.0016(0.0026) Grad: 9954.0830  LR: 0.000013  \n",
      "Epoch: [1][14700/36908] Elapsed 204m 16s (remain 308m 33s) Loss: 0.0038(0.0026) Grad: 44785.3945  LR: 0.000013  \n",
      "Epoch: [1][14800/36908] Elapsed 205m 38s (remain 307m 9s) Loss: 0.0036(0.0026) Grad: 8045.9175  LR: 0.000013  \n",
      "Epoch: [1][14900/36908] Elapsed 207m 1s (remain 305m 45s) Loss: 0.0002(0.0026) Grad: 139.7493  LR: 0.000013  \n",
      "Epoch: [1][15000/36908] Elapsed 208m 24s (remain 304m 21s) Loss: 0.0126(0.0026) Grad: 119047.4766  LR: 0.000013  \n",
      "Epoch: [1][15100/36908] Elapsed 209m 48s (remain 302m 59s) Loss: 0.0023(0.0026) Grad: 41862.3711  LR: 0.000013  \n",
      "Epoch: [1][15200/36908] Elapsed 211m 12s (remain 301m 35s) Loss: 0.0001(0.0026) Grad: 1028.7740  LR: 0.000013  \n",
      "Epoch: [1][15300/36908] Elapsed 212m 35s (remain 300m 12s) Loss: 0.0029(0.0026) Grad: 29915.5371  LR: 0.000013  \n",
      "Epoch: [1][15400/36908] Elapsed 213m 59s (remain 298m 49s) Loss: 0.0007(0.0026) Grad: 5363.8247  LR: 0.000013  \n",
      "Epoch: [1][15500/36908] Elapsed 215m 24s (remain 297m 28s) Loss: 0.0012(0.0026) Grad: 11114.7539  LR: 0.000013  \n",
      "Epoch: [1][15600/36908] Elapsed 216m 48s (remain 296m 5s) Loss: 0.0035(0.0026) Grad: 59755.1172  LR: 0.000013  \n",
      "Epoch: [1][15700/36908] Elapsed 218m 11s (remain 294m 42s) Loss: 0.0002(0.0026) Grad: 121.5545  LR: 0.000013  \n",
      "Epoch: [1][15800/36908] Elapsed 219m 35s (remain 293m 20s) Loss: 0.0091(0.0026) Grad: 55021.9609  LR: 0.000013  \n",
      "Epoch: [1][15900/36908] Elapsed 220m 58s (remain 291m 56s) Loss: 0.0001(0.0026) Grad: 185.2816  LR: 0.000013  \n",
      "Epoch: [1][16000/36908] Elapsed 222m 22s (remain 290m 33s) Loss: 0.0006(0.0026) Grad: 11835.5293  LR: 0.000013  \n",
      "Epoch: [1][16100/36908] Elapsed 223m 46s (remain 289m 10s) Loss: 0.0004(0.0026) Grad: 3943.9641  LR: 0.000013  \n",
      "Epoch: [1][16200/36908] Elapsed 225m 9s (remain 287m 46s) Loss: 0.0015(0.0026) Grad: 41106.4219  LR: 0.000012  \n",
      "Epoch: [1][16300/36908] Elapsed 226m 33s (remain 286m 23s) Loss: 0.0050(0.0026) Grad: 125889.7422  LR: 0.000012  \n",
      "Epoch: [1][16400/36908] Elapsed 227m 57s (remain 285m 1s) Loss: 0.0004(0.0026) Grad: 48186.3516  LR: 0.000012  \n",
      "Epoch: [1][16500/36908] Elapsed 229m 20s (remain 283m 37s) Loss: 0.0011(0.0026) Grad: 17425.4297  LR: 0.000012  \n",
      "Epoch: [1][16600/36908] Elapsed 230m 43s (remain 282m 14s) Loss: 0.0060(0.0026) Grad: 379951.9688  LR: 0.000012  \n",
      "Epoch: [1][16700/36908] Elapsed 232m 7s (remain 280m 51s) Loss: 0.0003(0.0026) Grad: 1531.5282  LR: 0.000012  \n",
      "Epoch: [1][16800/36908] Elapsed 233m 29s (remain 279m 26s) Loss: 0.0182(0.0026) Grad: 282781.3438  LR: 0.000012  \n",
      "Epoch: [1][16900/36908] Elapsed 234m 52s (remain 278m 1s) Loss: 0.0149(0.0026) Grad: 195375.6719  LR: 0.000012  \n",
      "Epoch: [1][17000/36908] Elapsed 236m 15s (remain 276m 38s) Loss: 0.0009(0.0026) Grad: 2452.7056  LR: 0.000012  \n",
      "Epoch: [1][17100/36908] Elapsed 237m 38s (remain 275m 15s) Loss: 0.0010(0.0026) Grad: 6199.9961  LR: 0.000012  \n",
      "Epoch: [1][17200/36908] Elapsed 239m 1s (remain 273m 51s) Loss: 0.0012(0.0026) Grad: 90454.2031  LR: 0.000012  \n",
      "Epoch: [1][17300/36908] Elapsed 240m 25s (remain 272m 28s) Loss: 0.0001(0.0026) Grad: 178.1856  LR: 0.000012  \n",
      "Epoch: [1][17400/36908] Elapsed 241m 49s (remain 271m 5s) Loss: 0.0026(0.0026) Grad: 123443.7891  LR: 0.000012  \n",
      "Epoch: [1][17500/36908] Elapsed 243m 13s (remain 269m 42s) Loss: 0.0009(0.0026) Grad: 49849.3398  LR: 0.000012  \n",
      "Epoch: [1][17600/36908] Elapsed 244m 36s (remain 268m 19s) Loss: 0.0069(0.0026) Grad: 238170.2656  LR: 0.000012  \n",
      "Epoch: [1][17700/36908] Elapsed 246m 0s (remain 266m 55s) Loss: 0.0025(0.0026) Grad: 7786.2158  LR: 0.000012  \n",
      "Epoch: [1][17800/36908] Elapsed 247m 23s (remain 265m 32s) Loss: 0.0020(0.0026) Grad: 21021.0078  LR: 0.000012  \n",
      "Epoch: [1][17900/36908] Elapsed 248m 48s (remain 264m 10s) Loss: 0.0000(0.0026) Grad: 85.8911  LR: 0.000011  \n",
      "Epoch: [1][18000/36908] Elapsed 250m 12s (remain 262m 47s) Loss: 0.0020(0.0026) Grad: 27705.4590  LR: 0.000011  \n",
      "Epoch: [1][18100/36908] Elapsed 251m 34s (remain 261m 23s) Loss: 0.0022(0.0026) Grad: 152984.3125  LR: 0.000011  \n",
      "Epoch: [1][18200/36908] Elapsed 252m 57s (remain 259m 59s) Loss: 0.0029(0.0026) Grad: 114572.1328  LR: 0.000011  \n",
      "Epoch: [1][18300/36908] Elapsed 254m 21s (remain 258m 36s) Loss: 0.0004(0.0026) Grad: 583.4658  LR: 0.000011  \n",
      "Epoch: [1][18400/36908] Elapsed 255m 45s (remain 257m 13s) Loss: 0.0042(0.0026) Grad: 22546.0664  LR: 0.000011  \n",
      "Epoch: [1][18500/36908] Elapsed 257m 9s (remain 255m 51s) Loss: 0.0006(0.0026) Grad: 1187.2325  LR: 0.000011  \n",
      "Epoch: [1][18600/36908] Elapsed 258m 32s (remain 254m 27s) Loss: 0.0003(0.0025) Grad: 1414.9517  LR: 0.000011  \n",
      "Epoch: [1][18700/36908] Elapsed 259m 56s (remain 253m 4s) Loss: 0.0001(0.0025) Grad: 118.2685  LR: 0.000011  \n",
      "Epoch: [1][18800/36908] Elapsed 261m 19s (remain 251m 40s) Loss: 0.0001(0.0026) Grad: 91.1021  LR: 0.000011  \n",
      "Epoch: [1][18900/36908] Elapsed 262m 43s (remain 250m 18s) Loss: 0.0047(0.0025) Grad: 75195.6406  LR: 0.000011  \n",
      "Epoch: [1][19000/36908] Elapsed 264m 7s (remain 248m 55s) Loss: 0.0001(0.0025) Grad: 113.7845  LR: 0.000011  \n",
      "Epoch: [1][19100/36908] Elapsed 265m 30s (remain 247m 31s) Loss: 0.0010(0.0025) Grad: 17330.5723  LR: 0.000011  \n",
      "Epoch: [1][19200/36908] Elapsed 266m 54s (remain 246m 8s) Loss: 0.0027(0.0025) Grad: 14449.6152  LR: 0.000011  \n",
      "Epoch: [1][19300/36908] Elapsed 268m 17s (remain 244m 44s) Loss: 0.0017(0.0025) Grad: 19674.1484  LR: 0.000011  \n",
      "Epoch: [1][19400/36908] Elapsed 269m 41s (remain 243m 21s) Loss: 0.0009(0.0025) Grad: 16190.9180  LR: 0.000011  \n",
      "Epoch: [1][19500/36908] Elapsed 271m 5s (remain 241m 58s) Loss: 0.0027(0.0025) Grad: 10908.6533  LR: 0.000010  \n",
      "Epoch: [1][19600/36908] Elapsed 272m 27s (remain 240m 34s) Loss: 0.0050(0.0025) Grad: 184279.1406  LR: 0.000010  \n",
      "Epoch: [1][19700/36908] Elapsed 273m 51s (remain 239m 11s) Loss: 0.0017(0.0025) Grad: 8387.7422  LR: 0.000010  \n",
      "Epoch: [1][19800/36908] Elapsed 275m 15s (remain 237m 48s) Loss: 0.0027(0.0025) Grad: 73320.9375  LR: 0.000010  \n",
      "Epoch: [1][19900/36908] Elapsed 276m 37s (remain 236m 24s) Loss: 0.0009(0.0025) Grad: 14480.8477  LR: 0.000010  \n",
      "Epoch: [1][20000/36908] Elapsed 278m 1s (remain 235m 0s) Loss: 0.0070(0.0025) Grad: 218622.8281  LR: 0.000010  \n",
      "Epoch: [1][20100/36908] Elapsed 279m 24s (remain 233m 36s) Loss: 0.0028(0.0025) Grad: 39910.8984  LR: 0.000010  \n",
      "Epoch: [1][20200/36908] Elapsed 280m 46s (remain 232m 12s) Loss: 0.0002(0.0025) Grad: 299.9507  LR: 0.000010  \n",
      "Epoch: [1][20300/36908] Elapsed 282m 10s (remain 230m 49s) Loss: 0.0111(0.0025) Grad: 308003.3125  LR: 0.000010  \n",
      "Epoch: [1][20400/36908] Elapsed 283m 34s (remain 229m 27s) Loss: 0.0034(0.0025) Grad: 14941.2090  LR: 0.000010  \n",
      "Epoch: [1][20500/36908] Elapsed 284m 58s (remain 228m 3s) Loss: 0.0019(0.0025) Grad: 7021.5723  LR: 0.000010  \n",
      "Epoch: [1][20600/36908] Elapsed 286m 22s (remain 226m 40s) Loss: 0.0028(0.0025) Grad: 14403.7764  LR: 0.000010  \n",
      "Epoch: [1][20700/36908] Elapsed 287m 46s (remain 225m 18s) Loss: 0.0022(0.0025) Grad: 30680.7129  LR: 0.000010  \n",
      "Epoch: [1][20800/36908] Elapsed 289m 10s (remain 223m 55s) Loss: 0.0009(0.0025) Grad: 1415.0575  LR: 0.000010  \n",
      "Epoch: [1][20900/36908] Elapsed 290m 34s (remain 222m 32s) Loss: 0.0043(0.0025) Grad: 19963.4336  LR: 0.000010  \n",
      "Epoch: [1][21000/36908] Elapsed 291m 58s (remain 221m 9s) Loss: 0.0002(0.0025) Grad: 747.9491  LR: 0.000010  \n",
      "Epoch: [1][21100/36908] Elapsed 293m 21s (remain 219m 45s) Loss: 0.0004(0.0025) Grad: 10001.7051  LR: 0.000010  \n",
      "Epoch: [1][21200/36908] Elapsed 294m 44s (remain 218m 21s) Loss: 0.0009(0.0025) Grad: 5718.0381  LR: 0.000009  \n",
      "Epoch: [1][21300/36908] Elapsed 296m 9s (remain 216m 59s) Loss: 0.0018(0.0025) Grad: 9291.6543  LR: 0.000009  \n",
      "Epoch: [1][21400/36908] Elapsed 297m 33s (remain 215m 36s) Loss: 0.0182(0.0025) Grad: 92915.2188  LR: 0.000009  \n",
      "Epoch: [1][21500/36908] Elapsed 298m 56s (remain 214m 12s) Loss: 0.0005(0.0025) Grad: 3074.5525  LR: 0.000009  \n",
      "Epoch: [1][21600/36908] Elapsed 300m 20s (remain 212m 49s) Loss: 0.0134(0.0025) Grad: 459187.5312  LR: 0.000009  \n",
      "Epoch: [1][21700/36908] Elapsed 301m 43s (remain 211m 25s) Loss: 0.0013(0.0025) Grad: 124029.2734  LR: 0.000009  \n",
      "Epoch: [1][21800/36908] Elapsed 303m 6s (remain 210m 2s) Loss: 0.0111(0.0025) Grad: 202749.7500  LR: 0.000009  \n",
      "Epoch: [1][21900/36908] Elapsed 304m 30s (remain 208m 38s) Loss: 0.0001(0.0025) Grad: 1760.4525  LR: 0.000009  \n",
      "Epoch: [1][22000/36908] Elapsed 305m 52s (remain 207m 15s) Loss: 0.0094(0.0025) Grad: 296980.9375  LR: 0.000009  \n",
      "Epoch: [1][22100/36908] Elapsed 307m 15s (remain 205m 51s) Loss: 0.0002(0.0025) Grad: 1256.6733  LR: 0.000009  \n",
      "Epoch: [1][22200/36908] Elapsed 308m 39s (remain 204m 28s) Loss: 0.0095(0.0025) Grad: 378873.9062  LR: 0.000009  \n",
      "Epoch: [1][22300/36908] Elapsed 310m 2s (remain 203m 4s) Loss: 0.0021(0.0025) Grad: 13857.9775  LR: 0.000009  \n",
      "Epoch: [1][22400/36908] Elapsed 311m 25s (remain 201m 40s) Loss: 0.0006(0.0025) Grad: 1356.7174  LR: 0.000009  \n",
      "Epoch: [1][22500/36908] Elapsed 312m 49s (remain 200m 17s) Loss: 0.0060(0.0025) Grad: 76269.8516  LR: 0.000009  \n",
      "Epoch: [1][22600/36908] Elapsed 314m 13s (remain 198m 54s) Loss: 0.0002(0.0025) Grad: 185.2939  LR: 0.000009  \n",
      "Epoch: [1][22700/36908] Elapsed 315m 36s (remain 197m 31s) Loss: 0.0026(0.0025) Grad: 18609.3281  LR: 0.000009  \n",
      "Epoch: [1][22800/36908] Elapsed 316m 59s (remain 196m 7s) Loss: 0.0003(0.0025) Grad: 1862.7932  LR: 0.000008  \n",
      "Epoch: [1][22900/36908] Elapsed 318m 22s (remain 194m 43s) Loss: 0.0002(0.0025) Grad: 657.3389  LR: 0.000008  \n",
      "Epoch: [1][23000/36908] Elapsed 319m 45s (remain 193m 20s) Loss: 0.0000(0.0025) Grad: 11.2142  LR: 0.000008  \n",
      "Epoch: [1][23100/36908] Elapsed 321m 9s (remain 191m 57s) Loss: 0.0046(0.0025) Grad: 22142.4492  LR: 0.000008  \n",
      "Epoch: [1][23200/36908] Elapsed 322m 33s (remain 190m 33s) Loss: 0.0001(0.0025) Grad: 51.9671  LR: 0.000008  \n",
      "Epoch: [1][23300/36908] Elapsed 323m 56s (remain 189m 10s) Loss: 0.0018(0.0025) Grad: 9541.2949  LR: 0.000008  \n",
      "Epoch: [1][23400/36908] Elapsed 325m 19s (remain 187m 46s) Loss: 0.0001(0.0025) Grad: 127.0222  LR: 0.000008  \n",
      "Epoch: [1][23500/36908] Elapsed 326m 43s (remain 186m 23s) Loss: 0.0003(0.0025) Grad: 23561.6934  LR: 0.000008  \n",
      "Epoch: [1][23600/36908] Elapsed 328m 7s (remain 185m 0s) Loss: 0.0003(0.0025) Grad: 1231.9668  LR: 0.000008  \n",
      "Epoch: [1][23700/36908] Elapsed 329m 30s (remain 183m 37s) Loss: 0.0119(0.0025) Grad: 326682.2500  LR: 0.000008  \n",
      "Epoch: [1][23800/36908] Elapsed 330m 54s (remain 182m 13s) Loss: 0.0036(0.0025) Grad: 65391.8828  LR: 0.000008  \n",
      "Epoch: [1][23900/36908] Elapsed 332m 17s (remain 180m 50s) Loss: 0.0020(0.0025) Grad: 9568.4072  LR: 0.000008  \n",
      "Epoch: [1][24000/36908] Elapsed 333m 42s (remain 179m 27s) Loss: 0.0003(0.0025) Grad: 295.7944  LR: 0.000008  \n",
      "Epoch: [1][24100/36908] Elapsed 335m 6s (remain 178m 4s) Loss: 0.0032(0.0025) Grad: 58198.2305  LR: 0.000008  \n",
      "Epoch: [1][24200/36908] Elapsed 336m 29s (remain 176m 40s) Loss: 0.0034(0.0025) Grad: 49387.0000  LR: 0.000008  \n",
      "Epoch: [1][24300/36908] Elapsed 337m 53s (remain 175m 17s) Loss: 0.0023(0.0025) Grad: 32289.3418  LR: 0.000008  \n",
      "Epoch: [1][24400/36908] Elapsed 339m 16s (remain 173m 53s) Loss: 0.0000(0.0025) Grad: 61.1235  LR: 0.000008  \n",
      "Epoch: [1][24500/36908] Elapsed 340m 40s (remain 172m 31s) Loss: 0.0005(0.0025) Grad: 12024.1172  LR: 0.000007  \n",
      "Epoch: [1][24600/36908] Elapsed 342m 4s (remain 171m 7s) Loss: 0.0032(0.0025) Grad: 14277.1748  LR: 0.000007  \n",
      "Epoch: [1][24700/36908] Elapsed 343m 28s (remain 169m 44s) Loss: 0.0002(0.0025) Grad: 211.0436  LR: 0.000007  \n",
      "Epoch: [1][24800/36908] Elapsed 344m 52s (remain 168m 21s) Loss: 0.0001(0.0025) Grad: 37.5920  LR: 0.000007  \n",
      "Epoch: [1][24900/36908] Elapsed 346m 17s (remain 166m 58s) Loss: 0.0004(0.0025) Grad: 3349.7422  LR: 0.000007  \n",
      "Epoch: [1][25000/36908] Elapsed 347m 41s (remain 165m 35s) Loss: 0.0001(0.0025) Grad: 30.2120  LR: 0.000007  \n",
      "Epoch: [1][25100/36908] Elapsed 349m 4s (remain 164m 11s) Loss: 0.0001(0.0025) Grad: 965.9371  LR: 0.000007  \n",
      "Epoch: [1][25200/36908] Elapsed 350m 29s (remain 162m 49s) Loss: 0.0002(0.0025) Grad: 114.8352  LR: 0.000007  \n",
      "Epoch: [1][25300/36908] Elapsed 351m 52s (remain 161m 25s) Loss: 0.0029(0.0025) Grad: 23844.0781  LR: 0.000007  \n",
      "Epoch: [1][25400/36908] Elapsed 353m 16s (remain 160m 2s) Loss: 0.0009(0.0025) Grad: 14001.0498  LR: 0.000007  \n",
      "Epoch: [1][25500/36908] Elapsed 354m 41s (remain 158m 39s) Loss: 0.0002(0.0025) Grad: 1493.7625  LR: 0.000007  \n",
      "Epoch: [1][25600/36908] Elapsed 356m 4s (remain 157m 16s) Loss: 0.0040(0.0025) Grad: 5606.1406  LR: 0.000007  \n",
      "Epoch: [1][25700/36908] Elapsed 357m 27s (remain 155m 52s) Loss: 0.0017(0.0025) Grad: 6997.3096  LR: 0.000007  \n",
      "Epoch: [1][25800/36908] Elapsed 358m 51s (remain 154m 28s) Loss: 0.0012(0.0025) Grad: 15167.0713  LR: 0.000007  \n",
      "Epoch: [1][25900/36908] Elapsed 360m 15s (remain 153m 5s) Loss: 0.0003(0.0025) Grad: 386.2693  LR: 0.000007  \n",
      "Epoch: [1][26000/36908] Elapsed 361m 39s (remain 151m 42s) Loss: 0.0002(0.0025) Grad: 2707.9238  LR: 0.000007  \n",
      "Epoch: [1][26100/36908] Elapsed 363m 2s (remain 150m 19s) Loss: 0.0050(0.0025) Grad: 9261.6807  LR: 0.000007  \n",
      "Epoch: [1][26200/36908] Elapsed 364m 25s (remain 148m 55s) Loss: 0.0018(0.0025) Grad: 913.5585  LR: 0.000006  \n",
      "Epoch: [1][26300/36908] Elapsed 365m 48s (remain 147m 31s) Loss: 0.0015(0.0025) Grad: 579.5332  LR: 0.000006  \n",
      "Epoch: [1][26400/36908] Elapsed 367m 13s (remain 146m 8s) Loss: 0.0047(0.0025) Grad: 44955.4844  LR: 0.000006  \n",
      "Epoch: [1][26500/36908] Elapsed 368m 37s (remain 144m 45s) Loss: 0.0058(0.0025) Grad: 23865.1367  LR: 0.000006  \n",
      "Epoch: [1][26600/36908] Elapsed 370m 0s (remain 143m 21s) Loss: 0.0003(0.0025) Grad: 2780.4573  LR: 0.000006  \n",
      "Epoch: [1][26700/36908] Elapsed 371m 25s (remain 141m 59s) Loss: 0.0001(0.0025) Grad: 2664.8440  LR: 0.000006  \n",
      "Epoch: [1][26800/36908] Elapsed 372m 49s (remain 140m 35s) Loss: 0.0005(0.0025) Grad: 234.8297  LR: 0.000006  \n",
      "Epoch: [1][26900/36908] Elapsed 374m 11s (remain 139m 11s) Loss: 0.0039(0.0025) Grad: 7866.5845  LR: 0.000006  \n",
      "Epoch: [1][27000/36908] Elapsed 375m 34s (remain 137m 48s) Loss: 0.0005(0.0025) Grad: 477.9923  LR: 0.000006  \n",
      "Epoch: [1][27100/36908] Elapsed 376m 57s (remain 136m 24s) Loss: 0.0017(0.0025) Grad: 14260.2803  LR: 0.000006  \n",
      "Epoch: [1][27200/36908] Elapsed 378m 21s (remain 135m 1s) Loss: 0.0001(0.0025) Grad: 23.1397  LR: 0.000006  \n",
      "Epoch: [1][27300/36908] Elapsed 379m 46s (remain 133m 38s) Loss: 0.0012(0.0025) Grad: 730.5842  LR: 0.000006  \n",
      "Epoch: [1][27400/36908] Elapsed 381m 8s (remain 132m 14s) Loss: 0.0006(0.0025) Grad: 2444.4609  LR: 0.000006  \n",
      "Epoch: [1][27500/36908] Elapsed 382m 32s (remain 130m 51s) Loss: 0.0061(0.0025) Grad: 19941.0645  LR: 0.000006  \n",
      "Epoch: [1][27600/36908] Elapsed 383m 56s (remain 129m 27s) Loss: 0.0004(0.0025) Grad: 1382.6736  LR: 0.000006  \n",
      "Epoch: [1][27700/36908] Elapsed 385m 20s (remain 128m 4s) Loss: 0.0149(0.0025) Grad: 81883.1406  LR: 0.000006  \n",
      "Epoch: [1][27800/36908] Elapsed 386m 44s (remain 126m 41s) Loss: 0.0001(0.0025) Grad: 39.3994  LR: 0.000005  \n",
      "Epoch: [1][27900/36908] Elapsed 388m 7s (remain 125m 17s) Loss: 0.0001(0.0025) Grad: 196.5303  LR: 0.000005  \n",
      "Epoch: [1][28000/36908] Elapsed 389m 31s (remain 123m 54s) Loss: 0.0006(0.0025) Grad: 2708.6892  LR: 0.000005  \n",
      "Epoch: [1][28100/36908] Elapsed 390m 55s (remain 122m 31s) Loss: 0.0002(0.0025) Grad: 324.6465  LR: 0.000005  \n",
      "Epoch: [1][28200/36908] Elapsed 392m 20s (remain 121m 8s) Loss: 0.0003(0.0025) Grad: 7214.0010  LR: 0.000005  \n",
      "Epoch: [1][28300/36908] Elapsed 393m 43s (remain 119m 44s) Loss: 0.0001(0.0025) Grad: 54.5207  LR: 0.000005  \n",
      "Epoch: [1][28400/36908] Elapsed 395m 7s (remain 118m 21s) Loss: 0.0010(0.0025) Grad: 18366.5566  LR: 0.000005  \n",
      "Epoch: [1][28500/36908] Elapsed 396m 30s (remain 116m 57s) Loss: 0.0000(0.0025) Grad: 16.0775  LR: 0.000005  \n",
      "Epoch: [1][28600/36908] Elapsed 397m 53s (remain 115m 33s) Loss: 0.0001(0.0025) Grad: 36.8510  LR: 0.000005  \n",
      "Epoch: [1][28700/36908] Elapsed 399m 16s (remain 114m 10s) Loss: 0.0001(0.0025) Grad: 140.5704  LR: 0.000005  \n",
      "Epoch: [1][28800/36908] Elapsed 400m 40s (remain 112m 46s) Loss: 0.0006(0.0025) Grad: 7009.1543  LR: 0.000005  \n",
      "Epoch: [1][28900/36908] Elapsed 402m 2s (remain 111m 23s) Loss: 0.0004(0.0025) Grad: 113.8754  LR: 0.000005  \n",
      "Epoch: [1][29000/36908] Elapsed 403m 26s (remain 109m 59s) Loss: 0.0025(0.0025) Grad: 24061.9863  LR: 0.000005  \n",
      "Epoch: [1][29100/36908] Elapsed 404m 50s (remain 108m 36s) Loss: 0.0001(0.0025) Grad: 35.1166  LR: 0.000005  \n",
      "Epoch: [1][29200/36908] Elapsed 406m 12s (remain 107m 12s) Loss: 0.0099(0.0025) Grad: 94530.2188  LR: 0.000005  \n",
      "Epoch: [1][29300/36908] Elapsed 407m 36s (remain 105m 49s) Loss: 0.0001(0.0025) Grad: 50.8745  LR: 0.000005  \n",
      "Epoch: [1][29400/36908] Elapsed 408m 59s (remain 104m 25s) Loss: 0.0004(0.0025) Grad: 3846.8777  LR: 0.000005  \n",
      "Epoch: [1][29500/36908] Elapsed 410m 22s (remain 103m 2s) Loss: 0.0007(0.0025) Grad: 11440.9375  LR: 0.000004  \n",
      "Epoch: [1][29600/36908] Elapsed 411m 46s (remain 101m 38s) Loss: 0.0001(0.0025) Grad: 53.6881  LR: 0.000004  \n",
      "Epoch: [1][29700/36908] Elapsed 413m 11s (remain 100m 15s) Loss: 0.0003(0.0025) Grad: 177.4774  LR: 0.000004  \n",
      "Epoch: [1][29800/36908] Elapsed 414m 35s (remain 98m 52s) Loss: 0.0000(0.0025) Grad: 21.3618  LR: 0.000004  \n",
      "Epoch: [1][29900/36908] Elapsed 415m 58s (remain 97m 28s) Loss: 0.0072(0.0025) Grad: 57655.5469  LR: 0.000004  \n",
      "Epoch: [1][30000/36908] Elapsed 417m 23s (remain 96m 5s) Loss: 0.0007(0.0025) Grad: 3360.5869  LR: 0.000004  \n",
      "Epoch: [1][30100/36908] Elapsed 418m 46s (remain 94m 42s) Loss: 0.0004(0.0025) Grad: 1277.9308  LR: 0.000004  \n",
      "Epoch: [1][30200/36908] Elapsed 420m 10s (remain 93m 18s) Loss: 0.0030(0.0025) Grad: 68915.0156  LR: 0.000004  \n",
      "Epoch: [1][30300/36908] Elapsed 421m 35s (remain 91m 55s) Loss: 0.0004(0.0025) Grad: 384.1178  LR: 0.000004  \n",
      "Epoch: [1][30400/36908] Elapsed 422m 59s (remain 90m 32s) Loss: 0.0007(0.0025) Grad: 1992.0011  LR: 0.000004  \n",
      "Epoch: [1][30500/36908] Elapsed 424m 23s (remain 89m 8s) Loss: 0.0023(0.0025) Grad: 21528.8223  LR: 0.000004  \n",
      "Epoch: [1][30600/36908] Elapsed 425m 47s (remain 87m 45s) Loss: 0.0067(0.0025) Grad: 110124.5859  LR: 0.000004  \n",
      "Epoch: [1][30700/36908] Elapsed 427m 10s (remain 86m 21s) Loss: 0.0074(0.0025) Grad: 61165.8711  LR: 0.000004  \n",
      "Epoch: [1][30800/36908] Elapsed 428m 34s (remain 84m 58s) Loss: 0.0001(0.0025) Grad: 605.5842  LR: 0.000004  \n",
      "Epoch: [1][30900/36908] Elapsed 429m 57s (remain 83m 34s) Loss: 0.0019(0.0025) Grad: 74961.8594  LR: 0.000004  \n",
      "Epoch: [1][31000/36908] Elapsed 431m 22s (remain 82m 11s) Loss: 0.0015(0.0025) Grad: 29331.4141  LR: 0.000004  \n",
      "Epoch: [1][31100/36908] Elapsed 432m 44s (remain 80m 48s) Loss: 0.0049(0.0025) Grad: 13320.9756  LR: 0.000003  \n",
      "Epoch: [1][31200/36908] Elapsed 434m 7s (remain 79m 24s) Loss: 0.0002(0.0025) Grad: 213.9535  LR: 0.000003  \n",
      "Epoch: [1][31300/36908] Elapsed 435m 30s (remain 78m 0s) Loss: 0.0027(0.0025) Grad: 41549.7539  LR: 0.000003  \n",
      "Epoch: [1][31400/36908] Elapsed 436m 55s (remain 76m 37s) Loss: 0.0019(0.0025) Grad: 10350.2100  LR: 0.000003  \n",
      "Epoch: [1][31500/36908] Elapsed 438m 19s (remain 75m 14s) Loss: 0.0004(0.0025) Grad: 748.7990  LR: 0.000003  \n",
      "Epoch: [1][31600/36908] Elapsed 439m 44s (remain 73m 50s) Loss: 0.0012(0.0025) Grad: 13361.7773  LR: 0.000003  \n",
      "Epoch: [1][31700/36908] Elapsed 441m 7s (remain 72m 27s) Loss: 0.0010(0.0025) Grad: 5175.2822  LR: 0.000003  \n",
      "Epoch: [1][31800/36908] Elapsed 442m 31s (remain 71m 3s) Loss: 0.0002(0.0025) Grad: 195.9945  LR: 0.000003  \n",
      "Epoch: [1][31900/36908] Elapsed 443m 54s (remain 69m 40s) Loss: 0.0001(0.0025) Grad: 2209.2798  LR: 0.000003  \n",
      "Epoch: [1][32000/36908] Elapsed 445m 18s (remain 68m 16s) Loss: 0.0032(0.0025) Grad: 37376.9727  LR: 0.000003  \n",
      "Epoch: [1][32100/36908] Elapsed 446m 41s (remain 66m 53s) Loss: 0.0002(0.0025) Grad: 444.1062  LR: 0.000003  \n",
      "Epoch: [1][32200/36908] Elapsed 448m 6s (remain 65m 30s) Loss: 0.0009(0.0025) Grad: 8518.3906  LR: 0.000003  \n",
      "Epoch: [1][32300/36908] Elapsed 449m 29s (remain 64m 6s) Loss: 0.0002(0.0025) Grad: 3177.1465  LR: 0.000003  \n",
      "Epoch: [1][32400/36908] Elapsed 450m 52s (remain 62m 43s) Loss: 0.0035(0.0025) Grad: 34212.3086  LR: 0.000003  \n",
      "Epoch: [1][32500/36908] Elapsed 452m 16s (remain 61m 19s) Loss: 0.0071(0.0025) Grad: 118600.1250  LR: 0.000003  \n",
      "Epoch: [1][32600/36908] Elapsed 453m 40s (remain 59m 56s) Loss: 0.0000(0.0025) Grad: 113.5739  LR: 0.000003  \n",
      "Epoch: [1][32700/36908] Elapsed 455m 4s (remain 58m 32s) Loss: 0.0003(0.0025) Grad: 895.6859  LR: 0.000003  \n",
      "Epoch: [1][32800/36908] Elapsed 456m 28s (remain 57m 9s) Loss: 0.0002(0.0025) Grad: 666.0565  LR: 0.000002  \n",
      "Epoch: [1][32900/36908] Elapsed 457m 51s (remain 55m 45s) Loss: 0.0022(0.0025) Grad: 14958.4639  LR: 0.000002  \n",
      "Epoch: [1][33000/36908] Elapsed 459m 15s (remain 54m 22s) Loss: 0.0002(0.0025) Grad: 2546.3950  LR: 0.000002  \n",
      "Epoch: [1][33100/36908] Elapsed 460m 38s (remain 52m 58s) Loss: 0.0074(0.0025) Grad: 39599.8633  LR: 0.000002  \n",
      "Epoch: [1][33200/36908] Elapsed 462m 1s (remain 51m 35s) Loss: 0.0029(0.0025) Grad: 28421.4551  LR: 0.000002  \n",
      "Epoch: [1][33300/36908] Elapsed 463m 24s (remain 50m 11s) Loss: 0.0017(0.0025) Grad: 13072.2090  LR: 0.000002  \n",
      "Epoch: [1][33400/36908] Elapsed 464m 47s (remain 48m 48s) Loss: 0.0029(0.0025) Grad: 14907.2695  LR: 0.000002  \n",
      "Epoch: [1][33500/36908] Elapsed 466m 9s (remain 47m 24s) Loss: 0.0139(0.0025) Grad: 174244.1094  LR: 0.000002  \n",
      "Epoch: [1][33600/36908] Elapsed 467m 33s (remain 46m 0s) Loss: 0.0017(0.0025) Grad: 82246.0703  LR: 0.000002  \n",
      "Epoch: [1][33700/36908] Elapsed 468m 55s (remain 44m 37s) Loss: 0.0001(0.0025) Grad: 65.3942  LR: 0.000002  \n",
      "Epoch: [1][33800/36908] Elapsed 470m 20s (remain 43m 13s) Loss: 0.0007(0.0025) Grad: 13978.1133  LR: 0.000002  \n",
      "Epoch: [1][33900/36908] Elapsed 471m 44s (remain 41m 50s) Loss: 0.0038(0.0025) Grad: 37533.6328  LR: 0.000002  \n",
      "Epoch: [1][34000/36908] Elapsed 473m 7s (remain 40m 27s) Loss: 0.0013(0.0025) Grad: 23893.7402  LR: 0.000002  \n",
      "Epoch: [1][34100/36908] Elapsed 474m 31s (remain 39m 3s) Loss: 0.0013(0.0025) Grad: 61138.4766  LR: 0.000002  \n",
      "Epoch: [1][34200/36908] Elapsed 475m 56s (remain 37m 40s) Loss: 0.0001(0.0025) Grad: 393.3578  LR: 0.000002  \n",
      "Epoch: [1][34300/36908] Elapsed 477m 20s (remain 36m 16s) Loss: 0.0023(0.0025) Grad: 22774.7305  LR: 0.000002  \n",
      "Epoch: [1][34400/36908] Elapsed 478m 44s (remain 34m 53s) Loss: 0.0001(0.0025) Grad: 83.5443  LR: 0.000002  \n",
      "Epoch: [1][34500/36908] Elapsed 480m 7s (remain 33m 29s) Loss: 0.0057(0.0025) Grad: 140225.0625  LR: 0.000001  \n",
      "Epoch: [1][34600/36908] Elapsed 481m 31s (remain 32m 6s) Loss: 0.0010(0.0025) Grad: 114325.9609  LR: 0.000001  \n",
      "Epoch: [1][34700/36908] Elapsed 482m 56s (remain 30m 42s) Loss: 0.0000(0.0025) Grad: 199.7033  LR: 0.000001  \n",
      "Epoch: [1][34800/36908] Elapsed 484m 18s (remain 29m 19s) Loss: 0.0004(0.0025) Grad: 2364.9541  LR: 0.000001  \n",
      "Epoch: [1][34900/36908] Elapsed 485m 43s (remain 27m 55s) Loss: 0.0026(0.0025) Grad: 12307.8145  LR: 0.000001  \n",
      "Epoch: [1][35000/36908] Elapsed 487m 7s (remain 26m 32s) Loss: 0.0001(0.0025) Grad: 378.9179  LR: 0.000001  \n",
      "Epoch: [1][35100/36908] Elapsed 488m 30s (remain 25m 8s) Loss: 0.0005(0.0025) Grad: 12496.6426  LR: 0.000001  \n",
      "Epoch: [1][35200/36908] Elapsed 489m 53s (remain 23m 45s) Loss: 0.0006(0.0025) Grad: 8268.8701  LR: 0.000001  \n",
      "Epoch: [1][35300/36908] Elapsed 491m 16s (remain 22m 21s) Loss: 0.0070(0.0025) Grad: 72159.0156  LR: 0.000001  \n",
      "Epoch: [1][35400/36908] Elapsed 492m 40s (remain 20m 58s) Loss: 0.0007(0.0025) Grad: 545.6942  LR: 0.000001  \n",
      "Epoch: [1][35500/36908] Elapsed 494m 4s (remain 19m 34s) Loss: 0.0032(0.0025) Grad: 81989.2656  LR: 0.000001  \n",
      "Epoch: [1][35600/36908] Elapsed 495m 28s (remain 18m 11s) Loss: 0.0001(0.0025) Grad: 1829.0524  LR: 0.000001  \n",
      "Epoch: [1][35700/36908] Elapsed 496m 51s (remain 16m 47s) Loss: 0.0001(0.0025) Grad: 202.0612  LR: 0.000001  \n",
      "Epoch: [1][35800/36908] Elapsed 498m 15s (remain 15m 24s) Loss: 0.0134(0.0025) Grad: 78699.1328  LR: 0.000001  \n",
      "Epoch: [1][35900/36908] Elapsed 499m 38s (remain 14m 0s) Loss: 0.0004(0.0025) Grad: 1119.3485  LR: 0.000001  \n",
      "Epoch: [1][36000/36908] Elapsed 501m 1s (remain 12m 37s) Loss: 0.0023(0.0025) Grad: 28052.6309  LR: 0.000001  \n",
      "Epoch: [1][36100/36908] Elapsed 502m 25s (remain 11m 13s) Loss: 0.0020(0.0025) Grad: 62447.0117  LR: 0.000000  \n",
      "Epoch: [1][36200/36908] Elapsed 503m 48s (remain 9m 50s) Loss: 0.0013(0.0025) Grad: 14617.5098  LR: 0.000000  \n",
      "Epoch: [1][36300/36908] Elapsed 505m 12s (remain 8m 26s) Loss: 0.0004(0.0025) Grad: 2014.6355  LR: 0.000000  \n",
      "Epoch: [1][36400/36908] Elapsed 506m 36s (remain 7m 3s) Loss: 0.0019(0.0025) Grad: 28696.1348  LR: 0.000000  \n",
      "Epoch: [1][36500/36908] Elapsed 507m 59s (remain 5m 39s) Loss: 0.0004(0.0025) Grad: 429.7171  LR: 0.000000  \n",
      "Epoch: [1][36600/36908] Elapsed 509m 22s (remain 4m 16s) Loss: 0.0015(0.0025) Grad: 13479.5986  LR: 0.000000  \n",
      "Epoch: [1][36700/36908] Elapsed 510m 46s (remain 2m 52s) Loss: 0.0000(0.0025) Grad: 1024.5419  LR: 0.000000  \n",
      "Epoch: [1][36800/36908] Elapsed 512m 11s (remain 1m 29s) Loss: 0.0001(0.0025) Grad: 48.4546  LR: 0.000000  \n",
      "Epoch: [1][36900/36908] Elapsed 513m 35s (remain 0m 5s) Loss: 0.0000(0.0025) Grad: 68.3251  LR: 0.000000  \n",
      "Epoch: [1][36907/36908] Elapsed 513m 41s (remain 0m 0s) Loss: 0.0001(0.0025) Grad: 1042.2007  LR: 0.000000  \n",
      "EVAL: [0/1192] Elapsed 0m 0s (remain 18m 31s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/1192] Elapsed 0m 31s (remain 5m 37s) Loss: 0.0549(0.0058) \n",
      "EVAL: [200/1192] Elapsed 1m 1s (remain 5m 1s) Loss: 0.0076(0.0057) \n",
      "EVAL: [300/1192] Elapsed 1m 30s (remain 4m 29s) Loss: 0.0088(0.0065) \n",
      "EVAL: [400/1192] Elapsed 2m 0s (remain 3m 57s) Loss: 0.0000(0.0061) \n",
      "EVAL: [500/1192] Elapsed 2m 30s (remain 3m 26s) Loss: 0.0677(0.0061) \n",
      "EVAL: [600/1192] Elapsed 3m 0s (remain 2m 57s) Loss: 0.0095(0.0063) \n",
      "EVAL: [700/1192] Elapsed 3m 29s (remain 2m 27s) Loss: 0.0055(0.0070) \n",
      "EVAL: [800/1192] Elapsed 4m 0s (remain 1m 57s) Loss: 0.0205(0.0072) \n",
      "EVAL: [900/1192] Elapsed 4m 30s (remain 1m 27s) Loss: 0.0086(0.0073) \n",
      "EVAL: [1000/1192] Elapsed 5m 0s (remain 0m 57s) Loss: 0.0000(0.0072) \n",
      "EVAL: [1100/1192] Elapsed 5m 29s (remain 0m 27s) Loss: 0.0228(0.0070) \n",
      "EVAL: [1191/1192] Elapsed 5m 57s (remain 0m 0s) Loss: 0.0000(0.0068) \n",
      "Epoch 1 - avg_train_loss: 0.0025  avg_val_loss: 0.0068  time: 31183s\n",
      "Epoch 1 - Score: 0.8976\n",
      "Epoch 1 - Save Best Score: 0.8976 Model\n",
      "best_thres: 0.47  score: 0.89123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp072/fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d140bb1493f4e709ec7d88d0bd777a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp072/fold1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f77a46ae03a4c4db3be3aa94b08b7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp072/fold2_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9a49ffb3504e769a149386702cfc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n",
      "load weights from ../output/nbme-score-clinical-patient-notes/nbme-exp072/fold3_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9559c5c9f647a293219b07beb5e825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp068.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02633c7de1ea4b7ca2fd899ae0c6d209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "032d2a594c45472e9681d2d7557ab93d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09da6c904a3344ad9d7d0f17c646c8b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66daca2dd30d44efbcd88adcbb1c2725",
      "placeholder": "​",
      "style": "IPY_MODEL_02633c7de1ea4b7ca2fd899ae0c6d209",
      "value": " 446k/446k [00:00&lt;00:00, 4.84MB/s]"
     }
    },
    "0c748174ece64ca6992b434a2d92e1e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_827b5e8189d242c9b62bb8d6a084de72",
       "IPY_MODEL_0f910e441d334b10bc666e6ef47de941",
       "IPY_MODEL_09da6c904a3344ad9d7d0f17c646c8b1"
      ],
      "layout": "IPY_MODEL_d6ba1f9a002c49268799fc4a17f793ee"
     }
    },
    "0f0864ef340b49aaa9b4596e032163a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0f910e441d334b10bc666e6ef47de941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_760cf6427cdc4b05affb72378d92a0f3",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a660863781b487392504ab3302a5f93",
      "value": 456318
     }
    },
    "13133c559d1b4a14ba19c157c169b532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13873604cb644df0b4b5e8e9ea57d645": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c619fc144a44ae8ba6d091c236a20f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c64feffa14d4a56b3bf4c25f6d05c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc34ac85840429e8d5d62785817dd03",
      "placeholder": "​",
      "style": "IPY_MODEL_c7dbd264bb804aabbb9a3a3922cdcc00",
      "value": " 52.0/52.0 [00:00&lt;00:00, 2.12kB/s]"
     }
    },
    "1fc34ac85840429e8d5d62785817dd03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "263650ffbf3145048f331827b49ef11b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_886eee1754fd42e185a7548aa44871f1",
      "placeholder": "​",
      "style": "IPY_MODEL_ec232b9c334c4987b35fde837fac77da",
      "value": " 878k/878k [00:00&lt;00:00, 3.84MB/s]"
     }
    },
    "2c0468cceac144b890d30b510202deba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2df59efc32cf4642a4cfff7db709db5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb191fc8e771447ab389bbb57fe22d2f",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ced0845b868342c29d4e2d830a48f203",
      "value": 143
     }
    },
    "323239c2e16449c088afd6eb5eeaa73f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5f8f50bdaf843f1a938f6129848cd83",
      "max": 898825,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f0864ef340b49aaa9b4596e032163a7",
      "value": 898825
     }
    },
    "323befd254f741a7b041d124d4073817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33bbf6ff0a9847fc9900a16ea8247120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61d290b99d78422494bd99ba7f4ce0b4",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_511fe7d1f0db48f5848e3539ddb29fff",
      "value": 52
     }
    },
    "3d505cf1fb134928953da8d79d68665a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c276b71af2f4301b4048e4f8dad36d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_563519b534874ec8a145d292258b2dad",
       "IPY_MODEL_535a8156a6da43928fd0d7a33c624540",
       "IPY_MODEL_ef3dd8c9fb4a46bfa6c30489d2d75b02"
      ],
      "layout": "IPY_MODEL_5d985ee5c7d84bf9a135972d46830ad0"
     }
    },
    "511fe7d1f0db48f5848e3539ddb29fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "530069c0165e4b3d8e077e9c6a4a1d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c0468cceac144b890d30b510202deba",
      "placeholder": "​",
      "style": "IPY_MODEL_b4c22ff3f7064b5c82b501058fa367a6",
      "value": "Downloading: 100%"
     }
    },
    "535a8156a6da43928fd0d7a33c624540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fa83fd7255f43ff9126aa633ed1b663",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9febd109d3a24bef886c8d24808347ba",
      "value": 42146
     }
    },
    "5504bc5bee8c4c189614fd398d1b7fef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "563519b534874ec8a145d292258b2dad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bc25dd928614ba999cefcde5efa9197",
      "placeholder": "​",
      "style": "IPY_MODEL_5ccb74cb082845d7ade9962f741a2910",
      "value": "100%"
     }
    },
    "5a47b531ee814b1eba201f0aa79212db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb3e7fc97c64d59a20a7ebb29a39800": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bc25dd928614ba999cefcde5efa9197": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ccb74cb082845d7ade9962f741a2910": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d985ee5c7d84bf9a135972d46830ad0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61d290b99d78422494bd99ba7f4ce0b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "638cf831bc0443658b4b455200f9b990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f0a30d22d004fd6866556696346fb74",
      "max": 475,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5504bc5bee8c4c189614fd398d1b7fef",
      "value": 475
     }
    },
    "6639cae9d2844ea3b7d9a777b43b2181": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e5be1d244794198afee6c8fefd3a191",
       "IPY_MODEL_2df59efc32cf4642a4cfff7db709db5a",
       "IPY_MODEL_72d201f9470a4d04b1e89f7d0018c0d7"
      ],
      "layout": "IPY_MODEL_cebcd629be2340bfa4ca1780d70dd364"
     }
    },
    "66a3685d05e1493c987e6cb1d9ed00a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66daca2dd30d44efbcd88adcbb1c2725": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e5be1d244794198afee6c8fefd3a191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da9bce59ac4845cda340d840b79be311",
      "placeholder": "​",
      "style": "IPY_MODEL_323befd254f741a7b041d124d4073817",
      "value": "100%"
     }
    },
    "72d201f9470a4d04b1e89f7d0018c0d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13873604cb644df0b4b5e8e9ea57d645",
      "placeholder": "​",
      "style": "IPY_MODEL_f129267b3ae6422e8d345c28b73f5516",
      "value": " 143/143 [00:00&lt;00:00, 2848.65it/s]"
     }
    },
    "760cf6427cdc4b05affb72378d92a0f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c1442db3949418184bfb68266910d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e01c08e3af148f580fcdc6ef6ebf5b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ebb3f8b10154ef4badb2d6856140d18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "808441188c1a4b5788ae84fa3edf27db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d505cf1fb134928953da8d79d68665a",
      "placeholder": "​",
      "style": "IPY_MODEL_81714296902f4d26a32aa05da8890693",
      "value": "Downloading: 100%"
     }
    },
    "80be6bc8b1c8454187599fe6f05cdcba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "811a7f7f9bc34108b113d084a7d488f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81714296902f4d26a32aa05da8890693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8254bfa8a6fa47dba57db5ba29dccaeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "827b5e8189d242c9b62bb8d6a084de72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc036c5ffc0a4a0fb2d0f504cf4264f3",
      "placeholder": "​",
      "style": "IPY_MODEL_80be6bc8b1c8454187599fe6f05cdcba",
      "value": "Downloading: 100%"
     }
    },
    "886eee1754fd42e185a7548aa44871f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e1aca2f17c6476a855cbe11a1d661a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa1104924af9458eb0d5443fd617cf29",
       "IPY_MODEL_b94dd392dc874911b1deeb39f77b342f",
       "IPY_MODEL_be8e2f5fc8eb4029a4aece3d1776054d"
      ],
      "layout": "IPY_MODEL_032d2a594c45472e9681d2d7557ab93d"
     }
    },
    "8f0a30d22d004fd6866556696346fb74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fa83fd7255f43ff9126aa633ed1b663": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9826121100004ec49f1cd7ed26023d9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfc527e5b7e84c45af32ba7e49275790",
       "IPY_MODEL_33bbf6ff0a9847fc9900a16ea8247120",
       "IPY_MODEL_1c64feffa14d4a56b3bf4c25f6d05c51"
      ],
      "layout": "IPY_MODEL_b42a1221467e43648126dc9432be0b28"
     }
    },
    "9a660863781b487392504ab3302a5f93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9febd109d3a24bef886c8d24808347ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a2fc47910e5a4b158eddf7faa455d683": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_808441188c1a4b5788ae84fa3edf27db",
       "IPY_MODEL_638cf831bc0443658b4b455200f9b990",
       "IPY_MODEL_c5ad324c87914e26ad665efcc418f354"
      ],
      "layout": "IPY_MODEL_8254bfa8a6fa47dba57db5ba29dccaeb"
     }
    },
    "aa1104924af9458eb0d5443fd617cf29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd01049905654fe6bee6c4c602b89ed9",
      "placeholder": "​",
      "style": "IPY_MODEL_66a3685d05e1493c987e6cb1d9ed00a1",
      "value": "100%"
     }
    },
    "b42a1221467e43648126dc9432be0b28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4c22ff3f7064b5c82b501058fa367a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5f8f50bdaf843f1a938f6129848cd83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b94dd392dc874911b1deeb39f77b342f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13133c559d1b4a14ba19c157c169b532",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e01c08e3af148f580fcdc6ef6ebf5b4",
      "value": 42146
     }
    },
    "be8e2f5fc8eb4029a4aece3d1776054d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e464d1ba21a1489183fda5c01bbc0cca",
      "placeholder": "​",
      "style": "IPY_MODEL_5bb3e7fc97c64d59a20a7ebb29a39800",
      "value": " 42146/42146 [00:22&lt;00:00, 2038.25it/s]"
     }
    },
    "c5ad324c87914e26ad665efcc418f354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a47b531ee814b1eba201f0aa79212db",
      "placeholder": "​",
      "style": "IPY_MODEL_7c1442db3949418184bfb68266910d91",
      "value": " 475/475 [00:00&lt;00:00, 18.8kB/s]"
     }
    },
    "c7dbd264bb804aabbb9a3a3922cdcc00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd01049905654fe6bee6c4c602b89ed9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cebcd629be2340bfa4ca1780d70dd364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ced0845b868342c29d4e2d830a48f203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cfc527e5b7e84c45af32ba7e49275790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c619fc144a44ae8ba6d091c236a20f6",
      "placeholder": "​",
      "style": "IPY_MODEL_f3dcb10079874c84a85896aae581b1dc",
      "value": "Downloading: 100%"
     }
    },
    "d6ba1f9a002c49268799fc4a17f793ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9bce59ac4845cda340d840b79be311": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc036c5ffc0a4a0fb2d0f504cf4264f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e464d1ba21a1489183fda5c01bbc0cca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb191fc8e771447ab389bbb57fe22d2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec232b9c334c4987b35fde837fac77da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecfdf18519e34e2d9a0b112b0815cba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef3dd8c9fb4a46bfa6c30489d2d75b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_811a7f7f9bc34108b113d084a7d488f4",
      "placeholder": "​",
      "style": "IPY_MODEL_ecfdf18519e34e2d9a0b112b0815cba5",
      "value": " 42146/42146 [00:00&lt;00:00, 687236.90it/s]"
     }
    },
    "f129267b3ae6422e8d345c28b73f5516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3dcb10079874c84a85896aae581b1dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f61172e130474199999fe10c8470b1e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_530069c0165e4b3d8e077e9c6a4a1d21",
       "IPY_MODEL_323239c2e16449c088afd6eb5eeaa73f",
       "IPY_MODEL_263650ffbf3145048f331827b49ef11b"
      ],
      "layout": "IPY_MODEL_7ebb3f8b10154ef4badb2d6856140d18"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
