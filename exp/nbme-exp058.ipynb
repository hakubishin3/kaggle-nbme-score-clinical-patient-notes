{"cells":[{"cell_type":"markdown","id":"national-fancy","metadata":{"id":"national-fancy"},"source":["## References"]},{"cell_type":"markdown","id":"copyrighted-centre","metadata":{"id":"copyrighted-centre"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"imported-offset","metadata":{"id":"imported-offset"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"complimentary-wyoming","metadata":{"id":"complimentary-wyoming","executionInfo":{"status":"ok","timestamp":1647823201637,"user_tz":-540,"elapsed":429,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp058\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"allied-circuit","metadata":{"id":"allied-circuit","executionInfo":{"status":"ok","timestamp":1647823201638,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    max_char_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"geographic-hindu","metadata":{"id":"geographic-hindu","executionInfo":{"status":"ok","timestamp":1647823201638,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"confident-fifth","metadata":{"id":"confident-fifth"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"miniature-greeting","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miniature-greeting","outputId":"07027ce7-013a-4bd0-eb1b-366a17a7e657","executionInfo":{"status":"ok","timestamp":1647823236476,"user_tz":-540,"elapsed":34846,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Mounted at /content/drive\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 14.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 58.8 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 44.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 45.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"guilty-filename","metadata":{"id":"guilty-filename","executionInfo":{"status":"ok","timestamp":1647823249310,"user_tz":-540,"elapsed":12840,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"cubic-designation","metadata":{"id":"cubic-designation"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"opposite-plasma","metadata":{"id":"opposite-plasma","executionInfo":{"status":"ok","timestamp":1647823249311,"user_tz":-540,"elapsed":15,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"multiple-poland","metadata":{"id":"multiple-poland","executionInfo":{"status":"ok","timestamp":1647823249762,"user_tz":-540,"elapsed":465,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        # result = np.where(char_prob >= th)[0] + 1\n","        result = np.where(char_prob >= th)[0]\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        # result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = [f\"{min(r)} {max(r) + 1}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5, use_token_prob=True):\n","    labels = create_labels_for_scoring(df)\n","\n","    if use_token_prob:\n","        token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","        char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    else:\n","        char_probs = df[[str(i) for i in range(CFG.max_char_len)]].values\n","        char_probs = [char_probs[i] for i in range(len(char_probs))]\n","\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"seventh-fighter","metadata":{"id":"seventh-fighter","executionInfo":{"status":"ok","timestamp":1647823249763,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"fifty-boundary","metadata":{"id":"fifty-boundary","executionInfo":{"status":"ok","timestamp":1647823249763,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"unlimited-hotel","metadata":{"id":"unlimited-hotel"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"classical-machine","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"classical-machine","outputId":"2857c3bc-4b7c-413b-b16a-1ae3b328f5bf","executionInfo":{"status":"ok","timestamp":1647823252191,"user_tz":-540,"elapsed":2433,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"vanilla-iceland","metadata":{"id":"vanilla-iceland","executionInfo":{"status":"ok","timestamp":1647823252191,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"convenient-plant","metadata":{"id":"convenient-plant"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"convertible-thunder","metadata":{"id":"convertible-thunder","executionInfo":{"status":"ok","timestamp":1647823252192,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"charitable-memphis","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"charitable-memphis","outputId":"028b360e-54c6-444a-d95b-f231b33d6580","executionInfo":{"status":"ok","timestamp":1647823252192,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"governing-election","metadata":{"id":"governing-election","executionInfo":{"status":"ok","timestamp":1647823252624,"user_tz":-540,"elapsed":436,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"negative-provincial","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"negative-provincial","outputId":"6c9effeb-f445-4a12-8293-6f19c7ca61a3","executionInfo":{"status":"ok","timestamp":1647823252624,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"arbitrary-beatles","metadata":{"id":"arbitrary-beatles"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"important-murray","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"important-murray","outputId":"3c18a1db-df7d-41d4-b006-292bd156759b","executionInfo":{"status":"ok","timestamp":1647823252625,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"configured-chemistry","metadata":{"id":"configured-chemistry"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"hindu-contest","metadata":{"id":"hindu-contest","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["9a4191658139420db4ea5e88370dadf1","58a7f6e7aaa94caebd8505341eb8d895","a5da600d56f944b6a83c44129a62acc7","31c129e810da4fbaae1e6e1c909f0971","bc736f58cca44cb7a3013e1a62fe8a67","829e21f7b9da4877a11f5cabe4be9348","b63c93e3c0be461fbf0775d7256fd0ce","93888a848cc9471f995230ca13642f5e","52ecc7a1b69d43b2aafb52279b7283ba","5d4b60e2c0cf4cc6a9e8c43d065e8e52","a08a254a8860468e930e7f4ac91d0077","81d8dad8f88349019cf233feff5a907e","b89eb0f4ec0f4b2fa740a716c7761a21","760ae51138e64152bb1161d32fc00ef7","85d1a91aa95649639a11e719975d8145","b771bcfc5ded41bcb8256332fa7f0224","5e453e7f1828430682d63f53a6706311","2c56af0c7aef4a9c997b6189aa554187","c44ab7c9029d4904b9eb7bdf102fb3ab","26ccdc75ccc24bc3a669e1b96c36c64a","065484021ad249b09d78f9aed0f9a6f4","06e7aeb86a2e44b69fa0c6f682e1612c","e4b9230f820845b0b58f5c32c0aec05c","000f14dfbb11496b8179f82ae1bec456","b4f164862be04ee6b9eed6e5f55811b1","2cd328fa2d4149e188321576dd98ee13","dcd9e85285054805b169b6b532997338","be350fa9ddbb4bd090c262f9fc7a4448","1809a935fcd74672b37672d67e192c87","5a5267bf243b45d3bedc41ebbc5ca2c5","fca0da53eb0b43bd8da4dd727b25529b","c9564ce4236541fc9aa309a6399751b2","5d399112636d42ce8e31c5229a9d621e","eff07706b0d74a4691488d2b04fabf65","9ec0ae63aaef4267ab3b0d110d68933a","f59c53db88784a61ab158f0679dc0e79","abc369aee9e24f8cb02645d3f568c1e1","dd92d56920954f6690adc08b36cd0da6","0ce68abce7444daca360906e2835bddb","1794fa18091e4eb092f47e092a6ad49d","45aed73a581749c8bb01f55e1480ef09","2cee51bc932c4e0bb63632d12701749b","ffad7695ae244627879251c5e2e1c8c0","fb98242c9fab47f5ba091b91d1411b50"]},"executionInfo":{"status":"ok","timestamp":1647823260363,"user_tz":-540,"elapsed":7744,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"2db3e35b-caee-43c4-97b9-479f93758ead"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4191658139420db4ea5e88370dadf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81d8dad8f88349019cf233feff5a907e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4b9230f820845b0b58f5c32c0aec05c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff07706b0d74a4691488d2b04fabf65"}},"metadata":{}}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","id":"alleged-protein","metadata":{"id":"alleged-protein"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":18,"id":"composed-stroke","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["b9e33669c46c45c88215bb3a458736ce","e70f578699a24c03b8d1435c80e7dcdb","ab16f3ce71ac4ec88ff9254bac15c947","05cd260a63c94a75af9b2f67e9252161","ac7de57038f64a37a8983497086e91ca","a7119ddc1a484040a8731b9f85ef2d2c","ffc21c0c662f493786b9419beb62a4aa","6f21b15ed2fa49fb9f1f7bb801e1ec41","2ae53060b978455a89d665a344c10478","7d09b7bc83ba4d409a2052bd47651d4d","02f1fb72222c4e9a9d4ae5297ba44c82"]},"id":"composed-stroke","outputId":"9af66d38-3b36-41cd-fc93-9080fc3edaac","executionInfo":{"status":"ok","timestamp":1647823296210,"user_tz":-540,"elapsed":35857,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9e33669c46c45c88215bb3a458736ce"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":19,"id":"emotional-region","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["4e0079a1e2224b9499d45b32db00161f","4d7951e25d4145c8b34f80e1ff8f26e8","cb0d46584b4f429ab6a85f9d9b9f6034","edd4651b4bd64d20b6d5d51e526615f6","a06696ec1f2745b88280e0e63f422e00","cb5f608255734d50b5e5b98d2c4e4fbd","2f43578f5f0947398307e4f435854634","e7be4f5993b34e90801912620f95d627","56d34e7e2c89498aa35aa250ca78f35d","47f88e0dc18f47f88db8e287d04aaf05","33ade92b57824ed3bc260ffe373d9ae5"]},"id":"emotional-region","outputId":"711b13e6-876a-461f-a0e1-dbe2c0844254","executionInfo":{"status":"ok","timestamp":1647823296707,"user_tz":-540,"elapsed":509,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e0079a1e2224b9499d45b32db00161f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":20,"id":"wrong-leisure","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrong-leisure","outputId":"4eb1e39f-9369-4e2b-8efe-a2feb90c98a5","executionInfo":{"status":"ok","timestamp":1647823296707,"user_tz":-540,"elapsed":12,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":21,"id":"convenient-gospel","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["4d2395161fe94cf38a4833667150d753","bb68423a99154d8d8ff214d32a163815","656dd135b9b441868177f297d26128ca","89c00e8d030b4483bdc379d21f3ccdb1","a7146ed849fb4f48b5715561debaa03c","d81e850c34d74c05ac3e21105e00a32f","efdf8bd06b96478ea84bcd4660ce0db7","70b0c5db7eaf48e2b51db969bf6f1a80","5b4092c5d6064d7ebc0da601b5645dc9","d098345be3c6454e9fd804958903fbf8","919ec1113f6a4c7e86d4f0abf074d971"]},"id":"convenient-gospel","executionInfo":{"status":"ok","timestamp":1647823296708,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"e46c8e72-e037-4c87-b80b-a91069bddaf3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2395161fe94cf38a4833667150d753"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 950\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(text)\n","    pn_history_lengths.append(length)\n","\n","CFG.max_char_len = max(pn_history_lengths)\n","\n","print(\"max length:\", CFG.max_char_len)"]},{"cell_type":"code","execution_count":22,"id":"representative-contributor","metadata":{"id":"representative-contributor","executionInfo":{"status":"ok","timestamp":1647823296708,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.max_char_len = self.cfg.max_char_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        label = np.zeros(self.max_char_len)\n","        label[len(pn_history):] = -1\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    label[start:end] = 1\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, label, mapping_from_token_to_char"]},{"cell_type":"code","execution_count":23,"id":"decent-johnson","metadata":{"id":"decent-johnson","executionInfo":{"status":"ok","timestamp":1647823296709,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, mapping_from_token_to_char"]},{"cell_type":"markdown","id":"arctic-joint","metadata":{"id":"arctic-joint"},"source":["## Model"]},{"cell_type":"code","source":["class Exp054Model(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"],"metadata":{"id":"UtM7nYFm333y","executionInfo":{"status":"ok","timestamp":1647823296709,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"UtM7nYFm333y","execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"id":"alternative-malawi","metadata":{"id":"alternative-malawi","executionInfo":{"status":"ok","timestamp":1647823296709,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False, i_fold=None):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","\n","            model = Exp054Model(cfg, model_config_path=None, pretrained=False)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp054\" /  f\"fold{i_fold}_best.pth\")\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            self.backbone = model.backbone\n","            print(f\"Load weight from {path}\")\n","\n","        self.lstm = nn.LSTM(\n","            input_size=self.model_config.hidden_size,\n","            bidirectional=True,\n","            hidden_size=self.model_config.hidden_size // 2,\n","            num_layers=2,\n","            dropout=self.cfg.dropout,\n","            batch_first=True,\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs, mappings_from_token_to_char):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]  # [batch, seq_len, d_model]\n","        mappings_from_token_to_char = mappings_from_token_to_char.unsqueeze(2).expand(-1, -1, self.model_config.hidden_size)\n","        h = torch.gather(h, 1, mappings_from_token_to_char)    # [batch, seq_len, d_model]\n","        h, _ = self.lstm(h)\n","        output = self.fc(h)\n","\n","        return output"]},{"cell_type":"markdown","id":"therapeutic-assembly","metadata":{"id":"therapeutic-assembly"},"source":["## Training"]},{"cell_type":"code","execution_count":26,"id":"going-conversion","metadata":{"id":"going-conversion","executionInfo":{"status":"ok","timestamp":1647823296710,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":27,"id":"alleged-commonwealth","metadata":{"id":"alleged-commonwealth","executionInfo":{"status":"ok","timestamp":1647823296710,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","    \n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":28,"id":"middle-determination","metadata":{"id":"middle-determination","executionInfo":{"status":"ok","timestamp":1647823296710,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for (inputs, mappings_from_token_to_char) in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.no_grad():\n","            output = model(inputs, mappings_from_token_to_char)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":29,"id":"familiar-participation","metadata":{"id":"familiar-participation","executionInfo":{"status":"ok","timestamp":1647823297070,"user_tz":-540,"elapsed":369,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False, i_fold=i_fold)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    # freeze\n","    for param in model.backbone.parameters():\n","        param.requires_grad = False\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_char_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5, use_token_prob=False)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_char_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"coated-cameroon","metadata":{"id":"coated-cameroon"},"source":["## Main"]},{"cell_type":"code","execution_count":30,"id":"quality-expansion","metadata":{"id":"quality-expansion","executionInfo":{"status":"ok","timestamp":1647823297070,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5, use_token_prob=False)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres, use_token_prob=False)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":31,"id":"proprietary-civilian","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"proprietary-civilian","outputId":"62ad2eab-8d86-4b6b-df10-05513fdf5332","executionInfo":{"status":"error","timestamp":1647849057238,"user_tz":-540,"elapsed":25760174,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold0_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 1s (remain 79m 39s) Loss: 0.3514(0.3514) Grad: 75920.7812  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 33s (remain 19m 3s) Loss: 0.3283(0.3445) Grad: 69375.7266  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 1m 3s (remain 17m 42s) Loss: 0.2702(0.3228) Grad: 61582.5469  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 33s (remain 16m 53s) Loss: 0.1824(0.2897) Grad: 47246.2969  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 2m 3s (remain 16m 14s) Loss: 0.0940(0.2509) Grad: 30949.5332  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 33s (remain 15m 39s) Loss: 0.0385(0.2129) Grad: 14800.9932  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 3m 2s (remain 15m 5s) Loss: 0.0171(0.1810) Grad: 4060.7195  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 32s (remain 14m 32s) Loss: 0.0048(0.1564) Grad: 1236.9506  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 4m 2s (remain 14m 1s) Loss: 0.0028(0.1375) Grad: 697.3129  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 32s (remain 13m 29s) Loss: 0.0015(0.1226) Grad: 497.6932  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 5m 2s (remain 12m 58s) Loss: 0.0018(0.1109) Grad: 470.6353  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 32s (remain 12m 27s) Loss: 0.0008(0.1011) Grad: 203.2449  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 6m 2s (remain 11m 56s) Loss: 0.0000(0.0930) Grad: 51.9821  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 32s (remain 11m 25s) Loss: 0.0002(0.0860) Grad: 98.9147  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 7m 1s (remain 10m 54s) Loss: 0.0010(0.0801) Grad: 277.2490  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 31s (remain 10m 24s) Loss: 0.0012(0.0749) Grad: 223.4768  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 8m 1s (remain 9m 53s) Loss: 0.0016(0.0704) Grad: 131.0833  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 31s (remain 9m 23s) Loss: 0.0090(0.0664) Grad: 1767.1444  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 9m 1s (remain 8m 53s) Loss: 0.0009(0.0629) Grad: 231.6631  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 30s (remain 8m 22s) Loss: 0.0053(0.0599) Grad: 890.4603  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 10m 0s (remain 7m 52s) Loss: 0.0032(0.0570) Grad: 856.8785  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 30s (remain 7m 22s) Loss: 0.0003(0.0545) Grad: 108.5119  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 11m 0s (remain 6m 52s) Loss: 0.0012(0.0522) Grad: 402.2337  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 29s (remain 6m 21s) Loss: 0.0003(0.0500) Grad: 118.7580  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 59s (remain 5m 51s) Loss: 0.0000(0.0480) Grad: 36.6327  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 29s (remain 5m 21s) Loss: 0.0001(0.0462) Grad: 34.2204  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 58s (remain 4m 51s) Loss: 0.0012(0.0445) Grad: 201.4504  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 28s (remain 4m 21s) Loss: 0.0001(0.0429) Grad: 67.8135  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 57s (remain 3m 51s) Loss: 0.0040(0.0415) Grad: 1068.6244  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 27s (remain 3m 21s) Loss: 0.0113(0.0402) Grad: 2546.9333  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 57s (remain 2m 51s) Loss: 0.0001(0.0389) Grad: 61.8567  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 26s (remain 2m 21s) Loss: 0.0002(0.0377) Grad: 66.6207  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 56s (remain 1m 51s) Loss: 0.0002(0.0366) Grad: 74.8254  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 26s (remain 1m 21s) Loss: 0.0043(0.0356) Grad: 784.4683  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 55s (remain 0m 51s) Loss: 0.0001(0.0347) Grad: 28.1010  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 17m 25s (remain 0m 22s) Loss: 0.0048(0.0337) Grad: 822.9423  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 17m 47s (remain 0m 0s) Loss: 0.0057(0.0331) Grad: 572.1140  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 5s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.0173(0.0058) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 24s) Loss: 0.0038(0.0068) \n","EVAL: [300/1192] Elapsed 0m 44s (remain 2m 10s) Loss: 0.0055(0.0072) \n","EVAL: [400/1192] Elapsed 0m 58s (remain 1m 56s) Loss: 0.0033(0.0073) \n","EVAL: [500/1192] Elapsed 1m 14s (remain 1m 42s) Loss: 0.0140(0.0068) \n","EVAL: [600/1192] Elapsed 1m 29s (remain 1m 27s) Loss: 0.0114(0.0070) \n","EVAL: [700/1192] Elapsed 1m 43s (remain 1m 12s) Loss: 0.0822(0.0085) \n","EVAL: [800/1192] Elapsed 1m 59s (remain 0m 58s) Loss: 0.0026(0.0086) \n","EVAL: [900/1192] Elapsed 2m 13s (remain 0m 43s) Loss: 0.0046(0.0086) \n","EVAL: [1000/1192] Elapsed 2m 28s (remain 0m 28s) Loss: 0.0000(0.0084) \n","EVAL: [1100/1192] Elapsed 2m 42s (remain 0m 13s) Loss: 0.0006(0.0080) \n","EVAL: [1191/1192] Elapsed 2m 56s (remain 0m 0s) Loss: 0.0001(0.0078) \n","Epoch 1 - avg_train_loss: 0.0331  avg_val_loss: 0.0078  time: 1247s\n","Epoch 1 - Score: 0.8789\n","Epoch 1 - Save Best Score: 0.8789 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 39m 12s) Loss: 0.0128(0.0128) Grad: 2782.1128  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 35s (remain 20m 10s) Loss: 0.0003(0.0021) Grad: 114.2007  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 5s (remain 18m 12s) Loss: 0.0002(0.0022) Grad: 68.2805  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 34s (remain 17m 10s) Loss: 0.0002(0.0021) Grad: 92.5968  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 4s (remain 16m 25s) Loss: 0.0009(0.0022) Grad: 192.7654  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 34s (remain 15m 46s) Loss: 0.0012(0.0024) Grad: 467.1814  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 3m 4s (remain 15m 11s) Loss: 0.0024(0.0024) Grad: 523.3143  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 34s (remain 14m 37s) Loss: 0.0230(0.0024) Grad: 4499.0181  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 4m 4s (remain 14m 5s) Loss: 0.0090(0.0023) Grad: 2179.2607  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 33s (remain 13m 32s) Loss: 0.0035(0.0023) Grad: 1166.5125  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 5m 3s (remain 13m 0s) Loss: 0.0001(0.0023) Grad: 31.4218  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 33s (remain 12m 29s) Loss: 0.0073(0.0025) Grad: 1367.4032  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 6m 3s (remain 11m 58s) Loss: 0.0002(0.0024) Grad: 87.9172  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 33s (remain 11m 27s) Loss: 0.0015(0.0024) Grad: 492.4618  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 7m 2s (remain 10m 56s) Loss: 0.0008(0.0024) Grad: 204.9138  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 32s (remain 10m 25s) Loss: 0.0002(0.0024) Grad: 98.6226  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 8m 2s (remain 9m 54s) Loss: 0.0005(0.0024) Grad: 132.3621  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 32s (remain 9m 24s) Loss: 0.0009(0.0024) Grad: 224.7432  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 9m 2s (remain 8m 53s) Loss: 0.0030(0.0024) Grad: 672.8782  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 31s (remain 8m 23s) Loss: 0.0003(0.0024) Grad: 122.8510  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 10m 1s (remain 7m 53s) Loss: 0.0075(0.0024) Grad: 1604.7036  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 31s (remain 7m 22s) Loss: 0.0001(0.0024) Grad: 60.0300  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 11m 0s (remain 6m 52s) Loss: 0.0003(0.0024) Grad: 182.8873  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 30s (remain 6m 22s) Loss: 0.0012(0.0024) Grad: 402.3665  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 12m 0s (remain 5m 52s) Loss: 0.0001(0.0024) Grad: 57.0692  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 29s (remain 5m 22s) Loss: 0.0001(0.0024) Grad: 52.7506  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 59s (remain 4m 51s) Loss: 0.0000(0.0024) Grad: 20.9081  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 29s (remain 4m 21s) Loss: 0.0234(0.0023) Grad: 3721.6145  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 59s (remain 3m 51s) Loss: 0.0000(0.0023) Grad: 24.4450  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 29s (remain 3m 22s) Loss: 0.0034(0.0023) Grad: 1046.6576  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 59s (remain 2m 51s) Loss: 0.0006(0.0023) Grad: 232.6520  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 28s (remain 2m 21s) Loss: 0.0010(0.0024) Grad: 294.0278  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 58s (remain 1m 51s) Loss: 0.0008(0.0024) Grad: 278.5510  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 28s (remain 1m 22s) Loss: 0.0001(0.0024) Grad: 48.6701  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 57s (remain 0m 52s) Loss: 0.0001(0.0024) Grad: 69.3761  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 27s (remain 0m 22s) Loss: 0.0065(0.0023) Grad: 1332.0085  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 17m 50s (remain 0m 0s) Loss: 0.0007(0.0024) Grad: 287.0264  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 8s) Loss: 0.0003(0.0003) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 41s) Loss: 0.0174(0.0059) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 25s) Loss: 0.0039(0.0071) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.0044(0.0075) \n","EVAL: [400/1192] Elapsed 0m 58s (remain 1m 55s) Loss: 0.0034(0.0076) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 40s) Loss: 0.0133(0.0071) \n","EVAL: [600/1192] Elapsed 1m 27s (remain 1m 25s) Loss: 0.0112(0.0074) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 11s) Loss: 0.0881(0.0089) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0029(0.0090) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0035(0.0090) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0088) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0006(0.0084) \n","EVAL: [1191/1192] Elapsed 2m 50s (remain 0m 0s) Loss: 0.0000(0.0082) \n","Epoch 2 - avg_train_loss: 0.0024  avg_val_loss: 0.0082  time: 1244s\n","Epoch 2 - Score: 0.8799\n","Epoch 2 - Save Best Score: 0.8799 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 37m 34s) Loss: 0.0062(0.0062) Grad: 963.2062  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 34s (remain 19m 49s) Loss: 0.0079(0.0023) Grad: 2285.6047  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 4s (remain 18m 4s) Loss: 0.0040(0.0022) Grad: 1728.9911  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 34s (remain 17m 4s) Loss: 0.0005(0.0021) Grad: 190.1867  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 3s (remain 16m 19s) Loss: 0.0014(0.0020) Grad: 376.6530  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 33s (remain 15m 40s) Loss: 0.0004(0.0024) Grad: 212.1057  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 2s (remain 15m 5s) Loss: 0.0002(0.0025) Grad: 128.8851  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 32s (remain 14m 31s) Loss: 0.0006(0.0023) Grad: 334.4439  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 4m 2s (remain 13m 58s) Loss: 0.0003(0.0023) Grad: 148.0163  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 31s (remain 13m 26s) Loss: 0.0001(0.0023) Grad: 62.7917  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 5m 1s (remain 12m 55s) Loss: 0.0300(0.0023) Grad: 6603.5786  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 31s (remain 12m 24s) Loss: 0.0034(0.0023) Grad: 765.9999  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 6m 0s (remain 11m 53s) Loss: 0.0001(0.0023) Grad: 44.3806  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 30s (remain 11m 22s) Loss: 0.0000(0.0022) Grad: 5.8486  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 7m 0s (remain 10m 52s) Loss: 0.0001(0.0022) Grad: 70.4178  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 29s (remain 10m 21s) Loss: 0.0038(0.0022) Grad: 1434.2363  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 59s (remain 9m 51s) Loss: 0.0000(0.0023) Grad: 23.2235  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 29s (remain 9m 20s) Loss: 0.0001(0.0023) Grad: 77.8277  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 58s (remain 8m 50s) Loss: 0.0000(0.0022) Grad: 29.4721  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 28s (remain 8m 20s) Loss: 0.0012(0.0022) Grad: 489.6804  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 58s (remain 7m 50s) Loss: 0.0035(0.0022) Grad: 1129.4578  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 27s (remain 7m 20s) Loss: 0.0000(0.0022) Grad: 7.7845  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 57s (remain 6m 50s) Loss: 0.0000(0.0022) Grad: 23.6795  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 26s (remain 6m 20s) Loss: 0.0000(0.0023) Grad: 34.2548  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 56s (remain 5m 50s) Loss: 0.0000(0.0022) Grad: 24.7226  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 26s (remain 5m 20s) Loss: 0.0001(0.0022) Grad: 50.5542  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 56s (remain 4m 50s) Loss: 0.0015(0.0023) Grad: 481.3502  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 25s (remain 4m 20s) Loss: 0.0000(0.0022) Grad: 3.3719  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 55s (remain 3m 50s) Loss: 0.0011(0.0022) Grad: 424.0251  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 24s (remain 3m 20s) Loss: 0.0008(0.0022) Grad: 273.7363  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 54s (remain 2m 51s) Loss: 0.0003(0.0022) Grad: 240.1351  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 24s (remain 2m 21s) Loss: 0.0008(0.0022) Grad: 372.5250  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 53s (remain 1m 51s) Loss: 0.0036(0.0022) Grad: 1235.7078  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 23s (remain 1m 21s) Loss: 0.0011(0.0022) Grad: 309.3067  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 53s (remain 0m 51s) Loss: 0.0001(0.0023) Grad: 62.8677  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 23s (remain 0m 22s) Loss: 0.0000(0.0022) Grad: 30.9345  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 17m 45s (remain 0m 0s) Loss: 0.0001(0.0022) Grad: 44.0899  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 6s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 15s (remain 2m 44s) Loss: 0.0158(0.0055) \n","EVAL: [200/1192] Elapsed 0m 30s (remain 2m 28s) Loss: 0.0037(0.0069) \n","EVAL: [300/1192] Elapsed 0m 44s (remain 2m 12s) Loss: 0.0047(0.0073) \n","EVAL: [400/1192] Elapsed 0m 59s (remain 1m 58s) Loss: 0.0032(0.0074) \n","EVAL: [500/1192] Elapsed 1m 14s (remain 1m 42s) Loss: 0.0118(0.0069) \n","EVAL: [600/1192] Elapsed 1m 29s (remain 1m 27s) Loss: 0.0112(0.0071) \n","EVAL: [700/1192] Elapsed 1m 43s (remain 1m 12s) Loss: 0.0890(0.0087) \n","EVAL: [800/1192] Elapsed 1m 58s (remain 0m 57s) Loss: 0.0026(0.0088) \n","EVAL: [900/1192] Elapsed 2m 12s (remain 0m 42s) Loss: 0.0030(0.0088) \n","EVAL: [1000/1192] Elapsed 2m 26s (remain 0m 28s) Loss: 0.0000(0.0086) \n","EVAL: [1100/1192] Elapsed 2m 41s (remain 0m 13s) Loss: 0.0009(0.0082) \n","EVAL: [1191/1192] Elapsed 2m 54s (remain 0m 0s) Loss: 0.0000(0.0080) \n","Epoch 3 - avg_train_loss: 0.0022  avg_val_loss: 0.0080  time: 1242s\n","Epoch 3 - Score: 0.8801\n","Epoch 3 - Save Best Score: 0.8801 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 36m 2s) Loss: 0.0000(0.0000) Grad: 79.3998  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 34s (remain 19m 51s) Loss: 0.0044(0.0016) Grad: 729.9901  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 4s (remain 18m 8s) Loss: 0.0001(0.0021) Grad: 100.6924  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 34s (remain 17m 7s) Loss: 0.0023(0.0022) Grad: 483.8654  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 4s (remain 16m 22s) Loss: 0.0006(0.0020) Grad: 428.5136  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 33s (remain 15m 43s) Loss: 0.0003(0.0021) Grad: 151.4751  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 3m 3s (remain 15m 7s) Loss: 0.0003(0.0021) Grad: 203.1965  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 33s (remain 14m 33s) Loss: 0.0000(0.0021) Grad: 6.2798  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 4m 2s (remain 14m 1s) Loss: 0.0000(0.0022) Grad: 6.1189  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 32s (remain 13m 28s) Loss: 0.0002(0.0022) Grad: 119.4738  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 5m 2s (remain 12m 57s) Loss: 0.0000(0.0022) Grad: 23.3343  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 32s (remain 12m 26s) Loss: 0.0025(0.0022) Grad: 649.1399  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 6m 1s (remain 11m 55s) Loss: 0.0004(0.0022) Grad: 157.4541  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 31s (remain 11m 24s) Loss: 0.0001(0.0022) Grad: 46.5655  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 7m 1s (remain 10m 53s) Loss: 0.0024(0.0022) Grad: 482.9842  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 30s (remain 10m 22s) Loss: 0.0031(0.0022) Grad: 1348.0724  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 8m 0s (remain 9m 52s) Loss: 0.0000(0.0022) Grad: 29.1969  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 30s (remain 9m 21s) Loss: 0.0064(0.0022) Grad: 1779.6000  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 59s (remain 8m 51s) Loss: 0.0005(0.0021) Grad: 314.3557  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 29s (remain 8m 21s) Loss: 0.0003(0.0021) Grad: 152.5744  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 58s (remain 7m 51s) Loss: 0.0000(0.0021) Grad: 26.4058  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 28s (remain 7m 21s) Loss: 0.0010(0.0022) Grad: 315.4514  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 58s (remain 6m 51s) Loss: 0.0000(0.0022) Grad: 22.4266  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 27s (remain 6m 20s) Loss: 0.0002(0.0021) Grad: 187.1855  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 57s (remain 5m 50s) Loss: 0.0000(0.0022) Grad: 33.4177  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 27s (remain 5m 20s) Loss: 0.0200(0.0022) Grad: 5089.3008  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 56s (remain 4m 50s) Loss: 0.0000(0.0022) Grad: 24.8840  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 26s (remain 4m 20s) Loss: 0.0078(0.0023) Grad: 2249.4512  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 56s (remain 3m 51s) Loss: 0.0001(0.0022) Grad: 46.1377  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 25s (remain 3m 21s) Loss: 0.0002(0.0022) Grad: 144.6829  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 55s (remain 2m 51s) Loss: 0.0002(0.0022) Grad: 80.3545  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 25s (remain 2m 21s) Loss: 0.0010(0.0022) Grad: 367.5432  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 55s (remain 1m 51s) Loss: 0.0132(0.0022) Grad: 3089.9460  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 16m 25s (remain 1m 21s) Loss: 0.0002(0.0022) Grad: 92.2826  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 55s (remain 0m 51s) Loss: 0.0001(0.0022) Grad: 77.8181  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 17m 25s (remain 0m 22s) Loss: 0.0034(0.0022) Grad: 692.1586  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 17m 47s (remain 0m 0s) Loss: 0.0003(0.0022) Grad: 201.7431  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 14m 8s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 17s (remain 3m 10s) Loss: 0.0166(0.0058) \n","EVAL: [200/1192] Elapsed 0m 34s (remain 2m 50s) Loss: 0.0041(0.0069) \n","EVAL: [300/1192] Elapsed 0m 51s (remain 2m 32s) Loss: 0.0044(0.0073) \n","EVAL: [400/1192] Elapsed 1m 8s (remain 2m 15s) Loss: 0.0037(0.0074) \n","EVAL: [500/1192] Elapsed 1m 26s (remain 1m 58s) Loss: 0.0133(0.0069) \n","EVAL: [600/1192] Elapsed 1m 43s (remain 1m 41s) Loss: 0.0099(0.0071) \n","EVAL: [700/1192] Elapsed 2m 0s (remain 1m 24s) Loss: 0.0854(0.0086) \n","EVAL: [800/1192] Elapsed 2m 17s (remain 1m 6s) Loss: 0.0027(0.0088) \n","EVAL: [900/1192] Elapsed 2m 34s (remain 0m 49s) Loss: 0.0037(0.0087) \n","EVAL: [1000/1192] Elapsed 2m 51s (remain 0m 32s) Loss: 0.0000(0.0086) \n","EVAL: [1100/1192] Elapsed 3m 7s (remain 0m 15s) Loss: 0.0007(0.0082) \n","EVAL: [1191/1192] Elapsed 3m 22s (remain 0m 0s) Loss: 0.0000(0.0080) \n","Epoch 4 - avg_train_loss: 0.0022  avg_val_loss: 0.0080  time: 1273s\n","Epoch 4 - Score: 0.8799\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 35m 56s) Loss: 0.0001(0.0001) Grad: 238.2580  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 30s (remain 17m 27s) Loss: 0.0011(0.0027) Grad: 467.4956  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 0s (remain 16m 51s) Loss: 0.0047(0.0027) Grad: 1043.3636  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 30s (remain 16m 19s) Loss: 0.0039(0.0025) Grad: 2095.0566  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 59s (remain 15m 48s) Loss: 0.0045(0.0022) Grad: 1518.7294  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 29s (remain 15m 17s) Loss: 0.0002(0.0024) Grad: 139.2487  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 59s (remain 14m 48s) Loss: 0.0003(0.0022) Grad: 157.3028  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 29s (remain 14m 17s) Loss: 0.0163(0.0022) Grad: 3887.1755  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 58s (remain 13m 47s) Loss: 0.0005(0.0020) Grad: 287.2568  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 28s (remain 13m 16s) Loss: 0.0005(0.0020) Grad: 390.0429  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 58s (remain 12m 46s) Loss: 0.0001(0.0021) Grad: 55.0875  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 27s (remain 12m 16s) Loss: 0.0000(0.0021) Grad: 27.5130  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 57s (remain 11m 46s) Loss: 0.0001(0.0020) Grad: 63.1044  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 27s (remain 11m 16s) Loss: 0.0022(0.0021) Grad: 805.4323  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 57s (remain 10m 47s) Loss: 0.0000(0.0021) Grad: 15.9542  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 26s (remain 10m 17s) Loss: 0.0213(0.0021) Grad: 4778.5073  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 56s (remain 9m 47s) Loss: 0.0001(0.0020) Grad: 94.1260  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 26s (remain 9m 17s) Loss: 0.0003(0.0021) Grad: 242.3411  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 55s (remain 8m 47s) Loss: 0.0003(0.0022) Grad: 181.0285  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 25s (remain 8m 18s) Loss: 0.0000(0.0022) Grad: 36.1946  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 55s (remain 7m 48s) Loss: 0.0002(0.0022) Grad: 84.3052  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 25s (remain 7m 18s) Loss: 0.0023(0.0023) Grad: 404.1602  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 54s (remain 6m 48s) Loss: 0.0000(0.0022) Grad: 25.6491  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 24s (remain 6m 18s) Loss: 0.0024(0.0022) Grad: 908.4826  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 54s (remain 5m 49s) Loss: 0.0327(0.0022) Grad: 6135.8833  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 23s (remain 5m 19s) Loss: 0.0001(0.0022) Grad: 65.9832  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 53s (remain 4m 49s) Loss: 0.0003(0.0022) Grad: 256.5447  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 23s (remain 4m 20s) Loss: 0.0066(0.0022) Grad: 1878.5208  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 53s (remain 3m 50s) Loss: 0.0001(0.0022) Grad: 49.9560  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 23s (remain 3m 20s) Loss: 0.0000(0.0022) Grad: 33.6879  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 53s (remain 2m 50s) Loss: 0.0013(0.0022) Grad: 586.5384  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 22s (remain 2m 21s) Loss: 0.0000(0.0022) Grad: 16.5409  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 52s (remain 1m 51s) Loss: 0.1185(0.0023) Grad: 17722.7812  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 22s (remain 1m 21s) Loss: 0.0012(0.0023) Grad: 430.2051  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 51s (remain 0m 51s) Loss: 0.0032(0.0022) Grad: 1110.5721  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 17m 21s (remain 0m 22s) Loss: 0.0001(0.0022) Grad: 49.8719  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 17m 43s (remain 0m 0s) Loss: 0.0212(0.0022) Grad: 5572.9043  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 55s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0169(0.0058) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.0040(0.0071) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.0043(0.0074) \n","EVAL: [400/1192] Elapsed 0m 58s (remain 1m 54s) Loss: 0.0038(0.0075) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 40s) Loss: 0.0129(0.0070) \n","EVAL: [600/1192] Elapsed 1m 27s (remain 1m 25s) Loss: 0.0102(0.0072) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 11s) Loss: 0.0885(0.0088) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0027(0.0089) \n","EVAL: [900/1192] Elapsed 2m 10s (remain 0m 42s) Loss: 0.0035(0.0089) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.0000(0.0087) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0006(0.0084) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.0081) \n","Epoch 5 - avg_train_loss: 0.0022  avg_val_loss: 0.0081  time: 1238s\n","Epoch 5 - Score: 0.8800\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold1_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 49m 57s) Loss: 0.3519(0.3519) Grad: 80350.5000  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 30s (remain 17m 37s) Loss: 0.3275(0.3436) Grad: 78020.0703  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 1m 0s (remain 16m 57s) Loss: 0.2590(0.3210) Grad: 66721.6641  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 30s (remain 16m 25s) Loss: 0.1719(0.2868) Grad: 49088.0898  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 2m 0s (remain 15m 53s) Loss: 0.0862(0.2469) Grad: 30347.5977  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 30s (remain 15m 22s) Loss: 0.0311(0.2086) Grad: 12370.2070  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 3m 0s (remain 14m 52s) Loss: 0.0048(0.1770) Grad: 3410.7451  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 30s (remain 14m 22s) Loss: 0.0139(0.1530) Grad: 1871.7775  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 4m 0s (remain 13m 52s) Loss: 0.0025(0.1346) Grad: 599.5613  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 30s (remain 13m 23s) Loss: 0.0052(0.1200) Grad: 703.9523  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 5m 0s (remain 12m 52s) Loss: 0.0033(0.1083) Grad: 464.3373  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 30s (remain 12m 22s) Loss: 0.0005(0.0987) Grad: 146.5518  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 6m 0s (remain 11m 52s) Loss: 0.0005(0.0908) Grad: 141.6327  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 30s (remain 11m 22s) Loss: 0.0006(0.0840) Grad: 152.6563  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 7m 0s (remain 10m 51s) Loss: 0.0416(0.0782) Grad: 4712.3271  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 29s (remain 10m 21s) Loss: 0.0051(0.0732) Grad: 567.5068  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 59s (remain 9m 51s) Loss: 0.0008(0.0687) Grad: 244.3274  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 29s (remain 9m 21s) Loss: 0.0004(0.0649) Grad: 141.7020  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 59s (remain 8m 51s) Loss: 0.0004(0.0615) Grad: 125.4952  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 29s (remain 8m 21s) Loss: 0.0001(0.0583) Grad: 62.3262  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 59s (remain 7m 51s) Loss: 0.0005(0.0555) Grad: 170.4062  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 28s (remain 7m 21s) Loss: 0.0001(0.0530) Grad: 37.8274  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 59s (remain 6m 51s) Loss: 0.0016(0.0507) Grad: 193.1808  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 29s (remain 6m 21s) Loss: 0.0000(0.0486) Grad: 22.1331  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 59s (remain 5m 51s) Loss: 0.0003(0.0466) Grad: 96.6447  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 29s (remain 5m 21s) Loss: 0.0008(0.0449) Grad: 260.3954  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 59s (remain 4m 51s) Loss: 0.0190(0.0433) Grad: 3085.3718  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 29s (remain 4m 21s) Loss: 0.0002(0.0418) Grad: 68.0328  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 58s (remain 3m 51s) Loss: 0.0008(0.0404) Grad: 247.1207  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 28s (remain 3m 21s) Loss: 0.0002(0.0390) Grad: 87.1160  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 58s (remain 2m 51s) Loss: 0.0015(0.0379) Grad: 347.1345  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 28s (remain 2m 21s) Loss: 0.0002(0.0367) Grad: 79.9662  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 58s (remain 1m 52s) Loss: 0.0006(0.0356) Grad: 147.5071  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 28s (remain 1m 22s) Loss: 0.0001(0.0346) Grad: 45.6730  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 58s (remain 0m 52s) Loss: 0.0000(0.0337) Grad: 17.6753  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 17m 28s (remain 0m 22s) Loss: 0.0002(0.0328) Grad: 94.4040  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 17m 51s (remain 0m 0s) Loss: 0.0002(0.0321) Grad: 91.9609  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 11m 36s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 41s) Loss: 0.0006(0.0056) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 24s) Loss: 0.0007(0.0066) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.0017(0.0102) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.0262(0.0104) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.0251(0.0094) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1222(0.0094) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0045(0.0104) \n","EVAL: [800/1192] Elapsed 1m 54s (remain 0m 56s) Loss: 0.0052(0.0101) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.0034(0.0098) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0001(0.0095) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.0051(0.0090) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0087(0.0086) \n","Epoch 1 - avg_train_loss: 0.0321  avg_val_loss: 0.0086  time: 1245s\n","Epoch 1 - Score: 0.8814\n","Epoch 1 - Save Best Score: 0.8814 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 42m 4s) Loss: 0.0008(0.0008) Grad: 213.2829  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 34s (remain 19m 35s) Loss: 0.0000(0.0026) Grad: 30.8718  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 4s (remain 18m 2s) Loss: 0.0005(0.0024) Grad: 173.1689  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 34s (remain 17m 4s) Loss: 0.0001(0.0024) Grad: 69.9660  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 3s (remain 16m 20s) Loss: 0.0001(0.0025) Grad: 52.6612  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 33s (remain 15m 42s) Loss: 0.0021(0.0024) Grad: 629.6797  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 3m 3s (remain 15m 6s) Loss: 0.0115(0.0024) Grad: 2525.2688  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 32s (remain 14m 33s) Loss: 0.0001(0.0024) Grad: 54.3817  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 4m 2s (remain 14m 0s) Loss: 0.0001(0.0024) Grad: 34.4000  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 32s (remain 13m 28s) Loss: 0.0000(0.0024) Grad: 8.5416  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 5m 2s (remain 12m 57s) Loss: 0.0008(0.0024) Grad: 251.9270  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 32s (remain 12m 26s) Loss: 0.0001(0.0024) Grad: 48.8615  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 6m 1s (remain 11m 55s) Loss: 0.0001(0.0023) Grad: 38.3113  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 31s (remain 11m 24s) Loss: 0.0007(0.0024) Grad: 202.2850  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 7m 1s (remain 10m 53s) Loss: 0.0001(0.0023) Grad: 40.6492  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 31s (remain 10m 23s) Loss: 0.0007(0.0024) Grad: 283.4712  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 8m 0s (remain 9m 52s) Loss: 0.0047(0.0024) Grad: 814.7440  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 30s (remain 9m 22s) Loss: 0.0005(0.0024) Grad: 173.7338  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 9m 0s (remain 8m 52s) Loss: 0.0001(0.0024) Grad: 63.0705  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 30s (remain 8m 22s) Loss: 0.0118(0.0024) Grad: 2205.1765  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 10m 0s (remain 7m 52s) Loss: 0.0001(0.0024) Grad: 36.9120  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 29s (remain 7m 21s) Loss: 0.0005(0.0024) Grad: 251.2034  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 59s (remain 6m 51s) Loss: 0.0000(0.0023) Grad: 28.2556  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 29s (remain 6m 21s) Loss: 0.0014(0.0023) Grad: 566.1673  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 59s (remain 5m 51s) Loss: 0.0000(0.0023) Grad: 16.5490  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 28s (remain 5m 21s) Loss: 0.0017(0.0023) Grad: 324.0692  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 58s (remain 4m 51s) Loss: 0.0012(0.0023) Grad: 219.4698  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 28s (remain 4m 21s) Loss: 0.0011(0.0023) Grad: 658.5195  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 58s (remain 3m 51s) Loss: 0.0008(0.0023) Grad: 446.0311  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 28s (remain 3m 21s) Loss: 0.0001(0.0023) Grad: 51.1458  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 58s (remain 2m 51s) Loss: 0.0005(0.0022) Grad: 164.5229  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 28s (remain 2m 21s) Loss: 0.0010(0.0023) Grad: 399.6532  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 58s (remain 1m 51s) Loss: 0.0001(0.0023) Grad: 54.7407  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 28s (remain 1m 22s) Loss: 0.0022(0.0023) Grad: 802.3331  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 58s (remain 0m 52s) Loss: 0.0000(0.0023) Grad: 25.1077  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 27s (remain 0m 22s) Loss: 0.0000(0.0023) Grad: 13.6460  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 17m 49s (remain 0m 0s) Loss: 0.0001(0.0023) Grad: 67.8392  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 10s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0005(0.0056) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 22s) Loss: 0.0007(0.0065) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 7s) Loss: 0.0018(0.0105) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.0267(0.0107) \n","EVAL: [500/1192] Elapsed 1m 11s (remain 1m 38s) Loss: 0.0264(0.0096) \n","EVAL: [600/1192] Elapsed 1m 25s (remain 1m 24s) Loss: 0.1270(0.0096) \n","EVAL: [700/1192] Elapsed 1m 39s (remain 1m 9s) Loss: 0.0047(0.0106) \n","EVAL: [800/1192] Elapsed 1m 53s (remain 0m 55s) Loss: 0.0047(0.0103) \n","EVAL: [900/1192] Elapsed 2m 7s (remain 0m 41s) Loss: 0.0034(0.0099) \n","EVAL: [1000/1192] Elapsed 2m 22s (remain 0m 27s) Loss: 0.0000(0.0097) \n","EVAL: [1100/1192] Elapsed 2m 36s (remain 0m 12s) Loss: 0.0055(0.0092) \n","EVAL: [1191/1192] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0084(0.0087) \n","Epoch 2 - avg_train_loss: 0.0023  avg_val_loss: 0.0087  time: 1241s\n","Epoch 2 - Score: 0.8834\n","Epoch 2 - Save Best Score: 0.8834 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 39m 53s) Loss: 0.0021(0.0021) Grad: 383.1491  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 34s (remain 19m 48s) Loss: 0.0091(0.0021) Grad: 2905.7983  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 4s (remain 18m 5s) Loss: 0.0020(0.0019) Grad: 627.3106  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 34s (remain 17m 6s) Loss: 0.0004(0.0017) Grad: 194.2769  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 4s (remain 16m 22s) Loss: 0.0001(0.0018) Grad: 55.6270  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 33s (remain 15m 43s) Loss: 0.0001(0.0018) Grad: 55.3375  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 3s (remain 15m 8s) Loss: 0.0001(0.0019) Grad: 59.0484  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 33s (remain 14m 34s) Loss: 0.0005(0.0019) Grad: 282.9653  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 4m 2s (remain 14m 1s) Loss: 0.0001(0.0019) Grad: 43.6009  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 32s (remain 13m 28s) Loss: 0.0009(0.0019) Grad: 358.8332  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 5m 2s (remain 12m 57s) Loss: 0.0018(0.0020) Grad: 763.7036  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 31s (remain 12m 25s) Loss: 0.0005(0.0019) Grad: 240.0524  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 6m 1s (remain 11m 54s) Loss: 0.0016(0.0020) Grad: 925.2142  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 31s (remain 11m 23s) Loss: 0.0223(0.0020) Grad: 4465.2603  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 7m 0s (remain 10m 53s) Loss: 0.0009(0.0020) Grad: 411.4583  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 30s (remain 10m 22s) Loss: 0.0000(0.0020) Grad: 24.1015  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 8m 0s (remain 9m 52s) Loss: 0.0411(0.0020) Grad: 6190.0317  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 30s (remain 9m 22s) Loss: 0.0000(0.0020) Grad: 26.0957  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 9m 0s (remain 8m 51s) Loss: 0.0023(0.0020) Grad: 691.9073  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 29s (remain 8m 21s) Loss: 0.0004(0.0021) Grad: 207.8115  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 59s (remain 7m 51s) Loss: 0.0001(0.0021) Grad: 76.9554  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 29s (remain 7m 21s) Loss: 0.0003(0.0021) Grad: 190.0798  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 58s (remain 6m 51s) Loss: 0.0000(0.0021) Grad: 10.4418  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 28s (remain 6m 21s) Loss: 0.0008(0.0021) Grad: 403.9794  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 58s (remain 5m 51s) Loss: 0.0001(0.0021) Grad: 33.9018  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 28s (remain 5m 21s) Loss: 0.0017(0.0021) Grad: 706.3450  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 57s (remain 4m 51s) Loss: 0.0000(0.0021) Grad: 25.9939  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 27s (remain 4m 21s) Loss: 0.0001(0.0021) Grad: 81.0500  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 57s (remain 3m 51s) Loss: 0.0001(0.0022) Grad: 56.2225  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 27s (remain 3m 21s) Loss: 0.0000(0.0022) Grad: 15.4021  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 56s (remain 2m 51s) Loss: 0.0000(0.0022) Grad: 4.3686  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 26s (remain 2m 21s) Loss: 0.0014(0.0022) Grad: 574.8798  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 56s (remain 1m 51s) Loss: 0.0004(0.0022) Grad: 194.2437  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 25s (remain 1m 21s) Loss: 0.0001(0.0022) Grad: 40.3256  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 55s (remain 0m 51s) Loss: 0.0003(0.0022) Grad: 169.9029  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 24s (remain 0m 22s) Loss: 0.0004(0.0021) Grad: 252.4962  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 17m 47s (remain 0m 0s) Loss: 0.0001(0.0021) Grad: 81.0331  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 35s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 37s) Loss: 0.0003(0.0058) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 21s) Loss: 0.0007(0.0068) \n","EVAL: [300/1192] Elapsed 0m 42s (remain 2m 7s) Loss: 0.0017(0.0109) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 52s) Loss: 0.0284(0.0112) \n","EVAL: [500/1192] Elapsed 1m 11s (remain 1m 38s) Loss: 0.0265(0.0100) \n","EVAL: [600/1192] Elapsed 1m 25s (remain 1m 24s) Loss: 0.1303(0.0100) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0050(0.0111) \n","EVAL: [800/1192] Elapsed 1m 54s (remain 0m 55s) Loss: 0.0048(0.0107) \n","EVAL: [900/1192] Elapsed 2m 8s (remain 0m 41s) Loss: 0.0038(0.0104) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.0000(0.0101) \n","EVAL: [1100/1192] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0062(0.0096) \n","EVAL: [1191/1192] Elapsed 2m 50s (remain 0m 0s) Loss: 0.0092(0.0091) \n","Epoch 3 - avg_train_loss: 0.0021  avg_val_loss: 0.0091  time: 1240s\n","Epoch 3 - Score: 0.8830\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 39m 29s) Loss: 0.0007(0.0007) Grad: 324.9285  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 30s (remain 17m 26s) Loss: 0.0000(0.0018) Grad: 9.0145  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 0s (remain 16m 48s) Loss: 0.0001(0.0018) Grad: 64.9978  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 29s (remain 16m 16s) Loss: 0.0004(0.0019) Grad: 257.1518  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 59s (remain 15m 45s) Loss: 0.0017(0.0020) Grad: 596.7047  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 29s (remain 15m 15s) Loss: 0.0000(0.0020) Grad: 3.7495  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 58s (remain 14m 44s) Loss: 0.0000(0.0020) Grad: 30.9567  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 28s (remain 14m 13s) Loss: 0.0015(0.0021) Grad: 533.0210  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 57s (remain 13m 42s) Loss: 0.0007(0.0021) Grad: 244.5446  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 27s (remain 13m 12s) Loss: 0.0009(0.0021) Grad: 323.9962  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 56s (remain 12m 41s) Loss: 0.0001(0.0020) Grad: 69.5101  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 25s (remain 12m 11s) Loss: 0.0032(0.0021) Grad: 1287.4304  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 54s (remain 11m 41s) Loss: 0.0002(0.0020) Grad: 113.8167  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 24s (remain 11m 11s) Loss: 0.0000(0.0020) Grad: 28.9227  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 53s (remain 10m 41s) Loss: 0.0002(0.0021) Grad: 149.9005  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 23s (remain 10m 12s) Loss: 0.0005(0.0020) Grad: 436.8701  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 52s (remain 9m 42s) Loss: 0.0000(0.0021) Grad: 36.0860  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 22s (remain 9m 13s) Loss: 0.0007(0.0021) Grad: 394.9871  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 52s (remain 8m 44s) Loss: 0.0039(0.0021) Grad: 1291.5559  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 22s (remain 8m 15s) Loss: 0.0026(0.0021) Grad: 750.3083  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 52s (remain 7m 45s) Loss: 0.0014(0.0021) Grad: 651.3843  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 21s (remain 7m 16s) Loss: 0.0018(0.0021) Grad: 840.3016  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 51s (remain 6m 46s) Loss: 0.0009(0.0021) Grad: 591.9697  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 21s (remain 6m 17s) Loss: 0.0001(0.0021) Grad: 106.9672  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 50s (remain 5m 47s) Loss: 0.0005(0.0021) Grad: 358.8141  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 20s (remain 5m 17s) Loss: 0.0003(0.0021) Grad: 225.3358  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 50s (remain 4m 48s) Loss: 0.0092(0.0021) Grad: 1873.8843  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 19s (remain 4m 18s) Loss: 0.0001(0.0021) Grad: 52.0520  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 49s (remain 3m 49s) Loss: 0.0006(0.0021) Grad: 431.9890  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 19s (remain 3m 19s) Loss: 0.0153(0.0021) Grad: 3234.8384  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 48s (remain 2m 50s) Loss: 0.0027(0.0020) Grad: 1009.1644  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 19s (remain 2m 20s) Loss: 0.0000(0.0020) Grad: 21.9835  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 49s (remain 1m 50s) Loss: 0.0038(0.0020) Grad: 1078.6576  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 16m 19s (remain 1m 21s) Loss: 0.0003(0.0021) Grad: 210.1609  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 48s (remain 0m 51s) Loss: 0.0084(0.0021) Grad: 1656.5275  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 17m 18s (remain 0m 21s) Loss: 0.0007(0.0021) Grad: 444.8229  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 17m 40s (remain 0m 0s) Loss: 0.0018(0.0021) Grad: 801.7947  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 38s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 37s) Loss: 0.0002(0.0058) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 20s) Loss: 0.0005(0.0067) \n","EVAL: [300/1192] Elapsed 0m 42s (remain 2m 6s) Loss: 0.0016(0.0108) \n","EVAL: [400/1192] Elapsed 0m 56s (remain 1m 51s) Loss: 0.0294(0.0110) \n","EVAL: [500/1192] Elapsed 1m 10s (remain 1m 37s) Loss: 0.0249(0.0099) \n","EVAL: [600/1192] Elapsed 1m 24s (remain 1m 23s) Loss: 0.1220(0.0098) \n","EVAL: [700/1192] Elapsed 1m 38s (remain 1m 8s) Loss: 0.0053(0.0109) \n","EVAL: [800/1192] Elapsed 1m 52s (remain 0m 54s) Loss: 0.0047(0.0105) \n","EVAL: [900/1192] Elapsed 2m 6s (remain 0m 40s) Loss: 0.0044(0.0102) \n","EVAL: [1000/1192] Elapsed 2m 20s (remain 0m 26s) Loss: 0.0000(0.0099) \n","EVAL: [1100/1192] Elapsed 2m 34s (remain 0m 12s) Loss: 0.0065(0.0095) \n","EVAL: [1191/1192] Elapsed 2m 47s (remain 0m 0s) Loss: 0.0096(0.0090) \n","Epoch 4 - avg_train_loss: 0.0021  avg_val_loss: 0.0090  time: 1230s\n","Epoch 4 - Score: 0.8844\n","Epoch 4 - Save Best Score: 0.8844 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 41m 2s) Loss: 0.0000(0.0000) Grad: 801.8744  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 35s (remain 20m 7s) Loss: 0.0002(0.0022) Grad: 140.9623  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 4s (remain 18m 5s) Loss: 0.0004(0.0021) Grad: 319.1329  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 34s (remain 17m 5s) Loss: 0.0000(0.0019) Grad: 24.1736  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 2m 3s (remain 16m 18s) Loss: 0.0015(0.0020) Grad: 659.9742  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 33s (remain 15m 40s) Loss: 0.0000(0.0020) Grad: 36.3093  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 3m 2s (remain 15m 4s) Loss: 0.0003(0.0020) Grad: 236.1362  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 32s (remain 14m 30s) Loss: 0.0001(0.0020) Grad: 53.2947  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 4m 2s (remain 13m 58s) Loss: 0.0002(0.0020) Grad: 143.5416  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 32s (remain 13m 28s) Loss: 0.0005(0.0021) Grad: 316.4456  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 5m 1s (remain 12m 56s) Loss: 0.0000(0.0021) Grad: 30.6451  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 31s (remain 12m 25s) Loss: 0.0000(0.0021) Grad: 10.5855  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 6m 1s (remain 11m 54s) Loss: 0.0000(0.0021) Grad: 13.5030  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 30s (remain 11m 23s) Loss: 0.0002(0.0021) Grad: 174.7695  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 7m 0s (remain 10m 52s) Loss: 0.0161(0.0022) Grad: 3256.3857  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 30s (remain 10m 21s) Loss: 0.0012(0.0021) Grad: 610.8561  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 59s (remain 9m 51s) Loss: 0.0000(0.0022) Grad: 11.2706  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 29s (remain 9m 21s) Loss: 0.0001(0.0023) Grad: 46.1749  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 58s (remain 8m 50s) Loss: 0.0002(0.0023) Grad: 82.6134  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 28s (remain 8m 20s) Loss: 0.0004(0.0023) Grad: 240.3558  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 58s (remain 7m 50s) Loss: 0.0069(0.0023) Grad: 1648.0682  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 27s (remain 7m 20s) Loss: 0.0002(0.0022) Grad: 147.0772  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 57s (remain 6m 50s) Loss: 0.0004(0.0022) Grad: 291.3846  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 26s (remain 6m 20s) Loss: 0.0025(0.0022) Grad: 430.5798  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 56s (remain 5m 50s) Loss: 0.0016(0.0022) Grad: 607.8721  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 26s (remain 5m 20s) Loss: 0.0041(0.0022) Grad: 797.1845  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 55s (remain 4m 50s) Loss: 0.0039(0.0021) Grad: 1339.6995  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 25s (remain 4m 20s) Loss: 0.0003(0.0022) Grad: 225.7997  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 54s (remain 3m 50s) Loss: 0.0000(0.0021) Grad: 36.5634  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 24s (remain 3m 20s) Loss: 0.0030(0.0021) Grad: 744.3019  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 54s (remain 2m 51s) Loss: 0.0001(0.0021) Grad: 112.8711  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 23s (remain 2m 21s) Loss: 0.0000(0.0021) Grad: 10.1732  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 53s (remain 1m 51s) Loss: 0.0004(0.0020) Grad: 220.5108  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 22s (remain 1m 21s) Loss: 0.0065(0.0020) Grad: 1924.7278  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 52s (remain 0m 51s) Loss: 0.0009(0.0020) Grad: 402.7511  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 17m 21s (remain 0m 22s) Loss: 0.0001(0.0020) Grad: 98.4604  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 17m 43s (remain 0m 0s) Loss: 0.0001(0.0020) Grad: 84.9247  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 23s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 34s) Loss: 0.0002(0.0058) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 20s) Loss: 0.0005(0.0067) \n","EVAL: [300/1192] Elapsed 0m 42s (remain 2m 6s) Loss: 0.0017(0.0107) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 52s) Loss: 0.0298(0.0110) \n","EVAL: [500/1192] Elapsed 1m 11s (remain 1m 38s) Loss: 0.0248(0.0099) \n","EVAL: [600/1192] Elapsed 1m 24s (remain 1m 23s) Loss: 0.1192(0.0098) \n","EVAL: [700/1192] Elapsed 1m 38s (remain 1m 9s) Loss: 0.0053(0.0108) \n","EVAL: [800/1192] Elapsed 1m 52s (remain 0m 54s) Loss: 0.0047(0.0105) \n","EVAL: [900/1192] Elapsed 2m 6s (remain 0m 40s) Loss: 0.0046(0.0102) \n","EVAL: [1000/1192] Elapsed 2m 20s (remain 0m 26s) Loss: 0.0000(0.0099) \n","EVAL: [1100/1192] Elapsed 2m 33s (remain 0m 12s) Loss: 0.0065(0.0094) \n","EVAL: [1191/1192] Elapsed 2m 46s (remain 0m 0s) Loss: 0.0096(0.0089) \n","Epoch 5 - avg_train_loss: 0.0020  avg_val_loss: 0.0089  time: 1232s\n","Epoch 5 - Score: 0.8843\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold2_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 51m 23s) Loss: 0.3696(0.3696) Grad: 85423.0234  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 30s (remain 17m 16s) Loss: 0.3427(0.3600) Grad: 80615.2109  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 59s (remain 16m 37s) Loss: 0.2718(0.3362) Grad: 68771.2891  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 28s (remain 16m 4s) Loss: 0.1743(0.3001) Grad: 52636.5195  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 57s (remain 15m 33s) Loss: 0.0868(0.2583) Grad: 32767.1367  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 27s (remain 15m 3s) Loss: 0.0301(0.2181) Grad: 13659.6006  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 56s (remain 14m 32s) Loss: 0.0086(0.1850) Grad: 3567.2937  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 25s (remain 14m 2s) Loss: 0.0204(0.1598) Grad: 1697.6321  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 54s (remain 13m 32s) Loss: 0.0039(0.1405) Grad: 970.7017  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 23s (remain 13m 2s) Loss: 0.0017(0.1254) Grad: 445.9432  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 52s (remain 12m 33s) Loss: 0.0113(0.1132) Grad: 1394.0231  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 22s (remain 12m 3s) Loss: 0.0015(0.1032) Grad: 401.8294  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 51s (remain 11m 34s) Loss: 0.0043(0.0950) Grad: 697.4222  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 20s (remain 11m 4s) Loss: 0.0003(0.0879) Grad: 111.4786  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 49s (remain 10m 35s) Loss: 0.0009(0.0818) Grad: 211.0281  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 18s (remain 10m 6s) Loss: 0.0010(0.0767) Grad: 286.0679  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 47s (remain 9m 36s) Loss: 0.0032(0.0721) Grad: 644.8214  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 17s (remain 9m 7s) Loss: 0.0010(0.0680) Grad: 301.1475  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 46s (remain 8m 38s) Loss: 0.0004(0.0644) Grad: 120.8952  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 15s (remain 8m 9s) Loss: 0.0011(0.0612) Grad: 252.5897  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 44s (remain 7m 39s) Loss: 0.0014(0.0583) Grad: 432.3313  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 13s (remain 7m 10s) Loss: 0.0068(0.0557) Grad: 1167.9171  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 43s (remain 6m 41s) Loss: 0.0054(0.0533) Grad: 762.9435  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 12s (remain 6m 12s) Loss: 0.0005(0.0511) Grad: 136.2344  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 41s (remain 5m 42s) Loss: 0.0038(0.0491) Grad: 987.1171  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 10s (remain 5m 13s) Loss: 0.0103(0.0472) Grad: 1554.0128  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 39s (remain 4m 44s) Loss: 0.0012(0.0455) Grad: 270.2992  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 9s (remain 4m 15s) Loss: 0.0030(0.0440) Grad: 1103.6798  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 38s (remain 3m 46s) Loss: 0.0000(0.0425) Grad: 12.0173  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 7s (remain 3m 16s) Loss: 0.0011(0.0411) Grad: 318.9927  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 37s (remain 2m 47s) Loss: 0.0017(0.0399) Grad: 293.9854  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 6s (remain 2m 18s) Loss: 0.0004(0.0386) Grad: 152.1327  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 35s (remain 1m 49s) Loss: 0.0069(0.0376) Grad: 1060.0472  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 4s (remain 1m 20s) Loss: 0.0005(0.0365) Grad: 168.2298  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 34s (remain 0m 50s) Loss: 0.0016(0.0355) Grad: 565.5222  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 17m 3s (remain 0m 21s) Loss: 0.0002(0.0346) Grad: 98.3659  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 17m 24s (remain 0m 0s) Loss: 0.0001(0.0340) Grad: 34.3909  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 59s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 33s) Loss: 0.0291(0.0079) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 17s) Loss: 0.0076(0.0071) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 2s) Loss: 0.0091(0.0071) \n","EVAL: [400/1192] Elapsed 0m 55s (remain 1m 48s) Loss: 0.0002(0.0076) \n","EVAL: [500/1192] Elapsed 1m 8s (remain 1m 35s) Loss: 0.0002(0.0070) \n","EVAL: [600/1192] Elapsed 1m 22s (remain 1m 21s) Loss: 0.0098(0.0073) \n","EVAL: [700/1192] Elapsed 1m 36s (remain 1m 7s) Loss: 0.0077(0.0080) \n","EVAL: [800/1192] Elapsed 1m 50s (remain 0m 53s) Loss: 0.0000(0.0082) \n","EVAL: [900/1192] Elapsed 2m 3s (remain 0m 40s) Loss: 0.0121(0.0083) \n","EVAL: [1000/1192] Elapsed 2m 17s (remain 0m 26s) Loss: 0.0003(0.0082) \n","EVAL: [1100/1192] Elapsed 2m 31s (remain 0m 12s) Loss: 0.0532(0.0078) \n","EVAL: [1191/1192] Elapsed 2m 43s (remain 0m 0s) Loss: 0.0001(0.0075) \n","Epoch 1 - avg_train_loss: 0.0340  avg_val_loss: 0.0075  time: 1212s\n","Epoch 1 - Score: 0.8859\n","Epoch 1 - Save Best Score: 0.8859 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 44m 9s) Loss: 0.0003(0.0003) Grad: 202.9297  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 33s (remain 19m 20s) Loss: 0.0000(0.0024) Grad: 11.7936  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 3s (remain 17m 40s) Loss: 0.0001(0.0024) Grad: 54.8791  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 32s (remain 16m 44s) Loss: 0.0007(0.0024) Grad: 300.6114  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 1s (remain 16m 1s) Loss: 0.0001(0.0024) Grad: 33.4796  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 30s (remain 15m 24s) Loss: 0.0002(0.0025) Grad: 99.2551  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 59s (remain 14m 49s) Loss: 0.0002(0.0024) Grad: 121.3340  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 28s (remain 14m 16s) Loss: 0.0002(0.0023) Grad: 83.5481  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 58s (remain 13m 44s) Loss: 0.0005(0.0023) Grad: 249.4417  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 27s (remain 13m 13s) Loss: 0.0013(0.0023) Grad: 358.3601  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 56s (remain 12m 42s) Loss: 0.0001(0.0024) Grad: 69.4559  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 25s (remain 12m 12s) Loss: 0.0011(0.0026) Grad: 635.0680  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 55s (remain 11m 42s) Loss: 0.0055(0.0026) Grad: 1339.8508  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 24s (remain 11m 12s) Loss: 0.0110(0.0026) Grad: 1612.8240  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 53s (remain 10m 42s) Loss: 0.0002(0.0027) Grad: 136.7514  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 23s (remain 10m 12s) Loss: 0.0007(0.0027) Grad: 369.8513  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 52s (remain 9m 42s) Loss: 0.0002(0.0027) Grad: 117.1871  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 21s (remain 9m 12s) Loss: 0.0048(0.0026) Grad: 1120.7228  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 50s (remain 8m 42s) Loss: 0.0000(0.0026) Grad: 23.4695  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 20s (remain 8m 13s) Loss: 0.0232(0.0026) Grad: 5765.3511  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 49s (remain 7m 43s) Loss: 0.0057(0.0026) Grad: 1755.0878  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 18s (remain 7m 14s) Loss: 0.0040(0.0026) Grad: 612.5386  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 47s (remain 6m 44s) Loss: 0.0034(0.0026) Grad: 763.3807  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 17s (remain 6m 14s) Loss: 0.0006(0.0026) Grad: 225.2764  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 46s (remain 5m 45s) Loss: 0.0001(0.0026) Grad: 36.3221  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 16s (remain 5m 16s) Loss: 0.0008(0.0026) Grad: 176.0628  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 45s (remain 4m 46s) Loss: 0.0001(0.0027) Grad: 51.6345  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 14s (remain 4m 17s) Loss: 0.0002(0.0026) Grad: 107.6099  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 44s (remain 3m 47s) Loss: 0.0007(0.0026) Grad: 394.6209  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 13s (remain 3m 18s) Loss: 0.0086(0.0026) Grad: 1832.1968  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 43s (remain 2m 48s) Loss: 0.0106(0.0026) Grad: 1681.6576  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 13s (remain 2m 19s) Loss: 0.0149(0.0026) Grad: 3474.5942  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 43s (remain 1m 50s) Loss: 0.0000(0.0026) Grad: 27.3264  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 13s (remain 1m 20s) Loss: 0.0001(0.0027) Grad: 32.2565  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 42s (remain 0m 51s) Loss: 0.0020(0.0026) Grad: 510.2151  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 12s (remain 0m 21s) Loss: 0.0037(0.0026) Grad: 940.1406  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 17m 34s (remain 0m 0s) Loss: 0.0001(0.0026) Grad: 81.7555  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 7s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 37s) Loss: 0.0260(0.0078) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 21s) Loss: 0.0060(0.0071) \n","EVAL: [300/1192] Elapsed 0m 42s (remain 2m 6s) Loss: 0.0078(0.0070) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 52s) Loss: 0.0002(0.0075) \n","EVAL: [500/1192] Elapsed 1m 11s (remain 1m 38s) Loss: 0.0001(0.0070) \n","EVAL: [600/1192] Elapsed 1m 25s (remain 1m 24s) Loss: 0.0085(0.0072) \n","EVAL: [700/1192] Elapsed 1m 39s (remain 1m 10s) Loss: 0.0056(0.0079) \n","EVAL: [800/1192] Elapsed 1m 54s (remain 0m 55s) Loss: 0.0000(0.0081) \n","EVAL: [900/1192] Elapsed 2m 8s (remain 0m 41s) Loss: 0.0127(0.0083) \n","EVAL: [1000/1192] Elapsed 2m 22s (remain 0m 27s) Loss: 0.0004(0.0081) \n","EVAL: [1100/1192] Elapsed 2m 36s (remain 0m 12s) Loss: 0.0590(0.0077) \n","EVAL: [1191/1192] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0001(0.0074) \n","Epoch 2 - avg_train_loss: 0.0026  avg_val_loss: 0.0074  time: 1226s\n","Epoch 2 - Score: 0.8872\n","Epoch 2 - Save Best Score: 0.8872 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 40m 38s) Loss: 0.0032(0.0032) Grad: 848.8223  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 35s (remain 20m 12s) Loss: 0.0109(0.0033) Grad: 1933.1866  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 4s (remain 18m 7s) Loss: 0.0001(0.0027) Grad: 49.6810  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 34s (remain 17m 5s) Loss: 0.0002(0.0025) Grad: 76.0686  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 3s (remain 16m 19s) Loss: 0.0003(0.0028) Grad: 124.2406  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 33s (remain 15m 40s) Loss: 0.0006(0.0026) Grad: 272.9473  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 2s (remain 15m 4s) Loss: 0.0004(0.0027) Grad: 208.7368  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 32s (remain 14m 30s) Loss: 0.0060(0.0027) Grad: 956.8305  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 4m 1s (remain 13m 57s) Loss: 0.0061(0.0028) Grad: 1654.5010  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 31s (remain 13m 26s) Loss: 0.0015(0.0027) Grad: 807.5227  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 5m 1s (remain 12m 54s) Loss: 0.0007(0.0028) Grad: 342.5873  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 30s (remain 12m 23s) Loss: 0.0001(0.0028) Grad: 54.2436  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 6m 0s (remain 11m 52s) Loss: 0.0049(0.0028) Grad: 1648.6226  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 29s (remain 11m 21s) Loss: 0.0000(0.0027) Grad: 25.1406  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 59s (remain 10m 50s) Loss: 0.0000(0.0027) Grad: 19.2556  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 28s (remain 10m 19s) Loss: 0.0004(0.0027) Grad: 208.5565  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 57s (remain 9m 49s) Loss: 0.0027(0.0027) Grad: 722.6365  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 27s (remain 9m 18s) Loss: 0.0000(0.0027) Grad: 22.9466  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 56s (remain 8m 48s) Loss: 0.0006(0.0027) Grad: 229.8860  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 25s (remain 8m 18s) Loss: 0.0002(0.0027) Grad: 123.7734  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 55s (remain 7m 48s) Loss: 0.0001(0.0027) Grad: 45.9167  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 24s (remain 7m 18s) Loss: 0.0002(0.0027) Grad: 81.5487  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 53s (remain 6m 48s) Loss: 0.0000(0.0027) Grad: 29.1744  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 23s (remain 6m 18s) Loss: 0.0006(0.0027) Grad: 302.2760  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 52s (remain 5m 48s) Loss: 0.0006(0.0027) Grad: 199.3087  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 22s (remain 5m 18s) Loss: 0.0077(0.0027) Grad: 1370.2435  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 51s (remain 4m 48s) Loss: 0.0001(0.0026) Grad: 34.4953  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 20s (remain 4m 19s) Loss: 0.0001(0.0026) Grad: 91.1430  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 50s (remain 3m 49s) Loss: 0.0001(0.0026) Grad: 79.5044  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 19s (remain 3m 19s) Loss: 0.0002(0.0026) Grad: 121.3446  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 48s (remain 2m 50s) Loss: 0.0006(0.0025) Grad: 367.4582  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 18s (remain 2m 20s) Loss: 0.0000(0.0025) Grad: 16.5422  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 47s (remain 1m 50s) Loss: 0.0014(0.0026) Grad: 548.5273  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 16s (remain 1m 21s) Loss: 0.0002(0.0025) Grad: 127.2451  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 45s (remain 0m 51s) Loss: 0.0091(0.0026) Grad: 2496.2124  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 15s (remain 0m 21s) Loss: 0.0001(0.0025) Grad: 97.3590  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 17m 37s (remain 0m 0s) Loss: 0.0001(0.0025) Grad: 57.9614  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 30s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 34s) Loss: 0.0280(0.0079) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 17s) Loss: 0.0066(0.0071) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 3s) Loss: 0.0086(0.0070) \n","EVAL: [400/1192] Elapsed 0m 55s (remain 1m 49s) Loss: 0.0001(0.0075) \n","EVAL: [500/1192] Elapsed 1m 9s (remain 1m 35s) Loss: 0.0001(0.0070) \n","EVAL: [600/1192] Elapsed 1m 23s (remain 1m 21s) Loss: 0.0092(0.0072) \n","EVAL: [700/1192] Elapsed 1m 37s (remain 1m 8s) Loss: 0.0058(0.0079) \n","EVAL: [800/1192] Elapsed 1m 51s (remain 0m 54s) Loss: 0.0000(0.0081) \n","EVAL: [900/1192] Elapsed 2m 4s (remain 0m 40s) Loss: 0.0114(0.0082) \n","EVAL: [1000/1192] Elapsed 2m 18s (remain 0m 26s) Loss: 0.0004(0.0081) \n","EVAL: [1100/1192] Elapsed 2m 32s (remain 0m 12s) Loss: 0.0572(0.0077) \n","EVAL: [1191/1192] Elapsed 2m 45s (remain 0m 0s) Loss: 0.0001(0.0074) \n","Epoch 3 - avg_train_loss: 0.0025  avg_val_loss: 0.0074  time: 1225s\n","Epoch 3 - Score: 0.8882\n","Epoch 3 - Save Best Score: 0.8882 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 42m 42s) Loss: 0.0004(0.0004) Grad: 285.8944  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 34s (remain 19m 34s) Loss: 0.0019(0.0019) Grad: 638.9358  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 3s (remain 17m 50s) Loss: 0.0006(0.0020) Grad: 316.8671  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 33s (remain 16m 53s) Loss: 0.0002(0.0024) Grad: 146.5146  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 2s (remain 16m 11s) Loss: 0.0001(0.0025) Grad: 39.0885  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 31s (remain 15m 32s) Loss: 0.0000(0.0026) Grad: 30.0102  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 3m 1s (remain 14m 57s) Loss: 0.0004(0.0027) Grad: 213.8784  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 30s (remain 14m 23s) Loss: 0.0045(0.0027) Grad: 1801.4349  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 59s (remain 13m 51s) Loss: 0.0422(0.0026) Grad: 7405.1621  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 29s (remain 13m 19s) Loss: 0.0007(0.0026) Grad: 366.0386  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 58s (remain 12m 48s) Loss: 0.0001(0.0025) Grad: 88.7697  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 28s (remain 12m 17s) Loss: 0.0001(0.0026) Grad: 69.1854  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 57s (remain 11m 46s) Loss: 0.0003(0.0025) Grad: 159.7525  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 27s (remain 11m 16s) Loss: 0.0001(0.0025) Grad: 43.9108  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 56s (remain 10m 46s) Loss: 0.0000(0.0025) Grad: 3.5161  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 26s (remain 10m 16s) Loss: 0.0003(0.0025) Grad: 180.8302  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 55s (remain 9m 46s) Loss: 0.0002(0.0025) Grad: 104.9476  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 24s (remain 9m 15s) Loss: 0.0001(0.0025) Grad: 78.6393  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 54s (remain 8m 46s) Loss: 0.0073(0.0025) Grad: 2605.5288  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 23s (remain 8m 16s) Loss: 0.0056(0.0024) Grad: 1500.9916  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 52s (remain 7m 46s) Loss: 0.0616(0.0024) Grad: 12282.1904  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 22s (remain 7m 16s) Loss: 0.0001(0.0024) Grad: 53.3516  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 51s (remain 6m 46s) Loss: 0.0032(0.0023) Grad: 1167.5217  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 20s (remain 6m 16s) Loss: 0.0004(0.0024) Grad: 200.4400  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 50s (remain 5m 47s) Loss: 0.0000(0.0024) Grad: 7.5187  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 19s (remain 5m 17s) Loss: 0.0115(0.0024) Grad: 2766.3777  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 48s (remain 4m 47s) Loss: 0.0001(0.0024) Grad: 44.2572  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 17s (remain 4m 18s) Loss: 0.0000(0.0024) Grad: 33.1911  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 47s (remain 3m 48s) Loss: 0.0007(0.0024) Grad: 320.1439  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 16s (remain 3m 19s) Loss: 0.0060(0.0024) Grad: 958.1442  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 46s (remain 2m 49s) Loss: 0.0005(0.0024) Grad: 347.9778  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 15s (remain 2m 19s) Loss: 0.0021(0.0024) Grad: 778.0535  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 44s (remain 1m 50s) Loss: 0.0000(0.0025) Grad: 12.2920  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 16m 13s (remain 1m 20s) Loss: 0.0000(0.0025) Grad: 19.4850  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 43s (remain 0m 51s) Loss: 0.0007(0.0025) Grad: 379.5490  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 17m 12s (remain 0m 21s) Loss: 0.0001(0.0025) Grad: 78.9720  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 17m 34s (remain 0m 0s) Loss: 0.0114(0.0025) Grad: 2639.6177  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 16s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 34s) Loss: 0.0287(0.0077) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 18s) Loss: 0.0065(0.0070) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 3s) Loss: 0.0090(0.0069) \n","EVAL: [400/1192] Elapsed 0m 55s (remain 1m 49s) Loss: 0.0001(0.0074) \n","EVAL: [500/1192] Elapsed 1m 9s (remain 1m 35s) Loss: 0.0002(0.0068) \n","EVAL: [600/1192] Elapsed 1m 23s (remain 1m 21s) Loss: 0.0096(0.0070) \n","EVAL: [700/1192] Elapsed 1m 36s (remain 1m 7s) Loss: 0.0059(0.0077) \n","EVAL: [800/1192] Elapsed 1m 50s (remain 0m 53s) Loss: 0.0000(0.0079) \n","EVAL: [900/1192] Elapsed 2m 4s (remain 0m 40s) Loss: 0.0102(0.0081) \n","EVAL: [1000/1192] Elapsed 2m 18s (remain 0m 26s) Loss: 0.0004(0.0079) \n","EVAL: [1100/1192] Elapsed 2m 32s (remain 0m 12s) Loss: 0.0567(0.0075) \n","EVAL: [1191/1192] Elapsed 2m 44s (remain 0m 0s) Loss: 0.0001(0.0072) \n","Epoch 4 - avg_train_loss: 0.0025  avg_val_loss: 0.0072  time: 1221s\n","Epoch 4 - Score: 0.8887\n","Epoch 4 - Save Best Score: 0.8887 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 40m 41s) Loss: 0.0049(0.0049) Grad: 1405.0201  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 34s (remain 19m 50s) Loss: 0.0002(0.0021) Grad: 151.4000  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 4s (remain 17m 55s) Loss: 0.0238(0.0021) Grad: 4999.4766  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 33s (remain 16m 56s) Loss: 0.0010(0.0024) Grad: 375.0380  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 2m 2s (remain 16m 10s) Loss: 0.0042(0.0023) Grad: 1553.4978  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 31s (remain 15m 32s) Loss: 0.0012(0.0025) Grad: 497.9117  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 3m 1s (remain 14m 56s) Loss: 0.0000(0.0024) Grad: 9.9841  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 30s (remain 14m 23s) Loss: 0.0000(0.0023) Grad: 5.9551  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 59s (remain 13m 50s) Loss: 0.0002(0.0022) Grad: 129.3540  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 29s (remain 13m 18s) Loss: 0.0056(0.0022) Grad: 1556.8276  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 58s (remain 12m 47s) Loss: 0.0001(0.0022) Grad: 59.2373  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 27s (remain 12m 16s) Loss: 0.0095(0.0022) Grad: 2589.9773  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 57s (remain 11m 45s) Loss: 0.0002(0.0022) Grad: 100.3935  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 26s (remain 11m 15s) Loss: 0.0000(0.0023) Grad: 30.8137  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 24s (remain 10m 14s) Loss: 0.0000(0.0023) Grad: 12.1609  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 54s (remain 9m 44s) Loss: 0.0299(0.0023) Grad: 6257.7285  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 23s (remain 9m 14s) Loss: 0.0010(0.0023) Grad: 431.9699  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 52s (remain 8m 44s) Loss: 0.0001(0.0024) Grad: 57.0440  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 21s (remain 8m 14s) Loss: 0.0003(0.0024) Grad: 193.4371  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 51s (remain 7m 44s) Loss: 0.0070(0.0024) Grad: 2639.2097  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 20s (remain 7m 15s) Loss: 0.0000(0.0024) Grad: 37.6459  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 49s (remain 6m 45s) Loss: 0.0054(0.0025) Grad: 2128.5481  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 18s (remain 6m 15s) Loss: 0.0469(0.0025) Grad: 9940.4658  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 48s (remain 5m 46s) Loss: 0.0010(0.0025) Grad: 401.1516  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 17s (remain 5m 16s) Loss: 0.0081(0.0025) Grad: 2547.5637  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 46s (remain 4m 47s) Loss: 0.0006(0.0024) Grad: 330.3945  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 15s (remain 4m 17s) Loss: 0.0000(0.0024) Grad: 34.5031  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 45s (remain 3m 48s) Loss: 0.0001(0.0025) Grad: 93.8737  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 14s (remain 3m 18s) Loss: 0.0029(0.0024) Grad: 868.8981  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 43s (remain 2m 49s) Loss: 0.0009(0.0025) Grad: 566.3246  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 13s (remain 2m 19s) Loss: 0.0003(0.0025) Grad: 175.8254  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 43s (remain 1m 50s) Loss: 0.0001(0.0025) Grad: 56.5818  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 13s (remain 1m 20s) Loss: 0.0028(0.0025) Grad: 1154.3535  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 42s (remain 0m 51s) Loss: 0.0114(0.0025) Grad: 3314.2603  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 17m 12s (remain 0m 21s) Loss: 0.0191(0.0025) Grad: 3858.5713  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 17m 34s (remain 0m 0s) Loss: 0.0068(0.0025) Grad: 1309.8137  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 23s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 37s) Loss: 0.0290(0.0080) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 21s) Loss: 0.0063(0.0072) \n","EVAL: [300/1192] Elapsed 0m 42s (remain 2m 6s) Loss: 0.0085(0.0071) \n","EVAL: [400/1192] Elapsed 0m 56s (remain 1m 51s) Loss: 0.0001(0.0076) \n","EVAL: [500/1192] Elapsed 1m 11s (remain 1m 37s) Loss: 0.0001(0.0070) \n","EVAL: [600/1192] Elapsed 1m 25s (remain 1m 23s) Loss: 0.0093(0.0072) \n","EVAL: [700/1192] Elapsed 1m 39s (remain 1m 9s) Loss: 0.0058(0.0079) \n","EVAL: [800/1192] Elapsed 1m 53s (remain 0m 55s) Loss: 0.0000(0.0081) \n","EVAL: [900/1192] Elapsed 2m 7s (remain 0m 41s) Loss: 0.0110(0.0083) \n","EVAL: [1000/1192] Elapsed 2m 21s (remain 0m 26s) Loss: 0.0004(0.0081) \n","EVAL: [1100/1192] Elapsed 2m 35s (remain 0m 12s) Loss: 0.0588(0.0078) \n","EVAL: [1191/1192] Elapsed 2m 47s (remain 0m 0s) Loss: 0.0001(0.0075) \n","Epoch 5 - avg_train_loss: 0.0025  avg_val_loss: 0.0075  time: 1225s\n","Epoch 5 - Score: 0.8885\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold3_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 55m 46s) Loss: 0.3349(0.3349) Grad: 76906.0625  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 30s (remain 17m 31s) Loss: 0.3112(0.3275) Grad: 73883.6953  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 1m 0s (remain 16m 48s) Loss: 0.2462(0.3048) Grad: 63213.3945  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 29s (remain 16m 16s) Loss: 0.1539(0.2705) Grad: 48485.5391  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 59s (remain 15m 45s) Loss: 0.0669(0.2310) Grad: 27867.5410  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 29s (remain 15m 14s) Loss: 0.0239(0.1940) Grad: 10975.3242  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 58s (remain 14m 44s) Loss: 0.0080(0.1644) Grad: 2708.7729  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 28s (remain 14m 14s) Loss: 0.0074(0.1419) Grad: 1611.9135  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 57s (remain 13m 43s) Loss: 0.0012(0.1248) Grad: 324.0103  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 27s (remain 13m 14s) Loss: 0.0005(0.1113) Grad: 212.1606  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 57s (remain 12m 44s) Loss: 0.0006(0.1006) Grad: 181.2595  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 26s (remain 12m 14s) Loss: 0.0017(0.0918) Grad: 278.4765  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 56s (remain 11m 44s) Loss: 0.0005(0.0844) Grad: 147.4421  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 26s (remain 11m 14s) Loss: 0.0003(0.0782) Grad: 111.2915  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 55s (remain 10m 44s) Loss: 0.0101(0.0728) Grad: 1010.5452  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 25s (remain 10m 15s) Loss: 0.0016(0.0682) Grad: 404.4788  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 54s (remain 9m 45s) Loss: 0.0015(0.0641) Grad: 309.3765  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 24s (remain 9m 15s) Loss: 0.0138(0.0605) Grad: 3453.7139  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 54s (remain 8m 46s) Loss: 0.0015(0.0574) Grad: 236.5378  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 23s (remain 8m 16s) Loss: 0.0007(0.0546) Grad: 155.0181  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 53s (remain 7m 46s) Loss: 0.0011(0.0520) Grad: 298.2226  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 22s (remain 7m 17s) Loss: 0.0001(0.0497) Grad: 36.1985  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 52s (remain 6m 47s) Loss: 0.0015(0.0475) Grad: 237.0759  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 21s (remain 6m 17s) Loss: 0.0001(0.0455) Grad: 59.1034  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 51s (remain 5m 47s) Loss: 0.0002(0.0437) Grad: 76.3391  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 20s (remain 5m 17s) Loss: 0.0035(0.0421) Grad: 773.7733  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 49s (remain 4m 48s) Loss: 0.0001(0.0405) Grad: 45.1525  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 19s (remain 4m 18s) Loss: 0.0009(0.0391) Grad: 255.9467  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 48s (remain 3m 48s) Loss: 0.0006(0.0378) Grad: 359.8593  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 17s (remain 3m 19s) Loss: 0.0003(0.0366) Grad: 123.2997  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 46s (remain 2m 49s) Loss: 0.0004(0.0354) Grad: 174.4215  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 16s (remain 2m 20s) Loss: 0.0006(0.0344) Grad: 229.9414  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 45s (remain 1m 50s) Loss: 0.0001(0.0334) Grad: 72.1032  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 14s (remain 1m 20s) Loss: 0.0078(0.0325) Grad: 1739.7977  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 44s (remain 0m 51s) Loss: 0.0162(0.0316) Grad: 2162.1130  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 17m 13s (remain 0m 21s) Loss: 0.0003(0.0307) Grad: 119.2104  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 17m 35s (remain 0m 0s) Loss: 0.0002(0.0302) Grad: 80.3488  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 11m 33s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 35s) Loss: 0.0467(0.0078) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 18s) Loss: 0.0085(0.0071) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 4s) Loss: 0.0080(0.0077) \n","EVAL: [400/1192] Elapsed 0m 55s (remain 1m 50s) Loss: 0.0000(0.0073) \n","EVAL: [500/1192] Elapsed 1m 9s (remain 1m 36s) Loss: 0.0612(0.0070) \n","EVAL: [600/1192] Elapsed 1m 23s (remain 1m 22s) Loss: 0.0100(0.0073) \n","EVAL: [700/1192] Elapsed 1m 37s (remain 1m 8s) Loss: 0.0042(0.0080) \n","EVAL: [800/1192] Elapsed 1m 51s (remain 0m 54s) Loss: 0.0200(0.0080) \n","EVAL: [900/1192] Elapsed 2m 5s (remain 0m 40s) Loss: 0.0100(0.0082) \n","EVAL: [1000/1192] Elapsed 2m 18s (remain 0m 26s) Loss: 0.0001(0.0080) \n","EVAL: [1100/1192] Elapsed 2m 32s (remain 0m 12s) Loss: 0.0170(0.0078) \n","EVAL: [1191/1192] Elapsed 2m 45s (remain 0m 0s) Loss: 0.0001(0.0076) \n","Epoch 1 - avg_train_loss: 0.0302  avg_val_loss: 0.0076  time: 1223s\n","Epoch 1 - Score: 0.8903\n","Epoch 1 - Save Best Score: 0.8903 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 44m 24s) Loss: 0.0001(0.0001) Grad: 123.8807  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 34s (remain 19m 37s) Loss: 0.0001(0.0016) Grad: 61.7860  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 3s (remain 17m 54s) Loss: 0.0007(0.0022) Grad: 310.5398  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 33s (remain 16m 54s) Loss: 0.0003(0.0021) Grad: 118.9880  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 2s (remain 16m 10s) Loss: 0.0062(0.0022) Grad: 1286.2465  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 31s (remain 15m 32s) Loss: 0.0031(0.0025) Grad: 1048.0542  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 3m 1s (remain 14m 57s) Loss: 0.0001(0.0024) Grad: 39.0928  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 30s (remain 14m 23s) Loss: 0.0001(0.0025) Grad: 36.7745  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 4m 0s (remain 13m 51s) Loss: 0.0002(0.0027) Grad: 94.4761  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 29s (remain 13m 19s) Loss: 0.0001(0.0026) Grad: 49.2453  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 58s (remain 12m 48s) Loss: 0.0136(0.0026) Grad: 2684.6323  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 28s (remain 12m 17s) Loss: 0.0006(0.0026) Grad: 286.2867  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 57s (remain 11m 46s) Loss: 0.0006(0.0025) Grad: 265.2800  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 26s (remain 11m 15s) Loss: 0.0005(0.0025) Grad: 209.9905  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 55s (remain 10m 45s) Loss: 0.0016(0.0026) Grad: 644.5178  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 25s (remain 10m 15s) Loss: 0.0012(0.0025) Grad: 429.9490  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 54s (remain 9m 45s) Loss: 0.0010(0.0025) Grad: 333.0639  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 23s (remain 9m 15s) Loss: 0.0001(0.0025) Grad: 83.1489  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 53s (remain 8m 45s) Loss: 0.0005(0.0024) Grad: 254.6617  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 22s (remain 8m 15s) Loss: 0.0010(0.0024) Grad: 185.1075  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 51s (remain 7m 45s) Loss: 0.0012(0.0024) Grad: 520.1111  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 21s (remain 7m 15s) Loss: 0.0004(0.0024) Grad: 160.1950  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 50s (remain 6m 46s) Loss: 0.0063(0.0024) Grad: 1680.4960  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 19s (remain 6m 16s) Loss: 0.0000(0.0024) Grad: 23.8914  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 49s (remain 5m 46s) Loss: 0.0013(0.0023) Grad: 215.6397  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 18s (remain 5m 17s) Loss: 0.0234(0.0024) Grad: 5334.0693  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 47s (remain 4m 47s) Loss: 0.0001(0.0024) Grad: 59.0475  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 17s (remain 4m 17s) Loss: 0.0003(0.0024) Grad: 185.5307  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 46s (remain 3m 48s) Loss: 0.0001(0.0024) Grad: 40.9141  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 15s (remain 3m 18s) Loss: 0.0001(0.0024) Grad: 44.0977  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 45s (remain 2m 49s) Loss: 0.0021(0.0024) Grad: 816.2206  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 14s (remain 2m 19s) Loss: 0.0001(0.0023) Grad: 56.1927  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 43s (remain 1m 50s) Loss: 0.0017(0.0024) Grad: 601.3317  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 13s (remain 1m 20s) Loss: 0.0003(0.0023) Grad: 168.2759  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 42s (remain 0m 51s) Loss: 0.0000(0.0023) Grad: 13.6550  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 11s (remain 0m 21s) Loss: 0.0006(0.0023) Grad: 327.8987  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 17m 33s (remain 0m 0s) Loss: 0.0030(0.0023) Grad: 912.1324  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 54s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 36s) Loss: 0.0474(0.0075) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 19s) Loss: 0.0063(0.0069) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 3s) Loss: 0.0088(0.0076) \n","EVAL: [400/1192] Elapsed 0m 55s (remain 1m 49s) Loss: 0.0000(0.0071) \n","EVAL: [500/1192] Elapsed 1m 9s (remain 1m 35s) Loss: 0.0666(0.0069) \n","EVAL: [600/1192] Elapsed 1m 23s (remain 1m 22s) Loss: 0.0094(0.0072) \n","EVAL: [700/1192] Elapsed 1m 37s (remain 1m 8s) Loss: 0.0044(0.0079) \n","EVAL: [800/1192] Elapsed 1m 52s (remain 0m 54s) Loss: 0.0190(0.0079) \n","EVAL: [900/1192] Elapsed 2m 6s (remain 0m 40s) Loss: 0.0105(0.0081) \n","EVAL: [1000/1192] Elapsed 2m 20s (remain 0m 26s) Loss: 0.0000(0.0079) \n","EVAL: [1100/1192] Elapsed 2m 33s (remain 0m 12s) Loss: 0.0183(0.0077) \n","EVAL: [1191/1192] Elapsed 2m 46s (remain 0m 0s) Loss: 0.0001(0.0075) \n","Epoch 2 - avg_train_loss: 0.0023  avg_val_loss: 0.0075  time: 1222s\n","Epoch 2 - Score: 0.8913\n","Epoch 2 - Save Best Score: 0.8913 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 40m 17s) Loss: 0.0000(0.0000) Grad: 910.2205  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 33s (remain 19m 8s) Loss: 0.0001(0.0021) Grad: 65.6483  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 3s (remain 17m 43s) Loss: 0.0004(0.0027) Grad: 144.7035  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 32s (remain 16m 47s) Loss: 0.0126(0.0023) Grad: 2526.5522  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 1s (remain 16m 4s) Loss: 0.0001(0.0021) Grad: 69.4599  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 31s (remain 15m 27s) Loss: 0.0020(0.0023) Grad: 491.8062  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 0s (remain 14m 52s) Loss: 0.0007(0.0022) Grad: 353.4323  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 29s (remain 14m 19s) Loss: 0.0004(0.0021) Grad: 153.9581  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 58s (remain 13m 46s) Loss: 0.0042(0.0020) Grad: 739.9516  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 27s (remain 13m 14s) Loss: 0.0000(0.0020) Grad: 21.0703  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 56s (remain 12m 43s) Loss: 0.0000(0.0020) Grad: 24.1175  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 26s (remain 12m 12s) Loss: 0.0077(0.0020) Grad: 2317.7263  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 55s (remain 11m 42s) Loss: 0.0002(0.0020) Grad: 88.2825  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 24s (remain 11m 11s) Loss: 0.0044(0.0021) Grad: 1709.8231  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 53s (remain 10m 41s) Loss: 0.0001(0.0021) Grad: 46.8087  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 22s (remain 10m 11s) Loss: 0.0000(0.0021) Grad: 22.0649  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 52s (remain 9m 42s) Loss: 0.0001(0.0021) Grad: 74.2517  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 21s (remain 9m 12s) Loss: 0.0010(0.0022) Grad: 532.6185  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 50s (remain 8m 42s) Loss: 0.0034(0.0021) Grad: 1145.1818  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 19s (remain 8m 12s) Loss: 0.0114(0.0022) Grad: 2630.1567  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 48s (remain 7m 43s) Loss: 0.0000(0.0022) Grad: 5.4161  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 17s (remain 7m 13s) Loss: 0.0000(0.0022) Grad: 31.5420  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 46s (remain 6m 43s) Loss: 0.0000(0.0022) Grad: 23.2724  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 16s (remain 6m 14s) Loss: 0.0031(0.0022) Grad: 923.3993  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 45s (remain 5m 44s) Loss: 0.0001(0.0022) Grad: 54.7538  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 14s (remain 5m 15s) Loss: 0.0000(0.0022) Grad: 13.9101  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 43s (remain 4m 45s) Loss: 0.0001(0.0022) Grad: 59.8042  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 12s (remain 4m 16s) Loss: 0.0019(0.0022) Grad: 598.8417  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 41s (remain 3m 47s) Loss: 0.0096(0.0022) Grad: 2910.2415  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 10s (remain 3m 17s) Loss: 0.0003(0.0022) Grad: 173.3239  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 39s (remain 2m 48s) Loss: 0.0001(0.0022) Grad: 40.8699  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 8s (remain 2m 18s) Loss: 0.0105(0.0022) Grad: 2227.3105  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 37s (remain 1m 49s) Loss: 0.0054(0.0022) Grad: 957.8069  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 6s (remain 1m 20s) Loss: 0.0001(0.0022) Grad: 72.8568  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 35s (remain 0m 50s) Loss: 0.0000(0.0023) Grad: 16.2999  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 4s (remain 0m 21s) Loss: 0.0003(0.0022) Grad: 210.6932  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 17m 26s (remain 0m 0s) Loss: 0.0001(0.0022) Grad: 79.1940  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 8s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 32s) Loss: 0.0475(0.0076) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 16s) Loss: 0.0066(0.0069) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 2s) Loss: 0.0091(0.0076) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 48s) Loss: 0.0000(0.0072) \n","EVAL: [500/1192] Elapsed 1m 8s (remain 1m 34s) Loss: 0.0690(0.0070) \n","EVAL: [600/1192] Elapsed 1m 22s (remain 1m 20s) Loss: 0.0098(0.0073) \n","EVAL: [700/1192] Elapsed 1m 35s (remain 1m 7s) Loss: 0.0044(0.0079) \n","EVAL: [800/1192] Elapsed 1m 49s (remain 0m 53s) Loss: 0.0190(0.0080) \n","EVAL: [900/1192] Elapsed 2m 2s (remain 0m 39s) Loss: 0.0105(0.0081) \n","EVAL: [1000/1192] Elapsed 2m 16s (remain 0m 26s) Loss: 0.0000(0.0080) \n","EVAL: [1100/1192] Elapsed 2m 30s (remain 0m 12s) Loss: 0.0190(0.0078) \n","EVAL: [1191/1192] Elapsed 2m 42s (remain 0m 0s) Loss: 0.0000(0.0076) \n","Epoch 3 - avg_train_loss: 0.0022  avg_val_loss: 0.0076  time: 1211s\n","Epoch 3 - Score: 0.8915\n","Epoch 3 - Save Best Score: 0.8915 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 39m 30s) Loss: 0.0006(0.0006) Grad: 288.5854  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 33s (remain 19m 25s) Loss: 0.0004(0.0027) Grad: 152.5285  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 3s (remain 17m 40s) Loss: 0.0103(0.0024) Grad: 1988.0599  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 32s (remain 16m 44s) Loss: 0.0000(0.0022) Grad: 28.9545  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 1s (remain 16m 1s) Loss: 0.0000(0.0021) Grad: 19.2142  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 30s (remain 15m 23s) Loss: 0.0000(0.0022) Grad: 31.9332  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 59s (remain 14m 48s) Loss: 0.0066(0.0021) Grad: 1296.9783  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 28s (remain 14m 15s) Loss: 0.0001(0.0021) Grad: 60.4421  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 57s (remain 13m 43s) Loss: 0.0018(0.0023) Grad: 872.5253  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 26s (remain 13m 11s) Loss: 0.0001(0.0022) Grad: 53.3471  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 55s (remain 12m 40s) Loss: 0.0059(0.0023) Grad: 1862.0481  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 24s (remain 12m 10s) Loss: 0.0000(0.0024) Grad: 30.5076  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 54s (remain 11m 39s) Loss: 0.0000(0.0023) Grad: 20.1401  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 23s (remain 11m 9s) Loss: 0.0001(0.0023) Grad: 69.8275  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 52s (remain 10m 40s) Loss: 0.0002(0.0023) Grad: 172.7493  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 21s (remain 10m 10s) Loss: 0.0001(0.0023) Grad: 35.5651  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 51s (remain 9m 41s) Loss: 0.0008(0.0023) Grad: 344.4746  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 20s (remain 9m 11s) Loss: 0.0007(0.0022) Grad: 429.8723  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 49s (remain 8m 41s) Loss: 0.0000(0.0022) Grad: 12.5331  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 18s (remain 8m 11s) Loss: 0.0000(0.0022) Grad: 21.7072  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 47s (remain 7m 42s) Loss: 0.0030(0.0022) Grad: 1153.9836  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 16s (remain 7m 12s) Loss: 0.0016(0.0022) Grad: 475.8077  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 45s (remain 6m 42s) Loss: 0.0030(0.0022) Grad: 971.9088  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 14s (remain 6m 13s) Loss: 0.0000(0.0022) Grad: 14.3375  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 43s (remain 5m 44s) Loss: 0.0023(0.0021) Grad: 1252.0605  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 12s (remain 5m 14s) Loss: 0.0034(0.0021) Grad: 1339.6616  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 41s (remain 4m 45s) Loss: 0.0008(0.0022) Grad: 485.8981  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 10s (remain 4m 15s) Loss: 0.0061(0.0022) Grad: 963.7662  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 40s (remain 3m 46s) Loss: 0.0003(0.0022) Grad: 186.3814  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 9s (remain 3m 17s) Loss: 0.0186(0.0022) Grad: 4478.9766  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 38s (remain 2m 48s) Loss: 0.0001(0.0022) Grad: 72.6709  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 7s (remain 2m 18s) Loss: 0.0130(0.0022) Grad: 4321.7739  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 36s (remain 1m 49s) Loss: 0.0004(0.0022) Grad: 212.8405  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 16m 5s (remain 1m 20s) Loss: 0.0028(0.0022) Grad: 733.4473  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 35s (remain 0m 50s) Loss: 0.0001(0.0022) Grad: 93.7848  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 17m 4s (remain 0m 21s) Loss: 0.0001(0.0022) Grad: 45.5815  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 17m 25s (remain 0m 0s) Loss: 0.0011(0.0022) Grad: 559.4411  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 32s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 31s) Loss: 0.0482(0.0077) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 16s) Loss: 0.0062(0.0070) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 1s) Loss: 0.0096(0.0077) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 47s) Loss: 0.0000(0.0073) \n","EVAL: [500/1192] Elapsed 1m 8s (remain 1m 33s) Loss: 0.0706(0.0071) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 20s) Loss: 0.0096(0.0074) \n","EVAL: [700/1192] Elapsed 1m 35s (remain 1m 6s) Loss: 0.0045(0.0081) \n","EVAL: [800/1192] Elapsed 1m 48s (remain 0m 53s) Loss: 0.0195(0.0081) \n","EVAL: [900/1192] Elapsed 2m 2s (remain 0m 39s) Loss: 0.0112(0.0083) \n","EVAL: [1000/1192] Elapsed 2m 15s (remain 0m 25s) Loss: 0.0000(0.0081) \n","EVAL: [1100/1192] Elapsed 2m 29s (remain 0m 12s) Loss: 0.0201(0.0079) \n","EVAL: [1191/1192] Elapsed 2m 41s (remain 0m 0s) Loss: 0.0000(0.0077) \n","Epoch 4 - avg_train_loss: 0.0022  avg_val_loss: 0.0077  time: 1210s\n","Epoch 4 - Score: 0.8916\n","Epoch 4 - Save Best Score: 0.8916 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 39m 15s) Loss: 0.0021(0.0021) Grad: 662.4108  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 34s (remain 19m 31s) Loss: 0.0051(0.0039) Grad: 1559.9349  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 3s (remain 17m 38s) Loss: 0.0000(0.0026) Grad: 40.8433  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 32s (remain 16m 42s) Loss: 0.0065(0.0026) Grad: 1441.5399  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 2m 1s (remain 15m 58s) Loss: 0.0002(0.0025) Grad: 114.4898  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 30s (remain 15m 21s) Loss: 0.0001(0.0024) Grad: 38.5336  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 59s (remain 14m 46s) Loss: 0.0000(0.0022) Grad: 35.9286  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 28s (remain 14m 13s) Loss: 0.0001(0.0022) Grad: 101.1728  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 57s (remain 13m 41s) Loss: 0.0027(0.0022) Grad: 928.8876  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 26s (remain 13m 10s) Loss: 0.0028(0.0021) Grad: 868.4738  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 55s (remain 12m 39s) Loss: 0.0000(0.0021) Grad: 47.2018  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 24s (remain 12m 9s) Loss: 0.0068(0.0022) Grad: 1913.7098  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 53s (remain 11m 38s) Loss: 0.0014(0.0021) Grad: 602.0536  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 22s (remain 11m 8s) Loss: 0.0001(0.0021) Grad: 68.8167  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 51s (remain 10m 38s) Loss: 0.0001(0.0020) Grad: 76.8191  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 20s (remain 10m 9s) Loss: 0.0000(0.0020) Grad: 32.3637  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 49s (remain 9m 39s) Loss: 0.0004(0.0020) Grad: 330.3319  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 19s (remain 9m 9s) Loss: 0.0001(0.0020) Grad: 112.2582  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 48s (remain 8m 40s) Loss: 0.0001(0.0020) Grad: 95.0532  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 17s (remain 8m 10s) Loss: 0.0043(0.0021) Grad: 1304.3424  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 46s (remain 7m 41s) Loss: 0.0001(0.0020) Grad: 51.6771  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 15s (remain 7m 11s) Loss: 0.0001(0.0020) Grad: 109.2647  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 44s (remain 6m 42s) Loss: 0.0002(0.0021) Grad: 98.1477  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 13s (remain 6m 13s) Loss: 0.0001(0.0020) Grad: 62.7609  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 43s (remain 5m 43s) Loss: 0.0001(0.0021) Grad: 77.5553  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 12s (remain 5m 14s) Loss: 0.0007(0.0021) Grad: 434.9407  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 41s (remain 4m 45s) Loss: 0.0000(0.0021) Grad: 30.6341  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 10s (remain 4m 15s) Loss: 0.0015(0.0021) Grad: 454.4183  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 39s (remain 3m 46s) Loss: 0.0001(0.0021) Grad: 76.0758  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 8s (remain 3m 17s) Loss: 0.0000(0.0021) Grad: 20.5849  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 37s (remain 2m 47s) Loss: 0.0011(0.0021) Grad: 514.2100  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 6s (remain 2m 18s) Loss: 0.0000(0.0021) Grad: 27.3591  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 35s (remain 1m 49s) Loss: 0.0002(0.0021) Grad: 105.7780  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 5s (remain 1m 20s) Loss: 0.0000(0.0021) Grad: 22.4731  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 34s (remain 0m 50s) Loss: 0.0001(0.0021) Grad: 43.5110  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 17m 3s (remain 0m 21s) Loss: 0.0000(0.0022) Grad: 21.6898  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 17m 24s (remain 0m 0s) Loss: 0.0001(0.0022) Grad: 42.1255  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 29s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 32s) Loss: 0.0481(0.0077) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 16s) Loss: 0.0067(0.0070) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 2s) Loss: 0.0095(0.0077) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 48s) Loss: 0.0000(0.0073) \n","EVAL: [500/1192] Elapsed 1m 8s (remain 1m 34s) Loss: 0.0704(0.0070) \n","EVAL: [600/1192] Elapsed 1m 22s (remain 1m 20s) Loss: 0.0100(0.0074) \n","EVAL: [700/1192] Elapsed 1m 35s (remain 1m 7s) Loss: 0.0044(0.0081) \n","EVAL: [800/1192] Elapsed 1m 49s (remain 0m 53s) Loss: 0.0197(0.0081) \n","EVAL: [900/1192] Elapsed 2m 2s (remain 0m 39s) Loss: 0.0109(0.0082) \n","EVAL: [1000/1192] Elapsed 2m 16s (remain 0m 26s) Loss: 0.0000(0.0081) \n","EVAL: [1100/1192] Elapsed 2m 30s (remain 0m 12s) Loss: 0.0196(0.0079) \n","EVAL: [1191/1192] Elapsed 2m 42s (remain 0m 0s) Loss: 0.0000(0.0077) \n","Epoch 5 - avg_train_loss: 0.0022  avg_val_loss: 0.0077  time: 1209s\n","Epoch 5 - Score: 0.8915\n","Best thres: 0.5, Score: 0.8862\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-30-0f6b8dbff6ab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_token_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best thres: 0.5, Score: {score:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mbest_thres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_thres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_token_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best thres: {best_thres}, Score: {score:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1c709edcc751>\u001b[0m in \u001b[0;36mget_best_thres\u001b[0;34m(oof_df)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mbest_thres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Nelder-Mead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_thres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1c709edcc751>\u001b[0m in \u001b[0;36mf1_opt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_best_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf1_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mbest_thres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Nelder-Mead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1c709edcc751>\u001b[0m in \u001b[0;36mscoring\u001b[0;34m(df, th, use_token_prob)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_location_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-13e59b373458>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspan_micro_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-13e59b373458>\u001b[0m in \u001b[0;36mspan_micro_f1\u001b[0;34m(preds, truths)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mbin_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mbin_truths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmicro_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_truths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-13e59b373458>\u001b[0m in \u001b[0;36mmicro_f1\u001b[0;34m(preds, truths)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtruths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m         \u001b[0msamplewise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamplewise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m     )\n\u001b[1;32m   1555\u001b[0m     \u001b[0mtp_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m_unique_multiclass\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_unique_multiclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maux_firstnan\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","score = scoring(oof_df, th=0.5, use_token_prob=False)\n","print(f\"Best thres: 0.5, Score: {score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Twai9e8UdUP1","executionInfo":{"status":"ok","timestamp":1647849081315,"user_tz":-540,"elapsed":11522,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"9ed6ab70-e118-4053-a0ba-6c01ba129819"},"id":"Twai9e8UdUP1","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Best thres: 0.5, Score: 0.8862\n"]}]},{"cell_type":"code","source":["best_th = 0.5\n","best_score = 0.\n","for th in np.arange(0.45, 0.55, 0.01):\n","    th = np.round(th, 2)\n","    score = scoring(oof_df, th=th, use_token_prob=False)\n","    if best_score < score:\n","        best_th = th\n","        best_score = score\n","print(f\"best_th: {best_th}  score: {best_score:.5f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcvIWWv5dYiN","executionInfo":{"status":"ok","timestamp":1647849255514,"user_tz":-540,"elapsed":119319,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"9b8f30bd-9a14-46c6-98bd-0864f785d8e4"},"id":"AcvIWWv5dYiN","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["best_th: 0.46  score: 0.88621\n"]}]},{"cell_type":"code","source":["def postprocess(texts, preds):\n","    fix_tokenize_dict = {\n","        'heart': ['h', 'eart'],\n","        'hair': ['h', 'air'],\n","        'adderal': ['a', 'dderal'],\n","        'mother': ['m', 'other'],\n","        'intermittent': ['i', 'ntermittent'],\n","        'temperature': ['t', 'emperature'],\n","        'episodes': ['e', 'pisodes'],\n","        'no': ['n', 'o'],\n","        'has': ['h', 'as'],\n","        'LMP': ['L', 'MP'],\n","        '10': ['1', '0'],\n","        'blood': ['b', 'lood'],\n","        'recurrent': ['r', 'ecurrent'],\n","        'denies': ['d', 'enies'],\n","        'sudden': ['s', 'udden'],\n","        'Sexually': ['S', 'exually'],\n","        'up': ['u', 'p'],\n","        'wakes': ['w', 'akes'],\n","        'sweats': ['s', 'weats'],\n","        'hot': ['h', 'ot'],\n","        'drenched': ['d', 'renched'],\n","        'gnawing': ['g', 'nawing'],\n","        'Uses': ['U', 'ses'],\n","        'Begin': ['B', 'egin'],\n","        'Nausea': ['N', 'ausea'],\n","        'Burning': ['B', 'urning'],\n","        'Started': ['S', 'tarted'],\n","        'neurvousness': ['n', 'eurvousness'],\n","        'constipation': ['c', 'onstipation'],\n","        'nervousness': ['n', 'ervousness'],\n","        'cold': ['c', 'old'],\n","        'loss': ['l', 'oss'],\n","        'CBC': ['C', 'BC'],\n","        'Hx': ['H', 'x'],\n","        'tingling': ['t', 'ingling'],\n","        'feels': ['f', 'eels'],\n","        'Lost': ['L', 'ost'],\n","        'she': ['s', 'he'],\n","        'racing': ['r', 'acing'],\n","        'throat': ['t', 'hroat'],\n","        'PATIENT': ['P', 'ATIENT'],\n","        'recreational': ['r', 'ecreational'],\n","        'clammy': ['c', 'lammy'],\n","        'numbness': ['n', 'umbness'],\n","        'like': ['l', 'ike'],\n","        'reports': ['r', 'eports'],\n","        'exercise': ['e', 'xercise'],\n","        'started': ['s', 'tarted'],\n","        'brough': ['b', 'rough'],\n","        'Associated': ['A', 'ssociated'],\n","        'exacerbated': ['e', 'xacerbated'],\n","        'sharp': ['s', 'harp'],\n","        'cannot': ['c', 'annot'],\n","        'heavy': ['h', 'eavy'],\n","        'fatigue': ['f', 'atigue'],\n","        'trouble': ['t', 'rouble'],\n","        'hearing': ['h', 'earing'],\n","        'reduced': ['r', 'educed'],\n","        'lack': ['l', 'ack'],\n","        'vomiting': ['v', 'omiting'],\n","        'generalized': ['g', 'eneralized'],\n","        'body': ['b', 'ody'],\n","        'all': ['a', 'll'],\n","        'scratchy': ['s', 'cratchy'],\n","        'mom': ['m', 'om'],\n","        'discomfort': ['d', 'iscomfort'],\n","        'CAD': ['C', 'AD'],\n","        'Thyroid': ['T', 'hyroid'],\n","        'BLADDER': ['B', 'LADDER'],\n","        'diarrhea': ['d', 'iarrhea'],\n","        'Started': ['S', 'tarted'],\n","        'Vaginal': ['V', 'aginal'],\n","        'sleeping': ['s', 'leeping'],\n","        'UNCLE': ['U', 'NCLE'],\n","        'USING': ['U', 'SING'],\n","        'BURNING': ['B', 'URNING'],\n","        'GETTING': ['G', 'ETTING'],\n","        'ETOH': ['E', 'TOH'],\n","        'ON': ['O', 'N'],\n","        'INITIALLY': ['I', 'NITIALLY'],\n","        'epigastric': ['e', 'pigastric'],\n","        'occurs': ['o', 'ccurs'],\n","        'began': ['b', 'egan'],\n","        'alleviated': ['a', 'lleviated'],\n","        'overwhelmed': ['o', 'verwhelmed'],\n","        'clamminess': ['c', 'lamminess'],\n","        'strongly': ['s', 'trongly'],\n","        'lump': ['l', 'ump'],\n","        'drugs': ['d', 'rugs'],\n","        'chest': ['c', 'hest'],\n","        'stuffy': ['s', 'tuffy'],\n","        'changes': ['c', 'hanges'],\n","        'trouble': ['t', 'rouble'],\n","        'takes': ['t', 'akes'],\n","        'tossing': ['t', 'ossing'],\n","        'Fam': ['F', 'am'],\n","        'sweating': ['s', 'weating'],\n","        'dyspareunia': ['d', 'yspareunia'],\n","        'irregular': ['i', 'rregular'],\n","        'time': ['t', 'ime'],\n","        'unpredictable': ['u', 'npredictable'],\n","        'darkened': ['d', 'arkened'],\n","        'anxiety': ['a', 'nxiety'],\n","        'nervous': ['n', 'ervous'],\n","        'TAKING': ['T', 'AKING'],\n","        'losing': ['l', 'osing'],\n","        'Difficulyt': ['D', 'ifficulyt'],\n","        'Appetite': ['A', 'ppetite'],\n","        'increased': ['i', 'ncreased'],\n","        'fingers': ['f', 'ingers'],\n","        'illicit': ['i', 'llicit'],\n","        'claminess': ['c', 'laminess'],\n","        'clamy': ['c', 'lamy'],\n","        'Recently': ['R', 'ecently'],\n","        'feeling': ['f', 'eeling'],\n","        'aggrav': ['a', 'ggrav'],\n","        'changing': ['c', 'hanging'],\n","        'unable': ['u', 'nable'],\n","        'SEEING': ['S', 'EEING'],\n","        'staying': ['s', 'taying'],\n","        'lightheadedness': ['l', 'ightheadedness'],\n","        'lighheadeness': ['l', 'ighheadeness'],\n","        'nail': ['n', 'ail'],\n","        'pounding': ['p', 'ounding'],\n","        'My': ['M', 'y'],\n","        'Father': ['F', 'ather'],\n","        'urinary': ['u', 'rinary'],\n","        'pain': ['p', 'ain'],\n","        'not': ['n', 'ot'],\n","        'lower': ['l', 'ower'],\n","        'menses': ['m', 'enses'],\n","        'at': ['a', 't'],\n","        'takes': ['t', 'akes'],\n","        'initally': ['i', 'nitally'],\n","        'melena': ['m', 'elena'],\n","        'BOWEL': ['B', 'OWEL'],\n","        'WEIGHT': ['W', 'EIGHT'],\n","        'difficulty': ['d', 'ifficulty'],\n","        'condo': ['c', 'ondo'],\n","        'experiences': ['e', 'xperiences'],\n","        'stuffy': ['s', 'tuffy'],\n","        'rhinorrhea': ['r', 'hinorrhea'],\n","        'felt': ['f', 'elt'],\n","        'feverish': ['f', 'everish'],\n","        'CYCLE': ['C', 'YCLE'],\n","        'tampon': ['t', 'ampon'],\n","        'Last': ['L', 'ast'],\n","        'Son': ['S', 'on'],\n","        'saw': ['s', 'aw'],\n","        'tightness': ['t', 'ightness'],\n","        'rash': ['r', 'ash'],\n","        'ibuprofen': ['i', 'buprofen'],\n","        'SCRATHY': ['S', 'CRATHY'],\n","        'PHOTOPHOBIA': ['P', 'HOTOPHOBIA'],\n","    }\n","    preds_pp = preds.copy()\n","    tk0 = range(len(preds_pp))\n","    for raw_idx in tk0:\n","        pred = preds[raw_idx]\n","        text = texts[raw_idx]\n","        if len(pred) != 0:\n","            # pp1: indexが1から始まる予測値は0から始まるように修正 ## 0.88579 -> 0.88702\n","            if pred[0][0] == 1:\n","                preds_pp[raw_idx][0][0] = 0\n","            for p_index, pp in enumerate(pred):\n","                start, end = pred[p_index]\n","                # pp2: startとendが同じ予測値はstartを前に１ずらす ## 0.88702 -> 0.88714\n","                if start == end:\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp3: 始点が改行の場合始点を1つ後ろにずらす ## 0.88714 -> 0.88746\n","                if text[start] == '\\n':\n","                    preds_pp[raw_idx][p_index][0] = start + 1\n","                    start = start + 1\n","                # pp4: 1-2などは-2で予測されることがあるので修正 ## 0.88746 -> 0.88747\n","                if text[start-1].isdigit() and text[start] == '-' and text[start+1].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-1].isdigit() and text[start] == '/' and text[start+1].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp5: 67などは7で予測されることがあるので修正 ## 0.88747 -> 0.88748\n","                if text[start-1].isdigit() and text[start].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp6: 文頭が大文字で始まるものは大文字部分が除かれて予測されることがあるので修正 ## 0.88748 -> 0.88761\n","                if text[start-2] == '.' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == ',' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == ':' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == '-' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp7: heart -> h + eart となっているようなものを修正する ## 0.88761 -> 0.88806\n","                for key, fix_tokenize in fix_tokenize_dict.items():\n","                    _s, s = fix_tokenize[0], fix_tokenize[1]\n","                    if text[start-1].lower() == _s.lower() and text[start:start+len(s)].lower() == s.lower():\n","                        preds_pp[raw_idx][p_index][0] = start - 1\n","                        start = start - 1\n","    return preds_pp\n"],"metadata":{"id":"jippbx3tdDXK","executionInfo":{"status":"ok","timestamp":1647849256282,"user_tz":-540,"elapsed":772,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"jippbx3tdDXK","execution_count":34,"outputs":[]},{"cell_type":"code","source":["#score = scoring(oof_df, th=0.5, use_token_prob=False)\n","labels = create_labels_for_scoring(oof_df)\n","char_probs = oof_df[[str(i) for i in range(CFG.max_char_len)]].values\n","char_probs = [char_probs[i] for i in range(len(char_probs))]\n","\n","predicted_location_str = get_predicted_location_str(char_probs, th=0.5)\n","preds = get_predictions(predicted_location_str)\n","preds = postprocess(oof_df['pn_history'].values, preds)\n","score = get_score(labels, preds)\n","print(f\"Best thres: 0.5, Score: {score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4CZPMagdthN","executionInfo":{"status":"ok","timestamp":1647849339536,"user_tz":-540,"elapsed":12719,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"d6e0c8c9-0a1b-4daf-ab56-2a0cb56da769"},"id":"Q4CZPMagdthN","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Best thres: 0.5, Score: 0.8867\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"tfiRsn5FebtI"},"id":"tfiRsn5FebtI","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"N5kZWfSSfJMf"},"id":"N5kZWfSSfJMf","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp058.ipynb","provenance":[{"file_id":"1wqr1Y1MTpmofNqOtVD8cCBYlPZoPt3XQ","timestamp":1647823100264}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9a4191658139420db4ea5e88370dadf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58a7f6e7aaa94caebd8505341eb8d895","IPY_MODEL_a5da600d56f944b6a83c44129a62acc7","IPY_MODEL_31c129e810da4fbaae1e6e1c909f0971"],"layout":"IPY_MODEL_bc736f58cca44cb7a3013e1a62fe8a67"}},"58a7f6e7aaa94caebd8505341eb8d895":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_829e21f7b9da4877a11f5cabe4be9348","placeholder":"​","style":"IPY_MODEL_b63c93e3c0be461fbf0775d7256fd0ce","value":"Downloading: 100%"}},"a5da600d56f944b6a83c44129a62acc7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93888a848cc9471f995230ca13642f5e","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52ecc7a1b69d43b2aafb52279b7283ba","value":52}},"31c129e810da4fbaae1e6e1c909f0971":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d4b60e2c0cf4cc6a9e8c43d065e8e52","placeholder":"​","style":"IPY_MODEL_a08a254a8860468e930e7f4ac91d0077","value":" 52.0/52.0 [00:00&lt;00:00, 1.59kB/s]"}},"bc736f58cca44cb7a3013e1a62fe8a67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"829e21f7b9da4877a11f5cabe4be9348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b63c93e3c0be461fbf0775d7256fd0ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93888a848cc9471f995230ca13642f5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52ecc7a1b69d43b2aafb52279b7283ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d4b60e2c0cf4cc6a9e8c43d065e8e52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a08a254a8860468e930e7f4ac91d0077":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81d8dad8f88349019cf233feff5a907e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b89eb0f4ec0f4b2fa740a716c7761a21","IPY_MODEL_760ae51138e64152bb1161d32fc00ef7","IPY_MODEL_85d1a91aa95649639a11e719975d8145"],"layout":"IPY_MODEL_b771bcfc5ded41bcb8256332fa7f0224"}},"b89eb0f4ec0f4b2fa740a716c7761a21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e453e7f1828430682d63f53a6706311","placeholder":"​","style":"IPY_MODEL_2c56af0c7aef4a9c997b6189aa554187","value":"Downloading: 100%"}},"760ae51138e64152bb1161d32fc00ef7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c44ab7c9029d4904b9eb7bdf102fb3ab","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26ccdc75ccc24bc3a669e1b96c36c64a","value":475}},"85d1a91aa95649639a11e719975d8145":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_065484021ad249b09d78f9aed0f9a6f4","placeholder":"​","style":"IPY_MODEL_06e7aeb86a2e44b69fa0c6f682e1612c","value":" 475/475 [00:00&lt;00:00, 15.9kB/s]"}},"b771bcfc5ded41bcb8256332fa7f0224":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e453e7f1828430682d63f53a6706311":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c56af0c7aef4a9c997b6189aa554187":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c44ab7c9029d4904b9eb7bdf102fb3ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26ccdc75ccc24bc3a669e1b96c36c64a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"065484021ad249b09d78f9aed0f9a6f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06e7aeb86a2e44b69fa0c6f682e1612c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4b9230f820845b0b58f5c32c0aec05c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_000f14dfbb11496b8179f82ae1bec456","IPY_MODEL_b4f164862be04ee6b9eed6e5f55811b1","IPY_MODEL_2cd328fa2d4149e188321576dd98ee13"],"layout":"IPY_MODEL_dcd9e85285054805b169b6b532997338"}},"000f14dfbb11496b8179f82ae1bec456":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be350fa9ddbb4bd090c262f9fc7a4448","placeholder":"​","style":"IPY_MODEL_1809a935fcd74672b37672d67e192c87","value":"Downloading: 100%"}},"b4f164862be04ee6b9eed6e5f55811b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a5267bf243b45d3bedc41ebbc5ca2c5","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fca0da53eb0b43bd8da4dd727b25529b","value":898825}},"2cd328fa2d4149e188321576dd98ee13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9564ce4236541fc9aa309a6399751b2","placeholder":"​","style":"IPY_MODEL_5d399112636d42ce8e31c5229a9d621e","value":" 878k/878k [00:00&lt;00:00, 2.11MB/s]"}},"dcd9e85285054805b169b6b532997338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be350fa9ddbb4bd090c262f9fc7a4448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1809a935fcd74672b37672d67e192c87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a5267bf243b45d3bedc41ebbc5ca2c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fca0da53eb0b43bd8da4dd727b25529b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9564ce4236541fc9aa309a6399751b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d399112636d42ce8e31c5229a9d621e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eff07706b0d74a4691488d2b04fabf65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ec0ae63aaef4267ab3b0d110d68933a","IPY_MODEL_f59c53db88784a61ab158f0679dc0e79","IPY_MODEL_abc369aee9e24f8cb02645d3f568c1e1"],"layout":"IPY_MODEL_dd92d56920954f6690adc08b36cd0da6"}},"9ec0ae63aaef4267ab3b0d110d68933a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ce68abce7444daca360906e2835bddb","placeholder":"​","style":"IPY_MODEL_1794fa18091e4eb092f47e092a6ad49d","value":"Downloading: 100%"}},"f59c53db88784a61ab158f0679dc0e79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45aed73a581749c8bb01f55e1480ef09","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cee51bc932c4e0bb63632d12701749b","value":456318}},"abc369aee9e24f8cb02645d3f568c1e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffad7695ae244627879251c5e2e1c8c0","placeholder":"​","style":"IPY_MODEL_fb98242c9fab47f5ba091b91d1411b50","value":" 446k/446k [00:00&lt;00:00, 643kB/s]"}},"dd92d56920954f6690adc08b36cd0da6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ce68abce7444daca360906e2835bddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1794fa18091e4eb092f47e092a6ad49d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45aed73a581749c8bb01f55e1480ef09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cee51bc932c4e0bb63632d12701749b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffad7695ae244627879251c5e2e1c8c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb98242c9fab47f5ba091b91d1411b50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9e33669c46c45c88215bb3a458736ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e70f578699a24c03b8d1435c80e7dcdb","IPY_MODEL_ab16f3ce71ac4ec88ff9254bac15c947","IPY_MODEL_05cd260a63c94a75af9b2f67e9252161"],"layout":"IPY_MODEL_ac7de57038f64a37a8983497086e91ca"}},"e70f578699a24c03b8d1435c80e7dcdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7119ddc1a484040a8731b9f85ef2d2c","placeholder":"​","style":"IPY_MODEL_ffc21c0c662f493786b9419beb62a4aa","value":"100%"}},"ab16f3ce71ac4ec88ff9254bac15c947":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f21b15ed2fa49fb9f1f7bb801e1ec41","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ae53060b978455a89d665a344c10478","value":42146}},"05cd260a63c94a75af9b2f67e9252161":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d09b7bc83ba4d409a2052bd47651d4d","placeholder":"​","style":"IPY_MODEL_02f1fb72222c4e9a9d4ae5297ba44c82","value":" 42146/42146 [00:36&lt;00:00, 1770.76it/s]"}},"ac7de57038f64a37a8983497086e91ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7119ddc1a484040a8731b9f85ef2d2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffc21c0c662f493786b9419beb62a4aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f21b15ed2fa49fb9f1f7bb801e1ec41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ae53060b978455a89d665a344c10478":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d09b7bc83ba4d409a2052bd47651d4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02f1fb72222c4e9a9d4ae5297ba44c82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e0079a1e2224b9499d45b32db00161f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d7951e25d4145c8b34f80e1ff8f26e8","IPY_MODEL_cb0d46584b4f429ab6a85f9d9b9f6034","IPY_MODEL_edd4651b4bd64d20b6d5d51e526615f6"],"layout":"IPY_MODEL_a06696ec1f2745b88280e0e63f422e00"}},"4d7951e25d4145c8b34f80e1ff8f26e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb5f608255734d50b5e5b98d2c4e4fbd","placeholder":"​","style":"IPY_MODEL_2f43578f5f0947398307e4f435854634","value":"100%"}},"cb0d46584b4f429ab6a85f9d9b9f6034":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7be4f5993b34e90801912620f95d627","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56d34e7e2c89498aa35aa250ca78f35d","value":143}},"edd4651b4bd64d20b6d5d51e526615f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47f88e0dc18f47f88db8e287d04aaf05","placeholder":"​","style":"IPY_MODEL_33ade92b57824ed3bc260ffe373d9ae5","value":" 143/143 [00:00&lt;00:00, 2219.62it/s]"}},"a06696ec1f2745b88280e0e63f422e00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb5f608255734d50b5e5b98d2c4e4fbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f43578f5f0947398307e4f435854634":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7be4f5993b34e90801912620f95d627":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56d34e7e2c89498aa35aa250ca78f35d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47f88e0dc18f47f88db8e287d04aaf05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33ade92b57824ed3bc260ffe373d9ae5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d2395161fe94cf38a4833667150d753":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb68423a99154d8d8ff214d32a163815","IPY_MODEL_656dd135b9b441868177f297d26128ca","IPY_MODEL_89c00e8d030b4483bdc379d21f3ccdb1"],"layout":"IPY_MODEL_a7146ed849fb4f48b5715561debaa03c"}},"bb68423a99154d8d8ff214d32a163815":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d81e850c34d74c05ac3e21105e00a32f","placeholder":"​","style":"IPY_MODEL_efdf8bd06b96478ea84bcd4660ce0db7","value":"100%"}},"656dd135b9b441868177f297d26128ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70b0c5db7eaf48e2b51db969bf6f1a80","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b4092c5d6064d7ebc0da601b5645dc9","value":42146}},"89c00e8d030b4483bdc379d21f3ccdb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d098345be3c6454e9fd804958903fbf8","placeholder":"​","style":"IPY_MODEL_919ec1113f6a4c7e86d4f0abf074d971","value":" 42146/42146 [00:00&lt;00:00, 474869.81it/s]"}},"a7146ed849fb4f48b5715561debaa03c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d81e850c34d74c05ac3e21105e00a32f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efdf8bd06b96478ea84bcd4660ce0db7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70b0c5db7eaf48e2b51db969bf6f1a80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b4092c5d6064d7ebc0da601b5645dc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d098345be3c6454e9fd804958903fbf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919ec1113f6a4c7e86d4f0abf074d971":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}