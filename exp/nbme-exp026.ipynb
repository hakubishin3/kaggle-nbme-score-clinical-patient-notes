{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-digit",
   "metadata": {
    "id": "blind-kingdom"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-central",
   "metadata": {
    "id": "antique-glenn"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-hunter",
   "metadata": {
    "id": "bored-ministry"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acoustic-death",
   "metadata": {
    "id": "deadly-confidence"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp026\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-halloween",
   "metadata": {
    "id": "aware-worcester"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-v3-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrow-peripheral",
   "metadata": {
    "id": "personalized-death"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-topic",
   "metadata": {
    "id": "cardiovascular-neutral"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serial-still",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "checked-boards",
    "outputId": "87364705-3e3f-4866-a538-14dfdc9c7e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "    !pip install sentencepiece\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "challenging-generic",
   "metadata": {
    "id": "iGai035Rvu1Z"
   },
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "if CFG.env == \"colab\":\n",
    "    input_dir = Path(\"./drive/MyDrive/00.kaggle/input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n",
    "else:\n",
    "    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)\n",
    "    \n",
    "    \n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broad-mainland",
   "metadata": {
    "id": "vital-mexico"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-staff",
   "metadata": {
    "id": "economic-ladder"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "armed-prevention",
   "metadata": {
    "id": "desperate-keyboard"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "built-sherman",
   "metadata": {
    "id": "flexible-wednesday"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atomic-concern",
   "metadata": {
    "id": "logical-chemistry"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indoor-booking",
   "metadata": {
    "id": "gorgeous-record"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-forge",
   "metadata": {
    "id": "frozen-africa"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "other-awareness",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shaped-metallic",
    "outputId": "11a7cabc-1b4b-4b13-c8cc-95ce538868f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quality-synthetic",
   "metadata": {
    "id": "visible-australia"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-special",
   "metadata": {
    "id": "hydraulic-gibson"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "olympic-possibility",
   "metadata": {
    "id": "interpreted-northeast"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "foster-syndication",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "martial-blind",
    "outputId": "42a83988-2022-4dc2-a38e-7f156b490c5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "military-damage",
   "metadata": {
    "id": "electoral-favor"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "artistic-bones",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "reported-parade",
    "outputId": "60a64543-0419-4942-9673-73f0921c1d34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-venture",
   "metadata": {
    "id": "enabling-relevance"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "complimentary-coordinator",
   "metadata": {
    "id": "mature-coalition"
   },
   "outputs": [],
   "source": [
    "def get_groupkfold(df, group_name):\n",
    "    groups = df[group_name].unique()\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=CFG.n_fold,\n",
    "        shuffle=True,\n",
    "        random_state=CFG.seed,\n",
    "    )\n",
    "    folds_ids = []\n",
    "    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n",
    "        val_group = groups[val_group_idx]\n",
    "        is_val = df[group_name].isin(val_group)\n",
    "        val_idx = df[is_val].index\n",
    "        df.loc[val_idx, \"fold\"] = int(i_fold)\n",
    "\n",
    "    df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "double-theme",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "every-minutes",
    "outputId": "b1991a8c-a884-4b5a-8ad9-58990576bef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    2902\n",
       "1    2894\n",
       "2    2813\n",
       "3    2791\n",
       "4    2900\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_groupkfold(train, \"pn_num\")\n",
    "display(train.groupby(\"fold\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-winning",
   "metadata": {
    "id": "subjective-entrance"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "related-plastic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dramatic-afghanistan",
    "outputId": "f56c7a0a-6282-4575-c71e-5e908bc30b95"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-expense",
   "metadata": {
    "id": "divided-arrow"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dominican-authentication",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "661a9a315f8646a49162891ae47c69e7",
      "ef004a834af944abbd512fa3218642a1",
      "74fa3a6b51ad46958e58de5580cf5333",
      "810a830f3b6743b9b074867dd8e4e179",
      "7316ae87cfb849898eb022e100730ba2",
      "c7cb034c107247cba318475c9952b4ac",
      "7d891639f26644e8a05d7fe38d178245",
      "c8a7a19edb074139baefe21f1901d4f4",
      "7ed0ca5ee62d45d89050f3caf3d528c9",
      "0b48bd338cc94fe396aa1b736b9a2507",
      "2ddd9fc857b549a4ba446dd64a1dd1d4"
     ]
    },
    "id": "immune-campbell",
    "outputId": "6b41528b-6e83-4946-cbd5-62621fd1ad43"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1c11e3e233490f8a8e9a9c1f92d085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 323\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aerial-chocolate",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f319feca977544738ff2400ab23a9276",
      "26b1a86ee1ff4ce2862c13d47be2b2d6",
      "9815ec90f12a4696a85db6dc629ec62a",
      "e032f2bf0bb241c2911087a6efe1ce0b",
      "19783f5141cb47f8aaa057fb01dda913",
      "953c495e9f64430cbdd9184bb0bd35cb",
      "7e210db5a5fe41f696351dc87d525ee4",
      "1ad701d95f084c98bd1bf0e9d7d498a9",
      "6d74dcf5002c4752af12a65c3aca2113",
      "1faca6dc4b0e43988d2f81cd209297be",
      "2c55e9e0223548fbbbe29b3e11e59d50"
     ]
    },
    "id": "northern-branch",
    "outputId": "82a35c47-ca3a-441a-ff12-3dc32603677d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d647302dc44d95be132ea78d646ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 28\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "renewable-court",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oriental-jacksonville",
    "outputId": "0ccfd10a-251f-49de-ce35-c4db182768ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 354\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "flexible-national",
   "metadata": {
    "id": "flexible-trainer"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cross-triangle",
   "metadata": {
    "id": "stock-robertson"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-valve",
   "metadata": {
    "id": "chemical-lucas"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spectacular-discovery",
   "metadata": {
    "id": "animated-array"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\"\n",
    "            state_dict = torch.load(path)\n",
    "            itpt.load_state_dict(state_dict)\n",
    "            self.backbone = itpt.deberta\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-binary",
   "metadata": {
    "id": "thorough-bristol"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "spread-auction",
   "metadata": {
    "id": "n8Z5UnO9cCxW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65938\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "incident-costa",
   "metadata": {
    "id": "talented-quantity"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "absent-surge",
   "metadata": {
    "id": "figured-cooperative"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "european-likelihood",
   "metadata": {
    "id": "played-pointer"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "helpful-haiti",
   "metadata": {
    "id": "brazilian-nigeria"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    #model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False)\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    #criterion = FocalLoss(reduce=False)\n",
    "    best_score = -1 * np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-elevation",
   "metadata": {
    "id": "bearing-switch"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "simplified-techno",
   "metadata": {
    "id": "desperate-crime"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    score = scoring(oof_df, th=0.5)\n",
    "    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n",
    "    best_thres = get_best_thres(oof_df)\n",
    "    score = scoring(oof_df, th=best_thres)\n",
    "    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=False)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            test_token_probs = inference_fn(test_dataloader, model, device)\n",
    "            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n",
    "            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_token_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "composed-preservation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f39640d290374992aa246753125a91de",
      "410c3733ee43430eb55278748d07bc45",
      "5292a911912d43c2b80919e486b99de9",
      "ce26114873ed4c96b5ea391a41b18f68",
      "bec237aed5184115b697ea257f7b0c9b",
      "3ca14e3fd6b84312b0af50a89d5ac7c1",
      "8234c7d9369644dea7e5c7e8fe436771",
      "5a3f361a320f480aa8a4115366073d32",
      "0f856d468c8a4c4c9c83b5b263745508",
      "490bfe688fe1419996b69f7de1cfee23",
      "789324d1692d4f478d5b95491b03fc22",
      "1193874a74974cc59982c8d5e3ced585",
      "84ea1506dcad4e01ad1cc35b76c0339a",
      "8e243ea82e59492fb5b845e51a56347a",
      "55ac42bee2ce4f00841b8bd49a7c552d",
      "2281dd4891c640a0b31c23976223f2ba",
      "6919ba0239084b04988e1de02316c76e",
      "548835fe547d4114bfd39e5fac680635",
      "5068fb514bf143ba812fe202c3e7a83d",
      "1e0d277fe44242e19e3bec17a1cb7280",
      "ab8e5c4cef00426fa0cf2fc25c51381a",
      "2b311e42f1294339a07248b31db0c26c",
      "fc3c6209df394eefa2df9ce8dbb56830",
      "3fb5b968d9ab4e88964b6b126c6023d9",
      "d240d13622c14726a5639d44ef2421ec",
      "9e66574c8c0343ffb0477891bfe5e892",
      "219090e2dd934c1296f12660ea69b161",
      "e7be4ec44f2a4183b295f486e250b414",
      "44650208feba4c118904c7efc9887532",
      "d1cd0285cfe34f188e9c779617d48448",
      "331b7288a5024ce3a5036af53eb75cec",
      "00419a15e9834e98b8a3459b62d01f8b",
      "05fdce5a55c1483a937d07a50bd9465e",
      "5536b7aaba7c41f28197e318b362ec75",
      "5ecd28892bb84432935145e27ac71de7",
      "3b50983bfae8445fa305d1edadd651af",
      "cdbf6aefee644006826f76e2f6722b07",
      "7c62f6a2b08c41a8bc3ecf2efa58c325",
      "8478e8bf8b6146b48e717b84c021e7ab",
      "b09413b459c8406882a16db62e8df9c0",
      "72a8b4ea52534d4e9feab6c6fdd72a77",
      "65d16c05424c4df0b79b5786be8bd5d1",
      "63aa4d26409d437fa76e5a156bb04791",
      "e48e5c946462499ab018748ccf80c5b5",
      "160e78a145894001b2a1295627d80df9",
      "008f77fefdba425ab2c755f515693e6f",
      "605151b49d7641a28ebd0ca083770c69",
      "8f8c8632070c4fa0a3182521f41e9c40",
      "dfb4641da88e47d3bafabbaa56bc6916",
      "537dee640701470c8fc3cc29e7940bee",
      "6dc964a8934744608f92a6af0f0f923f",
      "925a3ae98bd6488eb7cffdec89d768da",
      "d76610cad4f645f187b26f1b82733569",
      "b28fa99d1b1b4e4da668bcc50373e4cc",
      "b8554928c5f141de8dfb94c04c2dda03"
     ]
    },
    "id": "graduate-vision",
    "outputId": "2a3a96e3-9421-4bcd-d191-898f1c27a819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2849] Elapsed 0m 1s (remain 57m 45s) Loss: 1.0276(1.0276) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2849] Elapsed 0m 38s (remain 17m 28s) Loss: 0.3052(0.6211) Grad: 14954.8613  LR: 0.000001  \n",
      "Epoch: [1][200/2849] Elapsed 1m 16s (remain 16m 44s) Loss: 0.1425(0.4676) Grad: 9657.7236  LR: 0.000003  \n",
      "Epoch: [1][300/2849] Elapsed 1m 54s (remain 16m 9s) Loss: 0.0206(0.3362) Grad: 381.4003  LR: 0.000004  \n",
      "Epoch: [1][400/2849] Elapsed 2m 32s (remain 15m 31s) Loss: 0.0291(0.2623) Grad: 770.5939  LR: 0.000006  \n",
      "Epoch: [1][500/2849] Elapsed 3m 9s (remain 14m 48s) Loss: 0.0429(0.2184) Grad: 592.6948  LR: 0.000007  \n",
      "Epoch: [1][600/2849] Elapsed 3m 46s (remain 14m 7s) Loss: 0.0432(0.1891) Grad: 519.5160  LR: 0.000008  \n",
      "Epoch: [1][700/2849] Elapsed 4m 26s (remain 13m 36s) Loss: 0.0690(0.1677) Grad: 1934.3541  LR: 0.000010  \n",
      "Epoch: [1][800/2849] Elapsed 5m 6s (remain 13m 2s) Loss: 0.0183(0.1499) Grad: 1372.2388  LR: 0.000011  \n",
      "Epoch: [1][900/2849] Elapsed 5m 43s (remain 12m 23s) Loss: 0.0128(0.1353) Grad: 1353.2538  LR: 0.000013  \n",
      "Epoch: [1][1000/2849] Elapsed 6m 21s (remain 11m 43s) Loss: 0.0056(0.1234) Grad: 1188.7638  LR: 0.000014  \n",
      "Epoch: [1][1100/2849] Elapsed 6m 58s (remain 11m 4s) Loss: 0.0033(0.1134) Grad: 513.0315  LR: 0.000015  \n",
      "Epoch: [1][1200/2849] Elapsed 7m 36s (remain 10m 26s) Loss: 0.0037(0.1050) Grad: 970.3448  LR: 0.000017  \n",
      "Epoch: [1][1300/2849] Elapsed 8m 15s (remain 9m 49s) Loss: 0.0184(0.0978) Grad: 3516.8013  LR: 0.000018  \n",
      "Epoch: [1][1400/2849] Elapsed 8m 53s (remain 9m 11s) Loss: 0.0084(0.0916) Grad: 1281.9840  LR: 0.000020  \n",
      "Epoch: [1][1500/2849] Elapsed 9m 30s (remain 8m 32s) Loss: 0.0082(0.0862) Grad: 1087.2510  LR: 0.000020  \n",
      "Epoch: [1][1600/2849] Elapsed 10m 7s (remain 7m 53s) Loss: 0.0111(0.0814) Grad: 777.9452  LR: 0.000020  \n",
      "Epoch: [1][1700/2849] Elapsed 10m 45s (remain 7m 15s) Loss: 0.0006(0.0772) Grad: 114.7038  LR: 0.000020  \n",
      "Epoch: [1][1800/2849] Elapsed 11m 23s (remain 6m 37s) Loss: 0.0146(0.0734) Grad: 802.4949  LR: 0.000019  \n",
      "Epoch: [1][1900/2849] Elapsed 12m 0s (remain 5m 59s) Loss: 0.0021(0.0700) Grad: 417.0507  LR: 0.000019  \n",
      "Epoch: [1][2000/2849] Elapsed 12m 37s (remain 5m 21s) Loss: 0.0006(0.0670) Grad: 87.8603  LR: 0.000019  \n",
      "Epoch: [1][2100/2849] Elapsed 13m 17s (remain 4m 43s) Loss: 0.0010(0.0643) Grad: 162.8257  LR: 0.000019  \n",
      "Epoch: [1][2200/2849] Elapsed 13m 54s (remain 4m 5s) Loss: 0.0107(0.0618) Grad: 5993.7109  LR: 0.000019  \n",
      "Epoch: [1][2300/2849] Elapsed 14m 32s (remain 3m 27s) Loss: 0.0009(0.0596) Grad: 92.0371  LR: 0.000019  \n",
      "Epoch: [1][2400/2849] Elapsed 15m 10s (remain 2m 49s) Loss: 0.0100(0.0574) Grad: 1755.9873  LR: 0.000018  \n",
      "Epoch: [1][2500/2849] Elapsed 15m 48s (remain 2m 11s) Loss: 0.0211(0.0555) Grad: 1584.9357  LR: 0.000018  \n",
      "Epoch: [1][2600/2849] Elapsed 16m 24s (remain 1m 33s) Loss: 0.0049(0.0536) Grad: 404.5809  LR: 0.000018  \n",
      "Epoch: [1][2700/2849] Elapsed 17m 3s (remain 0m 56s) Loss: 0.0011(0.0519) Grad: 233.1599  LR: 0.000018  \n",
      "Epoch: [1][2800/2849] Elapsed 17m 43s (remain 0m 18s) Loss: 0.0029(0.0503) Grad: 268.2317  LR: 0.000018  \n",
      "Epoch: [1][2848/2849] Elapsed 18m 0s (remain 0m 0s) Loss: 0.0207(0.0496) Grad: 1020.6097  LR: 0.000018  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 5s) Loss: 0.0023(0.0023) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0027(0.0079) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0010(0.0078) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0002(0.0075) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0054(0.0092) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0184(0.0092) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0023(0.0088) \n",
      "EVAL: [700/726] Elapsed 2m 27s (remain 0m 5s) Loss: 0.0019(0.0083) \n",
      "EVAL: [725/726] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0003(0.0081) \n",
      "Epoch 1 - avg_train_loss: 0.0496  avg_val_loss: 0.0081  time: 1239s\n",
      "Epoch 1 - Score: 0.8466\n",
      "Epoch 1 - Save Best Score: 0.8466 Model\n",
      "Epoch: [2][0/2849] Elapsed 0m 0s (remain 29m 22s) Loss: 0.0093(0.0093) Grad: 112282.3672  LR: 0.000018  \n",
      "Epoch: [2][100/2849] Elapsed 0m 38s (remain 17m 19s) Loss: 0.0002(0.0072) Grad: 485.5917  LR: 0.000018  \n",
      "Epoch: [2][200/2849] Elapsed 1m 16s (remain 16m 42s) Loss: 0.0138(0.0066) Grad: 30728.1211  LR: 0.000017  \n",
      "Epoch: [2][300/2849] Elapsed 1m 56s (remain 16m 22s) Loss: 0.0024(0.0065) Grad: 40214.4414  LR: 0.000017  \n",
      "Epoch: [2][400/2849] Elapsed 2m 34s (remain 15m 41s) Loss: 0.0023(0.0067) Grad: 12453.3535  LR: 0.000017  \n",
      "Epoch: [2][500/2849] Elapsed 3m 13s (remain 15m 7s) Loss: 0.0492(0.0065) Grad: 88970.4766  LR: 0.000017  \n",
      "Epoch: [2][600/2849] Elapsed 3m 51s (remain 14m 26s) Loss: 0.0063(0.0066) Grad: 8748.3691  LR: 0.000017  \n",
      "Epoch: [2][700/2849] Elapsed 4m 29s (remain 13m 44s) Loss: 0.0049(0.0069) Grad: 9728.0967  LR: 0.000017  \n",
      "Epoch: [2][800/2849] Elapsed 5m 6s (remain 13m 3s) Loss: 0.0016(0.0067) Grad: 8137.1753  LR: 0.000017  \n",
      "Epoch: [2][900/2849] Elapsed 5m 45s (remain 12m 27s) Loss: 0.0000(0.0067) Grad: 81.4775  LR: 0.000016  \n",
      "Epoch: [2][1000/2849] Elapsed 6m 24s (remain 11m 50s) Loss: 0.0086(0.0067) Grad: 101903.8047  LR: 0.000016  \n",
      "Epoch: [2][1100/2849] Elapsed 7m 2s (remain 11m 10s) Loss: 0.0003(0.0066) Grad: 3778.8025  LR: 0.000016  \n",
      "Epoch: [2][1200/2849] Elapsed 7m 39s (remain 10m 31s) Loss: 0.0008(0.0065) Grad: 2493.4529  LR: 0.000016  \n",
      "Epoch: [2][1300/2849] Elapsed 8m 18s (remain 9m 52s) Loss: 0.0000(0.0064) Grad: 90.2326  LR: 0.000016  \n",
      "Epoch: [2][1400/2849] Elapsed 8m 57s (remain 9m 15s) Loss: 0.0013(0.0064) Grad: 4075.8547  LR: 0.000016  \n",
      "Epoch: [2][1500/2849] Elapsed 9m 35s (remain 8m 36s) Loss: 0.0003(0.0065) Grad: 1744.0653  LR: 0.000015  \n",
      "Epoch: [2][1600/2849] Elapsed 10m 13s (remain 7m 57s) Loss: 0.0001(0.0065) Grad: 147.9810  LR: 0.000015  \n",
      "Epoch: [2][1700/2849] Elapsed 10m 50s (remain 7m 19s) Loss: 0.0298(0.0065) Grad: 32436.0762  LR: 0.000015  \n",
      "Epoch: [2][1800/2849] Elapsed 11m 29s (remain 6m 41s) Loss: 0.0038(0.0066) Grad: 7598.6851  LR: 0.000015  \n",
      "Epoch: [2][1900/2849] Elapsed 12m 8s (remain 6m 3s) Loss: 0.0016(0.0067) Grad: 2725.8369  LR: 0.000015  \n",
      "Epoch: [2][2000/2849] Elapsed 12m 46s (remain 5m 24s) Loss: 0.0016(0.0067) Grad: 17075.4805  LR: 0.000015  \n",
      "Epoch: [2][2100/2849] Elapsed 13m 24s (remain 4m 46s) Loss: 0.0002(0.0067) Grad: 1892.7303  LR: 0.000014  \n",
      "Epoch: [2][2200/2849] Elapsed 14m 2s (remain 4m 8s) Loss: 0.0002(0.0066) Grad: 1285.2924  LR: 0.000014  \n",
      "Epoch: [2][2300/2849] Elapsed 14m 41s (remain 3m 29s) Loss: 0.0179(0.0067) Grad: 69176.9141  LR: 0.000014  \n",
      "Epoch: [2][2400/2849] Elapsed 15m 18s (remain 2m 51s) Loss: 0.0012(0.0066) Grad: 7939.7075  LR: 0.000014  \n",
      "Epoch: [2][2500/2849] Elapsed 15m 56s (remain 2m 13s) Loss: 0.0017(0.0066) Grad: 3012.0801  LR: 0.000014  \n",
      "Epoch: [2][2600/2849] Elapsed 16m 35s (remain 1m 34s) Loss: 0.0011(0.0067) Grad: 3911.2327  LR: 0.000014  \n",
      "Epoch: [2][2700/2849] Elapsed 17m 13s (remain 0m 56s) Loss: 0.0001(0.0067) Grad: 462.0681  LR: 0.000014  \n",
      "Epoch: [2][2800/2849] Elapsed 17m 51s (remain 0m 18s) Loss: 0.0272(0.0066) Grad: 19204.5137  LR: 0.000013  \n",
      "Epoch: [2][2848/2849] Elapsed 18m 8s (remain 0m 0s) Loss: 0.0001(0.0066) Grad: 187.4836  LR: 0.000013  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 6s) Loss: 0.0007(0.0007) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 13s) Loss: 0.0047(0.0096) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0003(0.0094) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0000(0.0093) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0020(0.0110) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0282(0.0110) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0027(0.0104) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0041(0.0098) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0001(0.0097) \n",
      "Epoch 2 - avg_train_loss: 0.0066  avg_val_loss: 0.0097  time: 1247s\n",
      "Epoch 2 - Score: 0.8742\n",
      "Epoch 2 - Save Best Score: 0.8742 Model\n",
      "Epoch: [3][0/2849] Elapsed 0m 0s (remain 30m 23s) Loss: 0.0002(0.0002) Grad: 670.3440  LR: 0.000013  \n",
      "Epoch: [3][100/2849] Elapsed 0m 38s (remain 17m 16s) Loss: 0.0003(0.0049) Grad: 1917.9242  LR: 0.000013  \n",
      "Epoch: [3][200/2849] Elapsed 1m 16s (remain 16m 50s) Loss: 0.0032(0.0051) Grad: 29144.4707  LR: 0.000013  \n",
      "Epoch: [3][300/2849] Elapsed 1m 55s (remain 16m 15s) Loss: 0.0256(0.0052) Grad: 19678.0117  LR: 0.000013  \n",
      "Epoch: [3][400/2849] Elapsed 2m 32s (remain 15m 33s) Loss: 0.0059(0.0051) Grad: 8834.2266  LR: 0.000013  \n",
      "Epoch: [3][500/2849] Elapsed 3m 10s (remain 14m 52s) Loss: 0.0076(0.0053) Grad: 6833.9585  LR: 0.000013  \n",
      "Epoch: [3][600/2849] Elapsed 3m 48s (remain 14m 15s) Loss: 0.0001(0.0052) Grad: 216.2044  LR: 0.000012  \n",
      "Epoch: [3][700/2849] Elapsed 4m 26s (remain 13m 37s) Loss: 0.0000(0.0054) Grad: 112.8551  LR: 0.000012  \n",
      "Epoch: [3][800/2849] Elapsed 5m 3s (remain 12m 57s) Loss: 0.0040(0.0053) Grad: 11682.9062  LR: 0.000012  \n",
      "Epoch: [3][900/2849] Elapsed 5m 41s (remain 12m 18s) Loss: 0.0058(0.0052) Grad: 36056.7305  LR: 0.000012  \n",
      "Epoch: [3][1000/2849] Elapsed 6m 18s (remain 11m 38s) Loss: 0.0086(0.0052) Grad: 23314.8574  LR: 0.000012  \n",
      "Epoch: [3][1100/2849] Elapsed 6m 56s (remain 11m 1s) Loss: 0.0035(0.0051) Grad: 9699.8301  LR: 0.000012  \n",
      "Epoch: [3][1200/2849] Elapsed 7m 35s (remain 10m 24s) Loss: 0.0336(0.0052) Grad: 30614.3379  LR: 0.000011  \n",
      "Epoch: [3][1300/2849] Elapsed 8m 14s (remain 9m 48s) Loss: 0.0221(0.0052) Grad: 19868.9414  LR: 0.000011  \n",
      "Epoch: [3][1400/2849] Elapsed 8m 51s (remain 9m 9s) Loss: 0.0034(0.0052) Grad: 7107.9507  LR: 0.000011  \n",
      "Epoch: [3][1500/2849] Elapsed 9m 29s (remain 8m 31s) Loss: 0.0008(0.0054) Grad: 3912.0540  LR: 0.000011  \n",
      "Epoch: [3][1600/2849] Elapsed 10m 7s (remain 7m 53s) Loss: 0.0064(0.0054) Grad: 29710.4551  LR: 0.000011  \n",
      "Epoch: [3][1700/2849] Elapsed 10m 45s (remain 7m 15s) Loss: 0.0000(0.0054) Grad: 123.3098  LR: 0.000011  \n",
      "Epoch: [3][1800/2849] Elapsed 11m 22s (remain 6m 37s) Loss: 0.0049(0.0055) Grad: 7739.2026  LR: 0.000011  \n",
      "Epoch: [3][1900/2849] Elapsed 11m 59s (remain 5m 59s) Loss: 0.0029(0.0055) Grad: 4238.6152  LR: 0.000010  \n",
      "Epoch: [3][2000/2849] Elapsed 12m 37s (remain 5m 21s) Loss: 0.0001(0.0055) Grad: 422.1596  LR: 0.000010  \n",
      "Epoch: [3][2100/2849] Elapsed 13m 15s (remain 4m 43s) Loss: 0.0001(0.0055) Grad: 847.5036  LR: 0.000010  \n",
      "Epoch: [3][2200/2849] Elapsed 13m 55s (remain 4m 6s) Loss: 0.0000(0.0055) Grad: 54.9751  LR: 0.000010  \n",
      "Epoch: [3][2300/2849] Elapsed 14m 33s (remain 3m 27s) Loss: 0.0001(0.0055) Grad: 641.5535  LR: 0.000010  \n",
      "Epoch: [3][2400/2849] Elapsed 15m 11s (remain 2m 50s) Loss: 0.0002(0.0056) Grad: 418.9493  LR: 0.000010  \n",
      "Epoch: [3][2500/2849] Elapsed 15m 49s (remain 2m 12s) Loss: 0.0052(0.0056) Grad: 15338.4199  LR: 0.000009  \n",
      "Epoch: [3][2600/2849] Elapsed 16m 28s (remain 1m 34s) Loss: 0.0184(0.0056) Grad: 22159.4238  LR: 0.000009  \n",
      "Epoch: [3][2700/2849] Elapsed 17m 5s (remain 0m 56s) Loss: 0.0057(0.0056) Grad: 15644.2422  LR: 0.000009  \n",
      "Epoch: [3][2800/2849] Elapsed 17m 43s (remain 0m 18s) Loss: 0.0001(0.0055) Grad: 419.0831  LR: 0.000009  \n",
      "Epoch: [3][2848/2849] Elapsed 18m 1s (remain 0m 0s) Loss: 0.0013(0.0055) Grad: 6317.7510  LR: 0.000009  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 44s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 13s) Loss: 0.0027(0.0094) \n",
      "EVAL: [200/726] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0001(0.0098) \n",
      "EVAL: [300/726] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0000(0.0092) \n",
      "EVAL: [400/726] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0043(0.0113) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 48s) Loss: 0.0371(0.0114) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0032(0.0107) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0029(0.0100) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0000(0.0099) \n",
      "Epoch 3 - avg_train_loss: 0.0055  avg_val_loss: 0.0099  time: 1240s\n",
      "Epoch 3 - Score: 0.8749\n",
      "Epoch 3 - Save Best Score: 0.8749 Model\n",
      "Epoch: [4][0/2849] Elapsed 0m 0s (remain 31m 16s) Loss: 0.0088(0.0088) Grad: 11493.6758  LR: 0.000009  \n",
      "Epoch: [4][100/2849] Elapsed 0m 39s (remain 17m 45s) Loss: 0.0004(0.0040) Grad: 3432.1711  LR: 0.000009  \n",
      "Epoch: [4][200/2849] Elapsed 1m 16s (remain 16m 50s) Loss: 0.0452(0.0046) Grad: 22781.0977  LR: 0.000009  \n",
      "Epoch: [4][300/2849] Elapsed 1m 55s (remain 16m 14s) Loss: 0.0008(0.0049) Grad: 6355.3516  LR: 0.000008  \n",
      "Epoch: [4][400/2849] Elapsed 2m 33s (remain 15m 40s) Loss: 0.0034(0.0048) Grad: 9788.9600  LR: 0.000008  \n",
      "Epoch: [4][500/2849] Elapsed 3m 11s (remain 14m 56s) Loss: 0.0005(0.0046) Grad: 4609.7598  LR: 0.000008  \n",
      "Epoch: [4][600/2849] Elapsed 3m 48s (remain 14m 15s) Loss: 0.0029(0.0046) Grad: 6854.8320  LR: 0.000008  \n",
      "Epoch: [4][700/2849] Elapsed 4m 26s (remain 13m 35s) Loss: 0.0009(0.0045) Grad: 3310.3435  LR: 0.000008  \n",
      "Epoch: [4][800/2849] Elapsed 5m 6s (remain 13m 3s) Loss: 0.0007(0.0049) Grad: 4982.6035  LR: 0.000008  \n",
      "Epoch: [4][900/2849] Elapsed 5m 45s (remain 12m 26s) Loss: 0.0014(0.0049) Grad: 12515.4092  LR: 0.000007  \n",
      "Epoch: [4][1000/2849] Elapsed 6m 23s (remain 11m 47s) Loss: 0.0017(0.0049) Grad: 10059.7324  LR: 0.000007  \n",
      "Epoch: [4][1100/2849] Elapsed 7m 2s (remain 11m 10s) Loss: 0.0115(0.0048) Grad: 25633.3516  LR: 0.000007  \n",
      "Epoch: [4][1200/2849] Elapsed 7m 42s (remain 10m 34s) Loss: 0.0014(0.0050) Grad: 11749.1895  LR: 0.000007  \n",
      "Epoch: [4][1300/2849] Elapsed 8m 20s (remain 9m 54s) Loss: 0.0000(0.0050) Grad: 75.9490  LR: 0.000007  \n",
      "Epoch: [4][1400/2849] Elapsed 8m 57s (remain 9m 15s) Loss: 0.0001(0.0050) Grad: 258.4406  LR: 0.000007  \n",
      "Epoch: [4][1500/2849] Elapsed 9m 34s (remain 8m 35s) Loss: 0.0000(0.0051) Grad: 60.0523  LR: 0.000007  \n",
      "Epoch: [4][1600/2849] Elapsed 10m 12s (remain 7m 57s) Loss: 0.0005(0.0050) Grad: 2857.8232  LR: 0.000006  \n",
      "Epoch: [4][1700/2849] Elapsed 10m 50s (remain 7m 19s) Loss: 0.0000(0.0050) Grad: 40.2236  LR: 0.000006  \n",
      "Epoch: [4][1800/2849] Elapsed 11m 28s (remain 6m 40s) Loss: 0.0000(0.0048) Grad: 180.4937  LR: 0.000006  \n",
      "Epoch: [4][1900/2849] Elapsed 12m 6s (remain 6m 2s) Loss: 0.0010(0.0048) Grad: 8398.4551  LR: 0.000006  \n",
      "Epoch: [4][2000/2849] Elapsed 12m 45s (remain 5m 24s) Loss: 0.0001(0.0048) Grad: 647.3889  LR: 0.000006  \n",
      "Epoch: [4][2100/2849] Elapsed 13m 22s (remain 4m 45s) Loss: 0.0000(0.0047) Grad: 47.7466  LR: 0.000006  \n",
      "Epoch: [4][2200/2849] Elapsed 14m 0s (remain 4m 7s) Loss: 0.0072(0.0047) Grad: 12495.3281  LR: 0.000005  \n",
      "Epoch: [4][2300/2849] Elapsed 14m 39s (remain 3m 29s) Loss: 0.0000(0.0046) Grad: 74.5915  LR: 0.000005  \n",
      "Epoch: [4][2400/2849] Elapsed 15m 16s (remain 2m 50s) Loss: 0.0017(0.0046) Grad: 5308.0918  LR: 0.000005  \n",
      "Epoch: [4][2500/2849] Elapsed 15m 53s (remain 2m 12s) Loss: 0.0068(0.0047) Grad: 25863.4785  LR: 0.000005  \n",
      "Epoch: [4][2600/2849] Elapsed 16m 31s (remain 1m 34s) Loss: 0.0009(0.0047) Grad: 4770.1304  LR: 0.000005  \n",
      "Epoch: [4][2700/2849] Elapsed 17m 9s (remain 0m 56s) Loss: 0.0027(0.0046) Grad: 13105.0693  LR: 0.000005  \n",
      "Epoch: [4][2800/2849] Elapsed 17m 47s (remain 0m 18s) Loss: 0.0001(0.0047) Grad: 300.6536  LR: 0.000005  \n",
      "Epoch: [4][2848/2849] Elapsed 18m 5s (remain 0m 0s) Loss: 0.0258(0.0047) Grad: 55624.1758  LR: 0.000004  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 1s) Loss: 0.0003(0.0003) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 15s) Loss: 0.0052(0.0098) \n",
      "EVAL: [200/726] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0003(0.0094) \n",
      "EVAL: [300/726] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0000(0.0091) \n",
      "EVAL: [400/726] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0019(0.0114) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0279(0.0115) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0126(0.0108) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0030(0.0101) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0000(0.0099) \n",
      "Epoch 4 - avg_train_loss: 0.0047  avg_val_loss: 0.0099  time: 1243s\n",
      "Epoch 4 - Score: 0.8810\n",
      "Epoch 4 - Save Best Score: 0.8810 Model\n",
      "Epoch: [5][0/2849] Elapsed 0m 0s (remain 29m 43s) Loss: 0.0015(0.0015) Grad: 11692.5781  LR: 0.000004  \n",
      "Epoch: [5][100/2849] Elapsed 0m 39s (remain 17m 57s) Loss: 0.0002(0.0031) Grad: 1828.1486  LR: 0.000004  \n",
      "Epoch: [5][200/2849] Elapsed 1m 17s (remain 17m 0s) Loss: 0.0000(0.0033) Grad: 31.1300  LR: 0.000004  \n",
      "Epoch: [5][300/2849] Elapsed 1m 54s (remain 16m 12s) Loss: 0.0000(0.0029) Grad: 10.4171  LR: 0.000004  \n",
      "Epoch: [5][400/2849] Elapsed 2m 32s (remain 15m 33s) Loss: 0.0242(0.0038) Grad: 52423.4141  LR: 0.000004  \n",
      "Epoch: [5][500/2849] Elapsed 3m 10s (remain 14m 51s) Loss: 0.0000(0.0039) Grad: 298.4745  LR: 0.000004  \n",
      "Epoch: [5][600/2849] Elapsed 3m 48s (remain 14m 13s) Loss: 0.0002(0.0040) Grad: 1416.6683  LR: 0.000004  \n",
      "Epoch: [5][700/2849] Elapsed 4m 26s (remain 13m 35s) Loss: 0.0015(0.0043) Grad: 2898.0718  LR: 0.000003  \n",
      "Epoch: [5][800/2849] Elapsed 5m 3s (remain 12m 54s) Loss: 0.0042(0.0042) Grad: 15738.5615  LR: 0.000003  \n",
      "Epoch: [5][900/2849] Elapsed 5m 42s (remain 12m 19s) Loss: 0.0000(0.0041) Grad: 44.2971  LR: 0.000003  \n",
      "Epoch: [5][1000/2849] Elapsed 6m 18s (remain 11m 39s) Loss: 0.0033(0.0040) Grad: 13687.9121  LR: 0.000003  \n",
      "Epoch: [5][1100/2849] Elapsed 6m 55s (remain 10m 59s) Loss: 0.0001(0.0040) Grad: 275.0740  LR: 0.000003  \n",
      "Epoch: [5][1200/2849] Elapsed 7m 32s (remain 10m 20s) Loss: 0.0000(0.0040) Grad: 17.6710  LR: 0.000003  \n",
      "Epoch: [5][1300/2849] Elapsed 8m 9s (remain 9m 42s) Loss: 0.0018(0.0042) Grad: 9245.7822  LR: 0.000002  \n",
      "Epoch: [5][1400/2849] Elapsed 8m 47s (remain 9m 5s) Loss: 0.0240(0.0041) Grad: 19915.0781  LR: 0.000002  \n",
      "Epoch: [5][1500/2849] Elapsed 9m 26s (remain 8m 29s) Loss: 0.0010(0.0040) Grad: 4230.3682  LR: 0.000002  \n",
      "Epoch: [5][1600/2849] Elapsed 10m 6s (remain 7m 52s) Loss: 0.0001(0.0040) Grad: 1025.0521  LR: 0.000002  \n",
      "Epoch: [5][1700/2849] Elapsed 10m 43s (remain 7m 14s) Loss: 0.0132(0.0041) Grad: 8700.5469  LR: 0.000002  \n",
      "Epoch: [5][1800/2849] Elapsed 11m 21s (remain 6m 36s) Loss: 0.0000(0.0040) Grad: 40.3862  LR: 0.000002  \n",
      "Epoch: [5][1900/2849] Elapsed 12m 1s (remain 5m 59s) Loss: 0.0033(0.0039) Grad: 6025.4146  LR: 0.000001  \n",
      "Epoch: [5][2000/2849] Elapsed 12m 39s (remain 5m 21s) Loss: 0.0003(0.0040) Grad: 5061.0679  LR: 0.000001  \n",
      "Epoch: [5][2100/2849] Elapsed 13m 16s (remain 4m 43s) Loss: 0.0026(0.0040) Grad: 6946.4966  LR: 0.000001  \n",
      "Epoch: [5][2200/2849] Elapsed 13m 54s (remain 4m 5s) Loss: 0.0000(0.0039) Grad: 14.9866  LR: 0.000001  \n",
      "Epoch: [5][2300/2849] Elapsed 14m 32s (remain 3m 27s) Loss: 0.0005(0.0040) Grad: 7957.0029  LR: 0.000001  \n",
      "Epoch: [5][2400/2849] Elapsed 15m 9s (remain 2m 49s) Loss: 0.0001(0.0040) Grad: 290.0544  LR: 0.000001  \n",
      "Epoch: [5][2500/2849] Elapsed 15m 47s (remain 2m 11s) Loss: 0.0000(0.0040) Grad: 61.0496  LR: 0.000001  \n",
      "Epoch: [5][2600/2849] Elapsed 16m 24s (remain 1m 33s) Loss: 0.0173(0.0041) Grad: 15232.6758  LR: 0.000000  \n",
      "Epoch: [5][2700/2849] Elapsed 17m 3s (remain 0m 56s) Loss: 0.0007(0.0041) Grad: 6305.7495  LR: 0.000000  \n",
      "Epoch: [5][2800/2849] Elapsed 17m 40s (remain 0m 18s) Loss: 0.0015(0.0041) Grad: 3348.0935  LR: 0.000000  \n",
      "Epoch: [5][2848/2849] Elapsed 17m 58s (remain 0m 0s) Loss: 0.0036(0.0041) Grad: 5794.8975  LR: 0.000000  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 5s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0053(0.0114) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 52s) Loss: 0.0001(0.0106) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 30s) Loss: 0.0000(0.0103) \n",
      "EVAL: [400/726] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0017(0.0126) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0309(0.0127) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0145(0.0119) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0032(0.0111) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0000(0.0109) \n",
      "Epoch 5 - avg_train_loss: 0.0041  avg_val_loss: 0.0109  time: 1236s\n",
      "Epoch 5 - Score: 0.8775\n",
      "========== fold: 1 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2851] Elapsed 0m 0s (remain 31m 5s) Loss: 0.4919(0.4919) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2851] Elapsed 0m 38s (remain 17m 21s) Loss: 0.2642(0.4916) Grad: 29332.3379  LR: 0.000001  \n",
      "Epoch: [1][200/2851] Elapsed 1m 16s (remain 16m 44s) Loss: 0.1279(0.3848) Grad: 16415.1777  LR: 0.000003  \n",
      "Epoch: [1][300/2851] Elapsed 1m 53s (remain 16m 4s) Loss: 0.0515(0.2824) Grad: 1010.9747  LR: 0.000004  \n",
      "Epoch: [1][400/2851] Elapsed 2m 31s (remain 15m 24s) Loss: 0.0496(0.2231) Grad: 1116.6167  LR: 0.000006  \n",
      "Epoch: [1][500/2851] Elapsed 3m 8s (remain 14m 45s) Loss: 0.1161(0.1868) Grad: 4368.3516  LR: 0.000007  \n",
      "Epoch: [1][600/2851] Elapsed 3m 47s (remain 14m 11s) Loss: 0.0564(0.1621) Grad: 1614.5374  LR: 0.000008  \n",
      "Epoch: [1][700/2851] Elapsed 4m 26s (remain 13m 38s) Loss: 0.0286(0.1441) Grad: 944.9935  LR: 0.000010  \n",
      "Epoch: [1][800/2851] Elapsed 5m 4s (remain 12m 59s) Loss: 0.0063(0.1302) Grad: 1760.6929  LR: 0.000011  \n",
      "Epoch: [1][900/2851] Elapsed 5m 42s (remain 12m 21s) Loss: 0.0290(0.1180) Grad: 4271.3062  LR: 0.000013  \n",
      "Epoch: [1][1000/2851] Elapsed 6m 20s (remain 11m 43s) Loss: 0.0018(0.1079) Grad: 371.9309  LR: 0.000014  \n",
      "Epoch: [1][1100/2851] Elapsed 7m 0s (remain 11m 8s) Loss: 0.0032(0.0995) Grad: 2131.2776  LR: 0.000015  \n",
      "Epoch: [1][1200/2851] Elapsed 7m 41s (remain 10m 34s) Loss: 0.0237(0.0922) Grad: 5236.6997  LR: 0.000017  \n",
      "Epoch: [1][1300/2851] Elapsed 8m 19s (remain 9m 54s) Loss: 0.0129(0.0862) Grad: 3632.0132  LR: 0.000018  \n",
      "Epoch: [1][1400/2851] Elapsed 8m 57s (remain 9m 15s) Loss: 0.0251(0.0808) Grad: 4954.2344  LR: 0.000020  \n",
      "Epoch: [1][1500/2851] Elapsed 9m 37s (remain 8m 38s) Loss: 0.0609(0.0762) Grad: 11920.4590  LR: 0.000020  \n",
      "Epoch: [1][1600/2851] Elapsed 10m 14s (remain 8m 0s) Loss: 0.0017(0.0721) Grad: 734.0381  LR: 0.000020  \n",
      "Epoch: [1][1700/2851] Elapsed 10m 52s (remain 7m 21s) Loss: 0.0012(0.0683) Grad: 929.8179  LR: 0.000020  \n",
      "Epoch: [1][1800/2851] Elapsed 11m 30s (remain 6m 42s) Loss: 0.0057(0.0653) Grad: 1911.7209  LR: 0.000019  \n",
      "Epoch: [1][1900/2851] Elapsed 12m 7s (remain 6m 3s) Loss: 0.0040(0.0624) Grad: 809.7362  LR: 0.000019  \n",
      "Epoch: [1][2000/2851] Elapsed 12m 46s (remain 5m 25s) Loss: 0.0138(0.0599) Grad: 1834.8295  LR: 0.000019  \n",
      "Epoch: [1][2100/2851] Elapsed 13m 24s (remain 4m 47s) Loss: 0.0042(0.0574) Grad: 1805.5353  LR: 0.000019  \n",
      "Epoch: [1][2200/2851] Elapsed 14m 1s (remain 4m 8s) Loss: 0.0770(0.0552) Grad: 12374.6963  LR: 0.000019  \n",
      "Epoch: [1][2300/2851] Elapsed 14m 38s (remain 3m 30s) Loss: 0.0015(0.0532) Grad: 1346.9540  LR: 0.000019  \n",
      "Epoch: [1][2400/2851] Elapsed 15m 17s (remain 2m 51s) Loss: 0.0081(0.0513) Grad: 1541.7018  LR: 0.000018  \n",
      "Epoch: [1][2500/2851] Elapsed 15m 56s (remain 2m 13s) Loss: 0.0113(0.0496) Grad: 3431.6660  LR: 0.000018  \n",
      "Epoch: [1][2600/2851] Elapsed 16m 33s (remain 1m 35s) Loss: 0.0034(0.0480) Grad: 1468.7728  LR: 0.000018  \n",
      "Epoch: [1][2700/2851] Elapsed 17m 11s (remain 0m 57s) Loss: 0.0196(0.0465) Grad: 5756.9468  LR: 0.000018  \n",
      "Epoch: [1][2800/2851] Elapsed 17m 49s (remain 0m 19s) Loss: 0.0089(0.0452) Grad: 2933.8118  LR: 0.000018  \n",
      "Epoch: [1][2850/2851] Elapsed 18m 8s (remain 0m 0s) Loss: 0.0030(0.0445) Grad: 816.8293  LR: 0.000018  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 27s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0054(0.0064) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 53s) Loss: 0.0000(0.0081) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0006(0.0079) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0000(0.0084) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0202(0.0096) \n",
      "EVAL: [600/724] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0035(0.0092) \n",
      "EVAL: [700/724] Elapsed 2m 29s (remain 0m 4s) Loss: 0.0000(0.0084) \n",
      "EVAL: [723/724] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0002(0.0083) \n",
      "Epoch 1 - avg_train_loss: 0.0445  avg_val_loss: 0.0083  time: 1247s\n",
      "Epoch 1 - Score: 0.8613\n",
      "Epoch 1 - Save Best Score: 0.8613 Model\n",
      "Epoch: [2][0/2851] Elapsed 0m 0s (remain 31m 27s) Loss: 0.0002(0.0002) Grad: 963.1376  LR: 0.000018  \n",
      "Epoch: [2][100/2851] Elapsed 0m 38s (remain 17m 27s) Loss: 0.0132(0.0085) Grad: 21733.9629  LR: 0.000018  \n",
      "Epoch: [2][200/2851] Elapsed 1m 16s (remain 16m 44s) Loss: 0.0008(0.0083) Grad: 3174.5125  LR: 0.000017  \n",
      "Epoch: [2][300/2851] Elapsed 1m 53s (remain 16m 2s) Loss: 0.0036(0.0081) Grad: 8635.2783  LR: 0.000017  \n",
      "Epoch: [2][400/2851] Elapsed 2m 32s (remain 15m 29s) Loss: 0.0006(0.0082) Grad: 4954.4907  LR: 0.000017  \n",
      "Epoch: [2][500/2851] Elapsed 3m 9s (remain 14m 50s) Loss: 0.1254(0.0083) Grad: 39477.4258  LR: 0.000017  \n",
      "Epoch: [2][600/2851] Elapsed 3m 47s (remain 14m 10s) Loss: 0.0035(0.0078) Grad: 9380.5176  LR: 0.000017  \n",
      "Epoch: [2][700/2851] Elapsed 4m 25s (remain 13m 35s) Loss: 0.0032(0.0079) Grad: 25623.1211  LR: 0.000017  \n",
      "Epoch: [2][800/2851] Elapsed 5m 4s (remain 12m 59s) Loss: 0.0000(0.0079) Grad: 135.8665  LR: 0.000017  \n",
      "Epoch: [2][900/2851] Elapsed 5m 42s (remain 12m 21s) Loss: 0.0004(0.0079) Grad: 1191.2311  LR: 0.000016  \n",
      "Epoch: [2][1000/2851] Elapsed 6m 20s (remain 11m 42s) Loss: 0.0021(0.0077) Grad: 4271.3442  LR: 0.000016  \n",
      "Epoch: [2][1100/2851] Elapsed 6m 57s (remain 11m 3s) Loss: 0.0056(0.0076) Grad: 10188.6016  LR: 0.000016  \n",
      "Epoch: [2][1200/2851] Elapsed 7m 34s (remain 10m 25s) Loss: 0.0039(0.0075) Grad: 11241.4219  LR: 0.000016  \n",
      "Epoch: [2][1300/2851] Elapsed 8m 13s (remain 9m 48s) Loss: 0.0025(0.0073) Grad: 6797.7539  LR: 0.000016  \n",
      "Epoch: [2][1400/2851] Elapsed 8m 51s (remain 9m 10s) Loss: 0.0058(0.0072) Grad: 7939.8398  LR: 0.000016  \n",
      "Epoch: [2][1500/2851] Elapsed 9m 30s (remain 8m 33s) Loss: 0.0017(0.0072) Grad: 21066.4375  LR: 0.000015  \n",
      "Epoch: [2][1600/2851] Elapsed 10m 8s (remain 7m 54s) Loss: 0.0003(0.0072) Grad: 987.0956  LR: 0.000015  \n",
      "Epoch: [2][1700/2851] Elapsed 10m 45s (remain 7m 16s) Loss: 0.0001(0.0072) Grad: 265.9933  LR: 0.000015  \n",
      "Epoch: [2][1800/2851] Elapsed 11m 23s (remain 6m 38s) Loss: 0.0057(0.0070) Grad: 5492.4160  LR: 0.000015  \n",
      "Epoch: [2][1900/2851] Elapsed 12m 0s (remain 6m 0s) Loss: 0.0011(0.0069) Grad: 2611.7480  LR: 0.000015  \n",
      "Epoch: [2][2000/2851] Elapsed 12m 39s (remain 5m 22s) Loss: 0.0014(0.0069) Grad: 2289.9448  LR: 0.000015  \n",
      "Epoch: [2][2100/2851] Elapsed 13m 20s (remain 4m 45s) Loss: 0.0092(0.0069) Grad: 15858.0625  LR: 0.000015  \n",
      "Epoch: [2][2200/2851] Elapsed 13m 58s (remain 4m 7s) Loss: 0.0202(0.0068) Grad: 59679.4844  LR: 0.000014  \n",
      "Epoch: [2][2300/2851] Elapsed 14m 35s (remain 3m 29s) Loss: 0.0004(0.0068) Grad: 3576.1272  LR: 0.000014  \n",
      "Epoch: [2][2400/2851] Elapsed 15m 15s (remain 2m 51s) Loss: 0.0122(0.0068) Grad: 31357.3418  LR: 0.000014  \n",
      "Epoch: [2][2500/2851] Elapsed 15m 55s (remain 2m 13s) Loss: 0.0026(0.0069) Grad: 4056.2473  LR: 0.000014  \n",
      "Epoch: [2][2600/2851] Elapsed 16m 33s (remain 1m 35s) Loss: 0.0054(0.0068) Grad: 5967.2593  LR: 0.000014  \n",
      "Epoch: [2][2700/2851] Elapsed 17m 10s (remain 0m 57s) Loss: 0.0252(0.0068) Grad: 65741.4922  LR: 0.000014  \n",
      "Epoch: [2][2800/2851] Elapsed 17m 48s (remain 0m 19s) Loss: 0.0021(0.0069) Grad: 4983.8008  LR: 0.000013  \n",
      "Epoch: [2][2850/2851] Elapsed 18m 8s (remain 0m 0s) Loss: 0.0003(0.0068) Grad: 2349.3752  LR: 0.000013  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 47s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0057(0.0064) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0000(0.0084) \n",
      "EVAL: [300/724] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0034(0.0080) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0000(0.0081) \n",
      "EVAL: [500/724] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0152(0.0097) \n",
      "EVAL: [600/724] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0073(0.0094) \n",
      "EVAL: [700/724] Elapsed 2m 28s (remain 0m 4s) Loss: 0.0000(0.0086) \n",
      "EVAL: [723/724] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0000(0.0086) \n",
      "Epoch 2 - avg_train_loss: 0.0068  avg_val_loss: 0.0086  time: 1247s\n",
      "Epoch 2 - Score: 0.8808\n",
      "Epoch 2 - Save Best Score: 0.8808 Model\n",
      "Epoch: [3][0/2851] Elapsed 0m 0s (remain 30m 59s) Loss: 0.0033(0.0033) Grad: 7718.8657  LR: 0.000013  \n",
      "Epoch: [3][100/2851] Elapsed 0m 38s (remain 17m 20s) Loss: 0.0001(0.0041) Grad: 127.5477  LR: 0.000013  \n",
      "Epoch: [3][200/2851] Elapsed 1m 16s (remain 16m 42s) Loss: 0.0002(0.0050) Grad: 1224.3298  LR: 0.000013  \n",
      "Epoch: [3][300/2851] Elapsed 1m 53s (remain 15m 59s) Loss: 0.0005(0.0055) Grad: 6250.5073  LR: 0.000013  \n",
      "Epoch: [3][400/2851] Elapsed 2m 30s (remain 15m 20s) Loss: 0.0000(0.0054) Grad: 36.1642  LR: 0.000013  \n",
      "Epoch: [3][500/2851] Elapsed 3m 8s (remain 14m 41s) Loss: 0.0001(0.0057) Grad: 354.2963  LR: 0.000013  \n",
      "Epoch: [3][600/2851] Elapsed 3m 46s (remain 14m 8s) Loss: 0.0429(0.0058) Grad: 33731.7188  LR: 0.000012  \n",
      "Epoch: [3][700/2851] Elapsed 4m 25s (remain 13m 34s) Loss: 0.0034(0.0059) Grad: 12573.7197  LR: 0.000012  \n",
      "Epoch: [3][800/2851] Elapsed 5m 2s (remain 12m 55s) Loss: 0.0067(0.0058) Grad: 13916.1533  LR: 0.000012  \n",
      "Epoch: [3][900/2851] Elapsed 5m 40s (remain 12m 17s) Loss: 0.0212(0.0056) Grad: 41963.3398  LR: 0.000012  \n",
      "Epoch: [3][1000/2851] Elapsed 6m 18s (remain 11m 38s) Loss: 0.0008(0.0057) Grad: 2098.9290  LR: 0.000012  \n",
      "Epoch: [3][1100/2851] Elapsed 6m 56s (remain 11m 1s) Loss: 0.0036(0.0057) Grad: 7058.7661  LR: 0.000012  \n",
      "Epoch: [3][1200/2851] Elapsed 7m 35s (remain 10m 25s) Loss: 0.0001(0.0058) Grad: 191.0118  LR: 0.000011  \n",
      "Epoch: [3][1300/2851] Elapsed 8m 14s (remain 9m 48s) Loss: 0.0001(0.0058) Grad: 335.5475  LR: 0.000011  \n",
      "Epoch: [3][1400/2851] Elapsed 8m 51s (remain 9m 9s) Loss: 0.0094(0.0058) Grad: 20565.9336  LR: 0.000011  \n",
      "Epoch: [3][1500/2851] Elapsed 9m 28s (remain 8m 31s) Loss: 0.0000(0.0060) Grad: 90.4093  LR: 0.000011  \n",
      "Epoch: [3][1600/2851] Elapsed 10m 6s (remain 7m 53s) Loss: 0.0077(0.0059) Grad: 16338.4639  LR: 0.000011  \n",
      "Epoch: [3][1700/2851] Elapsed 10m 46s (remain 7m 17s) Loss: 0.0000(0.0058) Grad: 44.5005  LR: 0.000011  \n",
      "Epoch: [3][1800/2851] Elapsed 11m 25s (remain 6m 39s) Loss: 0.0007(0.0058) Grad: 3607.7869  LR: 0.000011  \n",
      "Epoch: [3][1900/2851] Elapsed 12m 3s (remain 6m 1s) Loss: 0.0009(0.0059) Grad: 3736.3176  LR: 0.000010  \n",
      "Epoch: [3][2000/2851] Elapsed 12m 41s (remain 5m 23s) Loss: 0.0000(0.0058) Grad: 96.9414  LR: 0.000010  \n",
      "Epoch: [3][2100/2851] Elapsed 13m 19s (remain 4m 45s) Loss: 0.0030(0.0057) Grad: 13662.2725  LR: 0.000010  \n",
      "Epoch: [3][2200/2851] Elapsed 13m 58s (remain 4m 7s) Loss: 0.0001(0.0057) Grad: 181.1246  LR: 0.000010  \n",
      "Epoch: [3][2300/2851] Elapsed 14m 37s (remain 3m 29s) Loss: 0.0072(0.0058) Grad: 11513.1094  LR: 0.000010  \n",
      "Epoch: [3][2400/2851] Elapsed 15m 15s (remain 2m 51s) Loss: 0.0355(0.0057) Grad: 61330.8203  LR: 0.000010  \n",
      "Epoch: [3][2500/2851] Elapsed 15m 52s (remain 2m 13s) Loss: 0.0010(0.0057) Grad: 4015.6860  LR: 0.000009  \n",
      "Epoch: [3][2600/2851] Elapsed 16m 30s (remain 1m 35s) Loss: 0.0019(0.0058) Grad: 14317.0264  LR: 0.000009  \n",
      "Epoch: [3][2700/2851] Elapsed 17m 8s (remain 0m 57s) Loss: 0.0001(0.0057) Grad: 371.9068  LR: 0.000009  \n",
      "Epoch: [3][2800/2851] Elapsed 17m 49s (remain 0m 19s) Loss: 0.0004(0.0056) Grad: 2746.2590  LR: 0.000009  \n",
      "Epoch: [3][2850/2851] Elapsed 18m 7s (remain 0m 0s) Loss: 0.0001(0.0056) Grad: 508.6800  LR: 0.000009  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 33s) Loss: 0.0008(0.0008) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0007(0.0063) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0000(0.0089) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0169(0.0085) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0000(0.0083) \n",
      "EVAL: [500/724] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0199(0.0099) \n",
      "EVAL: [600/724] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0007(0.0093) \n",
      "EVAL: [700/724] Elapsed 2m 28s (remain 0m 4s) Loss: 0.0000(0.0086) \n",
      "EVAL: [723/724] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0000(0.0084) \n",
      "Epoch 3 - avg_train_loss: 0.0056  avg_val_loss: 0.0084  time: 1246s\n",
      "Epoch 3 - Score: 0.8862\n",
      "Epoch 3 - Save Best Score: 0.8862 Model\n",
      "Epoch: [4][0/2851] Elapsed 0m 0s (remain 32m 11s) Loss: 0.0036(0.0036) Grad: 16209.3203  LR: 0.000009  \n",
      "Epoch: [4][100/2851] Elapsed 0m 39s (remain 17m 42s) Loss: 0.0003(0.0036) Grad: 782.4806  LR: 0.000009  \n",
      "Epoch: [4][200/2851] Elapsed 1m 16s (remain 16m 42s) Loss: 0.0000(0.0035) Grad: 201.4152  LR: 0.000009  \n",
      "Epoch: [4][300/2851] Elapsed 1m 53s (remain 16m 0s) Loss: 0.0016(0.0036) Grad: 11297.4932  LR: 0.000008  \n",
      "Epoch: [4][400/2851] Elapsed 2m 32s (remain 15m 28s) Loss: 0.0001(0.0037) Grad: 497.1736  LR: 0.000008  \n",
      "Epoch: [4][500/2851] Elapsed 3m 10s (remain 14m 53s) Loss: 0.0001(0.0037) Grad: 842.2521  LR: 0.000008  \n",
      "Epoch: [4][600/2851] Elapsed 3m 48s (remain 14m 15s) Loss: 0.0401(0.0042) Grad: 197911.2812  LR: 0.000008  \n",
      "Epoch: [4][700/2851] Elapsed 4m 25s (remain 13m 34s) Loss: 0.0004(0.0043) Grad: 2547.6953  LR: 0.000008  \n",
      "Epoch: [4][800/2851] Elapsed 5m 2s (remain 12m 53s) Loss: 0.0013(0.0045) Grad: 5419.5415  LR: 0.000008  \n",
      "Epoch: [4][900/2851] Elapsed 5m 39s (remain 12m 13s) Loss: 0.0001(0.0048) Grad: 476.3251  LR: 0.000007  \n",
      "Epoch: [4][1000/2851] Elapsed 6m 17s (remain 11m 38s) Loss: 0.0086(0.0050) Grad: 18417.7246  LR: 0.000007  \n",
      "Epoch: [4][1100/2851] Elapsed 6m 55s (remain 11m 0s) Loss: 0.0001(0.0049) Grad: 523.6271  LR: 0.000007  \n",
      "Epoch: [4][1200/2851] Elapsed 7m 32s (remain 10m 22s) Loss: 0.0009(0.0049) Grad: 2340.1960  LR: 0.000007  \n",
      "Epoch: [4][1300/2851] Elapsed 8m 10s (remain 9m 44s) Loss: 0.0000(0.0049) Grad: 40.8579  LR: 0.000007  \n",
      "Epoch: [4][1400/2851] Elapsed 8m 49s (remain 9m 8s) Loss: 0.0009(0.0050) Grad: 6484.6919  LR: 0.000007  \n",
      "Epoch: [4][1500/2851] Elapsed 9m 27s (remain 8m 30s) Loss: 0.0008(0.0049) Grad: 4660.2705  LR: 0.000007  \n",
      "Epoch: [4][1600/2851] Elapsed 10m 4s (remain 7m 52s) Loss: 0.0011(0.0050) Grad: 15809.1250  LR: 0.000006  \n",
      "Epoch: [4][1700/2851] Elapsed 10m 42s (remain 7m 14s) Loss: 0.0000(0.0050) Grad: 95.0575  LR: 0.000006  \n",
      "Epoch: [4][1800/2851] Elapsed 11m 22s (remain 6m 37s) Loss: 0.0000(0.0050) Grad: 31.0099  LR: 0.000006  \n",
      "Epoch: [4][1900/2851] Elapsed 12m 2s (remain 6m 0s) Loss: 0.0001(0.0049) Grad: 366.3446  LR: 0.000006  \n",
      "Epoch: [4][2000/2851] Elapsed 12m 40s (remain 5m 22s) Loss: 0.0111(0.0049) Grad: 11616.8945  LR: 0.000006  \n",
      "Epoch: [4][2100/2851] Elapsed 13m 18s (remain 4m 45s) Loss: 0.0265(0.0049) Grad: 123628.3906  LR: 0.000006  \n",
      "Epoch: [4][2200/2851] Elapsed 13m 58s (remain 4m 7s) Loss: 0.0194(0.0048) Grad: 24113.4922  LR: 0.000005  \n",
      "Epoch: [4][2300/2851] Elapsed 14m 36s (remain 3m 29s) Loss: 0.0005(0.0048) Grad: 2143.0137  LR: 0.000005  \n",
      "Epoch: [4][2400/2851] Elapsed 15m 13s (remain 2m 51s) Loss: 0.0091(0.0049) Grad: 260809.4375  LR: 0.000005  \n",
      "Epoch: [4][2500/2851] Elapsed 15m 50s (remain 2m 13s) Loss: 0.0001(0.0048) Grad: 973.8810  LR: 0.000005  \n",
      "Epoch: [4][2600/2851] Elapsed 16m 30s (remain 1m 35s) Loss: 0.0000(0.0049) Grad: 97.7183  LR: 0.000005  \n",
      "Epoch: [4][2700/2851] Elapsed 17m 10s (remain 0m 57s) Loss: 0.0001(0.0048) Grad: 3553.7039  LR: 0.000005  \n",
      "Epoch: [4][2800/2851] Elapsed 17m 47s (remain 0m 19s) Loss: 0.0012(0.0048) Grad: 8100.0259  LR: 0.000005  \n",
      "Epoch: [4][2850/2851] Elapsed 18m 6s (remain 0m 0s) Loss: 0.0085(0.0048) Grad: 19015.5059  LR: 0.000004  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 6m 2s) Loss: 0.0020(0.0020) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0122(0.0078) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 53s) Loss: 0.0000(0.0102) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0325(0.0101) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0000(0.0099) \n",
      "EVAL: [500/724] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0228(0.0117) \n",
      "EVAL: [600/724] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0071(0.0110) \n",
      "EVAL: [700/724] Elapsed 2m 29s (remain 0m 4s) Loss: 0.0000(0.0101) \n",
      "EVAL: [723/724] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0000(0.0099) \n",
      "Epoch 4 - avg_train_loss: 0.0048  avg_val_loss: 0.0099  time: 1245s\n",
      "Epoch 4 - Score: 0.8839\n",
      "Epoch: [5][0/2851] Elapsed 0m 0s (remain 28m 43s) Loss: 0.0000(0.0000) Grad: 1003.2921  LR: 0.000004  \n",
      "Epoch: [5][100/2851] Elapsed 0m 38s (remain 17m 24s) Loss: 0.0143(0.0043) Grad: 24835.2480  LR: 0.000004  \n",
      "Epoch: [5][200/2851] Elapsed 1m 16s (remain 16m 48s) Loss: 0.0121(0.0043) Grad: 10425.2686  LR: 0.000004  \n",
      "Epoch: [5][300/2851] Elapsed 1m 55s (remain 16m 17s) Loss: 0.0000(0.0041) Grad: 256.9514  LR: 0.000004  \n",
      "Epoch: [5][400/2851] Elapsed 2m 33s (remain 15m 35s) Loss: 0.0001(0.0044) Grad: 697.8987  LR: 0.000004  \n",
      "Epoch: [5][500/2851] Elapsed 3m 10s (remain 14m 53s) Loss: 0.0034(0.0041) Grad: 18578.6758  LR: 0.000004  \n",
      "Epoch: [5][600/2851] Elapsed 3m 47s (remain 14m 13s) Loss: 0.0002(0.0040) Grad: 4731.8511  LR: 0.000004  \n",
      "Epoch: [5][700/2851] Elapsed 4m 25s (remain 13m 35s) Loss: 0.0104(0.0039) Grad: 14036.6260  LR: 0.000003  \n",
      "Epoch: [5][800/2851] Elapsed 5m 5s (remain 13m 0s) Loss: 0.0003(0.0039) Grad: 1006.4142  LR: 0.000003  \n",
      "Epoch: [5][900/2851] Elapsed 5m 42s (remain 12m 21s) Loss: 0.0037(0.0040) Grad: 7726.8008  LR: 0.000003  \n",
      "Epoch: [5][1000/2851] Elapsed 6m 19s (remain 11m 41s) Loss: 0.0039(0.0041) Grad: 17054.9043  LR: 0.000003  \n",
      "Epoch: [5][1100/2851] Elapsed 6m 57s (remain 11m 3s) Loss: 0.0019(0.0039) Grad: 17821.8066  LR: 0.000003  \n",
      "Epoch: [5][1200/2851] Elapsed 7m 36s (remain 10m 27s) Loss: 0.0003(0.0041) Grad: 2885.3682  LR: 0.000003  \n",
      "Epoch: [5][1300/2851] Elapsed 8m 14s (remain 9m 48s) Loss: 0.0044(0.0041) Grad: 16102.0332  LR: 0.000002  \n",
      "Epoch: [5][1400/2851] Elapsed 8m 51s (remain 9m 10s) Loss: 0.0008(0.0041) Grad: 3988.2666  LR: 0.000002  \n",
      "Epoch: [5][1500/2851] Elapsed 9m 29s (remain 8m 32s) Loss: 0.0004(0.0040) Grad: 2861.5649  LR: 0.000002  \n",
      "Epoch: [5][1600/2851] Elapsed 10m 10s (remain 7m 56s) Loss: 0.0149(0.0039) Grad: 32232.7832  LR: 0.000002  \n",
      "Epoch: [5][1700/2851] Elapsed 10m 48s (remain 7m 18s) Loss: 0.0035(0.0039) Grad: 3300.0859  LR: 0.000002  \n",
      "Epoch: [5][1800/2851] Elapsed 11m 25s (remain 6m 39s) Loss: 0.0107(0.0038) Grad: 14933.9443  LR: 0.000002  \n",
      "Epoch: [5][1900/2851] Elapsed 12m 3s (remain 6m 1s) Loss: 0.0018(0.0038) Grad: 8122.3955  LR: 0.000001  \n",
      "Epoch: [5][2000/2851] Elapsed 12m 41s (remain 5m 23s) Loss: 0.0192(0.0038) Grad: 50730.6680  LR: 0.000001  \n",
      "Epoch: [5][2100/2851] Elapsed 13m 20s (remain 4m 45s) Loss: 0.0008(0.0038) Grad: 4112.8530  LR: 0.000001  \n",
      "Epoch: [5][2200/2851] Elapsed 13m 57s (remain 4m 7s) Loss: 0.0000(0.0039) Grad: 76.4727  LR: 0.000001  \n",
      "Epoch: [5][2300/2851] Elapsed 14m 34s (remain 3m 29s) Loss: 0.0000(0.0039) Grad: 209.6102  LR: 0.000001  \n",
      "Epoch: [5][2400/2851] Elapsed 15m 12s (remain 2m 50s) Loss: 0.0001(0.0038) Grad: 767.8765  LR: 0.000001  \n",
      "Epoch: [5][2500/2851] Elapsed 15m 50s (remain 2m 12s) Loss: 0.0002(0.0039) Grad: 1501.3818  LR: 0.000001  \n",
      "Epoch: [5][2600/2851] Elapsed 16m 29s (remain 1m 35s) Loss: 0.0288(0.0039) Grad: 85437.8047  LR: 0.000000  \n",
      "Epoch: [5][2700/2851] Elapsed 17m 7s (remain 0m 57s) Loss: 0.0000(0.0040) Grad: 41.6004  LR: 0.000000  \n",
      "Epoch: [5][2800/2851] Elapsed 17m 44s (remain 0m 19s) Loss: 0.0006(0.0040) Grad: 4661.3564  LR: 0.000000  \n",
      "Epoch: [5][2850/2851] Elapsed 18m 3s (remain 0m 0s) Loss: 0.0015(0.0040) Grad: 5595.9668  LR: 0.000000  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 58s) Loss: 0.0017(0.0017) \n",
      "EVAL: [100/724] Elapsed 0m 22s (remain 2m 16s) Loss: 0.0079(0.0077) \n",
      "EVAL: [200/724] Elapsed 0m 44s (remain 1m 55s) Loss: 0.0000(0.0104) \n",
      "EVAL: [300/724] Elapsed 1m 5s (remain 1m 31s) Loss: 0.0350(0.0102) \n",
      "EVAL: [400/724] Elapsed 1m 26s (remain 1m 9s) Loss: 0.0000(0.0100) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0229(0.0118) \n",
      "EVAL: [600/724] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0010(0.0111) \n",
      "EVAL: [700/724] Elapsed 2m 29s (remain 0m 4s) Loss: 0.0000(0.0101) \n",
      "EVAL: [723/724] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0000(0.0100) \n",
      "Epoch 5 - avg_train_loss: 0.0040  avg_val_loss: 0.0100  time: 1242s\n",
      "Epoch 5 - Score: 0.8861\n",
      "========== fold: 2 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2871] Elapsed 0m 0s (remain 29m 29s) Loss: 0.6513(0.6513) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2871] Elapsed 0m 38s (remain 17m 23s) Loss: 0.2030(0.3871) Grad: 23126.2773  LR: 0.000001  \n",
      "Epoch: [1][200/2871] Elapsed 1m 15s (remain 16m 43s) Loss: 0.1377(0.3074) Grad: 12328.2256  LR: 0.000003  \n",
      "Epoch: [1][300/2871] Elapsed 1m 54s (remain 16m 16s) Loss: 0.0221(0.2274) Grad: 1490.6829  LR: 0.000004  \n",
      "Epoch: [1][400/2871] Elapsed 2m 32s (remain 15m 38s) Loss: 0.0479(0.1807) Grad: 1538.2529  LR: 0.000006  \n",
      "Epoch: [1][500/2871] Elapsed 3m 9s (remain 14m 57s) Loss: 0.0338(0.1523) Grad: 698.2468  LR: 0.000007  \n",
      "Epoch: [1][600/2871] Elapsed 3m 47s (remain 14m 18s) Loss: 0.0280(0.1333) Grad: 782.3443  LR: 0.000008  \n",
      "Epoch: [1][700/2871] Elapsed 4m 25s (remain 13m 41s) Loss: 0.0501(0.1187) Grad: 3626.5220  LR: 0.000010  \n",
      "Epoch: [1][800/2871] Elapsed 5m 3s (remain 13m 5s) Loss: 0.0123(0.1067) Grad: 1632.1588  LR: 0.000011  \n",
      "Epoch: [1][900/2871] Elapsed 5m 43s (remain 12m 31s) Loss: 0.0246(0.0967) Grad: 3881.2644  LR: 0.000013  \n",
      "Epoch: [1][1000/2871] Elapsed 6m 21s (remain 11m 52s) Loss: 0.0089(0.0886) Grad: 2182.0916  LR: 0.000014  \n",
      "Epoch: [1][1100/2871] Elapsed 6m 58s (remain 11m 13s) Loss: 0.0092(0.0817) Grad: 2126.9487  LR: 0.000015  \n",
      "Epoch: [1][1200/2871] Elapsed 7m 36s (remain 10m 34s) Loss: 0.0299(0.0760) Grad: 6864.8164  LR: 0.000017  \n",
      "Epoch: [1][1300/2871] Elapsed 8m 14s (remain 9m 56s) Loss: 0.0281(0.0711) Grad: 5249.1929  LR: 0.000018  \n",
      "Epoch: [1][1400/2871] Elapsed 8m 52s (remain 9m 19s) Loss: 0.0265(0.0668) Grad: 4597.7969  LR: 0.000020  \n",
      "Epoch: [1][1500/2871] Elapsed 9m 30s (remain 8m 41s) Loss: 0.0711(0.0632) Grad: 5458.5908  LR: 0.000020  \n",
      "Epoch: [1][1600/2871] Elapsed 10m 9s (remain 8m 3s) Loss: 0.0242(0.0601) Grad: 9362.0557  LR: 0.000020  \n",
      "Epoch: [1][1700/2871] Elapsed 10m 49s (remain 7m 26s) Loss: 0.0037(0.0572) Grad: 1527.9652  LR: 0.000020  \n",
      "Epoch: [1][1800/2871] Elapsed 11m 27s (remain 6m 48s) Loss: 0.0038(0.0547) Grad: 1045.5166  LR: 0.000019  \n",
      "Epoch: [1][1900/2871] Elapsed 12m 4s (remain 6m 9s) Loss: 0.0473(0.0523) Grad: 9698.2061  LR: 0.000019  \n",
      "Epoch: [1][2000/2871] Elapsed 12m 42s (remain 5m 31s) Loss: 0.0012(0.0502) Grad: 564.5413  LR: 0.000019  \n",
      "Epoch: [1][2100/2871] Elapsed 13m 19s (remain 4m 53s) Loss: 0.0080(0.0481) Grad: 2173.0625  LR: 0.000019  \n",
      "Epoch: [1][2200/2871] Elapsed 13m 57s (remain 4m 15s) Loss: 0.0616(0.0464) Grad: 7060.8813  LR: 0.000019  \n",
      "Epoch: [1][2300/2871] Elapsed 14m 37s (remain 3m 37s) Loss: 0.0202(0.0448) Grad: 1802.8202  LR: 0.000019  \n",
      "Epoch: [1][2400/2871] Elapsed 15m 18s (remain 2m 59s) Loss: 0.0121(0.0433) Grad: 3284.1230  LR: 0.000019  \n",
      "Epoch: [1][2500/2871] Elapsed 15m 56s (remain 2m 21s) Loss: 0.0034(0.0419) Grad: 642.3655  LR: 0.000018  \n",
      "Epoch: [1][2600/2871] Elapsed 16m 33s (remain 1m 43s) Loss: 0.0079(0.0407) Grad: 541.9217  LR: 0.000018  \n",
      "Epoch: [1][2700/2871] Elapsed 17m 10s (remain 1m 4s) Loss: 0.0024(0.0394) Grad: 696.5689  LR: 0.000018  \n",
      "Epoch: [1][2800/2871] Elapsed 17m 48s (remain 0m 26s) Loss: 0.0093(0.0384) Grad: 1994.4513  LR: 0.000018  \n",
      "Epoch: [1][2870/2871] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0031(0.0376) Grad: 990.4059  LR: 0.000018  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 23s) Loss: 0.0023(0.0023) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0163(0.0118) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 48s) Loss: 0.0002(0.0100) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 26s) Loss: 0.0003(0.0093) \n",
      "EVAL: [400/704] Elapsed 1m 25s (remain 1m 4s) Loss: 0.0056(0.0101) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 43s) Loss: 0.0296(0.0113) \n",
      "EVAL: [600/704] Elapsed 2m 7s (remain 0m 21s) Loss: 0.0011(0.0115) \n",
      "EVAL: [700/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0013(0.0108) \n",
      "EVAL: [703/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0001(0.0108) \n",
      "Epoch 1 - avg_train_loss: 0.0376  avg_val_loss: 0.0108  time: 1249s\n",
      "Epoch 1 - Score: 0.8265\n",
      "Epoch 1 - Save Best Score: 0.8265 Model\n",
      "Epoch: [2][0/2871] Elapsed 0m 0s (remain 31m 1s) Loss: 0.0097(0.0097) Grad: 8021.0278  LR: 0.000018  \n",
      "Epoch: [2][100/2871] Elapsed 0m 39s (remain 17m 55s) Loss: 0.0191(0.0087) Grad: 10110.8730  LR: 0.000018  \n",
      "Epoch: [2][200/2871] Elapsed 1m 18s (remain 17m 27s) Loss: 0.0030(0.0083) Grad: 7742.4927  LR: 0.000017  \n",
      "Epoch: [2][300/2871] Elapsed 1m 57s (remain 16m 43s) Loss: 0.0007(0.0076) Grad: 3029.7156  LR: 0.000017  \n",
      "Epoch: [2][400/2871] Elapsed 2m 35s (remain 15m 58s) Loss: 0.0059(0.0078) Grad: 4880.1001  LR: 0.000017  \n",
      "Epoch: [2][500/2871] Elapsed 3m 13s (remain 15m 16s) Loss: 0.0067(0.0073) Grad: 8965.1748  LR: 0.000017  \n",
      "Epoch: [2][600/2871] Elapsed 3m 51s (remain 14m 34s) Loss: 0.0000(0.0072) Grad: 219.1180  LR: 0.000017  \n",
      "Epoch: [2][700/2871] Elapsed 4m 29s (remain 13m 52s) Loss: 0.0003(0.0075) Grad: 630.5926  LR: 0.000017  \n",
      "Epoch: [2][800/2871] Elapsed 5m 6s (remain 13m 13s) Loss: 0.0024(0.0073) Grad: 4776.8174  LR: 0.000017  \n",
      "Epoch: [2][900/2871] Elapsed 5m 45s (remain 12m 35s) Loss: 0.0001(0.0075) Grad: 253.8183  LR: 0.000016  \n",
      "Epoch: [2][1000/2871] Elapsed 6m 26s (remain 12m 2s) Loss: 0.0002(0.0074) Grad: 671.6237  LR: 0.000016  \n",
      "Epoch: [2][1100/2871] Elapsed 7m 5s (remain 11m 24s) Loss: 0.0635(0.0074) Grad: 62512.0078  LR: 0.000016  \n",
      "Epoch: [2][1200/2871] Elapsed 7m 43s (remain 10m 44s) Loss: 0.0041(0.0074) Grad: 11391.2363  LR: 0.000016  \n",
      "Epoch: [2][1300/2871] Elapsed 8m 21s (remain 10m 4s) Loss: 0.0094(0.0073) Grad: 8100.1636  LR: 0.000016  \n",
      "Epoch: [2][1400/2871] Elapsed 8m 59s (remain 9m 26s) Loss: 0.0024(0.0073) Grad: 6867.3384  LR: 0.000016  \n",
      "Epoch: [2][1500/2871] Elapsed 9m 38s (remain 8m 48s) Loss: 0.0073(0.0074) Grad: 6703.5825  LR: 0.000015  \n",
      "Epoch: [2][1600/2871] Elapsed 10m 16s (remain 8m 9s) Loss: 0.0032(0.0073) Grad: 12819.4443  LR: 0.000015  \n",
      "Epoch: [2][1700/2871] Elapsed 10m 54s (remain 7m 29s) Loss: 0.0033(0.0073) Grad: 9257.1514  LR: 0.000015  \n",
      "Epoch: [2][1800/2871] Elapsed 11m 31s (remain 6m 50s) Loss: 0.0003(0.0073) Grad: 750.2208  LR: 0.000015  \n",
      "Epoch: [2][1900/2871] Elapsed 12m 9s (remain 6m 12s) Loss: 0.0041(0.0073) Grad: 8180.9106  LR: 0.000015  \n",
      "Epoch: [2][2000/2871] Elapsed 12m 48s (remain 5m 34s) Loss: 0.0093(0.0072) Grad: 21503.5840  LR: 0.000015  \n",
      "Epoch: [2][2100/2871] Elapsed 13m 26s (remain 4m 55s) Loss: 0.0108(0.0072) Grad: 17927.2598  LR: 0.000015  \n",
      "Epoch: [2][2200/2871] Elapsed 14m 3s (remain 4m 16s) Loss: 0.0000(0.0071) Grad: 681.0261  LR: 0.000014  \n",
      "Epoch: [2][2300/2871] Elapsed 14m 41s (remain 3m 38s) Loss: 0.0033(0.0072) Grad: 9143.6367  LR: 0.000014  \n",
      "Epoch: [2][2400/2871] Elapsed 15m 21s (remain 3m 0s) Loss: 0.0178(0.0071) Grad: 78951.5938  LR: 0.000014  \n",
      "Epoch: [2][2500/2871] Elapsed 16m 0s (remain 2m 22s) Loss: 0.0165(0.0072) Grad: 35139.8906  LR: 0.000014  \n",
      "Epoch: [2][2600/2871] Elapsed 16m 38s (remain 1m 43s) Loss: 0.0001(0.0072) Grad: 378.6235  LR: 0.000014  \n",
      "Epoch: [2][2700/2871] Elapsed 17m 15s (remain 1m 5s) Loss: 0.0014(0.0071) Grad: 6637.2803  LR: 0.000014  \n",
      "Epoch: [2][2800/2871] Elapsed 17m 53s (remain 0m 26s) Loss: 0.0020(0.0071) Grad: 5034.7085  LR: 0.000013  \n",
      "Epoch: [2][2870/2871] Elapsed 18m 21s (remain 0m 0s) Loss: 0.0000(0.0071) Grad: 21.1445  LR: 0.000013  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 28s) Loss: 0.0007(0.0007) \n",
      "EVAL: [100/704] Elapsed 0m 22s (remain 2m 12s) Loss: 0.0096(0.0098) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 48s) Loss: 0.0000(0.0091) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 26s) Loss: 0.0001(0.0084) \n",
      "EVAL: [400/704] Elapsed 1m 25s (remain 1m 4s) Loss: 0.0039(0.0090) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 43s) Loss: 0.0118(0.0099) \n",
      "EVAL: [600/704] Elapsed 2m 7s (remain 0m 21s) Loss: 0.0001(0.0104) \n",
      "EVAL: [700/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0098) \n",
      "EVAL: [703/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0097) \n",
      "Epoch 2 - avg_train_loss: 0.0071  avg_val_loss: 0.0097  time: 1256s\n",
      "Epoch 2 - Score: 0.8584\n",
      "Epoch 2 - Save Best Score: 0.8584 Model\n",
      "Epoch: [3][0/2871] Elapsed 0m 0s (remain 33m 21s) Loss: 0.0065(0.0065) Grad: 11056.0732  LR: 0.000013  \n",
      "Epoch: [3][100/2871] Elapsed 0m 38s (remain 17m 42s) Loss: 0.0073(0.0072) Grad: 9748.2812  LR: 0.000013  \n",
      "Epoch: [3][200/2871] Elapsed 1m 16s (remain 16m 53s) Loss: 0.0033(0.0068) Grad: 5011.9346  LR: 0.000013  \n",
      "Epoch: [3][300/2871] Elapsed 1m 54s (remain 16m 17s) Loss: 0.0003(0.0062) Grad: 1244.7045  LR: 0.000013  \n",
      "Epoch: [3][400/2871] Elapsed 2m 33s (remain 15m 44s) Loss: 0.0000(0.0059) Grad: 52.3247  LR: 0.000013  \n",
      "Epoch: [3][500/2871] Elapsed 3m 12s (remain 15m 11s) Loss: 0.0506(0.0062) Grad: 41530.8438  LR: 0.000013  \n",
      "Epoch: [3][600/2871] Elapsed 3m 49s (remain 14m 28s) Loss: 0.0020(0.0060) Grad: 7420.1851  LR: 0.000012  \n",
      "Epoch: [3][700/2871] Elapsed 4m 27s (remain 13m 47s) Loss: 0.0005(0.0061) Grad: 1564.9429  LR: 0.000012  \n",
      "Epoch: [3][800/2871] Elapsed 5m 5s (remain 13m 9s) Loss: 0.0107(0.0059) Grad: 34005.0938  LR: 0.000012  \n",
      "Epoch: [3][900/2871] Elapsed 5m 44s (remain 12m 33s) Loss: 0.0132(0.0059) Grad: 66181.7969  LR: 0.000012  \n",
      "Epoch: [3][1000/2871] Elapsed 6m 26s (remain 12m 1s) Loss: 0.0001(0.0058) Grad: 469.2574  LR: 0.000012  \n",
      "Epoch: [3][1100/2871] Elapsed 7m 4s (remain 11m 22s) Loss: 0.0014(0.0060) Grad: 10925.1299  LR: 0.000012  \n",
      "Epoch: [3][1200/2871] Elapsed 7m 42s (remain 10m 43s) Loss: 0.0002(0.0061) Grad: 810.4351  LR: 0.000011  \n",
      "Epoch: [3][1300/2871] Elapsed 8m 20s (remain 10m 3s) Loss: 0.0383(0.0062) Grad: 24622.6836  LR: 0.000011  \n",
      "Epoch: [3][1400/2871] Elapsed 8m 57s (remain 9m 23s) Loss: 0.0017(0.0063) Grad: 15872.8242  LR: 0.000011  \n",
      "Epoch: [3][1500/2871] Elapsed 9m 35s (remain 8m 45s) Loss: 0.0039(0.0062) Grad: 6822.6665  LR: 0.000011  \n",
      "Epoch: [3][1600/2871] Elapsed 10m 13s (remain 8m 6s) Loss: 0.0098(0.0061) Grad: 16200.5693  LR: 0.000011  \n",
      "Epoch: [3][1700/2871] Elapsed 10m 51s (remain 7m 28s) Loss: 0.0001(0.0062) Grad: 925.3794  LR: 0.000011  \n",
      "Epoch: [3][1800/2871] Elapsed 11m 29s (remain 6m 49s) Loss: 0.0021(0.0061) Grad: 4518.9102  LR: 0.000011  \n",
      "Epoch: [3][1900/2871] Elapsed 12m 6s (remain 6m 10s) Loss: 0.0388(0.0061) Grad: 169039.9688  LR: 0.000010  \n",
      "Epoch: [3][2000/2871] Elapsed 12m 45s (remain 5m 33s) Loss: 0.0000(0.0061) Grad: 256.9197  LR: 0.000010  \n",
      "Epoch: [3][2100/2871] Elapsed 13m 23s (remain 4m 54s) Loss: 0.0012(0.0061) Grad: 4644.9707  LR: 0.000010  \n",
      "Epoch: [3][2200/2871] Elapsed 14m 1s (remain 4m 16s) Loss: 0.0046(0.0061) Grad: 9999.7236  LR: 0.000010  \n",
      "Epoch: [3][2300/2871] Elapsed 14m 39s (remain 3m 37s) Loss: 0.0024(0.0062) Grad: 9362.0234  LR: 0.000010  \n",
      "Epoch: [3][2400/2871] Elapsed 15m 17s (remain 2m 59s) Loss: 0.0078(0.0061) Grad: 44062.7070  LR: 0.000010  \n",
      "Epoch: [3][2500/2871] Elapsed 15m 54s (remain 2m 21s) Loss: 0.0002(0.0062) Grad: 1625.8593  LR: 0.000009  \n",
      "Epoch: [3][2600/2871] Elapsed 16m 32s (remain 1m 43s) Loss: 0.0007(0.0061) Grad: 6389.0225  LR: 0.000009  \n",
      "Epoch: [3][2700/2871] Elapsed 17m 10s (remain 1m 4s) Loss: 0.0033(0.0061) Grad: 6634.9609  LR: 0.000009  \n",
      "Epoch: [3][2800/2871] Elapsed 17m 48s (remain 0m 26s) Loss: 0.0001(0.0061) Grad: 877.1279  LR: 0.000009  \n",
      "Epoch: [3][2870/2871] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0064(0.0061) Grad: 13071.2627  LR: 0.000009  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 39s) Loss: 0.0016(0.0016) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0161(0.0095) \n",
      "EVAL: [200/704] Elapsed 0m 42s (remain 1m 47s) Loss: 0.0000(0.0084) \n",
      "EVAL: [300/704] Elapsed 1m 3s (remain 1m 25s) Loss: 0.0020(0.0078) \n",
      "EVAL: [400/704] Elapsed 1m 24s (remain 1m 4s) Loss: 0.0047(0.0085) \n",
      "EVAL: [500/704] Elapsed 1m 45s (remain 0m 42s) Loss: 0.0104(0.0093) \n",
      "EVAL: [600/704] Elapsed 2m 6s (remain 0m 21s) Loss: 0.0001(0.0093) \n",
      "EVAL: [700/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0087) \n",
      "EVAL: [703/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0087) \n",
      "Epoch 3 - avg_train_loss: 0.0061  avg_val_loss: 0.0087  time: 1248s\n",
      "Epoch 3 - Score: 0.8598\n",
      "Epoch 3 - Save Best Score: 0.8598 Model\n",
      "Epoch: [4][0/2871] Elapsed 0m 0s (remain 30m 44s) Loss: 0.0143(0.0143) Grad: 58667.1641  LR: 0.000009  \n",
      "Epoch: [4][100/2871] Elapsed 0m 38s (remain 17m 27s) Loss: 0.0000(0.0064) Grad: 109.7994  LR: 0.000009  \n",
      "Epoch: [4][200/2871] Elapsed 1m 15s (remain 16m 44s) Loss: 0.0023(0.0058) Grad: 7459.6826  LR: 0.000009  \n",
      "Epoch: [4][300/2871] Elapsed 1m 52s (remain 16m 4s) Loss: 0.0004(0.0051) Grad: 1715.5852  LR: 0.000008  \n",
      "Epoch: [4][400/2871] Elapsed 2m 29s (remain 15m 23s) Loss: 0.0004(0.0049) Grad: 2317.8054  LR: 0.000008  \n",
      "Epoch: [4][500/2871] Elapsed 3m 8s (remain 14m 50s) Loss: 0.0003(0.0049) Grad: 2364.6006  LR: 0.000008  \n",
      "Epoch: [4][600/2871] Elapsed 3m 46s (remain 14m 15s) Loss: 0.0007(0.0050) Grad: 2599.3616  LR: 0.000008  \n",
      "Epoch: [4][700/2871] Elapsed 4m 23s (remain 13m 36s) Loss: 0.0035(0.0053) Grad: 14722.7910  LR: 0.000008  \n",
      "Epoch: [4][800/2871] Elapsed 5m 1s (remain 12m 59s) Loss: 0.0033(0.0051) Grad: 7163.5210  LR: 0.000008  \n",
      "Epoch: [4][900/2871] Elapsed 5m 40s (remain 12m 24s) Loss: 0.0000(0.0052) Grad: 21.4362  LR: 0.000007  \n",
      "Epoch: [4][1000/2871] Elapsed 6m 17s (remain 11m 45s) Loss: 0.0021(0.0053) Grad: 5629.6094  LR: 0.000007  \n",
      "Epoch: [4][1100/2871] Elapsed 6m 54s (remain 11m 7s) Loss: 0.0000(0.0052) Grad: 139.4635  LR: 0.000007  \n",
      "Epoch: [4][1200/2871] Elapsed 7m 31s (remain 10m 28s) Loss: 0.0001(0.0052) Grad: 281.9829  LR: 0.000007  \n",
      "Epoch: [4][1300/2871] Elapsed 8m 8s (remain 9m 50s) Loss: 0.0001(0.0051) Grad: 415.6379  LR: 0.000007  \n",
      "Epoch: [4][1400/2871] Elapsed 8m 46s (remain 9m 12s) Loss: 0.0004(0.0051) Grad: 2088.5566  LR: 0.000007  \n",
      "Epoch: [4][1500/2871] Elapsed 9m 25s (remain 8m 36s) Loss: 0.0000(0.0052) Grad: 61.5414  LR: 0.000007  \n",
      "Epoch: [4][1600/2871] Elapsed 10m 3s (remain 7m 58s) Loss: 0.0072(0.0050) Grad: 19237.9160  LR: 0.000006  \n",
      "Epoch: [4][1700/2871] Elapsed 10m 40s (remain 7m 20s) Loss: 0.0002(0.0050) Grad: 1318.6035  LR: 0.000006  \n",
      "Epoch: [4][1800/2871] Elapsed 11m 18s (remain 6m 43s) Loss: 0.0001(0.0050) Grad: 170.3152  LR: 0.000006  \n",
      "Epoch: [4][1900/2871] Elapsed 11m 57s (remain 6m 5s) Loss: 0.0024(0.0049) Grad: 8326.5146  LR: 0.000006  \n",
      "Epoch: [4][2000/2871] Elapsed 12m 34s (remain 5m 28s) Loss: 0.0000(0.0049) Grad: 180.1148  LR: 0.000006  \n",
      "Epoch: [4][2100/2871] Elapsed 13m 11s (remain 4m 50s) Loss: 0.0034(0.0049) Grad: 20329.2012  LR: 0.000006  \n",
      "Epoch: [4][2200/2871] Elapsed 13m 48s (remain 4m 12s) Loss: 0.0006(0.0048) Grad: 1728.8522  LR: 0.000005  \n",
      "Epoch: [4][2300/2871] Elapsed 14m 26s (remain 3m 34s) Loss: 0.0037(0.0048) Grad: 11646.9707  LR: 0.000005  \n",
      "Epoch: [4][2400/2871] Elapsed 15m 3s (remain 2m 56s) Loss: 0.0016(0.0049) Grad: 5593.1104  LR: 0.000005  \n",
      "Epoch: [4][2500/2871] Elapsed 15m 41s (remain 2m 19s) Loss: 0.0051(0.0049) Grad: 19407.0977  LR: 0.000005  \n",
      "Epoch: [4][2600/2871] Elapsed 16m 19s (remain 1m 41s) Loss: 0.0007(0.0049) Grad: 3306.3650  LR: 0.000005  \n",
      "Epoch: [4][2700/2871] Elapsed 16m 56s (remain 1m 3s) Loss: 0.0000(0.0049) Grad: 458.6244  LR: 0.000005  \n",
      "Epoch: [4][2800/2871] Elapsed 17m 33s (remain 0m 26s) Loss: 0.0292(0.0048) Grad: 67186.5312  LR: 0.000005  \n",
      "Epoch: [4][2870/2871] Elapsed 18m 0s (remain 0m 0s) Loss: 0.0005(0.0048) Grad: 4636.7520  LR: 0.000004  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 6m 0s) Loss: 0.0023(0.0023) \n",
      "EVAL: [100/704] Elapsed 0m 22s (remain 2m 11s) Loss: 0.0127(0.0092) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 49s) Loss: 0.0000(0.0084) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 26s) Loss: 0.0002(0.0076) \n",
      "EVAL: [400/704] Elapsed 1m 25s (remain 1m 4s) Loss: 0.0076(0.0086) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 43s) Loss: 0.0122(0.0095) \n",
      "EVAL: [600/704] Elapsed 2m 8s (remain 0m 21s) Loss: 0.0000(0.0097) \n",
      "EVAL: [700/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0091) \n",
      "EVAL: [703/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0091) \n",
      "Epoch 4 - avg_train_loss: 0.0048  avg_val_loss: 0.0091  time: 1235s\n",
      "Epoch 4 - Score: 0.8670\n",
      "Epoch 4 - Save Best Score: 0.8670 Model\n",
      "Epoch: [5][0/2871] Elapsed 0m 0s (remain 33m 30s) Loss: 0.0001(0.0001) Grad: 1064.9098  LR: 0.000004  \n",
      "Epoch: [5][100/2871] Elapsed 0m 38s (remain 17m 33s) Loss: 0.0000(0.0030) Grad: 120.8911  LR: 0.000004  \n",
      "Epoch: [5][200/2871] Elapsed 1m 16s (remain 16m 50s) Loss: 0.0000(0.0032) Grad: 237.3100  LR: 0.000004  \n",
      "Epoch: [5][300/2871] Elapsed 1m 54s (remain 16m 16s) Loss: 0.0055(0.0031) Grad: 39486.0195  LR: 0.000004  \n",
      "Epoch: [5][400/2871] Elapsed 2m 32s (remain 15m 40s) Loss: 0.0035(0.0036) Grad: 8705.4609  LR: 0.000004  \n",
      "Epoch: [5][500/2871] Elapsed 3m 10s (remain 14m 58s) Loss: 0.0000(0.0036) Grad: 53.9534  LR: 0.000004  \n",
      "Epoch: [5][600/2871] Elapsed 3m 47s (remain 14m 19s) Loss: 0.0008(0.0036) Grad: 13447.5566  LR: 0.000004  \n",
      "Epoch: [5][700/2871] Elapsed 4m 25s (remain 13m 41s) Loss: 0.0000(0.0037) Grad: 102.4473  LR: 0.000003  \n",
      "Epoch: [5][800/2871] Elapsed 5m 2s (remain 13m 2s) Loss: 0.0002(0.0039) Grad: 2452.0652  LR: 0.000003  \n",
      "Epoch: [5][900/2871] Elapsed 5m 40s (remain 12m 24s) Loss: 0.0024(0.0040) Grad: 19949.9688  LR: 0.000003  \n",
      "Epoch: [5][1000/2871] Elapsed 6m 20s (remain 11m 49s) Loss: 0.0100(0.0042) Grad: 23465.7441  LR: 0.000003  \n",
      "Epoch: [5][1100/2871] Elapsed 6m 57s (remain 11m 10s) Loss: 0.0000(0.0043) Grad: 28.1780  LR: 0.000003  \n",
      "Epoch: [5][1200/2871] Elapsed 7m 34s (remain 10m 31s) Loss: 0.0007(0.0043) Grad: 2515.5601  LR: 0.000003  \n",
      "Epoch: [5][1300/2871] Elapsed 8m 11s (remain 9m 53s) Loss: 0.0001(0.0043) Grad: 1264.7234  LR: 0.000002  \n",
      "Epoch: [5][1400/2871] Elapsed 8m 49s (remain 9m 15s) Loss: 0.0000(0.0044) Grad: 25.2980  LR: 0.000002  \n",
      "Epoch: [5][1500/2871] Elapsed 9m 26s (remain 8m 37s) Loss: 0.0001(0.0044) Grad: 179.7188  LR: 0.000002  \n",
      "Epoch: [5][1600/2871] Elapsed 10m 3s (remain 7m 58s) Loss: 0.0000(0.0043) Grad: 40.5270  LR: 0.000002  \n",
      "Epoch: [5][1700/2871] Elapsed 10m 41s (remain 7m 21s) Loss: 0.0003(0.0043) Grad: 1072.6403  LR: 0.000002  \n",
      "Epoch: [5][1800/2871] Elapsed 11m 19s (remain 6m 43s) Loss: 0.0009(0.0042) Grad: 4853.8867  LR: 0.000002  \n",
      "Epoch: [5][1900/2871] Elapsed 11m 57s (remain 6m 6s) Loss: 0.0001(0.0042) Grad: 414.5961  LR: 0.000002  \n",
      "Epoch: [5][2000/2871] Elapsed 12m 35s (remain 5m 28s) Loss: 0.0062(0.0043) Grad: 33117.9766  LR: 0.000001  \n",
      "Epoch: [5][2100/2871] Elapsed 13m 13s (remain 4m 50s) Loss: 0.0022(0.0043) Grad: 9578.6299  LR: 0.000001  \n",
      "Epoch: [5][2200/2871] Elapsed 13m 50s (remain 4m 12s) Loss: 0.0064(0.0043) Grad: 7263.1812  LR: 0.000001  \n",
      "Epoch: [5][2300/2871] Elapsed 14m 28s (remain 3m 35s) Loss: 0.0000(0.0043) Grad: 158.3151  LR: 0.000001  \n",
      "Epoch: [5][2400/2871] Elapsed 15m 6s (remain 2m 57s) Loss: 0.0000(0.0042) Grad: 134.2092  LR: 0.000001  \n",
      "Epoch: [5][2500/2871] Elapsed 15m 44s (remain 2m 19s) Loss: 0.0002(0.0042) Grad: 633.7145  LR: 0.000001  \n",
      "Epoch: [5][2600/2871] Elapsed 16m 21s (remain 1m 41s) Loss: 0.0000(0.0042) Grad: 29.1033  LR: 0.000000  \n",
      "Epoch: [5][2700/2871] Elapsed 16m 59s (remain 1m 4s) Loss: 0.0000(0.0042) Grad: 25.0484  LR: 0.000000  \n",
      "Epoch: [5][2800/2871] Elapsed 17m 39s (remain 0m 26s) Loss: 0.0002(0.0042) Grad: 1569.7369  LR: 0.000000  \n",
      "Epoch: [5][2870/2871] Elapsed 18m 6s (remain 0m 0s) Loss: 0.0073(0.0041) Grad: 24387.1094  LR: 0.000000  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 55s) Loss: 0.0016(0.0016) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0140(0.0100) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 49s) Loss: 0.0000(0.0089) \n",
      "EVAL: [300/704] Elapsed 1m 5s (remain 1m 27s) Loss: 0.0003(0.0082) \n",
      "EVAL: [400/704] Elapsed 1m 26s (remain 1m 5s) Loss: 0.0068(0.0094) \n",
      "EVAL: [500/704] Elapsed 1m 47s (remain 0m 43s) Loss: 0.0117(0.0104) \n",
      "EVAL: [600/704] Elapsed 2m 8s (remain 0m 22s) Loss: 0.0000(0.0105) \n",
      "EVAL: [700/704] Elapsed 2m 30s (remain 0m 0s) Loss: 0.0000(0.0098) \n",
      "EVAL: [703/704] Elapsed 2m 30s (remain 0m 0s) Loss: 0.0000(0.0098) \n",
      "Epoch 5 - avg_train_loss: 0.0041  avg_val_loss: 0.0098  time: 1242s\n",
      "Epoch 5 - Score: 0.8723\n",
      "Epoch 5 - Save Best Score: 0.8723 Model\n",
      "========== fold: 3 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2877] Elapsed 0m 0s (remain 31m 6s) Loss: 0.6141(0.6141) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2877] Elapsed 0m 39s (remain 18m 9s) Loss: 0.2818(0.5799) Grad: 15362.3105  LR: 0.000001  \n",
      "Epoch: [1][200/2877] Elapsed 1m 17s (remain 17m 8s) Loss: 0.1454(0.4407) Grad: 9251.1807  LR: 0.000003  \n",
      "Epoch: [1][300/2877] Elapsed 1m 54s (remain 16m 21s) Loss: 0.0661(0.3178) Grad: 1115.5762  LR: 0.000004  \n",
      "Epoch: [1][400/2877] Elapsed 2m 33s (remain 15m 47s) Loss: 0.0416(0.2484) Grad: 476.9301  LR: 0.000006  \n",
      "Epoch: [1][500/2877] Elapsed 3m 10s (remain 15m 1s) Loss: 0.0402(0.2073) Grad: 538.1306  LR: 0.000007  \n",
      "Epoch: [1][600/2877] Elapsed 3m 46s (remain 14m 19s) Loss: 0.0416(0.1788) Grad: 592.9173  LR: 0.000008  \n",
      "Epoch: [1][700/2877] Elapsed 4m 24s (remain 13m 39s) Loss: 0.0391(0.1582) Grad: 629.2626  LR: 0.000010  \n",
      "Epoch: [1][800/2877] Elapsed 5m 1s (remain 13m 0s) Loss: 0.0167(0.1418) Grad: 1366.8319  LR: 0.000011  \n",
      "Epoch: [1][900/2877] Elapsed 5m 38s (remain 12m 21s) Loss: 0.0037(0.1281) Grad: 430.6208  LR: 0.000013  \n",
      "Epoch: [1][1000/2877] Elapsed 6m 16s (remain 11m 46s) Loss: 0.0101(0.1173) Grad: 1948.1665  LR: 0.000014  \n",
      "Epoch: [1][1100/2877] Elapsed 6m 54s (remain 11m 8s) Loss: 0.0398(0.1079) Grad: 3097.5601  LR: 0.000015  \n",
      "Epoch: [1][1200/2877] Elapsed 7m 32s (remain 10m 31s) Loss: 0.0107(0.1001) Grad: 1210.6949  LR: 0.000017  \n",
      "Epoch: [1][1300/2877] Elapsed 8m 11s (remain 9m 55s) Loss: 0.0038(0.0933) Grad: 424.2867  LR: 0.000018  \n",
      "Epoch: [1][1400/2877] Elapsed 8m 49s (remain 9m 17s) Loss: 0.0030(0.0874) Grad: 517.5192  LR: 0.000019  \n",
      "Epoch: [1][1500/2877] Elapsed 9m 27s (remain 8m 39s) Loss: 0.0114(0.0824) Grad: 621.8334  LR: 0.000020  \n",
      "Epoch: [1][1600/2877] Elapsed 10m 5s (remain 8m 2s) Loss: 0.0277(0.0781) Grad: 2781.6528  LR: 0.000020  \n",
      "Epoch: [1][1700/2877] Elapsed 10m 43s (remain 7m 25s) Loss: 0.0097(0.0740) Grad: 877.3022  LR: 0.000020  \n",
      "Epoch: [1][1800/2877] Elapsed 11m 22s (remain 6m 47s) Loss: 0.0030(0.0705) Grad: 348.1079  LR: 0.000019  \n",
      "Epoch: [1][1900/2877] Elapsed 11m 59s (remain 6m 9s) Loss: 0.0089(0.0674) Grad: 586.0724  LR: 0.000019  \n",
      "Epoch: [1][2000/2877] Elapsed 12m 36s (remain 5m 31s) Loss: 0.0088(0.0644) Grad: 676.5029  LR: 0.000019  \n",
      "Epoch: [1][2100/2877] Elapsed 13m 13s (remain 4m 53s) Loss: 0.0020(0.0618) Grad: 210.5404  LR: 0.000019  \n",
      "Epoch: [1][2200/2877] Elapsed 13m 51s (remain 4m 15s) Loss: 0.0032(0.0593) Grad: 334.6350  LR: 0.000019  \n",
      "Epoch: [1][2300/2877] Elapsed 14m 30s (remain 3m 37s) Loss: 0.0112(0.0571) Grad: 397.8620  LR: 0.000019  \n",
      "Epoch: [1][2400/2877] Elapsed 15m 6s (remain 2m 59s) Loss: 0.0017(0.0551) Grad: 223.6306  LR: 0.000019  \n",
      "Epoch: [1][2500/2877] Elapsed 15m 43s (remain 2m 21s) Loss: 0.0074(0.0533) Grad: 1127.9849  LR: 0.000018  \n",
      "Epoch: [1][2600/2877] Elapsed 16m 20s (remain 1m 44s) Loss: 0.0030(0.0515) Grad: 1241.2869  LR: 0.000018  \n",
      "Epoch: [1][2700/2877] Elapsed 16m 58s (remain 1m 6s) Loss: 0.0011(0.0499) Grad: 123.3700  LR: 0.000018  \n",
      "Epoch: [1][2800/2877] Elapsed 17m 35s (remain 0m 28s) Loss: 0.0004(0.0483) Grad: 58.8347  LR: 0.000018  \n",
      "Epoch: [1][2876/2877] Elapsed 18m 3s (remain 0m 0s) Loss: 0.0241(0.0473) Grad: 2368.1021  LR: 0.000018  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 29s) Loss: 0.0019(0.0019) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0019(0.0052) \n",
      "EVAL: [200/698] Elapsed 0m 43s (remain 1m 46s) Loss: 0.0098(0.0071) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 24s) Loss: 0.0023(0.0068) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0185(0.0075) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0086(0.0075) \n",
      "EVAL: [600/698] Elapsed 2m 8s (remain 0m 20s) Loss: 0.0040(0.0072) \n",
      "EVAL: [697/698] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0001(0.0071) \n",
      "Epoch 1 - avg_train_loss: 0.0473  avg_val_loss: 0.0071  time: 1237s\n",
      "Epoch 1 - Score: 0.8499\n",
      "Epoch 1 - Save Best Score: 0.8499 Model\n",
      "Epoch: [2][0/2877] Elapsed 0m 0s (remain 29m 58s) Loss: 0.0039(0.0039) Grad: 4296.5078  LR: 0.000018  \n",
      "Epoch: [2][100/2877] Elapsed 0m 40s (remain 18m 27s) Loss: 0.0017(0.0075) Grad: 6040.1436  LR: 0.000018  \n",
      "Epoch: [2][200/2877] Elapsed 1m 22s (remain 18m 11s) Loss: 0.0030(0.0066) Grad: 4949.8062  LR: 0.000017  \n",
      "Epoch: [2][300/2877] Elapsed 2m 3s (remain 17m 34s) Loss: 0.0395(0.0063) Grad: 28918.1816  LR: 0.000017  \n",
      "Epoch: [2][400/2877] Elapsed 2m 40s (remain 16m 34s) Loss: 0.0032(0.0061) Grad: 8076.5718  LR: 0.000017  \n",
      "Epoch: [2][500/2877] Elapsed 3m 18s (remain 15m 40s) Loss: 0.0025(0.0060) Grad: 4671.4067  LR: 0.000017  \n",
      "Epoch: [2][600/2877] Elapsed 3m 55s (remain 14m 52s) Loss: 0.0036(0.0062) Grad: 5868.4072  LR: 0.000017  \n",
      "Epoch: [2][700/2877] Elapsed 4m 34s (remain 14m 10s) Loss: 0.0076(0.0063) Grad: 12639.9971  LR: 0.000017  \n",
      "Epoch: [2][800/2877] Elapsed 5m 13s (remain 13m 32s) Loss: 0.0082(0.0064) Grad: 13299.3779  LR: 0.000017  \n",
      "Epoch: [2][900/2877] Elapsed 5m 50s (remain 12m 49s) Loss: 0.0042(0.0064) Grad: 15537.4961  LR: 0.000016  \n",
      "Epoch: [2][1000/2877] Elapsed 6m 27s (remain 12m 7s) Loss: 0.0061(0.0065) Grad: 13746.8584  LR: 0.000016  \n",
      "Epoch: [2][1100/2877] Elapsed 7m 5s (remain 11m 26s) Loss: 0.0009(0.0065) Grad: 3638.5479  LR: 0.000016  \n",
      "Epoch: [2][1200/2877] Elapsed 7m 42s (remain 10m 45s) Loss: 0.0000(0.0065) Grad: 142.7033  LR: 0.000016  \n",
      "Epoch: [2][1300/2877] Elapsed 8m 20s (remain 10m 6s) Loss: 0.0053(0.0065) Grad: 11429.9170  LR: 0.000016  \n",
      "Epoch: [2][1400/2877] Elapsed 8m 58s (remain 9m 27s) Loss: 0.0371(0.0065) Grad: 61411.3281  LR: 0.000016  \n",
      "Epoch: [2][1500/2877] Elapsed 9m 39s (remain 8m 50s) Loss: 0.0010(0.0065) Grad: 3942.3069  LR: 0.000015  \n",
      "Epoch: [2][1600/2877] Elapsed 10m 16s (remain 8m 11s) Loss: 0.0009(0.0065) Grad: 3527.1763  LR: 0.000015  \n",
      "Epoch: [2][1700/2877] Elapsed 10m 54s (remain 7m 32s) Loss: 0.0003(0.0065) Grad: 662.2171  LR: 0.000015  \n",
      "Epoch: [2][1800/2877] Elapsed 11m 32s (remain 6m 53s) Loss: 0.0186(0.0066) Grad: 27000.0156  LR: 0.000015  \n",
      "Epoch: [2][1900/2877] Elapsed 12m 10s (remain 6m 14s) Loss: 0.0060(0.0066) Grad: 11069.7676  LR: 0.000015  \n",
      "Epoch: [2][2000/2877] Elapsed 12m 49s (remain 5m 36s) Loss: 0.0290(0.0067) Grad: 17510.6172  LR: 0.000015  \n",
      "Epoch: [2][2100/2877] Elapsed 13m 27s (remain 4m 58s) Loss: 0.0027(0.0067) Grad: 5679.0659  LR: 0.000015  \n",
      "Epoch: [2][2200/2877] Elapsed 14m 4s (remain 4m 19s) Loss: 0.0028(0.0067) Grad: 3389.5149  LR: 0.000014  \n",
      "Epoch: [2][2300/2877] Elapsed 14m 42s (remain 3m 40s) Loss: 0.0149(0.0067) Grad: 28924.5293  LR: 0.000014  \n",
      "Epoch: [2][2400/2877] Elapsed 15m 20s (remain 3m 2s) Loss: 0.0001(0.0067) Grad: 233.0788  LR: 0.000014  \n",
      "Epoch: [2][2500/2877] Elapsed 15m 58s (remain 2m 24s) Loss: 0.0001(0.0067) Grad: 142.5685  LR: 0.000014  \n",
      "Epoch: [2][2600/2877] Elapsed 16m 38s (remain 1m 45s) Loss: 0.0013(0.0067) Grad: 3938.2246  LR: 0.000014  \n",
      "Epoch: [2][2700/2877] Elapsed 17m 16s (remain 1m 7s) Loss: 0.0001(0.0066) Grad: 364.5213  LR: 0.000014  \n",
      "Epoch: [2][2800/2877] Elapsed 17m 54s (remain 0m 29s) Loss: 0.0075(0.0067) Grad: 11398.7363  LR: 0.000013  \n",
      "Epoch: [2][2876/2877] Elapsed 18m 22s (remain 0m 0s) Loss: 0.0002(0.0067) Grad: 405.8108  LR: 0.000013  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 30s) Loss: 0.0009(0.0009) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0005(0.0046) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 45s) Loss: 0.0213(0.0070) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 24s) Loss: 0.0029(0.0072) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0277(0.0076) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0048(0.0074) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0064(0.0071) \n",
      "EVAL: [697/698] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0000(0.0069) \n",
      "Epoch 2 - avg_train_loss: 0.0067  avg_val_loss: 0.0069  time: 1255s\n",
      "Epoch 2 - Score: 0.8818\n",
      "Epoch 2 - Save Best Score: 0.8818 Model\n",
      "Epoch: [3][0/2877] Elapsed 0m 0s (remain 32m 59s) Loss: 0.0003(0.0003) Grad: 2088.8440  LR: 0.000013  \n",
      "Epoch: [3][100/2877] Elapsed 0m 39s (remain 17m 54s) Loss: 0.0094(0.0043) Grad: 14745.9355  LR: 0.000013  \n",
      "Epoch: [3][200/2877] Elapsed 1m 16s (remain 16m 59s) Loss: 0.0051(0.0055) Grad: 15213.2949  LR: 0.000013  \n",
      "Epoch: [3][300/2877] Elapsed 1m 54s (remain 16m 16s) Loss: 0.0039(0.0052) Grad: 12571.7490  LR: 0.000013  \n",
      "Epoch: [3][400/2877] Elapsed 2m 31s (remain 15m 35s) Loss: 0.0063(0.0050) Grad: 13653.1221  LR: 0.000013  \n",
      "Epoch: [3][500/2877] Elapsed 3m 8s (remain 14m 55s) Loss: 0.0001(0.0051) Grad: 1216.9485  LR: 0.000013  \n",
      "Epoch: [3][600/2877] Elapsed 3m 47s (remain 14m 19s) Loss: 0.0000(0.0049) Grad: 52.2394  LR: 0.000012  \n",
      "Epoch: [3][700/2877] Elapsed 4m 26s (remain 13m 48s) Loss: 0.0008(0.0051) Grad: 5199.2378  LR: 0.000012  \n",
      "Epoch: [3][800/2877] Elapsed 5m 4s (remain 13m 9s) Loss: 0.0047(0.0053) Grad: 11506.9629  LR: 0.000012  \n",
      "Epoch: [3][900/2877] Elapsed 5m 43s (remain 12m 32s) Loss: 0.0027(0.0059) Grad: 3837.1675  LR: 0.000012  \n",
      "Epoch: [3][1000/2877] Elapsed 6m 22s (remain 11m 57s) Loss: 0.0065(0.0059) Grad: 13777.2217  LR: 0.000012  \n",
      "Epoch: [3][1100/2877] Elapsed 7m 0s (remain 11m 18s) Loss: 0.0163(0.0059) Grad: 10029.8398  LR: 0.000012  \n",
      "Epoch: [3][1200/2877] Elapsed 7m 38s (remain 10m 40s) Loss: 0.0006(0.0058) Grad: 5192.6997  LR: 0.000011  \n",
      "Epoch: [3][1300/2877] Elapsed 8m 19s (remain 10m 4s) Loss: 0.0010(0.0058) Grad: 3820.2166  LR: 0.000011  \n",
      "Epoch: [3][1400/2877] Elapsed 8m 56s (remain 9m 25s) Loss: 0.0001(0.0058) Grad: 135.9784  LR: 0.000011  \n",
      "Epoch: [3][1500/2877] Elapsed 9m 34s (remain 8m 46s) Loss: 0.0000(0.0058) Grad: 54.5468  LR: 0.000011  \n",
      "Epoch: [3][1600/2877] Elapsed 10m 11s (remain 8m 7s) Loss: 0.0011(0.0058) Grad: 4150.3687  LR: 0.000011  \n",
      "Epoch: [3][1700/2877] Elapsed 10m 48s (remain 7m 28s) Loss: 0.0100(0.0058) Grad: 41316.1523  LR: 0.000011  \n",
      "Epoch: [3][1800/2877] Elapsed 11m 26s (remain 6m 50s) Loss: 0.0039(0.0058) Grad: 7913.5825  LR: 0.000011  \n",
      "Epoch: [3][1900/2877] Elapsed 12m 5s (remain 6m 12s) Loss: 0.0085(0.0057) Grad: 18322.7930  LR: 0.000010  \n",
      "Epoch: [3][2000/2877] Elapsed 12m 42s (remain 5m 33s) Loss: 0.0133(0.0057) Grad: 10525.1943  LR: 0.000010  \n",
      "Epoch: [3][2100/2877] Elapsed 13m 19s (remain 4m 55s) Loss: 0.0000(0.0056) Grad: 13.0061  LR: 0.000010  \n",
      "Epoch: [3][2200/2877] Elapsed 13m 57s (remain 4m 17s) Loss: 0.0024(0.0056) Grad: 6486.7021  LR: 0.000010  \n",
      "Epoch: [3][2300/2877] Elapsed 14m 34s (remain 3m 38s) Loss: 0.0222(0.0057) Grad: 65441.8633  LR: 0.000010  \n",
      "Epoch: [3][2400/2877] Elapsed 15m 12s (remain 3m 0s) Loss: 0.0006(0.0056) Grad: 2016.6775  LR: 0.000010  \n",
      "Epoch: [3][2500/2877] Elapsed 15m 51s (remain 2m 22s) Loss: 0.0013(0.0056) Grad: 8672.1934  LR: 0.000009  \n",
      "Epoch: [3][2600/2877] Elapsed 16m 28s (remain 1m 44s) Loss: 0.0001(0.0055) Grad: 147.5650  LR: 0.000009  \n",
      "Epoch: [3][2700/2877] Elapsed 17m 6s (remain 1m 6s) Loss: 0.0005(0.0055) Grad: 4864.1567  LR: 0.000009  \n",
      "Epoch: [3][2800/2877] Elapsed 17m 45s (remain 0m 28s) Loss: 0.0045(0.0055) Grad: 5688.9224  LR: 0.000009  \n",
      "Epoch: [3][2876/2877] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0038(0.0055) Grad: 17182.1348  LR: 0.000009  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 24s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 8s) Loss: 0.0013(0.0063) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 45s) Loss: 0.0325(0.0089) \n",
      "EVAL: [300/698] Elapsed 1m 3s (remain 1m 24s) Loss: 0.0018(0.0090) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0228(0.0092) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0071(0.0090) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0088(0.0084) \n",
      "EVAL: [697/698] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0000(0.0082) \n",
      "Epoch 3 - avg_train_loss: 0.0055  avg_val_loss: 0.0082  time: 1247s\n",
      "Epoch 3 - Score: 0.8864\n",
      "Epoch 3 - Save Best Score: 0.8864 Model\n",
      "Epoch: [4][0/2877] Elapsed 0m 0s (remain 32m 39s) Loss: 0.0003(0.0003) Grad: 1929.1326  LR: 0.000009  \n",
      "Epoch: [4][100/2877] Elapsed 0m 40s (remain 18m 20s) Loss: 0.0000(0.0034) Grad: 92.1848  LR: 0.000009  \n",
      "Epoch: [4][200/2877] Elapsed 1m 17s (remain 17m 13s) Loss: 0.0000(0.0035) Grad: 51.6512  LR: 0.000009  \n",
      "Epoch: [4][300/2877] Elapsed 1m 54s (remain 16m 20s) Loss: 0.0042(0.0034) Grad: 28810.8828  LR: 0.000008  \n",
      "Epoch: [4][400/2877] Elapsed 2m 31s (remain 15m 37s) Loss: 0.0053(0.0041) Grad: 11570.3506  LR: 0.000008  \n",
      "Epoch: [4][500/2877] Elapsed 3m 10s (remain 15m 2s) Loss: 0.0200(0.0044) Grad: 20675.5488  LR: 0.000008  \n",
      "Epoch: [4][600/2877] Elapsed 3m 48s (remain 14m 24s) Loss: 0.0002(0.0044) Grad: 884.8842  LR: 0.000008  \n",
      "Epoch: [4][700/2877] Elapsed 4m 26s (remain 13m 46s) Loss: 0.0008(0.0044) Grad: 5593.3442  LR: 0.000008  \n",
      "Epoch: [4][800/2877] Elapsed 5m 4s (remain 13m 9s) Loss: 0.0019(0.0045) Grad: 7782.3013  LR: 0.000008  \n",
      "Epoch: [4][900/2877] Elapsed 5m 43s (remain 12m 33s) Loss: 0.0102(0.0046) Grad: 9842.2812  LR: 0.000007  \n",
      "Epoch: [4][1000/2877] Elapsed 6m 21s (remain 11m 55s) Loss: 0.0000(0.0047) Grad: 54.4205  LR: 0.000007  \n",
      "Epoch: [4][1100/2877] Elapsed 6m 59s (remain 11m 15s) Loss: 0.0026(0.0047) Grad: 10152.3936  LR: 0.000007  \n",
      "Epoch: [4][1200/2877] Elapsed 7m 36s (remain 10m 36s) Loss: 0.0005(0.0048) Grad: 1670.0498  LR: 0.000007  \n",
      "Epoch: [4][1300/2877] Elapsed 8m 14s (remain 9m 58s) Loss: 0.0014(0.0047) Grad: 11197.5664  LR: 0.000007  \n",
      "Epoch: [4][1400/2877] Elapsed 8m 51s (remain 9m 20s) Loss: 0.0000(0.0048) Grad: 103.8322  LR: 0.000007  \n",
      "Epoch: [4][1500/2877] Elapsed 9m 29s (remain 8m 42s) Loss: 0.0001(0.0048) Grad: 179.7701  LR: 0.000007  \n",
      "Epoch: [4][1600/2877] Elapsed 10m 7s (remain 8m 4s) Loss: 0.0001(0.0048) Grad: 249.6505  LR: 0.000006  \n",
      "Epoch: [4][1700/2877] Elapsed 10m 45s (remain 7m 26s) Loss: 0.0001(0.0048) Grad: 226.9818  LR: 0.000006  \n",
      "Epoch: [4][1800/2877] Elapsed 11m 22s (remain 6m 47s) Loss: 0.0001(0.0047) Grad: 905.2546  LR: 0.000006  \n",
      "Epoch: [4][1900/2877] Elapsed 12m 1s (remain 6m 10s) Loss: 0.0006(0.0047) Grad: 3778.5962  LR: 0.000006  \n",
      "Epoch: [4][2000/2877] Elapsed 12m 41s (remain 5m 33s) Loss: 0.0000(0.0047) Grad: 101.0174  LR: 0.000006  \n",
      "Epoch: [4][2100/2877] Elapsed 13m 20s (remain 4m 55s) Loss: 0.0000(0.0046) Grad: 158.3767  LR: 0.000006  \n",
      "Epoch: [4][2200/2877] Elapsed 13m 58s (remain 4m 17s) Loss: 0.0013(0.0046) Grad: 4883.5977  LR: 0.000005  \n",
      "Epoch: [4][2300/2877] Elapsed 14m 36s (remain 3m 39s) Loss: 0.0000(0.0046) Grad: 45.3525  LR: 0.000005  \n",
      "Epoch: [4][2400/2877] Elapsed 15m 14s (remain 3m 1s) Loss: 0.0011(0.0045) Grad: 4848.3052  LR: 0.000005  \n",
      "Epoch: [4][2500/2877] Elapsed 15m 51s (remain 2m 23s) Loss: 0.0062(0.0046) Grad: 17351.2207  LR: 0.000005  \n",
      "Epoch: [4][2600/2877] Elapsed 16m 29s (remain 1m 44s) Loss: 0.0051(0.0045) Grad: 18825.5801  LR: 0.000005  \n",
      "Epoch: [4][2700/2877] Elapsed 17m 6s (remain 1m 6s) Loss: 0.0013(0.0046) Grad: 12166.9512  LR: 0.000005  \n",
      "Epoch: [4][2800/2877] Elapsed 17m 44s (remain 0m 28s) Loss: 0.0000(0.0045) Grad: 86.9703  LR: 0.000005  \n",
      "Epoch: [4][2876/2877] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0007(0.0046) Grad: 3036.0146  LR: 0.000004  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 29s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0012(0.0066) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 45s) Loss: 0.0365(0.0093) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 24s) Loss: 0.0048(0.0095) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0280(0.0098) \n",
      "EVAL: [500/698] Elapsed 1m 47s (remain 0m 42s) Loss: 0.0021(0.0094) \n",
      "EVAL: [600/698] Elapsed 2m 8s (remain 0m 20s) Loss: 0.0103(0.0087) \n",
      "EVAL: [697/698] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0085) \n",
      "Epoch 4 - avg_train_loss: 0.0046  avg_val_loss: 0.0085  time: 1248s\n",
      "Epoch 4 - Score: 0.8860\n",
      "Epoch: [5][0/2877] Elapsed 0m 0s (remain 28m 39s) Loss: 0.0001(0.0001) Grad: 1056.8372  LR: 0.000004  \n",
      "Epoch: [5][100/2877] Elapsed 0m 37s (remain 17m 2s) Loss: 0.0014(0.0031) Grad: 4561.5654  LR: 0.000004  \n",
      "Epoch: [5][200/2877] Elapsed 1m 14s (remain 16m 35s) Loss: 0.0043(0.0032) Grad: 9397.4170  LR: 0.000004  \n",
      "Epoch: [5][300/2877] Elapsed 1m 52s (remain 15m 59s) Loss: 0.0031(0.0031) Grad: 28872.1523  LR: 0.000004  \n",
      "Epoch: [5][400/2877] Elapsed 2m 29s (remain 15m 26s) Loss: 0.0014(0.0036) Grad: 4804.3892  LR: 0.000004  \n",
      "Epoch: [5][500/2877] Elapsed 3m 8s (remain 14m 53s) Loss: 0.0001(0.0036) Grad: 353.8652  LR: 0.000004  \n",
      "Epoch: [5][600/2877] Elapsed 3m 45s (remain 14m 14s) Loss: 0.0000(0.0034) Grad: 17.8720  LR: 0.000004  \n",
      "Epoch: [5][700/2877] Elapsed 4m 22s (remain 13m 35s) Loss: 0.0012(0.0033) Grad: 5674.1270  LR: 0.000003  \n",
      "Epoch: [5][800/2877] Elapsed 5m 0s (remain 12m 57s) Loss: 0.0010(0.0036) Grad: 7590.2002  LR: 0.000003  \n",
      "Epoch: [5][900/2877] Elapsed 5m 40s (remain 12m 26s) Loss: 0.0015(0.0039) Grad: 5316.7104  LR: 0.000003  \n",
      "Epoch: [5][1000/2877] Elapsed 6m 17s (remain 11m 47s) Loss: 0.0002(0.0040) Grad: 818.7647  LR: 0.000003  \n",
      "Epoch: [5][1100/2877] Elapsed 6m 54s (remain 11m 8s) Loss: 0.0000(0.0038) Grad: 47.9382  LR: 0.000003  \n",
      "Epoch: [5][1200/2877] Elapsed 7m 31s (remain 10m 29s) Loss: 0.0046(0.0039) Grad: 34624.9297  LR: 0.000003  \n",
      "Epoch: [5][1300/2877] Elapsed 8m 8s (remain 9m 52s) Loss: 0.0001(0.0040) Grad: 903.4563  LR: 0.000002  \n",
      "Epoch: [5][1400/2877] Elapsed 8m 46s (remain 9m 14s) Loss: 0.0095(0.0040) Grad: 8671.7666  LR: 0.000002  \n",
      "Epoch: [5][1500/2877] Elapsed 9m 24s (remain 8m 37s) Loss: 0.0001(0.0039) Grad: 721.2778  LR: 0.000002  \n",
      "Epoch: [5][1600/2877] Elapsed 10m 3s (remain 8m 0s) Loss: 0.0001(0.0039) Grad: 245.0732  LR: 0.000002  \n",
      "Epoch: [5][1700/2877] Elapsed 10m 40s (remain 7m 22s) Loss: 0.0002(0.0038) Grad: 856.4960  LR: 0.000002  \n",
      "Epoch: [5][1800/2877] Elapsed 11m 18s (remain 6m 45s) Loss: 0.0059(0.0039) Grad: 6832.5786  LR: 0.000002  \n",
      "Epoch: [5][1900/2877] Elapsed 11m 56s (remain 6m 7s) Loss: 0.0002(0.0039) Grad: 930.2772  LR: 0.000002  \n",
      "Epoch: [5][2000/2877] Elapsed 12m 33s (remain 5m 29s) Loss: 0.0063(0.0038) Grad: 19825.1309  LR: 0.000001  \n",
      "Epoch: [5][2100/2877] Elapsed 13m 11s (remain 4m 52s) Loss: 0.0001(0.0039) Grad: 726.7741  LR: 0.000001  \n",
      "Epoch: [5][2200/2877] Elapsed 13m 49s (remain 4m 14s) Loss: 0.0000(0.0038) Grad: 140.5725  LR: 0.000001  \n",
      "Epoch: [5][2300/2877] Elapsed 14m 26s (remain 3m 36s) Loss: 0.0039(0.0039) Grad: 40138.9414  LR: 0.000001  \n",
      "Epoch: [5][2400/2877] Elapsed 15m 3s (remain 2m 59s) Loss: 0.0002(0.0039) Grad: 1073.7339  LR: 0.000001  \n",
      "Epoch: [5][2500/2877] Elapsed 15m 41s (remain 2m 21s) Loss: 0.0014(0.0039) Grad: 13072.9053  LR: 0.000001  \n",
      "Epoch: [5][2600/2877] Elapsed 16m 19s (remain 1m 43s) Loss: 0.0000(0.0038) Grad: 124.2032  LR: 0.000000  \n",
      "Epoch: [5][2700/2877] Elapsed 16m 57s (remain 1m 6s) Loss: 0.0033(0.0039) Grad: 91794.5547  LR: 0.000000  \n",
      "Epoch: [5][2800/2877] Elapsed 17m 35s (remain 0m 28s) Loss: 0.0000(0.0039) Grad: 29.7062  LR: 0.000000  \n",
      "Epoch: [5][2876/2877] Elapsed 18m 3s (remain 0m 0s) Loss: 0.0040(0.0039) Grad: 10089.9727  LR: 0.000000  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 33s) Loss: 0.0003(0.0003) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0006(0.0075) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 45s) Loss: 0.0396(0.0100) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 24s) Loss: 0.0047(0.0104) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0368(0.0107) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0033(0.0103) \n",
      "EVAL: [600/698] Elapsed 2m 8s (remain 0m 20s) Loss: 0.0124(0.0096) \n",
      "EVAL: [697/698] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0094) \n",
      "Epoch 5 - avg_train_loss: 0.0039  avg_val_loss: 0.0094  time: 1237s\n",
      "Epoch 5 - Score: 0.8865\n",
      "Epoch 5 - Save Best Score: 0.8865 Model\n",
      "========== fold: 4 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2850] Elapsed 0m 0s (remain 33m 27s) Loss: 0.4362(0.4362) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2850] Elapsed 0m 38s (remain 17m 20s) Loss: 0.6313(0.6277) Grad: 35539.7969  LR: 0.000001  \n",
      "Epoch: [1][200/2850] Elapsed 1m 15s (remain 16m 41s) Loss: 0.1701(0.4768) Grad: 11369.6533  LR: 0.000003  \n",
      "Epoch: [1][300/2850] Elapsed 1m 53s (remain 15m 59s) Loss: 0.0199(0.3436) Grad: 385.6317  LR: 0.000004  \n",
      "Epoch: [1][400/2850] Elapsed 2m 30s (remain 15m 17s) Loss: 0.0791(0.2695) Grad: 963.5564  LR: 0.000006  \n",
      "Epoch: [1][500/2850] Elapsed 3m 10s (remain 14m 51s) Loss: 0.0404(0.2235) Grad: 489.7776  LR: 0.000007  \n",
      "Epoch: [1][600/2850] Elapsed 3m 47s (remain 14m 11s) Loss: 0.0247(0.1928) Grad: 945.1460  LR: 0.000008  \n",
      "Epoch: [1][700/2850] Elapsed 4m 24s (remain 13m 31s) Loss: 0.0233(0.1700) Grad: 1374.7256  LR: 0.000010  \n",
      "Epoch: [1][800/2850] Elapsed 5m 3s (remain 12m 56s) Loss: 0.0183(0.1521) Grad: 1407.3844  LR: 0.000011  \n",
      "Epoch: [1][900/2850] Elapsed 5m 41s (remain 12m 17s) Loss: 0.0141(0.1371) Grad: 1835.1716  LR: 0.000013  \n",
      "Epoch: [1][1000/2850] Elapsed 6m 18s (remain 11m 38s) Loss: 0.0135(0.1247) Grad: 1668.7882  LR: 0.000014  \n",
      "Epoch: [1][1100/2850] Elapsed 6m 56s (remain 11m 1s) Loss: 0.0083(0.1146) Grad: 2284.9292  LR: 0.000015  \n",
      "Epoch: [1][1200/2850] Elapsed 7m 33s (remain 10m 23s) Loss: 0.0025(0.1062) Grad: 339.5913  LR: 0.000017  \n",
      "Epoch: [1][1300/2850] Elapsed 8m 12s (remain 9m 46s) Loss: 0.0073(0.0990) Grad: 861.1858  LR: 0.000018  \n",
      "Epoch: [1][1400/2850] Elapsed 8m 50s (remain 9m 8s) Loss: 0.0007(0.0928) Grad: 194.4111  LR: 0.000020  \n",
      "Epoch: [1][1500/2850] Elapsed 9m 27s (remain 8m 30s) Loss: 0.0341(0.0874) Grad: 5401.2837  LR: 0.000020  \n",
      "Epoch: [1][1600/2850] Elapsed 10m 4s (remain 7m 51s) Loss: 0.0054(0.0824) Grad: 461.1746  LR: 0.000020  \n",
      "Epoch: [1][1700/2850] Elapsed 10m 41s (remain 7m 13s) Loss: 0.0091(0.0782) Grad: 1133.3629  LR: 0.000020  \n",
      "Epoch: [1][1800/2850] Elapsed 11m 21s (remain 6m 36s) Loss: 0.0161(0.0745) Grad: 973.4651  LR: 0.000019  \n",
      "Epoch: [1][1900/2850] Elapsed 12m 2s (remain 6m 0s) Loss: 0.0013(0.0710) Grad: 1139.7056  LR: 0.000019  \n",
      "Epoch: [1][2000/2850] Elapsed 12m 40s (remain 5m 22s) Loss: 0.0104(0.0678) Grad: 2152.4197  LR: 0.000019  \n",
      "Epoch: [1][2100/2850] Elapsed 13m 16s (remain 4m 44s) Loss: 0.0018(0.0650) Grad: 279.1040  LR: 0.000019  \n",
      "Epoch: [1][2200/2850] Elapsed 13m 54s (remain 4m 6s) Loss: 0.0008(0.0625) Grad: 92.9278  LR: 0.000019  \n",
      "Epoch: [1][2300/2850] Elapsed 14m 32s (remain 3m 28s) Loss: 0.0012(0.0602) Grad: 251.0484  LR: 0.000019  \n",
      "Epoch: [1][2400/2850] Elapsed 15m 11s (remain 2m 50s) Loss: 0.0020(0.0580) Grad: 172.6216  LR: 0.000018  \n",
      "Epoch: [1][2500/2850] Elapsed 15m 48s (remain 2m 12s) Loss: 0.0015(0.0560) Grad: 177.0694  LR: 0.000018  \n",
      "Epoch: [1][2600/2850] Elapsed 16m 25s (remain 1m 34s) Loss: 0.0072(0.0541) Grad: 588.0822  LR: 0.000018  \n",
      "Epoch: [1][2700/2850] Elapsed 17m 1s (remain 0m 56s) Loss: 0.0027(0.0524) Grad: 244.9182  LR: 0.000018  \n",
      "Epoch: [1][2800/2850] Elapsed 17m 40s (remain 0m 18s) Loss: 0.0105(0.0508) Grad: 1915.5298  LR: 0.000018  \n",
      "Epoch: [1][2849/2850] Elapsed 17m 58s (remain 0m 0s) Loss: 0.0065(0.0501) Grad: 1020.6393  LR: 0.000018  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 27s) Loss: 0.0239(0.0239) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0009(0.0081) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0161(0.0101) \n",
      "EVAL: [300/725] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0033(0.0088) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 8s) Loss: 0.1470(0.0100) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0108(0.0101) \n",
      "EVAL: [600/725] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0029(0.0096) \n",
      "EVAL: [700/725] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0014(0.0088) \n",
      "EVAL: [724/725] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0120(0.0086) \n",
      "Epoch 1 - avg_train_loss: 0.0501  avg_val_loss: 0.0086  time: 1237s\n",
      "Epoch 1 - Score: 0.8458\n",
      "Epoch 1 - Save Best Score: 0.8458 Model\n",
      "Epoch: [2][0/2850] Elapsed 0m 0s (remain 32m 20s) Loss: 0.0010(0.0010) Grad: 4107.6582  LR: 0.000018  \n",
      "Epoch: [2][100/2850] Elapsed 0m 39s (remain 17m 45s) Loss: 0.0010(0.0054) Grad: 4389.5542  LR: 0.000018  \n",
      "Epoch: [2][200/2850] Elapsed 1m 16s (remain 16m 45s) Loss: 0.0108(0.0067) Grad: 17545.9863  LR: 0.000017  \n",
      "Epoch: [2][300/2850] Elapsed 1m 54s (remain 16m 13s) Loss: 0.0402(0.0074) Grad: 25245.1016  LR: 0.000017  \n",
      "Epoch: [2][400/2850] Elapsed 2m 32s (remain 15m 29s) Loss: 0.0040(0.0068) Grad: 6620.1475  LR: 0.000017  \n",
      "Epoch: [2][500/2850] Elapsed 3m 9s (remain 14m 48s) Loss: 0.0033(0.0070) Grad: 11919.3828  LR: 0.000017  \n",
      "Epoch: [2][600/2850] Elapsed 3m 47s (remain 14m 11s) Loss: 0.0115(0.0066) Grad: 17708.9609  LR: 0.000017  \n",
      "Epoch: [2][700/2850] Elapsed 4m 25s (remain 13m 34s) Loss: 0.0683(0.0069) Grad: 52141.5938  LR: 0.000017  \n",
      "Epoch: [2][800/2850] Elapsed 5m 4s (remain 12m 59s) Loss: 0.0030(0.0070) Grad: 13283.7383  LR: 0.000017  \n",
      "Epoch: [2][900/2850] Elapsed 5m 42s (remain 12m 21s) Loss: 0.0007(0.0069) Grad: 2816.6777  LR: 0.000016  \n",
      "Epoch: [2][1000/2850] Elapsed 6m 20s (remain 11m 42s) Loss: 0.0004(0.0069) Grad: 1238.9933  LR: 0.000016  \n",
      "Epoch: [2][1100/2850] Elapsed 6m 57s (remain 11m 3s) Loss: 0.0004(0.0070) Grad: 1232.6686  LR: 0.000016  \n",
      "Epoch: [2][1200/2850] Elapsed 7m 35s (remain 10m 25s) Loss: 0.0000(0.0070) Grad: 158.8138  LR: 0.000016  \n",
      "Epoch: [2][1300/2850] Elapsed 8m 13s (remain 9m 47s) Loss: 0.0095(0.0068) Grad: 16015.7881  LR: 0.000016  \n",
      "Epoch: [2][1400/2850] Elapsed 8m 51s (remain 9m 9s) Loss: 0.0000(0.0068) Grad: 45.1927  LR: 0.000016  \n",
      "Epoch: [2][1500/2850] Elapsed 9m 30s (remain 8m 32s) Loss: 0.0000(0.0068) Grad: 87.8958  LR: 0.000015  \n",
      "Epoch: [2][1600/2850] Elapsed 10m 8s (remain 7m 54s) Loss: 0.0009(0.0068) Grad: 6306.0332  LR: 0.000015  \n",
      "Epoch: [2][1700/2850] Elapsed 10m 45s (remain 7m 16s) Loss: 0.0055(0.0068) Grad: 6349.3745  LR: 0.000015  \n",
      "Epoch: [2][1800/2850] Elapsed 11m 24s (remain 6m 38s) Loss: 0.0066(0.0068) Grad: 17109.0195  LR: 0.000015  \n",
      "Epoch: [2][1900/2850] Elapsed 12m 2s (remain 6m 0s) Loss: 0.0037(0.0068) Grad: 12874.4043  LR: 0.000015  \n",
      "Epoch: [2][2000/2850] Elapsed 12m 40s (remain 5m 22s) Loss: 0.0001(0.0068) Grad: 529.9536  LR: 0.000015  \n",
      "Epoch: [2][2100/2850] Elapsed 13m 17s (remain 4m 44s) Loss: 0.0008(0.0067) Grad: 2707.7385  LR: 0.000015  \n",
      "Epoch: [2][2200/2850] Elapsed 13m 55s (remain 4m 6s) Loss: 0.0006(0.0067) Grad: 1275.1896  LR: 0.000014  \n",
      "Epoch: [2][2300/2850] Elapsed 14m 34s (remain 3m 28s) Loss: 0.0094(0.0067) Grad: 16457.4785  LR: 0.000014  \n",
      "Epoch: [2][2400/2850] Elapsed 15m 13s (remain 2m 50s) Loss: 0.0001(0.0066) Grad: 331.4291  LR: 0.000014  \n",
      "Epoch: [2][2500/2850] Elapsed 15m 50s (remain 2m 12s) Loss: 0.0000(0.0066) Grad: 97.6046  LR: 0.000014  \n",
      "Epoch: [2][2600/2850] Elapsed 16m 28s (remain 1m 34s) Loss: 0.0103(0.0067) Grad: 23220.6309  LR: 0.000014  \n",
      "Epoch: [2][2700/2850] Elapsed 17m 6s (remain 0m 56s) Loss: 0.0010(0.0067) Grad: 3814.5491  LR: 0.000014  \n",
      "Epoch: [2][2800/2850] Elapsed 17m 44s (remain 0m 18s) Loss: 0.0042(0.0067) Grad: 5239.3120  LR: 0.000013  \n",
      "Epoch: [2][2849/2850] Elapsed 18m 2s (remain 0m 0s) Loss: 0.0003(0.0066) Grad: 1336.1577  LR: 0.000013  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 10s) Loss: 0.0078(0.0078) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 13s) Loss: 0.0008(0.0078) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 53s) Loss: 0.0123(0.0102) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0034(0.0090) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0452(0.0092) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0136(0.0091) \n",
      "EVAL: [600/725] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0035(0.0089) \n",
      "EVAL: [700/725] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0002(0.0082) \n",
      "EVAL: [724/725] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0171(0.0080) \n",
      "Epoch 2 - avg_train_loss: 0.0066  avg_val_loss: 0.0080  time: 1241s\n",
      "Epoch 2 - Score: 0.8730\n",
      "Epoch 2 - Save Best Score: 0.8730 Model\n",
      "Epoch: [3][0/2850] Elapsed 0m 0s (remain 29m 2s) Loss: 0.0007(0.0007) Grad: 6113.5806  LR: 0.000013  \n",
      "Epoch: [3][100/2850] Elapsed 0m 39s (remain 17m 50s) Loss: 0.0003(0.0068) Grad: 1187.0157  LR: 0.000013  \n",
      "Epoch: [3][200/2850] Elapsed 1m 17s (remain 17m 5s) Loss: 0.0005(0.0061) Grad: 5129.9814  LR: 0.000013  \n",
      "Epoch: [3][300/2850] Elapsed 1m 55s (remain 16m 19s) Loss: 0.0000(0.0057) Grad: 71.7046  LR: 0.000013  \n",
      "Epoch: [3][400/2850] Elapsed 2m 33s (remain 15m 36s) Loss: 0.0123(0.0057) Grad: 12571.6738  LR: 0.000013  \n",
      "Epoch: [3][500/2850] Elapsed 3m 11s (remain 14m 56s) Loss: 0.0003(0.0054) Grad: 968.5336  LR: 0.000013  \n",
      "Epoch: [3][600/2850] Elapsed 3m 49s (remain 14m 20s) Loss: 0.0000(0.0056) Grad: 649.7369  LR: 0.000012  \n",
      "Epoch: [3][700/2850] Elapsed 4m 28s (remain 13m 43s) Loss: 0.0059(0.0051) Grad: 86635.9297  LR: 0.000012  \n",
      "Epoch: [3][800/2850] Elapsed 5m 6s (remain 13m 4s) Loss: 0.0056(0.0051) Grad: 11477.8643  LR: 0.000012  \n",
      "Epoch: [3][900/2850] Elapsed 5m 43s (remain 12m 24s) Loss: 0.0454(0.0052) Grad: 94728.1250  LR: 0.000012  \n",
      "Epoch: [3][1000/2850] Elapsed 6m 22s (remain 11m 46s) Loss: 0.0068(0.0054) Grad: 20086.0605  LR: 0.000012  \n",
      "Epoch: [3][1100/2850] Elapsed 7m 0s (remain 11m 7s) Loss: 0.0018(0.0053) Grad: 5054.4170  LR: 0.000012  \n",
      "Epoch: [3][1200/2850] Elapsed 7m 37s (remain 10m 28s) Loss: 0.0006(0.0054) Grad: 2570.2080  LR: 0.000011  \n",
      "Epoch: [3][1300/2850] Elapsed 8m 15s (remain 9m 49s) Loss: 0.0096(0.0054) Grad: 82651.9453  LR: 0.000011  \n",
      "Epoch: [3][1400/2850] Elapsed 8m 53s (remain 9m 12s) Loss: 0.0000(0.0054) Grad: 99.7683  LR: 0.000011  \n",
      "Epoch: [3][1500/2850] Elapsed 9m 31s (remain 8m 33s) Loss: 0.0000(0.0054) Grad: 61.0750  LR: 0.000011  \n",
      "Epoch: [3][1600/2850] Elapsed 10m 8s (remain 7m 54s) Loss: 0.0063(0.0055) Grad: 32216.5742  LR: 0.000011  \n",
      "Epoch: [3][1700/2850] Elapsed 10m 46s (remain 7m 16s) Loss: 0.0011(0.0055) Grad: 3722.7747  LR: 0.000011  \n",
      "Epoch: [3][1800/2850] Elapsed 11m 24s (remain 6m 38s) Loss: 0.0000(0.0054) Grad: 42.9819  LR: 0.000011  \n",
      "Epoch: [3][1900/2850] Elapsed 12m 3s (remain 6m 0s) Loss: 0.0000(0.0054) Grad: 153.2195  LR: 0.000010  \n",
      "Epoch: [3][2000/2850] Elapsed 12m 40s (remain 5m 22s) Loss: 0.0305(0.0055) Grad: 54891.2695  LR: 0.000010  \n",
      "Epoch: [3][2100/2850] Elapsed 13m 18s (remain 4m 44s) Loss: 0.0027(0.0055) Grad: 6810.5493  LR: 0.000010  \n",
      "Epoch: [3][2200/2850] Elapsed 13m 55s (remain 4m 6s) Loss: 0.0050(0.0056) Grad: 10263.7705  LR: 0.000010  \n",
      "Epoch: [3][2300/2850] Elapsed 14m 34s (remain 3m 28s) Loss: 0.0079(0.0056) Grad: 9622.2080  LR: 0.000010  \n",
      "Epoch: [3][2400/2850] Elapsed 15m 11s (remain 2m 50s) Loss: 0.0186(0.0056) Grad: 66887.7969  LR: 0.000010  \n",
      "Epoch: [3][2500/2850] Elapsed 15m 49s (remain 2m 12s) Loss: 0.0018(0.0055) Grad: 8225.1865  LR: 0.000009  \n",
      "Epoch: [3][2600/2850] Elapsed 16m 26s (remain 1m 34s) Loss: 0.0002(0.0054) Grad: 613.1129  LR: 0.000009  \n",
      "Epoch: [3][2700/2850] Elapsed 17m 3s (remain 0m 56s) Loss: 0.0017(0.0054) Grad: 5269.5020  LR: 0.000009  \n",
      "Epoch: [3][2800/2850] Elapsed 17m 41s (remain 0m 18s) Loss: 0.0000(0.0054) Grad: 123.8944  LR: 0.000009  \n",
      "Epoch: [3][2849/2850] Elapsed 17m 59s (remain 0m 0s) Loss: 0.0009(0.0053) Grad: 2814.4500  LR: 0.000009  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 14s) Loss: 0.0074(0.0074) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 15s) Loss: 0.0009(0.0078) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0156(0.0111) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0029(0.0097) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 8s) Loss: 0.1239(0.0107) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0223(0.0108) \n",
      "EVAL: [600/725] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0134(0.0104) \n",
      "EVAL: [700/725] Elapsed 2m 29s (remain 0m 5s) Loss: 0.0000(0.0096) \n",
      "EVAL: [724/725] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0173(0.0094) \n",
      "Epoch 3 - avg_train_loss: 0.0053  avg_val_loss: 0.0094  time: 1239s\n",
      "Epoch 3 - Score: 0.8807\n",
      "Epoch 3 - Save Best Score: 0.8807 Model\n",
      "Epoch: [4][0/2850] Elapsed 0m 0s (remain 30m 4s) Loss: 0.0001(0.0001) Grad: 175.0614  LR: 0.000009  \n",
      "Epoch: [4][100/2850] Elapsed 0m 38s (remain 17m 18s) Loss: 0.0001(0.0042) Grad: 184.5409  LR: 0.000009  \n",
      "Epoch: [4][200/2850] Elapsed 1m 16s (remain 16m 49s) Loss: 0.0140(0.0039) Grad: 26491.8770  LR: 0.000009  \n",
      "Epoch: [4][300/2850] Elapsed 1m 54s (remain 16m 12s) Loss: 0.0001(0.0043) Grad: 673.2487  LR: 0.000008  \n",
      "Epoch: [4][400/2850] Elapsed 2m 36s (remain 15m 52s) Loss: 0.0002(0.0047) Grad: 1105.9170  LR: 0.000008  \n",
      "Epoch: [4][500/2850] Elapsed 3m 15s (remain 15m 15s) Loss: 0.0073(0.0045) Grad: 7755.9233  LR: 0.000008  \n",
      "Epoch: [4][600/2850] Elapsed 3m 52s (remain 14m 29s) Loss: 0.0008(0.0044) Grad: 1803.5122  LR: 0.000008  \n",
      "Epoch: [4][700/2850] Elapsed 4m 29s (remain 13m 46s) Loss: 0.0020(0.0042) Grad: 3645.8557  LR: 0.000008  \n",
      "Epoch: [4][800/2850] Elapsed 5m 7s (remain 13m 5s) Loss: 0.0007(0.0043) Grad: 4148.3628  LR: 0.000008  \n",
      "Epoch: [4][900/2850] Elapsed 5m 45s (remain 12m 26s) Loss: 0.0020(0.0043) Grad: 8250.8545  LR: 0.000007  \n",
      "Epoch: [4][1000/2850] Elapsed 6m 22s (remain 11m 46s) Loss: 0.0045(0.0044) Grad: 8849.0293  LR: 0.000007  \n",
      "Epoch: [4][1100/2850] Elapsed 7m 0s (remain 11m 7s) Loss: 0.0070(0.0043) Grad: 36278.4219  LR: 0.000007  \n",
      "Epoch: [4][1200/2850] Elapsed 7m 40s (remain 10m 31s) Loss: 0.0081(0.0043) Grad: 13548.0889  LR: 0.000007  \n",
      "Epoch: [4][1300/2850] Elapsed 8m 17s (remain 9m 52s) Loss: 0.0004(0.0042) Grad: 5203.2090  LR: 0.000007  \n",
      "Epoch: [4][1400/2850] Elapsed 8m 55s (remain 9m 13s) Loss: 0.0018(0.0043) Grad: 6729.1504  LR: 0.000007  \n",
      "Epoch: [4][1500/2850] Elapsed 9m 34s (remain 8m 36s) Loss: 0.0005(0.0043) Grad: 4234.7275  LR: 0.000007  \n",
      "Epoch: [4][1600/2850] Elapsed 10m 12s (remain 7m 57s) Loss: 0.0001(0.0044) Grad: 1054.4858  LR: 0.000006  \n",
      "Epoch: [4][1700/2850] Elapsed 10m 49s (remain 7m 18s) Loss: 0.0001(0.0043) Grad: 1293.4036  LR: 0.000006  \n",
      "Epoch: [4][1800/2850] Elapsed 11m 27s (remain 6m 40s) Loss: 0.0006(0.0044) Grad: 2792.8313  LR: 0.000006  \n",
      "Epoch: [4][1900/2850] Elapsed 12m 5s (remain 6m 2s) Loss: 0.0088(0.0044) Grad: 15039.3486  LR: 0.000006  \n",
      "Epoch: [4][2000/2850] Elapsed 12m 43s (remain 5m 23s) Loss: 0.0009(0.0044) Grad: 4109.8857  LR: 0.000006  \n",
      "Epoch: [4][2100/2850] Elapsed 13m 20s (remain 4m 45s) Loss: 0.0003(0.0044) Grad: 1812.7788  LR: 0.000006  \n",
      "Epoch: [4][2200/2850] Elapsed 14m 0s (remain 4m 7s) Loss: 0.0050(0.0045) Grad: 26134.9043  LR: 0.000005  \n",
      "Epoch: [4][2300/2850] Elapsed 14m 39s (remain 3m 29s) Loss: 0.0086(0.0044) Grad: 17850.7754  LR: 0.000005  \n",
      "Epoch: [4][2400/2850] Elapsed 15m 17s (remain 2m 51s) Loss: 0.0019(0.0044) Grad: 6624.3301  LR: 0.000005  \n",
      "Epoch: [4][2500/2850] Elapsed 15m 54s (remain 2m 13s) Loss: 0.0253(0.0044) Grad: 19298.0723  LR: 0.000005  \n",
      "Epoch: [4][2600/2850] Elapsed 16m 32s (remain 1m 35s) Loss: 0.0004(0.0045) Grad: 4290.6289  LR: 0.000005  \n",
      "Epoch: [4][2700/2850] Elapsed 17m 11s (remain 0m 56s) Loss: 0.0000(0.0044) Grad: 18.6612  LR: 0.000005  \n",
      "Epoch: [4][2800/2850] Elapsed 17m 49s (remain 0m 18s) Loss: 0.0003(0.0045) Grad: 1208.9564  LR: 0.000005  \n",
      "Epoch: [4][2849/2850] Elapsed 18m 8s (remain 0m 0s) Loss: 0.0000(0.0045) Grad: 999.7183  LR: 0.000004  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 36s) Loss: 0.0083(0.0083) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 15s) Loss: 0.0016(0.0070) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0172(0.0108) \n",
      "EVAL: [300/725] Elapsed 1m 3s (remain 1m 30s) Loss: 0.0093(0.0095) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0365(0.0101) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0181(0.0102) \n",
      "EVAL: [600/725] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0134(0.0100) \n",
      "EVAL: [700/725] Elapsed 2m 29s (remain 0m 5s) Loss: 0.0000(0.0092) \n",
      "EVAL: [724/725] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0189(0.0090) \n",
      "Epoch 4 - avg_train_loss: 0.0045  avg_val_loss: 0.0090  time: 1248s\n",
      "Epoch 4 - Score: 0.8792\n",
      "Epoch: [5][0/2850] Elapsed 0m 0s (remain 28m 39s) Loss: 0.0004(0.0004) Grad: 2704.6628  LR: 0.000004  \n",
      "Epoch: [5][100/2850] Elapsed 0m 38s (remain 17m 38s) Loss: 0.0000(0.0038) Grad: 43.2176  LR: 0.000004  \n",
      "Epoch: [5][200/2850] Elapsed 1m 17s (remain 16m 55s) Loss: 0.0021(0.0040) Grad: 12084.4082  LR: 0.000004  \n",
      "Epoch: [5][300/2850] Elapsed 1m 54s (remain 16m 11s) Loss: 0.0143(0.0039) Grad: 13904.7598  LR: 0.000004  \n",
      "Epoch: [5][400/2850] Elapsed 2m 32s (remain 15m 28s) Loss: 0.0009(0.0039) Grad: 5370.9468  LR: 0.000004  \n",
      "Epoch: [5][500/2850] Elapsed 3m 9s (remain 14m 49s) Loss: 0.0009(0.0038) Grad: 5535.7388  LR: 0.000004  \n",
      "Epoch: [5][600/2850] Elapsed 3m 47s (remain 14m 11s) Loss: 0.0038(0.0038) Grad: 11674.3877  LR: 0.000004  \n",
      "Epoch: [5][700/2850] Elapsed 4m 24s (remain 13m 31s) Loss: 0.0009(0.0037) Grad: 9473.2100  LR: 0.000003  \n",
      "Epoch: [5][800/2850] Elapsed 5m 2s (remain 12m 53s) Loss: 0.0000(0.0037) Grad: 15.8234  LR: 0.000003  \n",
      "Epoch: [5][900/2850] Elapsed 5m 40s (remain 12m 16s) Loss: 0.0000(0.0037) Grad: 114.0110  LR: 0.000003  \n",
      "Epoch: [5][1000/2850] Elapsed 6m 18s (remain 11m 38s) Loss: 0.0006(0.0037) Grad: 3635.9014  LR: 0.000003  \n",
      "Epoch: [5][1100/2850] Elapsed 6m 56s (remain 11m 1s) Loss: 0.0035(0.0039) Grad: 23499.5586  LR: 0.000003  \n",
      "Epoch: [5][1200/2850] Elapsed 7m 34s (remain 10m 23s) Loss: 0.0000(0.0039) Grad: 18.7445  LR: 0.000003  \n",
      "Epoch: [5][1300/2850] Elapsed 8m 11s (remain 9m 44s) Loss: 0.0001(0.0038) Grad: 377.5846  LR: 0.000002  \n",
      "Epoch: [5][1400/2850] Elapsed 8m 48s (remain 9m 6s) Loss: 0.0009(0.0037) Grad: 8912.7900  LR: 0.000002  \n",
      "Epoch: [5][1500/2850] Elapsed 9m 29s (remain 8m 31s) Loss: 0.0001(0.0038) Grad: 182.1404  LR: 0.000002  \n",
      "Epoch: [5][1600/2850] Elapsed 10m 7s (remain 7m 54s) Loss: 0.0016(0.0037) Grad: 11341.5654  LR: 0.000002  \n",
      "Epoch: [5][1700/2850] Elapsed 10m 44s (remain 7m 15s) Loss: 0.0000(0.0037) Grad: 18.4610  LR: 0.000002  \n",
      "Epoch: [5][1800/2850] Elapsed 11m 24s (remain 6m 38s) Loss: 0.0101(0.0037) Grad: 25615.6992  LR: 0.000002  \n",
      "Epoch: [5][1900/2850] Elapsed 12m 2s (remain 6m 0s) Loss: 0.0000(0.0037) Grad: 305.5854  LR: 0.000001  \n",
      "Epoch: [5][2000/2850] Elapsed 12m 39s (remain 5m 22s) Loss: 0.0711(0.0038) Grad: 37225.6914  LR: 0.000001  \n",
      "Epoch: [5][2100/2850] Elapsed 13m 18s (remain 4m 44s) Loss: 0.0028(0.0038) Grad: 5291.4868  LR: 0.000001  \n",
      "Epoch: [5][2200/2850] Elapsed 13m 56s (remain 4m 6s) Loss: 0.0000(0.0038) Grad: 113.3283  LR: 0.000001  \n",
      "Epoch: [5][2300/2850] Elapsed 14m 33s (remain 3m 28s) Loss: 0.0000(0.0038) Grad: 355.3824  LR: 0.000001  \n",
      "Epoch: [5][2400/2850] Elapsed 15m 11s (remain 2m 50s) Loss: 0.0004(0.0037) Grad: 2656.2249  LR: 0.000001  \n",
      "Epoch: [5][2500/2850] Elapsed 15m 51s (remain 2m 12s) Loss: 0.0000(0.0038) Grad: 29.8878  LR: 0.000001  \n",
      "Epoch: [5][2600/2850] Elapsed 16m 29s (remain 1m 34s) Loss: 0.0005(0.0038) Grad: 3739.2588  LR: 0.000000  \n",
      "Epoch: [5][2700/2850] Elapsed 17m 6s (remain 0m 56s) Loss: 0.0001(0.0038) Grad: 1405.6998  LR: 0.000000  \n",
      "Epoch: [5][2800/2850] Elapsed 17m 43s (remain 0m 18s) Loss: 0.0001(0.0038) Grad: 625.1573  LR: 0.000000  \n",
      "Epoch: [5][2849/2850] Elapsed 18m 2s (remain 0m 0s) Loss: 0.0001(0.0038) Grad: 1177.5266  LR: 0.000000  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 37s) Loss: 0.0275(0.0275) \n",
      "EVAL: [100/725] Elapsed 0m 22s (remain 2m 16s) Loss: 0.0017(0.0087) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0144(0.0125) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0170(0.0111) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0461(0.0117) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0223(0.0118) \n",
      "EVAL: [600/725] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0148(0.0115) \n",
      "EVAL: [700/725] Elapsed 2m 29s (remain 0m 5s) Loss: 0.0000(0.0105) \n",
      "EVAL: [724/725] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0188(0.0103) \n",
      "Epoch 5 - avg_train_loss: 0.0038  avg_val_loss: 0.0103  time: 1242s\n",
      "Epoch 5 - Score: 0.8819\n",
      "Epoch 5 - Save Best Score: 0.8819 Model\n",
      "Best thres: 0.5, Score: 0.8815\n",
      "Best thres: 0.41865234374999993, Score: 0.8822\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6306e5ff02ac467aacb23ca1b9393e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5519f69a41604d03811544af324e7c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fea1e253af74835aa97028c65488c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b334d6080c8d4bbaab7a3d51c531b787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb65aad42b94cf59c1a57019e469952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp023.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00419a15e9834e98b8a3459b62d01f8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "008f77fefdba425ab2c755f515693e6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05fdce5a55c1483a937d07a50bd9465e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b48bd338cc94fe396aa1b736b9a2507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f856d468c8a4c4c9c83b5b263745508": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1193874a74974cc59982c8d5e3ced585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8e243ea82e59492fb5b845e51a56347a",
       "IPY_MODEL_55ac42bee2ce4f00841b8bd49a7c552d",
       "IPY_MODEL_2281dd4891c640a0b31c23976223f2ba"
      ],
      "layout": "IPY_MODEL_84ea1506dcad4e01ad1cc35b76c0339a"
     }
    },
    "160e78a145894001b2a1295627d80df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_605151b49d7641a28ebd0ca083770c69",
       "IPY_MODEL_8f8c8632070c4fa0a3182521f41e9c40",
       "IPY_MODEL_dfb4641da88e47d3bafabbaa56bc6916"
      ],
      "layout": "IPY_MODEL_008f77fefdba425ab2c755f515693e6f"
     }
    },
    "19783f5141cb47f8aaa057fb01dda913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c55e9e0223548fbbbe29b3e11e59d50",
      "placeholder": "​",
      "style": "IPY_MODEL_1faca6dc4b0e43988d2f81cd209297be",
      "value": " 143/143 [00:00&lt;00:00, 3251.56it/s]"
     }
    },
    "1ad701d95f084c98bd1bf0e9d7d498a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e0d277fe44242e19e3bec17a1cb7280": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1faca6dc4b0e43988d2f81cd209297be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "219090e2dd934c1296f12660ea69b161": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05fdce5a55c1483a937d07a50bd9465e",
      "placeholder": "​",
      "style": "IPY_MODEL_00419a15e9834e98b8a3459b62d01f8b",
      "value": " 2/2 [00:00&lt;00:00,  1.25it/s]"
     }
    },
    "2281dd4891c640a0b31c23976223f2ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b311e42f1294339a07248b31db0c26c",
      "placeholder": "​",
      "style": "IPY_MODEL_ab8e5c4cef00426fa0cf2fc25c51381a",
      "value": " 2/2 [00:00&lt;00:00,  1.31it/s]"
     }
    },
    "26b1a86ee1ff4ce2862c13d47be2b2d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b311e42f1294339a07248b31db0c26c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c55e9e0223548fbbbe29b3e11e59d50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ddd9fc857b549a4ba446dd64a1dd1d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "331b7288a5024ce3a5036af53eb75cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b50983bfae8445fa305d1edadd651af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b09413b459c8406882a16db62e8df9c0",
      "placeholder": "​",
      "style": "IPY_MODEL_8478e8bf8b6146b48e717b84c021e7ab",
      "value": "100%"
     }
    },
    "3ca14e3fd6b84312b0af50a89d5ac7c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fb5b968d9ab4e88964b6b126c6023d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "410c3733ee43430eb55278748d07bc45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44650208feba4c118904c7efc9887532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "490bfe688fe1419996b69f7de1cfee23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5068fb514bf143ba812fe202c3e7a83d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5292a911912d43c2b80919e486b99de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8234c7d9369644dea7e5c7e8fe436771",
      "placeholder": "​",
      "style": "IPY_MODEL_3ca14e3fd6b84312b0af50a89d5ac7c1",
      "value": "100%"
     }
    },
    "537dee640701470c8fc3cc29e7940bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "548835fe547d4114bfd39e5fac680635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5536b7aaba7c41f28197e318b362ec75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b50983bfae8445fa305d1edadd651af",
       "IPY_MODEL_cdbf6aefee644006826f76e2f6722b07",
       "IPY_MODEL_7c62f6a2b08c41a8bc3ecf2efa58c325"
      ],
      "layout": "IPY_MODEL_5ecd28892bb84432935145e27ac71de7"
     }
    },
    "55ac42bee2ce4f00841b8bd49a7c552d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e0d277fe44242e19e3bec17a1cb7280",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5068fb514bf143ba812fe202c3e7a83d",
      "value": 2
     }
    },
    "5a3f361a320f480aa8a4115366073d32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ecd28892bb84432935145e27ac71de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "605151b49d7641a28ebd0ca083770c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dc964a8934744608f92a6af0f0f923f",
      "placeholder": "​",
      "style": "IPY_MODEL_537dee640701470c8fc3cc29e7940bee",
      "value": "100%"
     }
    },
    "63aa4d26409d437fa76e5a156bb04791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65d16c05424c4df0b79b5786be8bd5d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661a9a315f8646a49162891ae47c69e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74fa3a6b51ad46958e58de5580cf5333",
       "IPY_MODEL_810a830f3b6743b9b074867dd8e4e179",
       "IPY_MODEL_7316ae87cfb849898eb022e100730ba2"
      ],
      "layout": "IPY_MODEL_ef004a834af944abbd512fa3218642a1"
     }
    },
    "6919ba0239084b04988e1de02316c76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d74dcf5002c4752af12a65c3aca2113": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc964a8934744608f92a6af0f0f923f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a8b4ea52534d4e9feab6c6fdd72a77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7316ae87cfb849898eb022e100730ba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ddd9fc857b549a4ba446dd64a1dd1d4",
      "placeholder": "​",
      "style": "IPY_MODEL_0b48bd338cc94fe396aa1b736b9a2507",
      "value": " 42146/42146 [00:22&lt;00:00, 1885.59it/s]"
     }
    },
    "74fa3a6b51ad46958e58de5580cf5333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d891639f26644e8a05d7fe38d178245",
      "placeholder": "​",
      "style": "IPY_MODEL_c7cb034c107247cba318475c9952b4ac",
      "value": "100%"
     }
    },
    "789324d1692d4f478d5b95491b03fc22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c62f6a2b08c41a8bc3ecf2efa58c325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e48e5c946462499ab018748ccf80c5b5",
      "placeholder": "​",
      "style": "IPY_MODEL_63aa4d26409d437fa76e5a156bb04791",
      "value": " 2/2 [00:01&lt;00:00,  1.16it/s]"
     }
    },
    "7d891639f26644e8a05d7fe38d178245": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e210db5a5fe41f696351dc87d525ee4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ed0ca5ee62d45d89050f3caf3d528c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "810a830f3b6743b9b074867dd8e4e179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ed0ca5ee62d45d89050f3caf3d528c9",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8a7a19edb074139baefe21f1901d4f4",
      "value": 42146
     }
    },
    "8234c7d9369644dea7e5c7e8fe436771": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8478e8bf8b6146b48e717b84c021e7ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84ea1506dcad4e01ad1cc35b76c0339a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e243ea82e59492fb5b845e51a56347a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_548835fe547d4114bfd39e5fac680635",
      "placeholder": "​",
      "style": "IPY_MODEL_6919ba0239084b04988e1de02316c76e",
      "value": "100%"
     }
    },
    "8f8c8632070c4fa0a3182521f41e9c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d76610cad4f645f187b26f1b82733569",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_925a3ae98bd6488eb7cffdec89d768da",
      "value": 2
     }
    },
    "925a3ae98bd6488eb7cffdec89d768da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "953c495e9f64430cbdd9184bb0bd35cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9815ec90f12a4696a85db6dc629ec62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e210db5a5fe41f696351dc87d525ee4",
      "placeholder": "​",
      "style": "IPY_MODEL_953c495e9f64430cbdd9184bb0bd35cb",
      "value": "100%"
     }
    },
    "9e66574c8c0343ffb0477891bfe5e892": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_331b7288a5024ce3a5036af53eb75cec",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1cd0285cfe34f188e9c779617d48448",
      "value": 2
     }
    },
    "ab8e5c4cef00426fa0cf2fc25c51381a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b09413b459c8406882a16db62e8df9c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28fa99d1b1b4e4da668bcc50373e4cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8554928c5f141de8dfb94c04c2dda03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bec237aed5184115b697ea257f7b0c9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_789324d1692d4f478d5b95491b03fc22",
      "placeholder": "​",
      "style": "IPY_MODEL_490bfe688fe1419996b69f7de1cfee23",
      "value": " 2/2 [00:00&lt;00:00,  1.38it/s]"
     }
    },
    "c7cb034c107247cba318475c9952b4ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8a7a19edb074139baefe21f1901d4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cdbf6aefee644006826f76e2f6722b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65d16c05424c4df0b79b5786be8bd5d1",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72a8b4ea52534d4e9feab6c6fdd72a77",
      "value": 2
     }
    },
    "ce26114873ed4c96b5ea391a41b18f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f856d468c8a4c4c9c83b5b263745508",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a3f361a320f480aa8a4115366073d32",
      "value": 2
     }
    },
    "d1cd0285cfe34f188e9c779617d48448": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d240d13622c14726a5639d44ef2421ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44650208feba4c118904c7efc9887532",
      "placeholder": "​",
      "style": "IPY_MODEL_e7be4ec44f2a4183b295f486e250b414",
      "value": "100%"
     }
    },
    "d76610cad4f645f187b26f1b82733569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfb4641da88e47d3bafabbaa56bc6916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8554928c5f141de8dfb94c04c2dda03",
      "placeholder": "​",
      "style": "IPY_MODEL_b28fa99d1b1b4e4da668bcc50373e4cc",
      "value": " 2/2 [00:01&lt;00:00,  1.11it/s]"
     }
    },
    "e032f2bf0bb241c2911087a6efe1ce0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d74dcf5002c4752af12a65c3aca2113",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ad701d95f084c98bd1bf0e9d7d498a9",
      "value": 143
     }
    },
    "e48e5c946462499ab018748ccf80c5b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7be4ec44f2a4183b295f486e250b414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef004a834af944abbd512fa3218642a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f319feca977544738ff2400ab23a9276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9815ec90f12a4696a85db6dc629ec62a",
       "IPY_MODEL_e032f2bf0bb241c2911087a6efe1ce0b",
       "IPY_MODEL_19783f5141cb47f8aaa057fb01dda913"
      ],
      "layout": "IPY_MODEL_26b1a86ee1ff4ce2862c13d47be2b2d6"
     }
    },
    "f39640d290374992aa246753125a91de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5292a911912d43c2b80919e486b99de9",
       "IPY_MODEL_ce26114873ed4c96b5ea391a41b18f68",
       "IPY_MODEL_bec237aed5184115b697ea257f7b0c9b"
      ],
      "layout": "IPY_MODEL_410c3733ee43430eb55278748d07bc45"
     }
    },
    "fc3c6209df394eefa2df9ce8dbb56830": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d240d13622c14726a5639d44ef2421ec",
       "IPY_MODEL_9e66574c8c0343ffb0477891bfe5e892",
       "IPY_MODEL_219090e2dd934c1296f12660ea69b161"
      ],
      "layout": "IPY_MODEL_3fb5b968d9ab4e88964b6b126c6023d9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
