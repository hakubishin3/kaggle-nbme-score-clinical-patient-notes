{"cells":[{"cell_type":"markdown","metadata":{"id":"national-fancy"},"source":["## References"],"id":"national-fancy"},{"cell_type":"markdown","metadata":{"id":"copyrighted-centre"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"],"id":"copyrighted-centre"},{"cell_type":"markdown","metadata":{"id":"imported-offset"},"source":["## Configurations"],"id":"imported-offset"},{"cell_type":"code","execution_count":1,"metadata":{"id":"complimentary-wyoming","executionInfo":{"status":"ok","timestamp":1650543975500,"user_tz":-540,"elapsed":13,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp091\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"],"id":"complimentary-wyoming"},{"cell_type":"code","source":["%env TOKENIZERS_PARALLELISM=true"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y03AHjwJAlGL","executionInfo":{"status":"ok","timestamp":1650543975500,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"07929de9-8767-47b0-a930-7b6c6eafcbf6"},"id":"Y03AHjwJAlGL","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["env: TOKENIZERS_PARALLELISM=true\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"allied-circuit","executionInfo":{"status":"ok","timestamp":1650543975501,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-v3-large\"\n","    tokenizer=None\n","    max_len=None\n","    #pseudo_plain_path='../output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl'\n","    pseudo_plain_path=\"./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\"\n","    n_pseudo_labels=100000\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    alpha=1\n","    gamma=2\n","    smoothing=0.0001\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=1\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"],"id":"allied-circuit"},{"cell_type":"code","execution_count":4,"metadata":{"id":"geographic-hindu","executionInfo":{"status":"ok","timestamp":1650543975501,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"],"id":"geographic-hindu"},{"cell_type":"markdown","metadata":{"id":"confident-fifth"},"source":["## Directory Settings"],"id":"confident-fifth"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miniature-greeting","outputId":"88540c5c-9df5-49aa-ff84-c9fca832af85","executionInfo":{"status":"ok","timestamp":1650544012999,"user_tz":-540,"elapsed":37507,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Mounted at /content/drive\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 14.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 49.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 72.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 76.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.16.2\n","\u001b[K     |████████████████████████████████| 1.2 MB 16.5 MB/s \n","\u001b[?25h"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","    !pip install -q sentencepiece==0.1.96\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"],"id":"miniature-greeting"},{"cell_type":"code","source":["# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n","# This must be done before importing transformers\n","import shutil\n","from pathlib import Path\n","\n","if CFG.env == \"colab\":\n","    input_dir = Path(\"./drive/MyDrive/00.kaggle/input/deberta-v2-3-fast-tokenizer\")\n","    transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","else:\n","    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n","    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)\n","    \n","    \n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"],"metadata":{"id":"nMFg9zv8YGcx","executionInfo":{"status":"ok","timestamp":1650544023480,"user_tz":-540,"elapsed":10488,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"nMFg9zv8YGcx","execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"guilty-filename","executionInfo":{"status":"ok","timestamp":1650544023989,"user_tz":-540,"elapsed":513,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"id":"guilty-filename"},{"cell_type":"markdown","metadata":{"id":"cubic-designation"},"source":["## Utilities"],"id":"cubic-designation"},{"cell_type":"code","execution_count":8,"metadata":{"id":"opposite-plasma","executionInfo":{"status":"ok","timestamp":1650544023989,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"],"id":"opposite-plasma"},{"cell_type":"code","execution_count":9,"metadata":{"id":"multiple-poland","executionInfo":{"status":"ok","timestamp":1650544023990,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        # result = np.where(char_prob >= th)[0] + 1\n","        result = np.where(char_prob >= th)[0]\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        # result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = [f\"{min(r)} {max(r) + 1}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5, use_token_prob=True):\n","    labels = create_labels_for_scoring(df)\n","\n","    if use_token_prob:\n","        token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","        char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    else:\n","        char_probs = df[[str(i) for i in range(CFG.max_char_len)]].values\n","        char_probs = [char_probs[i] for i in range(len(char_probs))]\n","\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"],"id":"multiple-poland"},{"cell_type":"code","execution_count":10,"metadata":{"id":"seventh-fighter","executionInfo":{"status":"ok","timestamp":1650544023990,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"id":"seventh-fighter"},{"cell_type":"code","execution_count":11,"metadata":{"id":"fifty-boundary","executionInfo":{"status":"ok","timestamp":1650544023990,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"],"id":"fifty-boundary"},{"cell_type":"code","source":["def postprocess(texts, preds):\n","    fix_tokenize_dict = {\n","        'heart': ['h', 'eart'],\n","        'hair': ['h', 'air'],\n","        'adderal': ['a', 'dderal'],\n","        'mother': ['m', 'other'],\n","        'intermittent': ['i', 'ntermittent'],\n","        'temperature': ['t', 'emperature'],\n","        'episodes': ['e', 'pisodes'],\n","        'no': ['n', 'o'],\n","        'has': ['h', 'as'],\n","        'LMP': ['L', 'MP'],\n","        '10': ['1', '0'],\n","        'blood': ['b', 'lood'],\n","        'recurrent': ['r', 'ecurrent'],\n","        'denies': ['d', 'enies'],\n","        'sudden': ['s', 'udden'],\n","        'Sexually': ['S', 'exually'],\n","        'up': ['u', 'p'],\n","        'wakes': ['w', 'akes'],\n","        'sweats': ['s', 'weats'],\n","        'hot': ['h', 'ot'],\n","        'drenched': ['d', 'renched'],\n","        'gnawing': ['g', 'nawing'],\n","        'Uses': ['U', 'ses'],\n","        'Begin': ['B', 'egin'],\n","        'Nausea': ['N', 'ausea'],\n","        'Burning': ['B', 'urning'],\n","        'Started': ['S', 'tarted'],\n","        'neurvousness': ['n', 'eurvousness'],\n","        'constipation': ['c', 'onstipation'],\n","        'nervousness': ['n', 'ervousness'],\n","        'cold': ['c', 'old'],\n","        'loss': ['l', 'oss'],\n","        'CBC': ['C', 'BC'],\n","        'Hx': ['H', 'x'],\n","        'tingling': ['t', 'ingling'],\n","        'feels': ['f', 'eels'],\n","        'Lost': ['L', 'ost'],\n","        'she': ['s', 'he'],\n","        'racing': ['r', 'acing'],\n","        'throat': ['t', 'hroat'],\n","        'PATIENT': ['P', 'ATIENT'],\n","        'recreational': ['r', 'ecreational'],\n","        'clammy': ['c', 'lammy'],\n","        'numbness': ['n', 'umbness'],\n","        'like': ['l', 'ike'],\n","        'reports': ['r', 'eports'],\n","        'exercise': ['e', 'xercise'],\n","        'started': ['s', 'tarted'],\n","        'brough': ['b', 'rough'],\n","        'Associated': ['A', 'ssociated'],\n","        'exacerbated': ['e', 'xacerbated'],\n","        'sharp': ['s', 'harp'],\n","        'cannot': ['c', 'annot'],\n","        'heavy': ['h', 'eavy'],\n","        'fatigue': ['f', 'atigue'],\n","        'trouble': ['t', 'rouble'],\n","        'hearing': ['h', 'earing'],\n","        'reduced': ['r', 'educed'],\n","        'lack': ['l', 'ack'],\n","        'vomiting': ['v', 'omiting'],\n","        'generalized': ['g', 'eneralized'],\n","        'body': ['b', 'ody'],\n","        'all': ['a', 'll'],\n","        'scratchy': ['s', 'cratchy'],\n","        'mom': ['m', 'om'],\n","        'discomfort': ['d', 'iscomfort'],\n","        'CAD': ['C', 'AD'],\n","        'Thyroid': ['T', 'hyroid'],\n","        'BLADDER': ['B', 'LADDER'],\n","        'diarrhea': ['d', 'iarrhea'],\n","        'Started': ['S', 'tarted'],\n","        'Vaginal': ['V', 'aginal'],\n","        'sleeping': ['s', 'leeping'],\n","        'UNCLE': ['U', 'NCLE'],\n","        'USING': ['U', 'SING'],\n","        'BURNING': ['B', 'URNING'],\n","        'GETTING': ['G', 'ETTING'],\n","        'ETOH': ['E', 'TOH'],\n","        'ON': ['O', 'N'],\n","        'INITIALLY': ['I', 'NITIALLY'],\n","        'epigastric': ['e', 'pigastric'],\n","        'occurs': ['o', 'ccurs'],\n","        'began': ['b', 'egan'],\n","        'alleviated': ['a', 'lleviated'],\n","        'overwhelmed': ['o', 'verwhelmed'],\n","        'clamminess': ['c', 'lamminess'],\n","        'strongly': ['s', 'trongly'],\n","        'lump': ['l', 'ump'],\n","        'drugs': ['d', 'rugs'],\n","        'chest': ['c', 'hest'],\n","        'stuffy': ['s', 'tuffy'],\n","        'changes': ['c', 'hanges'],\n","        'trouble': ['t', 'rouble'],\n","        'takes': ['t', 'akes'],\n","        'tossing': ['t', 'ossing'],\n","        'Fam': ['F', 'am'],\n","        'sweating': ['s', 'weating'],\n","        'dyspareunia': ['d', 'yspareunia'],\n","        'irregular': ['i', 'rregular'],\n","        'time': ['t', 'ime'],\n","        'unpredictable': ['u', 'npredictable'],\n","        'darkened': ['d', 'arkened'],\n","        'anxiety': ['a', 'nxiety'],\n","        'nervous': ['n', 'ervous'],\n","        'TAKING': ['T', 'AKING'],\n","        'losing': ['l', 'osing'],\n","        'Difficulyt': ['D', 'ifficulyt'],\n","        'Appetite': ['A', 'ppetite'],\n","        'increased': ['i', 'ncreased'],\n","        'fingers': ['f', 'ingers'],\n","        'illicit': ['i', 'llicit'],\n","        'claminess': ['c', 'laminess'],\n","        'clamy': ['c', 'lamy'],\n","        'Recently': ['R', 'ecently'],\n","        'feeling': ['f', 'eeling'],\n","        'aggrav': ['a', 'ggrav'],\n","        'changing': ['c', 'hanging'],\n","        'unable': ['u', 'nable'],\n","        'SEEING': ['S', 'EEING'],\n","        'staying': ['s', 'taying'],\n","        'lightheadedness': ['l', 'ightheadedness'],\n","        'lighheadeness': ['l', 'ighheadeness'],\n","        'nail': ['n', 'ail'],\n","        'pounding': ['p', 'ounding'],\n","        'My': ['M', 'y'],\n","        'Father': ['F', 'ather'],\n","        'urinary': ['u', 'rinary'],\n","        'pain': ['p', 'ain'],\n","        'not': ['n', 'ot'],\n","        'lower': ['l', 'ower'],\n","        'menses': ['m', 'enses'],\n","        'at': ['a', 't'],\n","        'takes': ['t', 'akes'],\n","        'initally': ['i', 'nitally'],\n","        'melena': ['m', 'elena'],\n","        'BOWEL': ['B', 'OWEL'],\n","        'WEIGHT': ['W', 'EIGHT'],\n","        'difficulty': ['d', 'ifficulty'],\n","        'condo': ['c', 'ondo'],\n","        'experiences': ['e', 'xperiences'],\n","        'stuffy': ['s', 'tuffy'],\n","        'rhinorrhea': ['r', 'hinorrhea'],\n","        'felt': ['f', 'elt'],\n","        'feverish': ['f', 'everish'],\n","        'CYCLE': ['C', 'YCLE'],\n","        'tampon': ['t', 'ampon'],\n","        'Last': ['L', 'ast'],\n","        'Son': ['S', 'on'],\n","        'saw': ['s', 'aw'],\n","        'tightness': ['t', 'ightness'],\n","        'rash': ['r', 'ash'],\n","        'ibuprofen': ['i', 'buprofen'],\n","        'SCRATHY': ['S', 'CRATHY'],\n","        'PHOTOPHOBIA': ['P', 'HOTOPHOBIA'],\n","    }\n","    preds_pp = preds.copy()\n","    tk0 = tqdm(range(len(preds_pp)), total=len(preds_pp))\n","    for raw_idx in tk0:\n","        pred = preds[raw_idx]\n","        text = texts[raw_idx]\n","        if len(pred) != 0:\n","            # pp1: indexが1から始まる予測値は0から始まるように修正 ## 0.88579 -> 0.88702\n","            if pred[0][0] == 1:\n","                preds_pp[raw_idx][0][0] = 0\n","            for p_index, pp in enumerate(pred):\n","                start, end = pred[p_index]\n","                # pp2: startとendが同じ予測値はstartを前に１ずらす ## 0.88702 -> 0.88714\n","                if start == end:\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp3: 始点が改行の場合始点を1つ後ろにずらす ## 0.88714 -> 0.88746\n","                if text[start] == '\\n':\n","                    preds_pp[raw_idx][p_index][0] = start + 1\n","                    start = start + 1\n","                # pp4: 1-2などは-2で予測されることがあるので修正 ## 0.88746 -> 0.88747\n","                if text[start-1].isdigit() and text[start] == '-' and text[start+1].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-1].isdigit() and text[start] == '/' and text[start+1].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp5: 67などは7で予測されることがあるので修正 ## 0.88747 -> 0.88748\n","                if text[start-1].isdigit() and text[start].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp6: 文頭が大文字で始まるものは大文字部分が除かれて予測されることがあるので修正 ## 0.88748 -> 0.88761\n","                if text[start-2] == '.' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == ',' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == ':' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == '-' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp7: heart -> h + eart となっているようなものを修正する ## 0.88761 -> 0.88806\n","                for key, fix_tokenize in fix_tokenize_dict.items():\n","                    _s, s = fix_tokenize[0], fix_tokenize[1]\n","                    if text[start-1].lower() == _s.lower() and text[start:start+len(s)].lower() == s.lower():\n","                        preds_pp[raw_idx][p_index][0] = start - 1\n","                        start = start - 1\n","    return preds_pp"],"metadata":{"id":"w7OU047YE4Jh","executionInfo":{"status":"ok","timestamp":1650544024818,"user_tz":-540,"elapsed":832,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"w7OU047YE4Jh","execution_count":12,"outputs":[]},{"cell_type":"code","source":["def get_results_from_preds_list(preds):\n","    results = []\n","    for pred in preds:\n","        s = []\n","        for p in pred:\n","            s.append(' '.join(list(map(str, p))))\n","        s = ';'.join(s)\n","        results.append(s)\n","    return results"],"metadata":{"id":"Tml-r1DPE4Qd","executionInfo":{"status":"ok","timestamp":1650544024819,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"Tml-r1DPE4Qd","execution_count":13,"outputs":[]},{"cell_type":"code","source":["def trunc_pred(texts, preds):\n","    preds_pp = preds.copy()\n","    tk0 = tqdm(range(len(preds_pp)), total=len(preds_pp))\n","    for raw_idx in tk0:\n","        text = texts[raw_idx]\n","        num_text = len(text)\n","        preds_pp[raw_idx, num_text:] = 0\n","    return preds_pp"],"metadata":{"id":"SpxoIpdsE4Wk","executionInfo":{"status":"ok","timestamp":1650544024819,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"SpxoIpdsE4Wk","execution_count":14,"outputs":[]},{"cell_type":"code","source":["def create_label(pn_history, location_list, max_char_len):\n","    label = np.zeros(max_char_len)\n","    label[len(pn_history):] = -1\n","    if len(location_list) > 0:\n","        for location in location_list:\n","            start, end = int(location[0]), int(location[1])\n","            label[start:end] = 1\n","    return label\n","\n","def get_preds_from_results(results, texts, max_char_len):\n","    labels = []\n","    for idx, result in enumerate(results):\n","        label = create_label(texts[idx], result, max_char_len)\n","        labels.append(label)\n","    labels = np.stack(labels)\n","    print(labels.shape)\n","    return labels"],"metadata":{"id":"5xKwuaAvE4Zn","executionInfo":{"status":"ok","timestamp":1650544024819,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"5xKwuaAvE4Zn","execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unlimited-hotel"},"source":["## Data Loading"],"id":"unlimited-hotel"},{"cell_type":"code","execution_count":16,"metadata":{"id":"classical-machine","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650544026594,"user_tz":-540,"elapsed":1779,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"76d5752e-c55f-4dc4-a076-6629512cab0a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":16}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"],"id":"classical-machine"},{"cell_type":"code","execution_count":17,"metadata":{"id":"vanilla-iceland","executionInfo":{"status":"ok","timestamp":1650544026964,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"],"id":"vanilla-iceland"},{"cell_type":"markdown","metadata":{"id":"convenient-plant"},"source":["## Preprocessing"],"id":"convenient-plant"},{"cell_type":"code","execution_count":18,"metadata":{"id":"convertible-thunder","executionInfo":{"status":"ok","timestamp":1650544026964,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"],"id":"convertible-thunder"},{"cell_type":"code","source":["features['feature_text'] = features['feature_text'].str.lower()\n","patient_notes['pn_history'] = patient_notes['pn_history'].str.lower()"],"metadata":{"id":"a7YBS_idYKtL","executionInfo":{"status":"ok","timestamp":1650544026965,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"a7YBS_idYKtL","execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"charitable-memphis","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650544026965,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"4232e57a-52a3-4fd2-e977-02e2c766212b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":20}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"],"id":"charitable-memphis"},{"cell_type":"code","execution_count":21,"metadata":{"id":"governing-election","executionInfo":{"status":"ok","timestamp":1650544027341,"user_tz":-540,"elapsed":381,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"],"id":"governing-election"},{"cell_type":"code","execution_count":22,"metadata":{"id":"negative-provincial","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1650544027341,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"cc2be62c-15fc-4dd9-e33e-c0b2eb781ef6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"],"id":"negative-provincial"},{"cell_type":"markdown","metadata":{"id":"arbitrary-beatles"},"source":["## CV split"],"id":"arbitrary-beatles"},{"cell_type":"code","execution_count":23,"metadata":{"id":"important-murray","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1650544027342,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"cf477991-f39f-4e81-96a1-4d9eb8cb9e2b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"],"id":"important-murray"},{"cell_type":"markdown","metadata":{"id":"configured-chemistry"},"source":["## Setup tokenizer"],"id":"configured-chemistry"},{"cell_type":"code","execution_count":24,"metadata":{"id":"hindu-contest","colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["2e29102c1f084856a5c7d70cdb6e37dc","772655b1f4c44befac43db54fcaf9d16","16ff0f4257c443ed967d2e550d3cddaa","256d535f774a40d6addf28feb2eaf147","e453e8d0cb9c4c799ba550a1595f11a2","0637e3b056c24fcc86b63969c81d7cb3","626dc5ef22e54667830854d8fb280592","ec2d9cf22b464c8da472f11d90d4c662","1848a6ab3c3841d9a8840df1e6106553","d7fe60fce5944324989d6ca00fb5e98b","8990b2fddc724af09137b591ee53f53a","62125de880c94419ad986cae52cebb65","7ba699e87d4147ed8151e48fe00ec754","0748c2873815467bb90ad91db89404b8","97173d2d810f49b2b25514f3db12af87","8bf4e88c35d94a3bbad5b76ee0c845e7","6ddb81acb87d4c2a91467bbb1a7f86c0","2a864544a81f4768bfaed0cff22e3f2c","fe16a92601f44c0aafadd190b13760e9","3634d42d4fb74684a64ee41b3c911c90","802d1c37647e45e7bc39b2e56ec13550","ac76267778dc4310bbff31eed2546a44","bc8fd650057149fcbbd62e3bdaf45860","0c656a7343a746f28af832e64bcb6abb","487c4fc3b7254258a0b0a17cf85fc1ae","ab1d695f112b4fd9a19c1742593c896f","3edacfc1f35748d6b8a152ff119c8d0e","68080b44fc514b2abfbd56e33acffb0e","c32b540da97d42a58be41c6fd965b435","051df790fbe64d6186e6836c396f9060","69ec916786ee44fd855b7bbb9927519d","babd5ac477fb4a9fa742d4bdc8472400","a59ef9241ec249e3bbcc99b35e609640"]},"executionInfo":{"status":"ok","timestamp":1650544032515,"user_tz":-540,"elapsed":5180,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"d64dbeb4-ffc2-46f4-9db3-a8fd65fdd04f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e29102c1f084856a5c7d70cdb6e37dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62125de880c94419ad986cae52cebb65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc8fd650057149fcbbd62e3bdaf45860"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["if CFG.submission:\n","    tokenizer = DebertaV2TokenizerFast.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"],"id":"hindu-contest"},{"cell_type":"markdown","metadata":{"id":"alleged-protein"},"source":["## Create dataset"],"id":"alleged-protein"},{"cell_type":"code","execution_count":25,"metadata":{"id":"composed-stroke","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["489bfb7c69c34bf983ebcaa2022498d5","bc1e85d52e5e490382f9b501cdd0f847","b3d7c1ce6e7b41eb9040a78024e950b6","d4fb80326dbb4632a888686a10ce0fd9","d488a8bf759d4484b7688d61c96c2e3f","3282e780d837477a9d9eb56c32e2fddb","ee231ab6a90444c98e0dadcea93a6d05","29eff1ad2d9a42629bca0be6d98d997d","8e5279aa3ec44baeafbfe15eed6c00d8","37a37d3de665420c93163c8f537db832","fc07f6aba3ce49eeaf36f1fc7f4d98ee"]},"executionInfo":{"status":"ok","timestamp":1650544056214,"user_tz":-540,"elapsed":23714,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"0f8a48f8-4dde-40d3-e41c-b9daae097400"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"489bfb7c69c34bf983ebcaa2022498d5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 284\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"],"id":"composed-stroke"},{"cell_type":"code","execution_count":26,"metadata":{"id":"emotional-region","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["f8d8973fe3584412b61224b0a002a60c","1aec2a9db2ad4ddaa975a5e0241901c9","2ccdce156a3e4855ac1f95c9094ca400","430616d568a94a1ab0536740b8f203dd","881c2f1bfde047149e8c1f8c44770e7a","853d19f0f0c540a3ab902c4873df83df","f50d5a1351fd4cbebce985582a3e3109","cf47ecbcbc8b4c1d84a3ebd65de101fd","f73b43f8803d4df3aa0c9f0be5656509","ba0b8b5d17b14473b977aeb8c7e94919","f31885063b5d440c888caa1d2861cbef"]},"executionInfo":{"status":"ok","timestamp":1650544056215,"user_tz":-540,"elapsed":15,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"3e3c7a46-5da4-4955-d52e-21db11724c08"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d8973fe3584412b61224b0a002a60c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 28\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"],"id":"emotional-region"},{"cell_type":"code","execution_count":27,"metadata":{"id":"wrong-leisure","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650544056215,"user_tz":-540,"elapsed":13,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"a338a680-a2c9-40f3-bd2b-c972b998c4fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 315\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"],"id":"wrong-leisure"},{"cell_type":"code","execution_count":28,"metadata":{"id":"convenient-gospel","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["db048ff502264cb8b4828e7fbf485ce2","66b32316e9734eeebc642562e95c7d1b","dbf8a0792ca04b9b8b674cb76178e0f3","7bb64d92d8be42ccb6fc2ec0e61f5f37","62ca5df9080d4bb6abce4553182caf6f","a709a7633bba4c879b0345eb6898c9f8","e1cb91b47d4541abade15ec0e028f9ca","e3181ffc60d44b5abba79bc06ef3b83b","12cb9a77e4444fc194fc5dfe60f08635","530e6f820336414c8b3fdbaff29aa672","feb96e5db0b345e49dcdc4db31d9dce1"]},"executionInfo":{"status":"ok","timestamp":1650544056216,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"8ae09c1a-cd97-4a2e-bba5-e378ee5f70a7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db048ff502264cb8b4828e7fbf485ce2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 950\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(text)\n","    pn_history_lengths.append(length)\n","\n","CFG.max_char_len = max(pn_history_lengths)\n","\n","print(\"max length:\", CFG.max_char_len)"],"id":"convenient-gospel"},{"cell_type":"code","execution_count":29,"metadata":{"id":"representative-contributor","executionInfo":{"status":"ok","timestamp":1650544056216,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df, pseudo_label=None):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.max_char_len = self.cfg.max_char_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","        if \"pseudo_idx\" in df.columns:\n","            self.pseudo_idx = self.df[\"pseudo_idx\"].values\n","            self.pseudo_label = pseudo_label\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        label = np.zeros(self.max_char_len)\n","        label[len(pn_history):] = -1\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    label[start:end] = 1\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        if not np.isnan(self.annotation_lengths[idx]):\n","            label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        else:\n","            p_idx = int(self.pseudo_idx[idx])\n","            label = torch.tensor(self.pseudo_label[p_idx], dtype=torch.float)\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, label, mapping_from_token_to_char"],"id":"representative-contributor"},{"cell_type":"code","execution_count":30,"metadata":{"id":"decent-johnson","executionInfo":{"status":"ok","timestamp":1650544056216,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.max_char_len = self.cfg.max_char_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, mapping_from_token_to_char"],"id":"decent-johnson"},{"cell_type":"markdown","metadata":{"id":"arctic-joint"},"source":["## Model"],"id":"arctic-joint"},{"cell_type":"code","source":["from transformers.modeling_outputs import MaskedLMOutput\n","\n","class MaskedModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(\n","                cfg.pretrained_model_name,\n","                output_hidden_states=False\n","                )\n","        else:\n","            self.config = torch.load(config_path)\n","        \n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.pretrained_model_name, config=self.config)\n","            self.lm_head = AutoModelForMaskedLM.from_pretrained(cfg.pretrained_model_name, config=self.config).cls # [cls, lm_head]\n","        else:\n","            self.model = AutoModel(self.config)\n","            self.lm_head = AutoModelForMaskedLM(self.config).cls # [cls, lm_head]\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(\n","            self, \n","            input_ids=None,\n","            attention_mask=None,\n","            token_type_ids=None,\n","            #position_ids=None,\n","            inputs_embeds=None,\n","            labels=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None):\n","        \n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            #position_ids=position_ids,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,)\n","        \n","        sequence_output = outputs[0]\n","        prediction_scores = self.lm_head(sequence_output)\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n","\n","        return MaskedLMOutput(loss=masked_lm_loss,\n","                              logits=prediction_scores,\n","                              hidden_states=outputs.hidden_states,\n","                              attentions=outputs.attentions)"],"metadata":{"id":"qTRu8eKOTlcX","executionInfo":{"status":"ok","timestamp":1650544056217,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"qTRu8eKOTlcX","execution_count":31,"outputs":[]},{"cell_type":"code","source":["class Exp090Model(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            self.backbone = AutoModel.from_config(self.model_config)\n","            # itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            # state_dict = torch.load(path)\n","            # itpt.load_state_dict(state_dict)\n","            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp073/microsoft-deberta-v3-large-mlm-epoch-12.bin\")\n","            #masked_model = MaskedModel(CFG, config_path=None, pretrained=True)\n","            #state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            #masked_model.load_state_dict(state)\n","            #self.backbone = masked_model.model\n","            #print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"],"metadata":{"id":"OJt_cHeyTmDS","executionInfo":{"status":"ok","timestamp":1650544056784,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"id":"OJt_cHeyTmDS","execution_count":32,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"id":"alternative-malawi","executionInfo":{"status":"ok","timestamp":1650544056784,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False, i_fold=None):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","\n","            model = Exp090Model(cfg, model_config_path=None, pretrained=False)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp090\" /  f\"fold{i_fold}_best.pth\")\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            self.backbone = model.backbone\n","            print(f\"Load weight from {path}\")\n","\n","        self.lstm = nn.GRU(\n","            input_size=self.model_config.hidden_size,\n","            bidirectional=True,\n","            hidden_size=self.model_config.hidden_size // 2,\n","            num_layers=4,\n","            dropout=self.cfg.dropout,\n","            batch_first=True,\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs, mappings_from_token_to_char):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]  # [batch, seq_len, d_model]\n","        mappings_from_token_to_char = mappings_from_token_to_char.unsqueeze(2).expand(-1, -1, self.model_config.hidden_size)\n","        h = torch.gather(h, 1, mappings_from_token_to_char)    # [batch, seq_len, d_model]\n","        h, _ = self.lstm(h)\n","        output = self.fc(h)\n","\n","        return output"],"id":"alternative-malawi"},{"cell_type":"markdown","metadata":{"id":"therapeutic-assembly"},"source":["## Training"],"id":"therapeutic-assembly"},{"cell_type":"code","execution_count":34,"metadata":{"id":"going-conversion","executionInfo":{"status":"ok","timestamp":1650544056784,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"],"id":"going-conversion"},{"cell_type":"code","execution_count":35,"metadata":{"id":"alleged-commonwealth","executionInfo":{"status":"ok","timestamp":1650544056785,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","    \n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"],"id":"alleged-commonwealth"},{"cell_type":"code","execution_count":36,"metadata":{"id":"middle-determination","executionInfo":{"status":"ok","timestamp":1650544056785,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for (inputs, mappings_from_token_to_char) in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.no_grad():\n","            output = model(inputs, mappings_from_token_to_char)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"],"id":"middle-determination"},{"cell_type":"code","execution_count":37,"metadata":{"id":"familiar-participation","executionInfo":{"status":"ok","timestamp":1650544056785,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    if CFG.pseudo_plain_path is not None:\n","        pseudo_plain = pd.read_pickle(CFG.pseudo_plain_path)\n","        print(f\"get pseudo plain from {CFG.pseudo_plain_path}\")\n","        pseudo_label_list = []\n","        weights = [0.4433659049657008, 0.20859987143371844, 0.3480342236005807]\n","        for exp_name in [\"nbme-exp060\", \"nbme-exp067\", \"nbme-exp083\"]:\n","            pseudo_label_path = f'./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/{exp_name}/pseudo_labels_{i_fold}.npy'\n","            #pseudo_label_path = f'../output/nbme-score-clinical-patient-notes/{exp_name}/pseudo_labels_{i_fold}.npy'\n","            pseudo_label = np.load(pseudo_label_path)\n","            print(f\"get pseudo labels from {pseudo_label_path}\")\n","            pseudo_label_list.append(pseudo_label)\n","\n","        pseudo_label = weights[0] * pseudo_label_list[0] + weights[1] * pseudo_label_list[1] + weights[2] * pseudo_label_list[2]\n","        pseudo_label = trunc_pred(pseudo_plain[\"pn_history\"].values, pseudo_label)\n","        predicted_location_str = get_predicted_location_str(pseudo_label, th=0.5)\n","        preds = get_predictions(predicted_location_str)\n","        results_postprocess = postprocess(pseudo_plain[\"pn_history\"].values, preds)\n","        #results_postprocess = get_results_from_preds_list(results_postprocess)\n","        pseudo_label = get_preds_from_results(results_postprocess, pseudo_plain[\"pn_history\"].values, pseudo_label.shape[1])\n","        print(pseudo_plain.shape, pseudo_label.shape)\n","\n","        pseudo_plain['feature_text'] = pseudo_plain['feature_text'].str.lower()\n","        pseudo_plain['pn_history'] = pseudo_plain['pn_history'].str.lower()\n","\n","        pseudo_plain[\"pseudo_idx\"] = np.arange(len(pseudo_plain))\n","        pseudo_plain = pseudo_plain.sample(n=CFG.n_pseudo_labels)\n","        print(pseudo_plain.shape)\n","        train_folds = pd.concat([train_folds, pseudo_plain], axis=0, ignore_index=True)\n","        print(train_folds.shape)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds, pseudo_label)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False, i_fold=i_fold)\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    # freeze\n","    for param in model.backbone.parameters():\n","        param.requires_grad = False\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_char_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5, use_token_prob=False)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_char_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"],"id":"familiar-participation"},{"cell_type":"markdown","metadata":{"id":"coated-cameroon"},"source":["## Main"],"id":"coated-cameroon"},{"cell_type":"code","execution_count":38,"metadata":{"id":"quality-expansion","executionInfo":{"status":"ok","timestamp":1650544056786,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    best_thres = 0.5\n","    best_score = 0.\n","    for th in np.arange(0.45, 0.55, 0.01):\n","        th = np.round(th, 2)\n","        score = scoring(oof_df, th=th, use_token_prob=False)\n","        if best_score < score:\n","            best_thres = th\n","            best_score = score\n","    print(f\"best_thres: {best_thres}  score: {best_score:.5f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            print(f\"load weights from {path}\")\n","            test_char_probs = inference_fn(test_dataloader, model, device)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_char_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"],"id":"quality-expansion"},{"cell_type":"code","execution_count":39,"metadata":{"id":"proprietary-civilian","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["098dfb21f7764ad79da1bb7846b58a7f","6f08575c65cb4d5b8d4d83a322ace46f","0d9350a9e6954c9e9c738c76a008ebd4","6a19b5e02cc24507b52fe8ade73fd132","a5b413f76e6347b2a769d51faa019d30","9b5de7c54a2845e58e5510e0d5f77773","db74cb5d088b4f8e9eba6b1b1829aea4","09edcee4ce5442dea094378efd41cfc7","83e95c5c59df411e9aaf7ba3d04e69c9","44cef72fb618493dbabe421c7df7a32f","7ca1bdf75319467fbd885569629f66a9","d717a406bb464c2987e24b0fee894044","32eee585b56847968a5b78fdebad22a7","746452a82a364d20add829d22ba0ece1","f914c533ac3e4c2ca148736d7e9b82d6","8b71d09d2e2f4c0aa3378300c35e3b4a","d0d15ed6ea3b42f593039f4ed232c8d5","b0bdfcb89fe040b4ab5a328ed8a728cc","ffdba6e0f7fb4baab81b7e3c817ac056","4929f62c055e4d11a2dd29ced499c868","828e2a35c3114ceba67ab887e1eb1c82","450c9eed30184bf38d3d29af7538ab8b","8692487d106a4c07a661a60ba5869bb0","c378314ed8b547da9d17c93f3248cb61","78b4080fa2be4e2ebfeac790cddc9e04","03a5ab3e54a843b693ae63e42bbb17c8","158d08b04b0046c1942836c1cb799062","7f00b4453db141a086f636dd1df6327e","94c328987a2e4eb0b0e5e72aece4d6c8","b0109ab201ee40539c036dddcccb220a","e6d317f8e9b0450e94f35a70248487e6","c69605df2ee6464cb9b7c20612be7bac","6843e9b50b2c490fb6f1201263191ceb","193ecba780d44d45a9bae3de377fc057","b7ac480071a44f07866dcd6b878a0224","67185274cea2499b914f023fbdd284ad","0dc64dacbf9a45f4b5106adedab197a1","4b30c0420c3e43b1babccd5e156a6bf5","da30992f5c694ac7920803e22eeb83cf","c64ad7f4dafe44c289341a61ee4a6270","37a01705794c4ccb86295169910b83bf","f0afcaf996724cb0a42b21fbc04dffc6","ac3aeea92944471c96329743cc522541","0dbf2371424c49619cedb4e125c2a16d","f2dd1f825d69486c8a77560365754ae5","48a4f61554354e2a8820fac432d0f2fa","fff25bd2498e4ab8ac71975cca373e2f","20efeef1318641579aa124645aa90696","f41c6ec0bb674f22858f9debb65b0ae4","b9e99b8fdb5c40638535767789b1dd33","60e49c9c7999448b88bd402c6ac62c6a","efcc0df46f774015806bdb49c3441e1c","dd8af70e33854c1f9585186d140727c7","eba418bd23ec41949940c04292aebc9f","d91e95e82fdd4850bdcc22f5eb9e2cd7","4e6ca0edd2e646889ddb4f46a94e6cd2","d39c495e737549d2aba9cda52e717128","8e797f712786450b9ad82b24342887d2","d8d5e521942545b8b1a033de9e03fcb2","6e01e48c7181431c9a185d123a1c5e23","3a70b81b6a5a41b894954d3a67643ae7","de02db17ca9e4756b2d7570925fbb878","5e0aeb17cce246298ddc411911ad610f","358528ea916747be986927acd7b558c8","d0e8cfeb3d3c4e1a97f22edbb047e932","48acb2c7a41d418d861b0efff1555344","e1533d738bd64bba90ca5bab036838e6","2f6af6a1c3184519875bb264cd04b40f","4c05554b925c41a0abf609651f3fefc8","0c0c49586eda4fd7ab8ffb4e460453ee","b7cd387c3505410a98e809159b895824","d3a1bef84f9f4d24a3d9a48dbbe3d047","5f6b099a528d4fb5b80781b1a838b372","383d20b015404c768354b37459c48bb8","c11b26e295574af2ae69b45602ed83b9","b96116b8bbde48ca9e937685eb36c45e","b92012b9f0ea404687caf795124867bc","84a8b42da5fd406386892b0b944e90d7","abdfdbe0a04049faac405c42f4f8aa88","62d65c1cee214e1d8bd3e3d947440a65","02e7d0fd370c47dcb6089a7b5eb92209","94e2039af3514952b41ed00367db6501","accc15d61c5644caac442a09f54594e5","eb60c86782ff4184ba591b90ab679ace","72365827fc3047bcbc312f02e56e8fea","ae1ca2fb360646a3be2c3a8e3c318448","4ed4ac01a3d943b88397f44fb312c7ef","4ae7d12353684d21aec12e1931325f21","fef7473534dc4f58ba3ecda136c2f3de","7d7bf5fac80c4532a21108c250d1fdb7","57aadffe9f2d4e90a8f03486ec26a5af","64cc9d92bca14ea7bd5434ffdd3cd703","1e94ec6d10d8480bb2a8f19f02d3239d","ab2160d8e2124e0f88d4c93a55be18a2","eba23fa6e0194ebc8309889ecb4d3919","511a2eb8dda5435d816b5a0fe1d16ba9","0af2993e0e2e4729b679f39f56a14171","b4de986fd5404a4d9bbb58497e076b81","eb1d117d057447109ad549efc42e0db3","79fbb9fa48a3416b9a3a0356829ad534","bdb6f0df88484e549746d626dda77f9d","2dd83abf7cd845c692562e4f00cca019","16a3072cf8414184b570c4a9d5788a1f","390b9875a3294b3696d9f32b8c98129e","05ceb2ae4df341849d60e11b48007166","33556689e77145fbb41685f369c6123b","879e4481cbaa443a87f56c39e418507d","6a72a7d46dad49508fbbef3142f0fe69","8b250cc0e6344c1d9707f8a42b617d75","e6c151fed257488bb416ee894b3a1011","ca09cdb52c2f47e0b288388d73b09db2","bc1c4eb2d281407d9e29c164a7deca71","e458f6a9dd134814920f60555e0e5096","acca7d37fccd4a688c04209dae9d32ba","b2c522dc9c734695811d60bc0f41baf2","215b86de20a940c6bb3be8e9d6ad4a6d","8552c48a0a7a4b46a49c2b6c598d06b2","075e6c0abbc04c8fb0492d0f72414c7f","9779ee8d55584ec19cc6721e67c56454","5efb09bd67cd48228c9ea65075852132","14589ce943fb48c39619b7f37fc0d122","a121eab69bc242e9b731796061a74379","cba4314a72dd41f7a34865143941a386","761c219e7aaf4bbd92bcec61adb972e2","79cdb0fb85434c54ae0a2da78dca7223","1884b95ce00b41a3bf027723629ceab3","2d06325828e8444c811ac2a0baaf61cf","04c8976e836d464d8a4449f13d2396d7","063b4d3c061b4dd1b1c8d467a423ea25","40a610c4a69b4cdda658c96a5ffffe61","e51219f086d143499f07cf70344d3021","89153fe19d8440f8b84df24bff65d235","d1f83b03b75b4d99a20ead8f5c762394","5ef9276485384088860e70fd07ba48a8","7cc77b355aa64020833ce67d5a460742","74bccf559448432db261f613eef2566c","c32c570a83934daeb49201852c9cd31f","cec4884a71fd48d8bd4bfb69a43b34ba","aaeb672105c84aa29329e752c914018d","2e960e5b7145433287c60db53f3c37b8","c5286a4e9aa748babc1845d192860d14","7208c3fc6cf943e6af04ffaf6ab69195","a84b48cb01a94050b580b19df539f441"]},"executionInfo":{"status":"ok","timestamp":1650620492113,"user_tz":-540,"elapsed":76435332,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}},"outputId":"10806ca1-1be3-499b-e731-bf6ae8c5e297"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_0.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_0.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp083/pseudo_labels_0.npy\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098dfb21f7764ad79da1bb7846b58a7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d717a406bb464c2987e24b0fee894044"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(612602, 950)\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","(110725, 11)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp090/fold0_best.pth\n","Epoch: [1][0/36908] Elapsed 0m 1s (remain 698m 1s) Loss: 0.3190(0.3190) Grad: 168659.3906  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 52s (remain 320m 56s) Loss: 0.2888(0.3075) Grad: 152082.6719  LR: 0.000001  \n","Epoch: [1][200/36908] Elapsed 1m 43s (remain 315m 53s) Loss: 0.2053(0.2780) Grad: 116888.4141  LR: 0.000001  \n","Epoch: [1][300/36908] Elapsed 2m 34s (remain 313m 37s) Loss: 0.1148(0.2377) Grad: 66563.5000  LR: 0.000002  \n","Epoch: [1][400/36908] Elapsed 3m 26s (remain 313m 13s) Loss: 0.0482(0.1973) Grad: 26949.1113  LR: 0.000002  \n","Epoch: [1][500/36908] Elapsed 4m 17s (remain 312m 14s) Loss: 0.0157(0.1646) Grad: 7728.7095  LR: 0.000003  \n","Epoch: [1][600/36908] Elapsed 5m 8s (remain 310m 50s) Loss: 0.0112(0.1400) Grad: 4429.2910  LR: 0.000003  \n","Epoch: [1][700/36908] Elapsed 5m 59s (remain 309m 36s) Loss: 0.0081(0.1211) Grad: 2664.0815  LR: 0.000004  \n","Epoch: [1][800/36908] Elapsed 6m 51s (remain 308m 53s) Loss: 0.0023(0.1065) Grad: 1109.6903  LR: 0.000004  \n","Epoch: [1][900/36908] Elapsed 7m 42s (remain 308m 20s) Loss: 0.0023(0.0952) Grad: 1262.9193  LR: 0.000005  \n","Epoch: [1][1000/36908] Elapsed 8m 35s (remain 308m 11s) Loss: 0.0010(0.0860) Grad: 551.8243  LR: 0.000005  \n","Epoch: [1][1100/36908] Elapsed 9m 28s (remain 307m 55s) Loss: 0.0003(0.0785) Grad: 175.8742  LR: 0.000006  \n","Epoch: [1][1200/36908] Elapsed 10m 20s (remain 307m 32s) Loss: 0.0008(0.0722) Grad: 339.8679  LR: 0.000007  \n","Epoch: [1][1300/36908] Elapsed 11m 12s (remain 306m 57s) Loss: 0.0020(0.0670) Grad: 616.2368  LR: 0.000007  \n","Epoch: [1][1400/36908] Elapsed 12m 5s (remain 306m 25s) Loss: 0.0008(0.0624) Grad: 378.4584  LR: 0.000008  \n","Epoch: [1][1500/36908] Elapsed 12m 57s (remain 305m 41s) Loss: 0.0038(0.0585) Grad: 2550.6199  LR: 0.000008  \n","Epoch: [1][1600/36908] Elapsed 13m 48s (remain 304m 31s) Loss: 0.0018(0.0550) Grad: 1909.4824  LR: 0.000009  \n","Epoch: [1][1700/36908] Elapsed 14m 40s (remain 303m 35s) Loss: 0.0004(0.0519) Grad: 192.1267  LR: 0.000009  \n","Epoch: [1][1800/36908] Elapsed 15m 31s (remain 302m 37s) Loss: 0.0012(0.0492) Grad: 746.0985  LR: 0.000010  \n","Epoch: [1][1900/36908] Elapsed 16m 22s (remain 301m 38s) Loss: 0.0003(0.0468) Grad: 172.7726  LR: 0.000010  \n","Epoch: [1][2000/36908] Elapsed 17m 13s (remain 300m 34s) Loss: 0.0001(0.0445) Grad: 63.6953  LR: 0.000011  \n","Epoch: [1][2100/36908] Elapsed 18m 4s (remain 299m 30s) Loss: 0.0029(0.0425) Grad: 1473.9541  LR: 0.000011  \n","Epoch: [1][2200/36908] Elapsed 18m 55s (remain 298m 28s) Loss: 0.0003(0.0407) Grad: 159.0241  LR: 0.000012  \n","Epoch: [1][2300/36908] Elapsed 19m 46s (remain 297m 32s) Loss: 0.0013(0.0390) Grad: 716.8203  LR: 0.000012  \n","Epoch: [1][2400/36908] Elapsed 20m 38s (remain 296m 37s) Loss: 0.0001(0.0375) Grad: 142.2853  LR: 0.000013  \n","Epoch: [1][2500/36908] Elapsed 21m 29s (remain 295m 40s) Loss: 0.0161(0.0360) Grad: 4511.8252  LR: 0.000014  \n","Epoch: [1][2600/36908] Elapsed 22m 20s (remain 294m 41s) Loss: 0.0004(0.0348) Grad: 397.6739  LR: 0.000014  \n","Epoch: [1][2700/36908] Elapsed 23m 11s (remain 293m 44s) Loss: 0.0003(0.0336) Grad: 156.2820  LR: 0.000015  \n","Epoch: [1][2800/36908] Elapsed 24m 2s (remain 292m 47s) Loss: 0.0010(0.0325) Grad: 637.4816  LR: 0.000015  \n","Epoch: [1][2900/36908] Elapsed 24m 53s (remain 291m 46s) Loss: 0.0002(0.0315) Grad: 152.9356  LR: 0.000016  \n","Epoch: [1][3000/36908] Elapsed 25m 44s (remain 290m 47s) Loss: 0.0006(0.0305) Grad: 500.4008  LR: 0.000016  \n","Epoch: [1][3100/36908] Elapsed 26m 35s (remain 289m 54s) Loss: 0.0007(0.0296) Grad: 1000.8096  LR: 0.000017  \n","Epoch: [1][3200/36908] Elapsed 27m 27s (remain 289m 4s) Loss: 0.0005(0.0288) Grad: 345.9252  LR: 0.000017  \n","Epoch: [1][3300/36908] Elapsed 28m 18s (remain 288m 10s) Loss: 0.0005(0.0280) Grad: 443.2664  LR: 0.000018  \n","Epoch: [1][3400/36908] Elapsed 29m 9s (remain 287m 19s) Loss: 0.0309(0.0272) Grad: 9902.9844  LR: 0.000018  \n","Epoch: [1][3500/36908] Elapsed 30m 1s (remain 286m 30s) Loss: 0.0000(0.0265) Grad: 56.6645  LR: 0.000019  \n","Epoch: [1][3600/36908] Elapsed 30m 53s (remain 285m 42s) Loss: 0.0010(0.0259) Grad: 855.0461  LR: 0.000020  \n","Epoch: [1][3700/36908] Elapsed 31m 44s (remain 284m 51s) Loss: 0.0025(0.0252) Grad: 675.1745  LR: 0.000020  \n","Epoch: [1][3800/36908] Elapsed 32m 36s (remain 283m 59s) Loss: 0.0002(0.0246) Grad: 325.2896  LR: 0.000020  \n","Epoch: [1][3900/36908] Elapsed 33m 27s (remain 283m 4s) Loss: 0.0269(0.0240) Grad: 6572.6343  LR: 0.000020  \n","Epoch: [1][4000/36908] Elapsed 34m 18s (remain 282m 11s) Loss: 0.0002(0.0235) Grad: 326.4355  LR: 0.000020  \n","Epoch: [1][4100/36908] Elapsed 35m 10s (remain 281m 19s) Loss: 0.0011(0.0230) Grad: 1068.2307  LR: 0.000020  \n","Epoch: [1][4200/36908] Elapsed 36m 1s (remain 280m 25s) Loss: 0.0005(0.0225) Grad: 1210.6172  LR: 0.000020  \n","Epoch: [1][4300/36908] Elapsed 36m 52s (remain 279m 34s) Loss: 0.0001(0.0220) Grad: 285.7131  LR: 0.000020  \n","Epoch: [1][4400/36908] Elapsed 37m 43s (remain 278m 40s) Loss: 0.0001(0.0216) Grad: 307.8875  LR: 0.000020  \n","Epoch: [1][4500/36908] Elapsed 38m 35s (remain 277m 51s) Loss: 0.0000(0.0212) Grad: 109.5150  LR: 0.000020  \n","Epoch: [1][4600/36908] Elapsed 39m 26s (remain 276m 57s) Loss: 0.0017(0.0207) Grad: 4596.5586  LR: 0.000019  \n","Epoch: [1][4700/36908] Elapsed 40m 17s (remain 276m 0s) Loss: 0.0001(0.0204) Grad: 161.8472  LR: 0.000019  \n","Epoch: [1][4800/36908] Elapsed 41m 8s (remain 275m 5s) Loss: 0.0003(0.0200) Grad: 1152.6447  LR: 0.000019  \n","Epoch: [1][4900/36908] Elapsed 41m 59s (remain 274m 10s) Loss: 0.0014(0.0196) Grad: 3777.7063  LR: 0.000019  \n","Epoch: [1][5000/36908] Elapsed 42m 50s (remain 273m 18s) Loss: 0.0006(0.0193) Grad: 1465.1183  LR: 0.000019  \n","Epoch: [1][5100/36908] Elapsed 43m 41s (remain 272m 24s) Loss: 0.0001(0.0189) Grad: 225.4859  LR: 0.000019  \n","Epoch: [1][5200/36908] Elapsed 44m 32s (remain 271m 33s) Loss: 0.0000(0.0186) Grad: 73.5322  LR: 0.000019  \n","Epoch: [1][5300/36908] Elapsed 45m 23s (remain 270m 40s) Loss: 0.0001(0.0183) Grad: 199.8186  LR: 0.000019  \n","Epoch: [1][5400/36908] Elapsed 46m 14s (remain 269m 48s) Loss: 0.0198(0.0180) Grad: 12128.9883  LR: 0.000019  \n","Epoch: [1][5500/36908] Elapsed 47m 6s (remain 268m 55s) Loss: 0.0001(0.0178) Grad: 266.0656  LR: 0.000019  \n","Epoch: [1][5600/36908] Elapsed 47m 57s (remain 268m 3s) Loss: 0.0001(0.0175) Grad: 472.0260  LR: 0.000019  \n","Epoch: [1][5700/36908] Elapsed 48m 48s (remain 267m 9s) Loss: 0.0043(0.0172) Grad: 3821.2351  LR: 0.000019  \n","Epoch: [1][5800/36908] Elapsed 49m 39s (remain 266m 16s) Loss: 0.0104(0.0169) Grad: 5867.9756  LR: 0.000019  \n","Epoch: [1][5900/36908] Elapsed 50m 30s (remain 265m 23s) Loss: 0.0025(0.0167) Grad: 6001.7432  LR: 0.000019  \n","Epoch: [1][6000/36908] Elapsed 51m 21s (remain 264m 30s) Loss: 0.0030(0.0164) Grad: 1842.4475  LR: 0.000019  \n","Epoch: [1][6100/36908] Elapsed 52m 12s (remain 263m 37s) Loss: 0.0000(0.0162) Grad: 91.9044  LR: 0.000019  \n","Epoch: [1][6200/36908] Elapsed 53m 3s (remain 262m 46s) Loss: 0.0002(0.0160) Grad: 794.7087  LR: 0.000018  \n","Epoch: [1][6300/36908] Elapsed 53m 55s (remain 261m 55s) Loss: 0.0001(0.0157) Grad: 146.9147  LR: 0.000018  \n","Epoch: [1][6400/36908] Elapsed 54m 46s (remain 261m 2s) Loss: 0.0000(0.0156) Grad: 29.1115  LR: 0.000018  \n","Epoch: [1][6500/36908] Elapsed 55m 37s (remain 260m 9s) Loss: 0.0000(0.0154) Grad: 34.2637  LR: 0.000018  \n","Epoch: [1][6600/36908] Elapsed 56m 28s (remain 259m 19s) Loss: 0.0082(0.0152) Grad: 6640.8535  LR: 0.000018  \n","Epoch: [1][6700/36908] Elapsed 57m 20s (remain 258m 29s) Loss: 0.0090(0.0150) Grad: 3598.0308  LR: 0.000018  \n","Epoch: [1][6800/36908] Elapsed 58m 12s (remain 257m 40s) Loss: 0.0090(0.0148) Grad: 11800.6943  LR: 0.000018  \n","Epoch: [1][6900/36908] Elapsed 59m 4s (remain 256m 50s) Loss: 0.0026(0.0146) Grad: 2146.3477  LR: 0.000018  \n","Epoch: [1][7000/36908] Elapsed 59m 55s (remain 255m 57s) Loss: 0.0005(0.0144) Grad: 1740.1307  LR: 0.000018  \n","Epoch: [1][7100/36908] Elapsed 60m 46s (remain 255m 6s) Loss: 0.0000(0.0142) Grad: 61.4235  LR: 0.000018  \n","Epoch: [1][7200/36908] Elapsed 61m 37s (remain 254m 14s) Loss: 0.0001(0.0141) Grad: 112.6747  LR: 0.000018  \n","Epoch: [1][7300/36908] Elapsed 62m 29s (remain 253m 23s) Loss: 0.0002(0.0139) Grad: 315.9859  LR: 0.000018  \n","Epoch: [1][7400/36908] Elapsed 63m 20s (remain 252m 33s) Loss: 0.0053(0.0137) Grad: 7673.3823  LR: 0.000018  \n","Epoch: [1][7500/36908] Elapsed 64m 12s (remain 251m 44s) Loss: 0.0001(0.0136) Grad: 697.1506  LR: 0.000018  \n","Epoch: [1][7600/36908] Elapsed 65m 5s (remain 250m 56s) Loss: 0.0002(0.0134) Grad: 417.1584  LR: 0.000018  \n","Epoch: [1][7700/36908] Elapsed 65m 55s (remain 250m 2s) Loss: 0.0092(0.0133) Grad: 9089.4092  LR: 0.000018  \n","Epoch: [1][7800/36908] Elapsed 66m 46s (remain 249m 10s) Loss: 0.0000(0.0132) Grad: 20.0176  LR: 0.000018  \n","Epoch: [1][7900/36908] Elapsed 67m 39s (remain 248m 22s) Loss: 0.0001(0.0130) Grad: 341.2427  LR: 0.000017  \n","Epoch: [1][8000/36908] Elapsed 68m 31s (remain 247m 35s) Loss: 0.0001(0.0129) Grad: 325.2597  LR: 0.000017  \n","Epoch: [1][8100/36908] Elapsed 69m 24s (remain 246m 48s) Loss: 0.0000(0.0128) Grad: 44.3924  LR: 0.000017  \n","Epoch: [1][8200/36908] Elapsed 70m 16s (remain 246m 0s) Loss: 0.0000(0.0126) Grad: 226.2809  LR: 0.000017  \n","Epoch: [1][8300/36908] Elapsed 71m 8s (remain 245m 11s) Loss: 0.0002(0.0125) Grad: 872.6617  LR: 0.000017  \n","Epoch: [1][8400/36908] Elapsed 72m 1s (remain 244m 23s) Loss: 0.0009(0.0124) Grad: 4636.4033  LR: 0.000017  \n","Epoch: [1][8500/36908] Elapsed 72m 53s (remain 243m 35s) Loss: 0.0000(0.0122) Grad: 74.5466  LR: 0.000017  \n","Epoch: [1][8600/36908] Elapsed 73m 45s (remain 242m 45s) Loss: 0.0004(0.0121) Grad: 3407.6396  LR: 0.000017  \n","Epoch: [1][8700/36908] Elapsed 74m 37s (remain 241m 53s) Loss: 0.0005(0.0120) Grad: 4567.5835  LR: 0.000017  \n","Epoch: [1][8800/36908] Elapsed 75m 28s (remain 241m 1s) Loss: 0.0000(0.0119) Grad: 277.6235  LR: 0.000017  \n","Epoch: [1][8900/36908] Elapsed 76m 19s (remain 240m 9s) Loss: 0.0001(0.0118) Grad: 1031.2924  LR: 0.000017  \n","Epoch: [1][9000/36908] Elapsed 77m 11s (remain 239m 18s) Loss: 0.0185(0.0117) Grad: 19613.5723  LR: 0.000017  \n","Epoch: [1][9100/36908] Elapsed 78m 2s (remain 238m 27s) Loss: 0.0046(0.0116) Grad: 29100.4668  LR: 0.000017  \n","Epoch: [1][9200/36908] Elapsed 78m 54s (remain 237m 35s) Loss: 0.0000(0.0115) Grad: 72.5902  LR: 0.000017  \n","Epoch: [1][9300/36908] Elapsed 79m 45s (remain 236m 45s) Loss: 0.0002(0.0114) Grad: 1804.4315  LR: 0.000017  \n","Epoch: [1][9400/36908] Elapsed 80m 37s (remain 235m 54s) Loss: 0.0009(0.0113) Grad: 2686.3164  LR: 0.000017  \n","Epoch: [1][9500/36908] Elapsed 81m 28s (remain 235m 2s) Loss: 0.0001(0.0112) Grad: 691.5005  LR: 0.000017  \n","Epoch: [1][9600/36908] Elapsed 82m 19s (remain 234m 10s) Loss: 0.0000(0.0111) Grad: 13.7006  LR: 0.000016  \n","Epoch: [1][9700/36908] Elapsed 83m 11s (remain 233m 18s) Loss: 0.0010(0.0110) Grad: 3512.7798  LR: 0.000016  \n","Epoch: [1][9800/36908] Elapsed 84m 2s (remain 232m 26s) Loss: 0.0000(0.0109) Grad: 33.2512  LR: 0.000016  \n","Epoch: [1][9900/36908] Elapsed 84m 54s (remain 231m 35s) Loss: 0.0000(0.0109) Grad: 112.5301  LR: 0.000016  \n","Epoch: [1][10000/36908] Elapsed 85m 45s (remain 230m 42s) Loss: 0.0025(0.0108) Grad: 12189.0430  LR: 0.000016  \n","Epoch: [1][10100/36908] Elapsed 86m 35s (remain 229m 49s) Loss: 0.0058(0.0107) Grad: 24024.5469  LR: 0.000016  \n","Epoch: [1][10200/36908] Elapsed 87m 27s (remain 228m 58s) Loss: 0.0005(0.0106) Grad: 2710.1121  LR: 0.000016  \n","Epoch: [1][10300/36908] Elapsed 88m 18s (remain 228m 6s) Loss: 0.0003(0.0105) Grad: 2016.2020  LR: 0.000016  \n","Epoch: [1][10400/36908] Elapsed 89m 9s (remain 227m 13s) Loss: 0.0000(0.0105) Grad: 35.6972  LR: 0.000016  \n","Epoch: [1][10500/36908] Elapsed 90m 0s (remain 226m 21s) Loss: 0.0000(0.0104) Grad: 255.2065  LR: 0.000016  \n","Epoch: [1][10600/36908] Elapsed 90m 52s (remain 225m 30s) Loss: 0.0001(0.0103) Grad: 727.2615  LR: 0.000016  \n","Epoch: [1][10700/36908] Elapsed 91m 43s (remain 224m 38s) Loss: 0.0001(0.0102) Grad: 523.1183  LR: 0.000016  \n","Epoch: [1][10800/36908] Elapsed 92m 34s (remain 223m 46s) Loss: 0.0095(0.0102) Grad: 11338.5762  LR: 0.000016  \n","Epoch: [1][10900/36908] Elapsed 93m 26s (remain 222m 54s) Loss: 0.0000(0.0101) Grad: 220.0567  LR: 0.000016  \n","Epoch: [1][11000/36908] Elapsed 94m 17s (remain 222m 3s) Loss: 0.0000(0.0100) Grad: 82.9686  LR: 0.000016  \n","Epoch: [1][11100/36908] Elapsed 95m 8s (remain 221m 10s) Loss: 0.0000(0.0099) Grad: 78.5714  LR: 0.000016  \n","Epoch: [1][11200/36908] Elapsed 96m 1s (remain 220m 21s) Loss: 0.0011(0.0099) Grad: 6947.4297  LR: 0.000015  \n","Epoch: [1][11300/36908] Elapsed 96m 54s (remain 219m 34s) Loss: 0.0000(0.0098) Grad: 160.0524  LR: 0.000015  \n","Epoch: [1][11400/36908] Elapsed 97m 46s (remain 218m 45s) Loss: 0.0097(0.0097) Grad: 24865.2812  LR: 0.000015  \n","Epoch: [1][11500/36908] Elapsed 98m 39s (remain 217m 56s) Loss: 0.0014(0.0097) Grad: 4073.3882  LR: 0.000015  \n","Epoch: [1][11600/36908] Elapsed 99m 31s (remain 217m 6s) Loss: 0.0172(0.0096) Grad: 34634.5742  LR: 0.000015  \n","Epoch: [1][11700/36908] Elapsed 100m 23s (remain 216m 15s) Loss: 0.0000(0.0095) Grad: 139.5596  LR: 0.000015  \n","Epoch: [1][11800/36908] Elapsed 101m 15s (remain 215m 25s) Loss: 0.0001(0.0095) Grad: 826.1024  LR: 0.000015  \n","Epoch: [1][11900/36908] Elapsed 102m 6s (remain 214m 34s) Loss: 0.0000(0.0094) Grad: 260.0542  LR: 0.000015  \n","Epoch: [1][12000/36908] Elapsed 102m 58s (remain 213m 43s) Loss: 0.0000(0.0094) Grad: 17.7428  LR: 0.000015  \n","Epoch: [1][12100/36908] Elapsed 103m 50s (remain 212m 52s) Loss: 0.0000(0.0093) Grad: 110.4120  LR: 0.000015  \n","Epoch: [1][12200/36908] Elapsed 104m 41s (remain 212m 0s) Loss: 0.0082(0.0093) Grad: 70546.7734  LR: 0.000015  \n","Epoch: [1][12300/36908] Elapsed 105m 32s (remain 211m 7s) Loss: 0.0019(0.0092) Grad: 17608.7598  LR: 0.000015  \n","Epoch: [1][12400/36908] Elapsed 106m 23s (remain 210m 15s) Loss: 0.0118(0.0091) Grad: 28261.3633  LR: 0.000015  \n","Epoch: [1][12500/36908] Elapsed 107m 15s (remain 209m 24s) Loss: 0.0000(0.0091) Grad: 204.9772  LR: 0.000015  \n","Epoch: [1][12600/36908] Elapsed 108m 7s (remain 208m 33s) Loss: 0.0000(0.0091) Grad: 32.0620  LR: 0.000015  \n","Epoch: [1][12700/36908] Elapsed 108m 58s (remain 207m 40s) Loss: 0.0000(0.0090) Grad: 149.2991  LR: 0.000015  \n","Epoch: [1][12800/36908] Elapsed 109m 48s (remain 206m 47s) Loss: 0.0006(0.0089) Grad: 9217.1543  LR: 0.000015  \n","Epoch: [1][12900/36908] Elapsed 110m 39s (remain 205m 54s) Loss: 0.0000(0.0089) Grad: 86.5031  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 111m 29s (remain 205m 1s) Loss: 0.0038(0.0089) Grad: 16454.8809  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 112m 20s (remain 204m 8s) Loss: 0.0049(0.0088) Grad: 38260.7422  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 113m 11s (remain 203m 15s) Loss: 0.0000(0.0088) Grad: 128.1795  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 114m 2s (remain 202m 23s) Loss: 0.0000(0.0087) Grad: 280.6229  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 114m 52s (remain 201m 30s) Loss: 0.0000(0.0087) Grad: 68.4091  LR: 0.000014  \n","Epoch: [1][13500/36908] Elapsed 115m 43s (remain 200m 38s) Loss: 0.0033(0.0086) Grad: 25039.2520  LR: 0.000014  \n","Epoch: [1][13600/36908] Elapsed 116m 35s (remain 199m 48s) Loss: 0.0042(0.0086) Grad: 31088.2598  LR: 0.000014  \n","Epoch: [1][13700/36908] Elapsed 117m 26s (remain 198m 56s) Loss: 0.0000(0.0085) Grad: 184.0571  LR: 0.000014  \n","Epoch: [1][13800/36908] Elapsed 118m 17s (remain 198m 3s) Loss: 0.0002(0.0085) Grad: 2306.6748  LR: 0.000014  \n","Epoch: [1][13900/36908] Elapsed 119m 9s (remain 197m 12s) Loss: 0.0000(0.0084) Grad: 40.3970  LR: 0.000014  \n","Epoch: [1][14000/36908] Elapsed 120m 0s (remain 196m 21s) Loss: 0.0000(0.0084) Grad: 46.2604  LR: 0.000014  \n","Epoch: [1][14100/36908] Elapsed 120m 52s (remain 195m 30s) Loss: 0.0000(0.0083) Grad: 58.9655  LR: 0.000014  \n","Epoch: [1][14200/36908] Elapsed 121m 44s (remain 194m 40s) Loss: 0.0040(0.0083) Grad: 21374.1699  LR: 0.000014  \n","Epoch: [1][14300/36908] Elapsed 122m 37s (remain 193m 50s) Loss: 0.0119(0.0083) Grad: 66270.5391  LR: 0.000014  \n","Epoch: [1][14400/36908] Elapsed 123m 29s (remain 193m 0s) Loss: 0.0000(0.0082) Grad: 88.0482  LR: 0.000014  \n","Epoch: [1][14500/36908] Elapsed 124m 22s (remain 192m 10s) Loss: 0.0014(0.0082) Grad: 8030.9385  LR: 0.000013  \n","Epoch: [1][14600/36908] Elapsed 125m 14s (remain 191m 20s) Loss: 0.0006(0.0082) Grad: 5152.7441  LR: 0.000013  \n","Epoch: [1][14700/36908] Elapsed 126m 6s (remain 190m 29s) Loss: 0.1755(0.0081) Grad: 360015.6875  LR: 0.000013  \n","Epoch: [1][14800/36908] Elapsed 126m 57s (remain 189m 38s) Loss: 0.0003(0.0081) Grad: 3025.1655  LR: 0.000013  \n","Epoch: [1][14900/36908] Elapsed 127m 49s (remain 188m 46s) Loss: 0.0000(0.0081) Grad: 180.1387  LR: 0.000013  \n","Epoch: [1][15000/36908] Elapsed 128m 40s (remain 187m 54s) Loss: 0.0000(0.0080) Grad: 167.3208  LR: 0.000013  \n","Epoch: [1][15100/36908] Elapsed 129m 31s (remain 187m 3s) Loss: 0.0000(0.0080) Grad: 34.2174  LR: 0.000013  \n","Epoch: [1][15200/36908] Elapsed 130m 22s (remain 186m 11s) Loss: 0.0013(0.0079) Grad: 12586.7217  LR: 0.000013  \n","Epoch: [1][15300/36908] Elapsed 131m 14s (remain 185m 19s) Loss: 0.0000(0.0079) Grad: 307.0015  LR: 0.000013  \n","Epoch: [1][15400/36908] Elapsed 132m 5s (remain 184m 27s) Loss: 0.0000(0.0079) Grad: 706.7063  LR: 0.000013  \n","Epoch: [1][15500/36908] Elapsed 132m 56s (remain 183m 36s) Loss: 0.0009(0.0078) Grad: 4832.8936  LR: 0.000013  \n","Epoch: [1][15600/36908] Elapsed 133m 47s (remain 182m 43s) Loss: 0.0264(0.0078) Grad: 100811.7266  LR: 0.000013  \n","Epoch: [1][15700/36908] Elapsed 134m 38s (remain 181m 51s) Loss: 0.0000(0.0078) Grad: 93.2654  LR: 0.000013  \n","Epoch: [1][15800/36908] Elapsed 135m 29s (remain 180m 59s) Loss: 0.0012(0.0078) Grad: 12063.8418  LR: 0.000013  \n","Epoch: [1][15900/36908] Elapsed 136m 20s (remain 180m 7s) Loss: 0.0000(0.0077) Grad: 481.5869  LR: 0.000013  \n","Epoch: [1][16000/36908] Elapsed 137m 11s (remain 179m 15s) Loss: 0.0000(0.0077) Grad: 190.4719  LR: 0.000013  \n","Epoch: [1][16100/36908] Elapsed 138m 2s (remain 178m 23s) Loss: 0.0002(0.0077) Grad: 6374.9126  LR: 0.000013  \n","Epoch: [1][16200/36908] Elapsed 138m 53s (remain 177m 30s) Loss: 0.0024(0.0076) Grad: 56307.6406  LR: 0.000012  \n","Epoch: [1][16300/36908] Elapsed 139m 44s (remain 176m 38s) Loss: 0.0000(0.0076) Grad: 1266.0310  LR: 0.000012  \n","Epoch: [1][16400/36908] Elapsed 140m 35s (remain 175m 47s) Loss: 0.0130(0.0076) Grad: 156944.0469  LR: 0.000012  \n","Epoch: [1][16500/36908] Elapsed 141m 26s (remain 174m 55s) Loss: 0.0001(0.0075) Grad: 3175.0376  LR: 0.000012  \n","Epoch: [1][16600/36908] Elapsed 142m 18s (remain 174m 4s) Loss: 0.0020(0.0075) Grad: 27153.7246  LR: 0.000012  \n","Epoch: [1][16700/36908] Elapsed 143m 10s (remain 173m 13s) Loss: 0.0008(0.0075) Grad: 10233.6934  LR: 0.000012  \n","Epoch: [1][16800/36908] Elapsed 144m 0s (remain 172m 21s) Loss: 0.0008(0.0074) Grad: 11599.3535  LR: 0.000012  \n","Epoch: [1][16900/36908] Elapsed 144m 51s (remain 171m 29s) Loss: 0.0001(0.0074) Grad: 3453.8643  LR: 0.000012  \n","Epoch: [1][17000/36908] Elapsed 145m 42s (remain 170m 37s) Loss: 0.0023(0.0074) Grad: 19806.5234  LR: 0.000012  \n","Epoch: [1][17100/36908] Elapsed 146m 33s (remain 169m 45s) Loss: 0.0000(0.0073) Grad: 116.0333  LR: 0.000012  \n","Epoch: [1][17200/36908] Elapsed 147m 24s (remain 168m 53s) Loss: 0.0025(0.0073) Grad: 18927.4277  LR: 0.000012  \n","Epoch: [1][17300/36908] Elapsed 148m 15s (remain 168m 1s) Loss: 0.0001(0.0073) Grad: 2748.8220  LR: 0.000012  \n","Epoch: [1][17400/36908] Elapsed 149m 5s (remain 167m 7s) Loss: 0.0000(0.0072) Grad: 43.5327  LR: 0.000012  \n","Epoch: [1][17500/36908] Elapsed 149m 54s (remain 166m 14s) Loss: 0.0000(0.0072) Grad: 624.8355  LR: 0.000012  \n","Epoch: [1][17600/36908] Elapsed 150m 45s (remain 165m 22s) Loss: 0.0206(0.0072) Grad: 49920.8711  LR: 0.000012  \n","Epoch: [1][17700/36908] Elapsed 151m 35s (remain 164m 28s) Loss: 0.0012(0.0072) Grad: 31909.7695  LR: 0.000012  \n","Epoch: [1][17800/36908] Elapsed 152m 24s (remain 163m 35s) Loss: 0.0008(0.0072) Grad: 31632.5840  LR: 0.000012  \n","Epoch: [1][17900/36908] Elapsed 153m 14s (remain 162m 42s) Loss: 0.0000(0.0071) Grad: 257.2070  LR: 0.000011  \n","Epoch: [1][18000/36908] Elapsed 154m 4s (remain 161m 49s) Loss: 0.0000(0.0071) Grad: 750.4419  LR: 0.000011  \n","Epoch: [1][18100/36908] Elapsed 154m 53s (remain 160m 56s) Loss: 0.0018(0.0071) Grad: 41552.9766  LR: 0.000011  \n","Epoch: [1][18200/36908] Elapsed 155m 43s (remain 160m 3s) Loss: 0.0002(0.0070) Grad: 8608.4150  LR: 0.000011  \n","Epoch: [1][18300/36908] Elapsed 156m 34s (remain 159m 11s) Loss: 0.0000(0.0070) Grad: 614.4725  LR: 0.000011  \n","Epoch: [1][18400/36908] Elapsed 157m 24s (remain 158m 19s) Loss: 0.0066(0.0070) Grad: 40138.0664  LR: 0.000011  \n","Epoch: [1][18500/36908] Elapsed 158m 14s (remain 157m 25s) Loss: 0.0000(0.0070) Grad: 77.7632  LR: 0.000011  \n","Epoch: [1][18600/36908] Elapsed 159m 4s (remain 156m 33s) Loss: 0.0026(0.0069) Grad: 31619.2324  LR: 0.000011  \n","Epoch: [1][18700/36908] Elapsed 159m 53s (remain 155m 40s) Loss: 0.0001(0.0069) Grad: 3851.9536  LR: 0.000011  \n","Epoch: [1][18800/36908] Elapsed 160m 43s (remain 154m 47s) Loss: 0.0000(0.0069) Grad: 144.1543  LR: 0.000011  \n","Epoch: [1][18900/36908] Elapsed 161m 33s (remain 153m 55s) Loss: 0.0090(0.0069) Grad: 53373.8242  LR: 0.000011  \n","Epoch: [1][19000/36908] Elapsed 162m 24s (remain 153m 3s) Loss: 0.0000(0.0068) Grad: 60.7366  LR: 0.000011  \n","Epoch: [1][19100/36908] Elapsed 163m 14s (remain 152m 10s) Loss: 0.0141(0.0068) Grad: 207377.0312  LR: 0.000011  \n","Epoch: [1][19200/36908] Elapsed 164m 4s (remain 151m 18s) Loss: 0.0000(0.0068) Grad: 60.9224  LR: 0.000011  \n","Epoch: [1][19300/36908] Elapsed 164m 54s (remain 150m 26s) Loss: 0.0000(0.0068) Grad: 112.5768  LR: 0.000011  \n","Epoch: [1][19400/36908] Elapsed 165m 45s (remain 149m 34s) Loss: 0.0034(0.0068) Grad: 43160.0430  LR: 0.000011  \n","Epoch: [1][19500/36908] Elapsed 166m 35s (remain 148m 42s) Loss: 0.0137(0.0067) Grad: 62723.5156  LR: 0.000010  \n","Epoch: [1][19600/36908] Elapsed 167m 26s (remain 147m 50s) Loss: 0.0000(0.0067) Grad: 598.8095  LR: 0.000010  \n","Epoch: [1][19700/36908] Elapsed 168m 16s (remain 146m 58s) Loss: 0.0000(0.0067) Grad: 82.3913  LR: 0.000010  \n","Epoch: [1][19800/36908] Elapsed 169m 6s (remain 146m 5s) Loss: 0.0000(0.0067) Grad: 465.8954  LR: 0.000010  \n","Epoch: [1][19900/36908] Elapsed 169m 56s (remain 145m 13s) Loss: 0.0000(0.0066) Grad: 62.6071  LR: 0.000010  \n","Epoch: [1][20000/36908] Elapsed 170m 46s (remain 144m 21s) Loss: 0.0008(0.0066) Grad: 19932.7988  LR: 0.000010  \n","Epoch: [1][20100/36908] Elapsed 171m 36s (remain 143m 29s) Loss: 0.0030(0.0066) Grad: 113665.6328  LR: 0.000010  \n","Epoch: [1][20200/36908] Elapsed 172m 27s (remain 142m 37s) Loss: 0.0019(0.0066) Grad: 69869.7422  LR: 0.000010  \n","Epoch: [1][20300/36908] Elapsed 173m 17s (remain 141m 45s) Loss: 0.0013(0.0066) Grad: 50873.7500  LR: 0.000010  \n","Epoch: [1][20400/36908] Elapsed 174m 8s (remain 140m 54s) Loss: 0.0000(0.0065) Grad: 39.1150  LR: 0.000010  \n","Epoch: [1][20500/36908] Elapsed 174m 59s (remain 140m 2s) Loss: 0.0000(0.0065) Grad: 208.4542  LR: 0.000010  \n","Epoch: [1][20600/36908] Elapsed 175m 48s (remain 139m 10s) Loss: 0.0011(0.0065) Grad: 68565.0469  LR: 0.000010  \n","Epoch: [1][20700/36908] Elapsed 176m 39s (remain 138m 18s) Loss: 0.0000(0.0065) Grad: 1374.6738  LR: 0.000010  \n","Epoch: [1][20800/36908] Elapsed 177m 29s (remain 137m 26s) Loss: 0.0000(0.0065) Grad: 86.4173  LR: 0.000010  \n","Epoch: [1][20900/36908] Elapsed 178m 19s (remain 136m 34s) Loss: 0.0000(0.0065) Grad: 1044.4507  LR: 0.000010  \n","Epoch: [1][21000/36908] Elapsed 179m 9s (remain 135m 42s) Loss: 0.0000(0.0064) Grad: 876.3182  LR: 0.000010  \n","Epoch: [1][21100/36908] Elapsed 180m 0s (remain 134m 50s) Loss: 0.0050(0.0064) Grad: 105267.7031  LR: 0.000010  \n","Epoch: [1][21200/36908] Elapsed 180m 51s (remain 133m 59s) Loss: 0.0000(0.0064) Grad: 74.6763  LR: 0.000009  \n","Epoch: [1][21300/36908] Elapsed 181m 41s (remain 133m 7s) Loss: 0.0005(0.0064) Grad: 35391.3203  LR: 0.000009  \n","Epoch: [1][21400/36908] Elapsed 182m 31s (remain 132m 15s) Loss: 0.0303(0.0064) Grad: 228663.3594  LR: 0.000009  \n","Epoch: [1][21500/36908] Elapsed 183m 21s (remain 131m 23s) Loss: 0.0041(0.0064) Grad: 215373.6094  LR: 0.000009  \n","Epoch: [1][21600/36908] Elapsed 184m 12s (remain 130m 31s) Loss: 0.0171(0.0063) Grad: 235346.8906  LR: 0.000009  \n","Epoch: [1][21700/36908] Elapsed 185m 2s (remain 129m 39s) Loss: 0.0004(0.0063) Grad: 32987.6328  LR: 0.000009  \n","Epoch: [1][21800/36908] Elapsed 185m 52s (remain 128m 48s) Loss: 0.0010(0.0063) Grad: 19119.1719  LR: 0.000009  \n","Epoch: [1][21900/36908] Elapsed 186m 43s (remain 127m 56s) Loss: 0.0008(0.0063) Grad: 57437.3008  LR: 0.000009  \n","Epoch: [1][22000/36908] Elapsed 187m 34s (remain 127m 5s) Loss: 0.0008(0.0063) Grad: 24664.7129  LR: 0.000009  \n","Epoch: [1][22100/36908] Elapsed 188m 25s (remain 126m 14s) Loss: 0.0413(0.0063) Grad: 918159.1250  LR: 0.000009  \n","Epoch: [1][22200/36908] Elapsed 189m 16s (remain 125m 22s) Loss: 0.0041(0.0062) Grad: 118192.7891  LR: 0.000009  \n","Epoch: [1][22300/36908] Elapsed 190m 6s (remain 124m 31s) Loss: 0.0177(0.0062) Grad: 164888.5156  LR: 0.000009  \n","Epoch: [1][22400/36908] Elapsed 190m 57s (remain 123m 39s) Loss: 0.0010(0.0062) Grad: 30129.0273  LR: 0.000009  \n","Epoch: [1][22500/36908] Elapsed 191m 47s (remain 122m 48s) Loss: 0.0019(0.0062) Grad: 89133.0312  LR: 0.000009  \n","Epoch: [1][22600/36908] Elapsed 192m 37s (remain 121m 56s) Loss: 0.0026(0.0062) Grad: 44216.4062  LR: 0.000009  \n","Epoch: [1][22700/36908] Elapsed 193m 28s (remain 121m 4s) Loss: 0.0000(0.0062) Grad: 115.1348  LR: 0.000009  \n","Epoch: [1][22800/36908] Elapsed 194m 18s (remain 120m 13s) Loss: 0.0026(0.0061) Grad: 79922.8906  LR: 0.000008  \n","Epoch: [1][22900/36908] Elapsed 195m 9s (remain 119m 21s) Loss: 0.0000(0.0061) Grad: 73.9018  LR: 0.000008  \n","Epoch: [1][23000/36908] Elapsed 195m 59s (remain 118m 30s) Loss: 0.0000(0.0061) Grad: 113.4837  LR: 0.000008  \n","Epoch: [1][23100/36908] Elapsed 196m 49s (remain 117m 38s) Loss: 0.0000(0.0061) Grad: 29.2912  LR: 0.000008  \n","Epoch: [1][23200/36908] Elapsed 197m 40s (remain 116m 47s) Loss: 0.0165(0.0061) Grad: 408226.8125  LR: 0.000008  \n","Epoch: [1][23300/36908] Elapsed 198m 31s (remain 115m 55s) Loss: 0.0000(0.0061) Grad: 34.6587  LR: 0.000008  \n","Epoch: [1][23400/36908] Elapsed 199m 21s (remain 115m 3s) Loss: 0.0000(0.0061) Grad: 2049.1230  LR: 0.000008  \n","Epoch: [1][23500/36908] Elapsed 200m 10s (remain 114m 12s) Loss: 0.0000(0.0060) Grad: 44.6983  LR: 0.000008  \n","Epoch: [1][23600/36908] Elapsed 201m 1s (remain 113m 20s) Loss: 0.0000(0.0060) Grad: 526.9960  LR: 0.000008  \n","Epoch: [1][23700/36908] Elapsed 201m 51s (remain 112m 29s) Loss: 0.0000(0.0060) Grad: 1767.2490  LR: 0.000008  \n","Epoch: [1][23800/36908] Elapsed 202m 42s (remain 111m 37s) Loss: 0.0166(0.0060) Grad: 481509.4062  LR: 0.000008  \n","Epoch: [1][23900/36908] Elapsed 203m 32s (remain 110m 45s) Loss: 0.0000(0.0060) Grad: 148.2105  LR: 0.000008  \n","Epoch: [1][24000/36908] Elapsed 204m 22s (remain 109m 54s) Loss: 0.0004(0.0060) Grad: 49101.4531  LR: 0.000008  \n","Epoch: [1][24100/36908] Elapsed 205m 12s (remain 109m 2s) Loss: 0.0000(0.0060) Grad: 160.3061  LR: 0.000008  \n","Epoch: [1][24200/36908] Elapsed 206m 2s (remain 108m 11s) Loss: 0.0000(0.0060) Grad: 142.8814  LR: 0.000008  \n","Epoch: [1][24300/36908] Elapsed 206m 53s (remain 107m 19s) Loss: 0.0000(0.0060) Grad: 153.0629  LR: 0.000008  \n","Epoch: [1][24400/36908] Elapsed 207m 44s (remain 106m 28s) Loss: 0.0001(0.0059) Grad: 13130.2646  LR: 0.000008  \n","Epoch: [1][24500/36908] Elapsed 208m 34s (remain 105m 37s) Loss: 0.0000(0.0059) Grad: 442.0869  LR: 0.000007  \n","Epoch: [1][24600/36908] Elapsed 209m 24s (remain 104m 45s) Loss: 0.0000(0.0059) Grad: 1526.0696  LR: 0.000007  \n","Epoch: [1][24700/36908] Elapsed 210m 14s (remain 103m 53s) Loss: 0.0106(0.0059) Grad: 86370.5000  LR: 0.000007  \n","Epoch: [1][24800/36908] Elapsed 211m 5s (remain 103m 2s) Loss: 0.0000(0.0059) Grad: 85.9177  LR: 0.000007  \n","Epoch: [1][24900/36908] Elapsed 211m 55s (remain 102m 11s) Loss: 0.0000(0.0059) Grad: 187.8261  LR: 0.000007  \n","Epoch: [1][25000/36908] Elapsed 212m 47s (remain 101m 20s) Loss: 0.0000(0.0059) Grad: 192.9988  LR: 0.000007  \n","Epoch: [1][25100/36908] Elapsed 213m 38s (remain 100m 29s) Loss: 0.0002(0.0059) Grad: 15023.9883  LR: 0.000007  \n","Epoch: [1][25200/36908] Elapsed 214m 30s (remain 99m 38s) Loss: 0.0001(0.0058) Grad: 5458.5200  LR: 0.000007  \n","Epoch: [1][25300/36908] Elapsed 215m 22s (remain 98m 48s) Loss: 0.0000(0.0058) Grad: 504.3265  LR: 0.000007  \n","Epoch: [1][25400/36908] Elapsed 216m 13s (remain 97m 57s) Loss: 0.0000(0.0058) Grad: 4.8581  LR: 0.000007  \n","Epoch: [1][25500/36908] Elapsed 217m 4s (remain 97m 6s) Loss: 0.0000(0.0058) Grad: 213.8197  LR: 0.000007  \n","Epoch: [1][25600/36908] Elapsed 217m 55s (remain 96m 14s) Loss: 0.0043(0.0058) Grad: 132943.4375  LR: 0.000007  \n","Epoch: [1][25700/36908] Elapsed 218m 45s (remain 95m 23s) Loss: 0.0023(0.0058) Grad: 136268.8281  LR: 0.000007  \n","Epoch: [1][25800/36908] Elapsed 219m 34s (remain 94m 31s) Loss: 0.0000(0.0058) Grad: 1387.5435  LR: 0.000007  \n","Epoch: [1][25900/36908] Elapsed 220m 24s (remain 93m 39s) Loss: 0.0000(0.0057) Grad: 162.1271  LR: 0.000007  \n","Epoch: [1][26000/36908] Elapsed 221m 15s (remain 92m 48s) Loss: 0.0011(0.0057) Grad: 58089.3984  LR: 0.000007  \n","Epoch: [1][26100/36908] Elapsed 222m 5s (remain 91m 57s) Loss: 0.0000(0.0057) Grad: 241.7637  LR: 0.000007  \n","Epoch: [1][26200/36908] Elapsed 222m 55s (remain 91m 5s) Loss: 0.0348(0.0057) Grad: 178475.6562  LR: 0.000006  \n","Epoch: [1][26300/36908] Elapsed 223m 45s (remain 90m 14s) Loss: 0.0000(0.0057) Grad: 28.8062  LR: 0.000006  \n","Epoch: [1][26400/36908] Elapsed 224m 35s (remain 89m 22s) Loss: 0.0000(0.0057) Grad: 852.9641  LR: 0.000006  \n","Epoch: [1][26500/36908] Elapsed 225m 25s (remain 88m 31s) Loss: 0.0008(0.0057) Grad: 41074.8281  LR: 0.000006  \n","Epoch: [1][26600/36908] Elapsed 226m 16s (remain 87m 40s) Loss: 0.0000(0.0057) Grad: 825.0651  LR: 0.000006  \n","Epoch: [1][26700/36908] Elapsed 227m 7s (remain 86m 49s) Loss: 0.0035(0.0057) Grad: 82828.5469  LR: 0.000006  \n","Epoch: [1][26800/36908] Elapsed 227m 58s (remain 85m 58s) Loss: 0.0000(0.0057) Grad: 168.7846  LR: 0.000006  \n","Epoch: [1][26900/36908] Elapsed 228m 48s (remain 85m 6s) Loss: 0.0001(0.0056) Grad: 4481.0723  LR: 0.000006  \n","Epoch: [1][27000/36908] Elapsed 229m 38s (remain 84m 15s) Loss: 0.0000(0.0056) Grad: 368.7367  LR: 0.000006  \n","Epoch: [1][27100/36908] Elapsed 230m 28s (remain 83m 24s) Loss: 0.0000(0.0056) Grad: 611.4771  LR: 0.000006  \n","Epoch: [1][27200/36908] Elapsed 231m 18s (remain 82m 32s) Loss: 0.0000(0.0056) Grad: 12.8323  LR: 0.000006  \n","Epoch: [1][27300/36908] Elapsed 232m 8s (remain 81m 41s) Loss: 0.0001(0.0056) Grad: 9290.0039  LR: 0.000006  \n","Epoch: [1][27400/36908] Elapsed 232m 59s (remain 80m 50s) Loss: 0.0000(0.0056) Grad: 290.5470  LR: 0.000006  \n","Epoch: [1][27500/36908] Elapsed 233m 49s (remain 79m 58s) Loss: 0.0004(0.0056) Grad: 21235.2871  LR: 0.000006  \n","Epoch: [1][27600/36908] Elapsed 234m 40s (remain 79m 7s) Loss: 0.0000(0.0056) Grad: 768.4411  LR: 0.000006  \n","Epoch: [1][27700/36908] Elapsed 235m 30s (remain 78m 16s) Loss: 0.0000(0.0056) Grad: 67.1521  LR: 0.000006  \n","Epoch: [1][27800/36908] Elapsed 236m 21s (remain 77m 25s) Loss: 0.0017(0.0055) Grad: 31965.5195  LR: 0.000005  \n","Epoch: [1][27900/36908] Elapsed 237m 10s (remain 76m 33s) Loss: 0.0000(0.0055) Grad: 63.3983  LR: 0.000005  \n","Epoch: [1][28000/36908] Elapsed 238m 0s (remain 75m 42s) Loss: 0.0000(0.0055) Grad: 5.0479  LR: 0.000005  \n","Epoch: [1][28100/36908] Elapsed 238m 50s (remain 74m 51s) Loss: 0.0008(0.0055) Grad: 26895.8027  LR: 0.000005  \n","Epoch: [1][28200/36908] Elapsed 239m 39s (remain 73m 59s) Loss: 0.0000(0.0055) Grad: 160.8861  LR: 0.000005  \n","Epoch: [1][28300/36908] Elapsed 240m 29s (remain 73m 8s) Loss: 0.0007(0.0055) Grad: 43348.7734  LR: 0.000005  \n","Epoch: [1][28400/36908] Elapsed 241m 19s (remain 72m 16s) Loss: 0.0019(0.0055) Grad: 93078.7578  LR: 0.000005  \n","Epoch: [1][28500/36908] Elapsed 242m 8s (remain 71m 25s) Loss: 0.0000(0.0055) Grad: 163.3743  LR: 0.000005  \n","Epoch: [1][28600/36908] Elapsed 242m 58s (remain 70m 34s) Loss: 0.0000(0.0055) Grad: 97.0533  LR: 0.000005  \n","Epoch: [1][28700/36908] Elapsed 243m 48s (remain 69m 43s) Loss: 0.0000(0.0055) Grad: 5803.6401  LR: 0.000005  \n","Epoch: [1][28800/36908] Elapsed 244m 39s (remain 68m 52s) Loss: 0.0023(0.0054) Grad: 285161.6250  LR: 0.000005  \n","Epoch: [1][28900/36908] Elapsed 245m 29s (remain 68m 0s) Loss: 0.0001(0.0054) Grad: 8921.4375  LR: 0.000005  \n","Epoch: [1][29000/36908] Elapsed 246m 18s (remain 67m 9s) Loss: 0.0000(0.0054) Grad: 196.0746  LR: 0.000005  \n","Epoch: [1][29100/36908] Elapsed 247m 8s (remain 66m 18s) Loss: 0.0149(0.0054) Grad: 300041.4062  LR: 0.000005  \n","Epoch: [1][29200/36908] Elapsed 247m 58s (remain 65m 26s) Loss: 0.0000(0.0054) Grad: 176.3688  LR: 0.000005  \n","Epoch: [1][29300/36908] Elapsed 248m 49s (remain 64m 35s) Loss: 0.0000(0.0054) Grad: 102.9197  LR: 0.000005  \n","Epoch: [1][29400/36908] Elapsed 249m 39s (remain 63m 44s) Loss: 0.0000(0.0054) Grad: 72.5336  LR: 0.000005  \n","Epoch: [1][29500/36908] Elapsed 250m 29s (remain 62m 53s) Loss: 0.0000(0.0054) Grad: 813.2651  LR: 0.000004  \n","Epoch: [1][29600/36908] Elapsed 251m 19s (remain 62m 2s) Loss: 0.0001(0.0054) Grad: 4612.0479  LR: 0.000004  \n","Epoch: [1][29700/36908] Elapsed 252m 9s (remain 61m 11s) Loss: 0.0000(0.0054) Grad: 110.1945  LR: 0.000004  \n","Epoch: [1][29800/36908] Elapsed 252m 59s (remain 60m 20s) Loss: 0.0001(0.0054) Grad: 7468.1162  LR: 0.000004  \n","Epoch: [1][29900/36908] Elapsed 253m 50s (remain 59m 29s) Loss: 0.0000(0.0054) Grad: 592.6203  LR: 0.000004  \n","Epoch: [1][30000/36908] Elapsed 254m 40s (remain 58m 38s) Loss: 0.0018(0.0053) Grad: 88055.0703  LR: 0.000004  \n","Epoch: [1][30100/36908] Elapsed 255m 31s (remain 57m 47s) Loss: 0.0000(0.0053) Grad: 3497.5796  LR: 0.000004  \n","Epoch: [1][30200/36908] Elapsed 256m 22s (remain 56m 56s) Loss: 0.0000(0.0053) Grad: 46.5338  LR: 0.000004  \n","Epoch: [1][30300/36908] Elapsed 257m 14s (remain 56m 5s) Loss: 0.0001(0.0053) Grad: 8754.3682  LR: 0.000004  \n","Epoch: [1][30400/36908] Elapsed 258m 5s (remain 55m 14s) Loss: 0.0000(0.0053) Grad: 365.7721  LR: 0.000004  \n","Epoch: [1][30500/36908] Elapsed 258m 56s (remain 54m 23s) Loss: 0.0000(0.0053) Grad: 60.7969  LR: 0.000004  \n","Epoch: [1][30600/36908] Elapsed 259m 47s (remain 53m 32s) Loss: 0.0038(0.0053) Grad: 128733.9609  LR: 0.000004  \n","Epoch: [1][30700/36908] Elapsed 260m 38s (remain 52m 41s) Loss: 0.0000(0.0053) Grad: 266.8879  LR: 0.000004  \n","Epoch: [1][30800/36908] Elapsed 261m 29s (remain 51m 50s) Loss: 0.0010(0.0053) Grad: 22429.5020  LR: 0.000004  \n","Epoch: [1][30900/36908] Elapsed 262m 21s (remain 51m 0s) Loss: 0.0001(0.0053) Grad: 5612.1182  LR: 0.000004  \n","Epoch: [1][31000/36908] Elapsed 263m 12s (remain 50m 9s) Loss: 0.0000(0.0053) Grad: 90.7153  LR: 0.000004  \n","Epoch: [1][31100/36908] Elapsed 264m 4s (remain 49m 18s) Loss: 0.0001(0.0053) Grad: 13390.5283  LR: 0.000003  \n","Epoch: [1][31200/36908] Elapsed 264m 57s (remain 48m 27s) Loss: 0.0000(0.0052) Grad: 58.5820  LR: 0.000003  \n","Epoch: [1][31300/36908] Elapsed 265m 48s (remain 47m 36s) Loss: 0.0000(0.0052) Grad: 22.9653  LR: 0.000003  \n","Epoch: [1][31400/36908] Elapsed 266m 40s (remain 46m 46s) Loss: 0.0000(0.0052) Grad: 29.6310  LR: 0.000003  \n","Epoch: [1][31500/36908] Elapsed 267m 32s (remain 45m 55s) Loss: 0.0000(0.0052) Grad: 35.6567  LR: 0.000003  \n","Epoch: [1][31600/36908] Elapsed 268m 23s (remain 45m 4s) Loss: 0.0039(0.0052) Grad: 100230.1797  LR: 0.000003  \n","Epoch: [1][31700/36908] Elapsed 269m 14s (remain 44m 13s) Loss: 0.0000(0.0052) Grad: 61.6835  LR: 0.000003  \n","Epoch: [1][31800/36908] Elapsed 270m 4s (remain 43m 22s) Loss: 0.0095(0.0052) Grad: 119528.1094  LR: 0.000003  \n","Epoch: [1][31900/36908] Elapsed 270m 54s (remain 42m 31s) Loss: 0.0000(0.0052) Grad: 882.7392  LR: 0.000003  \n","Epoch: [1][32000/36908] Elapsed 271m 44s (remain 41m 40s) Loss: 0.0000(0.0052) Grad: 159.4634  LR: 0.000003  \n","Epoch: [1][32100/36908] Elapsed 272m 34s (remain 40m 48s) Loss: 0.0072(0.0052) Grad: 97383.5938  LR: 0.000003  \n","Epoch: [1][32200/36908] Elapsed 273m 24s (remain 39m 57s) Loss: 0.0001(0.0052) Grad: 6108.7441  LR: 0.000003  \n","Epoch: [1][32300/36908] Elapsed 274m 14s (remain 39m 6s) Loss: 0.0000(0.0052) Grad: 36.5206  LR: 0.000003  \n","Epoch: [1][32400/36908] Elapsed 275m 6s (remain 38m 16s) Loss: 0.0000(0.0052) Grad: 98.2705  LR: 0.000003  \n","Epoch: [1][32500/36908] Elapsed 275m 56s (remain 37m 25s) Loss: 0.0012(0.0052) Grad: 24546.8945  LR: 0.000003  \n","Epoch: [1][32600/36908] Elapsed 276m 46s (remain 36m 33s) Loss: 0.0157(0.0051) Grad: 216940.2188  LR: 0.000003  \n","Epoch: [1][32700/36908] Elapsed 277m 35s (remain 35m 42s) Loss: 0.0000(0.0051) Grad: 66.9540  LR: 0.000003  \n","Epoch: [1][32800/36908] Elapsed 278m 25s (remain 34m 51s) Loss: 0.0156(0.0051) Grad: 121028.9766  LR: 0.000002  \n","Epoch: [1][32900/36908] Elapsed 279m 14s (remain 34m 0s) Loss: 0.0000(0.0051) Grad: 2369.2827  LR: 0.000002  \n","Epoch: [1][33000/36908] Elapsed 280m 4s (remain 33m 9s) Loss: 0.0000(0.0051) Grad: 2489.6509  LR: 0.000002  \n","Epoch: [1][33100/36908] Elapsed 280m 55s (remain 32m 18s) Loss: 0.0000(0.0051) Grad: 69.6391  LR: 0.000002  \n","Epoch: [1][33200/36908] Elapsed 281m 45s (remain 31m 27s) Loss: 0.0010(0.0051) Grad: 48699.0078  LR: 0.000002  \n","Epoch: [1][33300/36908] Elapsed 282m 36s (remain 30m 36s) Loss: 0.0004(0.0051) Grad: 50415.9922  LR: 0.000002  \n","Epoch: [1][33400/36908] Elapsed 283m 26s (remain 29m 45s) Loss: 0.0000(0.0051) Grad: 423.4444  LR: 0.000002  \n","Epoch: [1][33500/36908] Elapsed 284m 15s (remain 28m 54s) Loss: 0.0000(0.0051) Grad: 107.7088  LR: 0.000002  \n","Epoch: [1][33600/36908] Elapsed 285m 6s (remain 28m 3s) Loss: 0.0088(0.0051) Grad: 290973.4062  LR: 0.000002  \n","Epoch: [1][33700/36908] Elapsed 285m 56s (remain 27m 12s) Loss: 0.0000(0.0051) Grad: 773.3822  LR: 0.000002  \n","Epoch: [1][33800/36908] Elapsed 286m 46s (remain 26m 21s) Loss: 0.0003(0.0051) Grad: 52386.4258  LR: 0.000002  \n","Epoch: [1][33900/36908] Elapsed 287m 36s (remain 25m 30s) Loss: 0.0062(0.0050) Grad: 295183.1250  LR: 0.000002  \n","Epoch: [1][34000/36908] Elapsed 288m 27s (remain 24m 39s) Loss: 0.0000(0.0050) Grad: 2011.0701  LR: 0.000002  \n","Epoch: [1][34100/36908] Elapsed 289m 17s (remain 23m 48s) Loss: 0.0000(0.0050) Grad: 119.6364  LR: 0.000002  \n","Epoch: [1][34200/36908] Elapsed 290m 8s (remain 22m 57s) Loss: 0.0000(0.0050) Grad: 15.2228  LR: 0.000002  \n","Epoch: [1][34300/36908] Elapsed 291m 0s (remain 22m 7s) Loss: 0.0017(0.0050) Grad: 97638.2031  LR: 0.000002  \n","Epoch: [1][34400/36908] Elapsed 291m 51s (remain 21m 16s) Loss: 0.0000(0.0050) Grad: 206.5367  LR: 0.000002  \n","Epoch: [1][34500/36908] Elapsed 292m 43s (remain 20m 25s) Loss: 0.0000(0.0050) Grad: 3620.4563  LR: 0.000001  \n","Epoch: [1][34600/36908] Elapsed 293m 34s (remain 19m 34s) Loss: 0.0018(0.0050) Grad: 39312.1250  LR: 0.000001  \n","Epoch: [1][34700/36908] Elapsed 294m 26s (remain 18m 43s) Loss: 0.0000(0.0050) Grad: 37.7243  LR: 0.000001  \n","Epoch: [1][34800/36908] Elapsed 295m 17s (remain 17m 52s) Loss: 0.0000(0.0050) Grad: 713.5381  LR: 0.000001  \n","Epoch: [1][34900/36908] Elapsed 296m 8s (remain 17m 1s) Loss: 0.0022(0.0050) Grad: 35739.1484  LR: 0.000001  \n","Epoch: [1][35000/36908] Elapsed 296m 57s (remain 16m 10s) Loss: 0.0000(0.0050) Grad: 48.5139  LR: 0.000001  \n","Epoch: [1][35100/36908] Elapsed 297m 47s (remain 15m 19s) Loss: 0.0000(0.0050) Grad: 135.8974  LR: 0.000001  \n","Epoch: [1][35200/36908] Elapsed 298m 38s (remain 14m 28s) Loss: 0.0000(0.0050) Grad: 222.5738  LR: 0.000001  \n","Epoch: [1][35300/36908] Elapsed 299m 29s (remain 13m 38s) Loss: 0.0104(0.0049) Grad: 322799.0625  LR: 0.000001  \n","Epoch: [1][35400/36908] Elapsed 300m 19s (remain 12m 47s) Loss: 0.0035(0.0049) Grad: 406320.0000  LR: 0.000001  \n","Epoch: [1][35500/36908] Elapsed 301m 9s (remain 11m 56s) Loss: 0.0000(0.0049) Grad: 252.3354  LR: 0.000001  \n","Epoch: [1][35600/36908] Elapsed 302m 0s (remain 11m 5s) Loss: 0.0000(0.0049) Grad: 90.0909  LR: 0.000001  \n","Epoch: [1][35700/36908] Elapsed 302m 51s (remain 10m 14s) Loss: 0.0000(0.0049) Grad: 1131.7952  LR: 0.000001  \n","Epoch: [1][35800/36908] Elapsed 303m 41s (remain 9m 23s) Loss: 0.0000(0.0049) Grad: 3459.3333  LR: 0.000001  \n","Epoch: [1][35900/36908] Elapsed 304m 32s (remain 8m 32s) Loss: 0.0000(0.0049) Grad: 333.6241  LR: 0.000001  \n","Epoch: [1][36000/36908] Elapsed 305m 22s (remain 7m 41s) Loss: 0.0056(0.0049) Grad: 322515.3125  LR: 0.000001  \n","Epoch: [1][36100/36908] Elapsed 306m 12s (remain 6m 50s) Loss: 0.0422(0.0049) Grad: 977986.5000  LR: 0.000000  \n","Epoch: [1][36200/36908] Elapsed 307m 3s (remain 5m 59s) Loss: 0.0000(0.0049) Grad: 7.6481  LR: 0.000000  \n","Epoch: [1][36300/36908] Elapsed 307m 53s (remain 5m 8s) Loss: 0.0000(0.0049) Grad: 2589.0369  LR: 0.000000  \n","Epoch: [1][36400/36908] Elapsed 308m 43s (remain 4m 17s) Loss: 0.0000(0.0049) Grad: 17.2115  LR: 0.000000  \n","Epoch: [1][36500/36908] Elapsed 309m 32s (remain 3m 27s) Loss: 0.0000(0.0049) Grad: 132.2953  LR: 0.000000  \n","Epoch: [1][36600/36908] Elapsed 310m 22s (remain 2m 36s) Loss: 0.0001(0.0049) Grad: 22558.6797  LR: 0.000000  \n","Epoch: [1][36700/36908] Elapsed 311m 13s (remain 1m 45s) Loss: 0.0000(0.0049) Grad: 303.2439  LR: 0.000000  \n","Epoch: [1][36800/36908] Elapsed 312m 3s (remain 0m 54s) Loss: 0.0000(0.0049) Grad: 296.9577  LR: 0.000000  \n","Epoch: [1][36900/36908] Elapsed 312m 54s (remain 0m 3s) Loss: 0.0000(0.0049) Grad: 208.5962  LR: 0.000000  \n","Epoch: [1][36907/36908] Elapsed 312m 57s (remain 0m 0s) Loss: 0.0000(0.0049) Grad: 151.4352  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 6s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 22s (remain 4m 4s) Loss: 0.0281(0.0114) \n","EVAL: [200/1192] Elapsed 0m 44s (remain 3m 41s) Loss: 0.0311(0.0125) \n","EVAL: [300/1192] Elapsed 1m 7s (remain 3m 18s) Loss: 0.0046(0.0137) \n","EVAL: [400/1192] Elapsed 1m 29s (remain 2m 56s) Loss: 0.0155(0.0142) \n","EVAL: [500/1192] Elapsed 1m 52s (remain 2m 34s) Loss: 0.0195(0.0134) \n","EVAL: [600/1192] Elapsed 2m 14s (remain 2m 12s) Loss: 0.0000(0.0143) \n","EVAL: [700/1192] Elapsed 2m 36s (remain 1m 49s) Loss: 0.1567(0.0167) \n","EVAL: [800/1192] Elapsed 2m 59s (remain 1m 27s) Loss: 0.0098(0.0172) \n","EVAL: [900/1192] Elapsed 3m 21s (remain 1m 5s) Loss: 0.0001(0.0171) \n","EVAL: [1000/1192] Elapsed 3m 43s (remain 0m 42s) Loss: 0.0000(0.0168) \n","EVAL: [1100/1192] Elapsed 4m 5s (remain 0m 20s) Loss: 0.0122(0.0161) \n","EVAL: [1191/1192] Elapsed 4m 25s (remain 0m 0s) Loss: 0.0000(0.0156) \n","Epoch 1 - avg_train_loss: 0.0049  avg_val_loss: 0.0156  time: 19045s\n","Epoch 1 - Score: 0.8881\n","Epoch 1 - Save Best Score: 0.8881 Model\n","========== fold: 1 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_1.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_1.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp083/pseudo_labels_1.npy\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8692487d106a4c07a661a60ba5869bb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"193ecba780d44d45a9bae3de377fc057"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(612602, 950)\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","(110725, 11)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp090/fold1_best.pth\n","Epoch: [1][0/36908] Elapsed 0m 1s (remain 649m 26s) Loss: 0.3673(0.3673) Grad: 190636.9375  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 52s (remain 318m 14s) Loss: 0.3313(0.3532) Grad: 177621.4688  LR: 0.000001  \n","Epoch: [1][200/36908] Elapsed 1m 43s (remain 314m 48s) Loss: 0.2339(0.3188) Grad: 130486.3203  LR: 0.000001  \n","Epoch: [1][300/36908] Elapsed 2m 34s (remain 313m 43s) Loss: 0.1242(0.2713) Grad: 78496.4844  LR: 0.000002  \n","Epoch: [1][400/36908] Elapsed 3m 26s (remain 312m 57s) Loss: 0.0604(0.2237) Grad: 32382.8633  LR: 0.000002  \n","Epoch: [1][500/36908] Elapsed 4m 17s (remain 311m 30s) Loss: 0.0240(0.1851) Grad: 9983.5215  LR: 0.000003  \n","Epoch: [1][600/36908] Elapsed 5m 8s (remain 310m 12s) Loss: 0.0084(0.1565) Grad: 2898.0903  LR: 0.000003  \n","Epoch: [1][700/36908] Elapsed 5m 58s (remain 309m 1s) Loss: 0.0029(0.1350) Grad: 932.5056  LR: 0.000004  \n","Epoch: [1][800/36908] Elapsed 6m 49s (remain 307m 50s) Loss: 0.0026(0.1187) Grad: 990.9317  LR: 0.000004  \n","Epoch: [1][900/36908] Elapsed 7m 40s (remain 306m 58s) Loss: 0.0001(0.1061) Grad: 236.9072  LR: 0.000005  \n","Epoch: [1][1000/36908] Elapsed 8m 31s (remain 306m 4s) Loss: 0.0020(0.0959) Grad: 748.5955  LR: 0.000005  \n","Epoch: [1][1100/36908] Elapsed 9m 22s (remain 305m 9s) Loss: 0.0044(0.0875) Grad: 3212.3169  LR: 0.000006  \n","Epoch: [1][1200/36908] Elapsed 10m 13s (remain 303m 59s) Loss: 0.0029(0.0805) Grad: 943.9782  LR: 0.000007  \n","Epoch: [1][1300/36908] Elapsed 11m 4s (remain 303m 6s) Loss: 0.0050(0.0745) Grad: 1905.1750  LR: 0.000007  \n","Epoch: [1][1400/36908] Elapsed 11m 55s (remain 302m 1s) Loss: 0.0028(0.0695) Grad: 2075.5857  LR: 0.000008  \n","Epoch: [1][1500/36908] Elapsed 12m 45s (remain 301m 3s) Loss: 0.0002(0.0650) Grad: 129.9756  LR: 0.000008  \n","Epoch: [1][1600/36908] Elapsed 13m 36s (remain 300m 15s) Loss: 0.0100(0.0612) Grad: 2025.0808  LR: 0.000009  \n","Epoch: [1][1700/36908] Elapsed 14m 28s (remain 299m 30s) Loss: 0.0011(0.0577) Grad: 354.0418  LR: 0.000009  \n","Epoch: [1][1800/36908] Elapsed 15m 20s (remain 298m 54s) Loss: 0.0002(0.0547) Grad: 115.4593  LR: 0.000010  \n","Epoch: [1][1900/36908] Elapsed 16m 11s (remain 298m 17s) Loss: 0.0008(0.0520) Grad: 933.3542  LR: 0.000010  \n","Epoch: [1][2000/36908] Elapsed 17m 3s (remain 297m 37s) Loss: 0.0004(0.0495) Grad: 235.5619  LR: 0.000011  \n","Epoch: [1][2100/36908] Elapsed 17m 55s (remain 296m 56s) Loss: 0.0017(0.0473) Grad: 1384.5913  LR: 0.000011  \n","Epoch: [1][2200/36908] Elapsed 18m 47s (remain 296m 17s) Loss: 0.0003(0.0452) Grad: 220.7830  LR: 0.000012  \n","Epoch: [1][2300/36908] Elapsed 19m 38s (remain 295m 31s) Loss: 0.0002(0.0434) Grad: 160.2552  LR: 0.000012  \n","Epoch: [1][2400/36908] Elapsed 20m 28s (remain 294m 12s) Loss: 0.0007(0.0417) Grad: 320.7438  LR: 0.000013  \n","Epoch: [1][2500/36908] Elapsed 21m 18s (remain 293m 2s) Loss: 0.0005(0.0401) Grad: 239.4523  LR: 0.000014  \n","Epoch: [1][2600/36908] Elapsed 22m 9s (remain 292m 13s) Loss: 0.0067(0.0387) Grad: 2662.9131  LR: 0.000014  \n","Epoch: [1][2700/36908] Elapsed 22m 59s (remain 291m 9s) Loss: 0.0007(0.0373) Grad: 351.5497  LR: 0.000015  \n","Epoch: [1][2800/36908] Elapsed 23m 49s (remain 290m 6s) Loss: 0.0004(0.0361) Grad: 185.3189  LR: 0.000015  \n","Epoch: [1][2900/36908] Elapsed 24m 41s (remain 289m 23s) Loss: 0.0003(0.0349) Grad: 146.2510  LR: 0.000016  \n","Epoch: [1][3000/36908] Elapsed 25m 32s (remain 288m 30s) Loss: 0.0002(0.0338) Grad: 170.7888  LR: 0.000016  \n","Epoch: [1][3100/36908] Elapsed 26m 22s (remain 287m 30s) Loss: 0.0006(0.0328) Grad: 753.3876  LR: 0.000017  \n","Epoch: [1][3200/36908] Elapsed 27m 12s (remain 286m 34s) Loss: 0.0002(0.0319) Grad: 162.4443  LR: 0.000017  \n","Epoch: [1][3300/36908] Elapsed 28m 3s (remain 285m 39s) Loss: 0.0020(0.0310) Grad: 840.2264  LR: 0.000018  \n","Epoch: [1][3400/36908] Elapsed 28m 54s (remain 284m 47s) Loss: 0.0001(0.0301) Grad: 48.1413  LR: 0.000018  \n","Epoch: [1][3500/36908] Elapsed 29m 44s (remain 283m 51s) Loss: 0.0031(0.0293) Grad: 1856.3555  LR: 0.000019  \n","Epoch: [1][3600/36908] Elapsed 30m 35s (remain 282m 53s) Loss: 0.0004(0.0286) Grad: 404.0581  LR: 0.000020  \n","Epoch: [1][3700/36908] Elapsed 31m 25s (remain 281m 54s) Loss: 0.0002(0.0278) Grad: 124.6576  LR: 0.000020  \n","Epoch: [1][3800/36908] Elapsed 32m 15s (remain 280m 56s) Loss: 0.0051(0.0272) Grad: 5361.5586  LR: 0.000020  \n","Epoch: [1][3900/36908] Elapsed 33m 6s (remain 280m 8s) Loss: 0.0019(0.0265) Grad: 2121.4187  LR: 0.000020  \n","Epoch: [1][4000/36908] Elapsed 33m 56s (remain 279m 10s) Loss: 0.0000(0.0259) Grad: 66.7822  LR: 0.000020  \n","Epoch: [1][4100/36908] Elapsed 34m 46s (remain 278m 14s) Loss: 0.0013(0.0254) Grad: 2452.5540  LR: 0.000020  \n","Epoch: [1][4200/36908] Elapsed 35m 36s (remain 277m 14s) Loss: 0.0004(0.0248) Grad: 556.1970  LR: 0.000020  \n","Epoch: [1][4300/36908] Elapsed 36m 26s (remain 276m 14s) Loss: 0.0046(0.0243) Grad: 9315.2334  LR: 0.000020  \n","Epoch: [1][4400/36908] Elapsed 37m 16s (remain 275m 16s) Loss: 0.0001(0.0238) Grad: 198.1013  LR: 0.000020  \n","Epoch: [1][4500/36908] Elapsed 38m 5s (remain 274m 18s) Loss: 0.0008(0.0233) Grad: 3049.7305  LR: 0.000020  \n","Epoch: [1][4600/36908] Elapsed 38m 56s (remain 273m 23s) Loss: 0.0087(0.0228) Grad: 5137.1113  LR: 0.000019  \n","Epoch: [1][4700/36908] Elapsed 39m 46s (remain 272m 27s) Loss: 0.0000(0.0224) Grad: 53.0988  LR: 0.000019  \n","Epoch: [1][4800/36908] Elapsed 40m 36s (remain 271m 31s) Loss: 0.0000(0.0220) Grad: 63.6412  LR: 0.000019  \n","Epoch: [1][4900/36908] Elapsed 41m 26s (remain 270m 37s) Loss: 0.0116(0.0216) Grad: 12277.5781  LR: 0.000019  \n","Epoch: [1][5000/36908] Elapsed 42m 17s (remain 269m 47s) Loss: 0.0004(0.0212) Grad: 1335.2782  LR: 0.000019  \n","Epoch: [1][5100/36908] Elapsed 43m 7s (remain 268m 55s) Loss: 0.0001(0.0208) Grad: 166.0235  LR: 0.000019  \n","Epoch: [1][5200/36908] Elapsed 43m 58s (remain 268m 4s) Loss: 0.0132(0.0205) Grad: 10009.2705  LR: 0.000019  \n","Epoch: [1][5300/36908] Elapsed 44m 48s (remain 267m 12s) Loss: 0.0002(0.0201) Grad: 620.8494  LR: 0.000019  \n","Epoch: [1][5400/36908] Elapsed 45m 39s (remain 266m 23s) Loss: 0.0003(0.0198) Grad: 818.7142  LR: 0.000019  \n","Epoch: [1][5500/36908] Elapsed 46m 30s (remain 265m 34s) Loss: 0.0000(0.0195) Grad: 20.9433  LR: 0.000019  \n","Epoch: [1][5600/36908] Elapsed 47m 22s (remain 264m 45s) Loss: 0.0011(0.0192) Grad: 1667.5625  LR: 0.000019  \n","Epoch: [1][5700/36908] Elapsed 48m 13s (remain 263m 57s) Loss: 0.0009(0.0189) Grad: 1354.1208  LR: 0.000019  \n","Epoch: [1][5800/36908] Elapsed 49m 4s (remain 263m 8s) Loss: 0.0000(0.0186) Grad: 73.5298  LR: 0.000019  \n","Epoch: [1][5900/36908] Elapsed 49m 55s (remain 262m 17s) Loss: 0.0000(0.0184) Grad: 123.5018  LR: 0.000019  \n","Epoch: [1][6000/36908] Elapsed 50m 45s (remain 261m 26s) Loss: 0.0030(0.0181) Grad: 2881.2871  LR: 0.000019  \n","Epoch: [1][6100/36908] Elapsed 51m 36s (remain 260m 37s) Loss: 0.0009(0.0178) Grad: 1698.3324  LR: 0.000019  \n","Epoch: [1][6200/36908] Elapsed 52m 27s (remain 259m 47s) Loss: 0.0033(0.0176) Grad: 6835.1133  LR: 0.000018  \n","Epoch: [1][6300/36908] Elapsed 53m 18s (remain 258m 58s) Loss: 0.0186(0.0173) Grad: 10152.8145  LR: 0.000018  \n","Epoch: [1][6400/36908] Elapsed 54m 9s (remain 258m 8s) Loss: 0.0293(0.0171) Grad: 33727.8555  LR: 0.000018  \n","Epoch: [1][6500/36908] Elapsed 55m 0s (remain 257m 18s) Loss: 0.0031(0.0169) Grad: 2786.9541  LR: 0.000018  \n","Epoch: [1][6600/36908] Elapsed 55m 51s (remain 256m 28s) Loss: 0.0000(0.0166) Grad: 180.9197  LR: 0.000018  \n","Epoch: [1][6700/36908] Elapsed 56m 41s (remain 255m 35s) Loss: 0.0001(0.0164) Grad: 259.0532  LR: 0.000018  \n","Epoch: [1][6800/36908] Elapsed 57m 32s (remain 254m 44s) Loss: 0.0001(0.0162) Grad: 209.5891  LR: 0.000018  \n","Epoch: [1][6900/36908] Elapsed 58m 24s (remain 253m 58s) Loss: 0.0000(0.0160) Grad: 16.2990  LR: 0.000018  \n","Epoch: [1][7000/36908] Elapsed 59m 15s (remain 253m 6s) Loss: 0.0000(0.0158) Grad: 50.9246  LR: 0.000018  \n","Epoch: [1][7100/36908] Elapsed 60m 5s (remain 252m 13s) Loss: 0.0000(0.0156) Grad: 45.1650  LR: 0.000018  \n","Epoch: [1][7200/36908] Elapsed 60m 55s (remain 251m 19s) Loss: 0.0038(0.0154) Grad: 8588.7881  LR: 0.000018  \n","Epoch: [1][7300/36908] Elapsed 61m 45s (remain 250m 26s) Loss: 0.0003(0.0153) Grad: 889.7989  LR: 0.000018  \n","Epoch: [1][7400/36908] Elapsed 62m 35s (remain 249m 33s) Loss: 0.0000(0.0151) Grad: 124.7960  LR: 0.000018  \n","Epoch: [1][7500/36908] Elapsed 63m 26s (remain 248m 41s) Loss: 0.0001(0.0149) Grad: 181.9503  LR: 0.000018  \n","Epoch: [1][7600/36908] Elapsed 64m 16s (remain 247m 49s) Loss: 0.0001(0.0148) Grad: 172.7857  LR: 0.000018  \n","Epoch: [1][7700/36908] Elapsed 65m 6s (remain 246m 57s) Loss: 0.0084(0.0146) Grad: 10882.9355  LR: 0.000018  \n","Epoch: [1][7800/36908] Elapsed 65m 57s (remain 246m 6s) Loss: 0.0002(0.0144) Grad: 873.4683  LR: 0.000018  \n","Epoch: [1][7900/36908] Elapsed 66m 47s (remain 245m 14s) Loss: 0.0011(0.0143) Grad: 2053.7446  LR: 0.000017  \n","Epoch: [1][8000/36908] Elapsed 67m 38s (remain 244m 22s) Loss: 0.0000(0.0141) Grad: 118.4353  LR: 0.000017  \n","Epoch: [1][8100/36908] Elapsed 68m 28s (remain 243m 31s) Loss: 0.0000(0.0140) Grad: 48.0201  LR: 0.000017  \n","Epoch: [1][8200/36908] Elapsed 69m 19s (remain 242m 39s) Loss: 0.0008(0.0138) Grad: 3010.0398  LR: 0.000017  \n","Epoch: [1][8300/36908] Elapsed 70m 9s (remain 241m 46s) Loss: 0.0000(0.0137) Grad: 138.4669  LR: 0.000017  \n","Epoch: [1][8400/36908] Elapsed 70m 59s (remain 240m 55s) Loss: 0.0000(0.0136) Grad: 180.2693  LR: 0.000017  \n","Epoch: [1][8500/36908] Elapsed 71m 50s (remain 240m 2s) Loss: 0.0000(0.0135) Grad: 120.9388  LR: 0.000017  \n","Epoch: [1][8600/36908] Elapsed 72m 40s (remain 239m 11s) Loss: 0.0000(0.0133) Grad: 27.4153  LR: 0.000017  \n","Epoch: [1][8700/36908] Elapsed 73m 30s (remain 238m 19s) Loss: 0.0147(0.0132) Grad: 25971.8301  LR: 0.000017  \n","Epoch: [1][8800/36908] Elapsed 74m 20s (remain 237m 26s) Loss: 0.0001(0.0131) Grad: 373.3916  LR: 0.000017  \n","Epoch: [1][8900/36908] Elapsed 75m 10s (remain 236m 32s) Loss: 0.0012(0.0130) Grad: 1796.1506  LR: 0.000017  \n","Epoch: [1][9000/36908] Elapsed 76m 0s (remain 235m 39s) Loss: 0.0000(0.0128) Grad: 33.9397  LR: 0.000017  \n","Epoch: [1][9100/36908] Elapsed 76m 50s (remain 234m 47s) Loss: 0.0000(0.0127) Grad: 91.6878  LR: 0.000017  \n","Epoch: [1][9200/36908] Elapsed 77m 40s (remain 233m 55s) Loss: 0.0055(0.0126) Grad: 28277.2695  LR: 0.000017  \n","Epoch: [1][9300/36908] Elapsed 78m 31s (remain 233m 3s) Loss: 0.0001(0.0125) Grad: 293.7298  LR: 0.000017  \n","Epoch: [1][9400/36908] Elapsed 79m 21s (remain 232m 11s) Loss: 0.0000(0.0124) Grad: 67.2977  LR: 0.000017  \n","Epoch: [1][9500/36908] Elapsed 80m 11s (remain 231m 18s) Loss: 0.0000(0.0123) Grad: 145.8226  LR: 0.000017  \n","Epoch: [1][9600/36908] Elapsed 81m 1s (remain 230m 26s) Loss: 0.0000(0.0122) Grad: 11.9866  LR: 0.000016  \n","Epoch: [1][9700/36908] Elapsed 81m 51s (remain 229m 34s) Loss: 0.0000(0.0121) Grad: 195.7560  LR: 0.000016  \n","Epoch: [1][9800/36908] Elapsed 82m 42s (remain 228m 43s) Loss: 0.0004(0.0120) Grad: 2395.6716  LR: 0.000016  \n","Epoch: [1][9900/36908] Elapsed 83m 32s (remain 227m 53s) Loss: 0.0038(0.0119) Grad: 14448.9609  LR: 0.000016  \n","Epoch: [1][10000/36908] Elapsed 84m 22s (remain 227m 0s) Loss: 0.0032(0.0118) Grad: 5327.7900  LR: 0.000016  \n","Epoch: [1][10100/36908] Elapsed 85m 12s (remain 226m 8s) Loss: 0.0000(0.0117) Grad: 134.4301  LR: 0.000016  \n","Epoch: [1][10200/36908] Elapsed 86m 3s (remain 225m 17s) Loss: 0.0001(0.0116) Grad: 424.5177  LR: 0.000016  \n","Epoch: [1][10300/36908] Elapsed 86m 53s (remain 224m 25s) Loss: 0.0000(0.0115) Grad: 241.4979  LR: 0.000016  \n","Epoch: [1][10400/36908] Elapsed 87m 43s (remain 223m 33s) Loss: 0.0008(0.0114) Grad: 2450.6785  LR: 0.000016  \n","Epoch: [1][10500/36908] Elapsed 88m 33s (remain 222m 41s) Loss: 0.0000(0.0113) Grad: 160.8440  LR: 0.000016  \n","Epoch: [1][10600/36908] Elapsed 89m 23s (remain 221m 49s) Loss: 0.0000(0.0112) Grad: 28.5445  LR: 0.000016  \n","Epoch: [1][10700/36908] Elapsed 90m 13s (remain 220m 58s) Loss: 0.0000(0.0111) Grad: 150.5124  LR: 0.000016  \n","Epoch: [1][10800/36908] Elapsed 91m 4s (remain 220m 7s) Loss: 0.0024(0.0111) Grad: 12462.9756  LR: 0.000016  \n","Epoch: [1][10900/36908] Elapsed 91m 55s (remain 219m 18s) Loss: 0.0001(0.0110) Grad: 910.7963  LR: 0.000016  \n","Epoch: [1][11000/36908] Elapsed 92m 45s (remain 218m 27s) Loss: 0.0059(0.0109) Grad: 21940.2461  LR: 0.000016  \n","Epoch: [1][11100/36908] Elapsed 93m 36s (remain 217m 36s) Loss: 0.0014(0.0108) Grad: 5585.3389  LR: 0.000016  \n","Epoch: [1][11200/36908] Elapsed 94m 27s (remain 216m 46s) Loss: 0.0000(0.0107) Grad: 115.8631  LR: 0.000015  \n","Epoch: [1][11300/36908] Elapsed 95m 18s (remain 215m 57s) Loss: 0.0000(0.0107) Grad: 64.6001  LR: 0.000015  \n","Epoch: [1][11400/36908] Elapsed 96m 8s (remain 215m 6s) Loss: 0.0000(0.0106) Grad: 16.7566  LR: 0.000015  \n","Epoch: [1][11500/36908] Elapsed 96m 59s (remain 214m 14s) Loss: 0.0013(0.0105) Grad: 7900.3623  LR: 0.000015  \n","Epoch: [1][11600/36908] Elapsed 97m 49s (remain 213m 23s) Loss: 0.0000(0.0104) Grad: 203.4371  LR: 0.000015  \n","Epoch: [1][11700/36908] Elapsed 98m 39s (remain 212m 32s) Loss: 0.0024(0.0104) Grad: 4478.3789  LR: 0.000015  \n","Epoch: [1][11800/36908] Elapsed 99m 30s (remain 211m 42s) Loss: 0.0002(0.0103) Grad: 1385.7510  LR: 0.000015  \n","Epoch: [1][11900/36908] Elapsed 100m 20s (remain 210m 50s) Loss: 0.0064(0.0102) Grad: 24964.6992  LR: 0.000015  \n","Epoch: [1][12000/36908] Elapsed 101m 11s (remain 210m 0s) Loss: 0.0000(0.0102) Grad: 260.9951  LR: 0.000015  \n","Epoch: [1][12100/36908] Elapsed 102m 2s (remain 209m 10s) Loss: 0.0000(0.0101) Grad: 137.6707  LR: 0.000015  \n","Epoch: [1][12200/36908] Elapsed 102m 52s (remain 208m 19s) Loss: 0.0008(0.0100) Grad: 5952.6611  LR: 0.000015  \n","Epoch: [1][12300/36908] Elapsed 103m 43s (remain 207m 29s) Loss: 0.0000(0.0100) Grad: 887.5868  LR: 0.000015  \n","Epoch: [1][12400/36908] Elapsed 104m 34s (remain 206m 39s) Loss: 0.0036(0.0099) Grad: 8287.2842  LR: 0.000015  \n","Epoch: [1][12500/36908] Elapsed 105m 24s (remain 205m 48s) Loss: 0.0001(0.0098) Grad: 2197.0796  LR: 0.000015  \n","Epoch: [1][12600/36908] Elapsed 106m 14s (remain 204m 57s) Loss: 0.0012(0.0098) Grad: 8484.8975  LR: 0.000015  \n","Epoch: [1][12700/36908] Elapsed 107m 4s (remain 204m 5s) Loss: 0.0000(0.0097) Grad: 33.1368  LR: 0.000015  \n","Epoch: [1][12800/36908] Elapsed 107m 55s (remain 203m 13s) Loss: 0.0000(0.0097) Grad: 20.7566  LR: 0.000015  \n","Epoch: [1][12900/36908] Elapsed 108m 45s (remain 202m 22s) Loss: 0.0000(0.0096) Grad: 86.3779  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 109m 35s (remain 201m 30s) Loss: 0.0022(0.0095) Grad: 16357.3574  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 110m 25s (remain 200m 39s) Loss: 0.0000(0.0095) Grad: 382.8841  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 111m 15s (remain 199m 48s) Loss: 0.0024(0.0094) Grad: 18043.7949  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 112m 6s (remain 198m 57s) Loss: 0.0000(0.0094) Grad: 302.3457  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 112m 56s (remain 198m 6s) Loss: 0.0000(0.0093) Grad: 107.0967  LR: 0.000014  \n","Epoch: [1][13500/36908] Elapsed 113m 46s (remain 197m 15s) Loss: 0.0033(0.0093) Grad: 20483.0410  LR: 0.000014  \n","Epoch: [1][13600/36908] Elapsed 114m 36s (remain 196m 24s) Loss: 0.0000(0.0092) Grad: 774.4928  LR: 0.000014  \n","Epoch: [1][13700/36908] Elapsed 115m 27s (remain 195m 33s) Loss: 0.0000(0.0092) Grad: 149.9759  LR: 0.000014  \n","Epoch: [1][13800/36908] Elapsed 116m 18s (remain 194m 43s) Loss: 0.0000(0.0091) Grad: 255.9485  LR: 0.000014  \n","Epoch: [1][13900/36908] Elapsed 117m 9s (remain 193m 54s) Loss: 0.0006(0.0091) Grad: 9115.9912  LR: 0.000014  \n","Epoch: [1][14000/36908] Elapsed 118m 1s (remain 193m 6s) Loss: 0.0000(0.0090) Grad: 33.2788  LR: 0.000014  \n","Epoch: [1][14100/36908] Elapsed 118m 53s (remain 192m 18s) Loss: 0.0053(0.0090) Grad: 17385.8496  LR: 0.000014  \n","Epoch: [1][14200/36908] Elapsed 119m 46s (remain 191m 30s) Loss: 0.0005(0.0089) Grad: 4499.9531  LR: 0.000014  \n","Epoch: [1][14300/36908] Elapsed 120m 38s (remain 190m 42s) Loss: 0.0039(0.0089) Grad: 21338.3926  LR: 0.000014  \n","Epoch: [1][14400/36908] Elapsed 121m 29s (remain 189m 53s) Loss: 0.0000(0.0088) Grad: 230.3448  LR: 0.000014  \n","Epoch: [1][14500/36908] Elapsed 122m 21s (remain 189m 4s) Loss: 0.0000(0.0088) Grad: 369.5480  LR: 0.000013  \n","Epoch: [1][14600/36908] Elapsed 123m 13s (remain 188m 15s) Loss: 0.0144(0.0088) Grad: 89637.7188  LR: 0.000013  \n","Epoch: [1][14700/36908] Elapsed 124m 4s (remain 187m 24s) Loss: 0.0001(0.0087) Grad: 1030.5156  LR: 0.000013  \n","Epoch: [1][14800/36908] Elapsed 124m 54s (remain 186m 33s) Loss: 0.0009(0.0087) Grad: 7702.3501  LR: 0.000013  \n","Epoch: [1][14900/36908] Elapsed 125m 44s (remain 185m 42s) Loss: 0.0001(0.0086) Grad: 2514.3174  LR: 0.000013  \n","Epoch: [1][15000/36908] Elapsed 126m 35s (remain 184m 51s) Loss: 0.0003(0.0086) Grad: 4350.4614  LR: 0.000013  \n","Epoch: [1][15100/36908] Elapsed 127m 25s (remain 184m 0s) Loss: 0.0000(0.0086) Grad: 76.6622  LR: 0.000013  \n","Epoch: [1][15200/36908] Elapsed 128m 15s (remain 183m 9s) Loss: 0.0003(0.0085) Grad: 4839.7920  LR: 0.000013  \n","Epoch: [1][15300/36908] Elapsed 129m 6s (remain 182m 18s) Loss: 0.0009(0.0085) Grad: 9833.0879  LR: 0.000013  \n","Epoch: [1][15400/36908] Elapsed 129m 55s (remain 181m 26s) Loss: 0.0000(0.0084) Grad: 12.4679  LR: 0.000013  \n","Epoch: [1][15500/36908] Elapsed 130m 45s (remain 180m 35s) Loss: 0.0000(0.0084) Grad: 75.4907  LR: 0.000013  \n","Epoch: [1][15600/36908] Elapsed 131m 36s (remain 179m 43s) Loss: 0.0000(0.0084) Grad: 46.1099  LR: 0.000013  \n","Epoch: [1][15700/36908] Elapsed 132m 26s (remain 178m 53s) Loss: 0.0001(0.0083) Grad: 631.8049  LR: 0.000013  \n","Epoch: [1][15800/36908] Elapsed 133m 18s (remain 178m 4s) Loss: 0.0000(0.0083) Grad: 23.4180  LR: 0.000013  \n","Epoch: [1][15900/36908] Elapsed 134m 8s (remain 177m 13s) Loss: 0.0000(0.0082) Grad: 217.4922  LR: 0.000013  \n","Epoch: [1][16000/36908] Elapsed 134m 59s (remain 176m 22s) Loss: 0.0001(0.0082) Grad: 1085.1626  LR: 0.000013  \n","Epoch: [1][16100/36908] Elapsed 135m 49s (remain 175m 31s) Loss: 0.0292(0.0082) Grad: 191263.3750  LR: 0.000013  \n","Epoch: [1][16200/36908] Elapsed 136m 39s (remain 174m 39s) Loss: 0.0000(0.0081) Grad: 229.8718  LR: 0.000012  \n","Epoch: [1][16300/36908] Elapsed 137m 29s (remain 173m 48s) Loss: 0.0045(0.0081) Grad: 39397.0039  LR: 0.000012  \n","Epoch: [1][16400/36908] Elapsed 138m 19s (remain 172m 57s) Loss: 0.0015(0.0081) Grad: 15846.0850  LR: 0.000012  \n","Epoch: [1][16500/36908] Elapsed 139m 10s (remain 172m 6s) Loss: 0.0060(0.0080) Grad: 117047.3125  LR: 0.000012  \n","Epoch: [1][16600/36908] Elapsed 140m 0s (remain 171m 15s) Loss: 0.0000(0.0080) Grad: 206.6947  LR: 0.000012  \n","Epoch: [1][16700/36908] Elapsed 140m 51s (remain 170m 25s) Loss: 0.0000(0.0080) Grad: 46.7619  LR: 0.000012  \n","Epoch: [1][16800/36908] Elapsed 141m 41s (remain 169m 34s) Loss: 0.0000(0.0079) Grad: 362.2517  LR: 0.000012  \n","Epoch: [1][16900/36908] Elapsed 142m 32s (remain 168m 44s) Loss: 0.0016(0.0079) Grad: 10206.6396  LR: 0.000012  \n","Epoch: [1][17000/36908] Elapsed 143m 23s (remain 167m 53s) Loss: 0.0023(0.0079) Grad: 30973.9355  LR: 0.000012  \n","Epoch: [1][17100/36908] Elapsed 144m 13s (remain 167m 2s) Loss: 0.0093(0.0078) Grad: 56793.6875  LR: 0.000012  \n","Epoch: [1][17200/36908] Elapsed 145m 4s (remain 166m 12s) Loss: 0.0002(0.0078) Grad: 7025.5947  LR: 0.000012  \n","Epoch: [1][17300/36908] Elapsed 145m 55s (remain 165m 22s) Loss: 0.0004(0.0078) Grad: 8117.6646  LR: 0.000012  \n","Epoch: [1][17400/36908] Elapsed 146m 45s (remain 164m 31s) Loss: 0.0041(0.0077) Grad: 51794.3516  LR: 0.000012  \n","Epoch: [1][17500/36908] Elapsed 147m 35s (remain 163m 40s) Loss: 0.0146(0.0077) Grad: 109149.0156  LR: 0.000012  \n","Epoch: [1][17600/36908] Elapsed 148m 26s (remain 162m 49s) Loss: 0.0034(0.0077) Grad: 83322.6953  LR: 0.000012  \n","Epoch: [1][17700/36908] Elapsed 149m 16s (remain 161m 58s) Loss: 0.0014(0.0077) Grad: 13692.3545  LR: 0.000012  \n","Epoch: [1][17800/36908] Elapsed 150m 7s (remain 161m 7s) Loss: 0.0001(0.0076) Grad: 3025.9043  LR: 0.000012  \n","Epoch: [1][17900/36908] Elapsed 150m 57s (remain 160m 16s) Loss: 0.0000(0.0076) Grad: 45.4119  LR: 0.000011  \n","Epoch: [1][18000/36908] Elapsed 151m 47s (remain 159m 26s) Loss: 0.0016(0.0076) Grad: 9048.6045  LR: 0.000011  \n","Epoch: [1][18100/36908] Elapsed 152m 37s (remain 158m 34s) Loss: 0.0222(0.0076) Grad: 196054.9375  LR: 0.000011  \n","Epoch: [1][18200/36908] Elapsed 153m 27s (remain 157m 43s) Loss: 0.0000(0.0075) Grad: 157.4280  LR: 0.000011  \n","Epoch: [1][18300/36908] Elapsed 154m 17s (remain 156m 52s) Loss: 0.0000(0.0075) Grad: 735.5217  LR: 0.000011  \n","Epoch: [1][18400/36908] Elapsed 155m 7s (remain 156m 0s) Loss: 0.0058(0.0075) Grad: 109530.3516  LR: 0.000011  \n","Epoch: [1][18500/36908] Elapsed 155m 57s (remain 155m 9s) Loss: 0.0075(0.0074) Grad: 58846.0391  LR: 0.000011  \n","Epoch: [1][18600/36908] Elapsed 156m 47s (remain 154m 18s) Loss: 0.0003(0.0074) Grad: 9080.2119  LR: 0.000011  \n","Epoch: [1][18700/36908] Elapsed 157m 37s (remain 153m 27s) Loss: 0.0004(0.0074) Grad: 7732.0483  LR: 0.000011  \n","Epoch: [1][18800/36908] Elapsed 158m 27s (remain 152m 36s) Loss: 0.0001(0.0074) Grad: 3898.9578  LR: 0.000011  \n","Epoch: [1][18900/36908] Elapsed 159m 17s (remain 151m 45s) Loss: 0.0000(0.0073) Grad: 85.4018  LR: 0.000011  \n","Epoch: [1][19000/36908] Elapsed 160m 8s (remain 150m 55s) Loss: 0.0027(0.0073) Grad: 58201.7344  LR: 0.000011  \n","Epoch: [1][19100/36908] Elapsed 160m 58s (remain 150m 4s) Loss: 0.0005(0.0073) Grad: 9212.6885  LR: 0.000011  \n","Epoch: [1][19200/36908] Elapsed 161m 48s (remain 149m 13s) Loss: 0.0001(0.0073) Grad: 3222.5273  LR: 0.000011  \n","Epoch: [1][19300/36908] Elapsed 162m 39s (remain 148m 22s) Loss: 0.0000(0.0072) Grad: 110.2336  LR: 0.000011  \n","Epoch: [1][19400/36908] Elapsed 163m 29s (remain 147m 31s) Loss: 0.0000(0.0072) Grad: 78.9437  LR: 0.000011  \n","Epoch: [1][19500/36908] Elapsed 164m 19s (remain 146m 40s) Loss: 0.0014(0.0072) Grad: 8109.1099  LR: 0.000010  \n","Epoch: [1][19600/36908] Elapsed 165m 8s (remain 145m 49s) Loss: 0.0045(0.0072) Grad: 43176.8242  LR: 0.000010  \n","Epoch: [1][19700/36908] Elapsed 165m 59s (remain 144m 58s) Loss: 0.0019(0.0072) Grad: 11257.1660  LR: 0.000010  \n","Epoch: [1][19800/36908] Elapsed 166m 50s (remain 144m 8s) Loss: 0.0147(0.0071) Grad: 129573.0078  LR: 0.000010  \n","Epoch: [1][19900/36908] Elapsed 167m 40s (remain 143m 17s) Loss: 0.0000(0.0071) Grad: 12.0853  LR: 0.000010  \n","Epoch: [1][20000/36908] Elapsed 168m 31s (remain 142m 27s) Loss: 0.0000(0.0071) Grad: 117.5402  LR: 0.000010  \n","Epoch: [1][20100/36908] Elapsed 169m 22s (remain 141m 36s) Loss: 0.0000(0.0071) Grad: 463.8053  LR: 0.000010  \n","Epoch: [1][20200/36908] Elapsed 170m 12s (remain 140m 46s) Loss: 0.0000(0.0070) Grad: 483.9651  LR: 0.000010  \n","Epoch: [1][20300/36908] Elapsed 171m 2s (remain 139m 55s) Loss: 0.0269(0.0070) Grad: 383506.7188  LR: 0.000010  \n","Epoch: [1][20400/36908] Elapsed 171m 53s (remain 139m 4s) Loss: 0.0000(0.0070) Grad: 215.0523  LR: 0.000010  \n","Epoch: [1][20500/36908] Elapsed 172m 43s (remain 138m 14s) Loss: 0.0001(0.0070) Grad: 6095.0366  LR: 0.000010  \n","Epoch: [1][20600/36908] Elapsed 173m 34s (remain 137m 23s) Loss: 0.0010(0.0070) Grad: 20074.0020  LR: 0.000010  \n","Epoch: [1][20700/36908] Elapsed 174m 24s (remain 136m 33s) Loss: 0.0005(0.0069) Grad: 19401.1348  LR: 0.000010  \n","Epoch: [1][20800/36908] Elapsed 175m 15s (remain 135m 42s) Loss: 0.0000(0.0069) Grad: 702.2313  LR: 0.000010  \n","Epoch: [1][20900/36908] Elapsed 176m 4s (remain 134m 51s) Loss: 0.0009(0.0069) Grad: 27723.5410  LR: 0.000010  \n","Epoch: [1][21000/36908] Elapsed 176m 55s (remain 134m 0s) Loss: 0.0000(0.0069) Grad: 82.2243  LR: 0.000010  \n","Epoch: [1][21100/36908] Elapsed 177m 45s (remain 133m 9s) Loss: 0.0036(0.0068) Grad: 145829.4688  LR: 0.000010  \n","Epoch: [1][21200/36908] Elapsed 178m 35s (remain 132m 18s) Loss: 0.0001(0.0068) Grad: 2505.8887  LR: 0.000009  \n","Epoch: [1][21300/36908] Elapsed 179m 26s (remain 131m 28s) Loss: 0.0000(0.0068) Grad: 73.9141  LR: 0.000009  \n","Epoch: [1][21400/36908] Elapsed 180m 16s (remain 130m 37s) Loss: 0.0000(0.0068) Grad: 197.1349  LR: 0.000009  \n","Epoch: [1][21500/36908] Elapsed 181m 6s (remain 129m 46s) Loss: 0.0003(0.0068) Grad: 16533.2539  LR: 0.000009  \n","Epoch: [1][21600/36908] Elapsed 181m 57s (remain 128m 56s) Loss: 0.0022(0.0067) Grad: 39793.3320  LR: 0.000009  \n","Epoch: [1][21700/36908] Elapsed 182m 48s (remain 128m 5s) Loss: 0.0046(0.0067) Grad: 69176.6094  LR: 0.000009  \n","Epoch: [1][21800/36908] Elapsed 183m 38s (remain 127m 15s) Loss: 0.0001(0.0067) Grad: 5126.2207  LR: 0.000009  \n","Epoch: [1][21900/36908] Elapsed 184m 28s (remain 126m 24s) Loss: 0.0000(0.0067) Grad: 49.8585  LR: 0.000009  \n","Epoch: [1][22000/36908] Elapsed 185m 18s (remain 125m 33s) Loss: 0.0039(0.0067) Grad: 79190.7891  LR: 0.000009  \n","Epoch: [1][22100/36908] Elapsed 186m 8s (remain 124m 42s) Loss: 0.0011(0.0066) Grad: 17770.3828  LR: 0.000009  \n","Epoch: [1][22200/36908] Elapsed 186m 58s (remain 123m 51s) Loss: 0.0000(0.0066) Grad: 72.0823  LR: 0.000009  \n","Epoch: [1][22300/36908] Elapsed 187m 49s (remain 123m 1s) Loss: 0.0007(0.0066) Grad: 23488.9219  LR: 0.000009  \n","Epoch: [1][22400/36908] Elapsed 188m 39s (remain 122m 10s) Loss: 0.0004(0.0066) Grad: 19881.1113  LR: 0.000009  \n","Epoch: [1][22500/36908] Elapsed 189m 30s (remain 121m 20s) Loss: 0.0000(0.0066) Grad: 405.2039  LR: 0.000009  \n","Epoch: [1][22600/36908] Elapsed 190m 21s (remain 120m 29s) Loss: 0.0006(0.0066) Grad: 33679.9180  LR: 0.000009  \n","Epoch: [1][22700/36908] Elapsed 191m 11s (remain 119m 39s) Loss: 0.0026(0.0066) Grad: 49960.6992  LR: 0.000009  \n","Epoch: [1][22800/36908] Elapsed 192m 1s (remain 118m 48s) Loss: 0.0020(0.0065) Grad: 21332.3750  LR: 0.000008  \n","Epoch: [1][22900/36908] Elapsed 192m 52s (remain 117m 58s) Loss: 0.0009(0.0065) Grad: 67019.7500  LR: 0.000008  \n","Epoch: [1][23000/36908] Elapsed 193m 43s (remain 117m 7s) Loss: 0.0253(0.0065) Grad: 181795.1250  LR: 0.000008  \n","Epoch: [1][23100/36908] Elapsed 194m 33s (remain 116m 16s) Loss: 0.0041(0.0065) Grad: 46657.8281  LR: 0.000008  \n","Epoch: [1][23200/36908] Elapsed 195m 23s (remain 115m 26s) Loss: 0.0002(0.0065) Grad: 12502.2676  LR: 0.000008  \n","Epoch: [1][23300/36908] Elapsed 196m 13s (remain 114m 35s) Loss: 0.0000(0.0065) Grad: 38.9584  LR: 0.000008  \n","Epoch: [1][23400/36908] Elapsed 197m 3s (remain 113m 44s) Loss: 0.0000(0.0064) Grad: 1452.9265  LR: 0.000008  \n","Epoch: [1][23500/36908] Elapsed 197m 53s (remain 112m 53s) Loss: 0.0000(0.0064) Grad: 86.8711  LR: 0.000008  \n","Epoch: [1][23600/36908] Elapsed 198m 44s (remain 112m 3s) Loss: 0.0000(0.0064) Grad: 145.1491  LR: 0.000008  \n","Epoch: [1][23700/36908] Elapsed 199m 34s (remain 111m 12s) Loss: 0.0000(0.0064) Grad: 58.8797  LR: 0.000008  \n","Epoch: [1][23800/36908] Elapsed 200m 24s (remain 110m 21s) Loss: 0.0000(0.0064) Grad: 38.6283  LR: 0.000008  \n","Epoch: [1][23900/36908] Elapsed 201m 14s (remain 109m 31s) Loss: 0.0000(0.0064) Grad: 76.2862  LR: 0.000008  \n","Epoch: [1][24000/36908] Elapsed 202m 5s (remain 108m 40s) Loss: 0.0025(0.0063) Grad: 80473.7891  LR: 0.000008  \n","Epoch: [1][24100/36908] Elapsed 202m 55s (remain 107m 49s) Loss: 0.0000(0.0063) Grad: 866.8852  LR: 0.000008  \n","Epoch: [1][24200/36908] Elapsed 203m 46s (remain 106m 59s) Loss: 0.0058(0.0063) Grad: 199317.7188  LR: 0.000008  \n","Epoch: [1][24300/36908] Elapsed 204m 37s (remain 106m 9s) Loss: 0.0013(0.0063) Grad: 158157.8125  LR: 0.000008  \n","Epoch: [1][24400/36908] Elapsed 205m 29s (remain 105m 19s) Loss: 0.0000(0.0063) Grad: 1096.1428  LR: 0.000008  \n","Epoch: [1][24500/36908] Elapsed 206m 19s (remain 104m 29s) Loss: 0.0121(0.0063) Grad: 562602.8750  LR: 0.000007  \n","Epoch: [1][24600/36908] Elapsed 207m 10s (remain 103m 38s) Loss: 0.0000(0.0063) Grad: 111.5491  LR: 0.000007  \n","Epoch: [1][24700/36908] Elapsed 208m 2s (remain 102m 48s) Loss: 0.0036(0.0062) Grad: 62249.5547  LR: 0.000007  \n","Epoch: [1][24800/36908] Elapsed 208m 52s (remain 101m 58s) Loss: 0.0000(0.0062) Grad: 337.1627  LR: 0.000007  \n","Epoch: [1][24900/36908] Elapsed 209m 43s (remain 101m 7s) Loss: 0.0000(0.0062) Grad: 274.3838  LR: 0.000007  \n","Epoch: [1][25000/36908] Elapsed 210m 34s (remain 100m 17s) Loss: 0.0013(0.0062) Grad: 118241.9531  LR: 0.000007  \n","Epoch: [1][25100/36908] Elapsed 211m 25s (remain 99m 26s) Loss: 0.0000(0.0062) Grad: 188.5493  LR: 0.000007  \n","Epoch: [1][25200/36908] Elapsed 212m 16s (remain 98m 36s) Loss: 0.0001(0.0062) Grad: 6754.1973  LR: 0.000007  \n","Epoch: [1][25300/36908] Elapsed 213m 7s (remain 97m 46s) Loss: 0.0000(0.0062) Grad: 25.2990  LR: 0.000007  \n","Epoch: [1][25400/36908] Elapsed 213m 58s (remain 96m 56s) Loss: 0.0000(0.0061) Grad: 28.6677  LR: 0.000007  \n","Epoch: [1][25500/36908] Elapsed 214m 49s (remain 96m 5s) Loss: 0.0020(0.0061) Grad: 90553.4453  LR: 0.000007  \n","Epoch: [1][25600/36908] Elapsed 215m 39s (remain 95m 15s) Loss: 0.0000(0.0061) Grad: 158.2955  LR: 0.000007  \n","Epoch: [1][25700/36908] Elapsed 216m 30s (remain 94m 24s) Loss: 0.0032(0.0061) Grad: 164523.4688  LR: 0.000007  \n","Epoch: [1][25800/36908] Elapsed 217m 21s (remain 93m 34s) Loss: 0.0000(0.0061) Grad: 60.0981  LR: 0.000007  \n","Epoch: [1][25900/36908] Elapsed 218m 12s (remain 92m 43s) Loss: 0.0000(0.0061) Grad: 2427.3892  LR: 0.000007  \n","Epoch: [1][26000/36908] Elapsed 219m 2s (remain 91m 53s) Loss: 0.0000(0.0061) Grad: 124.9229  LR: 0.000007  \n","Epoch: [1][26100/36908] Elapsed 219m 52s (remain 91m 2s) Loss: 0.0008(0.0060) Grad: 18522.9570  LR: 0.000007  \n","Epoch: [1][26200/36908] Elapsed 220m 43s (remain 90m 11s) Loss: 0.0002(0.0060) Grad: 18336.7090  LR: 0.000006  \n","Epoch: [1][26300/36908] Elapsed 221m 33s (remain 89m 21s) Loss: 0.0430(0.0060) Grad: 608798.8750  LR: 0.000006  \n","Epoch: [1][26400/36908] Elapsed 222m 23s (remain 88m 30s) Loss: 0.0000(0.0060) Grad: 36.6846  LR: 0.000006  \n","Epoch: [1][26500/36908] Elapsed 223m 14s (remain 87m 39s) Loss: 0.0001(0.0060) Grad: 13714.0947  LR: 0.000006  \n","Epoch: [1][26600/36908] Elapsed 224m 4s (remain 86m 49s) Loss: 0.0001(0.0060) Grad: 12986.2344  LR: 0.000006  \n","Epoch: [1][26700/36908] Elapsed 224m 54s (remain 85m 58s) Loss: 0.0000(0.0060) Grad: 170.7503  LR: 0.000006  \n","Epoch: [1][26800/36908] Elapsed 225m 44s (remain 85m 7s) Loss: 0.0000(0.0060) Grad: 161.4605  LR: 0.000006  \n","Epoch: [1][26900/36908] Elapsed 226m 34s (remain 84m 17s) Loss: 0.0002(0.0059) Grad: 18486.4082  LR: 0.000006  \n","Epoch: [1][27000/36908] Elapsed 227m 25s (remain 83m 26s) Loss: 0.0000(0.0059) Grad: 9.2022  LR: 0.000006  \n","Epoch: [1][27100/36908] Elapsed 228m 15s (remain 82m 35s) Loss: 0.0000(0.0059) Grad: 199.8933  LR: 0.000006  \n","Epoch: [1][27200/36908] Elapsed 229m 5s (remain 81m 45s) Loss: 0.0203(0.0059) Grad: 371533.2812  LR: 0.000006  \n","Epoch: [1][27300/36908] Elapsed 229m 55s (remain 80m 54s) Loss: 0.0000(0.0059) Grad: 55.4370  LR: 0.000006  \n","Epoch: [1][27400/36908] Elapsed 230m 46s (remain 80m 4s) Loss: 0.0015(0.0059) Grad: 67919.7734  LR: 0.000006  \n","Epoch: [1][27500/36908] Elapsed 231m 36s (remain 79m 13s) Loss: 0.0000(0.0059) Grad: 20.3702  LR: 0.000006  \n","Epoch: [1][27600/36908] Elapsed 232m 26s (remain 78m 22s) Loss: 0.0000(0.0059) Grad: 139.6688  LR: 0.000006  \n","Epoch: [1][27700/36908] Elapsed 233m 16s (remain 77m 32s) Loss: 0.0285(0.0059) Grad: 490174.0312  LR: 0.000006  \n","Epoch: [1][27800/36908] Elapsed 234m 6s (remain 76m 41s) Loss: 0.0000(0.0058) Grad: 1128.2419  LR: 0.000005  \n","Epoch: [1][27900/36908] Elapsed 234m 56s (remain 75m 50s) Loss: 0.0000(0.0058) Grad: 638.5364  LR: 0.000005  \n","Epoch: [1][28000/36908] Elapsed 235m 46s (remain 75m 0s) Loss: 0.0000(0.0058) Grad: 367.4368  LR: 0.000005  \n","Epoch: [1][28100/36908] Elapsed 236m 36s (remain 74m 9s) Loss: 0.0087(0.0058) Grad: 172270.9531  LR: 0.000005  \n","Epoch: [1][28200/36908] Elapsed 237m 27s (remain 73m 18s) Loss: 0.0000(0.0058) Grad: 136.5895  LR: 0.000005  \n","Epoch: [1][28300/36908] Elapsed 238m 17s (remain 72m 28s) Loss: 0.0000(0.0058) Grad: 33.8214  LR: 0.000005  \n","Epoch: [1][28400/36908] Elapsed 239m 7s (remain 71m 37s) Loss: 0.0000(0.0058) Grad: 192.6760  LR: 0.000005  \n","Epoch: [1][28500/36908] Elapsed 239m 57s (remain 70m 46s) Loss: 0.0035(0.0058) Grad: 58296.1016  LR: 0.000005  \n","Epoch: [1][28600/36908] Elapsed 240m 47s (remain 69m 56s) Loss: 0.0023(0.0057) Grad: 99065.4141  LR: 0.000005  \n","Epoch: [1][28700/36908] Elapsed 241m 38s (remain 69m 5s) Loss: 0.0017(0.0057) Grad: 36631.3867  LR: 0.000005  \n","Epoch: [1][28800/36908] Elapsed 242m 28s (remain 68m 15s) Loss: 0.0180(0.0057) Grad: 211429.9062  LR: 0.000005  \n","Epoch: [1][28900/36908] Elapsed 243m 19s (remain 67m 24s) Loss: 0.0005(0.0057) Grad: 24473.4570  LR: 0.000005  \n","Epoch: [1][29000/36908] Elapsed 244m 9s (remain 66m 34s) Loss: 0.0000(0.0057) Grad: 198.3280  LR: 0.000005  \n","Epoch: [1][29100/36908] Elapsed 245m 0s (remain 65m 43s) Loss: 0.0011(0.0057) Grad: 91386.3281  LR: 0.000005  \n","Epoch: [1][29200/36908] Elapsed 245m 50s (remain 64m 53s) Loss: 0.0026(0.0057) Grad: 123982.8438  LR: 0.000005  \n","Epoch: [1][29300/36908] Elapsed 246m 41s (remain 64m 2s) Loss: 0.0043(0.0057) Grad: 365424.9375  LR: 0.000005  \n","Epoch: [1][29400/36908] Elapsed 247m 31s (remain 63m 12s) Loss: 0.0054(0.0057) Grad: 300598.6875  LR: 0.000005  \n","Epoch: [1][29500/36908] Elapsed 248m 21s (remain 62m 21s) Loss: 0.0003(0.0057) Grad: 55352.8242  LR: 0.000004  \n","Epoch: [1][29600/36908] Elapsed 249m 12s (remain 61m 30s) Loss: 0.0002(0.0057) Grad: 29189.7578  LR: 0.000004  \n","Epoch: [1][29700/36908] Elapsed 250m 2s (remain 60m 40s) Loss: 0.0011(0.0057) Grad: 43828.5078  LR: 0.000004  \n","Epoch: [1][29800/36908] Elapsed 250m 52s (remain 59m 49s) Loss: 0.0000(0.0056) Grad: 5448.9204  LR: 0.000004  \n","Epoch: [1][29900/36908] Elapsed 251m 43s (remain 58m 59s) Loss: 0.0006(0.0056) Grad: 87459.5625  LR: 0.000004  \n","Epoch: [1][30000/36908] Elapsed 252m 34s (remain 58m 8s) Loss: 0.0014(0.0056) Grad: 45633.9141  LR: 0.000004  \n","Epoch: [1][30100/36908] Elapsed 253m 24s (remain 57m 18s) Loss: 0.0000(0.0056) Grad: 4041.3293  LR: 0.000004  \n","Epoch: [1][30200/36908] Elapsed 254m 15s (remain 56m 27s) Loss: 0.0005(0.0056) Grad: 44969.5859  LR: 0.000004  \n","Epoch: [1][30300/36908] Elapsed 255m 5s (remain 55m 37s) Loss: 0.0000(0.0056) Grad: 119.0417  LR: 0.000004  \n","Epoch: [1][30400/36908] Elapsed 255m 56s (remain 54m 46s) Loss: 0.0000(0.0056) Grad: 510.7260  LR: 0.000004  \n","Epoch: [1][30500/36908] Elapsed 256m 46s (remain 53m 56s) Loss: 0.0000(0.0056) Grad: 109.2714  LR: 0.000004  \n","Epoch: [1][30600/36908] Elapsed 257m 37s (remain 53m 5s) Loss: 0.0000(0.0056) Grad: 191.1854  LR: 0.000004  \n","Epoch: [1][30700/36908] Elapsed 258m 27s (remain 52m 15s) Loss: 0.0000(0.0056) Grad: 1557.9072  LR: 0.000004  \n","Epoch: [1][30800/36908] Elapsed 259m 19s (remain 51m 24s) Loss: 0.0000(0.0055) Grad: 2337.3364  LR: 0.000004  \n","Epoch: [1][30900/36908] Elapsed 260m 10s (remain 50m 34s) Loss: 0.0000(0.0055) Grad: 1342.8413  LR: 0.000004  \n","Epoch: [1][31000/36908] Elapsed 261m 1s (remain 49m 44s) Loss: 0.0042(0.0055) Grad: 316674.5312  LR: 0.000004  \n","Epoch: [1][31100/36908] Elapsed 261m 52s (remain 48m 53s) Loss: 0.0031(0.0055) Grad: 140076.3906  LR: 0.000003  \n","Epoch: [1][31200/36908] Elapsed 262m 43s (remain 48m 3s) Loss: 0.0002(0.0055) Grad: 44447.6875  LR: 0.000003  \n","Epoch: [1][31300/36908] Elapsed 263m 34s (remain 47m 12s) Loss: 0.0104(0.0055) Grad: 345408.4062  LR: 0.000003  \n","Epoch: [1][31400/36908] Elapsed 264m 25s (remain 46m 22s) Loss: 0.0000(0.0055) Grad: 177.8839  LR: 0.000003  \n","Epoch: [1][31500/36908] Elapsed 265m 16s (remain 45m 32s) Loss: 0.0000(0.0055) Grad: 8.7244  LR: 0.000003  \n","Epoch: [1][31600/36908] Elapsed 266m 7s (remain 44m 41s) Loss: 0.0022(0.0055) Grad: 216145.9062  LR: 0.000003  \n","Epoch: [1][31700/36908] Elapsed 266m 59s (remain 43m 51s) Loss: 0.0002(0.0055) Grad: 27879.7559  LR: 0.000003  \n","Epoch: [1][31800/36908] Elapsed 267m 49s (remain 43m 0s) Loss: 0.0016(0.0055) Grad: 36785.2773  LR: 0.000003  \n","Epoch: [1][31900/36908] Elapsed 268m 40s (remain 42m 10s) Loss: 0.0002(0.0054) Grad: 31715.7285  LR: 0.000003  \n","Epoch: [1][32000/36908] Elapsed 269m 31s (remain 41m 19s) Loss: 0.0131(0.0054) Grad: 93763.4219  LR: 0.000003  \n","Epoch: [1][32100/36908] Elapsed 270m 22s (remain 40m 29s) Loss: 0.0000(0.0054) Grad: 20.3057  LR: 0.000003  \n","Epoch: [1][32200/36908] Elapsed 271m 12s (remain 39m 38s) Loss: 0.0000(0.0054) Grad: 20.8162  LR: 0.000003  \n","Epoch: [1][32300/36908] Elapsed 272m 4s (remain 38m 48s) Loss: 0.0005(0.0054) Grad: 30707.8301  LR: 0.000003  \n","Epoch: [1][32400/36908] Elapsed 272m 55s (remain 37m 57s) Loss: 0.0000(0.0054) Grad: 748.6970  LR: 0.000003  \n","Epoch: [1][32500/36908] Elapsed 273m 47s (remain 37m 7s) Loss: 0.0001(0.0054) Grad: 7244.0029  LR: 0.000003  \n","Epoch: [1][32600/36908] Elapsed 274m 40s (remain 36m 17s) Loss: 0.0006(0.0054) Grad: 31103.7207  LR: 0.000003  \n","Epoch: [1][32700/36908] Elapsed 275m 31s (remain 35m 26s) Loss: 0.0000(0.0054) Grad: 17.5090  LR: 0.000003  \n","Epoch: [1][32800/36908] Elapsed 276m 23s (remain 34m 36s) Loss: 0.0013(0.0054) Grad: 39951.1172  LR: 0.000002  \n","Epoch: [1][32900/36908] Elapsed 277m 14s (remain 33m 45s) Loss: 0.0064(0.0054) Grad: 140286.7031  LR: 0.000002  \n","Epoch: [1][33000/36908] Elapsed 278m 5s (remain 32m 55s) Loss: 0.0014(0.0054) Grad: 56102.6953  LR: 0.000002  \n","Epoch: [1][33100/36908] Elapsed 278m 57s (remain 32m 5s) Loss: 0.0000(0.0053) Grad: 2104.0723  LR: 0.000002  \n","Epoch: [1][33200/36908] Elapsed 279m 49s (remain 31m 14s) Loss: 0.0000(0.0053) Grad: 48.5687  LR: 0.000002  \n","Epoch: [1][33300/36908] Elapsed 280m 41s (remain 30m 24s) Loss: 0.0000(0.0053) Grad: 737.8674  LR: 0.000002  \n","Epoch: [1][33400/36908] Elapsed 281m 33s (remain 29m 33s) Loss: 0.0047(0.0053) Grad: 118963.0781  LR: 0.000002  \n","Epoch: [1][33500/36908] Elapsed 282m 24s (remain 28m 43s) Loss: 0.0005(0.0053) Grad: 22676.9941  LR: 0.000002  \n","Epoch: [1][33600/36908] Elapsed 283m 16s (remain 27m 52s) Loss: 0.0000(0.0053) Grad: 77.9023  LR: 0.000002  \n","Epoch: [1][33700/36908] Elapsed 284m 8s (remain 27m 2s) Loss: 0.0005(0.0053) Grad: 31033.5586  LR: 0.000002  \n","Epoch: [1][33800/36908] Elapsed 284m 59s (remain 26m 11s) Loss: 0.0000(0.0053) Grad: 99.3861  LR: 0.000002  \n","Epoch: [1][33900/36908] Elapsed 285m 50s (remain 25m 21s) Loss: 0.0033(0.0053) Grad: 96351.5234  LR: 0.000002  \n","Epoch: [1][34000/36908] Elapsed 286m 42s (remain 24m 30s) Loss: 0.0000(0.0053) Grad: 861.3624  LR: 0.000002  \n","Epoch: [1][34100/36908] Elapsed 287m 34s (remain 23m 40s) Loss: 0.0012(0.0053) Grad: 25122.2520  LR: 0.000002  \n","Epoch: [1][34200/36908] Elapsed 288m 25s (remain 22m 49s) Loss: 0.0002(0.0053) Grad: 13061.5557  LR: 0.000002  \n","Epoch: [1][34300/36908] Elapsed 289m 17s (remain 21m 59s) Loss: 0.0000(0.0052) Grad: 122.4694  LR: 0.000002  \n","Epoch: [1][34400/36908] Elapsed 290m 9s (remain 21m 8s) Loss: 0.0056(0.0052) Grad: 110297.7031  LR: 0.000002  \n","Epoch: [1][34500/36908] Elapsed 291m 0s (remain 20m 18s) Loss: 0.0002(0.0052) Grad: 14377.3252  LR: 0.000001  \n","Epoch: [1][34600/36908] Elapsed 291m 52s (remain 19m 27s) Loss: 0.0092(0.0052) Grad: 201579.0781  LR: 0.000001  \n","Epoch: [1][34700/36908] Elapsed 292m 44s (remain 18m 37s) Loss: 0.0000(0.0052) Grad: 97.0701  LR: 0.000001  \n","Epoch: [1][34800/36908] Elapsed 293m 35s (remain 17m 46s) Loss: 0.0000(0.0052) Grad: 4.2943  LR: 0.000001  \n","Epoch: [1][34900/36908] Elapsed 294m 27s (remain 16m 55s) Loss: 0.0000(0.0052) Grad: 219.7722  LR: 0.000001  \n","Epoch: [1][35000/36908] Elapsed 295m 19s (remain 16m 5s) Loss: 0.0013(0.0052) Grad: 61734.8945  LR: 0.000001  \n","Epoch: [1][35100/36908] Elapsed 296m 11s (remain 15m 14s) Loss: 0.0000(0.0052) Grad: 123.3869  LR: 0.000001  \n","Epoch: [1][35200/36908] Elapsed 297m 2s (remain 14m 24s) Loss: 0.0077(0.0052) Grad: 108517.1250  LR: 0.000001  \n","Epoch: [1][35300/36908] Elapsed 297m 54s (remain 13m 33s) Loss: 0.0072(0.0052) Grad: 107278.8281  LR: 0.000001  \n","Epoch: [1][35400/36908] Elapsed 298m 46s (remain 12m 43s) Loss: 0.0001(0.0052) Grad: 6651.8511  LR: 0.000001  \n","Epoch: [1][35500/36908] Elapsed 299m 37s (remain 11m 52s) Loss: 0.0000(0.0052) Grad: 79.1793  LR: 0.000001  \n","Epoch: [1][35600/36908] Elapsed 300m 29s (remain 11m 1s) Loss: 0.0033(0.0052) Grad: 42264.0859  LR: 0.000001  \n","Epoch: [1][35700/36908] Elapsed 301m 20s (remain 10m 11s) Loss: 0.0222(0.0052) Grad: 342516.5312  LR: 0.000001  \n","Epoch: [1][35800/36908] Elapsed 302m 12s (remain 9m 20s) Loss: 0.0000(0.0051) Grad: 623.1166  LR: 0.000001  \n","Epoch: [1][35900/36908] Elapsed 303m 4s (remain 8m 30s) Loss: 0.0000(0.0051) Grad: 1079.6124  LR: 0.000001  \n","Epoch: [1][36000/36908] Elapsed 303m 56s (remain 7m 39s) Loss: 0.0000(0.0051) Grad: 358.8752  LR: 0.000001  \n","Epoch: [1][36100/36908] Elapsed 304m 48s (remain 6m 48s) Loss: 0.0015(0.0051) Grad: 65379.2031  LR: 0.000000  \n","Epoch: [1][36200/36908] Elapsed 305m 39s (remain 5m 58s) Loss: 0.0000(0.0051) Grad: 169.1891  LR: 0.000000  \n","Epoch: [1][36300/36908] Elapsed 306m 31s (remain 5m 7s) Loss: 0.0005(0.0051) Grad: 61719.7227  LR: 0.000000  \n","Epoch: [1][36400/36908] Elapsed 307m 23s (remain 4m 16s) Loss: 0.0000(0.0051) Grad: 142.3323  LR: 0.000000  \n","Epoch: [1][36500/36908] Elapsed 308m 15s (remain 3m 26s) Loss: 0.0021(0.0051) Grad: 76981.8438  LR: 0.000000  \n","Epoch: [1][36600/36908] Elapsed 309m 6s (remain 2m 35s) Loss: 0.0000(0.0051) Grad: 36.7309  LR: 0.000000  \n","Epoch: [1][36700/36908] Elapsed 309m 58s (remain 1m 44s) Loss: 0.0000(0.0051) Grad: 155.2567  LR: 0.000000  \n","Epoch: [1][36800/36908] Elapsed 310m 50s (remain 0m 54s) Loss: 0.0000(0.0051) Grad: 5195.8081  LR: 0.000000  \n","Epoch: [1][36900/36908] Elapsed 311m 42s (remain 0m 3s) Loss: 0.0155(0.0051) Grad: 271897.5938  LR: 0.000000  \n","Epoch: [1][36907/36908] Elapsed 311m 46s (remain 0m 0s) Loss: 0.0000(0.0051) Grad: 1141.2793  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 13m 8s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 23s (remain 4m 15s) Loss: 0.0010(0.0112) \n","EVAL: [200/1192] Elapsed 0m 46s (remain 3m 49s) Loss: 0.0000(0.0119) \n","EVAL: [300/1192] Elapsed 1m 9s (remain 3m 26s) Loss: 0.0019(0.0182) \n","EVAL: [400/1192] Elapsed 1m 32s (remain 3m 2s) Loss: 0.0558(0.0189) \n","EVAL: [500/1192] Elapsed 1m 55s (remain 2m 39s) Loss: 0.0466(0.0171) \n","EVAL: [600/1192] Elapsed 2m 18s (remain 2m 16s) Loss: 0.2269(0.0171) \n","EVAL: [700/1192] Elapsed 2m 40s (remain 1m 52s) Loss: 0.0114(0.0195) \n","EVAL: [800/1192] Elapsed 3m 3s (remain 1m 29s) Loss: 0.0063(0.0190) \n","EVAL: [900/1192] Elapsed 3m 25s (remain 1m 6s) Loss: 0.0008(0.0185) \n","EVAL: [1000/1192] Elapsed 3m 47s (remain 0m 43s) Loss: 0.0000(0.0177) \n","EVAL: [1100/1192] Elapsed 4m 9s (remain 0m 20s) Loss: 0.0111(0.0170) \n","EVAL: [1191/1192] Elapsed 4m 29s (remain 0m 0s) Loss: 0.0176(0.0160) \n","Epoch 1 - avg_train_loss: 0.0051  avg_val_loss: 0.0160  time: 18978s\n","Epoch 1 - Score: 0.8860\n","Epoch 1 - Save Best Score: 0.8860 Model\n","========== fold: 2 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_2.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_2.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp083/pseudo_labels_2.npy\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2dd1f825d69486c8a77560365754ae5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e6ca0edd2e646889ddb4f46a94e6cd2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(612602, 950)\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","(110725, 11)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp090/fold2_best.pth\n","Epoch: [1][0/36908] Elapsed 0m 1s (remain 852m 37s) Loss: 0.3436(0.3436) Grad: 188703.6250  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 52s (remain 317m 25s) Loss: 0.3136(0.3331) Grad: 158894.0625  LR: 0.000001  \n","Epoch: [1][200/36908] Elapsed 1m 42s (remain 312m 33s) Loss: 0.2235(0.3003) Grad: 125904.8438  LR: 0.000001  \n","Epoch: [1][300/36908] Elapsed 2m 33s (remain 310m 18s) Loss: 0.1105(0.2551) Grad: 73811.2109  LR: 0.000002  \n","Epoch: [1][400/36908] Elapsed 3m 23s (remain 309m 9s) Loss: 0.0373(0.2109) Grad: 29807.4121  LR: 0.000002  \n","Epoch: [1][500/36908] Elapsed 4m 14s (remain 307m 50s) Loss: 0.0212(0.1756) Grad: 9159.0576  LR: 0.000003  \n","Epoch: [1][600/36908] Elapsed 5m 4s (remain 306m 36s) Loss: 0.0072(0.1491) Grad: 3872.1533  LR: 0.000003  \n","Epoch: [1][700/36908] Elapsed 5m 54s (remain 305m 17s) Loss: 0.0027(0.1289) Grad: 1509.9749  LR: 0.000004  \n","Epoch: [1][800/36908] Elapsed 6m 45s (remain 304m 18s) Loss: 0.0054(0.1134) Grad: 3134.6074  LR: 0.000004  \n","Epoch: [1][900/36908] Elapsed 7m 35s (remain 303m 19s) Loss: 0.0095(0.1012) Grad: 2584.5745  LR: 0.000005  \n","Epoch: [1][1000/36908] Elapsed 8m 26s (remain 302m 57s) Loss: 0.0065(0.0914) Grad: 1247.6658  LR: 0.000005  \n","Epoch: [1][1100/36908] Elapsed 9m 18s (remain 302m 59s) Loss: 0.0013(0.0834) Grad: 476.6292  LR: 0.000006  \n","Epoch: [1][1200/36908] Elapsed 10m 10s (remain 302m 23s) Loss: 0.0010(0.0768) Grad: 502.2176  LR: 0.000007  \n","Epoch: [1][1300/36908] Elapsed 11m 1s (remain 301m 49s) Loss: 0.0011(0.0711) Grad: 407.2201  LR: 0.000007  \n","Epoch: [1][1400/36908] Elapsed 11m 52s (remain 301m 5s) Loss: 0.0027(0.0663) Grad: 531.6575  LR: 0.000008  \n","Epoch: [1][1500/36908] Elapsed 12m 43s (remain 300m 17s) Loss: 0.0012(0.0621) Grad: 736.8608  LR: 0.000008  \n","Epoch: [1][1600/36908] Elapsed 13m 34s (remain 299m 32s) Loss: 0.0033(0.0584) Grad: 1458.4735  LR: 0.000009  \n","Epoch: [1][1700/36908] Elapsed 14m 26s (remain 298m 52s) Loss: 0.0010(0.0551) Grad: 268.9690  LR: 0.000009  \n","Epoch: [1][1800/36908] Elapsed 15m 17s (remain 298m 11s) Loss: 0.0004(0.0522) Grad: 257.2558  LR: 0.000010  \n","Epoch: [1][1900/36908] Elapsed 16m 9s (remain 297m 28s) Loss: 0.0111(0.0497) Grad: 8065.2119  LR: 0.000010  \n","Epoch: [1][2000/36908] Elapsed 17m 0s (remain 296m 39s) Loss: 0.0001(0.0473) Grad: 80.0144  LR: 0.000011  \n","Epoch: [1][2100/36908] Elapsed 17m 51s (remain 295m 49s) Loss: 0.0001(0.0451) Grad: 101.6011  LR: 0.000011  \n","Epoch: [1][2200/36908] Elapsed 18m 42s (remain 295m 5s) Loss: 0.0018(0.0431) Grad: 548.1164  LR: 0.000012  \n","Epoch: [1][2300/36908] Elapsed 19m 33s (remain 294m 15s) Loss: 0.0033(0.0414) Grad: 1752.2960  LR: 0.000012  \n","Epoch: [1][2400/36908] Elapsed 20m 24s (remain 293m 18s) Loss: 0.0375(0.0398) Grad: 14863.9844  LR: 0.000013  \n","Epoch: [1][2500/36908] Elapsed 21m 15s (remain 292m 24s) Loss: 0.0002(0.0383) Grad: 134.4061  LR: 0.000014  \n","Epoch: [1][2600/36908] Elapsed 22m 6s (remain 291m 36s) Loss: 0.0006(0.0369) Grad: 466.9718  LR: 0.000014  \n","Epoch: [1][2700/36908] Elapsed 22m 58s (remain 291m 0s) Loss: 0.0000(0.0357) Grad: 46.0247  LR: 0.000015  \n","Epoch: [1][2800/36908] Elapsed 23m 49s (remain 290m 9s) Loss: 0.0522(0.0345) Grad: 13633.0361  LR: 0.000015  \n","Epoch: [1][2900/36908] Elapsed 24m 40s (remain 289m 20s) Loss: 0.0006(0.0334) Grad: 516.1029  LR: 0.000016  \n","Epoch: [1][3000/36908] Elapsed 25m 31s (remain 288m 27s) Loss: 0.0074(0.0323) Grad: 4898.7627  LR: 0.000016  \n","Epoch: [1][3100/36908] Elapsed 26m 22s (remain 287m 35s) Loss: 0.0003(0.0314) Grad: 193.5031  LR: 0.000017  \n","Epoch: [1][3200/36908] Elapsed 27m 14s (remain 286m 50s) Loss: 0.0003(0.0304) Grad: 346.2510  LR: 0.000017  \n","Epoch: [1][3300/36908] Elapsed 28m 6s (remain 286m 6s) Loss: 0.0140(0.0296) Grad: 5103.4985  LR: 0.000018  \n","Epoch: [1][3400/36908] Elapsed 28m 57s (remain 285m 14s) Loss: 0.0014(0.0288) Grad: 1222.1302  LR: 0.000018  \n","Epoch: [1][3500/36908] Elapsed 29m 48s (remain 284m 24s) Loss: 0.0073(0.0281) Grad: 3258.8430  LR: 0.000019  \n","Epoch: [1][3600/36908] Elapsed 30m 39s (remain 283m 38s) Loss: 0.0001(0.0274) Grad: 213.0793  LR: 0.000020  \n","Epoch: [1][3700/36908] Elapsed 31m 31s (remain 282m 50s) Loss: 0.0001(0.0267) Grad: 105.2313  LR: 0.000020  \n","Epoch: [1][3800/36908] Elapsed 32m 22s (remain 282m 2s) Loss: 0.0003(0.0260) Grad: 312.9165  LR: 0.000020  \n","Epoch: [1][3900/36908] Elapsed 33m 14s (remain 281m 18s) Loss: 0.0018(0.0254) Grad: 1285.0361  LR: 0.000020  \n","Epoch: [1][4000/36908] Elapsed 34m 5s (remain 280m 25s) Loss: 0.0001(0.0248) Grad: 201.0935  LR: 0.000020  \n","Epoch: [1][4100/36908] Elapsed 34m 56s (remain 279m 32s) Loss: 0.0000(0.0243) Grad: 8.7869  LR: 0.000020  \n","Epoch: [1][4200/36908] Elapsed 35m 47s (remain 278m 39s) Loss: 0.0001(0.0238) Grad: 285.5923  LR: 0.000020  \n","Epoch: [1][4300/36908] Elapsed 36m 38s (remain 277m 46s) Loss: 0.0004(0.0233) Grad: 1691.8981  LR: 0.000020  \n","Epoch: [1][4400/36908] Elapsed 37m 29s (remain 276m 52s) Loss: 0.0058(0.0228) Grad: 9958.5742  LR: 0.000020  \n","Epoch: [1][4500/36908] Elapsed 38m 20s (remain 276m 0s) Loss: 0.0000(0.0223) Grad: 51.6947  LR: 0.000020  \n","Epoch: [1][4600/36908] Elapsed 39m 10s (remain 275m 8s) Loss: 0.0074(0.0219) Grad: 5184.4097  LR: 0.000019  \n","Epoch: [1][4700/36908] Elapsed 40m 1s (remain 274m 15s) Loss: 0.0000(0.0215) Grad: 143.5891  LR: 0.000019  \n","Epoch: [1][4800/36908] Elapsed 40m 52s (remain 273m 23s) Loss: 0.0044(0.0211) Grad: 4154.1865  LR: 0.000019  \n","Epoch: [1][4900/36908] Elapsed 41m 43s (remain 272m 32s) Loss: 0.0000(0.0207) Grad: 34.3517  LR: 0.000019  \n","Epoch: [1][5000/36908] Elapsed 42m 34s (remain 271m 38s) Loss: 0.0045(0.0203) Grad: 10097.2266  LR: 0.000019  \n","Epoch: [1][5100/36908] Elapsed 43m 25s (remain 270m 44s) Loss: 0.0003(0.0200) Grad: 770.2598  LR: 0.000019  \n","Epoch: [1][5200/36908] Elapsed 44m 15s (remain 269m 48s) Loss: 0.0005(0.0197) Grad: 1684.1245  LR: 0.000019  \n","Epoch: [1][5300/36908] Elapsed 45m 5s (remain 268m 53s) Loss: 0.0040(0.0193) Grad: 9703.4141  LR: 0.000019  \n","Epoch: [1][5400/36908] Elapsed 45m 56s (remain 267m 59s) Loss: 0.0000(0.0190) Grad: 110.4841  LR: 0.000019  \n","Epoch: [1][5500/36908] Elapsed 46m 47s (remain 267m 6s) Loss: 0.0001(0.0187) Grad: 104.3403  LR: 0.000019  \n","Epoch: [1][5600/36908] Elapsed 47m 38s (remain 266m 16s) Loss: 0.0008(0.0184) Grad: 1628.3101  LR: 0.000019  \n","Epoch: [1][5700/36908] Elapsed 48m 28s (remain 265m 22s) Loss: 0.0013(0.0182) Grad: 2423.7114  LR: 0.000019  \n","Epoch: [1][5800/36908] Elapsed 49m 19s (remain 264m 30s) Loss: 0.0111(0.0179) Grad: 8373.3496  LR: 0.000019  \n","Epoch: [1][5900/36908] Elapsed 50m 10s (remain 263m 38s) Loss: 0.0004(0.0176) Grad: 866.5928  LR: 0.000019  \n","Epoch: [1][6000/36908] Elapsed 51m 1s (remain 262m 47s) Loss: 0.0001(0.0173) Grad: 332.1755  LR: 0.000019  \n","Epoch: [1][6100/36908] Elapsed 51m 51s (remain 261m 53s) Loss: 0.0002(0.0171) Grad: 546.2538  LR: 0.000019  \n","Epoch: [1][6200/36908] Elapsed 52m 43s (remain 261m 3s) Loss: 0.0007(0.0169) Grad: 1267.9418  LR: 0.000018  \n","Epoch: [1][6300/36908] Elapsed 53m 33s (remain 260m 11s) Loss: 0.0001(0.0166) Grad: 245.8892  LR: 0.000018  \n","Epoch: [1][6400/36908] Elapsed 54m 25s (remain 259m 24s) Loss: 0.0001(0.0164) Grad: 352.0549  LR: 0.000018  \n","Epoch: [1][6500/36908] Elapsed 55m 16s (remain 258m 30s) Loss: 0.0089(0.0162) Grad: 9063.6016  LR: 0.000018  \n","Epoch: [1][6600/36908] Elapsed 56m 6s (remain 257m 36s) Loss: 0.0004(0.0160) Grad: 751.7835  LR: 0.000018  \n","Epoch: [1][6700/36908] Elapsed 56m 56s (remain 256m 41s) Loss: 0.0002(0.0158) Grad: 641.0070  LR: 0.000018  \n","Epoch: [1][6800/36908] Elapsed 57m 46s (remain 255m 47s) Loss: 0.0003(0.0156) Grad: 897.6371  LR: 0.000018  \n","Epoch: [1][6900/36908] Elapsed 58m 37s (remain 254m 53s) Loss: 0.0025(0.0154) Grad: 8231.0469  LR: 0.000018  \n","Epoch: [1][7000/36908] Elapsed 59m 27s (remain 253m 59s) Loss: 0.0000(0.0152) Grad: 48.4713  LR: 0.000018  \n","Epoch: [1][7100/36908] Elapsed 60m 17s (remain 253m 6s) Loss: 0.0041(0.0150) Grad: 9931.6152  LR: 0.000018  \n","Epoch: [1][7200/36908] Elapsed 61m 7s (remain 252m 11s) Loss: 0.0000(0.0148) Grad: 77.5188  LR: 0.000018  \n","Epoch: [1][7300/36908] Elapsed 61m 57s (remain 251m 16s) Loss: 0.0018(0.0146) Grad: 2286.8262  LR: 0.000018  \n","Epoch: [1][7400/36908] Elapsed 62m 48s (remain 250m 22s) Loss: 0.0001(0.0145) Grad: 227.9982  LR: 0.000018  \n","Epoch: [1][7500/36908] Elapsed 63m 38s (remain 249m 30s) Loss: 0.0010(0.0143) Grad: 1444.7941  LR: 0.000018  \n","Epoch: [1][7600/36908] Elapsed 64m 28s (remain 248m 36s) Loss: 0.0004(0.0141) Grad: 878.7981  LR: 0.000018  \n","Epoch: [1][7700/36908] Elapsed 65m 19s (remain 247m 44s) Loss: 0.0023(0.0140) Grad: 2218.2837  LR: 0.000018  \n","Epoch: [1][7800/36908] Elapsed 66m 9s (remain 246m 51s) Loss: 0.0062(0.0139) Grad: 5231.3936  LR: 0.000018  \n","Epoch: [1][7900/36908] Elapsed 67m 0s (remain 246m 0s) Loss: 0.0000(0.0137) Grad: 19.8147  LR: 0.000017  \n","Epoch: [1][8000/36908] Elapsed 67m 51s (remain 245m 9s) Loss: 0.0000(0.0136) Grad: 49.8312  LR: 0.000017  \n","Epoch: [1][8100/36908] Elapsed 68m 42s (remain 244m 18s) Loss: 0.0002(0.0134) Grad: 1045.5316  LR: 0.000017  \n","Epoch: [1][8200/36908] Elapsed 69m 33s (remain 243m 28s) Loss: 0.0000(0.0133) Grad: 66.6655  LR: 0.000017  \n","Epoch: [1][8300/36908] Elapsed 70m 24s (remain 242m 37s) Loss: 0.0007(0.0132) Grad: 3137.1292  LR: 0.000017  \n","Epoch: [1][8400/36908] Elapsed 71m 15s (remain 241m 47s) Loss: 0.0001(0.0130) Grad: 534.1553  LR: 0.000017  \n","Epoch: [1][8500/36908] Elapsed 72m 6s (remain 240m 57s) Loss: 0.0000(0.0129) Grad: 6.1455  LR: 0.000017  \n","Epoch: [1][8600/36908] Elapsed 72m 57s (remain 240m 6s) Loss: 0.0002(0.0128) Grad: 1127.9955  LR: 0.000017  \n","Epoch: [1][8700/36908] Elapsed 73m 48s (remain 239m 15s) Loss: 0.0121(0.0126) Grad: 29604.5078  LR: 0.000017  \n","Epoch: [1][8800/36908] Elapsed 74m 38s (remain 238m 23s) Loss: 0.0000(0.0125) Grad: 204.8913  LR: 0.000017  \n","Epoch: [1][8900/36908] Elapsed 75m 29s (remain 237m 30s) Loss: 0.0000(0.0124) Grad: 50.3985  LR: 0.000017  \n","Epoch: [1][9000/36908] Elapsed 76m 19s (remain 236m 38s) Loss: 0.0042(0.0123) Grad: 10822.8291  LR: 0.000017  \n","Epoch: [1][9100/36908] Elapsed 77m 9s (remain 235m 45s) Loss: 0.0000(0.0122) Grad: 314.7261  LR: 0.000017  \n","Epoch: [1][9200/36908] Elapsed 77m 59s (remain 234m 52s) Loss: 0.0000(0.0121) Grad: 75.2037  LR: 0.000017  \n","Epoch: [1][9300/36908] Elapsed 78m 50s (remain 234m 0s) Loss: 0.0102(0.0120) Grad: 41353.0938  LR: 0.000017  \n","Epoch: [1][9400/36908] Elapsed 79m 41s (remain 233m 9s) Loss: 0.0000(0.0119) Grad: 75.0936  LR: 0.000017  \n","Epoch: [1][9500/36908] Elapsed 80m 32s (remain 232m 18s) Loss: 0.0000(0.0118) Grad: 42.5438  LR: 0.000017  \n","Epoch: [1][9600/36908] Elapsed 81m 23s (remain 231m 28s) Loss: 0.0000(0.0117) Grad: 25.8052  LR: 0.000016  \n","Epoch: [1][9700/36908] Elapsed 82m 14s (remain 230m 38s) Loss: 0.0001(0.0116) Grad: 258.8532  LR: 0.000016  \n","Epoch: [1][9800/36908] Elapsed 83m 5s (remain 229m 47s) Loss: 0.0000(0.0115) Grad: 94.0225  LR: 0.000016  \n","Epoch: [1][9900/36908] Elapsed 83m 56s (remain 228m 57s) Loss: 0.0006(0.0114) Grad: 4753.3706  LR: 0.000016  \n","Epoch: [1][10000/36908] Elapsed 84m 46s (remain 228m 4s) Loss: 0.0000(0.0113) Grad: 8.6189  LR: 0.000016  \n","Epoch: [1][10100/36908] Elapsed 85m 36s (remain 227m 12s) Loss: 0.0001(0.0112) Grad: 600.6893  LR: 0.000016  \n","Epoch: [1][10200/36908] Elapsed 86m 27s (remain 226m 20s) Loss: 0.0000(0.0111) Grad: 68.3852  LR: 0.000016  \n","Epoch: [1][10300/36908] Elapsed 87m 19s (remain 225m 32s) Loss: 0.0180(0.0111) Grad: 26841.2539  LR: 0.000016  \n","Epoch: [1][10400/36908] Elapsed 88m 10s (remain 224m 42s) Loss: 0.0001(0.0110) Grad: 538.4146  LR: 0.000016  \n","Epoch: [1][10500/36908] Elapsed 89m 0s (remain 223m 50s) Loss: 0.0042(0.0109) Grad: 12408.3652  LR: 0.000016  \n","Epoch: [1][10600/36908] Elapsed 89m 50s (remain 222m 57s) Loss: 0.0078(0.0108) Grad: 26557.2852  LR: 0.000016  \n","Epoch: [1][10700/36908] Elapsed 90m 41s (remain 222m 6s) Loss: 0.0001(0.0107) Grad: 959.8948  LR: 0.000016  \n","Epoch: [1][10800/36908] Elapsed 91m 32s (remain 221m 15s) Loss: 0.0000(0.0107) Grad: 154.8552  LR: 0.000016  \n","Epoch: [1][10900/36908] Elapsed 92m 22s (remain 220m 23s) Loss: 0.0194(0.0106) Grad: 80146.8516  LR: 0.000016  \n","Epoch: [1][11000/36908] Elapsed 93m 13s (remain 219m 31s) Loss: 0.0000(0.0105) Grad: 133.3059  LR: 0.000016  \n","Epoch: [1][11100/36908] Elapsed 94m 3s (remain 218m 40s) Loss: 0.0000(0.0104) Grad: 108.0454  LR: 0.000016  \n","Epoch: [1][11200/36908] Elapsed 94m 53s (remain 217m 47s) Loss: 0.0009(0.0103) Grad: 2377.2478  LR: 0.000015  \n","Epoch: [1][11300/36908] Elapsed 95m 44s (remain 216m 56s) Loss: 0.0000(0.0103) Grad: 24.3536  LR: 0.000015  \n","Epoch: [1][11400/36908] Elapsed 96m 34s (remain 216m 4s) Loss: 0.0083(0.0102) Grad: 31661.6035  LR: 0.000015  \n","Epoch: [1][11500/36908] Elapsed 97m 26s (remain 215m 14s) Loss: 0.0000(0.0101) Grad: 149.0365  LR: 0.000015  \n","Epoch: [1][11600/36908] Elapsed 98m 16s (remain 214m 23s) Loss: 0.0204(0.0101) Grad: 30602.9883  LR: 0.000015  \n","Epoch: [1][11700/36908] Elapsed 99m 7s (remain 213m 33s) Loss: 0.0000(0.0100) Grad: 67.9094  LR: 0.000015  \n","Epoch: [1][11800/36908] Elapsed 99m 58s (remain 212m 42s) Loss: 0.0000(0.0099) Grad: 16.8185  LR: 0.000015  \n","Epoch: [1][11900/36908] Elapsed 100m 48s (remain 211m 50s) Loss: 0.0009(0.0099) Grad: 6780.4424  LR: 0.000015  \n","Epoch: [1][12000/36908] Elapsed 101m 39s (remain 210m 58s) Loss: 0.0000(0.0098) Grad: 14.9976  LR: 0.000015  \n","Epoch: [1][12100/36908] Elapsed 102m 29s (remain 210m 6s) Loss: 0.0000(0.0098) Grad: 179.3421  LR: 0.000015  \n","Epoch: [1][12200/36908] Elapsed 103m 20s (remain 209m 15s) Loss: 0.0003(0.0097) Grad: 3693.3770  LR: 0.000015  \n","Epoch: [1][12300/36908] Elapsed 104m 10s (remain 208m 23s) Loss: 0.0001(0.0096) Grad: 1249.6055  LR: 0.000015  \n","Epoch: [1][12400/36908] Elapsed 105m 1s (remain 207m 32s) Loss: 0.0001(0.0096) Grad: 1881.5928  LR: 0.000015  \n","Epoch: [1][12500/36908] Elapsed 105m 51s (remain 206m 41s) Loss: 0.0017(0.0095) Grad: 6626.1094  LR: 0.000015  \n","Epoch: [1][12600/36908] Elapsed 106m 43s (remain 205m 51s) Loss: 0.0000(0.0095) Grad: 668.2773  LR: 0.000015  \n","Epoch: [1][12700/36908] Elapsed 107m 34s (remain 205m 1s) Loss: 0.0001(0.0094) Grad: 1046.7982  LR: 0.000015  \n","Epoch: [1][12800/36908] Elapsed 108m 24s (remain 204m 10s) Loss: 0.0033(0.0094) Grad: 18805.6484  LR: 0.000015  \n","Epoch: [1][12900/36908] Elapsed 109m 16s (remain 203m 19s) Loss: 0.0000(0.0093) Grad: 9.4936  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 110m 7s (remain 202m 29s) Loss: 0.0002(0.0093) Grad: 3473.5271  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 110m 57s (remain 201m 38s) Loss: 0.0340(0.0092) Grad: 87617.0469  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 111m 48s (remain 200m 47s) Loss: 0.0060(0.0092) Grad: 17120.7617  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 112m 39s (remain 199m 56s) Loss: 0.0019(0.0091) Grad: 24678.7598  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 113m 29s (remain 199m 5s) Loss: 0.0023(0.0091) Grad: 21343.6660  LR: 0.000014  \n","Epoch: [1][13500/36908] Elapsed 114m 20s (remain 198m 14s) Loss: 0.0017(0.0090) Grad: 14586.8271  LR: 0.000014  \n","Epoch: [1][13600/36908] Elapsed 115m 10s (remain 197m 22s) Loss: 0.0530(0.0090) Grad: 107319.1562  LR: 0.000014  \n","Epoch: [1][13700/36908] Elapsed 116m 1s (remain 196m 30s) Loss: 0.0000(0.0089) Grad: 18.4889  LR: 0.000014  \n","Epoch: [1][13800/36908] Elapsed 116m 51s (remain 195m 39s) Loss: 0.0001(0.0089) Grad: 768.9446  LR: 0.000014  \n","Epoch: [1][13900/36908] Elapsed 117m 41s (remain 194m 47s) Loss: 0.0000(0.0088) Grad: 34.7756  LR: 0.000014  \n","Epoch: [1][14000/36908] Elapsed 118m 31s (remain 193m 55s) Loss: 0.0007(0.0088) Grad: 8316.4727  LR: 0.000014  \n","Epoch: [1][14100/36908] Elapsed 119m 22s (remain 193m 4s) Loss: 0.0081(0.0087) Grad: 27643.4980  LR: 0.000014  \n","Epoch: [1][14200/36908] Elapsed 120m 12s (remain 192m 13s) Loss: 0.0001(0.0087) Grad: 1098.5472  LR: 0.000014  \n","Epoch: [1][14300/36908] Elapsed 121m 3s (remain 191m 22s) Loss: 0.0000(0.0086) Grad: 35.4173  LR: 0.000014  \n","Epoch: [1][14400/36908] Elapsed 121m 54s (remain 190m 31s) Loss: 0.0079(0.0086) Grad: 20497.8535  LR: 0.000014  \n","Epoch: [1][14500/36908] Elapsed 122m 44s (remain 189m 39s) Loss: 0.0009(0.0085) Grad: 7669.4160  LR: 0.000013  \n","Epoch: [1][14600/36908] Elapsed 123m 34s (remain 188m 48s) Loss: 0.0000(0.0085) Grad: 219.2737  LR: 0.000013  \n","Epoch: [1][14700/36908] Elapsed 124m 25s (remain 187m 57s) Loss: 0.0037(0.0085) Grad: 27439.9531  LR: 0.000013  \n","Epoch: [1][14800/36908] Elapsed 125m 17s (remain 187m 8s) Loss: 0.0017(0.0084) Grad: 12733.5254  LR: 0.000013  \n","Epoch: [1][14900/36908] Elapsed 126m 8s (remain 186m 17s) Loss: 0.0047(0.0084) Grad: 54136.9102  LR: 0.000013  \n","Epoch: [1][15000/36908] Elapsed 126m 58s (remain 185m 25s) Loss: 0.0116(0.0083) Grad: 54788.6602  LR: 0.000013  \n","Epoch: [1][15100/36908] Elapsed 127m 48s (remain 184m 34s) Loss: 0.0011(0.0083) Grad: 7372.8901  LR: 0.000013  \n","Epoch: [1][15200/36908] Elapsed 128m 39s (remain 183m 43s) Loss: 0.0000(0.0082) Grad: 154.6431  LR: 0.000013  \n","Epoch: [1][15300/36908] Elapsed 129m 29s (remain 182m 51s) Loss: 0.0000(0.0082) Grad: 279.2524  LR: 0.000013  \n","Epoch: [1][15400/36908] Elapsed 130m 19s (remain 181m 59s) Loss: 0.0000(0.0082) Grad: 30.1982  LR: 0.000013  \n","Epoch: [1][15500/36908] Elapsed 131m 9s (remain 181m 7s) Loss: 0.0000(0.0081) Grad: 121.7098  LR: 0.000013  \n","Epoch: [1][15600/36908] Elapsed 131m 59s (remain 180m 16s) Loss: 0.0000(0.0081) Grad: 46.4694  LR: 0.000013  \n","Epoch: [1][15700/36908] Elapsed 132m 50s (remain 179m 25s) Loss: 0.0023(0.0081) Grad: 32539.1738  LR: 0.000013  \n","Epoch: [1][15800/36908] Elapsed 133m 40s (remain 178m 34s) Loss: 0.0000(0.0080) Grad: 227.9265  LR: 0.000013  \n","Epoch: [1][15900/36908] Elapsed 134m 31s (remain 177m 42s) Loss: 0.0038(0.0080) Grad: 29120.6758  LR: 0.000013  \n","Epoch: [1][16000/36908] Elapsed 135m 21s (remain 176m 51s) Loss: 0.0016(0.0080) Grad: 45478.3945  LR: 0.000013  \n","Epoch: [1][16100/36908] Elapsed 136m 10s (remain 175m 58s) Loss: 0.0013(0.0079) Grad: 33203.3086  LR: 0.000013  \n","Epoch: [1][16200/36908] Elapsed 136m 59s (remain 175m 5s) Loss: 0.0000(0.0079) Grad: 126.3391  LR: 0.000012  \n","Epoch: [1][16300/36908] Elapsed 137m 50s (remain 174m 14s) Loss: 0.0000(0.0078) Grad: 1384.7218  LR: 0.000012  \n","Epoch: [1][16400/36908] Elapsed 138m 40s (remain 173m 23s) Loss: 0.0000(0.0078) Grad: 107.7309  LR: 0.000012  \n","Epoch: [1][16500/36908] Elapsed 139m 30s (remain 172m 32s) Loss: 0.0000(0.0078) Grad: 22.8131  LR: 0.000012  \n","Epoch: [1][16600/36908] Elapsed 140m 21s (remain 171m 41s) Loss: 0.0000(0.0078) Grad: 232.6127  LR: 0.000012  \n","Epoch: [1][16700/36908] Elapsed 141m 11s (remain 170m 49s) Loss: 0.0101(0.0077) Grad: 64910.9492  LR: 0.000012  \n","Epoch: [1][16800/36908] Elapsed 142m 1s (remain 169m 58s) Loss: 0.0000(0.0077) Grad: 737.0848  LR: 0.000012  \n","Epoch: [1][16900/36908] Elapsed 142m 51s (remain 169m 6s) Loss: 0.0000(0.0077) Grad: 44.2742  LR: 0.000012  \n","Epoch: [1][17000/36908] Elapsed 143m 41s (remain 168m 15s) Loss: 0.0025(0.0076) Grad: 46426.1289  LR: 0.000012  \n","Epoch: [1][17100/36908] Elapsed 144m 32s (remain 167m 24s) Loss: 0.0017(0.0076) Grad: 54164.2695  LR: 0.000012  \n","Epoch: [1][17200/36908] Elapsed 145m 21s (remain 166m 32s) Loss: 0.0000(0.0076) Grad: 46.5784  LR: 0.000012  \n","Epoch: [1][17300/36908] Elapsed 146m 12s (remain 165m 41s) Loss: 0.0000(0.0075) Grad: 369.4053  LR: 0.000012  \n","Epoch: [1][17400/36908] Elapsed 147m 2s (remain 164m 50s) Loss: 0.0000(0.0075) Grad: 42.5597  LR: 0.000012  \n","Epoch: [1][17500/36908] Elapsed 147m 52s (remain 163m 59s) Loss: 0.0535(0.0075) Grad: 134380.1562  LR: 0.000012  \n","Epoch: [1][17600/36908] Elapsed 148m 42s (remain 163m 7s) Loss: 0.0000(0.0075) Grad: 47.6954  LR: 0.000012  \n","Epoch: [1][17700/36908] Elapsed 149m 32s (remain 162m 16s) Loss: 0.0010(0.0074) Grad: 21954.7246  LR: 0.000012  \n","Epoch: [1][17800/36908] Elapsed 150m 23s (remain 161m 25s) Loss: 0.0085(0.0074) Grad: 119052.7500  LR: 0.000012  \n","Epoch: [1][17900/36908] Elapsed 151m 13s (remain 160m 33s) Loss: 0.0000(0.0074) Grad: 12.5265  LR: 0.000011  \n","Epoch: [1][18000/36908] Elapsed 152m 3s (remain 159m 43s) Loss: 0.0000(0.0074) Grad: 216.4785  LR: 0.000011  \n","Epoch: [1][18100/36908] Elapsed 152m 54s (remain 158m 52s) Loss: 0.0000(0.0073) Grad: 49.0076  LR: 0.000011  \n","Epoch: [1][18200/36908] Elapsed 153m 46s (remain 158m 2s) Loss: 0.0000(0.0073) Grad: 64.7427  LR: 0.000011  \n","Epoch: [1][18300/36908] Elapsed 154m 37s (remain 157m 12s) Loss: 0.0000(0.0073) Grad: 264.6999  LR: 0.000011  \n","Epoch: [1][18400/36908] Elapsed 155m 27s (remain 156m 20s) Loss: 0.0000(0.0072) Grad: 133.7377  LR: 0.000011  \n","Epoch: [1][18500/36908] Elapsed 156m 17s (remain 155m 30s) Loss: 0.0390(0.0072) Grad: 205278.3594  LR: 0.000011  \n","Epoch: [1][18600/36908] Elapsed 157m 7s (remain 154m 38s) Loss: 0.0000(0.0072) Grad: 247.9648  LR: 0.000011  \n","Epoch: [1][18700/36908] Elapsed 157m 58s (remain 153m 48s) Loss: 0.0003(0.0072) Grad: 7209.0859  LR: 0.000011  \n","Epoch: [1][18800/36908] Elapsed 158m 49s (remain 152m 57s) Loss: 0.0001(0.0071) Grad: 3247.5378  LR: 0.000011  \n","Epoch: [1][18900/36908] Elapsed 159m 39s (remain 152m 6s) Loss: 0.0000(0.0071) Grad: 127.2131  LR: 0.000011  \n","Epoch: [1][19000/36908] Elapsed 160m 29s (remain 151m 15s) Loss: 0.0000(0.0071) Grad: 167.7831  LR: 0.000011  \n","Epoch: [1][19100/36908] Elapsed 161m 19s (remain 150m 23s) Loss: 0.0001(0.0071) Grad: 3088.7366  LR: 0.000011  \n","Epoch: [1][19200/36908] Elapsed 162m 9s (remain 149m 32s) Loss: 0.0000(0.0070) Grad: 263.9168  LR: 0.000011  \n","Epoch: [1][19300/36908] Elapsed 163m 0s (remain 148m 41s) Loss: 0.0000(0.0070) Grad: 44.1611  LR: 0.000011  \n","Epoch: [1][19400/36908] Elapsed 163m 50s (remain 147m 50s) Loss: 0.0182(0.0070) Grad: 80625.7188  LR: 0.000011  \n","Epoch: [1][19500/36908] Elapsed 164m 40s (remain 146m 59s) Loss: 0.0004(0.0070) Grad: 6573.1836  LR: 0.000010  \n","Epoch: [1][19600/36908] Elapsed 165m 31s (remain 146m 8s) Loss: 0.0000(0.0069) Grad: 351.6245  LR: 0.000010  \n","Epoch: [1][19700/36908] Elapsed 166m 21s (remain 145m 17s) Loss: 0.0000(0.0069) Grad: 62.8633  LR: 0.000010  \n","Epoch: [1][19800/36908] Elapsed 167m 11s (remain 144m 26s) Loss: 0.0045(0.0069) Grad: 56130.5703  LR: 0.000010  \n","Epoch: [1][19900/36908] Elapsed 168m 1s (remain 143m 35s) Loss: 0.0002(0.0069) Grad: 6200.0361  LR: 0.000010  \n","Epoch: [1][20000/36908] Elapsed 168m 51s (remain 142m 44s) Loss: 0.0054(0.0069) Grad: 62653.3984  LR: 0.000010  \n","Epoch: [1][20100/36908] Elapsed 169m 41s (remain 141m 53s) Loss: 0.0007(0.0068) Grad: 28397.4355  LR: 0.000010  \n","Epoch: [1][20200/36908] Elapsed 170m 32s (remain 141m 2s) Loss: 0.0000(0.0068) Grad: 1320.2404  LR: 0.000010  \n","Epoch: [1][20300/36908] Elapsed 171m 22s (remain 140m 11s) Loss: 0.0000(0.0068) Grad: 85.7537  LR: 0.000010  \n","Epoch: [1][20400/36908] Elapsed 172m 12s (remain 139m 20s) Loss: 0.0000(0.0068) Grad: 560.3940  LR: 0.000010  \n","Epoch: [1][20500/36908] Elapsed 173m 3s (remain 138m 29s) Loss: 0.0007(0.0067) Grad: 43500.8477  LR: 0.000010  \n","Epoch: [1][20600/36908] Elapsed 173m 54s (remain 137m 39s) Loss: 0.0005(0.0067) Grad: 40752.2227  LR: 0.000010  \n","Epoch: [1][20700/36908] Elapsed 174m 44s (remain 136m 48s) Loss: 0.0095(0.0067) Grad: 121890.4141  LR: 0.000010  \n","Epoch: [1][20800/36908] Elapsed 175m 36s (remain 135m 58s) Loss: 0.0000(0.0067) Grad: 84.8677  LR: 0.000010  \n","Epoch: [1][20900/36908] Elapsed 176m 27s (remain 135m 8s) Loss: 0.0283(0.0067) Grad: 212350.7969  LR: 0.000010  \n","Epoch: [1][21000/36908] Elapsed 177m 18s (remain 134m 18s) Loss: 0.0000(0.0066) Grad: 77.0591  LR: 0.000010  \n","Epoch: [1][21100/36908] Elapsed 178m 10s (remain 133m 28s) Loss: 0.0032(0.0066) Grad: 62576.0469  LR: 0.000010  \n","Epoch: [1][21200/36908] Elapsed 179m 1s (remain 132m 38s) Loss: 0.0045(0.0066) Grad: 167650.4375  LR: 0.000009  \n","Epoch: [1][21300/36908] Elapsed 179m 52s (remain 131m 47s) Loss: 0.0005(0.0066) Grad: 24595.8926  LR: 0.000009  \n","Epoch: [1][21400/36908] Elapsed 180m 43s (remain 130m 56s) Loss: 0.0052(0.0066) Grad: 204885.3906  LR: 0.000009  \n","Epoch: [1][21500/36908] Elapsed 181m 33s (remain 130m 6s) Loss: 0.0000(0.0066) Grad: 1223.0248  LR: 0.000009  \n","Epoch: [1][21600/36908] Elapsed 182m 24s (remain 129m 15s) Loss: 0.0228(0.0065) Grad: 205202.6875  LR: 0.000009  \n","Epoch: [1][21700/36908] Elapsed 183m 14s (remain 128m 24s) Loss: 0.0005(0.0065) Grad: 28925.8809  LR: 0.000009  \n","Epoch: [1][21800/36908] Elapsed 184m 5s (remain 127m 33s) Loss: 0.0134(0.0065) Grad: 167166.1250  LR: 0.000009  \n","Epoch: [1][21900/36908] Elapsed 184m 55s (remain 126m 42s) Loss: 0.0000(0.0065) Grad: 8.3236  LR: 0.000009  \n","Epoch: [1][22000/36908] Elapsed 185m 45s (remain 125m 51s) Loss: 0.0000(0.0065) Grad: 25.6773  LR: 0.000009  \n","Epoch: [1][22100/36908] Elapsed 186m 35s (remain 125m 0s) Loss: 0.0000(0.0064) Grad: 2646.6350  LR: 0.000009  \n","Epoch: [1][22200/36908] Elapsed 187m 25s (remain 124m 9s) Loss: 0.0000(0.0064) Grad: 4208.5054  LR: 0.000009  \n","Epoch: [1][22300/36908] Elapsed 188m 15s (remain 123m 18s) Loss: 0.0000(0.0064) Grad: 78.5184  LR: 0.000009  \n","Epoch: [1][22400/36908] Elapsed 189m 5s (remain 122m 27s) Loss: 0.0000(0.0064) Grad: 106.0110  LR: 0.000009  \n","Epoch: [1][22500/36908] Elapsed 189m 54s (remain 121m 35s) Loss: 0.0000(0.0064) Grad: 99.5811  LR: 0.000009  \n","Epoch: [1][22600/36908] Elapsed 190m 44s (remain 120m 44s) Loss: 0.0000(0.0064) Grad: 44.7083  LR: 0.000009  \n","Epoch: [1][22700/36908] Elapsed 191m 33s (remain 119m 53s) Loss: 0.0000(0.0063) Grad: 2374.8643  LR: 0.000009  \n","Epoch: [1][22800/36908] Elapsed 192m 23s (remain 119m 1s) Loss: 0.0021(0.0063) Grad: 130519.8438  LR: 0.000008  \n","Epoch: [1][22900/36908] Elapsed 193m 13s (remain 118m 10s) Loss: 0.0000(0.0063) Grad: 180.6195  LR: 0.000008  \n","Epoch: [1][23000/36908] Elapsed 194m 3s (remain 117m 19s) Loss: 0.0038(0.0063) Grad: 57260.1094  LR: 0.000008  \n","Epoch: [1][23100/36908] Elapsed 194m 53s (remain 116m 28s) Loss: 0.0000(0.0063) Grad: 47.2967  LR: 0.000008  \n","Epoch: [1][23200/36908] Elapsed 195m 42s (remain 115m 37s) Loss: 0.0020(0.0063) Grad: 112530.9453  LR: 0.000008  \n","Epoch: [1][23300/36908] Elapsed 196m 32s (remain 114m 46s) Loss: 0.0012(0.0062) Grad: 32746.5117  LR: 0.000008  \n","Epoch: [1][23400/36908] Elapsed 197m 22s (remain 113m 55s) Loss: 0.0000(0.0062) Grad: 221.4363  LR: 0.000008  \n","Epoch: [1][23500/36908] Elapsed 198m 11s (remain 113m 4s) Loss: 0.0018(0.0062) Grad: 36743.0586  LR: 0.000008  \n","Epoch: [1][23600/36908] Elapsed 199m 1s (remain 112m 13s) Loss: 0.0101(0.0062) Grad: 339333.9375  LR: 0.000008  \n","Epoch: [1][23700/36908] Elapsed 199m 51s (remain 111m 22s) Loss: 0.0000(0.0062) Grad: 43.8714  LR: 0.000008  \n","Epoch: [1][23800/36908] Elapsed 200m 41s (remain 110m 31s) Loss: 0.0000(0.0062) Grad: 17.2241  LR: 0.000008  \n","Epoch: [1][23900/36908] Elapsed 201m 30s (remain 109m 39s) Loss: 0.0001(0.0062) Grad: 6565.9097  LR: 0.000008  \n","Epoch: [1][24000/36908] Elapsed 202m 20s (remain 108m 48s) Loss: 0.0000(0.0061) Grad: 2866.5125  LR: 0.000008  \n","Epoch: [1][24100/36908] Elapsed 203m 10s (remain 107m 57s) Loss: 0.0000(0.0061) Grad: 530.1599  LR: 0.000008  \n","Epoch: [1][24200/36908] Elapsed 203m 59s (remain 107m 6s) Loss: 0.0029(0.0061) Grad: 47141.4844  LR: 0.000008  \n","Epoch: [1][24300/36908] Elapsed 204m 49s (remain 106m 15s) Loss: 0.0000(0.0061) Grad: 57.8551  LR: 0.000008  \n","Epoch: [1][24400/36908] Elapsed 205m 39s (remain 105m 24s) Loss: 0.0000(0.0061) Grad: 265.7386  LR: 0.000008  \n","Epoch: [1][24500/36908] Elapsed 206m 29s (remain 104m 33s) Loss: 0.0000(0.0061) Grad: 726.1771  LR: 0.000007  \n","Epoch: [1][24600/36908] Elapsed 207m 19s (remain 103m 42s) Loss: 0.0000(0.0061) Grad: 466.1663  LR: 0.000007  \n","Epoch: [1][24700/36908] Elapsed 208m 9s (remain 102m 52s) Loss: 0.0009(0.0060) Grad: 16884.2363  LR: 0.000007  \n","Epoch: [1][24800/36908] Elapsed 208m 59s (remain 102m 1s) Loss: 0.0000(0.0060) Grad: 58.5529  LR: 0.000007  \n","Epoch: [1][24900/36908] Elapsed 209m 49s (remain 101m 10s) Loss: 0.0000(0.0060) Grad: 179.5679  LR: 0.000007  \n","Epoch: [1][25000/36908] Elapsed 210m 40s (remain 100m 19s) Loss: 0.0000(0.0060) Grad: 2706.5417  LR: 0.000007  \n","Epoch: [1][25100/36908] Elapsed 211m 30s (remain 99m 29s) Loss: 0.0005(0.0060) Grad: 31051.6641  LR: 0.000007  \n","Epoch: [1][25200/36908] Elapsed 212m 19s (remain 98m 38s) Loss: 0.0000(0.0060) Grad: 6.8843  LR: 0.000007  \n","Epoch: [1][25300/36908] Elapsed 213m 10s (remain 97m 47s) Loss: 0.0000(0.0060) Grad: 564.8640  LR: 0.000007  \n","Epoch: [1][25400/36908] Elapsed 214m 0s (remain 96m 56s) Loss: 0.0121(0.0060) Grad: 308941.4375  LR: 0.000007  \n","Epoch: [1][25500/36908] Elapsed 214m 50s (remain 96m 5s) Loss: 0.0058(0.0059) Grad: 80477.3906  LR: 0.000007  \n","Epoch: [1][25600/36908] Elapsed 215m 39s (remain 95m 15s) Loss: 0.0000(0.0059) Grad: 151.4005  LR: 0.000007  \n","Epoch: [1][25700/36908] Elapsed 216m 29s (remain 94m 24s) Loss: 0.0000(0.0059) Grad: 65.5840  LR: 0.000007  \n","Epoch: [1][25800/36908] Elapsed 217m 19s (remain 93m 33s) Loss: 0.0008(0.0059) Grad: 20770.2285  LR: 0.000007  \n","Epoch: [1][25900/36908] Elapsed 218m 9s (remain 92m 42s) Loss: 0.0000(0.0059) Grad: 863.2122  LR: 0.000007  \n","Epoch: [1][26000/36908] Elapsed 218m 59s (remain 91m 51s) Loss: 0.0000(0.0059) Grad: 152.6095  LR: 0.000007  \n","Epoch: [1][26100/36908] Elapsed 219m 49s (remain 91m 0s) Loss: 0.0000(0.0059) Grad: 5.9440  LR: 0.000007  \n","Epoch: [1][26200/36908] Elapsed 220m 39s (remain 90m 10s) Loss: 0.0000(0.0059) Grad: 19.9715  LR: 0.000006  \n","Epoch: [1][26300/36908] Elapsed 221m 29s (remain 89m 19s) Loss: 0.0000(0.0059) Grad: 190.7798  LR: 0.000006  \n","Epoch: [1][26400/36908] Elapsed 222m 18s (remain 88m 28s) Loss: 0.0000(0.0058) Grad: 411.9372  LR: 0.000006  \n","Epoch: [1][26500/36908] Elapsed 223m 8s (remain 87m 37s) Loss: 0.0000(0.0058) Grad: 2998.0254  LR: 0.000006  \n","Epoch: [1][26600/36908] Elapsed 223m 58s (remain 86m 46s) Loss: 0.0000(0.0058) Grad: 111.9508  LR: 0.000006  \n","Epoch: [1][26700/36908] Elapsed 224m 47s (remain 85m 56s) Loss: 0.0007(0.0058) Grad: 58751.5469  LR: 0.000006  \n","Epoch: [1][26800/36908] Elapsed 225m 37s (remain 85m 5s) Loss: 0.0000(0.0058) Grad: 121.4687  LR: 0.000006  \n","Epoch: [1][26900/36908] Elapsed 226m 27s (remain 84m 14s) Loss: 0.0004(0.0058) Grad: 27767.0879  LR: 0.000006  \n","Epoch: [1][27000/36908] Elapsed 227m 17s (remain 83m 23s) Loss: 0.0000(0.0058) Grad: 126.6815  LR: 0.000006  \n","Epoch: [1][27100/36908] Elapsed 228m 7s (remain 82m 33s) Loss: 0.0125(0.0057) Grad: 372144.2500  LR: 0.000006  \n","Epoch: [1][27200/36908] Elapsed 228m 57s (remain 81m 42s) Loss: 0.0194(0.0057) Grad: 212803.7969  LR: 0.000006  \n","Epoch: [1][27300/36908] Elapsed 229m 46s (remain 80m 51s) Loss: 0.0072(0.0057) Grad: 178149.9219  LR: 0.000006  \n","Epoch: [1][27400/36908] Elapsed 230m 36s (remain 80m 0s) Loss: 0.0000(0.0057) Grad: 28.4730  LR: 0.000006  \n","Epoch: [1][27500/36908] Elapsed 231m 25s (remain 79m 9s) Loss: 0.0000(0.0057) Grad: 646.8839  LR: 0.000006  \n","Epoch: [1][27600/36908] Elapsed 232m 15s (remain 78m 18s) Loss: 0.0061(0.0057) Grad: 263467.2188  LR: 0.000006  \n","Epoch: [1][27700/36908] Elapsed 233m 5s (remain 77m 28s) Loss: 0.0012(0.0057) Grad: 61594.6562  LR: 0.000006  \n","Epoch: [1][27800/36908] Elapsed 233m 54s (remain 76m 37s) Loss: 0.0044(0.0057) Grad: 233319.9844  LR: 0.000005  \n","Epoch: [1][27900/36908] Elapsed 234m 45s (remain 75m 46s) Loss: 0.0000(0.0057) Grad: 58.3083  LR: 0.000005  \n","Epoch: [1][28000/36908] Elapsed 235m 35s (remain 74m 56s) Loss: 0.0000(0.0057) Grad: 39.7060  LR: 0.000005  \n","Epoch: [1][28100/36908] Elapsed 236m 25s (remain 74m 5s) Loss: 0.0000(0.0056) Grad: 249.4733  LR: 0.000005  \n","Epoch: [1][28200/36908] Elapsed 237m 15s (remain 73m 15s) Loss: 0.0000(0.0056) Grad: 20.4880  LR: 0.000005  \n","Epoch: [1][28300/36908] Elapsed 238m 5s (remain 72m 24s) Loss: 0.0009(0.0056) Grad: 35499.0195  LR: 0.000005  \n","Epoch: [1][28400/36908] Elapsed 238m 54s (remain 71m 33s) Loss: 0.0000(0.0056) Grad: 237.8792  LR: 0.000005  \n","Epoch: [1][28500/36908] Elapsed 239m 44s (remain 70m 43s) Loss: 0.0279(0.0056) Grad: 360077.7812  LR: 0.000005  \n","Epoch: [1][28600/36908] Elapsed 240m 34s (remain 69m 52s) Loss: 0.0000(0.0056) Grad: 108.5789  LR: 0.000005  \n","Epoch: [1][28700/36908] Elapsed 241m 24s (remain 69m 1s) Loss: 0.0006(0.0056) Grad: 25448.9082  LR: 0.000005  \n","Epoch: [1][28800/36908] Elapsed 242m 13s (remain 68m 11s) Loss: 0.0000(0.0056) Grad: 223.2889  LR: 0.000005  \n","Epoch: [1][28900/36908] Elapsed 243m 4s (remain 67m 20s) Loss: 0.0000(0.0056) Grad: 365.8818  LR: 0.000005  \n","Epoch: [1][29000/36908] Elapsed 243m 54s (remain 66m 29s) Loss: 0.0000(0.0056) Grad: 88.3577  LR: 0.000005  \n","Epoch: [1][29100/36908] Elapsed 244m 44s (remain 65m 39s) Loss: 0.0107(0.0056) Grad: 206338.5781  LR: 0.000005  \n","Epoch: [1][29200/36908] Elapsed 245m 34s (remain 64m 48s) Loss: 0.0149(0.0056) Grad: 420192.0312  LR: 0.000005  \n","Epoch: [1][29300/36908] Elapsed 246m 24s (remain 63m 58s) Loss: 0.0017(0.0055) Grad: 87081.4688  LR: 0.000005  \n","Epoch: [1][29400/36908] Elapsed 247m 14s (remain 63m 7s) Loss: 0.0000(0.0055) Grad: 33.2602  LR: 0.000005  \n","Epoch: [1][29500/36908] Elapsed 248m 5s (remain 62m 17s) Loss: 0.0076(0.0055) Grad: 94369.6406  LR: 0.000004  \n","Epoch: [1][29600/36908] Elapsed 248m 54s (remain 61m 26s) Loss: 0.0000(0.0055) Grad: 16.7517  LR: 0.000004  \n","Epoch: [1][29700/36908] Elapsed 249m 44s (remain 60m 36s) Loss: 0.0002(0.0055) Grad: 5659.1636  LR: 0.000004  \n","Epoch: [1][29800/36908] Elapsed 250m 34s (remain 59m 45s) Loss: 0.0044(0.0055) Grad: 84566.2109  LR: 0.000004  \n","Epoch: [1][29900/36908] Elapsed 251m 24s (remain 58m 54s) Loss: 0.0030(0.0055) Grad: 21373.0137  LR: 0.000004  \n","Epoch: [1][30000/36908] Elapsed 252m 14s (remain 58m 4s) Loss: 0.0000(0.0055) Grad: 51.9349  LR: 0.000004  \n","Epoch: [1][30100/36908] Elapsed 253m 4s (remain 57m 13s) Loss: 0.0059(0.0055) Grad: 56424.3008  LR: 0.000004  \n","Epoch: [1][30200/36908] Elapsed 253m 53s (remain 56m 23s) Loss: 0.0022(0.0055) Grad: 20930.3203  LR: 0.000004  \n","Epoch: [1][30300/36908] Elapsed 254m 43s (remain 55m 32s) Loss: 0.0001(0.0055) Grad: 3896.8093  LR: 0.000004  \n","Epoch: [1][30400/36908] Elapsed 255m 33s (remain 54m 41s) Loss: 0.0001(0.0054) Grad: 4296.6045  LR: 0.000004  \n","Epoch: [1][30500/36908] Elapsed 256m 23s (remain 53m 51s) Loss: 0.0212(0.0054) Grad: 153979.4531  LR: 0.000004  \n","Epoch: [1][30600/36908] Elapsed 257m 13s (remain 53m 0s) Loss: 0.0120(0.0054) Grad: 66081.8984  LR: 0.000004  \n","Epoch: [1][30700/36908] Elapsed 258m 3s (remain 52m 10s) Loss: 0.0000(0.0054) Grad: 456.8510  LR: 0.000004  \n","Epoch: [1][30800/36908] Elapsed 258m 53s (remain 51m 19s) Loss: 0.0000(0.0054) Grad: 345.6557  LR: 0.000004  \n","Epoch: [1][30900/36908] Elapsed 259m 43s (remain 50m 29s) Loss: 0.0000(0.0054) Grad: 42.8150  LR: 0.000004  \n","Epoch: [1][31000/36908] Elapsed 260m 33s (remain 49m 38s) Loss: 0.0000(0.0054) Grad: 31.6403  LR: 0.000004  \n","Epoch: [1][31100/36908] Elapsed 261m 23s (remain 48m 48s) Loss: 0.0000(0.0054) Grad: 203.5898  LR: 0.000003  \n","Epoch: [1][31200/36908] Elapsed 262m 12s (remain 47m 57s) Loss: 0.0001(0.0054) Grad: 2621.6990  LR: 0.000003  \n","Epoch: [1][31300/36908] Elapsed 263m 2s (remain 47m 7s) Loss: 0.0000(0.0054) Grad: 21.2672  LR: 0.000003  \n","Epoch: [1][31400/36908] Elapsed 263m 51s (remain 46m 16s) Loss: 0.0001(0.0054) Grad: 6972.4780  LR: 0.000003  \n","Epoch: [1][31500/36908] Elapsed 264m 41s (remain 45m 25s) Loss: 0.0000(0.0053) Grad: 33.1304  LR: 0.000003  \n","Epoch: [1][31600/36908] Elapsed 265m 30s (remain 44m 35s) Loss: 0.0000(0.0053) Grad: 8.1198  LR: 0.000003  \n","Epoch: [1][31700/36908] Elapsed 266m 19s (remain 43m 44s) Loss: 0.0000(0.0053) Grad: 41.3361  LR: 0.000003  \n","Epoch: [1][31800/36908] Elapsed 267m 9s (remain 42m 54s) Loss: 0.0000(0.0053) Grad: 166.9976  LR: 0.000003  \n","Epoch: [1][31900/36908] Elapsed 267m 58s (remain 42m 3s) Loss: 0.0000(0.0053) Grad: 105.7536  LR: 0.000003  \n","Epoch: [1][32000/36908] Elapsed 268m 47s (remain 41m 13s) Loss: 0.0055(0.0053) Grad: 43436.5352  LR: 0.000003  \n","Epoch: [1][32100/36908] Elapsed 269m 37s (remain 40m 22s) Loss: 0.0001(0.0053) Grad: 4973.4541  LR: 0.000003  \n","Epoch: [1][32200/36908] Elapsed 270m 26s (remain 39m 31s) Loss: 0.0001(0.0053) Grad: 4991.6494  LR: 0.000003  \n","Epoch: [1][32300/36908] Elapsed 271m 17s (remain 38m 41s) Loss: 0.0000(0.0053) Grad: 37.6763  LR: 0.000003  \n","Epoch: [1][32400/36908] Elapsed 272m 7s (remain 37m 51s) Loss: 0.0000(0.0053) Grad: 418.2871  LR: 0.000003  \n","Epoch: [1][32500/36908] Elapsed 272m 57s (remain 37m 0s) Loss: 0.0000(0.0053) Grad: 375.8549  LR: 0.000003  \n","Epoch: [1][32600/36908] Elapsed 273m 47s (remain 36m 10s) Loss: 0.0071(0.0052) Grad: 69723.0469  LR: 0.000003  \n","Epoch: [1][32700/36908] Elapsed 274m 37s (remain 35m 19s) Loss: 0.0070(0.0052) Grad: 86985.8125  LR: 0.000003  \n","Epoch: [1][32800/36908] Elapsed 275m 27s (remain 34m 29s) Loss: 0.0068(0.0052) Grad: 37352.7969  LR: 0.000002  \n","Epoch: [1][32900/36908] Elapsed 276m 17s (remain 33m 38s) Loss: 0.0000(0.0052) Grad: 926.9731  LR: 0.000002  \n","Epoch: [1][33000/36908] Elapsed 277m 6s (remain 32m 48s) Loss: 0.0000(0.0052) Grad: 10.7412  LR: 0.000002  \n","Epoch: [1][33100/36908] Elapsed 277m 56s (remain 31m 57s) Loss: 0.0001(0.0052) Grad: 2015.6270  LR: 0.000002  \n","Epoch: [1][33200/36908] Elapsed 278m 46s (remain 31m 7s) Loss: 0.0004(0.0052) Grad: 14192.3291  LR: 0.000002  \n","Epoch: [1][33300/36908] Elapsed 279m 36s (remain 30m 17s) Loss: 0.0000(0.0052) Grad: 22.1874  LR: 0.000002  \n","Epoch: [1][33400/36908] Elapsed 280m 25s (remain 29m 26s) Loss: 0.0001(0.0052) Grad: 3574.2759  LR: 0.000002  \n","Epoch: [1][33500/36908] Elapsed 281m 15s (remain 28m 36s) Loss: 0.0015(0.0052) Grad: 19687.4805  LR: 0.000002  \n","Epoch: [1][33600/36908] Elapsed 282m 5s (remain 27m 45s) Loss: 0.0174(0.0052) Grad: 251836.9062  LR: 0.000002  \n","Epoch: [1][33700/36908] Elapsed 282m 54s (remain 26m 55s) Loss: 0.0004(0.0052) Grad: 29395.9531  LR: 0.000002  \n","Epoch: [1][33800/36908] Elapsed 283m 45s (remain 26m 4s) Loss: 0.0008(0.0052) Grad: 22791.8027  LR: 0.000002  \n","Epoch: [1][33900/36908] Elapsed 284m 35s (remain 25m 14s) Loss: 0.0000(0.0051) Grad: 240.9129  LR: 0.000002  \n","Epoch: [1][34000/36908] Elapsed 285m 25s (remain 24m 24s) Loss: 0.0013(0.0051) Grad: 19079.5801  LR: 0.000002  \n","Epoch: [1][34100/36908] Elapsed 286m 16s (remain 23m 33s) Loss: 0.0034(0.0051) Grad: 105461.2578  LR: 0.000002  \n","Epoch: [1][34200/36908] Elapsed 287m 7s (remain 22m 43s) Loss: 0.0000(0.0051) Grad: 387.8246  LR: 0.000002  \n","Epoch: [1][34300/36908] Elapsed 287m 58s (remain 21m 53s) Loss: 0.0000(0.0051) Grad: 234.9642  LR: 0.000002  \n","Epoch: [1][34400/36908] Elapsed 288m 48s (remain 21m 2s) Loss: 0.0000(0.0051) Grad: 22.1546  LR: 0.000002  \n","Epoch: [1][34500/36908] Elapsed 289m 38s (remain 20m 12s) Loss: 0.0000(0.0051) Grad: 248.7435  LR: 0.000001  \n","Epoch: [1][34600/36908] Elapsed 290m 28s (remain 19m 22s) Loss: 0.0000(0.0051) Grad: 190.5369  LR: 0.000001  \n","Epoch: [1][34700/36908] Elapsed 291m 19s (remain 18m 31s) Loss: 0.0332(0.0051) Grad: 329436.4375  LR: 0.000001  \n","Epoch: [1][34800/36908] Elapsed 292m 9s (remain 17m 41s) Loss: 0.0000(0.0051) Grad: 197.2755  LR: 0.000001  \n","Epoch: [1][34900/36908] Elapsed 292m 59s (remain 16m 50s) Loss: 0.0000(0.0051) Grad: 99.8409  LR: 0.000001  \n","Epoch: [1][35000/36908] Elapsed 293m 49s (remain 16m 0s) Loss: 0.0000(0.0051) Grad: 430.7872  LR: 0.000001  \n","Epoch: [1][35100/36908] Elapsed 294m 40s (remain 15m 10s) Loss: 0.0000(0.0051) Grad: 233.4865  LR: 0.000001  \n","Epoch: [1][35200/36908] Elapsed 295m 30s (remain 14m 19s) Loss: 0.0000(0.0051) Grad: 208.2283  LR: 0.000001  \n","Epoch: [1][35300/36908] Elapsed 296m 20s (remain 13m 29s) Loss: 0.0000(0.0050) Grad: 19.1079  LR: 0.000001  \n","Epoch: [1][35400/36908] Elapsed 297m 10s (remain 12m 39s) Loss: 0.0000(0.0050) Grad: 89.9060  LR: 0.000001  \n","Epoch: [1][35500/36908] Elapsed 298m 1s (remain 11m 48s) Loss: 0.0039(0.0050) Grad: 74496.9922  LR: 0.000001  \n","Epoch: [1][35600/36908] Elapsed 298m 51s (remain 10m 58s) Loss: 0.0001(0.0050) Grad: 3880.8828  LR: 0.000001  \n","Epoch: [1][35700/36908] Elapsed 299m 41s (remain 10m 7s) Loss: 0.0000(0.0050) Grad: 51.4548  LR: 0.000001  \n","Epoch: [1][35800/36908] Elapsed 300m 32s (remain 9m 17s) Loss: 0.0000(0.0050) Grad: 37.0204  LR: 0.000001  \n","Epoch: [1][35900/36908] Elapsed 301m 22s (remain 8m 27s) Loss: 0.0007(0.0050) Grad: 11298.1572  LR: 0.000001  \n","Epoch: [1][36000/36908] Elapsed 302m 14s (remain 7m 36s) Loss: 0.0000(0.0050) Grad: 79.7184  LR: 0.000001  \n","Epoch: [1][36100/36908] Elapsed 303m 6s (remain 6m 46s) Loss: 0.0000(0.0050) Grad: 74.5701  LR: 0.000000  \n","Epoch: [1][36200/36908] Elapsed 303m 58s (remain 5m 56s) Loss: 0.0000(0.0050) Grad: 17.3113  LR: 0.000000  \n","Epoch: [1][36300/36908] Elapsed 304m 50s (remain 5m 5s) Loss: 0.0000(0.0050) Grad: 651.3428  LR: 0.000000  \n","Epoch: [1][36400/36908] Elapsed 305m 41s (remain 4m 15s) Loss: 0.0000(0.0050) Grad: 198.5309  LR: 0.000000  \n","Epoch: [1][36500/36908] Elapsed 306m 33s (remain 3m 25s) Loss: 0.0055(0.0050) Grad: 96990.2344  LR: 0.000000  \n","Epoch: [1][36600/36908] Elapsed 307m 24s (remain 2m 34s) Loss: 0.0060(0.0050) Grad: 147892.8438  LR: 0.000000  \n","Epoch: [1][36700/36908] Elapsed 308m 16s (remain 1m 44s) Loss: 0.0000(0.0050) Grad: 267.3368  LR: 0.000000  \n","Epoch: [1][36800/36908] Elapsed 309m 5s (remain 0m 53s) Loss: 0.0000(0.0050) Grad: 21.1487  LR: 0.000000  \n","Epoch: [1][36900/36908] Elapsed 309m 55s (remain 0m 3s) Loss: 0.0000(0.0050) Grad: 32.8320  LR: 0.000000  \n","Epoch: [1][36907/36908] Elapsed 309m 59s (remain 0m 0s) Loss: 0.0010(0.0050) Grad: 13349.2500  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 19m 36s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 23s (remain 4m 12s) Loss: 0.0642(0.0135) \n","EVAL: [200/1192] Elapsed 0m 45s (remain 3m 45s) Loss: 0.0242(0.0128) \n","EVAL: [300/1192] Elapsed 1m 8s (remain 3m 21s) Loss: 0.0209(0.0123) \n","EVAL: [400/1192] Elapsed 1m 30s (remain 2m 58s) Loss: 0.0000(0.0132) \n","EVAL: [500/1192] Elapsed 1m 52s (remain 2m 35s) Loss: 0.0000(0.0124) \n","EVAL: [600/1192] Elapsed 2m 14s (remain 2m 11s) Loss: 0.0098(0.0126) \n","EVAL: [700/1192] Elapsed 2m 36s (remain 1m 49s) Loss: 0.0185(0.0144) \n","EVAL: [800/1192] Elapsed 2m 58s (remain 1m 26s) Loss: 0.0000(0.0142) \n","EVAL: [900/1192] Elapsed 3m 20s (remain 1m 4s) Loss: 0.0132(0.0143) \n","EVAL: [1000/1192] Elapsed 3m 42s (remain 0m 42s) Loss: 0.0002(0.0139) \n","EVAL: [1100/1192] Elapsed 4m 4s (remain 0m 20s) Loss: 0.0582(0.0133) \n","EVAL: [1191/1192] Elapsed 4m 24s (remain 0m 0s) Loss: 0.0000(0.0128) \n","Epoch 1 - avg_train_loss: 0.0050  avg_val_loss: 0.0128  time: 18866s\n","Epoch 1 - Score: 0.8940\n","Epoch 1 - Save Best Score: 0.8940 Model\n","========== fold: 3 training ==========\n","get pseudo plain from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/make_pseudo_dataset/pseudo_plain.pkl\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp060/pseudo_labels_3.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp067/pseudo_labels_3.npy\n","get pseudo labels from ./drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp083/pseudo_labels_3.npy\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1533d738bd64bba90ca5bab036838e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/612602 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84a8b42da5fd406386892b0b944e90d7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(612602, 950)\n","(612602, 6) (612602, 950)\n","(100000, 7)\n","(110725, 11)\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp090/fold3_best.pth\n","Epoch: [1][0/36908] Elapsed 0m 1s (remain 918m 49s) Loss: 0.3684(0.3684) Grad: 179936.9688  LR: 0.000000  \n","Epoch: [1][100/36908] Elapsed 0m 51s (remain 314m 52s) Loss: 0.3357(0.3587) Grad: 159191.9062  LR: 0.000001  \n","Epoch: [1][200/36908] Elapsed 1m 42s (remain 311m 48s) Loss: 0.2414(0.3258) Grad: 132396.8438  LR: 0.000001  \n","Epoch: [1][300/36908] Elapsed 2m 32s (remain 308m 59s) Loss: 0.1312(0.2797) Grad: 81110.7188  LR: 0.000002  \n","Epoch: [1][400/36908] Elapsed 3m 21s (remain 306m 20s) Loss: 0.0505(0.2326) Grad: 35434.4688  LR: 0.000002  \n","Epoch: [1][500/36908] Elapsed 4m 11s (remain 304m 31s) Loss: 0.0194(0.1931) Grad: 10287.7188  LR: 0.000003  \n","Epoch: [1][600/36908] Elapsed 5m 1s (remain 303m 14s) Loss: 0.0038(0.1632) Grad: 2875.1768  LR: 0.000003  \n","Epoch: [1][700/36908] Elapsed 5m 50s (remain 301m 53s) Loss: 0.0032(0.1408) Grad: 1462.2880  LR: 0.000004  \n","Epoch: [1][800/36908] Elapsed 6m 40s (remain 300m 50s) Loss: 0.0014(0.1237) Grad: 652.6497  LR: 0.000004  \n","Epoch: [1][900/36908] Elapsed 7m 29s (remain 299m 34s) Loss: 0.0031(0.1105) Grad: 496.6165  LR: 0.000005  \n","Epoch: [1][1000/36908] Elapsed 8m 19s (remain 298m 25s) Loss: 0.0009(0.0999) Grad: 666.9608  LR: 0.000005  \n","Epoch: [1][1100/36908] Elapsed 9m 8s (remain 297m 27s) Loss: 0.0007(0.0912) Grad: 328.9893  LR: 0.000006  \n","Epoch: [1][1200/36908] Elapsed 9m 58s (remain 296m 32s) Loss: 0.0018(0.0839) Grad: 453.1646  LR: 0.000007  \n","Epoch: [1][1300/36908] Elapsed 10m 48s (remain 295m 43s) Loss: 0.0013(0.0777) Grad: 649.2192  LR: 0.000007  \n","Epoch: [1][1400/36908] Elapsed 11m 38s (remain 294m 55s) Loss: 0.0043(0.0724) Grad: 1558.7781  LR: 0.000008  \n","Epoch: [1][1500/36908] Elapsed 12m 27s (remain 294m 1s) Loss: 0.0131(0.0678) Grad: 3074.1741  LR: 0.000008  \n","Epoch: [1][1600/36908] Elapsed 13m 17s (remain 293m 2s) Loss: 0.0002(0.0637) Grad: 102.8214  LR: 0.000009  \n","Epoch: [1][1700/36908] Elapsed 14m 7s (remain 292m 11s) Loss: 0.0003(0.0602) Grad: 150.9686  LR: 0.000009  \n","Epoch: [1][1800/36908] Elapsed 14m 57s (remain 291m 26s) Loss: 0.0081(0.0570) Grad: 3877.6248  LR: 0.000010  \n","Epoch: [1][1900/36908] Elapsed 15m 46s (remain 290m 35s) Loss: 0.0018(0.0542) Grad: 357.6864  LR: 0.000010  \n","Epoch: [1][2000/36908] Elapsed 16m 37s (remain 290m 9s) Loss: 0.0078(0.0516) Grad: 5173.7603  LR: 0.000011  \n","Epoch: [1][2100/36908] Elapsed 17m 27s (remain 289m 18s) Loss: 0.0017(0.0493) Grad: 786.1138  LR: 0.000011  \n","Epoch: [1][2200/36908] Elapsed 18m 17s (remain 288m 29s) Loss: 0.0018(0.0472) Grad: 1473.6328  LR: 0.000012  \n","Epoch: [1][2300/36908] Elapsed 19m 7s (remain 287m 41s) Loss: 0.0197(0.0452) Grad: 4918.7881  LR: 0.000012  \n","Epoch: [1][2400/36908] Elapsed 19m 57s (remain 286m 48s) Loss: 0.0002(0.0435) Grad: 101.1148  LR: 0.000013  \n","Epoch: [1][2500/36908] Elapsed 20m 47s (remain 285m 57s) Loss: 0.0234(0.0418) Grad: 10372.2070  LR: 0.000014  \n","Epoch: [1][2600/36908] Elapsed 21m 36s (remain 285m 4s) Loss: 0.0002(0.0403) Grad: 130.3421  LR: 0.000014  \n","Epoch: [1][2700/36908] Elapsed 22m 26s (remain 284m 13s) Loss: 0.0002(0.0389) Grad: 226.5897  LR: 0.000015  \n","Epoch: [1][2800/36908] Elapsed 23m 16s (remain 283m 23s) Loss: 0.0013(0.0376) Grad: 1413.0018  LR: 0.000015  \n","Epoch: [1][2900/36908] Elapsed 24m 6s (remain 282m 38s) Loss: 0.0005(0.0364) Grad: 317.3521  LR: 0.000016  \n","Epoch: [1][3000/36908] Elapsed 24m 57s (remain 281m 55s) Loss: 0.0000(0.0353) Grad: 11.3419  LR: 0.000016  \n","Epoch: [1][3100/36908] Elapsed 25m 47s (remain 281m 5s) Loss: 0.0050(0.0343) Grad: 1998.2670  LR: 0.000017  \n","Epoch: [1][3200/36908] Elapsed 26m 36s (remain 280m 13s) Loss: 0.0002(0.0332) Grad: 106.4416  LR: 0.000017  \n","Epoch: [1][3300/36908] Elapsed 27m 26s (remain 279m 22s) Loss: 0.0000(0.0323) Grad: 56.9856  LR: 0.000018  \n","Epoch: [1][3400/36908] Elapsed 28m 16s (remain 278m 32s) Loss: 0.0002(0.0314) Grad: 168.1128  LR: 0.000018  \n","Epoch: [1][3500/36908] Elapsed 29m 6s (remain 277m 40s) Loss: 0.0001(0.0306) Grad: 72.2051  LR: 0.000019  \n","Epoch: [1][3600/36908] Elapsed 29m 55s (remain 276m 49s) Loss: 0.0008(0.0298) Grad: 776.4730  LR: 0.000020  \n","Epoch: [1][3700/36908] Elapsed 30m 45s (remain 275m 59s) Loss: 0.0020(0.0291) Grad: 1142.6182  LR: 0.000020  \n","Epoch: [1][3800/36908] Elapsed 31m 35s (remain 275m 6s) Loss: 0.0001(0.0284) Grad: 117.1094  LR: 0.000020  \n","Epoch: [1][3900/36908] Elapsed 32m 24s (remain 274m 14s) Loss: 0.0004(0.0277) Grad: 354.4788  LR: 0.000020  \n","Epoch: [1][4000/36908] Elapsed 33m 14s (remain 273m 22s) Loss: 0.0070(0.0271) Grad: 5756.8198  LR: 0.000020  \n","Epoch: [1][4100/36908] Elapsed 34m 4s (remain 272m 31s) Loss: 0.0003(0.0265) Grad: 594.1786  LR: 0.000020  \n","Epoch: [1][4200/36908] Elapsed 34m 53s (remain 271m 39s) Loss: 0.0004(0.0259) Grad: 1262.5920  LR: 0.000020  \n","Epoch: [1][4300/36908] Elapsed 35m 43s (remain 270m 47s) Loss: 0.0000(0.0253) Grad: 109.7448  LR: 0.000020  \n","Epoch: [1][4400/36908] Elapsed 36m 32s (remain 269m 57s) Loss: 0.0188(0.0248) Grad: 13526.9912  LR: 0.000020  \n","Epoch: [1][4500/36908] Elapsed 37m 22s (remain 269m 6s) Loss: 0.0001(0.0243) Grad: 217.3606  LR: 0.000020  \n","Epoch: [1][4600/36908] Elapsed 38m 12s (remain 268m 14s) Loss: 0.0015(0.0239) Grad: 1320.8312  LR: 0.000019  \n","Epoch: [1][4700/36908] Elapsed 39m 1s (remain 267m 23s) Loss: 0.0001(0.0234) Grad: 86.7497  LR: 0.000019  \n","Epoch: [1][4800/36908] Elapsed 39m 51s (remain 266m 31s) Loss: 0.0006(0.0230) Grad: 922.1039  LR: 0.000019  \n","Epoch: [1][4900/36908] Elapsed 40m 41s (remain 265m 42s) Loss: 0.0001(0.0225) Grad: 208.2020  LR: 0.000019  \n","Epoch: [1][5000/36908] Elapsed 41m 30s (remain 264m 51s) Loss: 0.0054(0.0221) Grad: 4132.7197  LR: 0.000019  \n","Epoch: [1][5100/36908] Elapsed 42m 20s (remain 264m 1s) Loss: 0.0001(0.0218) Grad: 118.5888  LR: 0.000019  \n","Epoch: [1][5200/36908] Elapsed 43m 10s (remain 263m 10s) Loss: 0.0002(0.0214) Grad: 430.9679  LR: 0.000019  \n","Epoch: [1][5300/36908] Elapsed 43m 59s (remain 262m 19s) Loss: 0.0007(0.0210) Grad: 1443.6118  LR: 0.000019  \n","Epoch: [1][5400/36908] Elapsed 44m 49s (remain 261m 28s) Loss: 0.0000(0.0207) Grad: 7.8633  LR: 0.000019  \n","Epoch: [1][5500/36908] Elapsed 45m 38s (remain 260m 37s) Loss: 0.0000(0.0204) Grad: 39.2474  LR: 0.000019  \n","Epoch: [1][5600/36908] Elapsed 46m 28s (remain 259m 46s) Loss: 0.0021(0.0200) Grad: 2786.6150  LR: 0.000019  \n","Epoch: [1][5700/36908] Elapsed 47m 18s (remain 258m 58s) Loss: 0.0016(0.0197) Grad: 3624.5613  LR: 0.000019  \n","Epoch: [1][5800/36908] Elapsed 48m 8s (remain 258m 7s) Loss: 0.0000(0.0194) Grad: 13.2944  LR: 0.000019  \n","Epoch: [1][5900/36908] Elapsed 48m 57s (remain 257m 15s) Loss: 0.0000(0.0191) Grad: 59.9990  LR: 0.000019  \n","Epoch: [1][6000/36908] Elapsed 49m 46s (remain 256m 23s) Loss: 0.0000(0.0189) Grad: 76.3771  LR: 0.000019  \n","Epoch: [1][6100/36908] Elapsed 50m 37s (remain 255m 35s) Loss: 0.0000(0.0186) Grad: 27.7490  LR: 0.000019  \n","Epoch: [1][6200/36908] Elapsed 51m 26s (remain 254m 46s) Loss: 0.0050(0.0183) Grad: 7294.1890  LR: 0.000018  \n","Epoch: [1][6300/36908] Elapsed 52m 16s (remain 253m 56s) Loss: 0.0000(0.0181) Grad: 32.8309  LR: 0.000018  \n","Epoch: [1][6400/36908] Elapsed 53m 6s (remain 253m 7s) Loss: 0.0052(0.0178) Grad: 6155.5869  LR: 0.000018  \n","Epoch: [1][6500/36908] Elapsed 53m 56s (remain 252m 16s) Loss: 0.0013(0.0176) Grad: 1711.0801  LR: 0.000018  \n","Epoch: [1][6600/36908] Elapsed 54m 46s (remain 251m 27s) Loss: 0.0001(0.0173) Grad: 350.5961  LR: 0.000018  \n","Epoch: [1][6700/36908] Elapsed 55m 35s (remain 250m 37s) Loss: 0.0009(0.0171) Grad: 1869.4397  LR: 0.000018  \n","Epoch: [1][6800/36908] Elapsed 56m 25s (remain 249m 47s) Loss: 0.0110(0.0169) Grad: 8608.7305  LR: 0.000018  \n","Epoch: [1][6900/36908] Elapsed 57m 15s (remain 248m 57s) Loss: 0.0000(0.0167) Grad: 60.9518  LR: 0.000018  \n","Epoch: [1][7000/36908] Elapsed 58m 5s (remain 248m 7s) Loss: 0.0003(0.0165) Grad: 811.7996  LR: 0.000018  \n","Epoch: [1][7100/36908] Elapsed 58m 54s (remain 247m 18s) Loss: 0.0001(0.0163) Grad: 159.2523  LR: 0.000018  \n","Epoch: [1][7200/36908] Elapsed 59m 44s (remain 246m 28s) Loss: 0.0079(0.0161) Grad: 6887.9517  LR: 0.000018  \n","Epoch: [1][7300/36908] Elapsed 60m 34s (remain 245m 39s) Loss: 0.0001(0.0159) Grad: 267.7970  LR: 0.000018  \n","Epoch: [1][7400/36908] Elapsed 61m 24s (remain 244m 50s) Loss: 0.0001(0.0157) Grad: 114.9457  LR: 0.000018  \n","Epoch: [1][7500/36908] Elapsed 62m 14s (remain 244m 0s) Loss: 0.0036(0.0156) Grad: 5814.6821  LR: 0.000018  \n","Epoch: [1][7600/36908] Elapsed 63m 3s (remain 243m 9s) Loss: 0.0001(0.0154) Grad: 188.0139  LR: 0.000018  \n","Epoch: [1][7700/36908] Elapsed 63m 53s (remain 242m 18s) Loss: 0.0000(0.0152) Grad: 39.5708  LR: 0.000018  \n","Epoch: [1][7800/36908] Elapsed 64m 43s (remain 241m 28s) Loss: 0.0002(0.0151) Grad: 788.8955  LR: 0.000018  \n","Epoch: [1][7900/36908] Elapsed 65m 32s (remain 240m 39s) Loss: 0.0000(0.0149) Grad: 40.1996  LR: 0.000017  \n","Epoch: [1][8000/36908] Elapsed 66m 22s (remain 239m 49s) Loss: 0.0001(0.0147) Grad: 816.6468  LR: 0.000017  \n","Epoch: [1][8100/36908] Elapsed 67m 12s (remain 238m 58s) Loss: 0.0115(0.0146) Grad: 22206.4746  LR: 0.000017  \n","Epoch: [1][8200/36908] Elapsed 68m 1s (remain 238m 8s) Loss: 0.0000(0.0144) Grad: 210.0599  LR: 0.000017  \n","Epoch: [1][8300/36908] Elapsed 68m 51s (remain 237m 18s) Loss: 0.0018(0.0143) Grad: 11048.3906  LR: 0.000017  \n","Epoch: [1][8400/36908] Elapsed 69m 41s (remain 236m 27s) Loss: 0.0000(0.0142) Grad: 35.1784  LR: 0.000017  \n","Epoch: [1][8500/36908] Elapsed 70m 30s (remain 235m 36s) Loss: 0.0000(0.0140) Grad: 154.8580  LR: 0.000017  \n","Epoch: [1][8600/36908] Elapsed 71m 20s (remain 234m 46s) Loss: 0.0106(0.0139) Grad: 19877.3223  LR: 0.000017  \n","Epoch: [1][8700/36908] Elapsed 72m 9s (remain 233m 55s) Loss: 0.0000(0.0138) Grad: 545.4795  LR: 0.000017  \n","Epoch: [1][8800/36908] Elapsed 72m 59s (remain 233m 6s) Loss: 0.0000(0.0136) Grad: 16.3983  LR: 0.000017  \n","Epoch: [1][8900/36908] Elapsed 73m 49s (remain 232m 16s) Loss: 0.0027(0.0135) Grad: 8054.2324  LR: 0.000017  \n","Epoch: [1][9000/36908] Elapsed 74m 38s (remain 231m 26s) Loss: 0.0014(0.0134) Grad: 5888.6421  LR: 0.000017  \n","Epoch: [1][9100/36908] Elapsed 75m 28s (remain 230m 35s) Loss: 0.0016(0.0132) Grad: 4134.8945  LR: 0.000017  \n","Epoch: [1][9200/36908] Elapsed 76m 17s (remain 229m 44s) Loss: 0.0000(0.0131) Grad: 193.4045  LR: 0.000017  \n","Epoch: [1][9300/36908] Elapsed 77m 7s (remain 228m 54s) Loss: 0.0000(0.0130) Grad: 257.3327  LR: 0.000017  \n","Epoch: [1][9400/36908] Elapsed 77m 56s (remain 228m 3s) Loss: 0.0001(0.0129) Grad: 592.6483  LR: 0.000017  \n","Epoch: [1][9500/36908] Elapsed 78m 46s (remain 227m 14s) Loss: 0.0001(0.0128) Grad: 788.2738  LR: 0.000017  \n","Epoch: [1][9600/36908] Elapsed 79m 36s (remain 226m 24s) Loss: 0.0000(0.0127) Grad: 412.5499  LR: 0.000016  \n","Epoch: [1][9700/36908] Elapsed 80m 25s (remain 225m 34s) Loss: 0.0000(0.0126) Grad: 65.3377  LR: 0.000016  \n","Epoch: [1][9800/36908] Elapsed 81m 15s (remain 224m 44s) Loss: 0.0000(0.0125) Grad: 46.2666  LR: 0.000016  \n","Epoch: [1][9900/36908] Elapsed 82m 5s (remain 223m 54s) Loss: 0.0000(0.0124) Grad: 21.8069  LR: 0.000016  \n","Epoch: [1][10000/36908] Elapsed 82m 55s (remain 223m 4s) Loss: 0.0047(0.0123) Grad: 22625.5059  LR: 0.000016  \n","Epoch: [1][10100/36908] Elapsed 83m 44s (remain 222m 14s) Loss: 0.0011(0.0122) Grad: 2666.9294  LR: 0.000016  \n","Epoch: [1][10200/36908] Elapsed 84m 34s (remain 221m 25s) Loss: 0.0000(0.0121) Grad: 27.3315  LR: 0.000016  \n","Epoch: [1][10300/36908] Elapsed 85m 24s (remain 220m 35s) Loss: 0.0000(0.0120) Grad: 35.8429  LR: 0.000016  \n","Epoch: [1][10400/36908] Elapsed 86m 13s (remain 219m 44s) Loss: 0.0005(0.0119) Grad: 3091.2734  LR: 0.000016  \n","Epoch: [1][10500/36908] Elapsed 87m 3s (remain 218m 54s) Loss: 0.0000(0.0118) Grad: 113.9361  LR: 0.000016  \n","Epoch: [1][10600/36908] Elapsed 87m 52s (remain 218m 3s) Loss: 0.0001(0.0117) Grad: 690.5771  LR: 0.000016  \n","Epoch: [1][10700/36908] Elapsed 88m 41s (remain 217m 12s) Loss: 0.0027(0.0116) Grad: 10650.9512  LR: 0.000016  \n","Epoch: [1][10800/36908] Elapsed 89m 31s (remain 216m 22s) Loss: 0.0000(0.0115) Grad: 29.9630  LR: 0.000016  \n","Epoch: [1][10900/36908] Elapsed 90m 20s (remain 215m 32s) Loss: 0.0030(0.0115) Grad: 6059.3628  LR: 0.000016  \n","Epoch: [1][11000/36908] Elapsed 91m 10s (remain 214m 43s) Loss: 0.0008(0.0114) Grad: 5555.7651  LR: 0.000016  \n","Epoch: [1][11100/36908] Elapsed 92m 0s (remain 213m 53s) Loss: 0.0006(0.0113) Grad: 2198.9436  LR: 0.000016  \n","Epoch: [1][11200/36908] Elapsed 92m 50s (remain 213m 4s) Loss: 0.0106(0.0112) Grad: 17413.9473  LR: 0.000015  \n","Epoch: [1][11300/36908] Elapsed 93m 40s (remain 212m 14s) Loss: 0.0000(0.0112) Grad: 63.8376  LR: 0.000015  \n","Epoch: [1][11400/36908] Elapsed 94m 30s (remain 211m 25s) Loss: 0.0001(0.0111) Grad: 677.8684  LR: 0.000015  \n","Epoch: [1][11500/36908] Elapsed 95m 19s (remain 210m 35s) Loss: 0.0000(0.0110) Grad: 115.9580  LR: 0.000015  \n","Epoch: [1][11600/36908] Elapsed 96m 8s (remain 209m 44s) Loss: 0.0000(0.0109) Grad: 156.2622  LR: 0.000015  \n","Epoch: [1][11700/36908] Elapsed 96m 58s (remain 208m 54s) Loss: 0.0001(0.0108) Grad: 796.4074  LR: 0.000015  \n","Epoch: [1][11800/36908] Elapsed 97m 48s (remain 208m 4s) Loss: 0.0006(0.0108) Grad: 3828.4856  LR: 0.000015  \n","Epoch: [1][11900/36908] Elapsed 98m 37s (remain 207m 14s) Loss: 0.0008(0.0107) Grad: 4799.5664  LR: 0.000015  \n","Epoch: [1][12000/36908] Elapsed 99m 27s (remain 206m 24s) Loss: 0.0078(0.0107) Grad: 29784.0703  LR: 0.000015  \n","Epoch: [1][12100/36908] Elapsed 100m 17s (remain 205m 34s) Loss: 0.0000(0.0106) Grad: 95.4249  LR: 0.000015  \n","Epoch: [1][12200/36908] Elapsed 101m 7s (remain 204m 46s) Loss: 0.0000(0.0105) Grad: 214.9762  LR: 0.000015  \n","Epoch: [1][12300/36908] Elapsed 101m 58s (remain 204m 0s) Loss: 0.0012(0.0105) Grad: 11770.6152  LR: 0.000015  \n","Epoch: [1][12400/36908] Elapsed 102m 49s (remain 203m 11s) Loss: 0.0136(0.0104) Grad: 29701.7207  LR: 0.000015  \n","Epoch: [1][12500/36908] Elapsed 103m 38s (remain 202m 21s) Loss: 0.0000(0.0103) Grad: 54.2780  LR: 0.000015  \n","Epoch: [1][12600/36908] Elapsed 104m 28s (remain 201m 31s) Loss: 0.0007(0.0103) Grad: 10425.0908  LR: 0.000015  \n","Epoch: [1][12700/36908] Elapsed 105m 18s (remain 200m 41s) Loss: 0.0015(0.0102) Grad: 17460.6406  LR: 0.000015  \n","Epoch: [1][12800/36908] Elapsed 106m 7s (remain 199m 51s) Loss: 0.0001(0.0102) Grad: 2200.7041  LR: 0.000015  \n","Epoch: [1][12900/36908] Elapsed 106m 57s (remain 199m 1s) Loss: 0.0000(0.0101) Grad: 42.9835  LR: 0.000014  \n","Epoch: [1][13000/36908] Elapsed 107m 46s (remain 198m 11s) Loss: 0.0000(0.0101) Grad: 642.8774  LR: 0.000014  \n","Epoch: [1][13100/36908] Elapsed 108m 36s (remain 197m 21s) Loss: 0.0017(0.0100) Grad: 21585.8613  LR: 0.000014  \n","Epoch: [1][13200/36908] Elapsed 109m 26s (remain 196m 32s) Loss: 0.0007(0.0099) Grad: 10414.3418  LR: 0.000014  \n","Epoch: [1][13300/36908] Elapsed 110m 16s (remain 195m 43s) Loss: 0.0003(0.0099) Grad: 2908.3745  LR: 0.000014  \n","Epoch: [1][13400/36908] Elapsed 111m 6s (remain 194m 53s) Loss: 0.0066(0.0098) Grad: 59465.2148  LR: 0.000014  \n","Epoch: [1][13500/36908] Elapsed 111m 55s (remain 194m 3s) Loss: 0.0000(0.0098) Grad: 58.6481  LR: 0.000014  \n","Epoch: [1][13600/36908] Elapsed 112m 45s (remain 193m 13s) Loss: 0.0000(0.0097) Grad: 63.1971  LR: 0.000014  \n","Epoch: [1][13700/36908] Elapsed 113m 35s (remain 192m 23s) Loss: 0.0002(0.0097) Grad: 3650.7876  LR: 0.000014  \n","Epoch: [1][13800/36908] Elapsed 114m 24s (remain 191m 33s) Loss: 0.0040(0.0096) Grad: 15701.2686  LR: 0.000014  \n","Epoch: [1][13900/36908] Elapsed 115m 13s (remain 190m 43s) Loss: 0.0000(0.0095) Grad: 193.4522  LR: 0.000014  \n","Epoch: [1][14000/36908] Elapsed 116m 3s (remain 189m 52s) Loss: 0.0000(0.0095) Grad: 109.7263  LR: 0.000014  \n","Epoch: [1][14100/36908] Elapsed 116m 53s (remain 189m 3s) Loss: 0.0023(0.0094) Grad: 12902.9766  LR: 0.000014  \n","Epoch: [1][14200/36908] Elapsed 117m 43s (remain 188m 14s) Loss: 0.0004(0.0094) Grad: 3151.1531  LR: 0.000014  \n","Epoch: [1][14300/36908] Elapsed 118m 33s (remain 187m 24s) Loss: 0.0000(0.0094) Grad: 61.9595  LR: 0.000014  \n","Epoch: [1][14400/36908] Elapsed 119m 23s (remain 186m 35s) Loss: 0.0000(0.0093) Grad: 721.6918  LR: 0.000014  \n","Epoch: [1][14500/36908] Elapsed 120m 13s (remain 185m 46s) Loss: 0.0000(0.0093) Grad: 135.9087  LR: 0.000013  \n","Epoch: [1][14600/36908] Elapsed 121m 3s (remain 184m 57s) Loss: 0.0147(0.0092) Grad: 66663.1875  LR: 0.000013  \n","Epoch: [1][14700/36908] Elapsed 121m 53s (remain 184m 7s) Loss: 0.0014(0.0092) Grad: 20681.1055  LR: 0.000013  \n","Epoch: [1][14800/36908] Elapsed 122m 43s (remain 183m 18s) Loss: 0.0000(0.0091) Grad: 333.9262  LR: 0.000013  \n","Epoch: [1][14900/36908] Elapsed 123m 32s (remain 182m 27s) Loss: 0.0000(0.0091) Grad: 520.7998  LR: 0.000013  \n","Epoch: [1][15000/36908] Elapsed 124m 22s (remain 181m 37s) Loss: 0.0114(0.0090) Grad: 39489.2070  LR: 0.000013  \n","Epoch: [1][15100/36908] Elapsed 125m 12s (remain 180m 47s) Loss: 0.0000(0.0090) Grad: 586.4159  LR: 0.000013  \n","Epoch: [1][15200/36908] Elapsed 126m 1s (remain 179m 57s) Loss: 0.0000(0.0089) Grad: 11.0384  LR: 0.000013  \n","Epoch: [1][15300/36908] Elapsed 126m 52s (remain 179m 9s) Loss: 0.0082(0.0089) Grad: 49460.1445  LR: 0.000013  \n","Epoch: [1][15400/36908] Elapsed 127m 42s (remain 178m 20s) Loss: 0.0017(0.0089) Grad: 20338.6973  LR: 0.000013  \n","Epoch: [1][15500/36908] Elapsed 128m 31s (remain 177m 29s) Loss: 0.0000(0.0088) Grad: 208.2304  LR: 0.000013  \n","Epoch: [1][15600/36908] Elapsed 129m 21s (remain 176m 39s) Loss: 0.0000(0.0088) Grad: 300.3404  LR: 0.000013  \n","Epoch: [1][15700/36908] Elapsed 130m 10s (remain 175m 49s) Loss: 0.0000(0.0087) Grad: 299.4398  LR: 0.000013  \n","Epoch: [1][15800/36908] Elapsed 131m 0s (remain 174m 59s) Loss: 0.0043(0.0087) Grad: 20472.8711  LR: 0.000013  \n","Epoch: [1][15900/36908] Elapsed 131m 50s (remain 174m 10s) Loss: 0.0090(0.0087) Grad: 44526.8359  LR: 0.000013  \n","Epoch: [1][16000/36908] Elapsed 132m 39s (remain 173m 20s) Loss: 0.0002(0.0086) Grad: 4827.8145  LR: 0.000013  \n","Epoch: [1][16100/36908] Elapsed 133m 29s (remain 172m 30s) Loss: 0.0000(0.0086) Grad: 1665.4637  LR: 0.000013  \n","Epoch: [1][16200/36908] Elapsed 134m 18s (remain 171m 40s) Loss: 0.0004(0.0086) Grad: 10157.1094  LR: 0.000012  \n","Epoch: [1][16300/36908] Elapsed 135m 8s (remain 170m 50s) Loss: 0.0005(0.0085) Grad: 14847.9707  LR: 0.000012  \n","Epoch: [1][16400/36908] Elapsed 135m 57s (remain 169m 59s) Loss: 0.0024(0.0085) Grad: 55585.9336  LR: 0.000012  \n","Epoch: [1][16500/36908] Elapsed 136m 46s (remain 169m 9s) Loss: 0.0000(0.0085) Grad: 8.1711  LR: 0.000012  \n","Epoch: [1][16600/36908] Elapsed 137m 36s (remain 168m 19s) Loss: 0.0300(0.0084) Grad: 120426.2969  LR: 0.000012  \n","Epoch: [1][16700/36908] Elapsed 138m 25s (remain 167m 28s) Loss: 0.0002(0.0084) Grad: 8108.6465  LR: 0.000012  \n","Epoch: [1][16800/36908] Elapsed 139m 14s (remain 166m 38s) Loss: 0.0409(0.0084) Grad: 233903.5625  LR: 0.000012  \n","Epoch: [1][16900/36908] Elapsed 140m 4s (remain 165m 49s) Loss: 0.0001(0.0083) Grad: 4771.4360  LR: 0.000012  \n","Epoch: [1][17000/36908] Elapsed 140m 54s (remain 164m 59s) Loss: 0.0024(0.0083) Grad: 56155.3711  LR: 0.000012  \n","Epoch: [1][17100/36908] Elapsed 141m 44s (remain 164m 10s) Loss: 0.0002(0.0083) Grad: 6749.7720  LR: 0.000012  \n","Epoch: [1][17200/36908] Elapsed 142m 34s (remain 163m 20s) Loss: 0.0003(0.0082) Grad: 11106.8848  LR: 0.000012  \n","Epoch: [1][17300/36908] Elapsed 143m 24s (remain 162m 30s) Loss: 0.0001(0.0082) Grad: 5607.1699  LR: 0.000012  \n","Epoch: [1][17400/36908] Elapsed 144m 13s (remain 161m 41s) Loss: 0.0011(0.0082) Grad: 10628.7617  LR: 0.000012  \n","Epoch: [1][17500/36908] Elapsed 145m 3s (remain 160m 51s) Loss: 0.0080(0.0081) Grad: 87867.9297  LR: 0.000012  \n","Epoch: [1][17600/36908] Elapsed 145m 53s (remain 160m 1s) Loss: 0.0256(0.0081) Grad: 168204.5000  LR: 0.000012  \n","Epoch: [1][17700/36908] Elapsed 146m 42s (remain 159m 11s) Loss: 0.0003(0.0081) Grad: 9133.1182  LR: 0.000012  \n","Epoch: [1][17800/36908] Elapsed 147m 32s (remain 158m 21s) Loss: 0.0000(0.0080) Grad: 22.3361  LR: 0.000012  \n","Epoch: [1][17900/36908] Elapsed 148m 22s (remain 157m 32s) Loss: 0.0000(0.0080) Grad: 82.2557  LR: 0.000011  \n","Epoch: [1][18000/36908] Elapsed 149m 11s (remain 156m 42s) Loss: 0.0000(0.0080) Grad: 1509.1476  LR: 0.000011  \n","Epoch: [1][18100/36908] Elapsed 150m 1s (remain 155m 52s) Loss: 0.0041(0.0079) Grad: 33401.5664  LR: 0.000011  \n","Epoch: [1][18200/36908] Elapsed 150m 51s (remain 155m 2s) Loss: 0.0431(0.0079) Grad: 175665.3281  LR: 0.000011  \n","Epoch: [1][18300/36908] Elapsed 151m 41s (remain 154m 13s) Loss: 0.0000(0.0079) Grad: 241.0965  LR: 0.000011  \n","Epoch: [1][18400/36908] Elapsed 152m 30s (remain 153m 23s) Loss: 0.0000(0.0079) Grad: 25.6963  LR: 0.000011  \n","Epoch: [1][18500/36908] Elapsed 153m 20s (remain 152m 33s) Loss: 0.0001(0.0078) Grad: 5894.8643  LR: 0.000011  \n","Epoch: [1][18600/36908] Elapsed 154m 9s (remain 151m 43s) Loss: 0.0000(0.0078) Grad: 1389.3212  LR: 0.000011  \n","Epoch: [1][18700/36908] Elapsed 154m 59s (remain 150m 53s) Loss: 0.0028(0.0078) Grad: 42727.1289  LR: 0.000011  \n","Epoch: [1][18800/36908] Elapsed 155m 48s (remain 150m 3s) Loss: 0.0000(0.0078) Grad: 164.2891  LR: 0.000011  \n","Epoch: [1][18900/36908] Elapsed 156m 38s (remain 149m 13s) Loss: 0.0008(0.0077) Grad: 9733.0127  LR: 0.000011  \n","Epoch: [1][19000/36908] Elapsed 157m 27s (remain 148m 23s) Loss: 0.0042(0.0077) Grad: 87807.4375  LR: 0.000011  \n","Epoch: [1][19100/36908] Elapsed 158m 17s (remain 147m 33s) Loss: 0.0001(0.0077) Grad: 2385.6042  LR: 0.000011  \n","Epoch: [1][19200/36908] Elapsed 159m 6s (remain 146m 43s) Loss: 0.0003(0.0076) Grad: 11680.7490  LR: 0.000011  \n","Epoch: [1][19300/36908] Elapsed 159m 55s (remain 145m 53s) Loss: 0.0001(0.0076) Grad: 3362.9465  LR: 0.000011  \n","Epoch: [1][19400/36908] Elapsed 160m 45s (remain 145m 3s) Loss: 0.0004(0.0076) Grad: 9069.1357  LR: 0.000011  \n","Epoch: [1][19500/36908] Elapsed 161m 34s (remain 144m 13s) Loss: 0.0068(0.0076) Grad: 100281.6094  LR: 0.000010  \n","Epoch: [1][19600/36908] Elapsed 162m 23s (remain 143m 23s) Loss: 0.0055(0.0075) Grad: 52664.9492  LR: 0.000010  \n","Epoch: [1][19700/36908] Elapsed 163m 12s (remain 142m 33s) Loss: 0.0000(0.0075) Grad: 966.3358  LR: 0.000010  \n","Epoch: [1][19800/36908] Elapsed 164m 2s (remain 141m 43s) Loss: 0.0000(0.0075) Grad: 29.9385  LR: 0.000010  \n","Epoch: [1][19900/36908] Elapsed 164m 51s (remain 140m 53s) Loss: 0.0014(0.0075) Grad: 18532.6465  LR: 0.000010  \n","Epoch: [1][20000/36908] Elapsed 165m 40s (remain 140m 3s) Loss: 0.0000(0.0075) Grad: 19.1899  LR: 0.000010  \n","Epoch: [1][20100/36908] Elapsed 166m 30s (remain 139m 13s) Loss: 0.0000(0.0074) Grad: 102.3821  LR: 0.000010  \n","Epoch: [1][20200/36908] Elapsed 167m 19s (remain 138m 23s) Loss: 0.0003(0.0074) Grad: 9487.5967  LR: 0.000010  \n","Epoch: [1][20300/36908] Elapsed 168m 8s (remain 137m 33s) Loss: 0.0000(0.0074) Grad: 94.1439  LR: 0.000010  \n","Epoch: [1][20400/36908] Elapsed 168m 58s (remain 136m 43s) Loss: 0.0001(0.0074) Grad: 8357.7686  LR: 0.000010  \n","Epoch: [1][20500/36908] Elapsed 169m 47s (remain 135m 53s) Loss: 0.0000(0.0073) Grad: 49.2589  LR: 0.000010  \n","Epoch: [1][20600/36908] Elapsed 170m 36s (remain 135m 3s) Loss: 0.0000(0.0073) Grad: 713.9681  LR: 0.000010  \n","Epoch: [1][20700/36908] Elapsed 171m 26s (remain 134m 13s) Loss: 0.0020(0.0073) Grad: 51210.1133  LR: 0.000010  \n","Epoch: [1][20800/36908] Elapsed 172m 15s (remain 133m 22s) Loss: 0.0000(0.0073) Grad: 161.9245  LR: 0.000010  \n","Epoch: [1][20900/36908] Elapsed 173m 4s (remain 132m 32s) Loss: 0.0010(0.0073) Grad: 59930.4531  LR: 0.000010  \n","Epoch: [1][21000/36908] Elapsed 173m 53s (remain 131m 42s) Loss: 0.0004(0.0072) Grad: 22019.4395  LR: 0.000010  \n","Epoch: [1][21100/36908] Elapsed 174m 42s (remain 130m 52s) Loss: 0.0000(0.0072) Grad: 30.6203  LR: 0.000010  \n","Epoch: [1][21200/36908] Elapsed 175m 31s (remain 130m 2s) Loss: 0.0046(0.0072) Grad: 152805.4688  LR: 0.000009  \n","Epoch: [1][21300/36908] Elapsed 176m 20s (remain 129m 12s) Loss: 0.0000(0.0072) Grad: 833.1996  LR: 0.000009  \n","Epoch: [1][21400/36908] Elapsed 177m 10s (remain 128m 22s) Loss: 0.0024(0.0072) Grad: 96808.0469  LR: 0.000009  \n","Epoch: [1][21500/36908] Elapsed 177m 59s (remain 127m 32s) Loss: 0.0038(0.0071) Grad: 135779.2188  LR: 0.000009  \n","Epoch: [1][21600/36908] Elapsed 178m 48s (remain 126m 42s) Loss: 0.0000(0.0071) Grad: 87.4801  LR: 0.000009  \n","Epoch: [1][21700/36908] Elapsed 179m 37s (remain 125m 52s) Loss: 0.0000(0.0071) Grad: 48.8680  LR: 0.000009  \n","Epoch: [1][21800/36908] Elapsed 180m 27s (remain 125m 2s) Loss: 0.0001(0.0071) Grad: 6178.1147  LR: 0.000009  \n","Epoch: [1][21900/36908] Elapsed 181m 16s (remain 124m 12s) Loss: 0.0001(0.0071) Grad: 9713.5957  LR: 0.000009  \n","Epoch: [1][22000/36908] Elapsed 182m 5s (remain 123m 22s) Loss: 0.0000(0.0070) Grad: 317.4580  LR: 0.000009  \n","Epoch: [1][22100/36908] Elapsed 182m 55s (remain 122m 33s) Loss: 0.0000(0.0070) Grad: 2000.5228  LR: 0.000009  \n","Epoch: [1][22200/36908] Elapsed 183m 45s (remain 121m 43s) Loss: 0.0005(0.0070) Grad: 20221.2148  LR: 0.000009  \n","Epoch: [1][22300/36908] Elapsed 184m 34s (remain 120m 53s) Loss: 0.0036(0.0070) Grad: 63964.5234  LR: 0.000009  \n","Epoch: [1][22400/36908] Elapsed 185m 24s (remain 120m 4s) Loss: 0.0044(0.0070) Grad: 134559.4062  LR: 0.000009  \n","Epoch: [1][22500/36908] Elapsed 186m 14s (remain 119m 14s) Loss: 0.0000(0.0070) Grad: 19.3140  LR: 0.000009  \n","Epoch: [1][22600/36908] Elapsed 187m 4s (remain 118m 25s) Loss: 0.0000(0.0069) Grad: 53.1536  LR: 0.000009  \n","Epoch: [1][22700/36908] Elapsed 187m 53s (remain 117m 35s) Loss: 0.0000(0.0069) Grad: 434.5872  LR: 0.000009  \n","Epoch: [1][22800/36908] Elapsed 188m 42s (remain 116m 45s) Loss: 0.0433(0.0069) Grad: 214735.0938  LR: 0.000008  \n","Epoch: [1][22900/36908] Elapsed 189m 32s (remain 115m 55s) Loss: 0.0000(0.0069) Grad: 144.8306  LR: 0.000008  \n","Epoch: [1][23000/36908] Elapsed 190m 21s (remain 115m 5s) Loss: 0.0002(0.0069) Grad: 12749.8994  LR: 0.000008  \n","Epoch: [1][23100/36908] Elapsed 191m 11s (remain 114m 16s) Loss: 0.0000(0.0069) Grad: 526.8203  LR: 0.000008  \n","Epoch: [1][23200/36908] Elapsed 192m 1s (remain 113m 27s) Loss: 0.0000(0.0068) Grad: 109.8817  LR: 0.000008  \n","Epoch: [1][23300/36908] Elapsed 192m 51s (remain 112m 37s) Loss: 0.0000(0.0068) Grad: 25.3021  LR: 0.000008  \n","Epoch: [1][23400/36908] Elapsed 193m 41s (remain 111m 47s) Loss: 0.0000(0.0068) Grad: 61.6716  LR: 0.000008  \n","Epoch: [1][23500/36908] Elapsed 194m 31s (remain 110m 58s) Loss: 0.0000(0.0068) Grad: 798.0005  LR: 0.000008  \n","Epoch: [1][23600/36908] Elapsed 195m 21s (remain 110m 8s) Loss: 0.0000(0.0068) Grad: 29.3872  LR: 0.000008  \n","Epoch: [1][23700/36908] Elapsed 196m 11s (remain 109m 19s) Loss: 0.0105(0.0067) Grad: 166307.3125  LR: 0.000008  \n","Epoch: [1][23800/36908] Elapsed 197m 0s (remain 108m 29s) Loss: 0.0029(0.0067) Grad: 74196.5391  LR: 0.000008  \n","Epoch: [1][23900/36908] Elapsed 197m 51s (remain 107m 40s) Loss: 0.0000(0.0067) Grad: 379.0656  LR: 0.000008  \n","Epoch: [1][24000/36908] Elapsed 198m 41s (remain 106m 50s) Loss: 0.0000(0.0067) Grad: 505.3000  LR: 0.000008  \n","Epoch: [1][24100/36908] Elapsed 199m 31s (remain 106m 1s) Loss: 0.0000(0.0067) Grad: 236.8060  LR: 0.000008  \n","Epoch: [1][24200/36908] Elapsed 200m 21s (remain 105m 11s) Loss: 0.0000(0.0066) Grad: 136.8869  LR: 0.000008  \n","Epoch: [1][24300/36908] Elapsed 201m 11s (remain 104m 22s) Loss: 0.0000(0.0066) Grad: 1695.8535  LR: 0.000008  \n","Epoch: [1][24400/36908] Elapsed 202m 1s (remain 103m 32s) Loss: 0.0000(0.0066) Grad: 85.8017  LR: 0.000008  \n","Epoch: [1][24500/36908] Elapsed 202m 51s (remain 102m 43s) Loss: 0.0000(0.0066) Grad: 3604.1848  LR: 0.000007  \n","Epoch: [1][24600/36908] Elapsed 203m 41s (remain 101m 53s) Loss: 0.0080(0.0066) Grad: 495435.4375  LR: 0.000007  \n","Epoch: [1][24700/36908] Elapsed 204m 31s (remain 101m 4s) Loss: 0.0000(0.0066) Grad: 132.2140  LR: 0.000007  \n","Epoch: [1][24800/36908] Elapsed 205m 20s (remain 100m 14s) Loss: 0.0002(0.0066) Grad: 21024.3359  LR: 0.000007  \n","Epoch: [1][24900/36908] Elapsed 206m 10s (remain 99m 24s) Loss: 0.0008(0.0065) Grad: 62433.7617  LR: 0.000007  \n","Epoch: [1][25000/36908] Elapsed 207m 0s (remain 98m 35s) Loss: 0.0000(0.0065) Grad: 475.0762  LR: 0.000007  \n","Epoch: [1][25100/36908] Elapsed 207m 50s (remain 97m 45s) Loss: 0.0045(0.0065) Grad: 49390.9648  LR: 0.000007  \n","Epoch: [1][25200/36908] Elapsed 208m 40s (remain 96m 56s) Loss: 0.0000(0.0065) Grad: 422.0089  LR: 0.000007  \n","Epoch: [1][25300/36908] Elapsed 209m 30s (remain 96m 6s) Loss: 0.0000(0.0065) Grad: 107.8709  LR: 0.000007  \n","Epoch: [1][25400/36908] Elapsed 210m 20s (remain 95m 17s) Loss: 0.0000(0.0065) Grad: 67.8695  LR: 0.000007  \n","Epoch: [1][25500/36908] Elapsed 211m 10s (remain 94m 27s) Loss: 0.0000(0.0065) Grad: 1556.5607  LR: 0.000007  \n","Epoch: [1][25600/36908] Elapsed 212m 0s (remain 93m 38s) Loss: 0.0013(0.0064) Grad: 74628.3594  LR: 0.000007  \n","Epoch: [1][25700/36908] Elapsed 212m 50s (remain 92m 48s) Loss: 0.0000(0.0064) Grad: 4069.3452  LR: 0.000007  \n","Epoch: [1][25800/36908] Elapsed 213m 40s (remain 91m 58s) Loss: 0.0022(0.0064) Grad: 64615.6719  LR: 0.000007  \n","Epoch: [1][25900/36908] Elapsed 214m 30s (remain 91m 9s) Loss: 0.0000(0.0064) Grad: 54.5580  LR: 0.000007  \n","Epoch: [1][26000/36908] Elapsed 215m 20s (remain 90m 19s) Loss: 0.0000(0.0064) Grad: 79.9331  LR: 0.000007  \n","Epoch: [1][26100/36908] Elapsed 216m 9s (remain 89m 30s) Loss: 0.0000(0.0064) Grad: 233.6375  LR: 0.000007  \n","Epoch: [1][26200/36908] Elapsed 217m 0s (remain 88m 40s) Loss: 0.0000(0.0064) Grad: 216.2648  LR: 0.000006  \n","Epoch: [1][26300/36908] Elapsed 217m 50s (remain 87m 51s) Loss: 0.0008(0.0063) Grad: 54326.2852  LR: 0.000006  \n","Epoch: [1][26400/36908] Elapsed 218m 40s (remain 87m 1s) Loss: 0.0000(0.0063) Grad: 25.6310  LR: 0.000006  \n","Epoch: [1][26500/36908] Elapsed 219m 30s (remain 86m 11s) Loss: 0.0011(0.0063) Grad: 71836.1797  LR: 0.000006  \n","Epoch: [1][26600/36908] Elapsed 220m 20s (remain 85m 22s) Loss: 0.0035(0.0063) Grad: 49640.4727  LR: 0.000006  \n","Epoch: [1][26700/36908] Elapsed 221m 10s (remain 84m 32s) Loss: 0.0000(0.0063) Grad: 22.3720  LR: 0.000006  \n","Epoch: [1][26800/36908] Elapsed 222m 0s (remain 83m 43s) Loss: 0.0000(0.0063) Grad: 286.6368  LR: 0.000006  \n","Epoch: [1][26900/36908] Elapsed 222m 50s (remain 82m 53s) Loss: 0.0000(0.0063) Grad: 3505.3491  LR: 0.000006  \n","Epoch: [1][27000/36908] Elapsed 223m 41s (remain 82m 4s) Loss: 0.0000(0.0062) Grad: 1448.1444  LR: 0.000006  \n","Epoch: [1][27100/36908] Elapsed 224m 32s (remain 81m 15s) Loss: 0.0000(0.0062) Grad: 993.7595  LR: 0.000006  \n","Epoch: [1][27200/36908] Elapsed 225m 22s (remain 80m 25s) Loss: 0.0000(0.0062) Grad: 611.2024  LR: 0.000006  \n","Epoch: [1][27300/36908] Elapsed 226m 12s (remain 79m 35s) Loss: 0.0137(0.0062) Grad: 197818.2500  LR: 0.000006  \n","Epoch: [1][27400/36908] Elapsed 227m 2s (remain 78m 46s) Loss: 0.0000(0.0062) Grad: 27.5070  LR: 0.000006  \n","Epoch: [1][27500/36908] Elapsed 227m 51s (remain 77m 56s) Loss: 0.0000(0.0062) Grad: 1180.6049  LR: 0.000006  \n","Epoch: [1][27600/36908] Elapsed 228m 40s (remain 77m 6s) Loss: 0.0001(0.0062) Grad: 2309.4614  LR: 0.000006  \n","Epoch: [1][27700/36908] Elapsed 229m 30s (remain 76m 16s) Loss: 0.0043(0.0062) Grad: 80160.6719  LR: 0.000006  \n","Epoch: [1][27800/36908] Elapsed 230m 20s (remain 75m 27s) Loss: 0.0000(0.0062) Grad: 385.5574  LR: 0.000005  \n","Epoch: [1][27900/36908] Elapsed 231m 9s (remain 74m 37s) Loss: 0.0005(0.0061) Grad: 26565.4844  LR: 0.000005  \n","Epoch: [1][28000/36908] Elapsed 232m 0s (remain 73m 47s) Loss: 0.0000(0.0061) Grad: 3263.5676  LR: 0.000005  \n","Epoch: [1][28100/36908] Elapsed 232m 50s (remain 72m 58s) Loss: 0.0001(0.0061) Grad: 9048.8359  LR: 0.000005  \n","Epoch: [1][28200/36908] Elapsed 233m 39s (remain 72m 8s) Loss: 0.0000(0.0061) Grad: 69.0067  LR: 0.000005  \n","Epoch: [1][28300/36908] Elapsed 234m 29s (remain 71m 18s) Loss: 0.0055(0.0061) Grad: 79286.5781  LR: 0.000005  \n","Epoch: [1][28400/36908] Elapsed 235m 18s (remain 70m 29s) Loss: 0.0000(0.0061) Grad: 1336.1458  LR: 0.000005  \n","Epoch: [1][28500/36908] Elapsed 236m 8s (remain 69m 39s) Loss: 0.0001(0.0061) Grad: 11222.6006  LR: 0.000005  \n","Epoch: [1][28600/36908] Elapsed 236m 58s (remain 68m 49s) Loss: 0.0006(0.0061) Grad: 17181.1367  LR: 0.000005  \n","Epoch: [1][28700/36908] Elapsed 237m 47s (remain 67m 59s) Loss: 0.0000(0.0060) Grad: 22.9737  LR: 0.000005  \n","Epoch: [1][28800/36908] Elapsed 238m 37s (remain 67m 10s) Loss: 0.0000(0.0060) Grad: 61.1542  LR: 0.000005  \n","Epoch: [1][28900/36908] Elapsed 239m 27s (remain 66m 20s) Loss: 0.0059(0.0060) Grad: 179593.6875  LR: 0.000005  \n","Epoch: [1][29000/36908] Elapsed 240m 16s (remain 65m 30s) Loss: 0.0001(0.0060) Grad: 13254.9150  LR: 0.000005  \n","Epoch: [1][29100/36908] Elapsed 241m 6s (remain 64m 40s) Loss: 0.0000(0.0060) Grad: 3806.8347  LR: 0.000005  \n","Epoch: [1][29200/36908] Elapsed 241m 56s (remain 63m 51s) Loss: 0.0000(0.0060) Grad: 551.8600  LR: 0.000005  \n","Epoch: [1][29300/36908] Elapsed 242m 45s (remain 63m 1s) Loss: 0.0001(0.0060) Grad: 12846.7148  LR: 0.000005  \n","Epoch: [1][29400/36908] Elapsed 243m 35s (remain 62m 11s) Loss: 0.0000(0.0060) Grad: 1259.8800  LR: 0.000005  \n","Epoch: [1][29500/36908] Elapsed 244m 24s (remain 61m 21s) Loss: 0.0000(0.0060) Grad: 2522.6221  LR: 0.000004  \n","Epoch: [1][29600/36908] Elapsed 245m 14s (remain 60m 32s) Loss: 0.0003(0.0059) Grad: 17412.1523  LR: 0.000004  \n","Epoch: [1][29700/36908] Elapsed 246m 3s (remain 59m 42s) Loss: 0.0000(0.0059) Grad: 191.0297  LR: 0.000004  \n","Epoch: [1][29800/36908] Elapsed 246m 53s (remain 58m 52s) Loss: 0.0000(0.0059) Grad: 173.5317  LR: 0.000004  \n","Epoch: [1][29900/36908] Elapsed 247m 43s (remain 58m 3s) Loss: 0.0000(0.0059) Grad: 1736.2495  LR: 0.000004  \n","Epoch: [1][30000/36908] Elapsed 248m 33s (remain 57m 13s) Loss: 0.0521(0.0059) Grad: 382878.7812  LR: 0.000004  \n","Epoch: [1][30100/36908] Elapsed 249m 23s (remain 56m 23s) Loss: 0.0013(0.0059) Grad: 64305.0273  LR: 0.000004  \n","Epoch: [1][30200/36908] Elapsed 250m 13s (remain 55m 34s) Loss: 0.0014(0.0059) Grad: 25974.2422  LR: 0.000004  \n","Epoch: [1][30300/36908] Elapsed 251m 3s (remain 54m 44s) Loss: 0.0000(0.0059) Grad: 86.1910  LR: 0.000004  \n","Epoch: [1][30400/36908] Elapsed 251m 54s (remain 53m 55s) Loss: 0.0000(0.0059) Grad: 102.5406  LR: 0.000004  \n","Epoch: [1][30500/36908] Elapsed 252m 44s (remain 53m 5s) Loss: 0.0139(0.0058) Grad: 180246.3906  LR: 0.000004  \n","Epoch: [1][30600/36908] Elapsed 253m 34s (remain 52m 15s) Loss: 0.0000(0.0058) Grad: 715.5849  LR: 0.000004  \n","Epoch: [1][30700/36908] Elapsed 254m 23s (remain 51m 26s) Loss: 0.0000(0.0058) Grad: 855.4039  LR: 0.000004  \n","Epoch: [1][30800/36908] Elapsed 255m 13s (remain 50m 36s) Loss: 0.0000(0.0058) Grad: 73.7359  LR: 0.000004  \n","Epoch: [1][30900/36908] Elapsed 256m 3s (remain 49m 46s) Loss: 0.0025(0.0058) Grad: 93262.2656  LR: 0.000004  \n","Epoch: [1][31000/36908] Elapsed 256m 53s (remain 48m 56s) Loss: 0.0000(0.0058) Grad: 247.9736  LR: 0.000004  \n","Epoch: [1][31100/36908] Elapsed 257m 43s (remain 48m 7s) Loss: 0.0000(0.0058) Grad: 1008.1436  LR: 0.000003  \n","Epoch: [1][31200/36908] Elapsed 258m 32s (remain 47m 17s) Loss: 0.0003(0.0058) Grad: 18362.8984  LR: 0.000003  \n","Epoch: [1][31300/36908] Elapsed 259m 22s (remain 46m 27s) Loss: 0.0034(0.0058) Grad: 44439.3906  LR: 0.000003  \n","Epoch: [1][31400/36908] Elapsed 260m 12s (remain 45m 38s) Loss: 0.0078(0.0058) Grad: 92258.6719  LR: 0.000003  \n","Epoch: [1][31500/36908] Elapsed 261m 2s (remain 44m 48s) Loss: 0.0305(0.0058) Grad: 578643.6250  LR: 0.000003  \n","Epoch: [1][31600/36908] Elapsed 261m 51s (remain 43m 58s) Loss: 0.0000(0.0057) Grad: 78.7421  LR: 0.000003  \n","Epoch: [1][31700/36908] Elapsed 262m 41s (remain 43m 8s) Loss: 0.0000(0.0057) Grad: 38.2987  LR: 0.000003  \n","Epoch: [1][31800/36908] Elapsed 263m 31s (remain 42m 19s) Loss: 0.0000(0.0057) Grad: 117.5608  LR: 0.000003  \n","Epoch: [1][31900/36908] Elapsed 264m 21s (remain 41m 29s) Loss: 0.0005(0.0057) Grad: 19773.6699  LR: 0.000003  \n","Epoch: [1][32000/36908] Elapsed 265m 10s (remain 40m 39s) Loss: 0.0000(0.0057) Grad: 57.7800  LR: 0.000003  \n","Epoch: [1][32100/36908] Elapsed 266m 0s (remain 39m 50s) Loss: 0.0000(0.0057) Grad: 91.4815  LR: 0.000003  \n","Epoch: [1][32200/36908] Elapsed 266m 50s (remain 39m 0s) Loss: 0.0000(0.0057) Grad: 3537.9578  LR: 0.000003  \n","Epoch: [1][32300/36908] Elapsed 267m 40s (remain 38m 10s) Loss: 0.0000(0.0057) Grad: 2138.1943  LR: 0.000003  \n","Epoch: [1][32400/36908] Elapsed 268m 30s (remain 37m 20s) Loss: 0.0001(0.0057) Grad: 7934.8750  LR: 0.000003  \n","Epoch: [1][32500/36908] Elapsed 269m 19s (remain 36m 31s) Loss: 0.0008(0.0056) Grad: 58944.0859  LR: 0.000003  \n","Epoch: [1][32600/36908] Elapsed 270m 9s (remain 35m 41s) Loss: 0.0003(0.0056) Grad: 21478.8711  LR: 0.000003  \n","Epoch: [1][32700/36908] Elapsed 270m 59s (remain 34m 51s) Loss: 0.0000(0.0056) Grad: 67.8973  LR: 0.000003  \n","Epoch: [1][32800/36908] Elapsed 271m 48s (remain 34m 2s) Loss: 0.0003(0.0056) Grad: 25545.0312  LR: 0.000002  \n","Epoch: [1][32900/36908] Elapsed 272m 38s (remain 33m 12s) Loss: 0.0000(0.0056) Grad: 290.2112  LR: 0.000002  \n","Epoch: [1][33000/36908] Elapsed 273m 28s (remain 32m 22s) Loss: 0.0000(0.0056) Grad: 159.3827  LR: 0.000002  \n","Epoch: [1][33100/36908] Elapsed 274m 17s (remain 31m 32s) Loss: 0.0000(0.0056) Grad: 407.6640  LR: 0.000002  \n","Epoch: [1][33200/36908] Elapsed 275m 7s (remain 30m 43s) Loss: 0.0000(0.0056) Grad: 3346.7937  LR: 0.000002  \n","Epoch: [1][33300/36908] Elapsed 275m 56s (remain 29m 53s) Loss: 0.0000(0.0056) Grad: 231.7101  LR: 0.000002  \n","Epoch: [1][33400/36908] Elapsed 276m 46s (remain 29m 3s) Loss: 0.0026(0.0056) Grad: 123871.0391  LR: 0.000002  \n","Epoch: [1][33500/36908] Elapsed 277m 36s (remain 28m 13s) Loss: 0.0015(0.0056) Grad: 56422.1328  LR: 0.000002  \n","Epoch: [1][33600/36908] Elapsed 278m 27s (remain 27m 24s) Loss: 0.0000(0.0055) Grad: 19.2170  LR: 0.000002  \n","Epoch: [1][33700/36908] Elapsed 279m 17s (remain 26m 34s) Loss: 0.0064(0.0055) Grad: 136474.6406  LR: 0.000002  \n","Epoch: [1][33800/36908] Elapsed 280m 7s (remain 25m 44s) Loss: 0.0108(0.0055) Grad: 173599.0781  LR: 0.000002  \n","Epoch: [1][33900/36908] Elapsed 280m 58s (remain 24m 55s) Loss: 0.0097(0.0055) Grad: 195863.7188  LR: 0.000002  \n","Epoch: [1][34000/36908] Elapsed 281m 48s (remain 24m 5s) Loss: 0.0000(0.0055) Grad: 520.1352  LR: 0.000002  \n","Epoch: [1][34100/36908] Elapsed 282m 39s (remain 23m 15s) Loss: 0.0000(0.0055) Grad: 205.6935  LR: 0.000002  \n","Epoch: [1][34200/36908] Elapsed 283m 29s (remain 22m 26s) Loss: 0.0000(0.0055) Grad: 33.0809  LR: 0.000002  \n","Epoch: [1][34300/36908] Elapsed 284m 19s (remain 21m 36s) Loss: 0.0000(0.0055) Grad: 992.8439  LR: 0.000002  \n","Epoch: [1][34400/36908] Elapsed 285m 8s (remain 20m 46s) Loss: 0.0000(0.0055) Grad: 138.9750  LR: 0.000002  \n","Epoch: [1][34500/36908] Elapsed 285m 57s (remain 19m 57s) Loss: 0.0000(0.0055) Grad: 594.3747  LR: 0.000001  \n","Epoch: [1][34600/36908] Elapsed 286m 48s (remain 19m 7s) Loss: 0.0007(0.0055) Grad: 18633.3711  LR: 0.000001  \n","Epoch: [1][34700/36908] Elapsed 287m 38s (remain 18m 17s) Loss: 0.0000(0.0055) Grad: 74.8164  LR: 0.000001  \n","Epoch: [1][34800/36908] Elapsed 288m 29s (remain 17m 27s) Loss: 0.0000(0.0055) Grad: 67.9116  LR: 0.000001  \n","Epoch: [1][34900/36908] Elapsed 289m 18s (remain 16m 38s) Loss: 0.0003(0.0054) Grad: 9313.1133  LR: 0.000001  \n","Epoch: [1][35000/36908] Elapsed 290m 8s (remain 15m 48s) Loss: 0.0001(0.0054) Grad: 5922.8408  LR: 0.000001  \n","Epoch: [1][35100/36908] Elapsed 290m 58s (remain 14m 58s) Loss: 0.0030(0.0054) Grad: 137740.3281  LR: 0.000001  \n","Epoch: [1][35200/36908] Elapsed 291m 49s (remain 14m 9s) Loss: 0.0000(0.0054) Grad: 76.7196  LR: 0.000001  \n","Epoch: [1][35300/36908] Elapsed 292m 41s (remain 13m 19s) Loss: 0.0000(0.0054) Grad: 18.0414  LR: 0.000001  \n","Epoch: [1][35400/36908] Elapsed 293m 32s (remain 12m 29s) Loss: 0.0006(0.0054) Grad: 38012.6523  LR: 0.000001  \n","Epoch: [1][35500/36908] Elapsed 294m 23s (remain 11m 40s) Loss: 0.0002(0.0054) Grad: 15999.6426  LR: 0.000001  \n","Epoch: [1][35600/36908] Elapsed 295m 14s (remain 10m 50s) Loss: 0.0002(0.0054) Grad: 20781.7891  LR: 0.000001  \n","Epoch: [1][35700/36908] Elapsed 296m 5s (remain 10m 0s) Loss: 0.0016(0.0054) Grad: 99729.5859  LR: 0.000001  \n","Epoch: [1][35800/36908] Elapsed 296m 56s (remain 9m 10s) Loss: 0.0000(0.0054) Grad: 573.3887  LR: 0.000001  \n","Epoch: [1][35900/36908] Elapsed 297m 48s (remain 8m 21s) Loss: 0.0824(0.0054) Grad: 419985.0000  LR: 0.000001  \n","Epoch: [1][36000/36908] Elapsed 298m 39s (remain 7m 31s) Loss: 0.0000(0.0054) Grad: 11.0478  LR: 0.000001  \n","Epoch: [1][36100/36908] Elapsed 299m 30s (remain 6m 41s) Loss: 0.0015(0.0054) Grad: 26600.2402  LR: 0.000000  \n","Epoch: [1][36200/36908] Elapsed 300m 21s (remain 5m 51s) Loss: 0.0000(0.0053) Grad: 7.2241  LR: 0.000000  \n","Epoch: [1][36300/36908] Elapsed 301m 11s (remain 5m 2s) Loss: 0.0059(0.0053) Grad: 119789.4844  LR: 0.000000  \n","Epoch: [1][36400/36908] Elapsed 302m 3s (remain 4m 12s) Loss: 0.0111(0.0053) Grad: 246041.0469  LR: 0.000000  \n","Epoch: [1][36500/36908] Elapsed 302m 53s (remain 3m 22s) Loss: 0.0029(0.0053) Grad: 39945.8008  LR: 0.000000  \n","Epoch: [1][36600/36908] Elapsed 303m 43s (remain 2m 32s) Loss: 0.0160(0.0053) Grad: 174320.7969  LR: 0.000000  \n","Epoch: [1][36700/36908] Elapsed 304m 33s (remain 1m 43s) Loss: 0.0562(0.0053) Grad: 685248.8750  LR: 0.000000  \n","Epoch: [1][36800/36908] Elapsed 305m 23s (remain 0m 53s) Loss: 0.0000(0.0053) Grad: 103.3489  LR: 0.000000  \n","Epoch: [1][36900/36908] Elapsed 306m 13s (remain 0m 3s) Loss: 0.0075(0.0053) Grad: 125754.9766  LR: 0.000000  \n","Epoch: [1][36907/36908] Elapsed 306m 16s (remain 0m 0s) Loss: 0.0000(0.0053) Grad: 1535.4419  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 1s (remain 22m 23s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 23s (remain 4m 13s) Loss: 0.0715(0.0124) \n","EVAL: [200/1192] Elapsed 0m 45s (remain 3m 44s) Loss: 0.0171(0.0113) \n","EVAL: [300/1192] Elapsed 1m 7s (remain 3m 20s) Loss: 0.0147(0.0133) \n","EVAL: [400/1192] Elapsed 1m 29s (remain 2m 56s) Loss: 0.0000(0.0131) \n","EVAL: [500/1192] Elapsed 1m 51s (remain 2m 34s) Loss: 0.0591(0.0125) \n","EVAL: [600/1192] Elapsed 2m 13s (remain 2m 11s) Loss: 0.0339(0.0129) \n","EVAL: [700/1192] Elapsed 2m 35s (remain 1m 49s) Loss: 0.0092(0.0147) \n","EVAL: [800/1192] Elapsed 2m 58s (remain 1m 26s) Loss: 0.0433(0.0148) \n","EVAL: [900/1192] Elapsed 3m 20s (remain 1m 4s) Loss: 0.0052(0.0152) \n","EVAL: [1000/1192] Elapsed 3m 42s (remain 0m 42s) Loss: 0.0000(0.0146) \n","EVAL: [1100/1192] Elapsed 4m 4s (remain 0m 20s) Loss: 0.0341(0.0142) \n","EVAL: [1191/1192] Elapsed 4m 24s (remain 0m 0s) Loss: 0.0000(0.0137) \n","Epoch 1 - avg_train_loss: 0.0053  avg_val_loss: 0.0137  time: 18644s\n","Epoch 1 - Score: 0.8939\n","Epoch 1 - Save Best Score: 0.8939 Model\n","best_thres: 0.54  score: 0.89054\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef7473534dc4f58ba3ecda136c2f3de"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n","load weights from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp091/fold0_best.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79fbb9fa48a3416b9a3a0356829ad534"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n","load weights from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp091/fold1_best.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca09cdb52c2f47e0b288388d73b09db2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n","load weights from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp091/fold2_best.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a121eab69bc242e9b731796061a74379"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n","load weights from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp091/fold3_best.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1f83b03b75b4d99a20ead8f5c762394"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"],"id":"proprietary-civilian"},{"cell_type":"code","execution_count":39,"metadata":{"id":"N5kZWfSSfJMf","executionInfo":{"status":"ok","timestamp":1650620492114,"user_tz":-540,"elapsed":26,"user":{"displayName":"Shuhei Goda","userId":"08246931244224045522"}}},"outputs":[],"source":[""],"id":"N5kZWfSSfJMf"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"nbme-exp091.ipynb","provenance":[{"file_id":"1EAQeYx7ZDlc73HHqsOI51H0I6B4rJ9nW","timestamp":1650543746407},{"file_id":"1Un3kcPOvK7CdpO-7Pd7r0upTnePSOWdv","timestamp":1649491695188},{"file_id":"13PUc1BK1XquiZCrLMEB3RguGfJtqCZgm","timestamp":1647850264218},{"file_id":"1wqr1Y1MTpmofNqOtVD8cCBYlPZoPt3XQ","timestamp":1647823100264}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2e29102c1f084856a5c7d70cdb6e37dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_772655b1f4c44befac43db54fcaf9d16","IPY_MODEL_16ff0f4257c443ed967d2e550d3cddaa","IPY_MODEL_256d535f774a40d6addf28feb2eaf147"],"layout":"IPY_MODEL_e453e8d0cb9c4c799ba550a1595f11a2"}},"772655b1f4c44befac43db54fcaf9d16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0637e3b056c24fcc86b63969c81d7cb3","placeholder":"​","style":"IPY_MODEL_626dc5ef22e54667830854d8fb280592","value":"Downloading: 100%"}},"16ff0f4257c443ed967d2e550d3cddaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec2d9cf22b464c8da472f11d90d4c662","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1848a6ab3c3841d9a8840df1e6106553","value":52}},"256d535f774a40d6addf28feb2eaf147":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7fe60fce5944324989d6ca00fb5e98b","placeholder":"​","style":"IPY_MODEL_8990b2fddc724af09137b591ee53f53a","value":" 52.0/52.0 [00:00&lt;00:00, 1.95kB/s]"}},"e453e8d0cb9c4c799ba550a1595f11a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0637e3b056c24fcc86b63969c81d7cb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"626dc5ef22e54667830854d8fb280592":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec2d9cf22b464c8da472f11d90d4c662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1848a6ab3c3841d9a8840df1e6106553":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7fe60fce5944324989d6ca00fb5e98b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8990b2fddc724af09137b591ee53f53a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62125de880c94419ad986cae52cebb65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ba699e87d4147ed8151e48fe00ec754","IPY_MODEL_0748c2873815467bb90ad91db89404b8","IPY_MODEL_97173d2d810f49b2b25514f3db12af87"],"layout":"IPY_MODEL_8bf4e88c35d94a3bbad5b76ee0c845e7"}},"7ba699e87d4147ed8151e48fe00ec754":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ddb81acb87d4c2a91467bbb1a7f86c0","placeholder":"​","style":"IPY_MODEL_2a864544a81f4768bfaed0cff22e3f2c","value":"Downloading: 100%"}},"0748c2873815467bb90ad91db89404b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe16a92601f44c0aafadd190b13760e9","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3634d42d4fb74684a64ee41b3c911c90","value":2464616}},"97173d2d810f49b2b25514f3db12af87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_802d1c37647e45e7bc39b2e56ec13550","placeholder":"​","style":"IPY_MODEL_ac76267778dc4310bbff31eed2546a44","value":" 2.35M/2.35M [00:00&lt;00:00, 28.4MB/s]"}},"8bf4e88c35d94a3bbad5b76ee0c845e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ddb81acb87d4c2a91467bbb1a7f86c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a864544a81f4768bfaed0cff22e3f2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe16a92601f44c0aafadd190b13760e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3634d42d4fb74684a64ee41b3c911c90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"802d1c37647e45e7bc39b2e56ec13550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac76267778dc4310bbff31eed2546a44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc8fd650057149fcbbd62e3bdaf45860":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c656a7343a746f28af832e64bcb6abb","IPY_MODEL_487c4fc3b7254258a0b0a17cf85fc1ae","IPY_MODEL_ab1d695f112b4fd9a19c1742593c896f"],"layout":"IPY_MODEL_3edacfc1f35748d6b8a152ff119c8d0e"}},"0c656a7343a746f28af832e64bcb6abb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68080b44fc514b2abfbd56e33acffb0e","placeholder":"​","style":"IPY_MODEL_c32b540da97d42a58be41c6fd965b435","value":"Downloading: 100%"}},"487c4fc3b7254258a0b0a17cf85fc1ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_051df790fbe64d6186e6836c396f9060","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69ec916786ee44fd855b7bbb9927519d","value":580}},"ab1d695f112b4fd9a19c1742593c896f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_babd5ac477fb4a9fa742d4bdc8472400","placeholder":"​","style":"IPY_MODEL_a59ef9241ec249e3bbcc99b35e609640","value":" 580/580 [00:00&lt;00:00, 20.8kB/s]"}},"3edacfc1f35748d6b8a152ff119c8d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68080b44fc514b2abfbd56e33acffb0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c32b540da97d42a58be41c6fd965b435":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"051df790fbe64d6186e6836c396f9060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69ec916786ee44fd855b7bbb9927519d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"babd5ac477fb4a9fa742d4bdc8472400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59ef9241ec249e3bbcc99b35e609640":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"489bfb7c69c34bf983ebcaa2022498d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc1e85d52e5e490382f9b501cdd0f847","IPY_MODEL_b3d7c1ce6e7b41eb9040a78024e950b6","IPY_MODEL_d4fb80326dbb4632a888686a10ce0fd9"],"layout":"IPY_MODEL_d488a8bf759d4484b7688d61c96c2e3f"}},"bc1e85d52e5e490382f9b501cdd0f847":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3282e780d837477a9d9eb56c32e2fddb","placeholder":"​","style":"IPY_MODEL_ee231ab6a90444c98e0dadcea93a6d05","value":"100%"}},"b3d7c1ce6e7b41eb9040a78024e950b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29eff1ad2d9a42629bca0be6d98d997d","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e5279aa3ec44baeafbfe15eed6c00d8","value":42146}},"d4fb80326dbb4632a888686a10ce0fd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37a37d3de665420c93163c8f537db832","placeholder":"​","style":"IPY_MODEL_fc07f6aba3ce49eeaf36f1fc7f4d98ee","value":" 42146/42146 [00:23&lt;00:00, 1884.61it/s]"}},"d488a8bf759d4484b7688d61c96c2e3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3282e780d837477a9d9eb56c32e2fddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee231ab6a90444c98e0dadcea93a6d05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29eff1ad2d9a42629bca0be6d98d997d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e5279aa3ec44baeafbfe15eed6c00d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37a37d3de665420c93163c8f537db832":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc07f6aba3ce49eeaf36f1fc7f4d98ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8d8973fe3584412b61224b0a002a60c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1aec2a9db2ad4ddaa975a5e0241901c9","IPY_MODEL_2ccdce156a3e4855ac1f95c9094ca400","IPY_MODEL_430616d568a94a1ab0536740b8f203dd"],"layout":"IPY_MODEL_881c2f1bfde047149e8c1f8c44770e7a"}},"1aec2a9db2ad4ddaa975a5e0241901c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_853d19f0f0c540a3ab902c4873df83df","placeholder":"​","style":"IPY_MODEL_f50d5a1351fd4cbebce985582a3e3109","value":"100%"}},"2ccdce156a3e4855ac1f95c9094ca400":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf47ecbcbc8b4c1d84a3ebd65de101fd","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f73b43f8803d4df3aa0c9f0be5656509","value":143}},"430616d568a94a1ab0536740b8f203dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba0b8b5d17b14473b977aeb8c7e94919","placeholder":"​","style":"IPY_MODEL_f31885063b5d440c888caa1d2861cbef","value":" 143/143 [00:00&lt;00:00, 3096.64it/s]"}},"881c2f1bfde047149e8c1f8c44770e7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"853d19f0f0c540a3ab902c4873df83df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f50d5a1351fd4cbebce985582a3e3109":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf47ecbcbc8b4c1d84a3ebd65de101fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73b43f8803d4df3aa0c9f0be5656509":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba0b8b5d17b14473b977aeb8c7e94919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31885063b5d440c888caa1d2861cbef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db048ff502264cb8b4828e7fbf485ce2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66b32316e9734eeebc642562e95c7d1b","IPY_MODEL_dbf8a0792ca04b9b8b674cb76178e0f3","IPY_MODEL_7bb64d92d8be42ccb6fc2ec0e61f5f37"],"layout":"IPY_MODEL_62ca5df9080d4bb6abce4553182caf6f"}},"66b32316e9734eeebc642562e95c7d1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a709a7633bba4c879b0345eb6898c9f8","placeholder":"​","style":"IPY_MODEL_e1cb91b47d4541abade15ec0e028f9ca","value":"100%"}},"dbf8a0792ca04b9b8b674cb76178e0f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3181ffc60d44b5abba79bc06ef3b83b","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12cb9a77e4444fc194fc5dfe60f08635","value":42146}},"7bb64d92d8be42ccb6fc2ec0e61f5f37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_530e6f820336414c8b3fdbaff29aa672","placeholder":"​","style":"IPY_MODEL_feb96e5db0b345e49dcdc4db31d9dce1","value":" 42146/42146 [00:00&lt;00:00, 676229.43it/s]"}},"62ca5df9080d4bb6abce4553182caf6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a709a7633bba4c879b0345eb6898c9f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1cb91b47d4541abade15ec0e028f9ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3181ffc60d44b5abba79bc06ef3b83b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12cb9a77e4444fc194fc5dfe60f08635":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"530e6f820336414c8b3fdbaff29aa672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feb96e5db0b345e49dcdc4db31d9dce1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"098dfb21f7764ad79da1bb7846b58a7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f08575c65cb4d5b8d4d83a322ace46f","IPY_MODEL_0d9350a9e6954c9e9c738c76a008ebd4","IPY_MODEL_6a19b5e02cc24507b52fe8ade73fd132"],"layout":"IPY_MODEL_a5b413f76e6347b2a769d51faa019d30"}},"6f08575c65cb4d5b8d4d83a322ace46f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5de7c54a2845e58e5510e0d5f77773","placeholder":"​","style":"IPY_MODEL_db74cb5d088b4f8e9eba6b1b1829aea4","value":"100%"}},"0d9350a9e6954c9e9c738c76a008ebd4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09edcee4ce5442dea094378efd41cfc7","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83e95c5c59df411e9aaf7ba3d04e69c9","value":612602}},"6a19b5e02cc24507b52fe8ade73fd132":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44cef72fb618493dbabe421c7df7a32f","placeholder":"​","style":"IPY_MODEL_7ca1bdf75319467fbd885569629f66a9","value":" 612602/612602 [00:00&lt;00:00, 926227.11it/s]"}},"a5b413f76e6347b2a769d51faa019d30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b5de7c54a2845e58e5510e0d5f77773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db74cb5d088b4f8e9eba6b1b1829aea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09edcee4ce5442dea094378efd41cfc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83e95c5c59df411e9aaf7ba3d04e69c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44cef72fb618493dbabe421c7df7a32f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ca1bdf75319467fbd885569629f66a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d717a406bb464c2987e24b0fee894044":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32eee585b56847968a5b78fdebad22a7","IPY_MODEL_746452a82a364d20add829d22ba0ece1","IPY_MODEL_f914c533ac3e4c2ca148736d7e9b82d6"],"layout":"IPY_MODEL_8b71d09d2e2f4c0aa3378300c35e3b4a"}},"32eee585b56847968a5b78fdebad22a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0d15ed6ea3b42f593039f4ed232c8d5","placeholder":"​","style":"IPY_MODEL_b0bdfcb89fe040b4ab5a328ed8a728cc","value":"100%"}},"746452a82a364d20add829d22ba0ece1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffdba6e0f7fb4baab81b7e3c817ac056","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4929f62c055e4d11a2dd29ced499c868","value":612602}},"f914c533ac3e4c2ca148736d7e9b82d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_828e2a35c3114ceba67ab887e1eb1c82","placeholder":"​","style":"IPY_MODEL_450c9eed30184bf38d3d29af7538ab8b","value":" 612602/612602 [00:31&lt;00:00, 23589.85it/s]"}},"8b71d09d2e2f4c0aa3378300c35e3b4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0d15ed6ea3b42f593039f4ed232c8d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0bdfcb89fe040b4ab5a328ed8a728cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffdba6e0f7fb4baab81b7e3c817ac056":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4929f62c055e4d11a2dd29ced499c868":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"828e2a35c3114ceba67ab887e1eb1c82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"450c9eed30184bf38d3d29af7538ab8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8692487d106a4c07a661a60ba5869bb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c378314ed8b547da9d17c93f3248cb61","IPY_MODEL_78b4080fa2be4e2ebfeac790cddc9e04","IPY_MODEL_03a5ab3e54a843b693ae63e42bbb17c8"],"layout":"IPY_MODEL_158d08b04b0046c1942836c1cb799062"}},"c378314ed8b547da9d17c93f3248cb61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f00b4453db141a086f636dd1df6327e","placeholder":"​","style":"IPY_MODEL_94c328987a2e4eb0b0e5e72aece4d6c8","value":"100%"}},"78b4080fa2be4e2ebfeac790cddc9e04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0109ab201ee40539c036dddcccb220a","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6d317f8e9b0450e94f35a70248487e6","value":612602}},"03a5ab3e54a843b693ae63e42bbb17c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c69605df2ee6464cb9b7c20612be7bac","placeholder":"​","style":"IPY_MODEL_6843e9b50b2c490fb6f1201263191ceb","value":" 612602/612602 [00:00&lt;00:00, 965448.60it/s]"}},"158d08b04b0046c1942836c1cb799062":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f00b4453db141a086f636dd1df6327e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94c328987a2e4eb0b0e5e72aece4d6c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0109ab201ee40539c036dddcccb220a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d317f8e9b0450e94f35a70248487e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c69605df2ee6464cb9b7c20612be7bac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6843e9b50b2c490fb6f1201263191ceb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"193ecba780d44d45a9bae3de377fc057":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7ac480071a44f07866dcd6b878a0224","IPY_MODEL_67185274cea2499b914f023fbdd284ad","IPY_MODEL_0dc64dacbf9a45f4b5106adedab197a1"],"layout":"IPY_MODEL_4b30c0420c3e43b1babccd5e156a6bf5"}},"b7ac480071a44f07866dcd6b878a0224":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da30992f5c694ac7920803e22eeb83cf","placeholder":"​","style":"IPY_MODEL_c64ad7f4dafe44c289341a61ee4a6270","value":"100%"}},"67185274cea2499b914f023fbdd284ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37a01705794c4ccb86295169910b83bf","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0afcaf996724cb0a42b21fbc04dffc6","value":612602}},"0dc64dacbf9a45f4b5106adedab197a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac3aeea92944471c96329743cc522541","placeholder":"​","style":"IPY_MODEL_0dbf2371424c49619cedb4e125c2a16d","value":" 612602/612602 [00:30&lt;00:00, 23965.64it/s]"}},"4b30c0420c3e43b1babccd5e156a6bf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da30992f5c694ac7920803e22eeb83cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c64ad7f4dafe44c289341a61ee4a6270":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37a01705794c4ccb86295169910b83bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0afcaf996724cb0a42b21fbc04dffc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac3aeea92944471c96329743cc522541":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dbf2371424c49619cedb4e125c2a16d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2dd1f825d69486c8a77560365754ae5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48a4f61554354e2a8820fac432d0f2fa","IPY_MODEL_fff25bd2498e4ab8ac71975cca373e2f","IPY_MODEL_20efeef1318641579aa124645aa90696"],"layout":"IPY_MODEL_f41c6ec0bb674f22858f9debb65b0ae4"}},"48a4f61554354e2a8820fac432d0f2fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9e99b8fdb5c40638535767789b1dd33","placeholder":"​","style":"IPY_MODEL_60e49c9c7999448b88bd402c6ac62c6a","value":"100%"}},"fff25bd2498e4ab8ac71975cca373e2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efcc0df46f774015806bdb49c3441e1c","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd8af70e33854c1f9585186d140727c7","value":612602}},"20efeef1318641579aa124645aa90696":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eba418bd23ec41949940c04292aebc9f","placeholder":"​","style":"IPY_MODEL_d91e95e82fdd4850bdcc22f5eb9e2cd7","value":" 612602/612602 [00:00&lt;00:00, 959763.74it/s]"}},"f41c6ec0bb674f22858f9debb65b0ae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e99b8fdb5c40638535767789b1dd33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e49c9c7999448b88bd402c6ac62c6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efcc0df46f774015806bdb49c3441e1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd8af70e33854c1f9585186d140727c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eba418bd23ec41949940c04292aebc9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91e95e82fdd4850bdcc22f5eb9e2cd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e6ca0edd2e646889ddb4f46a94e6cd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d39c495e737549d2aba9cda52e717128","IPY_MODEL_8e797f712786450b9ad82b24342887d2","IPY_MODEL_d8d5e521942545b8b1a033de9e03fcb2"],"layout":"IPY_MODEL_6e01e48c7181431c9a185d123a1c5e23"}},"d39c495e737549d2aba9cda52e717128":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a70b81b6a5a41b894954d3a67643ae7","placeholder":"​","style":"IPY_MODEL_de02db17ca9e4756b2d7570925fbb878","value":"100%"}},"8e797f712786450b9ad82b24342887d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e0aeb17cce246298ddc411911ad610f","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_358528ea916747be986927acd7b558c8","value":612602}},"d8d5e521942545b8b1a033de9e03fcb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0e8cfeb3d3c4e1a97f22edbb047e932","placeholder":"​","style":"IPY_MODEL_48acb2c7a41d418d861b0efff1555344","value":" 612602/612602 [00:29&lt;00:00, 24065.72it/s]"}},"6e01e48c7181431c9a185d123a1c5e23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a70b81b6a5a41b894954d3a67643ae7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de02db17ca9e4756b2d7570925fbb878":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e0aeb17cce246298ddc411911ad610f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"358528ea916747be986927acd7b558c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0e8cfeb3d3c4e1a97f22edbb047e932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48acb2c7a41d418d861b0efff1555344":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1533d738bd64bba90ca5bab036838e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f6af6a1c3184519875bb264cd04b40f","IPY_MODEL_4c05554b925c41a0abf609651f3fefc8","IPY_MODEL_0c0c49586eda4fd7ab8ffb4e460453ee"],"layout":"IPY_MODEL_b7cd387c3505410a98e809159b895824"}},"2f6af6a1c3184519875bb264cd04b40f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3a1bef84f9f4d24a3d9a48dbbe3d047","placeholder":"​","style":"IPY_MODEL_5f6b099a528d4fb5b80781b1a838b372","value":"100%"}},"4c05554b925c41a0abf609651f3fefc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_383d20b015404c768354b37459c48bb8","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c11b26e295574af2ae69b45602ed83b9","value":612602}},"0c0c49586eda4fd7ab8ffb4e460453ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b96116b8bbde48ca9e937685eb36c45e","placeholder":"​","style":"IPY_MODEL_b92012b9f0ea404687caf795124867bc","value":" 612602/612602 [00:00&lt;00:00, 949717.01it/s]"}},"b7cd387c3505410a98e809159b895824":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3a1bef84f9f4d24a3d9a48dbbe3d047":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f6b099a528d4fb5b80781b1a838b372":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"383d20b015404c768354b37459c48bb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c11b26e295574af2ae69b45602ed83b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b96116b8bbde48ca9e937685eb36c45e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92012b9f0ea404687caf795124867bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84a8b42da5fd406386892b0b944e90d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_abdfdbe0a04049faac405c42f4f8aa88","IPY_MODEL_62d65c1cee214e1d8bd3e3d947440a65","IPY_MODEL_02e7d0fd370c47dcb6089a7b5eb92209"],"layout":"IPY_MODEL_94e2039af3514952b41ed00367db6501"}},"abdfdbe0a04049faac405c42f4f8aa88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_accc15d61c5644caac442a09f54594e5","placeholder":"​","style":"IPY_MODEL_eb60c86782ff4184ba591b90ab679ace","value":"100%"}},"62d65c1cee214e1d8bd3e3d947440a65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72365827fc3047bcbc312f02e56e8fea","max":612602,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae1ca2fb360646a3be2c3a8e3c318448","value":612602}},"02e7d0fd370c47dcb6089a7b5eb92209":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ed4ac01a3d943b88397f44fb312c7ef","placeholder":"​","style":"IPY_MODEL_4ae7d12353684d21aec12e1931325f21","value":" 612602/612602 [00:29&lt;00:00, 24366.58it/s]"}},"94e2039af3514952b41ed00367db6501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"accc15d61c5644caac442a09f54594e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb60c86782ff4184ba591b90ab679ace":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72365827fc3047bcbc312f02e56e8fea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae1ca2fb360646a3be2c3a8e3c318448":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ed4ac01a3d943b88397f44fb312c7ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ae7d12353684d21aec12e1931325f21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef7473534dc4f58ba3ecda136c2f3de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d7bf5fac80c4532a21108c250d1fdb7","IPY_MODEL_57aadffe9f2d4e90a8f03486ec26a5af","IPY_MODEL_64cc9d92bca14ea7bd5434ffdd3cd703"],"layout":"IPY_MODEL_1e94ec6d10d8480bb2a8f19f02d3239d"}},"7d7bf5fac80c4532a21108c250d1fdb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab2160d8e2124e0f88d4c93a55be18a2","placeholder":"​","style":"IPY_MODEL_eba23fa6e0194ebc8309889ecb4d3919","value":"Downloading: 100%"}},"57aadffe9f2d4e90a8f03486ec26a5af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_511a2eb8dda5435d816b5a0fe1d16ba9","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0af2993e0e2e4729b679f39f56a14171","value":873673253}},"64cc9d92bca14ea7bd5434ffdd3cd703":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4de986fd5404a4d9bbb58497e076b81","placeholder":"​","style":"IPY_MODEL_eb1d117d057447109ad549efc42e0db3","value":" 833M/833M [00:14&lt;00:00, 62.0MB/s]"}},"1e94ec6d10d8480bb2a8f19f02d3239d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab2160d8e2124e0f88d4c93a55be18a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eba23fa6e0194ebc8309889ecb4d3919":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"511a2eb8dda5435d816b5a0fe1d16ba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0af2993e0e2e4729b679f39f56a14171":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4de986fd5404a4d9bbb58497e076b81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb1d117d057447109ad549efc42e0db3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79fbb9fa48a3416b9a3a0356829ad534":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdb6f0df88484e549746d626dda77f9d","IPY_MODEL_2dd83abf7cd845c692562e4f00cca019","IPY_MODEL_16a3072cf8414184b570c4a9d5788a1f"],"layout":"IPY_MODEL_390b9875a3294b3696d9f32b8c98129e"}},"bdb6f0df88484e549746d626dda77f9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05ceb2ae4df341849d60e11b48007166","placeholder":"​","style":"IPY_MODEL_33556689e77145fbb41685f369c6123b","value":"100%"}},"2dd83abf7cd845c692562e4f00cca019":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_879e4481cbaa443a87f56c39e418507d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a72a7d46dad49508fbbef3142f0fe69","value":2}},"16a3072cf8414184b570c4a9d5788a1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b250cc0e6344c1d9707f8a42b617d75","placeholder":"​","style":"IPY_MODEL_e6c151fed257488bb416ee894b3a1011","value":" 2/2 [00:02&lt;00:00,  1.02s/it]"}},"390b9875a3294b3696d9f32b8c98129e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05ceb2ae4df341849d60e11b48007166":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33556689e77145fbb41685f369c6123b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"879e4481cbaa443a87f56c39e418507d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a72a7d46dad49508fbbef3142f0fe69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b250cc0e6344c1d9707f8a42b617d75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6c151fed257488bb416ee894b3a1011":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca09cdb52c2f47e0b288388d73b09db2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc1c4eb2d281407d9e29c164a7deca71","IPY_MODEL_e458f6a9dd134814920f60555e0e5096","IPY_MODEL_acca7d37fccd4a688c04209dae9d32ba"],"layout":"IPY_MODEL_b2c522dc9c734695811d60bc0f41baf2"}},"bc1c4eb2d281407d9e29c164a7deca71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_215b86de20a940c6bb3be8e9d6ad4a6d","placeholder":"​","style":"IPY_MODEL_8552c48a0a7a4b46a49c2b6c598d06b2","value":"100%"}},"e458f6a9dd134814920f60555e0e5096":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_075e6c0abbc04c8fb0492d0f72414c7f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9779ee8d55584ec19cc6721e67c56454","value":2}},"acca7d37fccd4a688c04209dae9d32ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5efb09bd67cd48228c9ea65075852132","placeholder":"​","style":"IPY_MODEL_14589ce943fb48c39619b7f37fc0d122","value":" 2/2 [00:02&lt;00:00,  1.05it/s]"}},"b2c522dc9c734695811d60bc0f41baf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"215b86de20a940c6bb3be8e9d6ad4a6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8552c48a0a7a4b46a49c2b6c598d06b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"075e6c0abbc04c8fb0492d0f72414c7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9779ee8d55584ec19cc6721e67c56454":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5efb09bd67cd48228c9ea65075852132":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14589ce943fb48c39619b7f37fc0d122":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a121eab69bc242e9b731796061a74379":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cba4314a72dd41f7a34865143941a386","IPY_MODEL_761c219e7aaf4bbd92bcec61adb972e2","IPY_MODEL_79cdb0fb85434c54ae0a2da78dca7223"],"layout":"IPY_MODEL_1884b95ce00b41a3bf027723629ceab3"}},"cba4314a72dd41f7a34865143941a386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d06325828e8444c811ac2a0baaf61cf","placeholder":"​","style":"IPY_MODEL_04c8976e836d464d8a4449f13d2396d7","value":"100%"}},"761c219e7aaf4bbd92bcec61adb972e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_063b4d3c061b4dd1b1c8d467a423ea25","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40a610c4a69b4cdda658c96a5ffffe61","value":2}},"79cdb0fb85434c54ae0a2da78dca7223":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e51219f086d143499f07cf70344d3021","placeholder":"​","style":"IPY_MODEL_89153fe19d8440f8b84df24bff65d235","value":" 2/2 [00:02&lt;00:00,  1.13it/s]"}},"1884b95ce00b41a3bf027723629ceab3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d06325828e8444c811ac2a0baaf61cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04c8976e836d464d8a4449f13d2396d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"063b4d3c061b4dd1b1c8d467a423ea25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40a610c4a69b4cdda658c96a5ffffe61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e51219f086d143499f07cf70344d3021":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89153fe19d8440f8b84df24bff65d235":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1f83b03b75b4d99a20ead8f5c762394":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ef9276485384088860e70fd07ba48a8","IPY_MODEL_7cc77b355aa64020833ce67d5a460742","IPY_MODEL_74bccf559448432db261f613eef2566c"],"layout":"IPY_MODEL_c32c570a83934daeb49201852c9cd31f"}},"5ef9276485384088860e70fd07ba48a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cec4884a71fd48d8bd4bfb69a43b34ba","placeholder":"​","style":"IPY_MODEL_aaeb672105c84aa29329e752c914018d","value":"100%"}},"7cc77b355aa64020833ce67d5a460742":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e960e5b7145433287c60db53f3c37b8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5286a4e9aa748babc1845d192860d14","value":2}},"74bccf559448432db261f613eef2566c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7208c3fc6cf943e6af04ffaf6ab69195","placeholder":"​","style":"IPY_MODEL_a84b48cb01a94050b580b19df539f441","value":" 2/2 [00:02&lt;00:00,  1.17it/s]"}},"c32c570a83934daeb49201852c9cd31f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec4884a71fd48d8bd4bfb69a43b34ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaeb672105c84aa29329e752c914018d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e960e5b7145433287c60db53f3c37b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5286a4e9aa748babc1845d192860d14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7208c3fc6cf943e6af04ffaf6ab69195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a84b48cb01a94050b580b19df539f441":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}