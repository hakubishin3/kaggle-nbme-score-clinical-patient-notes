{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "clinical-cement",
   "metadata": {
    "id": "blind-kingdom"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-exploration",
   "metadata": {
    "id": "antique-glenn"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-annex",
   "metadata": {
    "id": "bored-ministry"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "three-principle",
   "metadata": {
    "id": "deadly-confidence"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp027\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "curious-gambling",
   "metadata": {
    "id": "aware-worcester"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-v3-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spectacular-circular",
   "metadata": {
    "id": "personalized-death"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-director",
   "metadata": {
    "id": "cardiovascular-neutral"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "architectural-landing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "checked-boards",
    "outputId": "87364705-3e3f-4866-a538-14dfdc9c7e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "    !pip install sentencepiece\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disciplinary-recall",
   "metadata": {
    "id": "iGai035Rvu1Z"
   },
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "if CFG.env == \"colab\":\n",
    "    input_dir = Path(\"./drive/MyDrive/00.kaggle/input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n",
    "else:\n",
    "    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)\n",
    "    \n",
    "    \n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "systematic-vehicle",
   "metadata": {
    "id": "vital-mexico"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-anatomy",
   "metadata": {
    "id": "economic-ladder"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consistent-rescue",
   "metadata": {
    "id": "desperate-keyboard"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reflected-radio",
   "metadata": {
    "id": "flexible-wednesday"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "noted-eating",
   "metadata": {
    "id": "logical-chemistry"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "innocent-america",
   "metadata": {
    "id": "gorgeous-record"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-jefferson",
   "metadata": {
    "id": "frozen-africa"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aerial-valley",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shaped-metallic",
    "outputId": "11a7cabc-1b4b-4b13-c8cc-95ce538868f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "present-legislation",
   "metadata": {
    "id": "visible-australia"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-notebook",
   "metadata": {
    "id": "hydraulic-gibson"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pending-rotation",
   "metadata": {
    "id": "interpreted-northeast"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "raising-anaheim",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "martial-blind",
    "outputId": "42a83988-2022-4dc2-a38e-7f156b490c5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "legislative-partition",
   "metadata": {
    "id": "electoral-favor"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indoor-humidity",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "reported-parade",
    "outputId": "60a64543-0419-4942-9673-73f0921c1d34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-saskatchewan",
   "metadata": {
    "id": "enabling-relevance"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "assumed-variation",
   "metadata": {
    "id": "mature-coalition"
   },
   "outputs": [],
   "source": [
    "def get_groupkfold(df, group_name):\n",
    "    groups = df[group_name].unique()\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=CFG.n_fold,\n",
    "        shuffle=True,\n",
    "        random_state=CFG.seed,\n",
    "    )\n",
    "    folds_ids = []\n",
    "    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n",
    "        val_group = groups[val_group_idx]\n",
    "        is_val = df[group_name].isin(val_group)\n",
    "        val_idx = df[is_val].index\n",
    "        df.loc[val_idx, \"fold\"] = int(i_fold)\n",
    "\n",
    "    df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "embedded-wheat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "every-minutes",
    "outputId": "b1991a8c-a884-4b5a-8ad9-58990576bef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    2902\n",
       "1    2894\n",
       "2    2813\n",
       "3    2791\n",
       "4    2900\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_groupkfold(train, \"pn_num\")\n",
    "display(train.groupby(\"fold\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-gnome",
   "metadata": {
    "id": "subjective-entrance"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "international-junior",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dramatic-afghanistan",
    "outputId": "f56c7a0a-6282-4575-c71e-5e908bc30b95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-power",
   "metadata": {
    "id": "divided-arrow"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "czech-remark",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "661a9a315f8646a49162891ae47c69e7",
      "ef004a834af944abbd512fa3218642a1",
      "74fa3a6b51ad46958e58de5580cf5333",
      "810a830f3b6743b9b074867dd8e4e179",
      "7316ae87cfb849898eb022e100730ba2",
      "c7cb034c107247cba318475c9952b4ac",
      "7d891639f26644e8a05d7fe38d178245",
      "c8a7a19edb074139baefe21f1901d4f4",
      "7ed0ca5ee62d45d89050f3caf3d528c9",
      "0b48bd338cc94fe396aa1b736b9a2507",
      "2ddd9fc857b549a4ba446dd64a1dd1d4"
     ]
    },
    "id": "immune-campbell",
    "outputId": "6b41528b-6e83-4946-cbd5-62621fd1ad43"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d944bc72a64c49229031034325f18608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 323\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "compressed-adoption",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f319feca977544738ff2400ab23a9276",
      "26b1a86ee1ff4ce2862c13d47be2b2d6",
      "9815ec90f12a4696a85db6dc629ec62a",
      "e032f2bf0bb241c2911087a6efe1ce0b",
      "19783f5141cb47f8aaa057fb01dda913",
      "953c495e9f64430cbdd9184bb0bd35cb",
      "7e210db5a5fe41f696351dc87d525ee4",
      "1ad701d95f084c98bd1bf0e9d7d498a9",
      "6d74dcf5002c4752af12a65c3aca2113",
      "1faca6dc4b0e43988d2f81cd209297be",
      "2c55e9e0223548fbbbe29b3e11e59d50"
     ]
    },
    "id": "northern-branch",
    "outputId": "82a35c47-ca3a-441a-ff12-3dc32603677d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dac59f944f14f4da7ab11cf9c884443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 28\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "human-housing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oriental-jacksonville",
    "outputId": "0ccfd10a-251f-49de-ce35-c4db182768ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 354\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "least-africa",
   "metadata": {
    "id": "flexible-trainer"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dedicated-boundary",
   "metadata": {
    "id": "stock-robertson"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-democracy",
   "metadata": {
    "id": "chemical-lucas"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "chicken-activation",
   "metadata": {
    "id": "animated-array"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\"\n",
    "            state_dict = torch.load(path)\n",
    "            itpt.load_state_dict(state_dict)\n",
    "            self.backbone = itpt.deberta\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-strand",
   "metadata": {
    "id": "thorough-bristol"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "different-narrow",
   "metadata": {
    "id": "n8Z5UnO9cCxW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65938\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "olive-pavilion",
   "metadata": {
    "id": "talented-quantity"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "crazy-oklahoma",
   "metadata": {
    "id": "figured-cooperative"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "clinical-story",
   "metadata": {
    "id": "played-pointer"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "other-wrapping",
   "metadata": {
    "id": "brazilian-nigeria"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    #model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False)\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    #criterion = FocalLoss(reduce=False)\n",
    "    best_score = -1 * np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-diesel",
   "metadata": {
    "id": "bearing-switch"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "logical-regular",
   "metadata": {
    "id": "desperate-crime"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    score = scoring(oof_df, th=0.5)\n",
    "    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n",
    "    best_thres = get_best_thres(oof_df)\n",
    "    score = scoring(oof_df, th=best_thres)\n",
    "    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=False)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            test_token_probs = inference_fn(test_dataloader, model, device)\n",
    "            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n",
    "            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_token_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "honest-brother",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f39640d290374992aa246753125a91de",
      "410c3733ee43430eb55278748d07bc45",
      "5292a911912d43c2b80919e486b99de9",
      "ce26114873ed4c96b5ea391a41b18f68",
      "bec237aed5184115b697ea257f7b0c9b",
      "3ca14e3fd6b84312b0af50a89d5ac7c1",
      "8234c7d9369644dea7e5c7e8fe436771",
      "5a3f361a320f480aa8a4115366073d32",
      "0f856d468c8a4c4c9c83b5b263745508",
      "490bfe688fe1419996b69f7de1cfee23",
      "789324d1692d4f478d5b95491b03fc22",
      "1193874a74974cc59982c8d5e3ced585",
      "84ea1506dcad4e01ad1cc35b76c0339a",
      "8e243ea82e59492fb5b845e51a56347a",
      "55ac42bee2ce4f00841b8bd49a7c552d",
      "2281dd4891c640a0b31c23976223f2ba",
      "6919ba0239084b04988e1de02316c76e",
      "548835fe547d4114bfd39e5fac680635",
      "5068fb514bf143ba812fe202c3e7a83d",
      "1e0d277fe44242e19e3bec17a1cb7280",
      "ab8e5c4cef00426fa0cf2fc25c51381a",
      "2b311e42f1294339a07248b31db0c26c",
      "fc3c6209df394eefa2df9ce8dbb56830",
      "3fb5b968d9ab4e88964b6b126c6023d9",
      "d240d13622c14726a5639d44ef2421ec",
      "9e66574c8c0343ffb0477891bfe5e892",
      "219090e2dd934c1296f12660ea69b161",
      "e7be4ec44f2a4183b295f486e250b414",
      "44650208feba4c118904c7efc9887532",
      "d1cd0285cfe34f188e9c779617d48448",
      "331b7288a5024ce3a5036af53eb75cec",
      "00419a15e9834e98b8a3459b62d01f8b",
      "05fdce5a55c1483a937d07a50bd9465e",
      "5536b7aaba7c41f28197e318b362ec75",
      "5ecd28892bb84432935145e27ac71de7",
      "3b50983bfae8445fa305d1edadd651af",
      "cdbf6aefee644006826f76e2f6722b07",
      "7c62f6a2b08c41a8bc3ecf2efa58c325",
      "8478e8bf8b6146b48e717b84c021e7ab",
      "b09413b459c8406882a16db62e8df9c0",
      "72a8b4ea52534d4e9feab6c6fdd72a77",
      "65d16c05424c4df0b79b5786be8bd5d1",
      "63aa4d26409d437fa76e5a156bb04791",
      "e48e5c946462499ab018748ccf80c5b5",
      "160e78a145894001b2a1295627d80df9",
      "008f77fefdba425ab2c755f515693e6f",
      "605151b49d7641a28ebd0ca083770c69",
      "8f8c8632070c4fa0a3182521f41e9c40",
      "dfb4641da88e47d3bafabbaa56bc6916",
      "537dee640701470c8fc3cc29e7940bee",
      "6dc964a8934744608f92a6af0f0f923f",
      "925a3ae98bd6488eb7cffdec89d768da",
      "d76610cad4f645f187b26f1b82733569",
      "b28fa99d1b1b4e4da668bcc50373e4cc",
      "b8554928c5f141de8dfb94c04c2dda03"
     ]
    },
    "id": "graduate-vision",
    "outputId": "2a3a96e3-9421-4bcd-d191-898f1c27a819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2849] Elapsed 0m 1s (remain 57m 7s) Loss: 1.0276(1.0276) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2849] Elapsed 0m 38s (remain 17m 20s) Loss: 0.3706(0.6608) Grad: 17613.2324  LR: 0.000000  \n",
      "Epoch: [1][200/2849] Elapsed 1m 15s (remain 16m 40s) Loss: 0.4644(0.6054) Grad: 26313.3301  LR: 0.000001  \n",
      "Epoch: [1][300/2849] Elapsed 1m 54s (remain 16m 12s) Loss: 0.3336(0.5346) Grad: 21105.5957  LR: 0.000001  \n",
      "Epoch: [1][400/2849] Elapsed 2m 33s (remain 15m 38s) Loss: 0.1872(0.4588) Grad: 12998.3584  LR: 0.000001  \n",
      "Epoch: [1][500/2849] Elapsed 3m 12s (remain 15m 0s) Loss: 0.0459(0.3867) Grad: 1008.8026  LR: 0.000002  \n",
      "Epoch: [1][600/2849] Elapsed 3m 49s (remain 14m 17s) Loss: 0.0503(0.3306) Grad: 568.4163  LR: 0.000002  \n",
      "Epoch: [1][700/2849] Elapsed 4m 26s (remain 13m 37s) Loss: 0.0907(0.2896) Grad: 1695.8649  LR: 0.000002  \n",
      "Epoch: [1][800/2849] Elapsed 5m 6s (remain 13m 2s) Loss: 0.0355(0.2583) Grad: 443.0050  LR: 0.000003  \n",
      "Epoch: [1][900/2849] Elapsed 5m 43s (remain 12m 22s) Loss: 0.0417(0.2344) Grad: 473.3349  LR: 0.000003  \n",
      "Epoch: [1][1000/2849] Elapsed 6m 20s (remain 11m 41s) Loss: 0.0172(0.2150) Grad: 726.0096  LR: 0.000004  \n",
      "Epoch: [1][1100/2849] Elapsed 6m 57s (remain 11m 3s) Loss: 0.0267(0.1990) Grad: 459.7395  LR: 0.000004  \n",
      "Epoch: [1][1200/2849] Elapsed 7m 36s (remain 10m 26s) Loss: 0.0388(0.1856) Grad: 652.5309  LR: 0.000004  \n",
      "Epoch: [1][1300/2849] Elapsed 8m 14s (remain 9m 48s) Loss: 0.0498(0.1742) Grad: 931.3953  LR: 0.000005  \n",
      "Epoch: [1][1400/2849] Elapsed 8m 54s (remain 9m 11s) Loss: 0.0529(0.1643) Grad: 1571.3835  LR: 0.000005  \n",
      "Epoch: [1][1500/2849] Elapsed 9m 35s (remain 8m 37s) Loss: 0.0322(0.1553) Grad: 1182.1503  LR: 0.000005  \n",
      "Epoch: [1][1600/2849] Elapsed 10m 14s (remain 7m 58s) Loss: 0.0145(0.1469) Grad: 1548.5117  LR: 0.000005  \n",
      "Epoch: [1][1700/2849] Elapsed 10m 52s (remain 7m 20s) Loss: 0.0057(0.1393) Grad: 540.2726  LR: 0.000005  \n",
      "Epoch: [1][1800/2849] Elapsed 11m 30s (remain 6m 41s) Loss: 0.0122(0.1324) Grad: 1403.6276  LR: 0.000005  \n",
      "Epoch: [1][1900/2849] Elapsed 12m 8s (remain 6m 3s) Loss: 0.0059(0.1262) Grad: 909.1487  LR: 0.000005  \n",
      "Epoch: [1][2000/2849] Elapsed 12m 47s (remain 5m 25s) Loss: 0.0069(0.1206) Grad: 1395.6808  LR: 0.000005  \n",
      "Epoch: [1][2100/2849] Elapsed 13m 25s (remain 4m 46s) Loss: 0.0137(0.1157) Grad: 2029.2800  LR: 0.000005  \n",
      "Epoch: [1][2200/2849] Elapsed 14m 3s (remain 4m 8s) Loss: 0.0269(0.1110) Grad: 3075.2759  LR: 0.000005  \n",
      "Epoch: [1][2300/2849] Elapsed 14m 41s (remain 3m 29s) Loss: 0.0078(0.1068) Grad: 2098.7964  LR: 0.000005  \n",
      "Epoch: [1][2400/2849] Elapsed 15m 19s (remain 2m 51s) Loss: 0.0066(0.1027) Grad: 2014.3232  LR: 0.000005  \n",
      "Epoch: [1][2500/2849] Elapsed 15m 57s (remain 2m 13s) Loss: 0.0163(0.0991) Grad: 3619.1616  LR: 0.000005  \n",
      "Epoch: [1][2600/2849] Elapsed 16m 35s (remain 1m 34s) Loss: 0.0048(0.0957) Grad: 624.3422  LR: 0.000005  \n",
      "Epoch: [1][2700/2849] Elapsed 17m 13s (remain 0m 56s) Loss: 0.0040(0.0925) Grad: 1230.3315  LR: 0.000005  \n",
      "Epoch: [1][2800/2849] Elapsed 17m 52s (remain 0m 18s) Loss: 0.0028(0.0896) Grad: 827.3087  LR: 0.000004  \n",
      "Epoch: [1][2848/2849] Elapsed 18m 11s (remain 0m 0s) Loss: 0.0384(0.0882) Grad: 3719.6118  LR: 0.000004  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 4m 54s) Loss: 0.0021(0.0021) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0049(0.0082) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0014(0.0088) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 30s) Loss: 0.0005(0.0095) \n",
      "EVAL: [400/726] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0053(0.0109) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0361(0.0111) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0074(0.0109) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0030(0.0104) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0010(0.0103) \n",
      "Epoch 1 - avg_train_loss: 0.0882  avg_val_loss: 0.0103  time: 1250s\n",
      "Epoch 1 - Score: 0.8167\n",
      "Epoch 1 - Save Best Score: 0.8167 Model\n",
      "Epoch: [2][0/2849] Elapsed 0m 0s (remain 26m 13s) Loss: 0.0044(0.0044) Grad: 36083.4375  LR: 0.000004  \n",
      "Epoch: [2][100/2849] Elapsed 0m 38s (remain 17m 18s) Loss: 0.0015(0.0084) Grad: 7620.9521  LR: 0.000004  \n",
      "Epoch: [2][200/2849] Elapsed 1m 16s (remain 16m 42s) Loss: 0.0110(0.0082) Grad: 50032.0195  LR: 0.000004  \n",
      "Epoch: [2][300/2849] Elapsed 1m 56s (remain 16m 28s) Loss: 0.0024(0.0081) Grad: 24087.7402  LR: 0.000004  \n",
      "Epoch: [2][400/2849] Elapsed 2m 36s (remain 15m 52s) Loss: 0.0030(0.0084) Grad: 20726.2031  LR: 0.000004  \n",
      "Epoch: [2][500/2849] Elapsed 3m 13s (remain 15m 8s) Loss: 0.0528(0.0086) Grad: 140697.8125  LR: 0.000004  \n",
      "Epoch: [2][600/2849] Elapsed 3m 51s (remain 14m 26s) Loss: 0.0055(0.0090) Grad: 13480.7090  LR: 0.000004  \n",
      "Epoch: [2][700/2849] Elapsed 4m 29s (remain 13m 45s) Loss: 0.0082(0.0093) Grad: 24686.1211  LR: 0.000004  \n",
      "Epoch: [2][800/2849] Elapsed 5m 6s (remain 13m 4s) Loss: 0.0027(0.0092) Grad: 9940.0635  LR: 0.000004  \n",
      "Epoch: [2][900/2849] Elapsed 5m 44s (remain 12m 24s) Loss: 0.0003(0.0092) Grad: 3062.9355  LR: 0.000004  \n",
      "Epoch: [2][1000/2849] Elapsed 6m 23s (remain 11m 47s) Loss: 0.0096(0.0094) Grad: 60922.1602  LR: 0.000004  \n",
      "Epoch: [2][1100/2849] Elapsed 7m 4s (remain 11m 13s) Loss: 0.0020(0.0093) Grad: 18228.9023  LR: 0.000004  \n",
      "Epoch: [2][1200/2849] Elapsed 7m 42s (remain 10m 33s) Loss: 0.0011(0.0093) Grad: 3070.1846  LR: 0.000004  \n",
      "Epoch: [2][1300/2849] Elapsed 8m 19s (remain 9m 54s) Loss: 0.0021(0.0091) Grad: 16811.8516  LR: 0.000004  \n",
      "Epoch: [2][1400/2849] Elapsed 8m 58s (remain 9m 16s) Loss: 0.0038(0.0091) Grad: 14531.4375  LR: 0.000004  \n",
      "Epoch: [2][1500/2849] Elapsed 9m 37s (remain 8m 39s) Loss: 0.0074(0.0092) Grad: 30513.6152  LR: 0.000004  \n",
      "Epoch: [2][1600/2849] Elapsed 10m 15s (remain 8m 0s) Loss: 0.0005(0.0092) Grad: 4588.9170  LR: 0.000004  \n",
      "Epoch: [2][1700/2849] Elapsed 10m 53s (remain 7m 21s) Loss: 0.0205(0.0092) Grad: 48328.5547  LR: 0.000004  \n",
      "Epoch: [2][1800/2849] Elapsed 11m 31s (remain 6m 42s) Loss: 0.0115(0.0091) Grad: 36137.2539  LR: 0.000004  \n",
      "Epoch: [2][1900/2849] Elapsed 12m 9s (remain 6m 3s) Loss: 0.0121(0.0092) Grad: 21829.2676  LR: 0.000004  \n",
      "Epoch: [2][2000/2849] Elapsed 12m 47s (remain 5m 25s) Loss: 0.0037(0.0092) Grad: 17498.4219  LR: 0.000004  \n",
      "Epoch: [2][2100/2849] Elapsed 13m 26s (remain 4m 47s) Loss: 0.0064(0.0092) Grad: 50292.0508  LR: 0.000004  \n",
      "Epoch: [2][2200/2849] Elapsed 14m 6s (remain 4m 9s) Loss: 0.0022(0.0092) Grad: 5914.0620  LR: 0.000004  \n",
      "Epoch: [2][2300/2849] Elapsed 14m 43s (remain 3m 30s) Loss: 0.0188(0.0092) Grad: 61130.4336  LR: 0.000004  \n",
      "Epoch: [2][2400/2849] Elapsed 15m 24s (remain 2m 52s) Loss: 0.0184(0.0092) Grad: 27838.5820  LR: 0.000004  \n",
      "Epoch: [2][2500/2849] Elapsed 16m 3s (remain 2m 14s) Loss: 0.0028(0.0092) Grad: 3273.0864  LR: 0.000003  \n",
      "Epoch: [2][2600/2849] Elapsed 16m 41s (remain 1m 35s) Loss: 0.0013(0.0092) Grad: 6705.1519  LR: 0.000003  \n",
      "Epoch: [2][2700/2849] Elapsed 17m 19s (remain 0m 56s) Loss: 0.0003(0.0092) Grad: 1805.0990  LR: 0.000003  \n",
      "Epoch: [2][2800/2849] Elapsed 17m 58s (remain 0m 18s) Loss: 0.0269(0.0091) Grad: 25840.5527  LR: 0.000003  \n",
      "Epoch: [2][2848/2849] Elapsed 18m 16s (remain 0m 0s) Loss: 0.0006(0.0091) Grad: 3239.4338  LR: 0.000003  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 4m 59s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0054(0.0085) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 52s) Loss: 0.0009(0.0096) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 30s) Loss: 0.0001(0.0096) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0032(0.0113) \n",
      "EVAL: [500/726] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0325(0.0113) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0069(0.0109) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0026(0.0103) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0002(0.0102) \n",
      "Epoch 2 - avg_train_loss: 0.0091  avg_val_loss: 0.0102  time: 1255s\n",
      "Epoch 2 - Score: 0.8450\n",
      "Epoch 2 - Save Best Score: 0.8450 Model\n",
      "Epoch: [3][0/2849] Elapsed 0m 0s (remain 30m 43s) Loss: 0.0002(0.0002) Grad: 1152.3153  LR: 0.000003  \n",
      "Epoch: [3][100/2849] Elapsed 0m 38s (remain 17m 28s) Loss: 0.0018(0.0086) Grad: 7913.7886  LR: 0.000003  \n",
      "Epoch: [3][200/2849] Elapsed 1m 16s (remain 16m 47s) Loss: 0.0075(0.0086) Grad: 27959.6895  LR: 0.000003  \n",
      "Epoch: [3][300/2849] Elapsed 1m 54s (remain 16m 10s) Loss: 0.0301(0.0081) Grad: 38905.5859  LR: 0.000003  \n",
      "Epoch: [3][400/2849] Elapsed 2m 34s (remain 15m 40s) Loss: 0.0142(0.0078) Grad: 55157.3008  LR: 0.000003  \n",
      "Epoch: [3][500/2849] Elapsed 3m 12s (remain 15m 3s) Loss: 0.0237(0.0081) Grad: 59610.6016  LR: 0.000003  \n",
      "Epoch: [3][600/2849] Elapsed 3m 50s (remain 14m 20s) Loss: 0.0003(0.0080) Grad: 1489.0571  LR: 0.000003  \n",
      "Epoch: [3][700/2849] Elapsed 4m 28s (remain 13m 43s) Loss: 0.0004(0.0080) Grad: 1939.4539  LR: 0.000003  \n",
      "Epoch: [3][800/2849] Elapsed 5m 7s (remain 13m 7s) Loss: 0.0115(0.0079) Grad: 69374.7266  LR: 0.000003  \n",
      "Epoch: [3][900/2849] Elapsed 5m 45s (remain 12m 27s) Loss: 0.0258(0.0078) Grad: 99497.2812  LR: 0.000003  \n",
      "Epoch: [3][1000/2849] Elapsed 6m 23s (remain 11m 47s) Loss: 0.0285(0.0077) Grad: 66440.5312  LR: 0.000003  \n",
      "Epoch: [3][1100/2849] Elapsed 7m 0s (remain 11m 7s) Loss: 0.0061(0.0077) Grad: 13033.6807  LR: 0.000003  \n",
      "Epoch: [3][1200/2849] Elapsed 7m 37s (remain 10m 27s) Loss: 0.0492(0.0078) Grad: 94313.0312  LR: 0.000003  \n",
      "Epoch: [3][1300/2849] Elapsed 8m 15s (remain 9m 49s) Loss: 0.0274(0.0078) Grad: 75251.0547  LR: 0.000003  \n",
      "Epoch: [3][1400/2849] Elapsed 8m 53s (remain 9m 11s) Loss: 0.0111(0.0079) Grad: 38803.4258  LR: 0.000003  \n",
      "Epoch: [3][1500/2849] Elapsed 9m 34s (remain 8m 35s) Loss: 0.0027(0.0080) Grad: 7688.2007  LR: 0.000003  \n",
      "Epoch: [3][1600/2849] Elapsed 10m 13s (remain 7m 58s) Loss: 0.0082(0.0080) Grad: 82121.0625  LR: 0.000003  \n",
      "Epoch: [3][1700/2849] Elapsed 10m 52s (remain 7m 20s) Loss: 0.0007(0.0080) Grad: 18254.3535  LR: 0.000003  \n",
      "Epoch: [3][1800/2849] Elapsed 11m 30s (remain 6m 41s) Loss: 0.0056(0.0081) Grad: 10799.9062  LR: 0.000003  \n",
      "Epoch: [3][1900/2849] Elapsed 12m 8s (remain 6m 3s) Loss: 0.0028(0.0081) Grad: 7685.6714  LR: 0.000003  \n",
      "Epoch: [3][2000/2849] Elapsed 12m 45s (remain 5m 24s) Loss: 0.0003(0.0080) Grad: 2313.4026  LR: 0.000003  \n",
      "Epoch: [3][2100/2849] Elapsed 13m 24s (remain 4m 46s) Loss: 0.0001(0.0080) Grad: 284.1078  LR: 0.000003  \n",
      "Epoch: [3][2200/2849] Elapsed 14m 2s (remain 4m 8s) Loss: 0.0002(0.0080) Grad: 1907.4081  LR: 0.000002  \n",
      "Epoch: [3][2300/2849] Elapsed 14m 40s (remain 3m 29s) Loss: 0.0004(0.0080) Grad: 2209.9309  LR: 0.000002  \n",
      "Epoch: [3][2400/2849] Elapsed 15m 19s (remain 2m 51s) Loss: 0.0016(0.0081) Grad: 5655.2661  LR: 0.000002  \n",
      "Epoch: [3][2500/2849] Elapsed 15m 57s (remain 2m 13s) Loss: 0.0039(0.0081) Grad: 13732.5166  LR: 0.000002  \n",
      "Epoch: [3][2600/2849] Elapsed 16m 35s (remain 1m 34s) Loss: 0.0388(0.0081) Grad: 68116.6328  LR: 0.000002  \n",
      "Epoch: [3][2700/2849] Elapsed 17m 13s (remain 0m 56s) Loss: 0.0133(0.0081) Grad: 21340.6523  LR: 0.000002  \n",
      "Epoch: [3][2800/2849] Elapsed 17m 53s (remain 0m 18s) Loss: 0.0014(0.0080) Grad: 9511.5762  LR: 0.000002  \n",
      "Epoch: [3][2848/2849] Elapsed 18m 12s (remain 0m 0s) Loss: 0.0078(0.0080) Grad: 27939.7656  LR: 0.000002  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 4m 48s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0055(0.0091) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0002(0.0093) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 30s) Loss: 0.0000(0.0093) \n",
      "EVAL: [400/726] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0038(0.0112) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0321(0.0112) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0041(0.0108) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0032(0.0102) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0001(0.0101) \n",
      "Epoch 3 - avg_train_loss: 0.0080  avg_val_loss: 0.0101  time: 1250s\n",
      "Epoch 3 - Score: 0.8566\n",
      "Epoch 3 - Save Best Score: 0.8566 Model\n",
      "Epoch: [4][0/2849] Elapsed 0m 0s (remain 28m 21s) Loss: 0.0047(0.0047) Grad: 8431.4844  LR: 0.000002  \n",
      "Epoch: [4][100/2849] Elapsed 0m 39s (remain 17m 47s) Loss: 0.0005(0.0068) Grad: 7362.2476  LR: 0.000002  \n",
      "Epoch: [4][200/2849] Elapsed 1m 19s (remain 17m 24s) Loss: 0.0424(0.0074) Grad: 25978.9141  LR: 0.000002  \n",
      "Epoch: [4][300/2849] Elapsed 1m 57s (remain 16m 35s) Loss: 0.0009(0.0077) Grad: 4628.7412  LR: 0.000002  \n",
      "Epoch: [4][400/2849] Elapsed 2m 35s (remain 15m 50s) Loss: 0.0038(0.0075) Grad: 14863.9795  LR: 0.000002  \n",
      "Epoch: [4][500/2849] Elapsed 3m 13s (remain 15m 7s) Loss: 0.0020(0.0072) Grad: 5448.9692  LR: 0.000002  \n",
      "Epoch: [4][600/2849] Elapsed 3m 51s (remain 14m 24s) Loss: 0.0030(0.0072) Grad: 8728.7832  LR: 0.000002  \n",
      "Epoch: [4][700/2849] Elapsed 4m 30s (remain 13m 49s) Loss: 0.0040(0.0073) Grad: 38772.9102  LR: 0.000002  \n",
      "Epoch: [4][800/2849] Elapsed 5m 9s (remain 13m 10s) Loss: 0.0072(0.0076) Grad: 11780.2305  LR: 0.000002  \n",
      "Epoch: [4][900/2849] Elapsed 5m 47s (remain 12m 30s) Loss: 0.0195(0.0077) Grad: 58583.8711  LR: 0.000002  \n",
      "Epoch: [4][1000/2849] Elapsed 6m 25s (remain 11m 50s) Loss: 0.0017(0.0076) Grad: 14460.5176  LR: 0.000002  \n",
      "Epoch: [4][1100/2849] Elapsed 7m 3s (remain 11m 12s) Loss: 0.0152(0.0076) Grad: 70315.5781  LR: 0.000002  \n",
      "Epoch: [4][1200/2849] Elapsed 7m 41s (remain 10m 33s) Loss: 0.0039(0.0077) Grad: 48813.5391  LR: 0.000002  \n",
      "Epoch: [4][1300/2849] Elapsed 8m 20s (remain 9m 55s) Loss: 0.0001(0.0078) Grad: 246.2607  LR: 0.000002  \n",
      "Epoch: [4][1400/2849] Elapsed 9m 1s (remain 9m 20s) Loss: 0.0002(0.0076) Grad: 2092.5994  LR: 0.000002  \n",
      "Epoch: [4][1500/2849] Elapsed 9m 39s (remain 8m 40s) Loss: 0.0001(0.0078) Grad: 2104.4478  LR: 0.000002  \n",
      "Epoch: [4][1600/2849] Elapsed 10m 17s (remain 8m 1s) Loss: 0.0167(0.0077) Grad: 56288.0273  LR: 0.000002  \n",
      "Epoch: [4][1700/2849] Elapsed 10m 55s (remain 7m 22s) Loss: 0.0001(0.0077) Grad: 693.2003  LR: 0.000002  \n",
      "Epoch: [4][1800/2849] Elapsed 11m 34s (remain 6m 44s) Loss: 0.0017(0.0076) Grad: 9652.8076  LR: 0.000002  \n",
      "Epoch: [4][1900/2849] Elapsed 12m 12s (remain 6m 5s) Loss: 0.0072(0.0075) Grad: 56300.1641  LR: 0.000001  \n",
      "Epoch: [4][2000/2849] Elapsed 12m 50s (remain 5m 26s) Loss: 0.0000(0.0074) Grad: 92.4393  LR: 0.000001  \n",
      "Epoch: [4][2100/2849] Elapsed 13m 31s (remain 4m 48s) Loss: 0.0001(0.0074) Grad: 1248.4578  LR: 0.000001  \n",
      "Epoch: [4][2200/2849] Elapsed 14m 9s (remain 4m 10s) Loss: 0.0106(0.0074) Grad: 34549.8398  LR: 0.000001  \n",
      "Epoch: [4][2300/2849] Elapsed 14m 46s (remain 3m 31s) Loss: 0.0001(0.0073) Grad: 438.9936  LR: 0.000001  \n",
      "Epoch: [4][2400/2849] Elapsed 15m 25s (remain 2m 52s) Loss: 0.0152(0.0073) Grad: 90944.9609  LR: 0.000001  \n",
      "Epoch: [4][2500/2849] Elapsed 16m 3s (remain 2m 14s) Loss: 0.0071(0.0073) Grad: 24548.6875  LR: 0.000001  \n",
      "Epoch: [4][2600/2849] Elapsed 16m 43s (remain 1m 35s) Loss: 0.0116(0.0073) Grad: 63149.7422  LR: 0.000001  \n",
      "Epoch: [4][2700/2849] Elapsed 17m 21s (remain 0m 57s) Loss: 0.0124(0.0073) Grad: 50238.3945  LR: 0.000001  \n",
      "Epoch: [4][2800/2849] Elapsed 17m 59s (remain 0m 18s) Loss: 0.0026(0.0074) Grad: 22546.3145  LR: 0.000001  \n",
      "Epoch: [4][2848/2849] Elapsed 18m 17s (remain 0m 0s) Loss: 0.0374(0.0074) Grad: 75090.2969  LR: 0.000001  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 4m 32s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0072(0.0090) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0002(0.0093) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0000(0.0093) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0029(0.0110) \n",
      "EVAL: [500/726] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0342(0.0110) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0080(0.0106) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0024(0.0100) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0001(0.0098) \n",
      "Epoch 4 - avg_train_loss: 0.0074  avg_val_loss: 0.0098  time: 1256s\n",
      "Epoch 4 - Score: 0.8569\n",
      "Epoch 4 - Save Best Score: 0.8569 Model\n",
      "Epoch: [5][0/2849] Elapsed 0m 0s (remain 26m 51s) Loss: 0.0013(0.0013) Grad: 4345.3115  LR: 0.000001  \n",
      "Epoch: [5][100/2849] Elapsed 0m 38s (remain 17m 32s) Loss: 0.0013(0.0058) Grad: 9356.8555  LR: 0.000001  \n",
      "Epoch: [5][200/2849] Elapsed 1m 16s (remain 16m 49s) Loss: 0.0000(0.0061) Grad: 230.0855  LR: 0.000001  \n",
      "Epoch: [5][300/2849] Elapsed 1m 54s (remain 16m 12s) Loss: 0.0001(0.0057) Grad: 2424.4453  LR: 0.000001  \n",
      "Epoch: [5][400/2849] Elapsed 2m 33s (remain 15m 38s) Loss: 0.0313(0.0066) Grad: 101270.1562  LR: 0.000001  \n",
      "Epoch: [5][500/2849] Elapsed 3m 11s (remain 14m 58s) Loss: 0.0001(0.0069) Grad: 997.0714  LR: 0.000001  \n",
      "Epoch: [5][600/2849] Elapsed 3m 49s (remain 14m 18s) Loss: 0.0020(0.0069) Grad: 10788.8008  LR: 0.000001  \n",
      "Epoch: [5][700/2849] Elapsed 4m 27s (remain 13m 39s) Loss: 0.0037(0.0071) Grad: 6126.3711  LR: 0.000001  \n",
      "Epoch: [5][800/2849] Elapsed 5m 6s (remain 13m 2s) Loss: 0.0041(0.0071) Grad: 16508.8828  LR: 0.000001  \n",
      "Epoch: [5][900/2849] Elapsed 5m 44s (remain 12m 25s) Loss: 0.0002(0.0069) Grad: 1518.7042  LR: 0.000001  \n",
      "Epoch: [5][1000/2849] Elapsed 6m 22s (remain 11m 46s) Loss: 0.0027(0.0069) Grad: 7415.3555  LR: 0.000001  \n",
      "Epoch: [5][1100/2849] Elapsed 7m 0s (remain 11m 7s) Loss: 0.0004(0.0069) Grad: 2172.8799  LR: 0.000001  \n",
      "Epoch: [5][1200/2849] Elapsed 7m 38s (remain 10m 29s) Loss: 0.0002(0.0068) Grad: 1703.3315  LR: 0.000001  \n",
      "Epoch: [5][1300/2849] Elapsed 8m 17s (remain 9m 51s) Loss: 0.0026(0.0070) Grad: 35498.1953  LR: 0.000001  \n",
      "Epoch: [5][1400/2849] Elapsed 8m 55s (remain 9m 13s) Loss: 0.0150(0.0070) Grad: 76715.5469  LR: 0.000001  \n",
      "Epoch: [5][1500/2849] Elapsed 9m 33s (remain 8m 35s) Loss: 0.0147(0.0070) Grad: 31648.3945  LR: 0.000001  \n",
      "Epoch: [5][1600/2849] Elapsed 10m 13s (remain 7m 57s) Loss: 0.0001(0.0070) Grad: 376.1346  LR: 0.000000  \n",
      "Epoch: [5][1700/2849] Elapsed 10m 52s (remain 7m 20s) Loss: 0.0105(0.0070) Grad: 22880.2988  LR: 0.000000  \n",
      "Epoch: [5][1800/2849] Elapsed 11m 30s (remain 6m 41s) Loss: 0.0000(0.0068) Grad: 488.4670  LR: 0.000000  \n",
      "Epoch: [5][1900/2849] Elapsed 12m 8s (remain 6m 3s) Loss: 0.0037(0.0067) Grad: 12575.0898  LR: 0.000000  \n",
      "Epoch: [5][2000/2849] Elapsed 12m 47s (remain 5m 25s) Loss: 0.0046(0.0069) Grad: 23463.5059  LR: 0.000000  \n",
      "Epoch: [5][2100/2849] Elapsed 13m 26s (remain 4m 47s) Loss: 0.0070(0.0069) Grad: 11641.5684  LR: 0.000000  \n",
      "Epoch: [5][2200/2849] Elapsed 14m 4s (remain 4m 8s) Loss: 0.0000(0.0069) Grad: 47.1961  LR: 0.000000  \n",
      "Epoch: [5][2300/2849] Elapsed 14m 42s (remain 3m 30s) Loss: 0.0004(0.0069) Grad: 4488.5879  LR: 0.000000  \n",
      "Epoch: [5][2400/2849] Elapsed 15m 21s (remain 2m 51s) Loss: 0.0009(0.0069) Grad: 10204.6924  LR: 0.000000  \n",
      "Epoch: [5][2500/2849] Elapsed 15m 59s (remain 2m 13s) Loss: 0.0000(0.0070) Grad: 186.6289  LR: 0.000000  \n",
      "Epoch: [5][2600/2849] Elapsed 16m 37s (remain 1m 35s) Loss: 0.0176(0.0071) Grad: 16178.7754  LR: 0.000000  \n",
      "Epoch: [5][2700/2849] Elapsed 17m 16s (remain 0m 56s) Loss: 0.0003(0.0070) Grad: 3758.2878  LR: 0.000000  \n",
      "Epoch: [5][2800/2849] Elapsed 17m 54s (remain 0m 18s) Loss: 0.0045(0.0071) Grad: 23368.7266  LR: 0.000000  \n",
      "Epoch: [5][2848/2849] Elapsed 18m 12s (remain 0m 0s) Loss: 0.0028(0.0070) Grad: 6584.3555  LR: 0.000000  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 25s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0073(0.0093) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0001(0.0095) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 30s) Loss: 0.0000(0.0096) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0027(0.0113) \n",
      "EVAL: [500/726] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0355(0.0114) \n",
      "EVAL: [600/726] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0087(0.0109) \n",
      "EVAL: [700/726] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0043(0.0104) \n",
      "EVAL: [725/726] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0001(0.0102) \n",
      "Epoch 5 - avg_train_loss: 0.0070  avg_val_loss: 0.0102  time: 1251s\n",
      "Epoch 5 - Score: 0.8571\n",
      "Epoch 5 - Save Best Score: 0.8571 Model\n",
      "========== fold: 1 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2851] Elapsed 0m 0s (remain 28m 46s) Loss: 0.4919(0.4919) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2851] Elapsed 0m 38s (remain 17m 31s) Loss: 0.3240(0.5235) Grad: 34648.5703  LR: 0.000000  \n",
      "Epoch: [1][200/2851] Elapsed 1m 17s (remain 16m 59s) Loss: 0.3713(0.4906) Grad: 43711.4922  LR: 0.000001  \n",
      "Epoch: [1][300/2851] Elapsed 1m 55s (remain 16m 21s) Loss: 0.2726(0.4390) Grad: 31272.1133  LR: 0.000001  \n",
      "Epoch: [1][400/2851] Elapsed 2m 34s (remain 15m 41s) Loss: 0.1287(0.3800) Grad: 13849.8623  LR: 0.000001  \n",
      "Epoch: [1][500/2851] Elapsed 3m 11s (remain 15m 0s) Loss: 0.1000(0.3245) Grad: 1755.8358  LR: 0.000002  \n",
      "Epoch: [1][600/2851] Elapsed 3m 50s (remain 14m 21s) Loss: 0.0594(0.2781) Grad: 1499.5491  LR: 0.000002  \n",
      "Epoch: [1][700/2851] Elapsed 4m 28s (remain 13m 44s) Loss: 0.0346(0.2442) Grad: 817.6384  LR: 0.000002  \n",
      "Epoch: [1][800/2851] Elapsed 5m 8s (remain 13m 8s) Loss: 0.0120(0.2188) Grad: 2338.9854  LR: 0.000003  \n",
      "Epoch: [1][900/2851] Elapsed 5m 48s (remain 12m 33s) Loss: 0.0609(0.1989) Grad: 2061.6042  LR: 0.000003  \n",
      "Epoch: [1][1000/2851] Elapsed 6m 25s (remain 11m 53s) Loss: 0.0218(0.1830) Grad: 1253.2747  LR: 0.000004  \n",
      "Epoch: [1][1100/2851] Elapsed 7m 4s (remain 11m 14s) Loss: 0.0254(0.1700) Grad: 768.4443  LR: 0.000004  \n",
      "Epoch: [1][1200/2851] Elapsed 7m 42s (remain 10m 34s) Loss: 0.0614(0.1589) Grad: 2409.5278  LR: 0.000004  \n",
      "Epoch: [1][1300/2851] Elapsed 8m 19s (remain 9m 55s) Loss: 0.0717(0.1496) Grad: 2646.1697  LR: 0.000005  \n",
      "Epoch: [1][1400/2851] Elapsed 8m 57s (remain 9m 16s) Loss: 0.0117(0.1414) Grad: 1262.5731  LR: 0.000005  \n",
      "Epoch: [1][1500/2851] Elapsed 9m 35s (remain 8m 37s) Loss: 0.0904(0.1343) Grad: 6929.6631  LR: 0.000005  \n",
      "Epoch: [1][1600/2851] Elapsed 10m 13s (remain 7m 59s) Loss: 0.0078(0.1274) Grad: 922.6896  LR: 0.000005  \n",
      "Epoch: [1][1700/2851] Elapsed 10m 51s (remain 7m 20s) Loss: 0.0066(0.1211) Grad: 2492.3511  LR: 0.000005  \n",
      "Epoch: [1][1800/2851] Elapsed 11m 29s (remain 6m 42s) Loss: 0.0134(0.1155) Grad: 2977.8325  LR: 0.000005  \n",
      "Epoch: [1][1900/2851] Elapsed 12m 7s (remain 6m 3s) Loss: 0.0104(0.1103) Grad: 2246.2520  LR: 0.000005  \n",
      "Epoch: [1][2000/2851] Elapsed 12m 45s (remain 5m 25s) Loss: 0.0351(0.1056) Grad: 3575.6221  LR: 0.000005  \n",
      "Epoch: [1][2100/2851] Elapsed 13m 24s (remain 4m 47s) Loss: 0.0044(0.1012) Grad: 3747.9241  LR: 0.000005  \n",
      "Epoch: [1][2200/2851] Elapsed 14m 2s (remain 4m 8s) Loss: 0.0637(0.0972) Grad: 10323.6201  LR: 0.000005  \n",
      "Epoch: [1][2300/2851] Elapsed 14m 40s (remain 3m 30s) Loss: 0.0026(0.0935) Grad: 572.3487  LR: 0.000005  \n",
      "Epoch: [1][2400/2851] Elapsed 15m 17s (remain 2m 51s) Loss: 0.0072(0.0901) Grad: 2420.3953  LR: 0.000005  \n",
      "Epoch: [1][2500/2851] Elapsed 15m 55s (remain 2m 13s) Loss: 0.0102(0.0870) Grad: 2996.5200  LR: 0.000005  \n",
      "Epoch: [1][2600/2851] Elapsed 16m 34s (remain 1m 35s) Loss: 0.0059(0.0840) Grad: 2069.7651  LR: 0.000005  \n",
      "Epoch: [1][2700/2851] Elapsed 17m 12s (remain 0m 57s) Loss: 0.0190(0.0813) Grad: 4563.1841  LR: 0.000005  \n",
      "Epoch: [1][2800/2851] Elapsed 17m 50s (remain 0m 19s) Loss: 0.0040(0.0788) Grad: 1145.7289  LR: 0.000004  \n",
      "Epoch: [1][2850/2851] Elapsed 18m 9s (remain 0m 0s) Loss: 0.0055(0.0776) Grad: 1989.9521  LR: 0.000004  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 9s) Loss: 0.0033(0.0033) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0024(0.0096) \n",
      "EVAL: [200/724] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0008(0.0108) \n",
      "EVAL: [300/724] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0032(0.0103) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0006(0.0108) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0084(0.0116) \n",
      "EVAL: [600/724] Elapsed 2m 9s (remain 0m 26s) Loss: 0.0020(0.0113) \n",
      "EVAL: [700/724] Elapsed 2m 29s (remain 0m 4s) Loss: 0.0007(0.0109) \n",
      "EVAL: [723/724] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0022(0.0107) \n",
      "Epoch 1 - avg_train_loss: 0.0776  avg_val_loss: 0.0107  time: 1249s\n",
      "Epoch 1 - Score: 0.8070\n",
      "Epoch 1 - Save Best Score: 0.8070 Model\n",
      "Epoch: [2][0/2851] Elapsed 0m 0s (remain 25m 40s) Loss: 0.0110(0.0110) Grad: 40445.8047  LR: 0.000004  \n",
      "Epoch: [2][100/2851] Elapsed 0m 38s (remain 17m 27s) Loss: 0.0191(0.0114) Grad: 33865.0352  LR: 0.000004  \n",
      "Epoch: [2][200/2851] Elapsed 1m 17s (remain 17m 1s) Loss: 0.0030(0.0115) Grad: 10558.4141  LR: 0.000004  \n",
      "Epoch: [2][300/2851] Elapsed 1m 57s (remain 16m 35s) Loss: 0.0047(0.0113) Grad: 16886.9473  LR: 0.000004  \n",
      "Epoch: [2][400/2851] Elapsed 2m 35s (remain 15m 50s) Loss: 0.0020(0.0111) Grad: 4763.1484  LR: 0.000004  \n",
      "Epoch: [2][500/2851] Elapsed 3m 13s (remain 15m 6s) Loss: 0.1022(0.0109) Grad: 56909.7891  LR: 0.000004  \n",
      "Epoch: [2][600/2851] Elapsed 3m 51s (remain 14m 26s) Loss: 0.0070(0.0103) Grad: 18760.1855  LR: 0.000004  \n",
      "Epoch: [2][700/2851] Elapsed 4m 29s (remain 13m 47s) Loss: 0.0014(0.0103) Grad: 10132.4258  LR: 0.000004  \n",
      "Epoch: [2][800/2851] Elapsed 5m 7s (remain 13m 7s) Loss: 0.0005(0.0103) Grad: 5743.1855  LR: 0.000004  \n",
      "Epoch: [2][900/2851] Elapsed 5m 46s (remain 12m 29s) Loss: 0.0009(0.0104) Grad: 2447.4722  LR: 0.000004  \n",
      "Epoch: [2][1000/2851] Elapsed 6m 24s (remain 11m 51s) Loss: 0.0070(0.0102) Grad: 24457.1641  LR: 0.000004  \n",
      "Epoch: [2][1100/2851] Elapsed 7m 2s (remain 11m 11s) Loss: 0.0043(0.0101) Grad: 14198.0742  LR: 0.000004  \n",
      "Epoch: [2][1200/2851] Elapsed 7m 42s (remain 10m 35s) Loss: 0.0062(0.0100) Grad: 13729.9160  LR: 0.000004  \n",
      "Epoch: [2][1300/2851] Elapsed 8m 20s (remain 9m 56s) Loss: 0.0181(0.0098) Grad: 46667.7500  LR: 0.000004  \n",
      "Epoch: [2][1400/2851] Elapsed 8m 58s (remain 9m 17s) Loss: 0.0111(0.0098) Grad: 19794.2852  LR: 0.000004  \n",
      "Epoch: [2][1500/2851] Elapsed 9m 36s (remain 8m 38s) Loss: 0.0046(0.0098) Grad: 18229.2852  LR: 0.000004  \n",
      "Epoch: [2][1600/2851] Elapsed 10m 15s (remain 8m 0s) Loss: 0.0028(0.0098) Grad: 10450.3438  LR: 0.000004  \n",
      "Epoch: [2][1700/2851] Elapsed 10m 53s (remain 7m 22s) Loss: 0.0002(0.0097) Grad: 1624.7913  LR: 0.000004  \n",
      "Epoch: [2][1800/2851] Elapsed 11m 31s (remain 6m 43s) Loss: 0.0126(0.0096) Grad: 15579.2227  LR: 0.000004  \n",
      "Epoch: [2][1900/2851] Elapsed 12m 9s (remain 6m 4s) Loss: 0.0040(0.0096) Grad: 31632.9062  LR: 0.000004  \n",
      "Epoch: [2][2000/2851] Elapsed 12m 50s (remain 5m 27s) Loss: 0.0085(0.0095) Grad: 39424.2266  LR: 0.000004  \n",
      "Epoch: [2][2100/2851] Elapsed 13m 28s (remain 4m 48s) Loss: 0.0151(0.0095) Grad: 34924.1484  LR: 0.000004  \n",
      "Epoch: [2][2200/2851] Elapsed 14m 5s (remain 4m 9s) Loss: 0.0116(0.0094) Grad: 71852.5547  LR: 0.000004  \n",
      "Epoch: [2][2300/2851] Elapsed 14m 44s (remain 3m 31s) Loss: 0.0072(0.0095) Grad: 23825.3086  LR: 0.000004  \n",
      "Epoch: [2][2400/2851] Elapsed 15m 23s (remain 2m 53s) Loss: 0.0059(0.0094) Grad: 33079.5039  LR: 0.000004  \n",
      "Epoch: [2][2500/2851] Elapsed 16m 1s (remain 2m 14s) Loss: 0.0037(0.0095) Grad: 6510.3467  LR: 0.000003  \n",
      "Epoch: [2][2600/2851] Elapsed 16m 39s (remain 1m 36s) Loss: 0.0057(0.0095) Grad: 10043.3359  LR: 0.000003  \n",
      "Epoch: [2][2700/2851] Elapsed 17m 17s (remain 0m 57s) Loss: 0.0107(0.0094) Grad: 31513.1934  LR: 0.000003  \n",
      "Epoch: [2][2800/2851] Elapsed 17m 54s (remain 0m 19s) Loss: 0.0036(0.0095) Grad: 17908.6465  LR: 0.000003  \n",
      "Epoch: [2][2850/2851] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0085(0.0094) Grad: 81955.6016  LR: 0.000003  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 6s) Loss: 0.0014(0.0014) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0010(0.0074) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0001(0.0098) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 29s) Loss: 0.0002(0.0094) \n",
      "EVAL: [400/724] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0001(0.0095) \n",
      "EVAL: [500/724] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0079(0.0103) \n",
      "EVAL: [600/724] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0041(0.0100) \n",
      "EVAL: [700/724] Elapsed 2m 28s (remain 0m 4s) Loss: 0.0001(0.0093) \n",
      "EVAL: [723/724] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0004(0.0092) \n",
      "Epoch 2 - avg_train_loss: 0.0094  avg_val_loss: 0.0092  time: 1252s\n",
      "Epoch 2 - Score: 0.8432\n",
      "Epoch 2 - Save Best Score: 0.8432 Model\n",
      "Epoch: [3][0/2851] Elapsed 0m 0s (remain 30m 19s) Loss: 0.0103(0.0103) Grad: 27909.5801  LR: 0.000003  \n",
      "Epoch: [3][100/2851] Elapsed 0m 38s (remain 17m 33s) Loss: 0.0003(0.0069) Grad: 938.5949  LR: 0.000003  \n",
      "Epoch: [3][200/2851] Elapsed 1m 16s (remain 16m 49s) Loss: 0.0016(0.0072) Grad: 7396.1362  LR: 0.000003  \n",
      "Epoch: [3][300/2851] Elapsed 1m 54s (remain 16m 8s) Loss: 0.0066(0.0076) Grad: 34293.7656  LR: 0.000003  \n",
      "Epoch: [3][400/2851] Elapsed 2m 33s (remain 15m 37s) Loss: 0.0000(0.0076) Grad: 237.9586  LR: 0.000003  \n",
      "Epoch: [3][500/2851] Elapsed 3m 12s (remain 15m 2s) Loss: 0.0003(0.0078) Grad: 1902.7750  LR: 0.000003  \n",
      "Epoch: [3][600/2851] Elapsed 3m 50s (remain 14m 22s) Loss: 0.0263(0.0083) Grad: 57916.5117  LR: 0.000003  \n",
      "Epoch: [3][700/2851] Elapsed 4m 28s (remain 13m 42s) Loss: 0.0142(0.0085) Grad: 60472.9727  LR: 0.000003  \n",
      "Epoch: [3][800/2851] Elapsed 5m 6s (remain 13m 3s) Loss: 0.0101(0.0086) Grad: 25639.4316  LR: 0.000003  \n",
      "Epoch: [3][900/2851] Elapsed 5m 46s (remain 12m 29s) Loss: 0.0210(0.0085) Grad: 60267.9219  LR: 0.000003  \n",
      "Epoch: [3][1000/2851] Elapsed 6m 24s (remain 11m 51s) Loss: 0.0013(0.0085) Grad: 3679.6294  LR: 0.000003  \n",
      "Epoch: [3][1100/2851] Elapsed 7m 3s (remain 11m 12s) Loss: 0.0019(0.0084) Grad: 9613.6436  LR: 0.000003  \n",
      "Epoch: [3][1200/2851] Elapsed 7m 41s (remain 10m 33s) Loss: 0.0006(0.0085) Grad: 7331.1621  LR: 0.000003  \n",
      "Epoch: [3][1300/2851] Elapsed 8m 18s (remain 9m 54s) Loss: 0.0010(0.0084) Grad: 6571.6274  LR: 0.000003  \n",
      "Epoch: [3][1400/2851] Elapsed 8m 56s (remain 9m 15s) Loss: 0.0214(0.0083) Grad: 28411.8340  LR: 0.000003  \n",
      "Epoch: [3][1500/2851] Elapsed 9m 34s (remain 8m 36s) Loss: 0.0003(0.0084) Grad: 1910.2267  LR: 0.000003  \n",
      "Epoch: [3][1600/2851] Elapsed 10m 15s (remain 8m 0s) Loss: 0.0137(0.0083) Grad: 19376.1270  LR: 0.000003  \n",
      "Epoch: [3][1700/2851] Elapsed 10m 52s (remain 7m 21s) Loss: 0.0049(0.0082) Grad: 61253.9414  LR: 0.000003  \n",
      "Epoch: [3][1800/2851] Elapsed 11m 31s (remain 6m 42s) Loss: 0.0006(0.0083) Grad: 2431.0117  LR: 0.000003  \n",
      "Epoch: [3][1900/2851] Elapsed 12m 9s (remain 6m 4s) Loss: 0.0009(0.0083) Grad: 4995.7363  LR: 0.000003  \n",
      "Epoch: [3][2000/2851] Elapsed 12m 48s (remain 5m 26s) Loss: 0.0002(0.0082) Grad: 1049.3593  LR: 0.000003  \n",
      "Epoch: [3][2100/2851] Elapsed 13m 26s (remain 4m 47s) Loss: 0.0107(0.0082) Grad: 30874.3887  LR: 0.000003  \n",
      "Epoch: [3][2200/2851] Elapsed 14m 5s (remain 4m 9s) Loss: 0.0018(0.0081) Grad: 9010.3408  LR: 0.000002  \n",
      "Epoch: [3][2300/2851] Elapsed 14m 42s (remain 3m 31s) Loss: 0.0091(0.0082) Grad: 15654.4346  LR: 0.000002  \n",
      "Epoch: [3][2400/2851] Elapsed 15m 21s (remain 2m 52s) Loss: 0.0430(0.0082) Grad: 29538.8281  LR: 0.000002  \n",
      "Epoch: [3][2500/2851] Elapsed 16m 0s (remain 2m 14s) Loss: 0.0021(0.0082) Grad: 9626.7480  LR: 0.000002  \n",
      "Epoch: [3][2600/2851] Elapsed 16m 38s (remain 1m 35s) Loss: 0.0011(0.0082) Grad: 7797.1724  LR: 0.000002  \n",
      "Epoch: [3][2700/2851] Elapsed 17m 17s (remain 0m 57s) Loss: 0.0009(0.0081) Grad: 3475.3928  LR: 0.000002  \n",
      "Epoch: [3][2800/2851] Elapsed 17m 55s (remain 0m 19s) Loss: 0.0065(0.0081) Grad: 20833.5469  LR: 0.000002  \n",
      "Epoch: [3][2850/2851] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0010(0.0081) Grad: 7058.6592  LR: 0.000002  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 8s) Loss: 0.0010(0.0010) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0011(0.0068) \n",
      "EVAL: [200/724] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0001(0.0094) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0001(0.0091) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0000(0.0092) \n",
      "EVAL: [500/724] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0136(0.0103) \n",
      "EVAL: [600/724] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0048(0.0099) \n",
      "EVAL: [700/724] Elapsed 2m 28s (remain 0m 4s) Loss: 0.0000(0.0091) \n",
      "EVAL: [723/724] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0003(0.0090) \n",
      "Epoch 3 - avg_train_loss: 0.0081  avg_val_loss: 0.0090  time: 1252s\n",
      "Epoch 3 - Score: 0.8640\n",
      "Epoch 3 - Save Best Score: 0.8640 Model\n",
      "Epoch: [4][0/2851] Elapsed 0m 0s (remain 30m 51s) Loss: 0.0086(0.0086) Grad: 34329.7227  LR: 0.000002  \n",
      "Epoch: [4][100/2851] Elapsed 0m 38s (remain 17m 31s) Loss: 0.0023(0.0067) Grad: 10602.5898  LR: 0.000002  \n",
      "Epoch: [4][200/2851] Elapsed 1m 16s (remain 16m 43s) Loss: 0.0007(0.0068) Grad: 6909.3447  LR: 0.000002  \n",
      "Epoch: [4][300/2851] Elapsed 1m 53s (remain 16m 4s) Loss: 0.0058(0.0066) Grad: 16093.2891  LR: 0.000002  \n",
      "Epoch: [4][400/2851] Elapsed 2m 32s (remain 15m 30s) Loss: 0.0002(0.0065) Grad: 1287.0769  LR: 0.000002  \n",
      "Epoch: [4][500/2851] Elapsed 3m 12s (remain 15m 3s) Loss: 0.0006(0.0066) Grad: 2691.0706  LR: 0.000002  \n",
      "Epoch: [4][600/2851] Elapsed 3m 50s (remain 14m 22s) Loss: 0.0086(0.0071) Grad: 29951.6406  LR: 0.000002  \n",
      "Epoch: [4][700/2851] Elapsed 4m 28s (remain 13m 43s) Loss: 0.0017(0.0071) Grad: 9596.7588  LR: 0.000002  \n",
      "Epoch: [4][800/2851] Elapsed 5m 6s (remain 13m 4s) Loss: 0.0038(0.0073) Grad: 18524.2734  LR: 0.000002  \n",
      "Epoch: [4][900/2851] Elapsed 5m 44s (remain 12m 26s) Loss: 0.0005(0.0076) Grad: 3949.7581  LR: 0.000002  \n",
      "Epoch: [4][1000/2851] Elapsed 6m 22s (remain 11m 47s) Loss: 0.0075(0.0078) Grad: 22081.2461  LR: 0.000002  \n",
      "Epoch: [4][1100/2851] Elapsed 7m 0s (remain 11m 8s) Loss: 0.0003(0.0076) Grad: 870.8835  LR: 0.000002  \n",
      "Epoch: [4][1200/2851] Elapsed 7m 38s (remain 10m 29s) Loss: 0.0055(0.0077) Grad: 35843.7695  LR: 0.000002  \n",
      "Epoch: [4][1300/2851] Elapsed 8m 17s (remain 9m 52s) Loss: 0.0001(0.0076) Grad: 299.1907  LR: 0.000002  \n",
      "Epoch: [4][1400/2851] Elapsed 8m 56s (remain 9m 14s) Loss: 0.0004(0.0077) Grad: 2127.5439  LR: 0.000002  \n",
      "Epoch: [4][1500/2851] Elapsed 9m 34s (remain 8m 36s) Loss: 0.0076(0.0076) Grad: 29081.8203  LR: 0.000002  \n",
      "Epoch: [4][1600/2851] Elapsed 10m 11s (remain 7m 57s) Loss: 0.0149(0.0076) Grad: 54880.3711  LR: 0.000002  \n",
      "Epoch: [4][1700/2851] Elapsed 10m 50s (remain 7m 19s) Loss: 0.0007(0.0076) Grad: 6156.7817  LR: 0.000002  \n",
      "Epoch: [4][1800/2851] Elapsed 11m 30s (remain 6m 42s) Loss: 0.0070(0.0077) Grad: 152332.0938  LR: 0.000002  \n",
      "Epoch: [4][1900/2851] Elapsed 12m 11s (remain 6m 5s) Loss: 0.0041(0.0076) Grad: 13645.9023  LR: 0.000001  \n",
      "Epoch: [4][2000/2851] Elapsed 12m 50s (remain 5m 27s) Loss: 0.0111(0.0076) Grad: 42618.4805  LR: 0.000001  \n",
      "Epoch: [4][2100/2851] Elapsed 13m 27s (remain 4m 48s) Loss: 0.0279(0.0076) Grad: 83589.9062  LR: 0.000001  \n",
      "Epoch: [4][2200/2851] Elapsed 14m 5s (remain 4m 9s) Loss: 0.0203(0.0075) Grad: 32574.2363  LR: 0.000001  \n",
      "Epoch: [4][2300/2851] Elapsed 14m 44s (remain 3m 31s) Loss: 0.0045(0.0074) Grad: 13252.1455  LR: 0.000001  \n",
      "Epoch: [4][2400/2851] Elapsed 15m 22s (remain 2m 52s) Loss: 0.0027(0.0074) Grad: 15317.4512  LR: 0.000001  \n",
      "Epoch: [4][2500/2851] Elapsed 16m 0s (remain 2m 14s) Loss: 0.0008(0.0074) Grad: 5258.9146  LR: 0.000001  \n",
      "Epoch: [4][2600/2851] Elapsed 16m 39s (remain 1m 36s) Loss: 0.0007(0.0074) Grad: 4896.3550  LR: 0.000001  \n",
      "Epoch: [4][2700/2851] Elapsed 17m 17s (remain 0m 57s) Loss: 0.0003(0.0073) Grad: 1361.0907  LR: 0.000001  \n",
      "Epoch: [4][2800/2851] Elapsed 17m 56s (remain 0m 19s) Loss: 0.0051(0.0073) Grad: 21133.2148  LR: 0.000001  \n",
      "Epoch: [4][2850/2851] Elapsed 18m 15s (remain 0m 0s) Loss: 0.0130(0.0073) Grad: 37186.4453  LR: 0.000001  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 35s) Loss: 0.0007(0.0007) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0010(0.0069) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0000(0.0095) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0001(0.0092) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0000(0.0093) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0090(0.0104) \n",
      "EVAL: [600/724] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0041(0.0100) \n",
      "EVAL: [700/724] Elapsed 2m 29s (remain 0m 4s) Loss: 0.0000(0.0091) \n",
      "EVAL: [723/724] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0002(0.0090) \n",
      "Epoch 4 - avg_train_loss: 0.0073  avg_val_loss: 0.0090  time: 1255s\n",
      "Epoch 4 - Score: 0.8686\n",
      "Epoch 4 - Save Best Score: 0.8686 Model\n",
      "Epoch: [5][0/2851] Elapsed 0m 0s (remain 30m 13s) Loss: 0.0005(0.0005) Grad: 9121.3623  LR: 0.000001  \n",
      "Epoch: [5][100/2851] Elapsed 0m 40s (remain 18m 28s) Loss: 0.0312(0.0077) Grad: 97654.9062  LR: 0.000001  \n",
      "Epoch: [5][200/2851] Elapsed 1m 18s (remain 17m 16s) Loss: 0.0115(0.0069) Grad: 12950.5625  LR: 0.000001  \n",
      "Epoch: [5][300/2851] Elapsed 1m 56s (remain 16m 23s) Loss: 0.0055(0.0070) Grad: 23096.4629  LR: 0.000001  \n",
      "Epoch: [5][400/2851] Elapsed 2m 33s (remain 15m 40s) Loss: 0.0027(0.0075) Grad: 16932.2754  LR: 0.000001  \n",
      "Epoch: [5][500/2851] Elapsed 3m 12s (remain 15m 2s) Loss: 0.0027(0.0072) Grad: 13684.5576  LR: 0.000001  \n",
      "Epoch: [5][600/2851] Elapsed 3m 50s (remain 14m 23s) Loss: 0.0000(0.0072) Grad: 225.8522  LR: 0.000001  \n",
      "Epoch: [5][700/2851] Elapsed 4m 28s (remain 13m 43s) Loss: 0.0063(0.0071) Grad: 16423.6250  LR: 0.000001  \n",
      "Epoch: [5][800/2851] Elapsed 5m 6s (remain 13m 3s) Loss: 0.0060(0.0069) Grad: 75582.7031  LR: 0.000001  \n",
      "Epoch: [5][900/2851] Elapsed 5m 44s (remain 12m 25s) Loss: 0.0083(0.0067) Grad: 42770.2461  LR: 0.000001  \n",
      "Epoch: [5][1000/2851] Elapsed 6m 23s (remain 11m 48s) Loss: 0.0024(0.0067) Grad: 13332.0869  LR: 0.000001  \n",
      "Epoch: [5][1100/2851] Elapsed 7m 4s (remain 11m 14s) Loss: 0.0058(0.0066) Grad: 19321.4375  LR: 0.000001  \n",
      "Epoch: [5][1200/2851] Elapsed 7m 46s (remain 10m 40s) Loss: 0.0004(0.0068) Grad: 2813.1094  LR: 0.000001  \n",
      "Epoch: [5][1300/2851] Elapsed 8m 24s (remain 10m 1s) Loss: 0.0277(0.0070) Grad: 47114.7070  LR: 0.000001  \n",
      "Epoch: [5][1400/2851] Elapsed 9m 3s (remain 9m 22s) Loss: 0.0047(0.0069) Grad: 6254.7490  LR: 0.000001  \n",
      "Epoch: [5][1500/2851] Elapsed 9m 40s (remain 8m 42s) Loss: 0.0027(0.0067) Grad: 17720.0508  LR: 0.000001  \n",
      "Epoch: [5][1600/2851] Elapsed 10m 19s (remain 8m 3s) Loss: 0.0130(0.0067) Grad: 29225.6270  LR: 0.000000  \n",
      "Epoch: [5][1700/2851] Elapsed 10m 58s (remain 7m 25s) Loss: 0.0034(0.0066) Grad: 7986.3071  LR: 0.000000  \n",
      "Epoch: [5][1800/2851] Elapsed 11m 36s (remain 6m 46s) Loss: 0.0106(0.0065) Grad: 22047.2988  LR: 0.000000  \n",
      "Epoch: [5][1900/2851] Elapsed 12m 14s (remain 6m 6s) Loss: 0.0012(0.0066) Grad: 8469.8281  LR: 0.000000  \n",
      "Epoch: [5][2000/2851] Elapsed 12m 53s (remain 5m 28s) Loss: 0.0506(0.0066) Grad: 125568.4922  LR: 0.000000  \n",
      "Epoch: [5][2100/2851] Elapsed 13m 31s (remain 4m 49s) Loss: 0.0144(0.0067) Grad: 29111.6445  LR: 0.000000  \n",
      "Epoch: [5][2200/2851] Elapsed 14m 8s (remain 4m 10s) Loss: 0.0003(0.0067) Grad: 3188.6785  LR: 0.000000  \n",
      "Epoch: [5][2300/2851] Elapsed 14m 46s (remain 3m 31s) Loss: 0.0002(0.0067) Grad: 2795.1877  LR: 0.000000  \n",
      "Epoch: [5][2400/2851] Elapsed 15m 24s (remain 2m 53s) Loss: 0.0013(0.0066) Grad: 9338.4268  LR: 0.000000  \n",
      "Epoch: [5][2500/2851] Elapsed 16m 5s (remain 2m 15s) Loss: 0.0004(0.0067) Grad: 4746.4990  LR: 0.000000  \n",
      "Epoch: [5][2600/2851] Elapsed 16m 43s (remain 1m 36s) Loss: 0.0344(0.0068) Grad: 106521.4219  LR: 0.000000  \n",
      "Epoch: [5][2700/2851] Elapsed 17m 21s (remain 0m 57s) Loss: 0.0001(0.0069) Grad: 490.5961  LR: 0.000000  \n",
      "Epoch: [5][2800/2851] Elapsed 17m 59s (remain 0m 19s) Loss: 0.0010(0.0068) Grad: 5493.8066  LR: 0.000000  \n",
      "Epoch: [5][2850/2851] Elapsed 18m 18s (remain 0m 0s) Loss: 0.0034(0.0068) Grad: 12563.1738  LR: 0.000000  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 0s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0011(0.0068) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 53s) Loss: 0.0000(0.0095) \n",
      "EVAL: [300/724] Elapsed 1m 5s (remain 1m 31s) Loss: 0.0001(0.0092) \n",
      "EVAL: [400/724] Elapsed 1m 26s (remain 1m 9s) Loss: 0.0000(0.0093) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0105(0.0105) \n",
      "EVAL: [600/724] Elapsed 2m 9s (remain 0m 26s) Loss: 0.0048(0.0101) \n",
      "EVAL: [700/724] Elapsed 2m 30s (remain 0m 4s) Loss: 0.0000(0.0092) \n",
      "EVAL: [723/724] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0002(0.0091) \n",
      "Epoch 5 - avg_train_loss: 0.0068  avg_val_loss: 0.0091  time: 1258s\n",
      "Epoch 5 - Score: 0.8725\n",
      "Epoch 5 - Save Best Score: 0.8725 Model\n",
      "========== fold: 2 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2871] Elapsed 0m 0s (remain 26m 37s) Loss: 0.6513(0.6513) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2871] Elapsed 0m 38s (remain 17m 37s) Loss: 0.2490(0.4125) Grad: 27379.4238  LR: 0.000000  \n",
      "Epoch: [1][200/2871] Elapsed 1m 16s (remain 16m 54s) Loss: 0.3152(0.3918) Grad: 33949.5195  LR: 0.000001  \n",
      "Epoch: [1][300/2871] Elapsed 1m 55s (remain 16m 26s) Loss: 0.3099(0.3534) Grad: 41120.9961  LR: 0.000001  \n",
      "Epoch: [1][400/2871] Elapsed 2m 35s (remain 15m 55s) Loss: 0.0804(0.3082) Grad: 7620.0161  LR: 0.000001  \n",
      "Epoch: [1][500/2871] Elapsed 3m 16s (remain 15m 30s) Loss: 0.0464(0.2641) Grad: 3530.9871  LR: 0.000002  \n",
      "Epoch: [1][600/2871] Elapsed 3m 54s (remain 14m 44s) Loss: 0.0299(0.2277) Grad: 812.3732  LR: 0.000002  \n",
      "Epoch: [1][700/2871] Elapsed 4m 32s (remain 14m 3s) Loss: 0.0486(0.2012) Grad: 1440.4554  LR: 0.000002  \n",
      "Epoch: [1][800/2871] Elapsed 5m 11s (remain 13m 24s) Loss: 0.0476(0.1816) Grad: 923.9147  LR: 0.000003  \n",
      "Epoch: [1][900/2871] Elapsed 5m 48s (remain 12m 42s) Loss: 0.0327(0.1655) Grad: 1250.1826  LR: 0.000003  \n",
      "Epoch: [1][1000/2871] Elapsed 6m 26s (remain 12m 1s) Loss: 0.0261(0.1529) Grad: 575.0233  LR: 0.000003  \n",
      "Epoch: [1][1100/2871] Elapsed 7m 4s (remain 11m 22s) Loss: 0.0535(0.1426) Grad: 1327.1549  LR: 0.000004  \n",
      "Epoch: [1][1200/2871] Elapsed 7m 42s (remain 10m 42s) Loss: 0.0678(0.1339) Grad: 3112.7793  LR: 0.000004  \n",
      "Epoch: [1][1300/2871] Elapsed 8m 20s (remain 10m 3s) Loss: 0.0499(0.1263) Grad: 3077.4050  LR: 0.000005  \n",
      "Epoch: [1][1400/2871] Elapsed 8m 58s (remain 9m 25s) Loss: 0.0639(0.1190) Grad: 6052.6772  LR: 0.000005  \n",
      "Epoch: [1][1500/2871] Elapsed 9m 37s (remain 8m 47s) Loss: 0.0368(0.1125) Grad: 4582.1304  LR: 0.000005  \n",
      "Epoch: [1][1600/2871] Elapsed 10m 15s (remain 8m 8s) Loss: 0.0227(0.1067) Grad: 4720.6665  LR: 0.000005  \n",
      "Epoch: [1][1700/2871] Elapsed 10m 54s (remain 7m 29s) Loss: 0.0117(0.1015) Grad: 3276.9019  LR: 0.000005  \n",
      "Epoch: [1][1800/2871] Elapsed 11m 35s (remain 6m 53s) Loss: 0.0084(0.0968) Grad: 2008.0637  LR: 0.000005  \n",
      "Epoch: [1][1900/2871] Elapsed 12m 12s (remain 6m 13s) Loss: 0.0167(0.0924) Grad: 3576.2932  LR: 0.000005  \n",
      "Epoch: [1][2000/2871] Elapsed 12m 51s (remain 5m 35s) Loss: 0.0042(0.0885) Grad: 1117.2977  LR: 0.000005  \n",
      "Epoch: [1][2100/2871] Elapsed 13m 32s (remain 4m 57s) Loss: 0.0171(0.0848) Grad: 5950.5576  LR: 0.000005  \n",
      "Epoch: [1][2200/2871] Elapsed 14m 13s (remain 4m 19s) Loss: 0.0513(0.0815) Grad: 9346.3896  LR: 0.000005  \n",
      "Epoch: [1][2300/2871] Elapsed 14m 50s (remain 3m 40s) Loss: 0.0185(0.0785) Grad: 2002.6932  LR: 0.000005  \n",
      "Epoch: [1][2400/2871] Elapsed 15m 28s (remain 3m 1s) Loss: 0.0063(0.0757) Grad: 4043.1240  LR: 0.000005  \n",
      "Epoch: [1][2500/2871] Elapsed 16m 7s (remain 2m 23s) Loss: 0.0088(0.0732) Grad: 3900.2178  LR: 0.000005  \n",
      "Epoch: [1][2600/2871] Elapsed 16m 45s (remain 1m 44s) Loss: 0.0097(0.0707) Grad: 2738.7312  LR: 0.000005  \n",
      "Epoch: [1][2700/2871] Elapsed 17m 23s (remain 1m 5s) Loss: 0.0031(0.0685) Grad: 1138.9219  LR: 0.000005  \n",
      "Epoch: [1][2800/2871] Elapsed 18m 3s (remain 0m 27s) Loss: 0.0078(0.0665) Grad: 3260.8252  LR: 0.000004  \n",
      "Epoch: [1][2870/2871] Elapsed 18m 30s (remain 0m 0s) Loss: 0.0028(0.0650) Grad: 1174.1920  LR: 0.000004  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 29s) Loss: 0.0045(0.0045) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 8s) Loss: 0.0146(0.0131) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 47s) Loss: 0.0006(0.0113) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 26s) Loss: 0.0018(0.0108) \n",
      "EVAL: [400/704] Elapsed 1m 25s (remain 1m 4s) Loss: 0.0103(0.0118) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 43s) Loss: 0.0351(0.0130) \n",
      "EVAL: [600/704] Elapsed 2m 7s (remain 0m 21s) Loss: 0.0024(0.0130) \n",
      "EVAL: [700/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0008(0.0125) \n",
      "EVAL: [703/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0002(0.0125) \n",
      "Epoch 1 - avg_train_loss: 0.0650  avg_val_loss: 0.0125  time: 1265s\n",
      "Epoch 1 - Score: 0.7781\n",
      "Epoch 1 - Save Best Score: 0.7781 Model\n",
      "Epoch: [2][0/2871] Elapsed 0m 0s (remain 27m 30s) Loss: 0.0160(0.0160) Grad: 14943.1865  LR: 0.000004  \n",
      "Epoch: [2][100/2871] Elapsed 0m 38s (remain 17m 29s) Loss: 0.0475(0.0116) Grad: 71268.0547  LR: 0.000004  \n",
      "Epoch: [2][200/2871] Elapsed 1m 16s (remain 16m 55s) Loss: 0.0142(0.0103) Grad: 32267.8633  LR: 0.000004  \n",
      "Epoch: [2][300/2871] Elapsed 1m 54s (remain 16m 16s) Loss: 0.0006(0.0101) Grad: 2891.7139  LR: 0.000004  \n",
      "Epoch: [2][400/2871] Elapsed 2m 32s (remain 15m 40s) Loss: 0.0067(0.0100) Grad: 15424.2939  LR: 0.000004  \n",
      "Epoch: [2][500/2871] Elapsed 3m 10s (remain 15m 1s) Loss: 0.0044(0.0093) Grad: 11954.4727  LR: 0.000004  \n",
      "Epoch: [2][600/2871] Elapsed 3m 48s (remain 14m 24s) Loss: 0.0033(0.0094) Grad: 25133.4355  LR: 0.000004  \n",
      "Epoch: [2][700/2871] Elapsed 4m 27s (remain 13m 49s) Loss: 0.0008(0.0096) Grad: 4770.2637  LR: 0.000004  \n",
      "Epoch: [2][800/2871] Elapsed 5m 5s (remain 13m 9s) Loss: 0.0037(0.0094) Grad: 7548.4795  LR: 0.000004  \n",
      "Epoch: [2][900/2871] Elapsed 5m 43s (remain 12m 30s) Loss: 0.0020(0.0096) Grad: 32556.2266  LR: 0.000004  \n",
      "Epoch: [2][1000/2871] Elapsed 6m 21s (remain 11m 52s) Loss: 0.0058(0.0095) Grad: 14698.8955  LR: 0.000004  \n",
      "Epoch: [2][1100/2871] Elapsed 7m 0s (remain 11m 15s) Loss: 0.0471(0.0095) Grad: 74178.8125  LR: 0.000004  \n",
      "Epoch: [2][1200/2871] Elapsed 7m 41s (remain 10m 41s) Loss: 0.0098(0.0095) Grad: 21807.2031  LR: 0.000004  \n",
      "Epoch: [2][1300/2871] Elapsed 8m 23s (remain 10m 7s) Loss: 0.0259(0.0095) Grad: 30781.9492  LR: 0.000004  \n",
      "Epoch: [2][1400/2871] Elapsed 9m 2s (remain 9m 28s) Loss: 0.0067(0.0094) Grad: 15033.2676  LR: 0.000004  \n",
      "Epoch: [2][1500/2871] Elapsed 9m 40s (remain 8m 50s) Loss: 0.0110(0.0095) Grad: 7445.0732  LR: 0.000004  \n",
      "Epoch: [2][1600/2871] Elapsed 10m 19s (remain 8m 11s) Loss: 0.0013(0.0094) Grad: 8849.5732  LR: 0.000004  \n",
      "Epoch: [2][1700/2871] Elapsed 10m 59s (remain 7m 33s) Loss: 0.0167(0.0094) Grad: 50163.7695  LR: 0.000004  \n",
      "Epoch: [2][1800/2871] Elapsed 11m 37s (remain 6m 54s) Loss: 0.0045(0.0093) Grad: 39481.0547  LR: 0.000004  \n",
      "Epoch: [2][1900/2871] Elapsed 12m 16s (remain 6m 15s) Loss: 0.0039(0.0093) Grad: 13031.8291  LR: 0.000004  \n",
      "Epoch: [2][2000/2871] Elapsed 12m 55s (remain 5m 37s) Loss: 0.0148(0.0092) Grad: 46973.4531  LR: 0.000004  \n",
      "Epoch: [2][2100/2871] Elapsed 13m 33s (remain 4m 57s) Loss: 0.0175(0.0092) Grad: 65648.0000  LR: 0.000004  \n",
      "Epoch: [2][2200/2871] Elapsed 14m 10s (remain 4m 18s) Loss: 0.0000(0.0091) Grad: 205.5901  LR: 0.000004  \n",
      "Epoch: [2][2300/2871] Elapsed 14m 48s (remain 3m 40s) Loss: 0.0045(0.0092) Grad: 18907.2109  LR: 0.000004  \n",
      "Epoch: [2][2400/2871] Elapsed 15m 27s (remain 3m 1s) Loss: 0.0207(0.0091) Grad: 63499.0820  LR: 0.000004  \n",
      "Epoch: [2][2500/2871] Elapsed 16m 5s (remain 2m 22s) Loss: 0.0112(0.0091) Grad: 43963.5234  LR: 0.000003  \n",
      "Epoch: [2][2600/2871] Elapsed 16m 43s (remain 1m 44s) Loss: 0.0015(0.0091) Grad: 5286.8726  LR: 0.000003  \n",
      "Epoch: [2][2700/2871] Elapsed 17m 21s (remain 1m 5s) Loss: 0.0017(0.0091) Grad: 32622.6348  LR: 0.000003  \n",
      "Epoch: [2][2800/2871] Elapsed 18m 0s (remain 0m 27s) Loss: 0.0085(0.0091) Grad: 27103.0762  LR: 0.000003  \n",
      "Epoch: [2][2870/2871] Elapsed 18m 28s (remain 0m 0s) Loss: 0.0000(0.0091) Grad: 129.1110  LR: 0.000003  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 20s) Loss: 0.0022(0.0022) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0162(0.0090) \n",
      "EVAL: [200/704] Elapsed 0m 42s (remain 1m 47s) Loss: 0.0001(0.0091) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0002(0.0087) \n",
      "EVAL: [400/704] Elapsed 1m 25s (remain 1m 4s) Loss: 0.0089(0.0098) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 43s) Loss: 0.0193(0.0106) \n",
      "EVAL: [600/704] Elapsed 2m 8s (remain 0m 22s) Loss: 0.0002(0.0107) \n",
      "EVAL: [700/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0001(0.0102) \n",
      "EVAL: [703/704] Elapsed 2m 30s (remain 0m 0s) Loss: 0.0000(0.0101) \n",
      "Epoch 2 - avg_train_loss: 0.0091  avg_val_loss: 0.0101  time: 1264s\n",
      "Epoch 2 - Score: 0.8309\n",
      "Epoch 2 - Save Best Score: 0.8309 Model\n",
      "Epoch: [3][0/2871] Elapsed 0m 0s (remain 33m 47s) Loss: 0.0034(0.0034) Grad: 19348.0859  LR: 0.000003  \n",
      "Epoch: [3][100/2871] Elapsed 0m 40s (remain 18m 28s) Loss: 0.0069(0.0086) Grad: 16976.9219  LR: 0.000003  \n",
      "Epoch: [3][200/2871] Elapsed 1m 18s (remain 17m 21s) Loss: 0.0136(0.0086) Grad: 38500.0352  LR: 0.000003  \n",
      "Epoch: [3][300/2871] Elapsed 1m 56s (remain 16m 33s) Loss: 0.0009(0.0082) Grad: 6238.0127  LR: 0.000003  \n",
      "Epoch: [3][400/2871] Elapsed 2m 34s (remain 15m 50s) Loss: 0.0000(0.0080) Grad: 143.9005  LR: 0.000003  \n",
      "Epoch: [3][500/2871] Elapsed 3m 12s (remain 15m 12s) Loss: 0.0282(0.0082) Grad: 100989.2188  LR: 0.000003  \n",
      "Epoch: [3][600/2871] Elapsed 3m 54s (remain 14m 46s) Loss: 0.0059(0.0081) Grad: 19224.1152  LR: 0.000003  \n",
      "Epoch: [3][700/2871] Elapsed 4m 33s (remain 14m 5s) Loss: 0.0034(0.0080) Grad: 23866.2754  LR: 0.000003  \n",
      "Epoch: [3][800/2871] Elapsed 5m 11s (remain 13m 24s) Loss: 0.0104(0.0080) Grad: 38321.0117  LR: 0.000003  \n",
      "Epoch: [3][900/2871] Elapsed 5m 49s (remain 12m 44s) Loss: 0.0116(0.0079) Grad: 125692.2969  LR: 0.000003  \n",
      "Epoch: [3][1000/2871] Elapsed 6m 27s (remain 12m 3s) Loss: 0.0004(0.0079) Grad: 1427.8214  LR: 0.000003  \n",
      "Epoch: [3][1100/2871] Elapsed 7m 5s (remain 11m 24s) Loss: 0.0021(0.0081) Grad: 10648.1953  LR: 0.000003  \n",
      "Epoch: [3][1200/2871] Elapsed 7m 45s (remain 10m 47s) Loss: 0.0050(0.0081) Grad: 24793.3613  LR: 0.000003  \n",
      "Epoch: [3][1300/2871] Elapsed 8m 23s (remain 10m 7s) Loss: 0.0324(0.0082) Grad: 36134.1680  LR: 0.000003  \n",
      "Epoch: [3][1400/2871] Elapsed 9m 1s (remain 9m 28s) Loss: 0.0018(0.0083) Grad: 11121.0986  LR: 0.000003  \n",
      "Epoch: [3][1500/2871] Elapsed 9m 40s (remain 8m 50s) Loss: 0.0055(0.0082) Grad: 11567.9209  LR: 0.000003  \n",
      "Epoch: [3][1600/2871] Elapsed 10m 19s (remain 8m 11s) Loss: 0.0115(0.0081) Grad: 39148.2930  LR: 0.000003  \n",
      "Epoch: [3][1700/2871] Elapsed 10m 57s (remain 7m 32s) Loss: 0.0011(0.0082) Grad: 8695.9932  LR: 0.000003  \n",
      "Epoch: [3][1800/2871] Elapsed 11m 35s (remain 6m 53s) Loss: 0.0059(0.0083) Grad: 26022.7305  LR: 0.000003  \n",
      "Epoch: [3][1900/2871] Elapsed 12m 13s (remain 6m 14s) Loss: 0.0008(0.0082) Grad: 7603.9448  LR: 0.000003  \n",
      "Epoch: [3][2000/2871] Elapsed 12m 51s (remain 5m 35s) Loss: 0.0001(0.0082) Grad: 182.0119  LR: 0.000003  \n",
      "Epoch: [3][2100/2871] Elapsed 13m 31s (remain 4m 57s) Loss: 0.0004(0.0081) Grad: 4697.9189  LR: 0.000003  \n",
      "Epoch: [3][2200/2871] Elapsed 14m 8s (remain 4m 18s) Loss: 0.0028(0.0082) Grad: 9742.3799  LR: 0.000002  \n",
      "Epoch: [3][2300/2871] Elapsed 14m 46s (remain 3m 39s) Loss: 0.0024(0.0082) Grad: 16702.7383  LR: 0.000002  \n",
      "Epoch: [3][2400/2871] Elapsed 15m 24s (remain 3m 0s) Loss: 0.0108(0.0082) Grad: 49569.2617  LR: 0.000002  \n",
      "Epoch: [3][2500/2871] Elapsed 16m 2s (remain 2m 22s) Loss: 0.0008(0.0082) Grad: 4184.6274  LR: 0.000002  \n",
      "Epoch: [3][2600/2871] Elapsed 16m 41s (remain 1m 43s) Loss: 0.0004(0.0082) Grad: 3416.2107  LR: 0.000002  \n",
      "Epoch: [3][2700/2871] Elapsed 17m 18s (remain 1m 5s) Loss: 0.0036(0.0081) Grad: 9455.0400  LR: 0.000002  \n",
      "Epoch: [3][2800/2871] Elapsed 17m 56s (remain 0m 26s) Loss: 0.0009(0.0081) Grad: 4248.3062  LR: 0.000002  \n",
      "Epoch: [3][2870/2871] Elapsed 18m 23s (remain 0m 0s) Loss: 0.0107(0.0081) Grad: 27603.0371  LR: 0.000002  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 1s) Loss: 0.0010(0.0010) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0148(0.0093) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 48s) Loss: 0.0001(0.0089) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 26s) Loss: 0.0004(0.0083) \n",
      "EVAL: [400/704] Elapsed 1m 25s (remain 1m 4s) Loss: 0.0086(0.0093) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 43s) Loss: 0.0057(0.0101) \n",
      "EVAL: [600/704] Elapsed 2m 7s (remain 0m 21s) Loss: 0.0002(0.0100) \n",
      "EVAL: [700/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0001(0.0094) \n",
      "EVAL: [703/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0094) \n",
      "Epoch 3 - avg_train_loss: 0.0081  avg_val_loss: 0.0094  time: 1258s\n",
      "Epoch 3 - Score: 0.8396\n",
      "Epoch 3 - Save Best Score: 0.8396 Model\n",
      "Epoch: [4][0/2871] Elapsed 0m 0s (remain 31m 19s) Loss: 0.0213(0.0213) Grad: 44982.2695  LR: 0.000002  \n",
      "Epoch: [4][100/2871] Elapsed 0m 38s (remain 17m 37s) Loss: 0.0005(0.0077) Grad: 4108.0928  LR: 0.000002  \n",
      "Epoch: [4][200/2871] Elapsed 1m 16s (remain 16m 57s) Loss: 0.0040(0.0087) Grad: 13200.7021  LR: 0.000002  \n",
      "Epoch: [4][300/2871] Elapsed 1m 57s (remain 16m 46s) Loss: 0.0021(0.0082) Grad: 5981.0977  LR: 0.000002  \n",
      "Epoch: [4][400/2871] Elapsed 2m 39s (remain 16m 24s) Loss: 0.0023(0.0076) Grad: 10838.9043  LR: 0.000002  \n",
      "Epoch: [4][500/2871] Elapsed 3m 20s (remain 15m 47s) Loss: 0.0009(0.0075) Grad: 13870.8623  LR: 0.000002  \n",
      "Epoch: [4][600/2871] Elapsed 3m 58s (remain 15m 0s) Loss: 0.0063(0.0076) Grad: 21131.2520  LR: 0.000002  \n",
      "Epoch: [4][700/2871] Elapsed 4m 37s (remain 14m 19s) Loss: 0.0040(0.0081) Grad: 16326.0791  LR: 0.000002  \n",
      "Epoch: [4][800/2871] Elapsed 5m 15s (remain 13m 35s) Loss: 0.0066(0.0079) Grad: 18149.0195  LR: 0.000002  \n",
      "Epoch: [4][900/2871] Elapsed 5m 53s (remain 12m 53s) Loss: 0.0012(0.0078) Grad: 57262.7578  LR: 0.000002  \n",
      "Epoch: [4][1000/2871] Elapsed 6m 32s (remain 12m 13s) Loss: 0.0037(0.0078) Grad: 4575.4619  LR: 0.000002  \n",
      "Epoch: [4][1100/2871] Elapsed 7m 11s (remain 11m 33s) Loss: 0.0005(0.0078) Grad: 2261.4927  LR: 0.000002  \n",
      "Epoch: [4][1200/2871] Elapsed 7m 49s (remain 10m 53s) Loss: 0.0006(0.0077) Grad: 7206.8550  LR: 0.000002  \n",
      "Epoch: [4][1300/2871] Elapsed 8m 28s (remain 10m 13s) Loss: 0.0001(0.0077) Grad: 240.5715  LR: 0.000002  \n",
      "Epoch: [4][1400/2871] Elapsed 9m 7s (remain 9m 34s) Loss: 0.0020(0.0077) Grad: 14692.5527  LR: 0.000002  \n",
      "Epoch: [4][1500/2871] Elapsed 9m 45s (remain 8m 54s) Loss: 0.0001(0.0078) Grad: 214.0079  LR: 0.000002  \n",
      "Epoch: [4][1600/2871] Elapsed 10m 25s (remain 8m 15s) Loss: 0.0125(0.0077) Grad: 45153.8477  LR: 0.000002  \n",
      "Epoch: [4][1700/2871] Elapsed 11m 3s (remain 7m 36s) Loss: 0.0037(0.0076) Grad: 16184.9414  LR: 0.000002  \n",
      "Epoch: [4][1800/2871] Elapsed 11m 41s (remain 6m 57s) Loss: 0.0006(0.0076) Grad: 4618.7554  LR: 0.000002  \n",
      "Epoch: [4][1900/2871] Elapsed 12m 20s (remain 6m 17s) Loss: 0.0110(0.0076) Grad: 38079.0703  LR: 0.000001  \n",
      "Epoch: [4][2000/2871] Elapsed 12m 58s (remain 5m 38s) Loss: 0.0015(0.0075) Grad: 14697.3818  LR: 0.000001  \n",
      "Epoch: [4][2100/2871] Elapsed 13m 36s (remain 4m 59s) Loss: 0.0150(0.0076) Grad: 29006.1895  LR: 0.000001  \n",
      "Epoch: [4][2200/2871] Elapsed 14m 14s (remain 4m 20s) Loss: 0.0024(0.0075) Grad: 10132.1943  LR: 0.000001  \n",
      "Epoch: [4][2300/2871] Elapsed 14m 53s (remain 3m 41s) Loss: 0.0112(0.0075) Grad: 36231.0000  LR: 0.000001  \n",
      "Epoch: [4][2400/2871] Elapsed 15m 31s (remain 3m 2s) Loss: 0.0031(0.0076) Grad: 15255.8838  LR: 0.000001  \n",
      "Epoch: [4][2500/2871] Elapsed 16m 9s (remain 2m 23s) Loss: 0.0049(0.0075) Grad: 26090.0566  LR: 0.000001  \n",
      "Epoch: [4][2600/2871] Elapsed 16m 47s (remain 1m 44s) Loss: 0.0021(0.0075) Grad: 6153.5728  LR: 0.000001  \n",
      "Epoch: [4][2700/2871] Elapsed 17m 27s (remain 1m 5s) Loss: 0.0124(0.0076) Grad: 323915.8438  LR: 0.000001  \n",
      "Epoch: [4][2800/2871] Elapsed 18m 6s (remain 0m 27s) Loss: 0.0479(0.0075) Grad: 139291.7812  LR: 0.000001  \n",
      "Epoch: [4][2870/2871] Elapsed 18m 32s (remain 0m 0s) Loss: 0.0405(0.0075) Grad: 175712.4062  LR: 0.000001  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 26s) Loss: 0.0012(0.0012) \n",
      "EVAL: [100/704] Elapsed 0m 22s (remain 2m 12s) Loss: 0.0147(0.0091) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 48s) Loss: 0.0000(0.0087) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 26s) Loss: 0.0002(0.0084) \n",
      "EVAL: [400/704] Elapsed 1m 26s (remain 1m 5s) Loss: 0.0095(0.0095) \n",
      "EVAL: [500/704] Elapsed 1m 48s (remain 0m 43s) Loss: 0.0077(0.0103) \n",
      "EVAL: [600/704] Elapsed 2m 9s (remain 0m 22s) Loss: 0.0001(0.0104) \n",
      "EVAL: [700/704] Elapsed 2m 30s (remain 0m 0s) Loss: 0.0000(0.0099) \n",
      "EVAL: [703/704] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0000(0.0098) \n",
      "Epoch 4 - avg_train_loss: 0.0075  avg_val_loss: 0.0098  time: 1268s\n",
      "Epoch 4 - Score: 0.8466\n",
      "Epoch 4 - Save Best Score: 0.8466 Model\n",
      "Epoch: [5][0/2871] Elapsed 0m 0s (remain 32m 21s) Loss: 0.0002(0.0002) Grad: 1568.9141  LR: 0.000001  \n",
      "Epoch: [5][100/2871] Elapsed 0m 39s (remain 17m 55s) Loss: 0.0005(0.0059) Grad: 4180.9839  LR: 0.000001  \n",
      "Epoch: [5][200/2871] Elapsed 1m 17s (remain 17m 4s) Loss: 0.0002(0.0060) Grad: 1392.6416  LR: 0.000001  \n",
      "Epoch: [5][300/2871] Elapsed 1m 54s (remain 16m 20s) Loss: 0.0120(0.0058) Grad: 91352.4297  LR: 0.000001  \n",
      "Epoch: [5][400/2871] Elapsed 2m 32s (remain 15m 41s) Loss: 0.0104(0.0063) Grad: 38411.3867  LR: 0.000001  \n",
      "Epoch: [5][500/2871] Elapsed 3m 12s (remain 15m 11s) Loss: 0.0000(0.0064) Grad: 180.6704  LR: 0.000001  \n",
      "Epoch: [5][600/2871] Elapsed 3m 52s (remain 14m 38s) Loss: 0.0008(0.0064) Grad: 11013.4268  LR: 0.000001  \n",
      "Epoch: [5][700/2871] Elapsed 4m 30s (remain 13m 58s) Loss: 0.0002(0.0066) Grad: 1621.9868  LR: 0.000001  \n",
      "Epoch: [5][800/2871] Elapsed 5m 9s (remain 13m 19s) Loss: 0.0008(0.0067) Grad: 15013.1104  LR: 0.000001  \n",
      "Epoch: [5][900/2871] Elapsed 5m 46s (remain 12m 38s) Loss: 0.0033(0.0068) Grad: 24569.4883  LR: 0.000001  \n",
      "Epoch: [5][1000/2871] Elapsed 6m 24s (remain 11m 58s) Loss: 0.0130(0.0070) Grad: 45883.7617  LR: 0.000001  \n",
      "Epoch: [5][1100/2871] Elapsed 7m 4s (remain 11m 22s) Loss: 0.0000(0.0071) Grad: 223.5562  LR: 0.000001  \n",
      "Epoch: [5][1200/2871] Elapsed 7m 42s (remain 10m 42s) Loss: 0.0024(0.0072) Grad: 12079.6279  LR: 0.000001  \n",
      "Epoch: [5][1300/2871] Elapsed 8m 19s (remain 10m 3s) Loss: 0.0007(0.0072) Grad: 6506.1738  LR: 0.000001  \n",
      "Epoch: [5][1400/2871] Elapsed 8m 58s (remain 9m 24s) Loss: 0.0003(0.0071) Grad: 3615.7327  LR: 0.000001  \n",
      "Epoch: [5][1500/2871] Elapsed 9m 37s (remain 8m 47s) Loss: 0.0039(0.0071) Grad: 15641.7842  LR: 0.000001  \n",
      "Epoch: [5][1600/2871] Elapsed 10m 15s (remain 8m 8s) Loss: 0.0000(0.0071) Grad: 196.3704  LR: 0.000000  \n",
      "Epoch: [5][1700/2871] Elapsed 10m 53s (remain 7m 29s) Loss: 0.0016(0.0071) Grad: 6016.1538  LR: 0.000000  \n",
      "Epoch: [5][1800/2871] Elapsed 11m 31s (remain 6m 51s) Loss: 0.0002(0.0070) Grad: 1258.2809  LR: 0.000000  \n",
      "Epoch: [5][1900/2871] Elapsed 12m 10s (remain 6m 12s) Loss: 0.0007(0.0070) Grad: 6628.1621  LR: 0.000000  \n",
      "Epoch: [5][2000/2871] Elapsed 12m 48s (remain 5m 34s) Loss: 0.0240(0.0071) Grad: 59627.5273  LR: 0.000000  \n",
      "Epoch: [5][2100/2871] Elapsed 13m 26s (remain 4m 55s) Loss: 0.0131(0.0072) Grad: 28356.6289  LR: 0.000000  \n",
      "Epoch: [5][2200/2871] Elapsed 14m 4s (remain 4m 16s) Loss: 0.0078(0.0071) Grad: 13141.3594  LR: 0.000000  \n",
      "Epoch: [5][2300/2871] Elapsed 14m 41s (remain 3m 38s) Loss: 0.0002(0.0071) Grad: 6161.2300  LR: 0.000000  \n",
      "Epoch: [5][2400/2871] Elapsed 15m 19s (remain 2m 59s) Loss: 0.0002(0.0070) Grad: 1487.0103  LR: 0.000000  \n",
      "Epoch: [5][2500/2871] Elapsed 15m 58s (remain 2m 21s) Loss: 0.0056(0.0071) Grad: 13535.7422  LR: 0.000000  \n",
      "Epoch: [5][2600/2871] Elapsed 16m 36s (remain 1m 43s) Loss: 0.0001(0.0070) Grad: 762.3562  LR: 0.000000  \n",
      "Epoch: [5][2700/2871] Elapsed 17m 14s (remain 1m 5s) Loss: 0.0006(0.0071) Grad: 5408.3193  LR: 0.000000  \n",
      "Epoch: [5][2800/2871] Elapsed 17m 52s (remain 0m 26s) Loss: 0.0021(0.0070) Grad: 8444.9912  LR: 0.000000  \n",
      "Epoch: [5][2870/2871] Elapsed 18m 20s (remain 0m 0s) Loss: 0.0097(0.0070) Grad: 40021.3203  LR: 0.000000  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 20s) Loss: 0.0011(0.0011) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 8s) Loss: 0.0136(0.0089) \n",
      "EVAL: [200/704] Elapsed 0m 42s (remain 1m 46s) Loss: 0.0000(0.0086) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 26s) Loss: 0.0001(0.0081) \n",
      "EVAL: [400/704] Elapsed 1m 25s (remain 1m 4s) Loss: 0.0076(0.0092) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 43s) Loss: 0.0077(0.0101) \n",
      "EVAL: [600/704] Elapsed 2m 8s (remain 0m 21s) Loss: 0.0001(0.0102) \n",
      "EVAL: [700/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0096) \n",
      "EVAL: [703/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0096) \n",
      "Epoch 5 - avg_train_loss: 0.0070  avg_val_loss: 0.0096  time: 1255s\n",
      "Epoch 5 - Score: 0.8509\n",
      "Epoch 5 - Save Best Score: 0.8509 Model\n",
      "========== fold: 3 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2877] Elapsed 0m 0s (remain 29m 45s) Loss: 0.6141(0.6141) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2877] Elapsed 0m 38s (remain 17m 37s) Loss: 0.3517(0.6179) Grad: 18409.3379  LR: 0.000000  \n",
      "Epoch: [1][200/2877] Elapsed 1m 16s (remain 16m 56s) Loss: 0.4591(0.5698) Grad: 25834.0195  LR: 0.000001  \n",
      "Epoch: [1][300/2877] Elapsed 1m 54s (remain 16m 20s) Loss: 0.1906(0.5044) Grad: 10538.9268  LR: 0.000001  \n",
      "Epoch: [1][400/2877] Elapsed 2m 33s (remain 15m 49s) Loss: 0.1418(0.4349) Grad: 8421.7930  LR: 0.000001  \n",
      "Epoch: [1][500/2877] Elapsed 3m 11s (remain 15m 9s) Loss: 0.0491(0.3675) Grad: 1199.0869  LR: 0.000002  \n",
      "Epoch: [1][600/2877] Elapsed 3m 48s (remain 14m 26s) Loss: 0.0419(0.3134) Grad: 642.8183  LR: 0.000002  \n",
      "Epoch: [1][700/2877] Elapsed 4m 26s (remain 13m 46s) Loss: 0.0496(0.2742) Grad: 596.5434  LR: 0.000002  \n",
      "Epoch: [1][800/2877] Elapsed 5m 3s (remain 13m 7s) Loss: 0.0541(0.2449) Grad: 667.9651  LR: 0.000003  \n",
      "Epoch: [1][900/2877] Elapsed 5m 40s (remain 12m 27s) Loss: 0.0250(0.2222) Grad: 736.2622  LR: 0.000003  \n",
      "Epoch: [1][1000/2877] Elapsed 6m 19s (remain 11m 51s) Loss: 0.0508(0.2044) Grad: 787.6733  LR: 0.000003  \n",
      "Epoch: [1][1100/2877] Elapsed 6m 56s (remain 11m 11s) Loss: 0.0771(0.1893) Grad: 1385.5098  LR: 0.000004  \n",
      "Epoch: [1][1200/2877] Elapsed 7m 33s (remain 10m 32s) Loss: 0.0566(0.1769) Grad: 710.1243  LR: 0.000004  \n",
      "Epoch: [1][1300/2877] Elapsed 8m 10s (remain 9m 54s) Loss: 0.0429(0.1660) Grad: 680.6805  LR: 0.000005  \n",
      "Epoch: [1][1400/2877] Elapsed 8m 47s (remain 9m 15s) Loss: 0.0149(0.1566) Grad: 492.7850  LR: 0.000005  \n",
      "Epoch: [1][1500/2877] Elapsed 9m 24s (remain 8m 37s) Loss: 0.0305(0.1482) Grad: 1167.7208  LR: 0.000005  \n",
      "Epoch: [1][1600/2877] Elapsed 10m 2s (remain 8m 0s) Loss: 0.0274(0.1404) Grad: 3567.5161  LR: 0.000005  \n",
      "Epoch: [1][1700/2877] Elapsed 10m 42s (remain 7m 23s) Loss: 0.0170(0.1331) Grad: 1594.3165  LR: 0.000005  \n",
      "Epoch: [1][1800/2877] Elapsed 11m 19s (remain 6m 46s) Loss: 0.0029(0.1267) Grad: 413.3178  LR: 0.000005  \n",
      "Epoch: [1][1900/2877] Elapsed 11m 57s (remain 6m 8s) Loss: 0.0205(0.1209) Grad: 2170.7534  LR: 0.000005  \n",
      "Epoch: [1][2000/2877] Elapsed 12m 35s (remain 5m 30s) Loss: 0.0096(0.1156) Grad: 1147.0076  LR: 0.000005  \n",
      "Epoch: [1][2100/2877] Elapsed 13m 13s (remain 4m 53s) Loss: 0.0040(0.1107) Grad: 476.0863  LR: 0.000005  \n",
      "Epoch: [1][2200/2877] Elapsed 13m 51s (remain 4m 15s) Loss: 0.0074(0.1062) Grad: 1016.5999  LR: 0.000005  \n",
      "Epoch: [1][2300/2877] Elapsed 14m 29s (remain 3m 37s) Loss: 0.0170(0.1022) Grad: 1003.1545  LR: 0.000005  \n",
      "Epoch: [1][2400/2877] Elapsed 15m 10s (remain 3m 0s) Loss: 0.0110(0.0984) Grad: 1956.0792  LR: 0.000005  \n",
      "Epoch: [1][2500/2877] Elapsed 15m 47s (remain 2m 22s) Loss: 0.0145(0.0949) Grad: 2257.8357  LR: 0.000005  \n",
      "Epoch: [1][2600/2877] Elapsed 16m 25s (remain 1m 44s) Loss: 0.0062(0.0917) Grad: 1242.8031  LR: 0.000005  \n",
      "Epoch: [1][2700/2877] Elapsed 17m 3s (remain 1m 6s) Loss: 0.0025(0.0887) Grad: 364.8215  LR: 0.000005  \n",
      "Epoch: [1][2800/2877] Elapsed 17m 44s (remain 0m 28s) Loss: 0.0011(0.0858) Grad: 359.4834  LR: 0.000004  \n",
      "Epoch: [1][2876/2877] Elapsed 18m 15s (remain 0m 0s) Loss: 0.0125(0.0838) Grad: 3414.1531  LR: 0.000004  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 18s) Loss: 0.0045(0.0045) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0063(0.0077) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 46s) Loss: 0.0253(0.0093) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0016(0.0092) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0252(0.0102) \n",
      "EVAL: [500/698] Elapsed 1m 47s (remain 0m 42s) Loss: 0.0073(0.0102) \n",
      "EVAL: [600/698] Elapsed 2m 9s (remain 0m 20s) Loss: 0.0121(0.0099) \n",
      "EVAL: [697/698] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0003(0.0095) \n",
      "Epoch 1 - avg_train_loss: 0.0838  avg_val_loss: 0.0095  time: 1250s\n",
      "Epoch 1 - Score: 0.8174\n",
      "Epoch 1 - Save Best Score: 0.8174 Model\n",
      "Epoch: [2][0/2877] Elapsed 0m 0s (remain 27m 48s) Loss: 0.0059(0.0059) Grad: 14426.8301  LR: 0.000004  \n",
      "Epoch: [2][100/2877] Elapsed 0m 40s (remain 18m 19s) Loss: 0.0027(0.0098) Grad: 10246.8584  LR: 0.000004  \n",
      "Epoch: [2][200/2877] Elapsed 1m 17s (remain 17m 14s) Loss: 0.0106(0.0088) Grad: 29731.4297  LR: 0.000004  \n",
      "Epoch: [2][300/2877] Elapsed 1m 55s (remain 16m 29s) Loss: 0.0243(0.0085) Grad: 32439.3672  LR: 0.000004  \n",
      "Epoch: [2][400/2877] Elapsed 2m 34s (remain 15m 54s) Loss: 0.0052(0.0086) Grad: 11917.9443  LR: 0.000004  \n",
      "Epoch: [2][500/2877] Elapsed 3m 14s (remain 15m 23s) Loss: 0.0106(0.0086) Grad: 22362.2656  LR: 0.000004  \n",
      "Epoch: [2][600/2877] Elapsed 3m 53s (remain 14m 44s) Loss: 0.0137(0.0089) Grad: 45360.4375  LR: 0.000004  \n",
      "Epoch: [2][700/2877] Elapsed 4m 31s (remain 14m 3s) Loss: 0.0124(0.0088) Grad: 19965.9629  LR: 0.000004  \n",
      "Epoch: [2][800/2877] Elapsed 5m 9s (remain 13m 22s) Loss: 0.0068(0.0088) Grad: 17712.7266  LR: 0.000004  \n",
      "Epoch: [2][900/2877] Elapsed 5m 47s (remain 12m 41s) Loss: 0.0101(0.0089) Grad: 33094.7461  LR: 0.000004  \n",
      "Epoch: [2][1000/2877] Elapsed 6m 26s (remain 12m 4s) Loss: 0.0135(0.0089) Grad: 31629.0820  LR: 0.000004  \n",
      "Epoch: [2][1100/2877] Elapsed 7m 5s (remain 11m 25s) Loss: 0.0014(0.0087) Grad: 6666.2588  LR: 0.000004  \n",
      "Epoch: [2][1200/2877] Elapsed 7m 43s (remain 10m 46s) Loss: 0.0001(0.0088) Grad: 455.3080  LR: 0.000004  \n",
      "Epoch: [2][1300/2877] Elapsed 8m 20s (remain 10m 6s) Loss: 0.0068(0.0088) Grad: 27208.0566  LR: 0.000004  \n",
      "Epoch: [2][1400/2877] Elapsed 8m 58s (remain 9m 27s) Loss: 0.0323(0.0088) Grad: 68402.3984  LR: 0.000004  \n",
      "Epoch: [2][1500/2877] Elapsed 9m 37s (remain 8m 49s) Loss: 0.0062(0.0088) Grad: 19911.4688  LR: 0.000004  \n",
      "Epoch: [2][1600/2877] Elapsed 10m 16s (remain 8m 11s) Loss: 0.0040(0.0088) Grad: 17505.7051  LR: 0.000004  \n",
      "Epoch: [2][1700/2877] Elapsed 10m 54s (remain 7m 32s) Loss: 0.0008(0.0087) Grad: 3409.9019  LR: 0.000004  \n",
      "Epoch: [2][1800/2877] Elapsed 11m 32s (remain 6m 53s) Loss: 0.0103(0.0088) Grad: 21508.4043  LR: 0.000004  \n",
      "Epoch: [2][1900/2877] Elapsed 12m 12s (remain 6m 15s) Loss: 0.0047(0.0088) Grad: 13116.8945  LR: 0.000004  \n",
      "Epoch: [2][2000/2877] Elapsed 12m 51s (remain 5m 37s) Loss: 0.0232(0.0089) Grad: 44826.1250  LR: 0.000004  \n",
      "Epoch: [2][2100/2877] Elapsed 13m 29s (remain 4m 58s) Loss: 0.0039(0.0089) Grad: 12202.4336  LR: 0.000004  \n",
      "Epoch: [2][2200/2877] Elapsed 14m 7s (remain 4m 20s) Loss: 0.0030(0.0088) Grad: 6272.4663  LR: 0.000004  \n",
      "Epoch: [2][2300/2877] Elapsed 14m 49s (remain 3m 42s) Loss: 0.0074(0.0088) Grad: 23064.8555  LR: 0.000004  \n",
      "Epoch: [2][2400/2877] Elapsed 15m 27s (remain 3m 3s) Loss: 0.0096(0.0088) Grad: 49569.4141  LR: 0.000004  \n",
      "Epoch: [2][2500/2877] Elapsed 16m 5s (remain 2m 25s) Loss: 0.0013(0.0088) Grad: 9746.7578  LR: 0.000003  \n",
      "Epoch: [2][2600/2877] Elapsed 16m 44s (remain 1m 46s) Loss: 0.0032(0.0088) Grad: 9032.1611  LR: 0.000003  \n",
      "Epoch: [2][2700/2877] Elapsed 17m 23s (remain 1m 7s) Loss: 0.0013(0.0088) Grad: 11689.4014  LR: 0.000003  \n",
      "Epoch: [2][2800/2877] Elapsed 18m 0s (remain 0m 29s) Loss: 0.0301(0.0089) Grad: 82052.5312  LR: 0.000003  \n",
      "Epoch: [2][2876/2877] Elapsed 18m 29s (remain 0m 0s) Loss: 0.0005(0.0089) Grad: 2059.5103  LR: 0.000003  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 10s) Loss: 0.0042(0.0042) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 8s) Loss: 0.0016(0.0059) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 46s) Loss: 0.0194(0.0080) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0008(0.0078) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0304(0.0088) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 42s) Loss: 0.0073(0.0089) \n",
      "EVAL: [600/698] Elapsed 2m 9s (remain 0m 20s) Loss: 0.0086(0.0086) \n",
      "EVAL: [697/698] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0001(0.0084) \n",
      "Epoch 2 - avg_train_loss: 0.0089  avg_val_loss: 0.0084  time: 1264s\n",
      "Epoch 2 - Score: 0.8478\n",
      "Epoch 2 - Save Best Score: 0.8478 Model\n",
      "Epoch: [3][0/2877] Elapsed 0m 0s (remain 32m 24s) Loss: 0.0057(0.0057) Grad: 30794.6504  LR: 0.000003  \n",
      "Epoch: [3][100/2877] Elapsed 0m 39s (remain 17m 55s) Loss: 0.0087(0.0062) Grad: 25641.3438  LR: 0.000003  \n",
      "Epoch: [3][200/2877] Elapsed 1m 16s (remain 17m 4s) Loss: 0.0075(0.0080) Grad: 21058.0996  LR: 0.000003  \n",
      "Epoch: [3][300/2877] Elapsed 1m 55s (remain 16m 31s) Loss: 0.0046(0.0076) Grad: 29541.4961  LR: 0.000003  \n",
      "Epoch: [3][400/2877] Elapsed 2m 33s (remain 15m 48s) Loss: 0.0052(0.0075) Grad: 18209.7246  LR: 0.000003  \n",
      "Epoch: [3][500/2877] Elapsed 3m 11s (remain 15m 7s) Loss: 0.0027(0.0075) Grad: 89929.6016  LR: 0.000003  \n",
      "Epoch: [3][600/2877] Elapsed 3m 49s (remain 14m 27s) Loss: 0.0006(0.0076) Grad: 2910.6018  LR: 0.000003  \n",
      "Epoch: [3][700/2877] Elapsed 4m 27s (remain 13m 50s) Loss: 0.0329(0.0079) Grad: 79472.9453  LR: 0.000003  \n",
      "Epoch: [3][800/2877] Elapsed 5m 7s (remain 13m 15s) Loss: 0.0061(0.0079) Grad: 30044.2832  LR: 0.000003  \n",
      "Epoch: [3][900/2877] Elapsed 5m 47s (remain 12m 41s) Loss: 0.0090(0.0084) Grad: 12124.8408  LR: 0.000003  \n",
      "Epoch: [3][1000/2877] Elapsed 6m 25s (remain 12m 2s) Loss: 0.0128(0.0084) Grad: 27526.5684  LR: 0.000003  \n",
      "Epoch: [3][1100/2877] Elapsed 7m 3s (remain 11m 22s) Loss: 0.0149(0.0084) Grad: 25128.1719  LR: 0.000003  \n",
      "Epoch: [3][1200/2877] Elapsed 7m 41s (remain 10m 43s) Loss: 0.0014(0.0083) Grad: 14829.3408  LR: 0.000003  \n",
      "Epoch: [3][1300/2877] Elapsed 8m 19s (remain 10m 5s) Loss: 0.0030(0.0083) Grad: 6518.2993  LR: 0.000003  \n",
      "Epoch: [3][1400/2877] Elapsed 8m 57s (remain 9m 26s) Loss: 0.0001(0.0084) Grad: 412.4256  LR: 0.000003  \n",
      "Epoch: [3][1500/2877] Elapsed 9m 35s (remain 8m 47s) Loss: 0.0000(0.0084) Grad: 125.9495  LR: 0.000003  \n",
      "Epoch: [3][1600/2877] Elapsed 10m 14s (remain 8m 9s) Loss: 0.0038(0.0084) Grad: 19420.3105  LR: 0.000003  \n",
      "Epoch: [3][1700/2877] Elapsed 10m 52s (remain 7m 31s) Loss: 0.0211(0.0084) Grad: 48854.3164  LR: 0.000003  \n",
      "Epoch: [3][1800/2877] Elapsed 11m 33s (remain 6m 54s) Loss: 0.0141(0.0083) Grad: 58574.0625  LR: 0.000003  \n",
      "Epoch: [3][1900/2877] Elapsed 12m 11s (remain 6m 15s) Loss: 0.0113(0.0082) Grad: 25666.7227  LR: 0.000003  \n",
      "Epoch: [3][2000/2877] Elapsed 12m 49s (remain 5m 37s) Loss: 0.0049(0.0082) Grad: 26768.9590  LR: 0.000003  \n",
      "Epoch: [3][2100/2877] Elapsed 13m 28s (remain 4m 58s) Loss: 0.0000(0.0081) Grad: 46.7844  LR: 0.000003  \n",
      "Epoch: [3][2200/2877] Elapsed 14m 8s (remain 4m 20s) Loss: 0.0039(0.0081) Grad: 13284.2139  LR: 0.000002  \n",
      "Epoch: [3][2300/2877] Elapsed 14m 45s (remain 3m 41s) Loss: 0.0332(0.0081) Grad: 94817.0781  LR: 0.000002  \n",
      "Epoch: [3][2400/2877] Elapsed 15m 23s (remain 3m 3s) Loss: 0.0007(0.0081) Grad: 3738.2954  LR: 0.000002  \n",
      "Epoch: [3][2500/2877] Elapsed 16m 3s (remain 2m 24s) Loss: 0.0076(0.0080) Grad: 32380.0488  LR: 0.000002  \n",
      "Epoch: [3][2600/2877] Elapsed 16m 41s (remain 1m 46s) Loss: 0.0007(0.0080) Grad: 2500.8174  LR: 0.000002  \n",
      "Epoch: [3][2700/2877] Elapsed 17m 18s (remain 1m 7s) Loss: 0.0070(0.0080) Grad: 40320.2617  LR: 0.000002  \n",
      "Epoch: [3][2800/2877] Elapsed 17m 57s (remain 0m 29s) Loss: 0.0074(0.0079) Grad: 17071.4512  LR: 0.000002  \n",
      "Epoch: [3][2876/2877] Elapsed 18m 26s (remain 0m 0s) Loss: 0.0155(0.0079) Grad: 34086.5781  LR: 0.000002  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 19s) Loss: 0.0037(0.0037) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0025(0.0066) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 45s) Loss: 0.0243(0.0089) \n",
      "EVAL: [300/698] Elapsed 1m 3s (remain 1m 24s) Loss: 0.0003(0.0089) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0261(0.0097) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0047(0.0095) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0091(0.0090) \n",
      "EVAL: [697/698] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0000(0.0088) \n",
      "Epoch 3 - avg_train_loss: 0.0079  avg_val_loss: 0.0088  time: 1260s\n",
      "Epoch 3 - Score: 0.8579\n",
      "Epoch 3 - Save Best Score: 0.8579 Model\n",
      "Epoch: [4][0/2877] Elapsed 0m 0s (remain 33m 7s) Loss: 0.0017(0.0017) Grad: 8738.8359  LR: 0.000002  \n",
      "Epoch: [4][100/2877] Elapsed 0m 39s (remain 17m 54s) Loss: 0.0004(0.0076) Grad: 3061.7988  LR: 0.000002  \n",
      "Epoch: [4][200/2877] Elapsed 1m 16s (remain 17m 2s) Loss: 0.0002(0.0066) Grad: 766.7971  LR: 0.000002  \n",
      "Epoch: [4][300/2877] Elapsed 1m 54s (remain 16m 22s) Loss: 0.0038(0.0063) Grad: 25715.9258  LR: 0.000002  \n",
      "Epoch: [4][400/2877] Elapsed 2m 32s (remain 15m 42s) Loss: 0.0102(0.0069) Grad: 31670.1328  LR: 0.000002  \n",
      "Epoch: [4][500/2877] Elapsed 3m 11s (remain 15m 9s) Loss: 0.0270(0.0071) Grad: 51669.8398  LR: 0.000002  \n",
      "Epoch: [4][600/2877] Elapsed 3m 49s (remain 14m 30s) Loss: 0.0007(0.0071) Grad: 5067.2085  LR: 0.000002  \n",
      "Epoch: [4][700/2877] Elapsed 4m 27s (remain 13m 50s) Loss: 0.0025(0.0070) Grad: 15777.0293  LR: 0.000002  \n",
      "Epoch: [4][800/2877] Elapsed 5m 5s (remain 13m 12s) Loss: 0.0096(0.0071) Grad: 27286.1855  LR: 0.000002  \n",
      "Epoch: [4][900/2877] Elapsed 5m 45s (remain 12m 37s) Loss: 0.0165(0.0073) Grad: 9002.2988  LR: 0.000002  \n",
      "Epoch: [4][1000/2877] Elapsed 6m 23s (remain 11m 58s) Loss: 0.0002(0.0074) Grad: 1079.8966  LR: 0.000002  \n",
      "Epoch: [4][1100/2877] Elapsed 7m 1s (remain 11m 19s) Loss: 0.0100(0.0074) Grad: 45393.8555  LR: 0.000002  \n",
      "Epoch: [4][1200/2877] Elapsed 7m 39s (remain 10m 40s) Loss: 0.0027(0.0074) Grad: 8329.3896  LR: 0.000002  \n",
      "Epoch: [4][1300/2877] Elapsed 8m 16s (remain 10m 1s) Loss: 0.0060(0.0073) Grad: 57551.1914  LR: 0.000002  \n",
      "Epoch: [4][1400/2877] Elapsed 8m 54s (remain 9m 22s) Loss: 0.0003(0.0073) Grad: 1226.8502  LR: 0.000002  \n",
      "Epoch: [4][1500/2877] Elapsed 9m 31s (remain 8m 43s) Loss: 0.0030(0.0073) Grad: 25286.9531  LR: 0.000002  \n",
      "Epoch: [4][1600/2877] Elapsed 10m 10s (remain 8m 6s) Loss: 0.0003(0.0074) Grad: 1954.5854  LR: 0.000002  \n",
      "Epoch: [4][1700/2877] Elapsed 10m 48s (remain 7m 28s) Loss: 0.0003(0.0073) Grad: 1381.5137  LR: 0.000002  \n",
      "Epoch: [4][1800/2877] Elapsed 11m 29s (remain 6m 51s) Loss: 0.0198(0.0072) Grad: 126486.6953  LR: 0.000002  \n",
      "Epoch: [4][1900/2877] Elapsed 12m 7s (remain 6m 13s) Loss: 0.0001(0.0072) Grad: 264.2707  LR: 0.000001  \n",
      "Epoch: [4][2000/2877] Elapsed 12m 45s (remain 5m 34s) Loss: 0.0007(0.0072) Grad: 7764.4917  LR: 0.000001  \n",
      "Epoch: [4][2100/2877] Elapsed 13m 23s (remain 4m 56s) Loss: 0.0006(0.0072) Grad: 5575.8696  LR: 0.000001  \n",
      "Epoch: [4][2200/2877] Elapsed 14m 0s (remain 4m 18s) Loss: 0.0019(0.0072) Grad: 8659.8047  LR: 0.000001  \n",
      "Epoch: [4][2300/2877] Elapsed 14m 39s (remain 3m 40s) Loss: 0.0003(0.0072) Grad: 3055.1958  LR: 0.000001  \n",
      "Epoch: [4][2400/2877] Elapsed 15m 20s (remain 3m 2s) Loss: 0.0020(0.0072) Grad: 8588.4775  LR: 0.000001  \n",
      "Epoch: [4][2500/2877] Elapsed 16m 0s (remain 2m 24s) Loss: 0.0129(0.0072) Grad: 34641.7188  LR: 0.000001  \n",
      "Epoch: [4][2600/2877] Elapsed 16m 38s (remain 1m 45s) Loss: 0.0181(0.0071) Grad: 54406.8359  LR: 0.000001  \n",
      "Epoch: [4][2700/2877] Elapsed 17m 16s (remain 1m 7s) Loss: 0.0062(0.0072) Grad: 11923.6426  LR: 0.000001  \n",
      "Epoch: [4][2800/2877] Elapsed 17m 54s (remain 0m 29s) Loss: 0.0008(0.0072) Grad: 5515.6973  LR: 0.000001  \n",
      "Epoch: [4][2876/2877] Elapsed 18m 23s (remain 0m 0s) Loss: 0.0022(0.0072) Grad: 8891.2920  LR: 0.000001  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 21s) Loss: 0.0024(0.0024) \n",
      "EVAL: [100/698] Elapsed 0m 22s (remain 2m 10s) Loss: 0.0027(0.0065) \n",
      "EVAL: [200/698] Elapsed 0m 43s (remain 1m 46s) Loss: 0.0208(0.0088) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 24s) Loss: 0.0006(0.0087) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0365(0.0095) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 42s) Loss: 0.0052(0.0093) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0088(0.0089) \n",
      "EVAL: [697/698] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0087) \n",
      "Epoch 4 - avg_train_loss: 0.0072  avg_val_loss: 0.0087  time: 1256s\n",
      "Epoch 4 - Score: 0.8587\n",
      "Epoch 4 - Save Best Score: 0.8587 Model\n",
      "Epoch: [5][0/2877] Elapsed 0m 0s (remain 31m 18s) Loss: 0.0001(0.0001) Grad: 1243.5359  LR: 0.000001  \n",
      "Epoch: [5][100/2877] Elapsed 0m 39s (remain 17m 52s) Loss: 0.0063(0.0067) Grad: 29029.1797  LR: 0.000001  \n",
      "Epoch: [5][200/2877] Elapsed 1m 18s (remain 17m 25s) Loss: 0.0024(0.0067) Grad: 11464.3652  LR: 0.000001  \n",
      "Epoch: [5][300/2877] Elapsed 1m 58s (remain 16m 51s) Loss: 0.0042(0.0064) Grad: 15572.6816  LR: 0.000001  \n",
      "Epoch: [5][400/2877] Elapsed 2m 35s (remain 16m 1s) Loss: 0.0026(0.0071) Grad: 5062.0474  LR: 0.000001  \n",
      "Epoch: [5][500/2877] Elapsed 3m 13s (remain 15m 17s) Loss: 0.0009(0.0069) Grad: 7406.0742  LR: 0.000001  \n",
      "Epoch: [5][600/2877] Elapsed 3m 52s (remain 14m 40s) Loss: 0.0004(0.0069) Grad: 8369.5635  LR: 0.000001  \n",
      "Epoch: [5][700/2877] Elapsed 4m 30s (remain 13m 58s) Loss: 0.0011(0.0068) Grad: 3957.8335  LR: 0.000001  \n",
      "Epoch: [5][800/2877] Elapsed 5m 7s (remain 13m 17s) Loss: 0.0039(0.0070) Grad: 12687.6855  LR: 0.000001  \n",
      "Epoch: [5][900/2877] Elapsed 5m 45s (remain 12m 38s) Loss: 0.0027(0.0071) Grad: 5436.9326  LR: 0.000001  \n",
      "Epoch: [5][1000/2877] Elapsed 6m 23s (remain 11m 59s) Loss: 0.0010(0.0071) Grad: 5971.9824  LR: 0.000001  \n",
      "Epoch: [5][1100/2877] Elapsed 7m 1s (remain 11m 20s) Loss: 0.0001(0.0071) Grad: 975.8790  LR: 0.000001  \n",
      "Epoch: [5][1200/2877] Elapsed 7m 39s (remain 10m 40s) Loss: 0.0178(0.0071) Grad: 96958.0469  LR: 0.000001  \n",
      "Epoch: [5][1300/2877] Elapsed 8m 17s (remain 10m 2s) Loss: 0.0014(0.0071) Grad: 11738.2666  LR: 0.000001  \n",
      "Epoch: [5][1400/2877] Elapsed 8m 56s (remain 9m 24s) Loss: 0.0135(0.0071) Grad: 22528.8965  LR: 0.000001  \n",
      "Epoch: [5][1500/2877] Elapsed 9m 34s (remain 8m 46s) Loss: 0.0011(0.0071) Grad: 14234.5410  LR: 0.000001  \n",
      "Epoch: [5][1600/2877] Elapsed 10m 12s (remain 8m 8s) Loss: 0.0008(0.0070) Grad: 6775.0732  LR: 0.000000  \n",
      "Epoch: [5][1700/2877] Elapsed 10m 51s (remain 7m 30s) Loss: 0.0034(0.0069) Grad: 10490.2236  LR: 0.000000  \n",
      "Epoch: [5][1800/2877] Elapsed 11m 30s (remain 6m 52s) Loss: 0.0096(0.0069) Grad: 17449.4961  LR: 0.000000  \n",
      "Epoch: [5][1900/2877] Elapsed 12m 10s (remain 6m 15s) Loss: 0.0026(0.0069) Grad: 7736.7197  LR: 0.000000  \n",
      "Epoch: [5][2000/2877] Elapsed 12m 48s (remain 5m 36s) Loss: 0.0085(0.0068) Grad: 28562.7383  LR: 0.000000  \n",
      "Epoch: [5][2100/2877] Elapsed 13m 28s (remain 4m 58s) Loss: 0.0022(0.0069) Grad: 12730.7803  LR: 0.000000  \n",
      "Epoch: [5][2200/2877] Elapsed 14m 7s (remain 4m 20s) Loss: 0.0050(0.0069) Grad: 54511.5664  LR: 0.000000  \n",
      "Epoch: [5][2300/2877] Elapsed 14m 45s (remain 3m 41s) Loss: 0.0083(0.0070) Grad: 16401.9121  LR: 0.000000  \n",
      "Epoch: [5][2400/2877] Elapsed 15m 25s (remain 3m 3s) Loss: 0.0052(0.0069) Grad: 121439.6406  LR: 0.000000  \n",
      "Epoch: [5][2500/2877] Elapsed 16m 2s (remain 2m 24s) Loss: 0.0009(0.0069) Grad: 6231.5718  LR: 0.000000  \n",
      "Epoch: [5][2600/2877] Elapsed 16m 42s (remain 1m 46s) Loss: 0.0000(0.0069) Grad: 148.0421  LR: 0.000000  \n",
      "Epoch: [5][2700/2877] Elapsed 17m 20s (remain 1m 7s) Loss: 0.0054(0.0069) Grad: 52656.3789  LR: 0.000000  \n",
      "Epoch: [5][2800/2877] Elapsed 17m 58s (remain 0m 29s) Loss: 0.0002(0.0069) Grad: 879.9540  LR: 0.000000  \n",
      "Epoch: [5][2876/2877] Elapsed 18m 27s (remain 0m 0s) Loss: 0.0131(0.0069) Grad: 34765.8359  LR: 0.000000  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 31s) Loss: 0.0026(0.0026) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0011(0.0064) \n",
      "EVAL: [200/698] Elapsed 0m 43s (remain 1m 46s) Loss: 0.0215(0.0089) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 24s) Loss: 0.0003(0.0087) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0334(0.0095) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0052(0.0093) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0087(0.0088) \n",
      "EVAL: [697/698] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0000(0.0086) \n",
      "Epoch 5 - avg_train_loss: 0.0069  avg_val_loss: 0.0086  time: 1260s\n",
      "Epoch 5 - Score: 0.8647\n",
      "Epoch 5 - Save Best Score: 0.8647 Model\n",
      "========== fold: 4 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2850] Elapsed 0m 0s (remain 28m 23s) Loss: 0.4362(0.4362) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2850] Elapsed 0m 38s (remain 17m 25s) Loss: 0.7969(0.6715) Grad: 41735.3203  LR: 0.000000  \n",
      "Epoch: [1][200/2850] Elapsed 1m 18s (remain 17m 14s) Loss: 0.5255(0.6209) Grad: 29121.5293  LR: 0.000001  \n",
      "Epoch: [1][300/2850] Elapsed 1m 57s (remain 16m 31s) Loss: 0.3793(0.5504) Grad: 24097.7031  LR: 0.000001  \n",
      "Epoch: [1][400/2850] Elapsed 2m 35s (remain 15m 49s) Loss: 0.1642(0.4701) Grad: 8964.3711  LR: 0.000001  \n",
      "Epoch: [1][500/2850] Elapsed 3m 13s (remain 15m 7s) Loss: 0.0452(0.3964) Grad: 1126.5477  LR: 0.000002  \n",
      "Epoch: [1][600/2850] Elapsed 3m 53s (remain 14m 33s) Loss: 0.0272(0.3382) Grad: 745.2524  LR: 0.000002  \n",
      "Epoch: [1][700/2850] Elapsed 4m 31s (remain 13m 52s) Loss: 0.0260(0.2957) Grad: 323.1610  LR: 0.000002  \n",
      "Epoch: [1][800/2850] Elapsed 5m 8s (remain 13m 9s) Loss: 0.0473(0.2643) Grad: 711.4789  LR: 0.000003  \n",
      "Epoch: [1][900/2850] Elapsed 5m 46s (remain 12m 29s) Loss: 0.0428(0.2398) Grad: 475.9331  LR: 0.000003  \n",
      "Epoch: [1][1000/2850] Elapsed 6m 25s (remain 11m 52s) Loss: 0.0317(0.2195) Grad: 388.9057  LR: 0.000004  \n",
      "Epoch: [1][1100/2850] Elapsed 7m 2s (remain 11m 10s) Loss: 0.0210(0.2029) Grad: 522.2242  LR: 0.000004  \n",
      "Epoch: [1][1200/2850] Elapsed 7m 40s (remain 10m 31s) Loss: 0.0187(0.1892) Grad: 316.0672  LR: 0.000004  \n",
      "Epoch: [1][1300/2850] Elapsed 8m 17s (remain 9m 52s) Loss: 0.0168(0.1775) Grad: 966.9592  LR: 0.000005  \n",
      "Epoch: [1][1400/2850] Elapsed 8m 55s (remain 9m 13s) Loss: 0.0119(0.1671) Grad: 490.9185  LR: 0.000005  \n",
      "Epoch: [1][1500/2850] Elapsed 9m 34s (remain 8m 35s) Loss: 0.0090(0.1578) Grad: 1090.4569  LR: 0.000005  \n",
      "Epoch: [1][1600/2850] Elapsed 10m 11s (remain 7m 57s) Loss: 0.0132(0.1490) Grad: 2321.1826  LR: 0.000005  \n",
      "Epoch: [1][1700/2850] Elapsed 10m 49s (remain 7m 18s) Loss: 0.0180(0.1412) Grad: 1799.7856  LR: 0.000005  \n",
      "Epoch: [1][1800/2850] Elapsed 11m 27s (remain 6m 40s) Loss: 0.0366(0.1343) Grad: 2567.2549  LR: 0.000005  \n",
      "Epoch: [1][1900/2850] Elapsed 12m 5s (remain 6m 2s) Loss: 0.0033(0.1280) Grad: 482.3215  LR: 0.000005  \n",
      "Epoch: [1][2000/2850] Elapsed 12m 43s (remain 5m 23s) Loss: 0.0091(0.1222) Grad: 1092.1628  LR: 0.000005  \n",
      "Epoch: [1][2100/2850] Elapsed 13m 21s (remain 4m 45s) Loss: 0.0042(0.1169) Grad: 718.4352  LR: 0.000005  \n",
      "Epoch: [1][2200/2850] Elapsed 13m 59s (remain 4m 7s) Loss: 0.0035(0.1123) Grad: 285.5557  LR: 0.000005  \n",
      "Epoch: [1][2300/2850] Elapsed 14m 37s (remain 3m 29s) Loss: 0.0055(0.1080) Grad: 809.0623  LR: 0.000005  \n",
      "Epoch: [1][2400/2850] Elapsed 15m 14s (remain 2m 51s) Loss: 0.0044(0.1039) Grad: 725.0582  LR: 0.000005  \n",
      "Epoch: [1][2500/2850] Elapsed 15m 52s (remain 2m 12s) Loss: 0.0041(0.1002) Grad: 768.8046  LR: 0.000005  \n",
      "Epoch: [1][2600/2850] Elapsed 16m 30s (remain 1m 34s) Loss: 0.0127(0.0968) Grad: 981.7995  LR: 0.000005  \n",
      "Epoch: [1][2700/2850] Elapsed 17m 10s (remain 0m 56s) Loss: 0.0044(0.0936) Grad: 1083.0298  LR: 0.000005  \n",
      "Epoch: [1][2800/2850] Elapsed 17m 47s (remain 0m 18s) Loss: 0.0240(0.0906) Grad: 3006.7754  LR: 0.000004  \n",
      "Epoch: [1][2849/2850] Elapsed 18m 6s (remain 0m 0s) Loss: 0.0097(0.0892) Grad: 1693.0183  LR: 0.000004  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 0s) Loss: 0.0100(0.0100) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0020(0.0103) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0200(0.0122) \n",
      "EVAL: [300/725] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0047(0.0107) \n",
      "EVAL: [400/725] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0967(0.0116) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0098(0.0116) \n",
      "EVAL: [600/725] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0046(0.0113) \n",
      "EVAL: [700/725] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0037(0.0106) \n",
      "EVAL: [724/725] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0083(0.0105) \n",
      "Epoch 1 - avg_train_loss: 0.0892  avg_val_loss: 0.0105  time: 1245s\n",
      "Epoch 1 - Score: 0.8015\n",
      "Epoch 1 - Save Best Score: 0.8015 Model\n",
      "Epoch: [2][0/2850] Elapsed 0m 0s (remain 28m 46s) Loss: 0.0015(0.0015) Grad: 7533.6221  LR: 0.000004  \n",
      "Epoch: [2][100/2850] Elapsed 0m 40s (remain 18m 9s) Loss: 0.0018(0.0081) Grad: 5910.9019  LR: 0.000004  \n",
      "Epoch: [2][200/2850] Elapsed 1m 17s (remain 17m 5s) Loss: 0.0176(0.0088) Grad: 45144.2969  LR: 0.000004  \n",
      "Epoch: [2][300/2850] Elapsed 1m 55s (remain 16m 21s) Loss: 0.0349(0.0096) Grad: 41161.0508  LR: 0.000004  \n",
      "Epoch: [2][400/2850] Elapsed 2m 34s (remain 15m 43s) Loss: 0.0082(0.0091) Grad: 17641.7383  LR: 0.000004  \n",
      "Epoch: [2][500/2850] Elapsed 3m 12s (remain 15m 2s) Loss: 0.0044(0.0094) Grad: 12197.4277  LR: 0.000004  \n",
      "Epoch: [2][600/2850] Elapsed 3m 51s (remain 14m 27s) Loss: 0.0086(0.0089) Grad: 21552.7695  LR: 0.000004  \n",
      "Epoch: [2][700/2850] Elapsed 4m 29s (remain 13m 46s) Loss: 0.0662(0.0090) Grad: 68586.8516  LR: 0.000004  \n",
      "Epoch: [2][800/2850] Elapsed 5m 7s (remain 13m 6s) Loss: 0.0094(0.0090) Grad: 23663.3945  LR: 0.000004  \n",
      "Epoch: [2][900/2850] Elapsed 5m 44s (remain 12m 26s) Loss: 0.0016(0.0089) Grad: 8094.3540  LR: 0.000004  \n",
      "Epoch: [2][1000/2850] Elapsed 6m 22s (remain 11m 46s) Loss: 0.0018(0.0089) Grad: 4464.9292  LR: 0.000004  \n",
      "Epoch: [2][1100/2850] Elapsed 7m 0s (remain 11m 7s) Loss: 0.0035(0.0090) Grad: 15575.4336  LR: 0.000004  \n",
      "Epoch: [2][1200/2850] Elapsed 7m 38s (remain 10m 29s) Loss: 0.0013(0.0090) Grad: 9121.9492  LR: 0.000004  \n",
      "Epoch: [2][1300/2850] Elapsed 8m 17s (remain 9m 52s) Loss: 0.0144(0.0090) Grad: 20131.3086  LR: 0.000004  \n",
      "Epoch: [2][1400/2850] Elapsed 8m 56s (remain 9m 14s) Loss: 0.0000(0.0090) Grad: 152.1498  LR: 0.000004  \n",
      "Epoch: [2][1500/2850] Elapsed 9m 34s (remain 8m 35s) Loss: 0.0001(0.0090) Grad: 1292.8469  LR: 0.000004  \n",
      "Epoch: [2][1600/2850] Elapsed 10m 12s (remain 7m 58s) Loss: 0.0047(0.0090) Grad: 16112.3271  LR: 0.000004  \n",
      "Epoch: [2][1700/2850] Elapsed 10m 50s (remain 7m 19s) Loss: 0.0091(0.0089) Grad: 28675.1543  LR: 0.000004  \n",
      "Epoch: [2][1800/2850] Elapsed 11m 28s (remain 6m 41s) Loss: 0.0101(0.0089) Grad: 35547.8008  LR: 0.000004  \n",
      "Epoch: [2][1900/2850] Elapsed 12m 6s (remain 6m 2s) Loss: 0.0016(0.0089) Grad: 5243.1577  LR: 0.000004  \n",
      "Epoch: [2][2000/2850] Elapsed 12m 45s (remain 5m 24s) Loss: 0.0011(0.0088) Grad: 9484.2480  LR: 0.000004  \n",
      "Epoch: [2][2100/2850] Elapsed 13m 23s (remain 4m 46s) Loss: 0.0029(0.0088) Grad: 3455.2209  LR: 0.000004  \n",
      "Epoch: [2][2200/2850] Elapsed 14m 2s (remain 4m 8s) Loss: 0.0017(0.0088) Grad: 4330.1431  LR: 0.000004  \n",
      "Epoch: [2][2300/2850] Elapsed 14m 40s (remain 3m 30s) Loss: 0.0106(0.0088) Grad: 21847.3320  LR: 0.000004  \n",
      "Epoch: [2][2400/2850] Elapsed 15m 18s (remain 2m 51s) Loss: 0.0008(0.0088) Grad: 5523.7729  LR: 0.000004  \n",
      "Epoch: [2][2500/2850] Elapsed 15m 56s (remain 2m 13s) Loss: 0.0007(0.0088) Grad: 5228.9780  LR: 0.000003  \n",
      "Epoch: [2][2600/2850] Elapsed 16m 37s (remain 1m 35s) Loss: 0.0268(0.0089) Grad: 106977.6484  LR: 0.000003  \n",
      "Epoch: [2][2700/2850] Elapsed 17m 15s (remain 0m 57s) Loss: 0.0019(0.0088) Grad: 9613.7197  LR: 0.000003  \n",
      "Epoch: [2][2800/2850] Elapsed 17m 53s (remain 0m 18s) Loss: 0.0046(0.0088) Grad: 14904.5508  LR: 0.000003  \n",
      "Epoch: [2][2849/2850] Elapsed 18m 12s (remain 0m 0s) Loss: 0.0037(0.0088) Grad: 12222.9062  LR: 0.000003  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 35s) Loss: 0.0082(0.0082) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0010(0.0083) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 53s) Loss: 0.0206(0.0111) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 31s) Loss: 0.0038(0.0097) \n",
      "EVAL: [400/725] Elapsed 1m 26s (remain 1m 9s) Loss: 0.0684(0.0104) \n",
      "EVAL: [500/725] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0085(0.0106) \n",
      "EVAL: [600/725] Elapsed 2m 9s (remain 0m 26s) Loss: 0.0024(0.0103) \n",
      "EVAL: [700/725] Elapsed 2m 30s (remain 0m 5s) Loss: 0.0009(0.0096) \n",
      "EVAL: [724/725] Elapsed 2m 35s (remain 0m 0s) Loss: 0.0115(0.0094) \n",
      "Epoch 2 - avg_train_loss: 0.0088  avg_val_loss: 0.0094  time: 1253s\n",
      "Epoch 2 - Score: 0.8389\n",
      "Epoch 2 - Save Best Score: 0.8389 Model\n",
      "Epoch: [3][0/2850] Elapsed 0m 0s (remain 29m 43s) Loss: 0.0034(0.0034) Grad: 17550.7910  LR: 0.000003  \n",
      "Epoch: [3][100/2850] Elapsed 0m 40s (remain 18m 25s) Loss: 0.0012(0.0089) Grad: 8863.7764  LR: 0.000003  \n",
      "Epoch: [3][200/2850] Elapsed 1m 19s (remain 17m 23s) Loss: 0.0028(0.0082) Grad: 2997.2358  LR: 0.000003  \n",
      "Epoch: [3][300/2850] Elapsed 1m 57s (remain 16m 32s) Loss: 0.0003(0.0077) Grad: 3433.9451  LR: 0.000003  \n",
      "Epoch: [3][400/2850] Elapsed 2m 34s (remain 15m 46s) Loss: 0.0173(0.0082) Grad: 14152.1973  LR: 0.000003  \n",
      "Epoch: [3][500/2850] Elapsed 3m 12s (remain 15m 3s) Loss: 0.0023(0.0080) Grad: 5675.9878  LR: 0.000003  \n",
      "Epoch: [3][600/2850] Elapsed 3m 50s (remain 14m 22s) Loss: 0.0048(0.0081) Grad: 10689.2969  LR: 0.000003  \n",
      "Epoch: [3][700/2850] Elapsed 4m 29s (remain 13m 44s) Loss: 0.0016(0.0075) Grad: 6922.0317  LR: 0.000003  \n",
      "Epoch: [3][800/2850] Elapsed 5m 8s (remain 13m 9s) Loss: 0.0108(0.0076) Grad: 17814.1504  LR: 0.000003  \n",
      "Epoch: [3][900/2850] Elapsed 5m 46s (remain 12m 30s) Loss: 0.0461(0.0077) Grad: 163346.0312  LR: 0.000003  \n",
      "Epoch: [3][1000/2850] Elapsed 6m 24s (remain 11m 50s) Loss: 0.0114(0.0078) Grad: 27912.9902  LR: 0.000003  \n",
      "Epoch: [3][1100/2850] Elapsed 7m 4s (remain 11m 13s) Loss: 0.0026(0.0077) Grad: 11159.6455  LR: 0.000003  \n",
      "Epoch: [3][1200/2850] Elapsed 7m 42s (remain 10m 34s) Loss: 0.0006(0.0079) Grad: 2251.4712  LR: 0.000003  \n",
      "Epoch: [3][1300/2850] Elapsed 8m 19s (remain 9m 55s) Loss: 0.0232(0.0078) Grad: 62854.3008  LR: 0.000003  \n",
      "Epoch: [3][1400/2850] Elapsed 8m 57s (remain 9m 16s) Loss: 0.0001(0.0078) Grad: 345.8549  LR: 0.000003  \n",
      "Epoch: [3][1500/2850] Elapsed 9m 36s (remain 8m 38s) Loss: 0.0021(0.0078) Grad: 28661.6973  LR: 0.000003  \n",
      "Epoch: [3][1600/2850] Elapsed 10m 15s (remain 7m 59s) Loss: 0.0066(0.0078) Grad: 44094.2930  LR: 0.000003  \n",
      "Epoch: [3][1700/2850] Elapsed 10m 52s (remain 7m 20s) Loss: 0.0008(0.0078) Grad: 4172.8052  LR: 0.000003  \n",
      "Epoch: [3][1800/2850] Elapsed 11m 30s (remain 6m 41s) Loss: 0.0001(0.0077) Grad: 279.9475  LR: 0.000003  \n",
      "Epoch: [3][1900/2850] Elapsed 12m 8s (remain 6m 3s) Loss: 0.0046(0.0077) Grad: 103795.8594  LR: 0.000003  \n",
      "Epoch: [3][2000/2850] Elapsed 12m 46s (remain 5m 25s) Loss: 0.0142(0.0077) Grad: 54215.1094  LR: 0.000003  \n",
      "Epoch: [3][2100/2850] Elapsed 13m 25s (remain 4m 47s) Loss: 0.0021(0.0077) Grad: 10300.7451  LR: 0.000003  \n",
      "Epoch: [3][2200/2850] Elapsed 14m 3s (remain 4m 8s) Loss: 0.0085(0.0078) Grad: 18411.7129  LR: 0.000002  \n",
      "Epoch: [3][2300/2850] Elapsed 14m 41s (remain 3m 30s) Loss: 0.0067(0.0077) Grad: 13159.5186  LR: 0.000002  \n",
      "Epoch: [3][2400/2850] Elapsed 15m 19s (remain 2m 51s) Loss: 0.0321(0.0078) Grad: 31905.1758  LR: 0.000002  \n",
      "Epoch: [3][2500/2850] Elapsed 15m 57s (remain 2m 13s) Loss: 0.0024(0.0077) Grad: 6335.1611  LR: 0.000002  \n",
      "Epoch: [3][2600/2850] Elapsed 16m 35s (remain 1m 35s) Loss: 0.0017(0.0077) Grad: 6227.9492  LR: 0.000002  \n",
      "Epoch: [3][2700/2850] Elapsed 17m 14s (remain 0m 57s) Loss: 0.0021(0.0076) Grad: 5772.0996  LR: 0.000002  \n",
      "Epoch: [3][2800/2850] Elapsed 17m 52s (remain 0m 18s) Loss: 0.0008(0.0076) Grad: 7980.8750  LR: 0.000002  \n",
      "Epoch: [3][2849/2850] Elapsed 18m 10s (remain 0m 0s) Loss: 0.0081(0.0076) Grad: 69605.9297  LR: 0.000002  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 3s) Loss: 0.0079(0.0079) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0008(0.0082) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0227(0.0103) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0023(0.0091) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0832(0.0102) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0121(0.0103) \n",
      "EVAL: [600/725] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0057(0.0100) \n",
      "EVAL: [700/725] Elapsed 2m 29s (remain 0m 5s) Loss: 0.0005(0.0093) \n",
      "EVAL: [724/725] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0121(0.0091) \n",
      "Epoch 3 - avg_train_loss: 0.0076  avg_val_loss: 0.0091  time: 1250s\n",
      "Epoch 3 - Score: 0.8490\n",
      "Epoch 3 - Save Best Score: 0.8490 Model\n",
      "Epoch: [4][0/2850] Elapsed 0m 0s (remain 32m 17s) Loss: 0.0005(0.0005) Grad: 1342.1863  LR: 0.000002  \n",
      "Epoch: [4][100/2850] Elapsed 0m 39s (remain 17m 49s) Loss: 0.0016(0.0068) Grad: 5160.2324  LR: 0.000002  \n",
      "Epoch: [4][200/2850] Elapsed 1m 17s (remain 16m 57s) Loss: 0.0237(0.0064) Grad: 75171.7969  LR: 0.000002  \n",
      "Epoch: [4][300/2850] Elapsed 1m 55s (remain 16m 14s) Loss: 0.0085(0.0067) Grad: 119917.2344  LR: 0.000002  \n",
      "Epoch: [4][400/2850] Elapsed 2m 33s (remain 15m 37s) Loss: 0.0020(0.0071) Grad: 34563.3789  LR: 0.000002  \n",
      "Epoch: [4][500/2850] Elapsed 3m 11s (remain 14m 58s) Loss: 0.0084(0.0071) Grad: 12848.7637  LR: 0.000002  \n",
      "Epoch: [4][600/2850] Elapsed 3m 49s (remain 14m 18s) Loss: 0.0022(0.0069) Grad: 25197.5918  LR: 0.000002  \n",
      "Epoch: [4][700/2850] Elapsed 4m 26s (remain 13m 38s) Loss: 0.0026(0.0067) Grad: 7802.6504  LR: 0.000002  \n",
      "Epoch: [4][800/2850] Elapsed 5m 5s (remain 13m 1s) Loss: 0.0092(0.0068) Grad: 60038.4102  LR: 0.000002  \n",
      "Epoch: [4][900/2850] Elapsed 5m 44s (remain 12m 24s) Loss: 0.0042(0.0068) Grad: 23324.0898  LR: 0.000002  \n",
      "Epoch: [4][1000/2850] Elapsed 6m 22s (remain 11m 47s) Loss: 0.0152(0.0069) Grad: 37976.8164  LR: 0.000002  \n",
      "Epoch: [4][1100/2850] Elapsed 7m 0s (remain 11m 8s) Loss: 0.0256(0.0069) Grad: 60105.0781  LR: 0.000002  \n",
      "Epoch: [4][1200/2850] Elapsed 7m 38s (remain 10m 30s) Loss: 0.0148(0.0070) Grad: 32952.8672  LR: 0.000002  \n",
      "Epoch: [4][1300/2850] Elapsed 8m 16s (remain 9m 50s) Loss: 0.0073(0.0070) Grad: 22456.7480  LR: 0.000002  \n",
      "Epoch: [4][1400/2850] Elapsed 8m 53s (remain 9m 12s) Loss: 0.0063(0.0070) Grad: 16226.9980  LR: 0.000002  \n",
      "Epoch: [4][1500/2850] Elapsed 9m 31s (remain 8m 33s) Loss: 0.0015(0.0070) Grad: 5493.8945  LR: 0.000002  \n",
      "Epoch: [4][1600/2850] Elapsed 10m 9s (remain 7m 55s) Loss: 0.0005(0.0070) Grad: 3314.0222  LR: 0.000002  \n",
      "Epoch: [4][1700/2850] Elapsed 10m 50s (remain 7m 19s) Loss: 0.0137(0.0069) Grad: 121673.0938  LR: 0.000002  \n",
      "Epoch: [4][1800/2850] Elapsed 11m 30s (remain 6m 42s) Loss: 0.0037(0.0070) Grad: 21211.6777  LR: 0.000002  \n",
      "Epoch: [4][1900/2850] Elapsed 12m 8s (remain 6m 3s) Loss: 0.0066(0.0070) Grad: 36812.5781  LR: 0.000001  \n",
      "Epoch: [4][2000/2850] Elapsed 12m 45s (remain 5m 24s) Loss: 0.0010(0.0071) Grad: 3098.8823  LR: 0.000001  \n",
      "Epoch: [4][2100/2850] Elapsed 13m 24s (remain 4m 46s) Loss: 0.0017(0.0071) Grad: 12556.3428  LR: 0.000001  \n",
      "Epoch: [4][2200/2850] Elapsed 14m 4s (remain 4m 9s) Loss: 0.0062(0.0071) Grad: 17763.4883  LR: 0.000001  \n",
      "Epoch: [4][2300/2850] Elapsed 14m 42s (remain 3m 30s) Loss: 0.0124(0.0071) Grad: 50076.8555  LR: 0.000001  \n",
      "Epoch: [4][2400/2850] Elapsed 15m 19s (remain 2m 52s) Loss: 0.0020(0.0070) Grad: 10938.6348  LR: 0.000001  \n",
      "Epoch: [4][2500/2850] Elapsed 15m 59s (remain 2m 13s) Loss: 0.0182(0.0070) Grad: 28553.4922  LR: 0.000001  \n",
      "Epoch: [4][2600/2850] Elapsed 16m 38s (remain 1m 35s) Loss: 0.0006(0.0071) Grad: 2008.6057  LR: 0.000001  \n",
      "Epoch: [4][2700/2850] Elapsed 17m 15s (remain 0m 57s) Loss: 0.0000(0.0070) Grad: 115.5278  LR: 0.000001  \n",
      "Epoch: [4][2800/2850] Elapsed 17m 53s (remain 0m 18s) Loss: 0.0011(0.0070) Grad: 3197.7776  LR: 0.000001  \n",
      "Epoch: [4][2849/2850] Elapsed 18m 11s (remain 0m 0s) Loss: 0.0001(0.0070) Grad: 1369.2990  LR: 0.000001  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 23s) Loss: 0.0068(0.0068) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0007(0.0084) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0190(0.0108) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0039(0.0094) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0739(0.0103) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0094(0.0105) \n",
      "EVAL: [600/725] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0065(0.0101) \n",
      "EVAL: [700/725] Elapsed 2m 29s (remain 0m 5s) Loss: 0.0005(0.0094) \n",
      "EVAL: [724/725] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0133(0.0092) \n",
      "Epoch 4 - avg_train_loss: 0.0070  avg_val_loss: 0.0092  time: 1251s\n",
      "Epoch 4 - Score: 0.8546\n",
      "Epoch 4 - Save Best Score: 0.8546 Model\n",
      "Epoch: [5][0/2850] Elapsed 0m 0s (remain 31m 20s) Loss: 0.0019(0.0019) Grad: 9349.4307  LR: 0.000001  \n",
      "Epoch: [5][100/2850] Elapsed 0m 40s (remain 18m 19s) Loss: 0.0002(0.0069) Grad: 2747.3877  LR: 0.000001  \n",
      "Epoch: [5][200/2850] Elapsed 1m 18s (remain 17m 9s) Loss: 0.0026(0.0070) Grad: 8321.3652  LR: 0.000001  \n",
      "Epoch: [5][300/2850] Elapsed 1m 56s (remain 16m 24s) Loss: 0.0151(0.0073) Grad: 13831.0703  LR: 0.000001  \n",
      "Epoch: [5][400/2850] Elapsed 2m 34s (remain 15m 40s) Loss: 0.0048(0.0070) Grad: 16043.0566  LR: 0.000001  \n",
      "Epoch: [5][500/2850] Elapsed 3m 11s (remain 14m 56s) Loss: 0.0053(0.0069) Grad: 18145.0703  LR: 0.000001  \n",
      "Epoch: [5][600/2850] Elapsed 3m 49s (remain 14m 17s) Loss: 0.0036(0.0069) Grad: 17374.5098  LR: 0.000001  \n",
      "Epoch: [5][700/2850] Elapsed 4m 28s (remain 13m 43s) Loss: 0.0016(0.0067) Grad: 5716.9077  LR: 0.000001  \n",
      "Epoch: [5][800/2850] Elapsed 5m 6s (remain 13m 4s) Loss: 0.0000(0.0065) Grad: 135.5249  LR: 0.000001  \n",
      "Epoch: [5][900/2850] Elapsed 5m 44s (remain 12m 24s) Loss: 0.0009(0.0065) Grad: 13210.1172  LR: 0.000001  \n",
      "Epoch: [5][1000/2850] Elapsed 6m 23s (remain 11m 47s) Loss: 0.0011(0.0065) Grad: 7838.0264  LR: 0.000001  \n",
      "Epoch: [5][1100/2850] Elapsed 7m 2s (remain 11m 11s) Loss: 0.0018(0.0067) Grad: 13010.7412  LR: 0.000001  \n",
      "Epoch: [5][1200/2850] Elapsed 7m 40s (remain 10m 32s) Loss: 0.0000(0.0066) Grad: 324.6355  LR: 0.000001  \n",
      "Epoch: [5][1300/2850] Elapsed 8m 18s (remain 9m 53s) Loss: 0.0023(0.0065) Grad: 19295.5469  LR: 0.000001  \n",
      "Epoch: [5][1400/2850] Elapsed 8m 56s (remain 9m 14s) Loss: 0.0007(0.0064) Grad: 2989.6023  LR: 0.000001  \n",
      "Epoch: [5][1500/2850] Elapsed 9m 36s (remain 8m 37s) Loss: 0.0020(0.0065) Grad: 8626.9678  LR: 0.000001  \n",
      "Epoch: [5][1600/2850] Elapsed 10m 14s (remain 7m 59s) Loss: 0.0010(0.0065) Grad: 15258.0010  LR: 0.000000  \n",
      "Epoch: [5][1700/2850] Elapsed 10m 51s (remain 7m 20s) Loss: 0.0001(0.0065) Grad: 383.7470  LR: 0.000000  \n",
      "Epoch: [5][1800/2850] Elapsed 11m 30s (remain 6m 41s) Loss: 0.0286(0.0065) Grad: 69134.2812  LR: 0.000000  \n",
      "Epoch: [5][1900/2850] Elapsed 12m 8s (remain 6m 3s) Loss: 0.0021(0.0065) Grad: 10449.8730  LR: 0.000000  \n",
      "Epoch: [5][2000/2850] Elapsed 12m 46s (remain 5m 25s) Loss: 0.0559(0.0065) Grad: 52900.4492  LR: 0.000000  \n",
      "Epoch: [5][2100/2850] Elapsed 13m 24s (remain 4m 46s) Loss: 0.0050(0.0066) Grad: 13788.0117  LR: 0.000000  \n",
      "Epoch: [5][2200/2850] Elapsed 14m 4s (remain 4m 8s) Loss: 0.0003(0.0066) Grad: 3018.3860  LR: 0.000000  \n",
      "Epoch: [5][2300/2850] Elapsed 14m 42s (remain 3m 30s) Loss: 0.0010(0.0066) Grad: 14100.0479  LR: 0.000000  \n",
      "Epoch: [5][2400/2850] Elapsed 15m 19s (remain 2m 52s) Loss: 0.0011(0.0065) Grad: 5657.1719  LR: 0.000000  \n",
      "Epoch: [5][2500/2850] Elapsed 15m 57s (remain 2m 13s) Loss: 0.0000(0.0066) Grad: 137.4626  LR: 0.000000  \n",
      "Epoch: [5][2600/2850] Elapsed 16m 35s (remain 1m 35s) Loss: 0.0093(0.0067) Grad: 20104.2949  LR: 0.000000  \n",
      "Epoch: [5][2700/2850] Elapsed 17m 13s (remain 0m 57s) Loss: 0.0005(0.0067) Grad: 1974.2577  LR: 0.000000  \n",
      "Epoch: [5][2800/2850] Elapsed 17m 53s (remain 0m 18s) Loss: 0.0002(0.0066) Grad: 927.3901  LR: 0.000000  \n",
      "Epoch: [5][2849/2850] Elapsed 18m 11s (remain 0m 0s) Loss: 0.0002(0.0067) Grad: 1500.1263  LR: 0.000000  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 23s) Loss: 0.0080(0.0080) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 15s) Loss: 0.0008(0.0090) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0143(0.0115) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0059(0.0099) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0705(0.0107) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0098(0.0109) \n",
      "EVAL: [600/725] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0053(0.0104) \n",
      "EVAL: [700/725] Elapsed 2m 29s (remain 0m 5s) Loss: 0.0004(0.0097) \n",
      "EVAL: [724/725] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0132(0.0095) \n",
      "Epoch 5 - avg_train_loss: 0.0067  avg_val_loss: 0.0095  time: 1251s\n",
      "Epoch 5 - Score: 0.8580\n",
      "Epoch 5 - Save Best Score: 0.8580 Model\n",
      "Best thres: 0.5, Score: 0.8605\n",
      "Best thres: 0.5541015625000001, Score: 0.8608\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873a7ab9a61145f7b0c9a36dc5d7a146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae112f4569794cc8a44c8c2efe89e9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eec8dd6b51c4bfe88dbf926de87010f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5c0511e31c496f87747fd15d8ea007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6cd932ae9e4b479af2974a42beadc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp023.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00419a15e9834e98b8a3459b62d01f8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "008f77fefdba425ab2c755f515693e6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05fdce5a55c1483a937d07a50bd9465e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b48bd338cc94fe396aa1b736b9a2507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f856d468c8a4c4c9c83b5b263745508": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1193874a74974cc59982c8d5e3ced585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8e243ea82e59492fb5b845e51a56347a",
       "IPY_MODEL_55ac42bee2ce4f00841b8bd49a7c552d",
       "IPY_MODEL_2281dd4891c640a0b31c23976223f2ba"
      ],
      "layout": "IPY_MODEL_84ea1506dcad4e01ad1cc35b76c0339a"
     }
    },
    "160e78a145894001b2a1295627d80df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_605151b49d7641a28ebd0ca083770c69",
       "IPY_MODEL_8f8c8632070c4fa0a3182521f41e9c40",
       "IPY_MODEL_dfb4641da88e47d3bafabbaa56bc6916"
      ],
      "layout": "IPY_MODEL_008f77fefdba425ab2c755f515693e6f"
     }
    },
    "19783f5141cb47f8aaa057fb01dda913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c55e9e0223548fbbbe29b3e11e59d50",
      "placeholder": "​",
      "style": "IPY_MODEL_1faca6dc4b0e43988d2f81cd209297be",
      "value": " 143/143 [00:00&lt;00:00, 3251.56it/s]"
     }
    },
    "1ad701d95f084c98bd1bf0e9d7d498a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e0d277fe44242e19e3bec17a1cb7280": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1faca6dc4b0e43988d2f81cd209297be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "219090e2dd934c1296f12660ea69b161": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05fdce5a55c1483a937d07a50bd9465e",
      "placeholder": "​",
      "style": "IPY_MODEL_00419a15e9834e98b8a3459b62d01f8b",
      "value": " 2/2 [00:00&lt;00:00,  1.25it/s]"
     }
    },
    "2281dd4891c640a0b31c23976223f2ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b311e42f1294339a07248b31db0c26c",
      "placeholder": "​",
      "style": "IPY_MODEL_ab8e5c4cef00426fa0cf2fc25c51381a",
      "value": " 2/2 [00:00&lt;00:00,  1.31it/s]"
     }
    },
    "26b1a86ee1ff4ce2862c13d47be2b2d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b311e42f1294339a07248b31db0c26c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c55e9e0223548fbbbe29b3e11e59d50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ddd9fc857b549a4ba446dd64a1dd1d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "331b7288a5024ce3a5036af53eb75cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b50983bfae8445fa305d1edadd651af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b09413b459c8406882a16db62e8df9c0",
      "placeholder": "​",
      "style": "IPY_MODEL_8478e8bf8b6146b48e717b84c021e7ab",
      "value": "100%"
     }
    },
    "3ca14e3fd6b84312b0af50a89d5ac7c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fb5b968d9ab4e88964b6b126c6023d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "410c3733ee43430eb55278748d07bc45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44650208feba4c118904c7efc9887532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "490bfe688fe1419996b69f7de1cfee23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5068fb514bf143ba812fe202c3e7a83d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5292a911912d43c2b80919e486b99de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8234c7d9369644dea7e5c7e8fe436771",
      "placeholder": "​",
      "style": "IPY_MODEL_3ca14e3fd6b84312b0af50a89d5ac7c1",
      "value": "100%"
     }
    },
    "537dee640701470c8fc3cc29e7940bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "548835fe547d4114bfd39e5fac680635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5536b7aaba7c41f28197e318b362ec75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b50983bfae8445fa305d1edadd651af",
       "IPY_MODEL_cdbf6aefee644006826f76e2f6722b07",
       "IPY_MODEL_7c62f6a2b08c41a8bc3ecf2efa58c325"
      ],
      "layout": "IPY_MODEL_5ecd28892bb84432935145e27ac71de7"
     }
    },
    "55ac42bee2ce4f00841b8bd49a7c552d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e0d277fe44242e19e3bec17a1cb7280",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5068fb514bf143ba812fe202c3e7a83d",
      "value": 2
     }
    },
    "5a3f361a320f480aa8a4115366073d32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ecd28892bb84432935145e27ac71de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "605151b49d7641a28ebd0ca083770c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dc964a8934744608f92a6af0f0f923f",
      "placeholder": "​",
      "style": "IPY_MODEL_537dee640701470c8fc3cc29e7940bee",
      "value": "100%"
     }
    },
    "63aa4d26409d437fa76e5a156bb04791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65d16c05424c4df0b79b5786be8bd5d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661a9a315f8646a49162891ae47c69e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74fa3a6b51ad46958e58de5580cf5333",
       "IPY_MODEL_810a830f3b6743b9b074867dd8e4e179",
       "IPY_MODEL_7316ae87cfb849898eb022e100730ba2"
      ],
      "layout": "IPY_MODEL_ef004a834af944abbd512fa3218642a1"
     }
    },
    "6919ba0239084b04988e1de02316c76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d74dcf5002c4752af12a65c3aca2113": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc964a8934744608f92a6af0f0f923f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a8b4ea52534d4e9feab6c6fdd72a77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7316ae87cfb849898eb022e100730ba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ddd9fc857b549a4ba446dd64a1dd1d4",
      "placeholder": "​",
      "style": "IPY_MODEL_0b48bd338cc94fe396aa1b736b9a2507",
      "value": " 42146/42146 [00:22&lt;00:00, 1885.59it/s]"
     }
    },
    "74fa3a6b51ad46958e58de5580cf5333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d891639f26644e8a05d7fe38d178245",
      "placeholder": "​",
      "style": "IPY_MODEL_c7cb034c107247cba318475c9952b4ac",
      "value": "100%"
     }
    },
    "789324d1692d4f478d5b95491b03fc22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c62f6a2b08c41a8bc3ecf2efa58c325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e48e5c946462499ab018748ccf80c5b5",
      "placeholder": "​",
      "style": "IPY_MODEL_63aa4d26409d437fa76e5a156bb04791",
      "value": " 2/2 [00:01&lt;00:00,  1.16it/s]"
     }
    },
    "7d891639f26644e8a05d7fe38d178245": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e210db5a5fe41f696351dc87d525ee4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ed0ca5ee62d45d89050f3caf3d528c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "810a830f3b6743b9b074867dd8e4e179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ed0ca5ee62d45d89050f3caf3d528c9",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8a7a19edb074139baefe21f1901d4f4",
      "value": 42146
     }
    },
    "8234c7d9369644dea7e5c7e8fe436771": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8478e8bf8b6146b48e717b84c021e7ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84ea1506dcad4e01ad1cc35b76c0339a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e243ea82e59492fb5b845e51a56347a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_548835fe547d4114bfd39e5fac680635",
      "placeholder": "​",
      "style": "IPY_MODEL_6919ba0239084b04988e1de02316c76e",
      "value": "100%"
     }
    },
    "8f8c8632070c4fa0a3182521f41e9c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d76610cad4f645f187b26f1b82733569",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_925a3ae98bd6488eb7cffdec89d768da",
      "value": 2
     }
    },
    "925a3ae98bd6488eb7cffdec89d768da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "953c495e9f64430cbdd9184bb0bd35cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9815ec90f12a4696a85db6dc629ec62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e210db5a5fe41f696351dc87d525ee4",
      "placeholder": "​",
      "style": "IPY_MODEL_953c495e9f64430cbdd9184bb0bd35cb",
      "value": "100%"
     }
    },
    "9e66574c8c0343ffb0477891bfe5e892": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_331b7288a5024ce3a5036af53eb75cec",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1cd0285cfe34f188e9c779617d48448",
      "value": 2
     }
    },
    "ab8e5c4cef00426fa0cf2fc25c51381a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b09413b459c8406882a16db62e8df9c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28fa99d1b1b4e4da668bcc50373e4cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8554928c5f141de8dfb94c04c2dda03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bec237aed5184115b697ea257f7b0c9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_789324d1692d4f478d5b95491b03fc22",
      "placeholder": "​",
      "style": "IPY_MODEL_490bfe688fe1419996b69f7de1cfee23",
      "value": " 2/2 [00:00&lt;00:00,  1.38it/s]"
     }
    },
    "c7cb034c107247cba318475c9952b4ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8a7a19edb074139baefe21f1901d4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cdbf6aefee644006826f76e2f6722b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65d16c05424c4df0b79b5786be8bd5d1",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72a8b4ea52534d4e9feab6c6fdd72a77",
      "value": 2
     }
    },
    "ce26114873ed4c96b5ea391a41b18f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f856d468c8a4c4c9c83b5b263745508",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a3f361a320f480aa8a4115366073d32",
      "value": 2
     }
    },
    "d1cd0285cfe34f188e9c779617d48448": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d240d13622c14726a5639d44ef2421ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44650208feba4c118904c7efc9887532",
      "placeholder": "​",
      "style": "IPY_MODEL_e7be4ec44f2a4183b295f486e250b414",
      "value": "100%"
     }
    },
    "d76610cad4f645f187b26f1b82733569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfb4641da88e47d3bafabbaa56bc6916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8554928c5f141de8dfb94c04c2dda03",
      "placeholder": "​",
      "style": "IPY_MODEL_b28fa99d1b1b4e4da668bcc50373e4cc",
      "value": " 2/2 [00:01&lt;00:00,  1.11it/s]"
     }
    },
    "e032f2bf0bb241c2911087a6efe1ce0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d74dcf5002c4752af12a65c3aca2113",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ad701d95f084c98bd1bf0e9d7d498a9",
      "value": 143
     }
    },
    "e48e5c946462499ab018748ccf80c5b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7be4ec44f2a4183b295f486e250b414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef004a834af944abbd512fa3218642a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f319feca977544738ff2400ab23a9276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9815ec90f12a4696a85db6dc629ec62a",
       "IPY_MODEL_e032f2bf0bb241c2911087a6efe1ce0b",
       "IPY_MODEL_19783f5141cb47f8aaa057fb01dda913"
      ],
      "layout": "IPY_MODEL_26b1a86ee1ff4ce2862c13d47be2b2d6"
     }
    },
    "f39640d290374992aa246753125a91de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5292a911912d43c2b80919e486b99de9",
       "IPY_MODEL_ce26114873ed4c96b5ea391a41b18f68",
       "IPY_MODEL_bec237aed5184115b697ea257f7b0c9b"
      ],
      "layout": "IPY_MODEL_410c3733ee43430eb55278748d07bc45"
     }
    },
    "fc3c6209df394eefa2df9ce8dbb56830": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d240d13622c14726a5639d44ef2421ec",
       "IPY_MODEL_9e66574c8c0343ffb0477891bfe5e892",
       "IPY_MODEL_219090e2dd934c1296f12660ea69b161"
      ],
      "layout": "IPY_MODEL_3fb5b968d9ab4e88964b6b126c6023d9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
