{"cells":[{"cell_type":"markdown","id":"national-fancy","metadata":{"id":"national-fancy"},"source":["## References"]},{"cell_type":"markdown","id":"copyrighted-centre","metadata":{"id":"copyrighted-centre"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"imported-offset","metadata":{"id":"imported-offset"},"source":["## Configurations"]},{"cell_type":"code","execution_count":6,"id":"complimentary-wyoming","metadata":{"id":"complimentary-wyoming","executionInfo":{"status":"ok","timestamp":1647906174939,"user_tz":-540,"elapsed":356,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp059\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":7,"id":"allied-circuit","metadata":{"id":"allied-circuit","executionInfo":{"status":"ok","timestamp":1647906175706,"user_tz":-540,"elapsed":237,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    max_char_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":8,"id":"geographic-hindu","metadata":{"id":"geographic-hindu","executionInfo":{"status":"ok","timestamp":1647906178739,"user_tz":-540,"elapsed":235,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"confident-fifth","metadata":{"id":"confident-fifth"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":9,"id":"miniature-greeting","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miniature-greeting","outputId":"f15fa12c-42d4-4a21-e924-e1f4bf0ccf8e","executionInfo":{"status":"ok","timestamp":1647906210442,"user_tz":-540,"elapsed":30309,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Mounted at /content/drive\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 65.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 52.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 51.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":4,"id":"guilty-filename","metadata":{"id":"guilty-filename","colab":{"base_uri":"https://localhost:8080/","height":387},"executionInfo":{"status":"error","timestamp":1647906160585,"user_tz":-540,"elapsed":6033,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"839e05d5-3d1e-4df3-ec7a-43c85d297d82"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ffd91053cc70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForMaskedLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBartModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDebertaModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDebertaTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"cubic-designation","metadata":{"id":"cubic-designation"},"source":["## Utilities"]},{"cell_type":"code","execution_count":12,"id":"opposite-plasma","metadata":{"id":"opposite-plasma","executionInfo":{"status":"ok","timestamp":1647906238926,"user_tz":-540,"elapsed":268,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":11,"id":"multiple-poland","metadata":{"id":"multiple-poland","executionInfo":{"status":"ok","timestamp":1647906235825,"user_tz":-540,"elapsed":236,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        # result = np.where(char_prob >= th)[0] + 1\n","        result = np.where(char_prob >= th)[0]\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        # result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = [f\"{min(r)} {max(r) + 1}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5, use_token_prob=True):\n","    labels = create_labels_for_scoring(df)\n","\n","    if use_token_prob:\n","        token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","        char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    else:\n","        char_probs = df[[str(i) for i in range(CFG.max_char_len)]].values\n","        char_probs = [char_probs[i] for i in range(len(char_probs))]\n","\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"seventh-fighter","metadata":{"id":"seventh-fighter","executionInfo":{"status":"ok","timestamp":1647850372156,"user_tz":-540,"elapsed":14,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"fifty-boundary","metadata":{"id":"fifty-boundary","executionInfo":{"status":"ok","timestamp":1647850372156,"user_tz":-540,"elapsed":13,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"unlimited-hotel","metadata":{"id":"unlimited-hotel"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"classical-machine","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"classical-machine","outputId":"582132fe-c9a1-4332-a567-6d0e9430a607","executionInfo":{"status":"ok","timestamp":1647850374732,"user_tz":-540,"elapsed":2589,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"vanilla-iceland","metadata":{"id":"vanilla-iceland","executionInfo":{"status":"ok","timestamp":1647850375084,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"convenient-plant","metadata":{"id":"convenient-plant"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"convertible-thunder","metadata":{"id":"convertible-thunder","executionInfo":{"status":"ok","timestamp":1647850375084,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"charitable-memphis","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"charitable-memphis","outputId":"c57e2a70-f681-4929-f222-80618afcbaa1","executionInfo":{"status":"ok","timestamp":1647850375085,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"governing-election","metadata":{"id":"governing-election","executionInfo":{"status":"ok","timestamp":1647850375085,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"negative-provincial","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"negative-provincial","outputId":"c15f32c0-408a-47dd-c9f6-f2b05923e7d6","executionInfo":{"status":"ok","timestamp":1647850375087,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"arbitrary-beatles","metadata":{"id":"arbitrary-beatles"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"important-murray","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"important-murray","outputId":"fea219de-56c9-4d41-fc3e-5c698c037ac0","executionInfo":{"status":"ok","timestamp":1647850375490,"user_tz":-540,"elapsed":411,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"configured-chemistry","metadata":{"id":"configured-chemistry"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"hindu-contest","metadata":{"id":"hindu-contest","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["804a30f0d5bb454d948d2c7fcb6f47cb","0012e56d3e964048941549da70cae0cf","3ce637381f8248e48f09a5ec038215d0","7d977e08f08746cf9143891b043fe138","5428218cb94a476a8703fc08cf2a7dfd","a3f7241a9f9845d1bebc5c355c207aea","fb7ac917f46a490ab74b6f443f28df9d","b1655f8d2d85435596e9ddfd4e74fde8","aa87d84b81ed4227abbff18501261687","2fb96632eb84452987ebcb54c7aef241","3fb4b8618c3c4d0dbd244932f1332d50","fa211b09ce934b388aef5745e2be7f2c","e0db56c592c34e6b94fc4da2b7b50b15","ffd6495f6df74c29b115e9ae24676245","7b36a2c0fef8478e93a4e2eedb06292a","1b53b698719544edb36bb460f8b02267","2d84c51121b54e0d8e8174acbddf2e60","c1fdb9ec354a48be8e12a80035e4e89d","55c14ab0417c4e4e8258bd57a0f16b2d","a392e281c7e54acba9c1d12d3d8a61a2","2a156e39829d40c4991ae595138139bd","68cb2504845d4f828d69c117a7baef84","62448458033b47ad97a2ab5c102f5b20","e19c4e2d74d74150b4ad2fef87522d3b","5427e63f31534355abf401dbd00f8b39","99a67610d9774bdaa925a2b634be5c1e","b52c0997abfe4cedb0631f3694ed4bde","508b20f7c28847318cd36d1c075741ba","81c23f589edc429f825eda5c9e86c62c","9bdade367fad44479cdcb5b016685fb5","dce9b50718224bc89877e1d371f46a94","c7d537c5842e4d2f8f40082760c08f93","74cfe922ec024630af8f866df12eaebc","50147a1d3ffe470caa49737f72ce4f92","a65a035cd77f4e31915c373a6ae8ca20","eb6181520b5b48c691ffc2f1109ad8b5","bf8c6aa4616e4b3886a40c3dd90f3969","0c173e244e784511ac985d3a2377dc0f","6f1d03271ec74ba8adf327c4013c4a9e","a355cc803bb442b9af511621db484f0b","a4a60a23ed2344bf99091d318da0eca5","6010dbad339a48b18644fe0e05ae84df","04ea09532c504a0f90e0b7d9e22a36ed","bc1fc3212a574949b9703fa8b974903e"]},"executionInfo":{"status":"ok","timestamp":1647850382908,"user_tz":-540,"elapsed":7424,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"132d761c-29c3-4c66-c1dc-3392e22a99a3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"804a30f0d5bb454d948d2c7fcb6f47cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa211b09ce934b388aef5745e2be7f2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62448458033b47ad97a2ab5c102f5b20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50147a1d3ffe470caa49737f72ce4f92"}},"metadata":{}}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","id":"alleged-protein","metadata":{"id":"alleged-protein"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":18,"id":"composed-stroke","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["e526cd925bb044909394f9a2d6237694","7c11452952eb40988a2eb8f6948fd553","b0ea0c3edca144eca0e3d937f0ee5d1e","020f55dd776d4ca6a369f920fe0822fd","7297ca4414d64d01bf9b7f053411782e","a18bcc2112e549bb8d3b927645f1c55c","70097c2bb2f740198beded85989d0d26","e3da4baf21a04a77a09cf79aa6600ee2","fc82593d171f4e59aaff2f7c5e50017b","08790f4221f7438ab9ad43a2b606c702","1411066860064e85a84155b9c2c8b8a5"]},"id":"composed-stroke","outputId":"790295b0-3c9e-4e01-b7c0-844afe0d10e2","executionInfo":{"status":"ok","timestamp":1647850413917,"user_tz":-540,"elapsed":31025,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e526cd925bb044909394f9a2d6237694"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":19,"id":"emotional-region","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["1bef222d05914a94b1b914041dad3201","7d0f1385ffad41c8b9d55e71f99ff559","a6241185131948e489813f18641f429f","e3a1461d512740eba06f2af134540634","b04e9eac49f1492cad7d84bb8f200763","d3b0b0fa56c5491ab5da3a97ed8226e6","db4c1399530745c6aaf8df5f91872f69","5622a5bd84854a178985c79ed1e97a2e","3fdb26732186421c9d070899c9b70c46","0a5bd15420d04aa880c8c887492ba25d","caa39ad69f294796b486bbe5bf488916"]},"id":"emotional-region","outputId":"0c761652-f10b-4909-ee2f-34cc05daa705","executionInfo":{"status":"ok","timestamp":1647850414456,"user_tz":-540,"elapsed":554,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bef222d05914a94b1b914041dad3201"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":20,"id":"wrong-leisure","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrong-leisure","outputId":"fb567f24-db9b-46bc-980c-2a149c3c68c0","executionInfo":{"status":"ok","timestamp":1647850414457,"user_tz":-540,"elapsed":12,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":21,"id":"convenient-gospel","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["505d3ee65b114c3b8bf2d79d2cc0c3f3","dffc146547934b8cb176a1474b9d774f","2b886ed180604097a14094db7011a63e","997c9eb7b51942edb819214651865917","de7ca5a058c94a0ab7bc9b1bb25db914","fd3c5f81e3734adba40927c40c9b3447","f073dd8fda054959ab49a7878a72a907","83c5db101b1e47188907faaa4ab6f504","013d9bb941684591994028700e0fac4e","f208da8c4ff04799be4feb9e6f7a2a93","59784b7614f64ea4b747547ddeaffc67"]},"id":"convenient-gospel","executionInfo":{"status":"ok","timestamp":1647850414457,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"2d7d20a1-2779-4f4d-f424-33fa14122629"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505d3ee65b114c3b8bf2d79d2cc0c3f3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 950\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(text)\n","    pn_history_lengths.append(length)\n","\n","CFG.max_char_len = max(pn_history_lengths)\n","\n","print(\"max length:\", CFG.max_char_len)"]},{"cell_type":"code","execution_count":22,"id":"representative-contributor","metadata":{"id":"representative-contributor","executionInfo":{"status":"ok","timestamp":1647850414458,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.max_char_len = self.cfg.max_char_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        label = np.zeros(self.max_char_len)\n","        label[len(pn_history):] = -1\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    label[start:end] = 1\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, label, mapping_from_token_to_char"]},{"cell_type":"code","execution_count":23,"id":"decent-johnson","metadata":{"id":"decent-johnson","executionInfo":{"status":"ok","timestamp":1647850414458,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_mapping_from_token_to_char(self, pn_history):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        mapping_from_token_to_char = np.zeros(self.max_char_len)\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        for i, offset in enumerate(offset_mapping):\n","            start_idx, end_idx = offset\n","            mapping_from_token_to_char[start_idx:end_idx] = i\n","        return torch.tensor(mapping_from_token_to_char, dtype=torch.long)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n","        return input_, mapping_from_token_to_char"]},{"cell_type":"markdown","id":"arctic-joint","metadata":{"id":"arctic-joint"},"source":["## Model"]},{"cell_type":"code","source":["class Exp054Model(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"],"metadata":{"id":"UtM7nYFm333y","executionInfo":{"status":"ok","timestamp":1647850414458,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"UtM7nYFm333y","execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"id":"alternative-malawi","metadata":{"id":"alternative-malawi","executionInfo":{"status":"ok","timestamp":1647850414459,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False, i_fold=None):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","\n","            model = Exp054Model(cfg, model_config_path=None, pretrained=False)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp054\" /  f\"fold{i_fold}_best.pth\")\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            self.backbone = model.backbone\n","            print(f\"Load weight from {path}\")\n","\n","        self.lstm = nn.GRU(\n","            input_size=self.model_config.hidden_size,\n","            bidirectional=True,\n","            hidden_size=self.model_config.hidden_size // 2,\n","            num_layers=2,\n","            dropout=self.cfg.dropout,\n","            batch_first=True,\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs, mappings_from_token_to_char):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]  # [batch, seq_len, d_model]\n","        mappings_from_token_to_char = mappings_from_token_to_char.unsqueeze(2).expand(-1, -1, self.model_config.hidden_size)\n","        h = torch.gather(h, 1, mappings_from_token_to_char)    # [batch, seq_len, d_model]\n","        h, _ = self.lstm(h)\n","        output = self.fc(h)\n","\n","        return output"]},{"cell_type":"markdown","id":"therapeutic-assembly","metadata":{"id":"therapeutic-assembly"},"source":["## Training"]},{"cell_type":"code","execution_count":26,"id":"going-conversion","metadata":{"id":"going-conversion","executionInfo":{"status":"ok","timestamp":1647850414459,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":27,"id":"alleged-commonwealth","metadata":{"id":"alleged-commonwealth","executionInfo":{"status":"ok","timestamp":1647850414459,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels, mappings_from_token_to_char) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device) \n","        batch_size = labels.size(0)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs, mappings_from_token_to_char)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","    \n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":28,"id":"middle-determination","metadata":{"id":"middle-determination","executionInfo":{"status":"ok","timestamp":1647850414460,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for (inputs, mappings_from_token_to_char) in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        mappings_from_token_to_char = mappings_from_token_to_char.to(device)\n","\n","        with torch.no_grad():\n","            output = model(inputs, mappings_from_token_to_char)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":29,"id":"familiar-participation","metadata":{"id":"familiar-participation","executionInfo":{"status":"ok","timestamp":1647850414762,"user_tz":-540,"elapsed":310,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False, i_fold=i_fold)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    # freeze\n","    for param in model.backbone.parameters():\n","        param.requires_grad = False\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_char_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5, use_token_prob=False)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_char_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"coated-cameroon","metadata":{"id":"coated-cameroon"},"source":["## Main"]},{"cell_type":"code","execution_count":30,"id":"quality-expansion","metadata":{"id":"quality-expansion","executionInfo":{"status":"ok","timestamp":1647850414762,"user_tz":-540,"elapsed":3,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5, use_token_prob=False)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres, use_token_prob=False)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":31,"id":"proprietary-civilian","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8b94b965c11b40668833d2d4e7a47e93","25ee30a9f6d645c8b9bdbfe1c93e7d21","824cb019808f427bad53fe473dee8db9","16cda8e3999d408da0bfbb7b23ba644b","526e8e82fc5d42c498739abe20a53b4e","301379784fc64a47974dffa6339baabc","ea717cd9279b42c2b921dfd247af6c21","728fed76d0a24cf890080a5df949f47b","b8cb38d508014fc090976d8e44683dcc","9ef7f0c16b8646a0bdb46fa097548965","79d8efaf1534495cb7329d9109262b0d","b65f6a0e9e3b4ecc8fcd77d45648701e","488b389bd3b043c5bba2a5246dd4caca","8602b99dcce3497887034d8b42211730","07aeb3c98e454465a8ec1374e9db7097","8780ac842d6942cc85fda655aa49a705","481024fc3357443c9737cb8cddf4888c","9766001cebf447059e7fdf5eef0828c4","b426cbf27b244f8881073a3afc64bd35","98282bcaa60d40feab78b0c31f93727c","60a29e7071d3421e95d438ea2129b3ad","71d369e8e5174dc6a6e0a21f8908c495"]},"id":"proprietary-civilian","outputId":"27a10483-9446-4951-c86e-9184b3ab9faf","executionInfo":{"status":"error","timestamp":1647875131589,"user_tz":-540,"elapsed":24716829,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold0_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 1s (remain 65m 49s) Loss: 0.3056(0.3056) Grad: 243728.2500  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 31s (remain 17m 57s) Loss: 0.2459(0.2877) Grad: 205452.0781  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 59s (remain 16m 44s) Loss: 0.1198(0.2349) Grad: 104850.7500  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 28s (remain 16m 1s) Loss: 0.0303(0.1795) Grad: 29521.0293  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 56s (remain 15m 25s) Loss: 0.0111(0.1388) Grad: 5689.0859  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 25s (remain 14m 51s) Loss: 0.0026(0.1121) Grad: 1168.4467  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 53s (remain 14m 20s) Loss: 0.0028(0.0942) Grad: 800.0337  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 22s (remain 13m 49s) Loss: 0.0093(0.0814) Grad: 2371.9373  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 50s (remain 13m 19s) Loss: 0.0015(0.0717) Grad: 757.6014  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 19s (remain 12m 49s) Loss: 0.0004(0.0642) Grad: 160.4539  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 47s (remain 12m 20s) Loss: 0.0030(0.0580) Grad: 635.3279  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 16s (remain 11m 50s) Loss: 0.0005(0.0532) Grad: 309.0391  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 44s (remain 11m 21s) Loss: 0.0077(0.0490) Grad: 2054.7822  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 13s (remain 10m 52s) Loss: 0.0003(0.0454) Grad: 151.8581  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 42s (remain 10m 23s) Loss: 0.0000(0.0424) Grad: 45.1975  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 10s (remain 9m 54s) Loss: 0.0003(0.0398) Grad: 130.0137  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 39s (remain 9m 25s) Loss: 0.0007(0.0376) Grad: 276.9151  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 7s (remain 8m 57s) Loss: 0.0001(0.0355) Grad: 66.2113  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 36s (remain 8m 28s) Loss: 0.0011(0.0336) Grad: 285.7788  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 4s (remain 7m 59s) Loss: 0.0202(0.0320) Grad: 3806.5498  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 33s (remain 7m 30s) Loss: 0.0009(0.0305) Grad: 648.8987  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 1s (remain 7m 2s) Loss: 0.0003(0.0291) Grad: 151.8061  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 30s (remain 6m 33s) Loss: 0.0001(0.0279) Grad: 43.2950  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 58s (remain 6m 4s) Loss: 0.0001(0.0268) Grad: 53.7266  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 27s (remain 5m 35s) Loss: 0.0001(0.0258) Grad: 52.4686  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 55s (remain 5m 7s) Loss: 0.0049(0.0249) Grad: 2216.4678  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 24s (remain 4m 38s) Loss: 0.0000(0.0240) Grad: 50.4163  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 52s (remain 4m 10s) Loss: 0.0001(0.0232) Grad: 133.5399  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 21s (remain 3m 41s) Loss: 0.0007(0.0224) Grad: 528.8942  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 49s (remain 3m 12s) Loss: 0.0006(0.0217) Grad: 309.4484  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 18s (remain 2m 44s) Loss: 0.0016(0.0211) Grad: 666.6437  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 46s (remain 2m 15s) Loss: 0.0018(0.0205) Grad: 1019.5464  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 15s (remain 1m 46s) Loss: 0.0144(0.0199) Grad: 4062.9856  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 43s (remain 1m 18s) Loss: 0.0028(0.0194) Grad: 1884.4091  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 12s (remain 0m 49s) Loss: 0.0005(0.0189) Grad: 264.6387  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 41s (remain 0m 21s) Loss: 0.0064(0.0185) Grad: 2846.8704  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 17m 2s (remain 0m 0s) Loss: 0.0001(0.0181) Grad: 117.8373  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 46s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 29s) Loss: 0.0179(0.0063) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0038(0.0075) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0043(0.0080) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 46s) Loss: 0.0035(0.0081) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 32s) Loss: 0.0139(0.0075) \n","EVAL: [600/1192] Elapsed 1m 20s (remain 1m 19s) Loss: 0.0123(0.0078) \n","EVAL: [700/1192] Elapsed 1m 33s (remain 1m 5s) Loss: 0.0871(0.0094) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0037(0.0096) \n","EVAL: [900/1192] Elapsed 2m 0s (remain 0m 38s) Loss: 0.0025(0.0095) \n","EVAL: [1000/1192] Elapsed 2m 13s (remain 0m 25s) Loss: 0.0000(0.0093) \n","EVAL: [1100/1192] Elapsed 2m 27s (remain 0m 12s) Loss: 0.0007(0.0089) \n","EVAL: [1191/1192] Elapsed 2m 39s (remain 0m 0s) Loss: 0.0001(0.0086) \n","Epoch 1 - avg_train_loss: 0.0181  avg_val_loss: 0.0086  time: 1184s\n","Epoch 1 - Score: 0.8789\n","Epoch 1 - Save Best Score: 0.8789 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 37m 43s) Loss: 0.0001(0.0001) Grad: 163.5317  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 33s (remain 19m 11s) Loss: 0.0001(0.0023) Grad: 76.3181  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 2s (remain 17m 30s) Loss: 0.0001(0.0021) Grad: 97.3669  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 31s (remain 16m 31s) Loss: 0.0005(0.0021) Grad: 296.7101  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 59s (remain 15m 47s) Loss: 0.0030(0.0021) Grad: 1441.7509  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 28s (remain 15m 9s) Loss: 0.0001(0.0021) Grad: 73.7752  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 56s (remain 14m 34s) Loss: 0.0001(0.0023) Grad: 61.1759  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 25s (remain 14m 1s) Loss: 0.0001(0.0023) Grad: 71.4728  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 53s (remain 13m 29s) Loss: 0.0001(0.0024) Grad: 100.4388  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 22s (remain 12m 57s) Loss: 0.0001(0.0024) Grad: 96.2960  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 50s (remain 12m 27s) Loss: 0.0131(0.0025) Grad: 4238.3237  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 19s (remain 11m 56s) Loss: 0.0003(0.0024) Grad: 248.8891  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 47s (remain 11m 26s) Loss: 0.0000(0.0024) Grad: 36.7091  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 15s (remain 10m 57s) Loss: 0.0023(0.0025) Grad: 1971.2762  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 44s (remain 10m 27s) Loss: 0.0001(0.0025) Grad: 71.8728  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 13s (remain 9m 58s) Loss: 0.0001(0.0025) Grad: 56.6784  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 41s (remain 9m 29s) Loss: 0.0005(0.0024) Grad: 385.8517  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 10s (remain 9m 0s) Loss: 0.0002(0.0024) Grad: 130.2987  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 38s (remain 8m 31s) Loss: 0.0002(0.0023) Grad: 97.6431  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 7s (remain 8m 1s) Loss: 0.0044(0.0024) Grad: 1697.4506  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 35s (remain 7m 32s) Loss: 0.0007(0.0023) Grad: 369.2353  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 3s (remain 7m 3s) Loss: 0.0061(0.0023) Grad: 2222.5320  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 32s (remain 6m 34s) Loss: 0.0001(0.0023) Grad: 56.6389  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 0s (remain 6m 5s) Loss: 0.0004(0.0023) Grad: 418.4245  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 28s (remain 5m 36s) Loss: 0.0000(0.0023) Grad: 25.6381  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 57s (remain 5m 7s) Loss: 0.0004(0.0023) Grad: 314.2633  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 25s (remain 4m 39s) Loss: 0.0001(0.0023) Grad: 90.7685  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 53s (remain 4m 10s) Loss: 0.0001(0.0023) Grad: 109.6943  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 22s (remain 3m 41s) Loss: 0.0005(0.0023) Grad: 599.8793  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 50s (remain 3m 12s) Loss: 0.0024(0.0023) Grad: 1188.9166  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 18s (remain 2m 44s) Loss: 0.0000(0.0023) Grad: 48.8567  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 47s (remain 2m 15s) Loss: 0.0140(0.0023) Grad: 2909.1641  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 15s (remain 1m 46s) Loss: 0.0031(0.0023) Grad: 1552.0687  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 43s (remain 1m 18s) Loss: 0.0020(0.0024) Grad: 1490.6609  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 12s (remain 0m 49s) Loss: 0.0038(0.0024) Grad: 1311.7753  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 40s (remain 0m 21s) Loss: 0.0016(0.0024) Grad: 1458.2306  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 17m 1s (remain 0m 0s) Loss: 0.0000(0.0024) Grad: 47.0790  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 14s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 28s) Loss: 0.0167(0.0061) \n","EVAL: [200/1192] Elapsed 0m 26s (remain 2m 12s) Loss: 0.0040(0.0074) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 1m 58s) Loss: 0.0041(0.0079) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 45s) Loss: 0.0036(0.0080) \n","EVAL: [500/1192] Elapsed 1m 6s (remain 1m 31s) Loss: 0.0139(0.0075) \n","EVAL: [600/1192] Elapsed 1m 19s (remain 1m 18s) Loss: 0.0109(0.0077) \n","EVAL: [700/1192] Elapsed 1m 33s (remain 1m 5s) Loss: 0.0876(0.0093) \n","EVAL: [800/1192] Elapsed 1m 46s (remain 0m 51s) Loss: 0.0038(0.0095) \n","EVAL: [900/1192] Elapsed 1m 59s (remain 0m 38s) Loss: 0.0021(0.0094) \n","EVAL: [1000/1192] Elapsed 2m 12s (remain 0m 25s) Loss: 0.0000(0.0092) \n","EVAL: [1100/1192] Elapsed 2m 25s (remain 0m 12s) Loss: 0.0005(0.0089) \n","EVAL: [1191/1192] Elapsed 2m 37s (remain 0m 0s) Loss: 0.0000(0.0086) \n","Epoch 2 - avg_train_loss: 0.0024  avg_val_loss: 0.0086  time: 1182s\n","Epoch 2 - Score: 0.8795\n","Epoch 2 - Save Best Score: 0.8795 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 39m 15s) Loss: 0.0000(0.0000) Grad: 54.7951  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 32s (remain 18m 25s) Loss: 0.0000(0.0014) Grad: 26.2440  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 0s (remain 17m 3s) Loss: 0.0076(0.0014) Grad: 3446.7224  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 29s (remain 16m 11s) Loss: 0.0013(0.0019) Grad: 1297.3898  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 57s (remain 15m 29s) Loss: 0.0016(0.0021) Grad: 1613.5125  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 25s (remain 14m 54s) Loss: 0.0001(0.0023) Grad: 138.0777  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 54s (remain 14m 21s) Loss: 0.0008(0.0023) Grad: 598.0011  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 22s (remain 13m 48s) Loss: 0.0076(0.0023) Grad: 2241.3904  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 50s (remain 13m 17s) Loss: 0.0007(0.0022) Grad: 588.0886  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 18s (remain 12m 47s) Loss: 0.0000(0.0021) Grad: 49.0312  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 46s (remain 12m 17s) Loss: 0.0041(0.0022) Grad: 1386.8507  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 14s (remain 11m 47s) Loss: 0.0019(0.0021) Grad: 1062.1437  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 43s (remain 11m 18s) Loss: 0.0008(0.0021) Grad: 347.8958  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 11s (remain 10m 49s) Loss: 0.0002(0.0021) Grad: 172.3459  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 39s (remain 10m 20s) Loss: 0.0002(0.0023) Grad: 129.2894  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 7s (remain 9m 51s) Loss: 0.0000(0.0023) Grad: 18.4772  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 36s (remain 9m 22s) Loss: 0.0001(0.0022) Grad: 75.9220  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 4s (remain 8m 53s) Loss: 0.0522(0.0023) Grad: 17319.6074  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 33s (remain 8m 25s) Loss: 0.0000(0.0022) Grad: 30.3868  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 1s (remain 7m 56s) Loss: 0.0001(0.0022) Grad: 104.2361  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 30s (remain 7m 28s) Loss: 0.0016(0.0022) Grad: 1129.4302  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 58s (remain 6m 59s) Loss: 0.0038(0.0022) Grad: 1454.3230  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 26s (remain 6m 31s) Loss: 0.0079(0.0023) Grad: 3620.0994  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 54s (remain 6m 2s) Loss: 0.0000(0.0022) Grad: 53.7172  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 23s (remain 5m 33s) Loss: 0.0003(0.0022) Grad: 233.3121  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 51s (remain 5m 5s) Loss: 0.0000(0.0022) Grad: 8.9023  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 19s (remain 4m 36s) Loss: 0.0000(0.0022) Grad: 38.8318  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 47s (remain 4m 8s) Loss: 0.0043(0.0022) Grad: 1842.9846  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 16s (remain 3m 39s) Loss: 0.0044(0.0022) Grad: 3155.0889  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 44s (remain 3m 11s) Loss: 0.0000(0.0022) Grad: 45.8929  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 12s (remain 2m 43s) Loss: 0.0001(0.0022) Grad: 92.1257  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 41s (remain 2m 14s) Loss: 0.0000(0.0022) Grad: 62.5853  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 9s (remain 1m 46s) Loss: 0.0003(0.0023) Grad: 290.0440  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 37s (remain 1m 17s) Loss: 0.0000(0.0023) Grad: 27.6279  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 5s (remain 0m 49s) Loss: 0.0000(0.0023) Grad: 37.4486  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 34s (remain 0m 21s) Loss: 0.0000(0.0023) Grad: 26.8102  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 54s (remain 0m 0s) Loss: 0.0045(0.0024) Grad: 2630.4402  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 47s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 27s) Loss: 0.0180(0.0061) \n","EVAL: [200/1192] Elapsed 0m 26s (remain 2m 12s) Loss: 0.0037(0.0074) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 1m 58s) Loss: 0.0041(0.0079) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 45s) Loss: 0.0038(0.0080) \n","EVAL: [500/1192] Elapsed 1m 6s (remain 1m 31s) Loss: 0.0131(0.0074) \n","EVAL: [600/1192] Elapsed 1m 19s (remain 1m 18s) Loss: 0.0110(0.0076) \n","EVAL: [700/1192] Elapsed 1m 33s (remain 1m 5s) Loss: 0.0877(0.0093) \n","EVAL: [800/1192] Elapsed 1m 46s (remain 0m 51s) Loss: 0.0036(0.0094) \n","EVAL: [900/1192] Elapsed 1m 59s (remain 0m 38s) Loss: 0.0024(0.0094) \n","EVAL: [1000/1192] Elapsed 2m 12s (remain 0m 25s) Loss: 0.0000(0.0092) \n","EVAL: [1100/1192] Elapsed 2m 26s (remain 0m 12s) Loss: 0.0006(0.0088) \n","EVAL: [1191/1192] Elapsed 2m 38s (remain 0m 0s) Loss: 0.0000(0.0085) \n","Epoch 3 - avg_train_loss: 0.0024  avg_val_loss: 0.0085  time: 1175s\n","Epoch 3 - Score: 0.8799\n","Epoch 3 - Save Best Score: 0.8799 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 36m 14s) Loss: 0.0001(0.0001) Grad: 1044.3627  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 31s (remain 18m 4s) Loss: 0.0033(0.0019) Grad: 1344.8605  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 0s (remain 16m 57s) Loss: 0.0002(0.0023) Grad: 194.3838  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 28s (remain 16m 5s) Loss: 0.0176(0.0021) Grad: 4913.4067  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 56s (remain 15m 25s) Loss: 0.0000(0.0023) Grad: 45.0043  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 25s (remain 14m 50s) Loss: 0.0001(0.0023) Grad: 123.6076  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 53s (remain 14m 17s) Loss: 0.0007(0.0023) Grad: 425.7897  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 21s (remain 13m 46s) Loss: 0.1313(0.0025) Grad: 18899.3105  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 49s (remain 13m 16s) Loss: 0.0000(0.0025) Grad: 7.4554  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 18s (remain 12m 45s) Loss: 0.0000(0.0025) Grad: 25.7250  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 46s (remain 12m 15s) Loss: 0.0001(0.0026) Grad: 158.0033  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 14s (remain 11m 46s) Loss: 0.0003(0.0025) Grad: 248.6153  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 42s (remain 11m 17s) Loss: 0.0001(0.0024) Grad: 91.8535  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 10s (remain 10m 47s) Loss: 0.0000(0.0024) Grad: 16.5633  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 38s (remain 10m 18s) Loss: 0.0000(0.0024) Grad: 33.2141  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 6s (remain 9m 49s) Loss: 0.0001(0.0024) Grad: 80.5397  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 35s (remain 9m 21s) Loss: 0.0004(0.0023) Grad: 437.0003  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 3s (remain 8m 52s) Loss: 0.0101(0.0023) Grad: 4007.2424  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 31s (remain 8m 23s) Loss: 0.0000(0.0022) Grad: 22.7349  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 59s (remain 7m 55s) Loss: 0.0064(0.0022) Grad: 3424.7415  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 28s (remain 7m 26s) Loss: 0.0007(0.0023) Grad: 369.0996  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 56s (remain 6m 58s) Loss: 0.0000(0.0024) Grad: 14.7264  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 24s (remain 6m 29s) Loss: 0.0000(0.0024) Grad: 34.8352  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 52s (remain 6m 1s) Loss: 0.0012(0.0023) Grad: 691.2604  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 21s (remain 5m 33s) Loss: 0.0001(0.0024) Grad: 84.7129  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 49s (remain 5m 4s) Loss: 0.0000(0.0023) Grad: 58.2812  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 17s (remain 4m 36s) Loss: 0.0003(0.0023) Grad: 217.7458  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 45s (remain 4m 7s) Loss: 0.0001(0.0023) Grad: 146.8059  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 14s (remain 3m 39s) Loss: 0.0001(0.0022) Grad: 121.2848  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 42s (remain 3m 11s) Loss: 0.0020(0.0023) Grad: 716.7426  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 10s (remain 2m 42s) Loss: 0.0000(0.0023) Grad: 17.3863  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 38s (remain 2m 14s) Loss: 0.0000(0.0023) Grad: 20.1966  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 7s (remain 1m 46s) Loss: 0.0111(0.0023) Grad: 3211.5610  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 35s (remain 1m 17s) Loss: 0.0497(0.0023) Grad: 12980.3008  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 4s (remain 0m 49s) Loss: 0.0008(0.0023) Grad: 419.3360  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 32s (remain 0m 20s) Loss: 0.0154(0.0023) Grad: 4023.4109  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 53s (remain 0m 0s) Loss: 0.0000(0.0023) Grad: 38.0998  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 54s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 26s) Loss: 0.0186(0.0063) \n","EVAL: [200/1192] Elapsed 0m 26s (remain 2m 12s) Loss: 0.0036(0.0075) \n","EVAL: [300/1192] Elapsed 0m 39s (remain 1m 58s) Loss: 0.0040(0.0080) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 44s) Loss: 0.0041(0.0081) \n","EVAL: [500/1192] Elapsed 1m 6s (remain 1m 31s) Loss: 0.0135(0.0075) \n","EVAL: [600/1192] Elapsed 1m 19s (remain 1m 18s) Loss: 0.0107(0.0078) \n","EVAL: [700/1192] Elapsed 1m 32s (remain 1m 4s) Loss: 0.0891(0.0094) \n","EVAL: [800/1192] Elapsed 1m 46s (remain 0m 51s) Loss: 0.0038(0.0096) \n","EVAL: [900/1192] Elapsed 1m 59s (remain 0m 38s) Loss: 0.0023(0.0095) \n","EVAL: [1000/1192] Elapsed 2m 12s (remain 0m 25s) Loss: 0.0000(0.0093) \n","EVAL: [1100/1192] Elapsed 2m 25s (remain 0m 12s) Loss: 0.0006(0.0089) \n","EVAL: [1191/1192] Elapsed 2m 37s (remain 0m 0s) Loss: 0.0000(0.0087) \n","Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0087  time: 1172s\n","Epoch 4 - Score: 0.8800\n","Epoch 4 - Save Best Score: 0.8800 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 34m 35s) Loss: 0.0001(0.0001) Grad: 94.6353  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 31s (remain 17m 52s) Loss: 0.0001(0.0018) Grad: 137.1578  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 0s (remain 16m 56s) Loss: 0.0000(0.0021) Grad: 37.8283  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 28s (remain 16m 5s) Loss: 0.0002(0.0021) Grad: 216.2254  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 56s (remain 15m 25s) Loss: 0.0001(0.0020) Grad: 140.2779  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 25s (remain 14m 49s) Loss: 0.0277(0.0022) Grad: 9610.0176  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 53s (remain 14m 17s) Loss: 0.0073(0.0021) Grad: 3407.2639  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 21s (remain 13m 45s) Loss: 0.0002(0.0020) Grad: 236.0896  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 49s (remain 13m 15s) Loss: 0.0094(0.0020) Grad: 3552.4434  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 17s (remain 12m 44s) Loss: 0.0000(0.0020) Grad: 19.6770  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 46s (remain 12m 16s) Loss: 0.0073(0.0020) Grad: 2129.6558  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 14s (remain 11m 47s) Loss: 0.0000(0.0020) Grad: 6.8599  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 43s (remain 11m 18s) Loss: 0.0001(0.0021) Grad: 151.0104  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 11s (remain 10m 49s) Loss: 0.0017(0.0020) Grad: 759.7956  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 39s (remain 10m 20s) Loss: 0.0003(0.0020) Grad: 243.8730  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 8s (remain 9m 51s) Loss: 0.0000(0.0020) Grad: 24.6016  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 36s (remain 9m 22s) Loss: 0.0000(0.0020) Grad: 33.0159  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 4s (remain 8m 53s) Loss: 0.0001(0.0020) Grad: 101.6733  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 32s (remain 8m 25s) Loss: 0.0003(0.0021) Grad: 222.0172  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 1s (remain 7m 56s) Loss: 0.0001(0.0021) Grad: 57.3180  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 29s (remain 7m 27s) Loss: 0.0326(0.0022) Grad: 8235.3926  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 57s (remain 6m 59s) Loss: 0.0160(0.0022) Grad: 6358.0454  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 26s (remain 6m 30s) Loss: 0.0000(0.0023) Grad: 33.7103  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 54s (remain 6m 2s) Loss: 0.0002(0.0023) Grad: 244.0026  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 22s (remain 5m 33s) Loss: 0.0008(0.0023) Grad: 454.7182  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 51s (remain 5m 5s) Loss: 0.0002(0.0023) Grad: 183.7945  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 19s (remain 4m 36s) Loss: 0.0000(0.0023) Grad: 7.3371  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 47s (remain 4m 8s) Loss: 0.0006(0.0023) Grad: 510.7999  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 15s (remain 3m 39s) Loss: 0.0000(0.0023) Grad: 28.7192  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 44s (remain 3m 11s) Loss: 0.0007(0.0023) Grad: 906.6007  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 12s (remain 2m 43s) Loss: 0.0053(0.0023) Grad: 2681.1196  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 40s (remain 2m 14s) Loss: 0.0000(0.0023) Grad: 18.3941  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 9s (remain 1m 46s) Loss: 0.0034(0.0023) Grad: 2790.0276  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 37s (remain 1m 17s) Loss: 0.0000(0.0023) Grad: 57.7360  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 5s (remain 0m 49s) Loss: 0.0010(0.0023) Grad: 974.7740  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 33s (remain 0m 21s) Loss: 0.0010(0.0023) Grad: 957.1445  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 54s (remain 0m 0s) Loss: 0.0004(0.0023) Grad: 508.5326  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 54s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 27s) Loss: 0.0193(0.0064) \n","EVAL: [200/1192] Elapsed 0m 26s (remain 2m 11s) Loss: 0.0039(0.0075) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 1m 58s) Loss: 0.0042(0.0080) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 45s) Loss: 0.0044(0.0080) \n","EVAL: [500/1192] Elapsed 1m 6s (remain 1m 31s) Loss: 0.0138(0.0075) \n","EVAL: [600/1192] Elapsed 1m 19s (remain 1m 18s) Loss: 0.0105(0.0077) \n","EVAL: [700/1192] Elapsed 1m 32s (remain 1m 5s) Loss: 0.0882(0.0094) \n","EVAL: [800/1192] Elapsed 1m 46s (remain 0m 51s) Loss: 0.0040(0.0095) \n","EVAL: [900/1192] Elapsed 1m 59s (remain 0m 38s) Loss: 0.0032(0.0095) \n","EVAL: [1000/1192] Elapsed 2m 12s (remain 0m 25s) Loss: 0.0000(0.0093) \n","EVAL: [1100/1192] Elapsed 2m 25s (remain 0m 12s) Loss: 0.0005(0.0089) \n","EVAL: [1191/1192] Elapsed 2m 37s (remain 0m 0s) Loss: 0.0000(0.0086) \n","Epoch 5 - avg_train_loss: 0.0023  avg_val_loss: 0.0086  time: 1174s\n","Epoch 5 - Score: 0.8804\n","Epoch 5 - Save Best Score: 0.8804 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold1_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 55m 47s) Loss: 0.3537(0.3537) Grad: 265255.7812  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 29s (remain 16m 54s) Loss: 0.2812(0.3265) Grad: 227171.9219  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 57s (remain 16m 11s) Loss: 0.1347(0.2691) Grad: 124851.4453  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 26s (remain 15m 37s) Loss: 0.0419(0.2062) Grad: 36047.5000  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 54s (remain 15m 6s) Loss: 0.0084(0.1596) Grad: 6200.8472  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 22s (remain 14m 36s) Loss: 0.0010(0.1289) Grad: 739.3600  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 51s (remain 14m 6s) Loss: 0.0019(0.1081) Grad: 567.0131  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 19s (remain 13m 37s) Loss: 0.0002(0.0930) Grad: 168.4831  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 47s (remain 13m 8s) Loss: 0.0005(0.0816) Grad: 207.6514  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 16s (remain 12m 39s) Loss: 0.0002(0.0730) Grad: 106.1295  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 44s (remain 12m 11s) Loss: 0.0004(0.0659) Grad: 239.1260  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 12s (remain 11m 42s) Loss: 0.0005(0.0603) Grad: 224.2203  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 41s (remain 11m 14s) Loss: 0.0080(0.0555) Grad: 1855.4673  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 9s (remain 10m 45s) Loss: 0.0105(0.0514) Grad: 2253.5469  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 37s (remain 10m 17s) Loss: 0.0055(0.0479) Grad: 2596.7300  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 6s (remain 9m 48s) Loss: 0.0000(0.0449) Grad: 37.8001  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 34s (remain 9m 20s) Loss: 0.0014(0.0423) Grad: 631.7170  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 2s (remain 8m 51s) Loss: 0.0005(0.0400) Grad: 233.7053  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 31s (remain 8m 23s) Loss: 0.0063(0.0379) Grad: 1891.2052  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 59s (remain 7m 54s) Loss: 0.0011(0.0360) Grad: 731.9476  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 27s (remain 7m 26s) Loss: 0.0077(0.0344) Grad: 4296.6768  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 55s (remain 6m 58s) Loss: 0.0002(0.0328) Grad: 93.2898  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 24s (remain 6m 29s) Loss: 0.0000(0.0314) Grad: 41.5841  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 52s (remain 6m 1s) Loss: 0.0009(0.0302) Grad: 537.5009  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 20s (remain 5m 32s) Loss: 0.0002(0.0290) Grad: 128.7459  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 48s (remain 5m 4s) Loss: 0.0007(0.0280) Grad: 392.1086  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 17s (remain 4m 36s) Loss: 0.0023(0.0270) Grad: 1436.7911  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 45s (remain 4m 7s) Loss: 0.0002(0.0261) Grad: 137.1326  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 13s (remain 3m 39s) Loss: 0.0001(0.0252) Grad: 67.9291  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 42s (remain 3m 11s) Loss: 0.0003(0.0244) Grad: 273.3757  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 11s (remain 2m 42s) Loss: 0.0001(0.0237) Grad: 78.5740  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 39s (remain 2m 14s) Loss: 0.0000(0.0230) Grad: 26.9370  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 7s (remain 1m 46s) Loss: 0.0006(0.0224) Grad: 294.3589  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 36s (remain 1m 17s) Loss: 0.0002(0.0218) Grad: 209.2258  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 4s (remain 0m 49s) Loss: 0.0002(0.0213) Grad: 103.1019  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 32s (remain 0m 20s) Loss: 0.0005(0.0207) Grad: 231.1265  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 53s (remain 0m 0s) Loss: 0.0002(0.0203) Grad: 175.8239  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 31s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 30s) Loss: 0.0005(0.0058) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 13s) Loss: 0.0006(0.0067) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 1m 59s) Loss: 0.0015(0.0103) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 46s) Loss: 0.0251(0.0105) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 32s) Loss: 0.0256(0.0095) \n","EVAL: [600/1192] Elapsed 1m 20s (remain 1m 19s) Loss: 0.1219(0.0095) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 5s) Loss: 0.0048(0.0106) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0060(0.0103) \n","EVAL: [900/1192] Elapsed 2m 0s (remain 0m 38s) Loss: 0.0037(0.0100) \n","EVAL: [1000/1192] Elapsed 2m 13s (remain 0m 25s) Loss: 0.0001(0.0097) \n","EVAL: [1100/1192] Elapsed 2m 27s (remain 0m 12s) Loss: 0.0055(0.0092) \n","EVAL: [1191/1192] Elapsed 2m 39s (remain 0m 0s) Loss: 0.0094(0.0088) \n","Epoch 1 - avg_train_loss: 0.0203  avg_val_loss: 0.0088  time: 1175s\n","Epoch 1 - Score: 0.8819\n","Epoch 1 - Save Best Score: 0.8819 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 45m 40s) Loss: 0.0001(0.0001) Grad: 257.1876  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 31s (remain 18m 18s) Loss: 0.0001(0.0023) Grad: 69.6548  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 0s (remain 17m 3s) Loss: 0.0072(0.0026) Grad: 2732.8235  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 29s (remain 16m 12s) Loss: 0.0169(0.0026) Grad: 4335.4565  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 57s (remain 15m 31s) Loss: 0.0002(0.0026) Grad: 130.3358  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 26s (remain 14m 55s) Loss: 0.0000(0.0024) Grad: 43.0959  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 54s (remain 14m 23s) Loss: 0.0008(0.0024) Grad: 467.7008  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 23s (remain 13m 52s) Loss: 0.0001(0.0025) Grad: 57.0554  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 51s (remain 13m 22s) Loss: 0.0005(0.0024) Grad: 280.8935  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 20s (remain 12m 51s) Loss: 0.0227(0.0025) Grad: 7453.1865  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 48s (remain 12m 21s) Loss: 0.0004(0.0025) Grad: 460.5751  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 16s (remain 11m 51s) Loss: 0.0002(0.0025) Grad: 110.4965  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 45s (remain 11m 22s) Loss: 0.0001(0.0024) Grad: 55.9036  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 13s (remain 10m 52s) Loss: 0.0000(0.0024) Grad: 15.5053  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 41s (remain 10m 23s) Loss: 0.0003(0.0024) Grad: 293.5155  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 10s (remain 9m 54s) Loss: 0.0014(0.0024) Grad: 1155.3413  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 38s (remain 9m 25s) Loss: 0.0003(0.0024) Grad: 334.0699  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 6s (remain 8m 56s) Loss: 0.0000(0.0024) Grad: 34.9369  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 34s (remain 8m 27s) Loss: 0.0044(0.0024) Grad: 1662.8816  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 3s (remain 7m 58s) Loss: 0.0003(0.0024) Grad: 232.6233  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 31s (remain 7m 29s) Loss: 0.0000(0.0024) Grad: 33.4271  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 59s (remain 7m 0s) Loss: 0.0012(0.0024) Grad: 1016.4749  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 27s (remain 6m 31s) Loss: 0.0002(0.0024) Grad: 259.7165  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 56s (remain 6m 3s) Loss: 0.0000(0.0024) Grad: 39.5554  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 24s (remain 5m 34s) Loss: 0.0000(0.0024) Grad: 42.9387  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 52s (remain 5m 6s) Loss: 0.0000(0.0023) Grad: 25.6203  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 21s (remain 4m 37s) Loss: 0.0001(0.0023) Grad: 84.4513  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 49s (remain 4m 9s) Loss: 0.0002(0.0023) Grad: 140.1768  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 18s (remain 3m 40s) Loss: 0.0001(0.0023) Grad: 110.5372  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 46s (remain 3m 12s) Loss: 0.0000(0.0023) Grad: 29.9374  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 15s (remain 2m 43s) Loss: 0.0001(0.0023) Grad: 77.7706  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 44s (remain 2m 15s) Loss: 0.0000(0.0023) Grad: 9.4242  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 13s (remain 1m 46s) Loss: 0.0003(0.0023) Grad: 182.5456  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 41s (remain 1m 18s) Loss: 0.0001(0.0023) Grad: 50.4699  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 10s (remain 0m 49s) Loss: 0.0003(0.0023) Grad: 262.0599  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 38s (remain 0m 21s) Loss: 0.0001(0.0023) Grad: 82.1180  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 59s (remain 0m 0s) Loss: 0.0061(0.0023) Grad: 2618.0667  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 25s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 32s) Loss: 0.0003(0.0059) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 16s) Loss: 0.0003(0.0067) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 2s) Loss: 0.0015(0.0104) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 48s) Loss: 0.0288(0.0107) \n","EVAL: [500/1192] Elapsed 1m 8s (remain 1m 34s) Loss: 0.0244(0.0096) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 20s) Loss: 0.1166(0.0096) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0057(0.0107) \n","EVAL: [800/1192] Elapsed 1m 48s (remain 0m 52s) Loss: 0.0051(0.0104) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0047(0.0101) \n","EVAL: [1000/1192] Elapsed 2m 15s (remain 0m 25s) Loss: 0.0000(0.0098) \n","EVAL: [1100/1192] Elapsed 2m 28s (remain 0m 12s) Loss: 0.0062(0.0093) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0097(0.0088) \n","Epoch 2 - avg_train_loss: 0.0023  avg_val_loss: 0.0088  time: 1182s\n","Epoch 2 - Score: 0.8844\n","Epoch 2 - Save Best Score: 0.8844 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 38m 49s) Loss: 0.0000(0.0000) Grad: 998.5231  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 32s (remain 18m 39s) Loss: 0.0029(0.0023) Grad: 1239.5131  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 2s (remain 17m 22s) Loss: 0.0058(0.0024) Grad: 2262.9788  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 30s (remain 16m 25s) Loss: 0.0001(0.0022) Grad: 61.5323  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 59s (remain 15m 42s) Loss: 0.0000(0.0020) Grad: 7.5738  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 27s (remain 15m 6s) Loss: 0.0003(0.0021) Grad: 302.2432  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 56s (remain 14m 31s) Loss: 0.0008(0.0022) Grad: 647.9866  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 24s (remain 13m 59s) Loss: 0.0118(0.0022) Grad: 3241.4434  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 53s (remain 13m 28s) Loss: 0.0000(0.0022) Grad: 34.4586  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 21s (remain 12m 57s) Loss: 0.0002(0.0021) Grad: 133.1494  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 50s (remain 12m 27s) Loss: 0.0033(0.0023) Grad: 1118.8516  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 18s (remain 11m 56s) Loss: 0.0000(0.0023) Grad: 15.7587  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 47s (remain 11m 26s) Loss: 0.0001(0.0022) Grad: 112.6297  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 16s (remain 10m 57s) Loss: 0.0003(0.0022) Grad: 273.1833  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 44s (remain 10m 27s) Loss: 0.0001(0.0022) Grad: 168.7406  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 13s (remain 9m 58s) Loss: 0.0002(0.0022) Grad: 251.6060  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 41s (remain 9m 29s) Loss: 0.0000(0.0021) Grad: 10.8352  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 10s (remain 9m 0s) Loss: 0.0067(0.0021) Grad: 3292.5623  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 38s (remain 8m 31s) Loss: 0.0001(0.0021) Grad: 104.6176  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 7s (remain 8m 2s) Loss: 0.0000(0.0021) Grad: 11.2038  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 36s (remain 7m 33s) Loss: 0.0001(0.0021) Grad: 59.6591  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 4s (remain 7m 4s) Loss: 0.0002(0.0021) Grad: 165.6426  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 33s (remain 6m 35s) Loss: 0.0013(0.0021) Grad: 640.6868  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 1s (remain 6m 6s) Loss: 0.0007(0.0021) Grad: 315.8317  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 30s (remain 5m 37s) Loss: 0.0049(0.0021) Grad: 1829.3877  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 58s (remain 5m 8s) Loss: 0.0000(0.0021) Grad: 35.5493  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 27s (remain 4m 39s) Loss: 0.0044(0.0021) Grad: 2161.3342  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 56s (remain 4m 11s) Loss: 0.0001(0.0022) Grad: 86.8020  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 24s (remain 3m 42s) Loss: 0.0000(0.0022) Grad: 19.8095  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 53s (remain 3m 13s) Loss: 0.0143(0.0022) Grad: 4835.2881  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 21s (remain 2m 44s) Loss: 0.0000(0.0022) Grad: 49.8048  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 50s (remain 2m 16s) Loss: 0.0001(0.0022) Grad: 101.1893  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 18s (remain 1m 47s) Loss: 0.0033(0.0022) Grad: 1966.3397  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 47s (remain 1m 18s) Loss: 0.0001(0.0022) Grad: 65.5946  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 15s (remain 0m 49s) Loss: 0.0001(0.0022) Grad: 55.0234  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 44s (remain 0m 21s) Loss: 0.0002(0.0022) Grad: 203.4594  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 17m 5s (remain 0m 0s) Loss: 0.0000(0.0022) Grad: 5.7394  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 35s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 28s) Loss: 0.0002(0.0061) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0004(0.0069) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0015(0.0108) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 46s) Loss: 0.0284(0.0110) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0251(0.0099) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 19s) Loss: 0.1221(0.0099) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0057(0.0110) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0053(0.0107) \n","EVAL: [900/1192] Elapsed 2m 0s (remain 0m 39s) Loss: 0.0047(0.0103) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0000(0.0101) \n","EVAL: [1100/1192] Elapsed 2m 27s (remain 0m 12s) Loss: 0.0064(0.0096) \n","EVAL: [1191/1192] Elapsed 2m 39s (remain 0m 0s) Loss: 0.0096(0.0091) \n","Epoch 3 - avg_train_loss: 0.0022  avg_val_loss: 0.0091  time: 1188s\n","Epoch 3 - Score: 0.8847\n","Epoch 3 - Save Best Score: 0.8847 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 38m 19s) Loss: 0.0001(0.0001) Grad: 159.9203  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 33s (remain 19m 23s) Loss: 0.0002(0.0028) Grad: 111.6895  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 3s (remain 17m 39s) Loss: 0.0000(0.0028) Grad: 16.2407  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 31s (remain 16m 37s) Loss: 0.0000(0.0025) Grad: 11.2445  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 0s (remain 15m 51s) Loss: 0.0000(0.0023) Grad: 10.3955  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 28s (remain 15m 12s) Loss: 0.0000(0.0022) Grad: 16.4716  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 57s (remain 14m 36s) Loss: 0.0041(0.0021) Grad: 1070.6641  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 25s (remain 14m 3s) Loss: 0.0000(0.0021) Grad: 35.7775  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 54s (remain 13m 31s) Loss: 0.0001(0.0022) Grad: 69.8779  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 22s (remain 13m 0s) Loss: 0.0001(0.0023) Grad: 132.7319  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 51s (remain 12m 29s) Loss: 0.0011(0.0022) Grad: 986.9127  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 19s (remain 11m 58s) Loss: 0.0000(0.0022) Grad: 12.0954  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 48s (remain 11m 28s) Loss: 0.0008(0.0021) Grad: 778.8311  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 16s (remain 10m 58s) Loss: 0.0001(0.0021) Grad: 74.6941  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 45s (remain 10m 29s) Loss: 0.0001(0.0021) Grad: 160.1439  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 14s (remain 9m 59s) Loss: 0.0001(0.0022) Grad: 51.5031  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 42s (remain 9m 30s) Loss: 0.0001(0.0022) Grad: 70.8064  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 11s (remain 9m 1s) Loss: 0.0011(0.0022) Grad: 803.0436  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 40s (remain 8m 32s) Loss: 0.0001(0.0022) Grad: 104.5726  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 8s (remain 8m 3s) Loss: 0.0002(0.0023) Grad: 270.8175  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 37s (remain 7m 33s) Loss: 0.0002(0.0022) Grad: 113.5910  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 5s (remain 7m 4s) Loss: 0.0000(0.0023) Grad: 31.1535  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 34s (remain 6m 35s) Loss: 0.0001(0.0022) Grad: 117.2605  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 2s (remain 6m 6s) Loss: 0.0002(0.0023) Grad: 131.9653  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 31s (remain 5m 37s) Loss: 0.0008(0.0022) Grad: 592.6887  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 59s (remain 5m 9s) Loss: 0.0085(0.0022) Grad: 3399.8745  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 28s (remain 4m 40s) Loss: 0.0001(0.0022) Grad: 102.6758  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 56s (remain 4m 11s) Loss: 0.0028(0.0022) Grad: 972.3628  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 25s (remain 3m 42s) Loss: 0.0003(0.0022) Grad: 192.3338  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 53s (remain 3m 13s) Loss: 0.0000(0.0022) Grad: 11.9963  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 22s (remain 2m 45s) Loss: 0.0131(0.0022) Grad: 4029.9951  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 51s (remain 2m 16s) Loss: 0.0003(0.0021) Grad: 251.1499  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 19s (remain 1m 47s) Loss: 0.0035(0.0022) Grad: 2346.8616  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 48s (remain 1m 18s) Loss: 0.0022(0.0021) Grad: 1508.4390  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 16s (remain 0m 49s) Loss: 0.0002(0.0021) Grad: 121.5347  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 45s (remain 0m 21s) Loss: 0.0045(0.0021) Grad: 1574.2914  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 17m 6s (remain 0m 0s) Loss: 0.0000(0.0021) Grad: 3.9986  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 58s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 29s) Loss: 0.0001(0.0061) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0003(0.0068) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0014(0.0107) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 46s) Loss: 0.0295(0.0109) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 32s) Loss: 0.0240(0.0098) \n","EVAL: [600/1192] Elapsed 1m 20s (remain 1m 19s) Loss: 0.1169(0.0098) \n","EVAL: [700/1192] Elapsed 1m 33s (remain 1m 5s) Loss: 0.0058(0.0109) \n","EVAL: [800/1192] Elapsed 1m 46s (remain 0m 52s) Loss: 0.0054(0.0106) \n","EVAL: [900/1192] Elapsed 2m 0s (remain 0m 38s) Loss: 0.0053(0.0102) \n","EVAL: [1000/1192] Elapsed 2m 13s (remain 0m 25s) Loss: 0.0000(0.0099) \n","EVAL: [1100/1192] Elapsed 2m 26s (remain 0m 12s) Loss: 0.0067(0.0095) \n","EVAL: [1191/1192] Elapsed 2m 38s (remain 0m 0s) Loss: 0.0101(0.0090) \n","Epoch 4 - avg_train_loss: 0.0021  avg_val_loss: 0.0090  time: 1187s\n","Epoch 4 - Score: 0.8843\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 35m 58s) Loss: 0.0000(0.0000) Grad: 34.3870  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 29s (remain 16m 40s) Loss: 0.0387(0.0024) Grad: 9604.6641  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 57s (remain 16m 4s) Loss: 0.0003(0.0020) Grad: 214.4183  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 25s (remain 15m 34s) Loss: 0.0000(0.0020) Grad: 10.0506  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 54s (remain 15m 6s) Loss: 0.0015(0.0021) Grad: 698.0256  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 23s (remain 14m 41s) Loss: 0.0005(0.0021) Grad: 396.7055  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 52s (remain 14m 13s) Loss: 0.0001(0.0020) Grad: 119.3446  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 21s (remain 13m 44s) Loss: 0.0009(0.0020) Grad: 860.7451  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 49s (remain 13m 15s) Loss: 0.0019(0.0021) Grad: 1150.1172  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 18s (remain 12m 46s) Loss: 0.0572(0.0021) Grad: 7693.3623  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 46s (remain 12m 17s) Loss: 0.0000(0.0020) Grad: 41.4889  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 15s (remain 11m 48s) Loss: 0.0017(0.0020) Grad: 1441.7017  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 44s (remain 11m 20s) Loss: 0.0077(0.0020) Grad: 2376.8247  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 12s (remain 10m 51s) Loss: 0.0000(0.0020) Grad: 45.2466  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 41s (remain 10m 23s) Loss: 0.0000(0.0020) Grad: 37.0969  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 10s (remain 9m 54s) Loss: 0.0002(0.0020) Grad: 176.1128  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 39s (remain 9m 26s) Loss: 0.0000(0.0020) Grad: 12.4235  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 7s (remain 8m 57s) Loss: 0.0000(0.0020) Grad: 28.5812  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 36s (remain 8m 29s) Loss: 0.0014(0.0021) Grad: 1546.8639  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 5s (remain 8m 0s) Loss: 0.0000(0.0021) Grad: 47.0069  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 34s (remain 7m 31s) Loss: 0.0004(0.0022) Grad: 404.5750  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 2s (remain 7m 2s) Loss: 0.0068(0.0021) Grad: 2836.5811  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 31s (remain 6m 34s) Loss: 0.0000(0.0021) Grad: 26.4997  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 0s (remain 6m 5s) Loss: 0.0000(0.0021) Grad: 32.9560  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 28s (remain 5m 36s) Loss: 0.0006(0.0021) Grad: 653.7357  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 57s (remain 5m 7s) Loss: 0.0057(0.0021) Grad: 1022.4534  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 25s (remain 4m 39s) Loss: 0.0004(0.0021) Grad: 371.9631  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 54s (remain 4m 10s) Loss: 0.0008(0.0021) Grad: 765.0131  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 23s (remain 3m 41s) Loss: 0.0000(0.0021) Grad: 35.8464  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 51s (remain 3m 13s) Loss: 0.0000(0.0020) Grad: 36.2030  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 20s (remain 2m 44s) Loss: 0.0000(0.0021) Grad: 13.5874  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 48s (remain 2m 15s) Loss: 0.0000(0.0020) Grad: 17.9641  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 17s (remain 1m 47s) Loss: 0.0000(0.0020) Grad: 27.3157  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 45s (remain 1m 18s) Loss: 0.0000(0.0020) Grad: 19.2580  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 14s (remain 0m 49s) Loss: 0.0002(0.0020) Grad: 213.9449  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 43s (remain 0m 21s) Loss: 0.0000(0.0021) Grad: 33.5894  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 17m 4s (remain 0m 0s) Loss: 0.0001(0.0021) Grad: 78.9265  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 0s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 29s) Loss: 0.0001(0.0062) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0003(0.0069) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 1m 59s) Loss: 0.0014(0.0108) \n","EVAL: [400/1192] Elapsed 0m 53s (remain 1m 46s) Loss: 0.0304(0.0110) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 32s) Loss: 0.0241(0.0099) \n","EVAL: [600/1192] Elapsed 1m 20s (remain 1m 19s) Loss: 0.1178(0.0099) \n","EVAL: [700/1192] Elapsed 1m 33s (remain 1m 5s) Loss: 0.0059(0.0110) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0054(0.0107) \n","EVAL: [900/1192] Elapsed 2m 0s (remain 0m 38s) Loss: 0.0056(0.0103) \n","EVAL: [1000/1192] Elapsed 2m 13s (remain 0m 25s) Loss: 0.0000(0.0100) \n","EVAL: [1100/1192] Elapsed 2m 26s (remain 0m 12s) Loss: 0.0069(0.0096) \n","EVAL: [1191/1192] Elapsed 2m 39s (remain 0m 0s) Loss: 0.0104(0.0091) \n","Epoch 5 - avg_train_loss: 0.0021  avg_val_loss: 0.0091  time: 1185s\n","Epoch 5 - Score: 0.8845\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold2_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 42m 56s) Loss: 0.2862(0.2862) Grad: 235217.7656  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 29s (remain 16m 53s) Loss: 0.2334(0.2679) Grad: 203028.5156  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 58s (remain 16m 14s) Loss: 0.1000(0.2174) Grad: 97878.8438  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 26s (remain 15m 41s) Loss: 0.0237(0.1649) Grad: 23366.7930  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 55s (remain 15m 12s) Loss: 0.0085(0.1274) Grad: 4676.7222  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 23s (remain 14m 42s) Loss: 0.0039(0.1032) Grad: 1850.1001  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 52s (remain 14m 13s) Loss: 0.0011(0.0867) Grad: 497.7375  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 21s (remain 13m 44s) Loss: 0.0004(0.0748) Grad: 224.4780  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 49s (remain 13m 15s) Loss: 0.0030(0.0658) Grad: 735.5848  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 18s (remain 12m 46s) Loss: 0.0005(0.0588) Grad: 215.8478  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 47s (remain 12m 18s) Loss: 0.0010(0.0534) Grad: 465.6878  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 15s (remain 11m 49s) Loss: 0.0008(0.0489) Grad: 493.3867  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 44s (remain 11m 20s) Loss: 0.0004(0.0450) Grad: 170.3314  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 12s (remain 10m 51s) Loss: 0.0053(0.0419) Grad: 2139.2888  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 41s (remain 10m 23s) Loss: 0.0013(0.0392) Grad: 628.5494  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 10s (remain 9m 54s) Loss: 0.0043(0.0367) Grad: 2189.6492  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 38s (remain 9m 25s) Loss: 0.0001(0.0347) Grad: 61.3231  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 7s (remain 8m 56s) Loss: 0.0008(0.0328) Grad: 290.0406  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 35s (remain 8m 28s) Loss: 0.0107(0.0311) Grad: 3621.4036  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 4s (remain 7m 59s) Loss: 0.0030(0.0296) Grad: 1032.8464  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 33s (remain 7m 30s) Loss: 0.0003(0.0283) Grad: 180.2589  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 1s (remain 7m 2s) Loss: 0.0002(0.0271) Grad: 144.2568  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 30s (remain 6m 33s) Loss: 0.0025(0.0260) Grad: 1687.7755  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 59s (remain 6m 4s) Loss: 0.0004(0.0250) Grad: 210.7996  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 27s (remain 5m 36s) Loss: 0.0012(0.0240) Grad: 329.1013  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 56s (remain 5m 7s) Loss: 0.0047(0.0232) Grad: 965.9086  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 25s (remain 4m 38s) Loss: 0.0058(0.0224) Grad: 2015.3507  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 53s (remain 4m 10s) Loss: 0.0003(0.0217) Grad: 161.9914  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 22s (remain 3m 41s) Loss: 0.0003(0.0211) Grad: 241.1049  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 50s (remain 3m 13s) Loss: 0.0009(0.0204) Grad: 787.3140  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 19s (remain 2m 44s) Loss: 0.0002(0.0199) Grad: 151.1852  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 48s (remain 2m 15s) Loss: 0.0012(0.0193) Grad: 1036.3386  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 16s (remain 1m 47s) Loss: 0.0001(0.0188) Grad: 44.7161  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 45s (remain 1m 18s) Loss: 0.0001(0.0183) Grad: 112.4247  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 14s (remain 0m 49s) Loss: 0.0128(0.0179) Grad: 4126.4575  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 42s (remain 0m 21s) Loss: 0.0006(0.0175) Grad: 266.2155  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 17m 4s (remain 0m 0s) Loss: 0.0236(0.0171) Grad: 3696.8354  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 41s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 30s) Loss: 0.0325(0.0088) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0113(0.0080) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0099(0.0080) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 46s) Loss: 0.0001(0.0085) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0001(0.0078) \n","EVAL: [600/1192] Elapsed 1m 20s (remain 1m 19s) Loss: 0.0101(0.0081) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0090(0.0089) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0000(0.0090) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0123(0.0092) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0003(0.0090) \n","EVAL: [1100/1192] Elapsed 2m 27s (remain 0m 12s) Loss: 0.0530(0.0086) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0001(0.0083) \n","Epoch 1 - avg_train_loss: 0.0171  avg_val_loss: 0.0083  time: 1187s\n","Epoch 1 - Score: 0.8871\n","Epoch 1 - Save Best Score: 0.8871 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 43m 43s) Loss: 0.0003(0.0003) Grad: 942.6595  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 32s (remain 18m 41s) Loss: 0.0008(0.0031) Grad: 429.2835  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 1s (remain 17m 17s) Loss: 0.0002(0.0032) Grad: 213.4668  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 30s (remain 16m 22s) Loss: 0.0001(0.0030) Grad: 66.0343  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 58s (remain 15m 41s) Loss: 0.0001(0.0028) Grad: 89.3826  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 27s (remain 15m 6s) Loss: 0.0000(0.0026) Grad: 17.0164  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 56s (remain 14m 32s) Loss: 0.0002(0.0027) Grad: 130.4856  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 24s (remain 13m 59s) Loss: 0.0001(0.0026) Grad: 72.4115  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 53s (remain 13m 28s) Loss: 0.0001(0.0027) Grad: 64.6511  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 22s (remain 12m 57s) Loss: 0.0015(0.0026) Grad: 1111.6718  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 50s (remain 12m 27s) Loss: 0.0003(0.0027) Grad: 254.0371  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 19s (remain 11m 57s) Loss: 0.0002(0.0026) Grad: 144.0898  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 47s (remain 11m 27s) Loss: 0.0000(0.0026) Grad: 29.4205  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 16s (remain 10m 57s) Loss: 0.0003(0.0026) Grad: 206.8713  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 44s (remain 10m 28s) Loss: 0.0000(0.0025) Grad: 8.3897  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 13s (remain 9m 58s) Loss: 0.0007(0.0026) Grad: 306.5230  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 42s (remain 9m 29s) Loss: 0.0001(0.0026) Grad: 74.7226  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 10s (remain 9m 0s) Loss: 0.0002(0.0026) Grad: 208.0533  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 39s (remain 8m 31s) Loss: 0.0002(0.0026) Grad: 192.8718  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 7s (remain 8m 2s) Loss: 0.0003(0.0026) Grad: 221.3146  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 36s (remain 7m 33s) Loss: 0.0052(0.0026) Grad: 2912.2480  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 5s (remain 7m 4s) Loss: 0.0001(0.0025) Grad: 44.8853  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 33s (remain 6m 35s) Loss: 0.0518(0.0025) Grad: 13185.9014  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 2s (remain 6m 6s) Loss: 0.0044(0.0025) Grad: 1510.6533  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 30s (remain 5m 37s) Loss: 0.0001(0.0026) Grad: 72.6953  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 59s (remain 5m 8s) Loss: 0.0000(0.0026) Grad: 26.3380  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 28s (remain 4m 40s) Loss: 0.0172(0.0026) Grad: 7353.1406  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 56s (remain 4m 11s) Loss: 0.0146(0.0026) Grad: 4662.3691  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 25s (remain 3m 42s) Loss: 0.0000(0.0026) Grad: 22.6768  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 53s (remain 3m 13s) Loss: 0.0001(0.0026) Grad: 139.3925  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 21s (remain 2m 44s) Loss: 0.0000(0.0027) Grad: 11.9407  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 50s (remain 2m 16s) Loss: 0.0001(0.0026) Grad: 55.2205  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 18s (remain 1m 47s) Loss: 0.0028(0.0027) Grad: 1114.4502  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 47s (remain 1m 18s) Loss: 0.0001(0.0027) Grad: 58.4255  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 15s (remain 0m 49s) Loss: 0.0001(0.0027) Grad: 77.1162  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 44s (remain 0m 21s) Loss: 0.0035(0.0027) Grad: 1598.4757  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 17m 5s (remain 0m 0s) Loss: 0.0004(0.0027) Grad: 311.8402  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 7s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 30s) Loss: 0.0256(0.0080) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 15s) Loss: 0.0081(0.0072) \n","EVAL: [300/1192] Elapsed 0m 41s (remain 2m 1s) Loss: 0.0080(0.0071) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 47s) Loss: 0.0002(0.0076) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0001(0.0070) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 20s) Loss: 0.0083(0.0073) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0066(0.0080) \n","EVAL: [800/1192] Elapsed 1m 48s (remain 0m 52s) Loss: 0.0000(0.0082) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0122(0.0083) \n","EVAL: [1000/1192] Elapsed 2m 15s (remain 0m 25s) Loss: 0.0004(0.0081) \n","EVAL: [1100/1192] Elapsed 2m 28s (remain 0m 12s) Loss: 0.0522(0.0078) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0001(0.0075) \n","Epoch 2 - avg_train_loss: 0.0027  avg_val_loss: 0.0075  time: 1188s\n","Epoch 2 - Score: 0.8878\n","Epoch 2 - Save Best Score: 0.8878 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 38m 32s) Loss: 0.0001(0.0001) Grad: 336.5490  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 32s (remain 18m 37s) Loss: 0.0006(0.0027) Grad: 526.2780  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 1s (remain 17m 19s) Loss: 0.0013(0.0028) Grad: 1022.4813  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 30s (remain 16m 25s) Loss: 0.0000(0.0028) Grad: 46.3695  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 59s (remain 15m 43s) Loss: 0.0115(0.0029) Grad: 5187.1401  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 28s (remain 15m 8s) Loss: 0.0018(0.0028) Grad: 1481.1204  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 56s (remain 14m 34s) Loss: 0.0009(0.0028) Grad: 448.9041  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 25s (remain 14m 2s) Loss: 0.0009(0.0027) Grad: 800.7989  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 54s (remain 13m 31s) Loss: 0.0040(0.0025) Grad: 1374.6199  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 22s (remain 13m 0s) Loss: 0.0064(0.0027) Grad: 3554.2036  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 51s (remain 12m 29s) Loss: 0.0000(0.0027) Grad: 54.3644  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 20s (remain 11m 59s) Loss: 0.0183(0.0027) Grad: 7097.3369  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 48s (remain 11m 29s) Loss: 0.0000(0.0027) Grad: 38.6939  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 17s (remain 10m 59s) Loss: 0.0001(0.0028) Grad: 59.7139  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 46s (remain 10m 30s) Loss: 0.0000(0.0028) Grad: 44.0303  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 14s (remain 10m 0s) Loss: 0.0002(0.0028) Grad: 156.4996  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 43s (remain 9m 31s) Loss: 0.0018(0.0028) Grad: 906.0345  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 12s (remain 9m 2s) Loss: 0.0008(0.0028) Grad: 699.0023  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 41s (remain 8m 33s) Loss: 0.0002(0.0028) Grad: 181.6394  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 9s (remain 8m 4s) Loss: 0.0003(0.0027) Grad: 251.6982  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 38s (remain 7m 34s) Loss: 0.0001(0.0027) Grad: 95.1001  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 7s (remain 7m 5s) Loss: 0.0000(0.0027) Grad: 57.0152  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 35s (remain 6m 36s) Loss: 0.0047(0.0026) Grad: 2878.6941  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 4s (remain 6m 7s) Loss: 0.0000(0.0027) Grad: 14.6505  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 32s (remain 5m 38s) Loss: 0.0001(0.0026) Grad: 95.6552  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 1s (remain 5m 9s) Loss: 0.0000(0.0026) Grad: 15.6341  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 30s (remain 4m 40s) Loss: 0.0054(0.0026) Grad: 1196.1036  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 58s (remain 4m 11s) Loss: 0.0017(0.0026) Grad: 604.5795  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 27s (remain 3m 43s) Loss: 0.0000(0.0026) Grad: 45.0708  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 55s (remain 3m 14s) Loss: 0.0023(0.0026) Grad: 1148.1017  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 24s (remain 2m 45s) Loss: 0.0001(0.0026) Grad: 54.2906  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 53s (remain 2m 16s) Loss: 0.0054(0.0026) Grad: 2812.6873  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 21s (remain 1m 47s) Loss: 0.0000(0.0026) Grad: 48.5961  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 50s (remain 1m 18s) Loss: 0.0000(0.0026) Grad: 45.8501  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 19s (remain 0m 50s) Loss: 0.0000(0.0026) Grad: 12.1528  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 47s (remain 0m 21s) Loss: 0.0014(0.0026) Grad: 1115.4066  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 17m 8s (remain 0m 0s) Loss: 0.0069(0.0026) Grad: 2432.4121  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 8s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 29s) Loss: 0.0321(0.0087) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 13s) Loss: 0.0089(0.0078) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0093(0.0078) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 46s) Loss: 0.0001(0.0083) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 32s) Loss: 0.0000(0.0076) \n","EVAL: [600/1192] Elapsed 1m 20s (remain 1m 19s) Loss: 0.0100(0.0079) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 5s) Loss: 0.0077(0.0086) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0000(0.0088) \n","EVAL: [900/1192] Elapsed 2m 0s (remain 0m 39s) Loss: 0.0118(0.0090) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0003(0.0088) \n","EVAL: [1100/1192] Elapsed 2m 27s (remain 0m 12s) Loss: 0.0557(0.0084) \n","EVAL: [1191/1192] Elapsed 2m 39s (remain 0m 0s) Loss: 0.0000(0.0080) \n","Epoch 3 - avg_train_loss: 0.0026  avg_val_loss: 0.0080  time: 1191s\n","Epoch 3 - Score: 0.8885\n","Epoch 3 - Save Best Score: 0.8885 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 37m 56s) Loss: 0.0001(0.0001) Grad: 994.5983  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 31s (remain 18m 17s) Loss: 0.0109(0.0023) Grad: 3745.7708  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 1s (remain 17m 9s) Loss: 0.0001(0.0028) Grad: 68.3051  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 29s (remain 16m 17s) Loss: 0.0170(0.0030) Grad: 6200.6646  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 58s (remain 15m 38s) Loss: 0.0023(0.0028) Grad: 1895.8015  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 27s (remain 15m 2s) Loss: 0.0001(0.0028) Grad: 159.5673  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 55s (remain 14m 29s) Loss: 0.0009(0.0028) Grad: 853.4478  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 24s (remain 13m 58s) Loss: 0.0039(0.0027) Grad: 1945.1962  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 52s (remain 13m 26s) Loss: 0.0000(0.0027) Grad: 10.8996  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 21s (remain 12m 56s) Loss: 0.0008(0.0026) Grad: 801.6268  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 50s (remain 12m 26s) Loss: 0.0001(0.0027) Grad: 56.4718  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 18s (remain 11m 56s) Loss: 0.0000(0.0026) Grad: 8.2030  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 47s (remain 11m 26s) Loss: 0.0019(0.0026) Grad: 1210.1061  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 15s (remain 10m 56s) Loss: 0.0001(0.0025) Grad: 60.3159  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 44s (remain 10m 27s) Loss: 0.0002(0.0025) Grad: 190.8693  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 13s (remain 9m 58s) Loss: 0.0004(0.0025) Grad: 341.6255  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 41s (remain 9m 29s) Loss: 0.0053(0.0026) Grad: 2537.6714  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 10s (remain 9m 0s) Loss: 0.0006(0.0026) Grad: 277.6795  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 38s (remain 8m 31s) Loss: 0.0002(0.0026) Grad: 253.5660  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 7s (remain 8m 2s) Loss: 0.0055(0.0027) Grad: 1690.3450  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 35s (remain 7m 33s) Loss: 0.0001(0.0027) Grad: 73.4811  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 4s (remain 7m 4s) Loss: 0.0000(0.0026) Grad: 19.1489  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 33s (remain 6m 35s) Loss: 0.0000(0.0026) Grad: 14.5021  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 1s (remain 6m 6s) Loss: 0.0004(0.0026) Grad: 502.4727  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 30s (remain 5m 37s) Loss: 0.0000(0.0026) Grad: 47.4375  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 59s (remain 5m 8s) Loss: 0.0000(0.0026) Grad: 29.7543  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 28s (remain 4m 40s) Loss: 0.0000(0.0026) Grad: 54.1579  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 56s (remain 4m 11s) Loss: 0.0003(0.0025) Grad: 253.1893  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 25s (remain 3m 42s) Loss: 0.0001(0.0026) Grad: 189.9192  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 54s (remain 3m 13s) Loss: 0.0000(0.0026) Grad: 5.3550  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 22s (remain 2m 45s) Loss: 0.0043(0.0025) Grad: 2208.8770  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 51s (remain 2m 16s) Loss: 0.0432(0.0026) Grad: 8099.0054  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 20s (remain 1m 47s) Loss: 0.0038(0.0026) Grad: 2196.8130  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 48s (remain 1m 18s) Loss: 0.0001(0.0026) Grad: 151.9700  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 17s (remain 0m 50s) Loss: 0.0002(0.0026) Grad: 217.7032  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 45s (remain 0m 21s) Loss: 0.0000(0.0026) Grad: 25.6490  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 17m 7s (remain 0m 0s) Loss: 0.0000(0.0026) Grad: 42.1826  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 50s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 28s) Loss: 0.0308(0.0083) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0090(0.0075) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0102(0.0074) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 46s) Loss: 0.0001(0.0079) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0001(0.0072) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 19s) Loss: 0.0107(0.0074) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0078(0.0081) \n","EVAL: [800/1192] Elapsed 1m 48s (remain 0m 52s) Loss: 0.0000(0.0083) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0098(0.0085) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0003(0.0083) \n","EVAL: [1100/1192] Elapsed 2m 28s (remain 0m 12s) Loss: 0.0542(0.0079) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0000(0.0076) \n","Epoch 4 - avg_train_loss: 0.0026  avg_val_loss: 0.0076  time: 1190s\n","Epoch 4 - Score: 0.8885\n","Epoch 4 - Save Best Score: 0.8885 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 38m 57s) Loss: 0.0000(0.0000) Grad: 62.4526  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 33s (remain 19m 9s) Loss: 0.0001(0.0027) Grad: 91.5326  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 2s (remain 17m 21s) Loss: 0.0000(0.0026) Grad: 21.8552  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 30s (remain 16m 28s) Loss: 0.0001(0.0022) Grad: 140.0150  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 59s (remain 15m 47s) Loss: 0.0001(0.0022) Grad: 84.4918  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 28s (remain 15m 10s) Loss: 0.0000(0.0022) Grad: 16.9771  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 57s (remain 14m 35s) Loss: 0.0000(0.0024) Grad: 29.8984  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 25s (remain 14m 2s) Loss: 0.0000(0.0025) Grad: 48.2227  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 54s (remain 13m 30s) Loss: 0.0033(0.0026) Grad: 1455.0492  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 22s (remain 12m 59s) Loss: 0.0001(0.0027) Grad: 62.0859  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 51s (remain 12m 29s) Loss: 0.0002(0.0026) Grad: 141.9341  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 19s (remain 11m 58s) Loss: 0.0003(0.0027) Grad: 269.1929  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 48s (remain 11m 28s) Loss: 0.0000(0.0026) Grad: 6.3851  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 17s (remain 10m 59s) Loss: 0.0004(0.0027) Grad: 444.1790  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 45s (remain 10m 29s) Loss: 0.0029(0.0027) Grad: 581.8265  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 14s (remain 10m 0s) Loss: 0.0013(0.0027) Grad: 650.5726  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 43s (remain 9m 30s) Loss: 0.0000(0.0028) Grad: 43.1623  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 11s (remain 9m 1s) Loss: 0.0004(0.0027) Grad: 352.1017  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 40s (remain 8m 32s) Loss: 0.0017(0.0027) Grad: 1397.3425  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 8s (remain 8m 3s) Loss: 0.0001(0.0027) Grad: 63.4220  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 37s (remain 7m 34s) Loss: 0.0000(0.0027) Grad: 52.3935  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 5s (remain 7m 5s) Loss: 0.0001(0.0027) Grad: 73.7786  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 34s (remain 6m 36s) Loss: 0.0000(0.0026) Grad: 48.9918  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 3s (remain 6m 7s) Loss: 0.0033(0.0026) Grad: 1379.3016  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 31s (remain 5m 38s) Loss: 0.0000(0.0026) Grad: 38.0570  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 0s (remain 5m 9s) Loss: 0.0000(0.0026) Grad: 36.4678  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 28s (remain 4m 40s) Loss: 0.0005(0.0026) Grad: 360.0834  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 57s (remain 4m 11s) Loss: 0.0016(0.0026) Grad: 1080.9624  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 26s (remain 3m 42s) Loss: 0.0000(0.0026) Grad: 44.7314  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 54s (remain 3m 13s) Loss: 0.0001(0.0026) Grad: 67.4211  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 23s (remain 2m 45s) Loss: 0.0000(0.0026) Grad: 35.5175  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 52s (remain 2m 16s) Loss: 0.0000(0.0025) Grad: 43.9934  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 20s (remain 1m 47s) Loss: 0.0004(0.0025) Grad: 416.4413  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 49s (remain 1m 18s) Loss: 0.0000(0.0025) Grad: 26.7943  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 18s (remain 0m 50s) Loss: 0.0005(0.0026) Grad: 294.2821  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 46s (remain 0m 21s) Loss: 0.0000(0.0026) Grad: 11.1246  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 17m 7s (remain 0m 0s) Loss: 0.0000(0.0026) Grad: 23.1795  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 16s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 28s) Loss: 0.0311(0.0085) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 13s) Loss: 0.0086(0.0076) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0093(0.0076) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 46s) Loss: 0.0001(0.0081) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0000(0.0074) \n","EVAL: [600/1192] Elapsed 1m 20s (remain 1m 19s) Loss: 0.0101(0.0076) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0076(0.0084) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0000(0.0085) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0106(0.0087) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0003(0.0085) \n","EVAL: [1100/1192] Elapsed 2m 27s (remain 0m 12s) Loss: 0.0561(0.0081) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0000(0.0078) \n","Epoch 5 - avg_train_loss: 0.0026  avg_val_loss: 0.0078  time: 1190s\n","Epoch 5 - Score: 0.8889\n","Epoch 5 - Save Best Score: 0.8889 Model\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp054/fold3_best.pth\n","Epoch: [1][0/3575] Elapsed 0m 1s (remain 61m 9s) Loss: 0.2667(0.2667) Grad: 230086.8906  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 29s (remain 17m 7s) Loss: 0.2092(0.2486) Grad: 191175.3125  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 58s (remain 16m 20s) Loss: 0.0855(0.1989) Grad: 85428.5469  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 27s (remain 15m 47s) Loss: 0.0184(0.1495) Grad: 18886.8867  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 56s (remain 15m 18s) Loss: 0.0053(0.1151) Grad: 3217.7527  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 24s (remain 14m 47s) Loss: 0.0008(0.0930) Grad: 520.3605  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 53s (remain 14m 17s) Loss: 0.0007(0.0782) Grad: 382.4508  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 22s (remain 13m 48s) Loss: 0.0034(0.0675) Grad: 1302.9570  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 50s (remain 13m 18s) Loss: 0.0008(0.0595) Grad: 333.1980  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 19s (remain 12m 49s) Loss: 0.0003(0.0531) Grad: 140.7656  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 47s (remain 12m 19s) Loss: 0.0099(0.0483) Grad: 2802.0852  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 16s (remain 11m 50s) Loss: 0.0541(0.0442) Grad: 13186.4795  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 45s (remain 11m 22s) Loss: 0.0001(0.0407) Grad: 100.4982  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 13s (remain 10m 53s) Loss: 0.0002(0.0377) Grad: 112.2080  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 42s (remain 10m 24s) Loss: 0.0054(0.0351) Grad: 1191.7601  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 11s (remain 9m 55s) Loss: 0.0002(0.0330) Grad: 113.8668  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 39s (remain 9m 27s) Loss: 0.0014(0.0311) Grad: 426.1666  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 8s (remain 8m 58s) Loss: 0.0003(0.0294) Grad: 144.8827  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 37s (remain 8m 29s) Loss: 0.0007(0.0278) Grad: 352.3846  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 6s (remain 8m 0s) Loss: 0.0009(0.0265) Grad: 417.4535  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 34s (remain 7m 31s) Loss: 0.0041(0.0253) Grad: 2030.3951  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 3s (remain 7m 3s) Loss: 0.0001(0.0243) Grad: 81.4868  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 31s (remain 6m 34s) Loss: 0.0001(0.0233) Grad: 81.9130  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 0s (remain 6m 5s) Loss: 0.0009(0.0224) Grad: 476.1843  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 11m 29s (remain 5m 36s) Loss: 0.0001(0.0216) Grad: 83.7853  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 57s (remain 5m 8s) Loss: 0.0002(0.0208) Grad: 100.1884  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 12m 26s (remain 4m 39s) Loss: 0.0000(0.0201) Grad: 32.6696  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 54s (remain 4m 10s) Loss: 0.0006(0.0194) Grad: 445.4195  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 13m 23s (remain 3m 42s) Loss: 0.0003(0.0189) Grad: 363.1108  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 52s (remain 3m 13s) Loss: 0.0004(0.0183) Grad: 342.6973  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 14m 20s (remain 2m 44s) Loss: 0.0002(0.0178) Grad: 123.5808  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 49s (remain 2m 15s) Loss: 0.0052(0.0173) Grad: 2797.2456  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 15m 18s (remain 1m 47s) Loss: 0.0000(0.0169) Grad: 41.0635  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 46s (remain 1m 18s) Loss: 0.0051(0.0164) Grad: 1574.6047  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 16m 15s (remain 0m 49s) Loss: 0.0001(0.0160) Grad: 101.6062  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 16m 44s (remain 0m 21s) Loss: 0.0126(0.0156) Grad: 4326.0620  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 17m 5s (remain 0m 0s) Loss: 0.0000(0.0154) Grad: 47.5933  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 58s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 32s) Loss: 0.0505(0.0083) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 16s) Loss: 0.0068(0.0076) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 1s) Loss: 0.0091(0.0084) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 47s) Loss: 0.0000(0.0079) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0651(0.0076) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 19s) Loss: 0.0093(0.0079) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0039(0.0086) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0211(0.0086) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0112(0.0088) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0000(0.0086) \n","EVAL: [1100/1192] Elapsed 2m 28s (remain 0m 12s) Loss: 0.0193(0.0084) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0001(0.0082) \n","Epoch 1 - avg_train_loss: 0.0154  avg_val_loss: 0.0082  time: 1188s\n","Epoch 1 - Score: 0.8905\n","Epoch 1 - Save Best Score: 0.8905 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 41m 23s) Loss: 0.0033(0.0033) Grad: 1827.7372  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 33s (remain 19m 2s) Loss: 0.0001(0.0024) Grad: 90.2676  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 2s (remain 17m 24s) Loss: 0.0003(0.0036) Grad: 197.8504  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 30s (remain 16m 29s) Loss: 0.0008(0.0033) Grad: 496.3690  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 59s (remain 15m 47s) Loss: 0.0007(0.0030) Grad: 570.5594  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 28s (remain 15m 10s) Loss: 0.0000(0.0028) Grad: 37.1250  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 57s (remain 14m 36s) Loss: 0.0002(0.0026) Grad: 121.4033  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 25s (remain 14m 4s) Loss: 0.0002(0.0027) Grad: 194.5888  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 54s (remain 13m 32s) Loss: 0.0003(0.0026) Grad: 174.1533  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 23s (remain 13m 0s) Loss: 0.0005(0.0025) Grad: 229.0399  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 51s (remain 12m 30s) Loss: 0.0087(0.0025) Grad: 2169.2473  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 20s (remain 11m 59s) Loss: 0.0003(0.0024) Grad: 231.6325  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 49s (remain 11m 29s) Loss: 0.0001(0.0025) Grad: 102.9234  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 17s (remain 11m 0s) Loss: 0.0000(0.0025) Grad: 12.8231  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 46s (remain 10m 30s) Loss: 0.0001(0.0025) Grad: 102.2998  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 15s (remain 10m 1s) Loss: 0.0002(0.0025) Grad: 179.9566  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 43s (remain 9m 31s) Loss: 0.0049(0.0024) Grad: 2851.8276  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 12s (remain 9m 2s) Loss: 0.0001(0.0024) Grad: 83.2789  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 40s (remain 8m 33s) Loss: 0.0745(0.0024) Grad: 20461.0176  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 9s (remain 8m 3s) Loss: 0.0003(0.0024) Grad: 200.6748  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 38s (remain 7m 34s) Loss: 0.0056(0.0024) Grad: 1876.3958  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 6s (remain 7m 5s) Loss: 0.0003(0.0024) Grad: 210.2283  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 35s (remain 6m 36s) Loss: 0.0001(0.0024) Grad: 115.5796  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 4s (remain 6m 7s) Loss: 0.0029(0.0024) Grad: 1910.8651  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 11m 32s (remain 5m 38s) Loss: 0.0000(0.0024) Grad: 44.3462  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 1s (remain 5m 9s) Loss: 0.0465(0.0024) Grad: 12506.7363  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 12m 30s (remain 4m 40s) Loss: 0.0136(0.0024) Grad: 4319.9429  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 58s (remain 4m 12s) Loss: 0.0002(0.0024) Grad: 137.4402  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 13m 27s (remain 3m 43s) Loss: 0.0005(0.0024) Grad: 270.7701  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 56s (remain 3m 14s) Loss: 0.0002(0.0024) Grad: 195.1911  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 14m 24s (remain 2m 45s) Loss: 0.0001(0.0024) Grad: 73.7850  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 53s (remain 2m 16s) Loss: 0.0149(0.0023) Grad: 4892.5850  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 15m 22s (remain 1m 47s) Loss: 0.0091(0.0023) Grad: 4919.5386  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 50s (remain 1m 18s) Loss: 0.0007(0.0023) Grad: 522.7184  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 16m 19s (remain 0m 50s) Loss: 0.0001(0.0024) Grad: 89.9873  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 16m 47s (remain 0m 21s) Loss: 0.0002(0.0023) Grad: 204.0278  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 17m 8s (remain 0m 0s) Loss: 0.0014(0.0023) Grad: 472.2968  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 3s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 30s) Loss: 0.0547(0.0089) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0106(0.0081) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 1s) Loss: 0.0107(0.0088) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 47s) Loss: 0.0000(0.0084) \n","EVAL: [500/1192] Elapsed 1m 8s (remain 1m 34s) Loss: 0.0690(0.0080) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 20s) Loss: 0.0121(0.0084) \n","EVAL: [700/1192] Elapsed 1m 35s (remain 1m 6s) Loss: 0.0048(0.0091) \n","EVAL: [800/1192] Elapsed 1m 48s (remain 0m 53s) Loss: 0.0227(0.0091) \n","EVAL: [900/1192] Elapsed 2m 2s (remain 0m 39s) Loss: 0.0117(0.0093) \n","EVAL: [1000/1192] Elapsed 2m 16s (remain 0m 25s) Loss: 0.0000(0.0091) \n","EVAL: [1100/1192] Elapsed 2m 29s (remain 0m 12s) Loss: 0.0208(0.0089) \n","EVAL: [1191/1192] Elapsed 2m 41s (remain 0m 0s) Loss: 0.0000(0.0087) \n","Epoch 2 - avg_train_loss: 0.0023  avg_val_loss: 0.0087  time: 1193s\n","Epoch 2 - Score: 0.8915\n","Epoch 2 - Save Best Score: 0.8915 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 37m 54s) Loss: 0.0001(0.0001) Grad: 493.4990  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 33s (remain 19m 0s) Loss: 0.0000(0.0019) Grad: 17.9689  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 2s (remain 17m 31s) Loss: 0.0000(0.0021) Grad: 31.5599  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 31s (remain 16m 31s) Loss: 0.0016(0.0023) Grad: 1048.8555  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 59s (remain 15m 49s) Loss: 0.0001(0.0021) Grad: 86.6911  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 28s (remain 15m 11s) Loss: 0.0201(0.0022) Grad: 4879.4194  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 57s (remain 14m 37s) Loss: 0.0000(0.0023) Grad: 9.9631  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 25s (remain 14m 4s) Loss: 0.0001(0.0024) Grad: 95.0157  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 54s (remain 13m 32s) Loss: 0.0004(0.0022) Grad: 399.7371  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 23s (remain 13m 1s) Loss: 0.0012(0.0022) Grad: 729.1074  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 51s (remain 12m 30s) Loss: 0.0001(0.0022) Grad: 81.8244  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 20s (remain 12m 0s) Loss: 0.0000(0.0022) Grad: 46.6421  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 49s (remain 11m 30s) Loss: 0.0001(0.0023) Grad: 145.5294  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 17s (remain 11m 0s) Loss: 0.0000(0.0023) Grad: 31.6383  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 46s (remain 10m 30s) Loss: 0.0004(0.0024) Grad: 333.9641  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 15s (remain 10m 1s) Loss: 0.0020(0.0023) Grad: 1272.3297  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 43s (remain 9m 31s) Loss: 0.0156(0.0024) Grad: 4210.7422  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 12s (remain 9m 2s) Loss: 0.0005(0.0024) Grad: 457.1207  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 40s (remain 8m 33s) Loss: 0.0005(0.0024) Grad: 384.7365  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 9s (remain 8m 3s) Loss: 0.0022(0.0024) Grad: 1277.2963  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 38s (remain 7m 34s) Loss: 0.0027(0.0024) Grad: 1754.1537  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 7s (remain 7m 5s) Loss: 0.0002(0.0024) Grad: 236.7145  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 35s (remain 6m 37s) Loss: 0.0030(0.0024) Grad: 2312.2522  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 4s (remain 6m 7s) Loss: 0.0014(0.0024) Grad: 1151.9955  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 11m 33s (remain 5m 39s) Loss: 0.0001(0.0024) Grad: 78.0283  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 2s (remain 5m 10s) Loss: 0.0041(0.0023) Grad: 1570.4609  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 12m 30s (remain 4m 41s) Loss: 0.0024(0.0023) Grad: 1525.8981  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 59s (remain 4m 12s) Loss: 0.0008(0.0024) Grad: 532.8355  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 13m 28s (remain 3m 43s) Loss: 0.0000(0.0024) Grad: 20.6428  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 56s (remain 3m 14s) Loss: 0.0015(0.0024) Grad: 666.1826  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 14m 25s (remain 2m 45s) Loss: 0.0063(0.0023) Grad: 2693.8794  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 53s (remain 2m 16s) Loss: 0.0031(0.0023) Grad: 1785.3671  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 15m 22s (remain 1m 47s) Loss: 0.0001(0.0023) Grad: 108.9549  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 51s (remain 1m 18s) Loss: 0.0019(0.0023) Grad: 1350.5553  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 16m 20s (remain 0m 50s) Loss: 0.0002(0.0023) Grad: 183.9171  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 16m 48s (remain 0m 21s) Loss: 0.0030(0.0023) Grad: 1960.6741  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 17m 9s (remain 0m 0s) Loss: 0.0000(0.0023) Grad: 20.3194  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 27s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 28s) Loss: 0.0473(0.0076) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0069(0.0070) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0102(0.0077) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 46s) Loss: 0.0000(0.0073) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0669(0.0071) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 19s) Loss: 0.0086(0.0074) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0048(0.0081) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0183(0.0081) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0117(0.0083) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0000(0.0081) \n","EVAL: [1100/1192] Elapsed 2m 28s (remain 0m 12s) Loss: 0.0216(0.0079) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0001(0.0077) \n","Epoch 3 - avg_train_loss: 0.0023  avg_val_loss: 0.0077  time: 1193s\n","Epoch 3 - Score: 0.8920\n","Epoch 3 - Save Best Score: 0.8920 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 35m 34s) Loss: 0.0004(0.0004) Grad: 411.7352  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 32s (remain 18m 25s) Loss: 0.0000(0.0045) Grad: 23.2116  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 2s (remain 17m 20s) Loss: 0.0044(0.0035) Grad: 2079.0142  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 30s (remain 16m 27s) Loss: 0.0005(0.0039) Grad: 458.8158  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 59s (remain 15m 45s) Loss: 0.0001(0.0036) Grad: 66.8954  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 28s (remain 15m 9s) Loss: 0.0001(0.0032) Grad: 78.1576  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 56s (remain 14m 34s) Loss: 0.0005(0.0031) Grad: 493.2091  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 25s (remain 14m 2s) Loss: 0.0000(0.0028) Grad: 35.5909  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 54s (remain 13m 31s) Loss: 0.0060(0.0028) Grad: 1725.2372  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 22s (remain 12m 59s) Loss: 0.0003(0.0027) Grad: 331.8613  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 51s (remain 12m 29s) Loss: 0.0002(0.0027) Grad: 145.9690  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 20s (remain 11m 59s) Loss: 0.0000(0.0026) Grad: 15.8521  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 48s (remain 11m 29s) Loss: 0.0000(0.0026) Grad: 39.9707  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 17s (remain 11m 0s) Loss: 0.0000(0.0027) Grad: 44.4716  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 46s (remain 10m 30s) Loss: 0.0012(0.0026) Grad: 904.5546  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 14s (remain 10m 0s) Loss: 0.0094(0.0026) Grad: 3949.3872  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 43s (remain 9m 31s) Loss: 0.0001(0.0026) Grad: 93.2278  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 12s (remain 9m 2s) Loss: 0.0000(0.0025) Grad: 35.3254  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 40s (remain 8m 33s) Loss: 0.0267(0.0025) Grad: 6888.9888  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 9s (remain 8m 3s) Loss: 0.0001(0.0025) Grad: 102.0059  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 38s (remain 7m 34s) Loss: 0.0024(0.0025) Grad: 1143.0378  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 6s (remain 7m 5s) Loss: 0.0001(0.0025) Grad: 148.9209  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 35s (remain 6m 36s) Loss: 0.0001(0.0025) Grad: 59.5449  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 4s (remain 6m 7s) Loss: 0.0000(0.0024) Grad: 54.3071  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 11m 32s (remain 5m 38s) Loss: 0.0001(0.0024) Grad: 73.0022  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 1s (remain 5m 9s) Loss: 0.0004(0.0024) Grad: 307.0876  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 12m 30s (remain 4m 41s) Loss: 0.0092(0.0023) Grad: 3030.0161  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 59s (remain 4m 12s) Loss: 0.0056(0.0023) Grad: 3814.2629  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 13m 27s (remain 3m 43s) Loss: 0.0000(0.0023) Grad: 12.8653  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 56s (remain 3m 14s) Loss: 0.0000(0.0023) Grad: 28.5808  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 14m 25s (remain 2m 45s) Loss: 0.0083(0.0023) Grad: 1972.9553  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 53s (remain 2m 16s) Loss: 0.0062(0.0023) Grad: 2554.6135  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 15m 22s (remain 1m 47s) Loss: 0.0005(0.0023) Grad: 289.7059  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 51s (remain 1m 18s) Loss: 0.0000(0.0023) Grad: 22.8895  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 16m 20s (remain 0m 50s) Loss: 0.0000(0.0023) Grad: 51.6550  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 16m 48s (remain 0m 21s) Loss: 0.0000(0.0023) Grad: 59.6272  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 17m 9s (remain 0m 0s) Loss: 0.0009(0.0023) Grad: 625.6873  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 49s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 31s) Loss: 0.0505(0.0082) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 14s) Loss: 0.0082(0.0075) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 0s) Loss: 0.0102(0.0082) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 46s) Loss: 0.0000(0.0078) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0698(0.0075) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 19s) Loss: 0.0105(0.0079) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0048(0.0086) \n","EVAL: [800/1192] Elapsed 1m 47s (remain 0m 52s) Loss: 0.0206(0.0086) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0119(0.0088) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0000(0.0086) \n","EVAL: [1100/1192] Elapsed 2m 28s (remain 0m 12s) Loss: 0.0214(0.0084) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0000(0.0082) \n","Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0082  time: 1193s\n","Epoch 4 - Score: 0.8914\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 36m 44s) Loss: 0.0008(0.0008) Grad: 936.4751  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 29s (remain 16m 44s) Loss: 0.0044(0.0024) Grad: 1836.0190  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 57s (remain 16m 12s) Loss: 0.0001(0.0024) Grad: 110.5087  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 26s (remain 15m 42s) Loss: 0.0000(0.0023) Grad: 33.1329  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 55s (remain 15m 11s) Loss: 0.0000(0.0023) Grad: 11.7410  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 23s (remain 14m 42s) Loss: 0.0000(0.0023) Grad: 14.7342  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 52s (remain 14m 13s) Loss: 0.0003(0.0022) Grad: 342.2332  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 21s (remain 13m 44s) Loss: 0.0001(0.0023) Grad: 104.7136  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 49s (remain 13m 15s) Loss: 0.0002(0.0022) Grad: 256.0894  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 18s (remain 12m 46s) Loss: 0.0000(0.0021) Grad: 47.4933  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 47s (remain 12m 18s) Loss: 0.0101(0.0020) Grad: 4896.5010  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 15s (remain 11m 49s) Loss: 0.0019(0.0021) Grad: 1105.3906  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 44s (remain 11m 20s) Loss: 0.0036(0.0022) Grad: 1786.4052  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 13s (remain 10m 52s) Loss: 0.0000(0.0023) Grad: 48.2939  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 41s (remain 10m 23s) Loss: 0.0001(0.0023) Grad: 81.4676  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 10s (remain 9m 54s) Loss: 0.0399(0.0023) Grad: 13973.7637  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 39s (remain 9m 25s) Loss: 0.0000(0.0023) Grad: 43.7151  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 7s (remain 8m 57s) Loss: 0.0001(0.0023) Grad: 49.6448  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 36s (remain 8m 28s) Loss: 0.0015(0.0022) Grad: 806.0256  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 4s (remain 7m 59s) Loss: 0.0001(0.0023) Grad: 134.2296  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 33s (remain 7m 31s) Loss: 0.0000(0.0022) Grad: 20.9234  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 1s (remain 7m 2s) Loss: 0.0000(0.0022) Grad: 22.3341  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 30s (remain 6m 33s) Loss: 0.0054(0.0022) Grad: 2894.2563  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 59s (remain 6m 5s) Loss: 0.0011(0.0022) Grad: 1119.8345  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 11m 28s (remain 5m 36s) Loss: 0.0000(0.0021) Grad: 21.9237  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 56s (remain 5m 7s) Loss: 0.0000(0.0021) Grad: 24.4373  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 12m 25s (remain 4m 39s) Loss: 0.0001(0.0021) Grad: 83.7171  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 54s (remain 4m 10s) Loss: 0.0053(0.0021) Grad: 2245.9431  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 13m 22s (remain 3m 41s) Loss: 0.0202(0.0022) Grad: 5802.9067  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 51s (remain 3m 13s) Loss: 0.0009(0.0022) Grad: 715.8955  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 14m 19s (remain 2m 44s) Loss: 0.0009(0.0022) Grad: 612.5027  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 48s (remain 2m 15s) Loss: 0.0000(0.0022) Grad: 34.5426  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 15m 17s (remain 1m 47s) Loss: 0.0004(0.0022) Grad: 372.3836  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 45s (remain 1m 18s) Loss: 0.0318(0.0022) Grad: 10658.8564  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 16m 14s (remain 0m 49s) Loss: 0.0051(0.0022) Grad: 2445.4490  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 16m 43s (remain 0m 21s) Loss: 0.0000(0.0022) Grad: 6.1804  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 17m 4s (remain 0m 0s) Loss: 0.0001(0.0022) Grad: 87.0157  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 1s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 13s (remain 2m 30s) Loss: 0.0488(0.0079) \n","EVAL: [200/1192] Elapsed 0m 27s (remain 2m 15s) Loss: 0.0075(0.0073) \n","EVAL: [300/1192] Elapsed 0m 40s (remain 2m 1s) Loss: 0.0101(0.0079) \n","EVAL: [400/1192] Elapsed 0m 54s (remain 1m 47s) Loss: 0.0000(0.0076) \n","EVAL: [500/1192] Elapsed 1m 7s (remain 1m 33s) Loss: 0.0691(0.0073) \n","EVAL: [600/1192] Elapsed 1m 21s (remain 1m 19s) Loss: 0.0098(0.0076) \n","EVAL: [700/1192] Elapsed 1m 34s (remain 1m 6s) Loss: 0.0047(0.0083) \n","EVAL: [800/1192] Elapsed 1m 48s (remain 0m 52s) Loss: 0.0197(0.0083) \n","EVAL: [900/1192] Elapsed 2m 1s (remain 0m 39s) Loss: 0.0118(0.0085) \n","EVAL: [1000/1192] Elapsed 2m 14s (remain 0m 25s) Loss: 0.0000(0.0083) \n","EVAL: [1100/1192] Elapsed 2m 28s (remain 0m 12s) Loss: 0.0214(0.0081) \n","EVAL: [1191/1192] Elapsed 2m 40s (remain 0m 0s) Loss: 0.0000(0.0079) \n","Epoch 5 - avg_train_loss: 0.0022  avg_val_loss: 0.0079  time: 1187s\n","Epoch 5 - Score: 0.8917\n","Best thres: 0.5, Score: 0.8865\n","Best thres: 0.48671875000000003, Score: 0.8865\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b94b965c11b40668833d2d4e7a47e93"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b65f6a0e9e3b4ecc8fcd77d45648701e"}},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-30-0f6b8dbff6ab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mtest_token_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold{i_fold}_{i}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_token_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtest_char_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_char_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pn_history\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_token_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-ef7a3b9ca97f>\u001b[0m in \u001b[0;36minference_fn\u001b[0;34m(test_dataloader, model, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappings_from_token_to_char\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtk0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-23-8e89234e65ba>\", line 41, in __getitem__\n    mapping_from_token_to_char = self._create_mapping_from_token_to_char(self.pn_historys[idx])\n  File \"<ipython-input-23-8e89234e65ba>\", line 32, in _create_mapping_from_token_to_char\n    mapping_from_token_to_char = np.zeros(self.max_char_len)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 83, in __getattr__\n    raise AttributeError\nAttributeError\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","score = scoring(oof_df, th=0.5, use_token_prob=False)\n","print(f\"Best thres: 0.5, Score: {score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Twai9e8UdUP1","executionInfo":{"status":"ok","timestamp":1647906305282,"user_tz":-540,"elapsed":8287,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"e9042cbd-5e47-4fe3-f5cc-8c77d0d36dff"},"id":"Twai9e8UdUP1","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Best thres: 0.5, Score: 0.8865\n"]}]},{"cell_type":"code","source":["best_th = 0.5\n","best_score = 0.\n","for th in np.arange(0.45, 0.55, 0.01):\n","    th = np.round(th, 2)\n","    score = scoring(oof_df, th=th, use_token_prob=False)\n","    if best_score < score:\n","        best_th = th\n","        best_score = score\n","print(f\"best_th: {best_th}  score: {best_score:.5f}\")"],"metadata":{"id":"AcvIWWv5dYiN","executionInfo":{"status":"aborted","timestamp":1647875131102,"user_tz":-540,"elapsed":1886,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"AcvIWWv5dYiN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def postprocess(texts, preds):\n","    fix_tokenize_dict = {\n","        'heart': ['h', 'eart'],\n","        'hair': ['h', 'air'],\n","        'adderal': ['a', 'dderal'],\n","        'mother': ['m', 'other'],\n","        'intermittent': ['i', 'ntermittent'],\n","        'temperature': ['t', 'emperature'],\n","        'episodes': ['e', 'pisodes'],\n","        'no': ['n', 'o'],\n","        'has': ['h', 'as'],\n","        'LMP': ['L', 'MP'],\n","        '10': ['1', '0'],\n","        'blood': ['b', 'lood'],\n","        'recurrent': ['r', 'ecurrent'],\n","        'denies': ['d', 'enies'],\n","        'sudden': ['s', 'udden'],\n","        'Sexually': ['S', 'exually'],\n","        'up': ['u', 'p'],\n","        'wakes': ['w', 'akes'],\n","        'sweats': ['s', 'weats'],\n","        'hot': ['h', 'ot'],\n","        'drenched': ['d', 'renched'],\n","        'gnawing': ['g', 'nawing'],\n","        'Uses': ['U', 'ses'],\n","        'Begin': ['B', 'egin'],\n","        'Nausea': ['N', 'ausea'],\n","        'Burning': ['B', 'urning'],\n","        'Started': ['S', 'tarted'],\n","        'neurvousness': ['n', 'eurvousness'],\n","        'constipation': ['c', 'onstipation'],\n","        'nervousness': ['n', 'ervousness'],\n","        'cold': ['c', 'old'],\n","        'loss': ['l', 'oss'],\n","        'CBC': ['C', 'BC'],\n","        'Hx': ['H', 'x'],\n","        'tingling': ['t', 'ingling'],\n","        'feels': ['f', 'eels'],\n","        'Lost': ['L', 'ost'],\n","        'she': ['s', 'he'],\n","        'racing': ['r', 'acing'],\n","        'throat': ['t', 'hroat'],\n","        'PATIENT': ['P', 'ATIENT'],\n","        'recreational': ['r', 'ecreational'],\n","        'clammy': ['c', 'lammy'],\n","        'numbness': ['n', 'umbness'],\n","        'like': ['l', 'ike'],\n","        'reports': ['r', 'eports'],\n","        'exercise': ['e', 'xercise'],\n","        'started': ['s', 'tarted'],\n","        'brough': ['b', 'rough'],\n","        'Associated': ['A', 'ssociated'],\n","        'exacerbated': ['e', 'xacerbated'],\n","        'sharp': ['s', 'harp'],\n","        'cannot': ['c', 'annot'],\n","        'heavy': ['h', 'eavy'],\n","        'fatigue': ['f', 'atigue'],\n","        'trouble': ['t', 'rouble'],\n","        'hearing': ['h', 'earing'],\n","        'reduced': ['r', 'educed'],\n","        'lack': ['l', 'ack'],\n","        'vomiting': ['v', 'omiting'],\n","        'generalized': ['g', 'eneralized'],\n","        'body': ['b', 'ody'],\n","        'all': ['a', 'll'],\n","        'scratchy': ['s', 'cratchy'],\n","        'mom': ['m', 'om'],\n","        'discomfort': ['d', 'iscomfort'],\n","        'CAD': ['C', 'AD'],\n","        'Thyroid': ['T', 'hyroid'],\n","        'BLADDER': ['B', 'LADDER'],\n","        'diarrhea': ['d', 'iarrhea'],\n","        'Started': ['S', 'tarted'],\n","        'Vaginal': ['V', 'aginal'],\n","        'sleeping': ['s', 'leeping'],\n","        'UNCLE': ['U', 'NCLE'],\n","        'USING': ['U', 'SING'],\n","        'BURNING': ['B', 'URNING'],\n","        'GETTING': ['G', 'ETTING'],\n","        'ETOH': ['E', 'TOH'],\n","        'ON': ['O', 'N'],\n","        'INITIALLY': ['I', 'NITIALLY'],\n","        'epigastric': ['e', 'pigastric'],\n","        'occurs': ['o', 'ccurs'],\n","        'began': ['b', 'egan'],\n","        'alleviated': ['a', 'lleviated'],\n","        'overwhelmed': ['o', 'verwhelmed'],\n","        'clamminess': ['c', 'lamminess'],\n","        'strongly': ['s', 'trongly'],\n","        'lump': ['l', 'ump'],\n","        'drugs': ['d', 'rugs'],\n","        'chest': ['c', 'hest'],\n","        'stuffy': ['s', 'tuffy'],\n","        'changes': ['c', 'hanges'],\n","        'trouble': ['t', 'rouble'],\n","        'takes': ['t', 'akes'],\n","        'tossing': ['t', 'ossing'],\n","        'Fam': ['F', 'am'],\n","        'sweating': ['s', 'weating'],\n","        'dyspareunia': ['d', 'yspareunia'],\n","        'irregular': ['i', 'rregular'],\n","        'time': ['t', 'ime'],\n","        'unpredictable': ['u', 'npredictable'],\n","        'darkened': ['d', 'arkened'],\n","        'anxiety': ['a', 'nxiety'],\n","        'nervous': ['n', 'ervous'],\n","        'TAKING': ['T', 'AKING'],\n","        'losing': ['l', 'osing'],\n","        'Difficulyt': ['D', 'ifficulyt'],\n","        'Appetite': ['A', 'ppetite'],\n","        'increased': ['i', 'ncreased'],\n","        'fingers': ['f', 'ingers'],\n","        'illicit': ['i', 'llicit'],\n","        'claminess': ['c', 'laminess'],\n","        'clamy': ['c', 'lamy'],\n","        'Recently': ['R', 'ecently'],\n","        'feeling': ['f', 'eeling'],\n","        'aggrav': ['a', 'ggrav'],\n","        'changing': ['c', 'hanging'],\n","        'unable': ['u', 'nable'],\n","        'SEEING': ['S', 'EEING'],\n","        'staying': ['s', 'taying'],\n","        'lightheadedness': ['l', 'ightheadedness'],\n","        'lighheadeness': ['l', 'ighheadeness'],\n","        'nail': ['n', 'ail'],\n","        'pounding': ['p', 'ounding'],\n","        'My': ['M', 'y'],\n","        'Father': ['F', 'ather'],\n","        'urinary': ['u', 'rinary'],\n","        'pain': ['p', 'ain'],\n","        'not': ['n', 'ot'],\n","        'lower': ['l', 'ower'],\n","        'menses': ['m', 'enses'],\n","        'at': ['a', 't'],\n","        'takes': ['t', 'akes'],\n","        'initally': ['i', 'nitally'],\n","        'melena': ['m', 'elena'],\n","        'BOWEL': ['B', 'OWEL'],\n","        'WEIGHT': ['W', 'EIGHT'],\n","        'difficulty': ['d', 'ifficulty'],\n","        'condo': ['c', 'ondo'],\n","        'experiences': ['e', 'xperiences'],\n","        'stuffy': ['s', 'tuffy'],\n","        'rhinorrhea': ['r', 'hinorrhea'],\n","        'felt': ['f', 'elt'],\n","        'feverish': ['f', 'everish'],\n","        'CYCLE': ['C', 'YCLE'],\n","        'tampon': ['t', 'ampon'],\n","        'Last': ['L', 'ast'],\n","        'Son': ['S', 'on'],\n","        'saw': ['s', 'aw'],\n","        'tightness': ['t', 'ightness'],\n","        'rash': ['r', 'ash'],\n","        'ibuprofen': ['i', 'buprofen'],\n","        'SCRATHY': ['S', 'CRATHY'],\n","        'PHOTOPHOBIA': ['P', 'HOTOPHOBIA'],\n","    }\n","    preds_pp = preds.copy()\n","    tk0 = range(len(preds_pp))\n","    for raw_idx in tk0:\n","        pred = preds[raw_idx]\n","        text = texts[raw_idx]\n","        if len(pred) != 0:\n","            # pp1: indexが1から始まる予測値は0から始まるように修正 ## 0.88579 -> 0.88702\n","            if pred[0][0] == 1:\n","                preds_pp[raw_idx][0][0] = 0\n","            for p_index, pp in enumerate(pred):\n","                start, end = pred[p_index]\n","                # pp2: startとendが同じ予測値はstartを前に１ずらす ## 0.88702 -> 0.88714\n","                if start == end:\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp3: 始点が改行の場合始点を1つ後ろにずらす ## 0.88714 -> 0.88746\n","                if text[start] == '\\n':\n","                    preds_pp[raw_idx][p_index][0] = start + 1\n","                    start = start + 1\n","                # pp4: 1-2などは-2で予測されることがあるので修正 ## 0.88746 -> 0.88747\n","                if text[start-1].isdigit() and text[start] == '-' and text[start+1].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-1].isdigit() and text[start] == '/' and text[start+1].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp5: 67などは7で予測されることがあるので修正 ## 0.88747 -> 0.88748\n","                if text[start-1].isdigit() and text[start].isdigit():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp6: 文頭が大文字で始まるものは大文字部分が除かれて予測されることがあるので修正 ## 0.88748 -> 0.88761\n","                if text[start-2] == '.' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == ',' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == ':' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                if text[start-2] == '-' and text[start-1].isupper():\n","                    preds_pp[raw_idx][p_index][0] = start - 1\n","                    start = start - 1\n","                # pp7: heart -> h + eart となっているようなものを修正する ## 0.88761 -> 0.88806\n","                for key, fix_tokenize in fix_tokenize_dict.items():\n","                    _s, s = fix_tokenize[0], fix_tokenize[1]\n","                    if text[start-1].lower() == _s.lower() and text[start:start+len(s)].lower() == s.lower():\n","                        preds_pp[raw_idx][p_index][0] = start - 1\n","                        start = start - 1\n","    return preds_pp\n"],"metadata":{"id":"jippbx3tdDXK","executionInfo":{"status":"aborted","timestamp":1647906211425,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"jippbx3tdDXK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#score = scoring(oof_df, th=0.5, use_token_prob=False)\n","labels = create_labels_for_scoring(oof_df)\n","char_probs = oof_df[[str(i) for i in range(CFG.max_char_len)]].values\n","char_probs = [char_probs[i] for i in range(len(char_probs))]\n","\n","predicted_location_str = get_predicted_location_str(char_probs, th=0.5)\n","preds = get_predictions(predicted_location_str)\n","preds = postprocess(oof_df['pn_history'].values, preds)\n","score = get_score(labels, preds)\n","print(f\"Best thres: 0.5, Score: {score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4CZPMagdthN","executionInfo":{"status":"ok","timestamp":1647906313273,"user_tz":-540,"elapsed":7994,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"d91f631d-8e0d-4730-8c8e-fb8e96c535fb"},"id":"Q4CZPMagdthN","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Best thres: 0.5, Score: 0.8869\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"tfiRsn5FebtI","executionInfo":{"status":"aborted","timestamp":1647875131103,"user_tz":-540,"elapsed":1887,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"tfiRsn5FebtI","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"N5kZWfSSfJMf","executionInfo":{"status":"aborted","timestamp":1647875131103,"user_tz":-540,"elapsed":1558,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"N5kZWfSSfJMf","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp059.ipynb","provenance":[{"file_id":"13PUc1BK1XquiZCrLMEB3RguGfJtqCZgm","timestamp":1647850264218},{"file_id":"1wqr1Y1MTpmofNqOtVD8cCBYlPZoPt3XQ","timestamp":1647823100264}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"804a30f0d5bb454d948d2c7fcb6f47cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0012e56d3e964048941549da70cae0cf","IPY_MODEL_3ce637381f8248e48f09a5ec038215d0","IPY_MODEL_7d977e08f08746cf9143891b043fe138"],"layout":"IPY_MODEL_5428218cb94a476a8703fc08cf2a7dfd"}},"0012e56d3e964048941549da70cae0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3f7241a9f9845d1bebc5c355c207aea","placeholder":"​","style":"IPY_MODEL_fb7ac917f46a490ab74b6f443f28df9d","value":"Downloading: 100%"}},"3ce637381f8248e48f09a5ec038215d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1655f8d2d85435596e9ddfd4e74fde8","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa87d84b81ed4227abbff18501261687","value":52}},"7d977e08f08746cf9143891b043fe138":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb96632eb84452987ebcb54c7aef241","placeholder":"​","style":"IPY_MODEL_3fb4b8618c3c4d0dbd244932f1332d50","value":" 52.0/52.0 [00:00&lt;00:00, 1.67kB/s]"}},"5428218cb94a476a8703fc08cf2a7dfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3f7241a9f9845d1bebc5c355c207aea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb7ac917f46a490ab74b6f443f28df9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1655f8d2d85435596e9ddfd4e74fde8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa87d84b81ed4227abbff18501261687":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fb96632eb84452987ebcb54c7aef241":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fb4b8618c3c4d0dbd244932f1332d50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa211b09ce934b388aef5745e2be7f2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0db56c592c34e6b94fc4da2b7b50b15","IPY_MODEL_ffd6495f6df74c29b115e9ae24676245","IPY_MODEL_7b36a2c0fef8478e93a4e2eedb06292a"],"layout":"IPY_MODEL_1b53b698719544edb36bb460f8b02267"}},"e0db56c592c34e6b94fc4da2b7b50b15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d84c51121b54e0d8e8174acbddf2e60","placeholder":"​","style":"IPY_MODEL_c1fdb9ec354a48be8e12a80035e4e89d","value":"Downloading: 100%"}},"ffd6495f6df74c29b115e9ae24676245":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55c14ab0417c4e4e8258bd57a0f16b2d","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a392e281c7e54acba9c1d12d3d8a61a2","value":475}},"7b36a2c0fef8478e93a4e2eedb06292a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a156e39829d40c4991ae595138139bd","placeholder":"​","style":"IPY_MODEL_68cb2504845d4f828d69c117a7baef84","value":" 475/475 [00:00&lt;00:00, 6.39kB/s]"}},"1b53b698719544edb36bb460f8b02267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d84c51121b54e0d8e8174acbddf2e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1fdb9ec354a48be8e12a80035e4e89d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55c14ab0417c4e4e8258bd57a0f16b2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a392e281c7e54acba9c1d12d3d8a61a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a156e39829d40c4991ae595138139bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68cb2504845d4f828d69c117a7baef84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62448458033b47ad97a2ab5c102f5b20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e19c4e2d74d74150b4ad2fef87522d3b","IPY_MODEL_5427e63f31534355abf401dbd00f8b39","IPY_MODEL_99a67610d9774bdaa925a2b634be5c1e"],"layout":"IPY_MODEL_b52c0997abfe4cedb0631f3694ed4bde"}},"e19c4e2d74d74150b4ad2fef87522d3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_508b20f7c28847318cd36d1c075741ba","placeholder":"​","style":"IPY_MODEL_81c23f589edc429f825eda5c9e86c62c","value":"Downloading: 100%"}},"5427e63f31534355abf401dbd00f8b39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bdade367fad44479cdcb5b016685fb5","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dce9b50718224bc89877e1d371f46a94","value":898825}},"99a67610d9774bdaa925a2b634be5c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7d537c5842e4d2f8f40082760c08f93","placeholder":"​","style":"IPY_MODEL_74cfe922ec024630af8f866df12eaebc","value":" 878k/878k [00:00&lt;00:00, 1.35MB/s]"}},"b52c0997abfe4cedb0631f3694ed4bde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"508b20f7c28847318cd36d1c075741ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81c23f589edc429f825eda5c9e86c62c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bdade367fad44479cdcb5b016685fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce9b50718224bc89877e1d371f46a94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7d537c5842e4d2f8f40082760c08f93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74cfe922ec024630af8f866df12eaebc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50147a1d3ffe470caa49737f72ce4f92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a65a035cd77f4e31915c373a6ae8ca20","IPY_MODEL_eb6181520b5b48c691ffc2f1109ad8b5","IPY_MODEL_bf8c6aa4616e4b3886a40c3dd90f3969"],"layout":"IPY_MODEL_0c173e244e784511ac985d3a2377dc0f"}},"a65a035cd77f4e31915c373a6ae8ca20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f1d03271ec74ba8adf327c4013c4a9e","placeholder":"​","style":"IPY_MODEL_a355cc803bb442b9af511621db484f0b","value":"Downloading: 100%"}},"eb6181520b5b48c691ffc2f1109ad8b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4a60a23ed2344bf99091d318da0eca5","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6010dbad339a48b18644fe0e05ae84df","value":456318}},"bf8c6aa4616e4b3886a40c3dd90f3969":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04ea09532c504a0f90e0b7d9e22a36ed","placeholder":"​","style":"IPY_MODEL_bc1fc3212a574949b9703fa8b974903e","value":" 446k/446k [00:00&lt;00:00, 520kB/s]"}},"0c173e244e784511ac985d3a2377dc0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f1d03271ec74ba8adf327c4013c4a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a355cc803bb442b9af511621db484f0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4a60a23ed2344bf99091d318da0eca5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6010dbad339a48b18644fe0e05ae84df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04ea09532c504a0f90e0b7d9e22a36ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc1fc3212a574949b9703fa8b974903e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e526cd925bb044909394f9a2d6237694":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c11452952eb40988a2eb8f6948fd553","IPY_MODEL_b0ea0c3edca144eca0e3d937f0ee5d1e","IPY_MODEL_020f55dd776d4ca6a369f920fe0822fd"],"layout":"IPY_MODEL_7297ca4414d64d01bf9b7f053411782e"}},"7c11452952eb40988a2eb8f6948fd553":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a18bcc2112e549bb8d3b927645f1c55c","placeholder":"​","style":"IPY_MODEL_70097c2bb2f740198beded85989d0d26","value":"100%"}},"b0ea0c3edca144eca0e3d937f0ee5d1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3da4baf21a04a77a09cf79aa6600ee2","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc82593d171f4e59aaff2f7c5e50017b","value":42146}},"020f55dd776d4ca6a369f920fe0822fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08790f4221f7438ab9ad43a2b606c702","placeholder":"​","style":"IPY_MODEL_1411066860064e85a84155b9c2c8b8a5","value":" 42146/42146 [00:31&lt;00:00, 2033.39it/s]"}},"7297ca4414d64d01bf9b7f053411782e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a18bcc2112e549bb8d3b927645f1c55c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70097c2bb2f740198beded85989d0d26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3da4baf21a04a77a09cf79aa6600ee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc82593d171f4e59aaff2f7c5e50017b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08790f4221f7438ab9ad43a2b606c702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1411066860064e85a84155b9c2c8b8a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bef222d05914a94b1b914041dad3201":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d0f1385ffad41c8b9d55e71f99ff559","IPY_MODEL_a6241185131948e489813f18641f429f","IPY_MODEL_e3a1461d512740eba06f2af134540634"],"layout":"IPY_MODEL_b04e9eac49f1492cad7d84bb8f200763"}},"7d0f1385ffad41c8b9d55e71f99ff559":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3b0b0fa56c5491ab5da3a97ed8226e6","placeholder":"​","style":"IPY_MODEL_db4c1399530745c6aaf8df5f91872f69","value":"100%"}},"a6241185131948e489813f18641f429f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5622a5bd84854a178985c79ed1e97a2e","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3fdb26732186421c9d070899c9b70c46","value":143}},"e3a1461d512740eba06f2af134540634":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a5bd15420d04aa880c8c887492ba25d","placeholder":"​","style":"IPY_MODEL_caa39ad69f294796b486bbe5bf488916","value":" 143/143 [00:00&lt;00:00, 2143.19it/s]"}},"b04e9eac49f1492cad7d84bb8f200763":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b0b0fa56c5491ab5da3a97ed8226e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4c1399530745c6aaf8df5f91872f69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5622a5bd84854a178985c79ed1e97a2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fdb26732186421c9d070899c9b70c46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a5bd15420d04aa880c8c887492ba25d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa39ad69f294796b486bbe5bf488916":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"505d3ee65b114c3b8bf2d79d2cc0c3f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dffc146547934b8cb176a1474b9d774f","IPY_MODEL_2b886ed180604097a14094db7011a63e","IPY_MODEL_997c9eb7b51942edb819214651865917"],"layout":"IPY_MODEL_de7ca5a058c94a0ab7bc9b1bb25db914"}},"dffc146547934b8cb176a1474b9d774f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3c5f81e3734adba40927c40c9b3447","placeholder":"​","style":"IPY_MODEL_f073dd8fda054959ab49a7878a72a907","value":"100%"}},"2b886ed180604097a14094db7011a63e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83c5db101b1e47188907faaa4ab6f504","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_013d9bb941684591994028700e0fac4e","value":42146}},"997c9eb7b51942edb819214651865917":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f208da8c4ff04799be4feb9e6f7a2a93","placeholder":"​","style":"IPY_MODEL_59784b7614f64ea4b747547ddeaffc67","value":" 42146/42146 [00:00&lt;00:00, 470705.92it/s]"}},"de7ca5a058c94a0ab7bc9b1bb25db914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3c5f81e3734adba40927c40c9b3447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f073dd8fda054959ab49a7878a72a907":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83c5db101b1e47188907faaa4ab6f504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"013d9bb941684591994028700e0fac4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f208da8c4ff04799be4feb9e6f7a2a93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59784b7614f64ea4b747547ddeaffc67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b94b965c11b40668833d2d4e7a47e93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25ee30a9f6d645c8b9bdbfe1c93e7d21","IPY_MODEL_824cb019808f427bad53fe473dee8db9","IPY_MODEL_16cda8e3999d408da0bfbb7b23ba644b"],"layout":"IPY_MODEL_526e8e82fc5d42c498739abe20a53b4e"}},"25ee30a9f6d645c8b9bdbfe1c93e7d21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_301379784fc64a47974dffa6339baabc","placeholder":"​","style":"IPY_MODEL_ea717cd9279b42c2b921dfd247af6c21","value":"Downloading: 100%"}},"824cb019808f427bad53fe473dee8db9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_728fed76d0a24cf890080a5df949f47b","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8cb38d508014fc090976d8e44683dcc","value":1627284589}},"16cda8e3999d408da0bfbb7b23ba644b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ef7f0c16b8646a0bdb46fa097548965","placeholder":"​","style":"IPY_MODEL_79d8efaf1534495cb7329d9109262b0d","value":" 1.52G/1.52G [00:33&lt;00:00, 51.9MB/s]"}},"526e8e82fc5d42c498739abe20a53b4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"301379784fc64a47974dffa6339baabc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea717cd9279b42c2b921dfd247af6c21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"728fed76d0a24cf890080a5df949f47b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8cb38d508014fc090976d8e44683dcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ef7f0c16b8646a0bdb46fa097548965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79d8efaf1534495cb7329d9109262b0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b65f6a0e9e3b4ecc8fcd77d45648701e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_488b389bd3b043c5bba2a5246dd4caca","IPY_MODEL_8602b99dcce3497887034d8b42211730","IPY_MODEL_07aeb3c98e454465a8ec1374e9db7097"],"layout":"IPY_MODEL_8780ac842d6942cc85fda655aa49a705"}},"488b389bd3b043c5bba2a5246dd4caca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_481024fc3357443c9737cb8cddf4888c","placeholder":"​","style":"IPY_MODEL_9766001cebf447059e7fdf5eef0828c4","value":"  0%"}},"8602b99dcce3497887034d8b42211730":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b426cbf27b244f8881073a3afc64bd35","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98282bcaa60d40feab78b0c31f93727c","value":0}},"07aeb3c98e454465a8ec1374e9db7097":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60a29e7071d3421e95d438ea2129b3ad","placeholder":"​","style":"IPY_MODEL_71d369e8e5174dc6a6e0a21f8908c495","value":" 0/2 [00:01&lt;?, ?it/s]"}},"8780ac842d6942cc85fda655aa49a705":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"481024fc3357443c9737cb8cddf4888c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9766001cebf447059e7fdf5eef0828c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b426cbf27b244f8881073a3afc64bd35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98282bcaa60d40feab78b0c31f93727c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60a29e7071d3421e95d438ea2129b3ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71d369e8e5174dc6a6e0a21f8908c495":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}