{"cells":[{"cell_type":"markdown","id":"colored-security","metadata":{"id":"colored-security"},"source":["## References"]},{"cell_type":"markdown","id":"educational-operator","metadata":{"id":"educational-operator"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"incorrect-greek","metadata":{"id":"incorrect-greek"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"alive-granny","metadata":{"id":"alive-granny","executionInfo":{"status":"ok","timestamp":1648041767067,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp062\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"heavy-prophet","metadata":{"id":"heavy-prophet","executionInfo":{"status":"ok","timestamp":1648041767067,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"vocational-coating","metadata":{"id":"vocational-coating","executionInfo":{"status":"ok","timestamp":1648041767068,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"private-moderator","metadata":{"id":"private-moderator"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"married-tokyo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"married-tokyo","outputId":"20413017-cf96-414d-d05c-e160c6c531ae","executionInfo":{"status":"ok","timestamp":1648041772406,"user_tz":-540,"elapsed":5345,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.49)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"blank-pierre","metadata":{"id":"blank-pierre","executionInfo":{"status":"ok","timestamp":1648041776862,"user_tz":-540,"elapsed":4460,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"sound-still","metadata":{"id":"sound-still"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"surprised-commercial","metadata":{"id":"surprised-commercial","executionInfo":{"status":"ok","timestamp":1648041776863,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"interstate-accident","metadata":{"id":"interstate-accident","executionInfo":{"status":"ok","timestamp":1648041776863,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"coated-pioneer","metadata":{"id":"coated-pioneer","executionInfo":{"status":"ok","timestamp":1648041776865,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"nervous-delaware","metadata":{"id":"nervous-delaware","executionInfo":{"status":"ok","timestamp":1648041776865,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"functioning-destruction","metadata":{"id":"functioning-destruction"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"global-monte","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"global-monte","outputId":"e3fabcc3-b326-4ee5-ccce-354728950058","executionInfo":{"status":"ok","timestamp":1648041777330,"user_tz":-540,"elapsed":472,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"independent-airfare","metadata":{"id":"independent-airfare","executionInfo":{"status":"ok","timestamp":1648041777330,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"silent-locator","metadata":{"id":"silent-locator"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"unusual-fifty","metadata":{"id":"unusual-fifty","executionInfo":{"status":"ok","timestamp":1648041777331,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"decreased-mustang","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"decreased-mustang","outputId":"51783c47-becc-47f5-8593-77dc97d7c57a","executionInfo":{"status":"ok","timestamp":1648041777331,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"boolean-trade","metadata":{"id":"boolean-trade","executionInfo":{"status":"ok","timestamp":1648041777791,"user_tz":-540,"elapsed":464,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"accomplished-dakota","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"accomplished-dakota","outputId":"1c411e12-7d7d-4b21-bf78-d5d519d0fb68","executionInfo":{"status":"ok","timestamp":1648041777792,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"funded-elizabeth","metadata":{"id":"funded-elizabeth"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"unexpected-columbia","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"unexpected-columbia","outputId":"46894698-4418-4c1f-c5ac-626a8c3e1947","executionInfo":{"status":"ok","timestamp":1648041777792,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"critical-archive","metadata":{"id":"critical-archive"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"broken-generator","metadata":{"id":"broken-generator","executionInfo":{"status":"ok","timestamp":1648041781809,"user_tz":-540,"elapsed":4022,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","id":"compatible-lincoln","metadata":{"id":"compatible-lincoln"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":18,"id":"fluid-nancy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["938ee232963b4f8a940a9ae7b5ae6c19","0c1d2c1d32dc4b839f4cbcc6107b7b22","e6b2f50dd6a94bec84fd501df4573853","78584d62586b4dcc97c2aeaf8bb896ed","5b0f30da0d4147dcb7e5349a8eeb5831","9961154a7a7e41d7aaf78b066bfba7db","382746446ecc420b8b59c6f93afab990","243ef0ab0f344337865fe231e8992d9b","e9de60ddef1549b0a08616928619a39b","1e3edd16a5ee40a2bcfd9d2a6896d6fa","2deee6cd567a40b8a072a7af5de0ccf0"]},"id":"fluid-nancy","outputId":"2b2b6400-41a9-4f70-e402-2e9cfcda8360","executionInfo":{"status":"ok","timestamp":1648041818765,"user_tz":-540,"elapsed":36962,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"938ee232963b4f8a940a9ae7b5ae6c19"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":19,"id":"posted-humidity","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["6ff6bc209c7540718c53c7782f5366e8","1016356e8ba644f8abf726ba83a02ff7","9ecc6315278f430d97b848584e53b9fd","c8880ca56e8c4e0cb890243dcf662815","561571b6c65e46f9b156118de46721aa","a4ca92c4a4824b54aa95dda817736cd8","a4b5bc59f19e4c2a8ebe9a5f54fe8069","b6589c9349b34393a05fdf32a6d47e71","544a611b8ef2467988340118c35e5363","29192b46c6bd492199042bb162ec568c","7d38f3c6055a47258c45e09435ab7c74"]},"id":"posted-humidity","outputId":"b984da64-aa43-49d2-addc-081a83ab3d91","executionInfo":{"status":"ok","timestamp":1648041818765,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ff6bc209c7540718c53c7782f5366e8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":20,"id":"resistant-amount","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"resistant-amount","outputId":"36a9441d-715c-4683-8924-a11b9e6d68e0","executionInfo":{"status":"ok","timestamp":1648041818766,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":21,"id":"august-equity","metadata":{"id":"august-equity","executionInfo":{"status":"ok","timestamp":1648041818766,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":22,"id":"weird-interaction","metadata":{"id":"weird-interaction","executionInfo":{"status":"ok","timestamp":1648041819347,"user_tz":-540,"elapsed":586,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"upper-mobility","metadata":{"id":"upper-mobility"},"source":["## Model"]},{"cell_type":"code","execution_count":23,"id":"spanish-destruction","metadata":{"id":"spanish-destruction","executionInfo":{"status":"ok","timestamp":1648041819347,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"chronic-bullet","metadata":{"id":"chronic-bullet"},"source":["## Training"]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","\n","class FocalTverskyLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(FocalTverskyLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1, alpha=0.5, beta=0.5, gamma=1.0):\n","\n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = F.sigmoid(inputs)       \n","\n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        #True Positives, False Positives & False Negatives\n","        TP = (inputs * targets).sum()    \n","        FP = ((1-targets) * inputs).sum()\n","        FN = (targets * (1-inputs)).sum()\n","\n","        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n","        FocalTversky = (1 - Tversky)**gamma\n","                       \n","        return FocalTversky"],"metadata":{"id":"J7qgt4asI-EI","executionInfo":{"status":"ok","timestamp":1648041819348,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"J7qgt4asI-EI","execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"id":"biological-hunger","metadata":{"id":"biological-hunger","executionInfo":{"status":"ok","timestamp":1648041819348,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        not_mask = labels.view(-1, 1) != -1\n","        loss = criterion(output.view(-1, 1)[not_mask], labels.view(-1, 1)[not_mask])\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":26,"id":"satisfied-sterling","metadata":{"id":"satisfied-sterling","executionInfo":{"status":"ok","timestamp":1648041819348,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        not_mask = labels.view(-1, 1) != -1\n","        loss = criterion(output.view(-1, 1)[not_mask], labels.view(-1, 1)[not_mask])\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":27,"id":"incorporate-viking","metadata":{"id":"incorporate-viking","executionInfo":{"status":"ok","timestamp":1648041819349,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":28,"id":"dental-sunset","metadata":{"id":"dental-sunset","executionInfo":{"status":"ok","timestamp":1648041819349,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = FocalTverskyLoss()\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"brazilian-graphics","metadata":{"id":"brazilian-graphics"},"source":["## Main"]},{"cell_type":"code","execution_count":29,"id":"connected-protein","metadata":{"id":"connected-protein","executionInfo":{"status":"ok","timestamp":1648041819349,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"id":"serious-bunny","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4629262a603244db9ef8d03d4f2a0779","959ead905cbd42439ecfe660b87b6d0d","a65b63d56ff34ff8b05d12c7fa674740","6506b7740ab9428c844661b4b6cb8576","4cbd0f0154414f8c8972260fa5c0b5b3","9d76472e5e97482a9539ccbf7a2fdfe0","5461fb13f4954fd6a7b5fe60febd8667","647e72343bc840fd91654e5838be66a0","b671fde322314b6a9198de134f0e19b7","fb3e6cadf7d046eb980d484ab3ab211a","e180a8fd7405478094277a8ebd2f65a5","d6317fe9bb984c24a458c3ea9037bba6","f5bf72f58dda4d0b8f43b1e441dd9832","1f040707d6304e13b584ed04ffce98ec","947d23a6f96243b3b75ad45e5ce363e7","e694185281054c55aa5656bf67676da9","45d834a99f4a45a78a1f2fa342807efb","9f078db1d3574ebe9bc75417601c1119","28347a9064804c7e9661d8c33158e643","919f245d5c0142c88e7914fec1de7d97","4597715dcb3e4f859336ac72806b5772","26f5525964c449a593e52bad121dc705","de78ec21942f418487b281a34ab7f3fe","73772b0c8aa74ef7b68a47a4a2b08fd4","5f408da9a97a4f5581a99e4c3298495f","fc5cadacc92f4131ba56c6b95535ac22","3ae740f8381e40bf975030bc4b2b85d2","948099f4dbac47f5bc8c03f3f0fdb5dd","13212f48ceac484aadd2c214dfcdf90b","90efa2cc48464cf88e7f27a7f38822a7","8e652bbe14b44206916f1276a6c94664","185884c747d0439aac6a6a2ba24305df","618d917c35e64365ae08c92a0a8e525e","5c7e83e3722c4ae89428ca490fc753ca","6a9bc80c699b48bb81bc76a7eb9ba529","c0102ec4687242b1953420e74a2c685f","60b473a07d4741b4844db2473ca61edd","8a74dbac965a46ea826757667ad15b71","bf5fd7fc1d564a2faedc7e0ac913f551","c2d819eb10244122a922467b49590977","67e285e8b50c475db8ea0ac1b6838786","24f7c1442a4b45ee955c825698754ec6","b0e4e8754d8640119acca8b8904fcc69","f2aec39a3aea4e8aaf6b62ab07a1c3c4"]},"id":"serious-bunny","outputId":"8bc86b68-6401-42b8-ff98-f3d477c689d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 45m 49s) Loss: 0.4886(0.4886) Grad: 7137.5488  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 27s (remain 15m 59s) Loss: 0.4779(0.4816) Grad: 8477.4023  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 55s (remain 15m 23s) Loss: 0.4870(0.4818) Grad: 5870.5527  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 23s (remain 15m 7s) Loss: 0.4736(0.4814) Grad: 7998.8027  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 50s (remain 14m 35s) Loss: 0.4741(0.4794) Grad: 10044.7705  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 17s (remain 14m 6s) Loss: 0.4232(0.4715) Grad: 48.5639  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 45s (remain 13m 36s) Loss: 0.3000(0.4551) Grad: 14.4034  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 12s (remain 13m 7s) Loss: 0.1667(0.4442) Grad: 25.6036  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 39s (remain 12m 39s) Loss: 0.4000(0.4351) Grad: 1.0444  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 6s (remain 12m 10s) Loss: 0.3571(0.4292) Grad: 2.1409  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 33s (remain 11m 42s) Loss: 0.4333(0.4239) Grad: 0.2028  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 0s (remain 11m 14s) Loss: 0.2500(0.4192) Grad: 2.9750  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 27s (remain 10m 47s) Loss: 0.0000(0.4146) Grad: 8.6383  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 54s (remain 10m 19s) Loss: 0.4167(0.4117) Grad: 0.1859  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 21s (remain 9m 52s) Loss: 0.4375(0.4099) Grad: 0.0573  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.0000(0.4071) Grad: 3.9388  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 15s (remain 8m 57s) Loss: 0.3000(0.4043) Grad: 0.3700  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.4444(0.4028) Grad: 0.0141  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 9s (remain 8m 2s) Loss: 0.4524(0.4010) Grad: 0.0035  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 37s (remain 7m 35s) Loss: 0.3889(0.3993) Grad: 0.0309  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 4s (remain 7m 8s) Loss: 0.4333(0.3984) Grad: 0.0067  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 31s (remain 6m 40s) Loss: 0.4375(0.3975) Grad: 0.0022  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 9m 58s (remain 6m 13s) Loss: 0.3750(0.3965) Grad: 0.0188  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.4333(0.3959) Grad: 0.0032  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 52s (remain 5m 19s) Loss: 0.3000(0.3953) Grad: 0.0183  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 19s (remain 4m 51s) Loss: 0.3333(0.3947) Grad: 0.0085  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.3750(0.3940) Grad: 0.0057  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.4091(0.3934) Grad: 0.0061  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.3571(0.3930) Grad: 0.0117  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 7s (remain 3m 3s) Loss: 0.4630(0.3927) Grad: 0.0012  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.3750(0.3920) Grad: 0.0020  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.3333(0.3915) Grad: 0.0043  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.4600(0.3910) Grad: 0.0004  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 14m 56s (remain 1m 14s) Loss: 0.4000(0.3904) Grad: 0.0010  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 23s (remain 0m 47s) Loss: 0.4231(0.3900) Grad: 0.0011  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.3750(0.3893) Grad: 0.0029  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.4167(0.3886) Grad: 0.0007  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 11s) Loss: 0.4474(0.4474) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4091(0.3881) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4643(0.3920) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4688(0.3761) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.4333(0.3739) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4474(0.3732) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4231(0.3736) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4545(0.3739) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3754) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3769) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3000(0.3789) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4000(0.3753) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.2500(0.3724) \n","Epoch 1 - avg_train_loss: 0.3886  avg_val_loss: 0.3724  time: 1148s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 34m 30s) Loss: 0.3750(0.3750) Grad: 0.0143  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 29s (remain 16m 42s) Loss: 0.4474(0.3897) Grad: 0.0021  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 56s (remain 15m 51s) Loss: 0.4000(0.3796) Grad: 0.0051  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 23s (remain 15m 10s) Loss: 0.3889(0.3732) Grad: 0.0000  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 50s (remain 14m 37s) Loss: 0.3000(0.3758) Grad: 0.0113  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 17s (remain 14m 5s) Loss: 0.4630(0.3785) Grad: 0.0054  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 44s (remain 13m 36s) Loss: 0.4444(0.3799) Grad: 0.0023  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 11s (remain 13m 7s) Loss: 0.4333(0.3790) Grad: 0.0012  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 39s (remain 12m 38s) Loss: 0.4630(0.3778) Grad: 0.0051  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 6s (remain 12m 11s) Loss: 0.4524(0.3767) Grad: 0.0012  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 33s (remain 11m 43s) Loss: 0.3000(0.3757) Grad: 0.0000  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 0s (remain 11m 15s) Loss: 0.4474(0.3761) Grad: 0.0014  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 27s (remain 10m 47s) Loss: 0.4167(0.3756) Grad: 0.0060  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 54s (remain 10m 19s) Loss: 0.4091(0.3756) Grad: 0.0032  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 21s (remain 9m 52s) Loss: 0.4000(0.3751) Grad: 0.0027  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.4524(0.3751) Grad: 0.0065  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 15s (remain 8m 57s) Loss: 0.3889(0.3748) Grad: 0.0049  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.4412(0.3750) Grad: 0.0026  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 9s (remain 8m 2s) Loss: 0.3000(0.3752) Grad: 0.0206  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 36s (remain 7m 35s) Loss: 0.3889(0.3746) Grad: 0.0063  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 4s (remain 7m 7s) Loss: 0.4474(0.3747) Grad: 0.0074  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 31s (remain 6m 40s) Loss: 0.3571(0.3746) Grad: 0.0032  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 9m 58s (remain 6m 13s) Loss: 0.4231(0.3755) Grad: 0.0023  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.3750(0.3751) Grad: 0.0136  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 52s (remain 5m 19s) Loss: 0.4333(0.3745) Grad: 0.0012  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 19s (remain 4m 51s) Loss: 0.3889(0.3745) Grad: 0.0064  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.3750(0.3747) Grad: 0.0043  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.4167(0.3740) Grad: 0.0019  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.4231(0.3740) Grad: 0.0038  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 7s (remain 3m 3s) Loss: 0.4167(0.3741) Grad: 0.0054  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 35s (remain 2m 35s) Loss: 0.4333(0.3742) Grad: 0.0007  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 2s (remain 2m 8s) Loss: 0.3750(0.3746) Grad: 0.0043  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 29s (remain 1m 41s) Loss: 0.4167(0.3748) Grad: 0.0011  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 14m 56s (remain 1m 14s) Loss: 0.4286(0.3749) Grad: 0.0000  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 23s (remain 0m 47s) Loss: 0.3889(0.3750) Grad: 0.0019  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.4333(0.3751) Grad: 0.0017  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.4474(0.3753) Grad: 0.0011  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 45s) Loss: 0.4474(0.4474) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.4091(0.3881) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4643(0.3920) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4688(0.3761) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.4333(0.3739) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4474(0.3732) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.4231(0.3736) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4545(0.3739) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3754) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3769) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3000(0.3789) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4000(0.3753) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.2500(0.3724) \n","Epoch 2 - avg_train_loss: 0.3753  avg_val_loss: 0.3724  time: 1147s\n","Epoch 2 - Score: 0.0000\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 31m 30s) Loss: 0.4286(0.4286) Grad: 0.0029  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 27s (remain 15m 49s) Loss: 0.2500(0.3775) Grad: 0.0323  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 54s (remain 15m 18s) Loss: 0.4000(0.3693) Grad: 0.0015  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 21s (remain 14m 49s) Loss: 0.3333(0.3678) Grad: 0.0000  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 48s (remain 14m 21s) Loss: 0.4545(0.3677) Grad: 0.0008  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 15s (remain 13m 53s) Loss: 0.4000(0.3728) Grad: 0.0000  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 42s (remain 13m 26s) Loss: 0.3571(0.3708) Grad: 0.0032  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 10s (remain 12m 59s) Loss: 0.4167(0.3751) Grad: 0.0000  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 37s (remain 12m 31s) Loss: 0.3333(0.3746) Grad: 0.0044  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 4s (remain 12m 4s) Loss: 0.4091(0.3758) Grad: 0.0043  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 31s (remain 11m 37s) Loss: 0.3571(0.3767) Grad: 0.0253  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 58s (remain 11m 10s) Loss: 0.4412(0.3764) Grad: 0.0000  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 25s (remain 10m 43s) Loss: 0.4231(0.3770) Grad: 0.0037  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 52s (remain 10m 16s) Loss: 0.3750(0.3770) Grad: 0.0099  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 19s (remain 9m 49s) Loss: 0.4231(0.3777) Grad: 0.0009  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 46s (remain 9m 22s) Loss: 0.3000(0.3768) Grad: 0.0109  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 13s (remain 8m 55s) Loss: 0.3750(0.3764) Grad: 0.0043  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 40s (remain 8m 27s) Loss: 0.4524(0.3761) Grad: 0.0006  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 8s (remain 8m 0s) Loss: 0.4500(0.3768) Grad: 0.0004  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 35s (remain 7m 33s) Loss: 0.4375(0.3760) Grad: 0.0006  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 2s (remain 7m 6s) Loss: 0.4722(0.3766) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 29s (remain 6m 39s) Loss: 0.4231(0.3769) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 9m 56s (remain 6m 12s) Loss: 0.3000(0.3768) Grad: 0.0109  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 23s (remain 5m 45s) Loss: 0.4615(0.3769) Grad: 0.0002  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 50s (remain 5m 18s) Loss: 0.4231(0.3766) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 17s (remain 4m 50s) Loss: 0.3333(0.3762) Grad: 0.0044  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 44s (remain 4m 23s) Loss: 0.3333(0.3764) Grad: 0.0076  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 11s (remain 3m 56s) Loss: 0.4565(0.3759) Grad: 0.0003  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 38s (remain 3m 29s) Loss: 0.4091(0.3756) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 5s (remain 3m 2s) Loss: 0.4000(0.3756) Grad: 0.0015  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 32s (remain 2m 35s) Loss: 0.4412(0.3756) Grad: 0.0076  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 13m 59s (remain 2m 8s) Loss: 0.4231(0.3758) Grad: 0.0023  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 26s (remain 1m 41s) Loss: 0.3571(0.3755) Grad: 0.0060  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 14m 54s (remain 1m 14s) Loss: 0.0000(0.3754) Grad: 0.0710  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 21s (remain 0m 47s) Loss: 0.4091(0.3754) Grad: 0.0023  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 48s (remain 0m 20s) Loss: 0.3000(0.3753) Grad: 0.0000  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 8s (remain 0m 0s) Loss: 0.4643(0.3752) Grad: 0.0000  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 55s) Loss: 0.4474(0.4474) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.4091(0.3881) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4643(0.3920) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4688(0.3761) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.4333(0.3739) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4474(0.3732) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.4231(0.3736) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4545(0.3739) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3754) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3769) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3000(0.3789) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4000(0.3753) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.2500(0.3724) \n","Epoch 3 - avg_train_loss: 0.3752  avg_val_loss: 0.3724  time: 1144s\n","Epoch 3 - Score: 0.0000\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 32m 13s) Loss: 0.4583(0.4583) Grad: 0.0003  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 27s (remain 15m 50s) Loss: 0.4688(0.3792) Grad: 0.0002  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 54s (remain 15m 18s) Loss: 0.3571(0.3868) Grad: 0.0032  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 21s (remain 14m 49s) Loss: 0.3889(0.3848) Grad: 0.0063  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.4000(0.3831) Grad: 0.0028  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 16s (remain 13m 55s) Loss: 0.3750(0.3800) Grad: 0.0025  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 43s (remain 13m 27s) Loss: 0.4000(0.3795) Grad: 0.0065  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 10s (remain 12m 59s) Loss: 0.4474(0.3778) Grad: 0.0004  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 37s (remain 12m 32s) Loss: 0.3333(0.3778) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 4s (remain 12m 5s) Loss: 0.4333(0.3780) Grad: 0.0094  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 31s (remain 11m 37s) Loss: 0.4167(0.3784) Grad: 0.0011  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 58s (remain 11m 10s) Loss: 0.3750(0.3777) Grad: 0.0024  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 25s (remain 10m 43s) Loss: 0.4444(0.3774) Grad: 0.0005  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.4500(0.3778) Grad: 0.0004  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.3889(0.3786) Grad: 0.0019  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.4286(0.3787) Grad: 0.0008  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 14s (remain 8m 56s) Loss: 0.4167(0.3797) Grad: 0.0011  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.0000(0.3796) Grad: 0.0606  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 9s (remain 8m 2s) Loss: 0.4231(0.3789) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.3333(0.3790) Grad: 0.0042  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.4333(0.3786) Grad: 0.0012  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.4375(0.3787) Grad: 0.0011  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 9m 57s (remain 6m 13s) Loss: 0.4167(0.3783) Grad: 0.0011  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.4091(0.3781) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 52s (remain 5m 18s) Loss: 0.3571(0.3782) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 19s (remain 4m 51s) Loss: 0.4231(0.3778) Grad: 0.0016  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.3000(0.3779) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.4600(0.3779) Grad: 0.0006  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.3333(0.3777) Grad: 0.0077  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.4091(0.3777) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.4000(0.3777) Grad: 0.0016  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.4000(0.3776) Grad: 0.0016  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.3571(0.3775) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.3571(0.3773) Grad: 0.0057  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.4231(0.3771) Grad: 0.0009  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 49s (remain 0m 20s) Loss: 0.4444(0.3774) Grad: 0.0008  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 9s (remain 0m 0s) Loss: 0.4286(0.3773) Grad: 0.0014  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 41s) Loss: 0.4474(0.4474) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4091(0.3881) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4643(0.3920) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4688(0.3761) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4333(0.3739) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4474(0.3732) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4231(0.3736) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4545(0.3739) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3754) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3769) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3000(0.3789) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4000(0.3753) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.2500(0.3724) \n","Epoch 4 - avg_train_loss: 0.3773  avg_val_loss: 0.3724  time: 1145s\n","Epoch 4 - Score: 0.0000\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 31m 12s) Loss: 0.3333(0.3333) Grad: 0.0053  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 27s (remain 15m 47s) Loss: 0.4286(0.3784) Grad: 0.0008  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 54s (remain 15m 16s) Loss: 0.1667(0.3768) Grad: 0.0306  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 21s (remain 14m 47s) Loss: 0.3571(0.3709) Grad: 0.0031  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 48s (remain 14m 19s) Loss: 0.1667(0.3715) Grad: 0.0176  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 15s (remain 13m 51s) Loss: 0.4412(0.3737) Grad: 0.0005  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 42s (remain 13m 24s) Loss: 0.4412(0.3730) Grad: 0.0000  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 9s (remain 12m 57s) Loss: 0.1667(0.3689) Grad: 0.0576  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 36s (remain 12m 30s) Loss: 0.4091(0.3720) Grad: 0.0013  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 3s (remain 12m 3s) Loss: 0.4231(0.3741) Grad: 0.0009  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 30s (remain 11m 36s) Loss: 0.4706(0.3753) Grad: 0.0044  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 57s (remain 11m 9s) Loss: 0.4737(0.3759) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 24s (remain 10m 42s) Loss: 0.0000(0.3750) Grad: 0.0728  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 51s (remain 10m 14s) Loss: 0.4286(0.3748) Grad: 0.0014  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 18s (remain 9m 47s) Loss: 0.4167(0.3739) Grad: 0.0011  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 45s (remain 9m 20s) Loss: 0.4286(0.3736) Grad: 0.0008  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 12s (remain 8m 53s) Loss: 0.3571(0.3742) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 39s (remain 8m 26s) Loss: 0.4091(0.3742) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 6s (remain 7m 59s) Loss: 0.3889(0.3743) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 33s (remain 7m 32s) Loss: 0.3571(0.3741) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 0s (remain 7m 5s) Loss: 0.4000(0.3739) Grad: 0.0067  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 27s (remain 6m 38s) Loss: 0.4286(0.3740) Grad: 0.0008  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 9m 54s (remain 6m 11s) Loss: 0.4375(0.3737) Grad: 0.0093  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 22s (remain 5m 44s) Loss: 0.3889(0.3733) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 49s (remain 5m 17s) Loss: 0.4000(0.3736) Grad: 0.0028  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 16s (remain 4m 50s) Loss: 0.4000(0.3729) Grad: 0.0016  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 43s (remain 4m 23s) Loss: 0.4231(0.3737) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 10s (remain 3m 56s) Loss: 0.4474(0.3737) Grad: 0.0004  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 37s (remain 3m 29s) Loss: 0.4333(0.3739) Grad: 0.0007  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 4s (remain 3m 2s) Loss: 0.4091(0.3735) Grad: 0.0033  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 31s (remain 2m 35s) Loss: 0.3000(0.3734) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 13m 58s (remain 2m 8s) Loss: 0.4565(0.3738) Grad: 0.0007  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 25s (remain 1m 41s) Loss: 0.3571(0.3740) Grad: 0.0000  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 14m 52s (remain 1m 14s) Loss: 0.4000(0.3738) Grad: 0.0000  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 19s (remain 0m 47s) Loss: 0.4231(0.3738) Grad: 0.0023  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 46s (remain 0m 20s) Loss: 0.4333(0.3736) Grad: 0.0000  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 6s (remain 0m 0s) Loss: 0.2500(0.3740) Grad: 0.0098  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 23s) Loss: 0.4474(0.4474) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.4091(0.3881) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4643(0.3920) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4688(0.3761) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.4333(0.3739) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4474(0.3732) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.4231(0.3736) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4545(0.3739) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3754) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3769) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3000(0.3789) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4000(0.3753) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.2500(0.3724) \n","Epoch 5 - avg_train_loss: 0.3740  avg_val_loss: 0.3724  time: 1143s\n","Epoch 5 - Score: 0.0000\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 37m 47s) Loss: 0.4669(0.4669) Grad: 9133.1953  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 27s (remain 15m 56s) Loss: 0.4870(0.4844) Grad: 5498.7505  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 54s (remain 15m 21s) Loss: 0.4636(0.4832) Grad: 10398.6768  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 21s (remain 14m 51s) Loss: 0.4858(0.4827) Grad: 6806.0234  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.4894(0.4820) Grad: 6585.9546  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 16s (remain 13m 55s) Loss: 0.4614(0.4805) Grad: 28788.0137  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 43s (remain 13m 27s) Loss: 0.4333(0.4702) Grad: 94.7141  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 10s (remain 12m 59s) Loss: 0.3572(0.4587) Grad: 10.4603  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 37s (remain 12m 32s) Loss: 0.4655(0.4471) Grad: 0.1543  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 4s (remain 12m 5s) Loss: 0.4714(0.4388) Grad: 0.1151  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 31s (remain 11m 37s) Loss: 0.3750(0.4318) Grad: 1.7002  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 58s (remain 11m 10s) Loss: 0.4091(0.4277) Grad: 0.7234  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 25s (remain 10m 43s) Loss: 0.3333(0.4229) Grad: 2.2113  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 52s (remain 10m 16s) Loss: 0.3571(0.4180) Grad: 1.0252  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 19s (remain 9m 49s) Loss: 0.3333(0.4157) Grad: 1.2156  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 46s (remain 9m 21s) Loss: 0.3333(0.4121) Grad: 0.9360  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 13s (remain 8m 54s) Loss: 0.4000(0.4096) Grad: 0.5962  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 40s (remain 8m 27s) Loss: 0.4091(0.4088) Grad: 0.1328  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 7s (remain 8m 0s) Loss: 0.3333(0.4063) Grad: 0.2430  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 34s (remain 7m 33s) Loss: 0.4167(0.4050) Grad: 0.0325  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 1s (remain 7m 6s) Loss: 0.3571(0.4036) Grad: 0.0668  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 28s (remain 6m 39s) Loss: 0.3750(0.4018) Grad: 0.0441  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 9m 55s (remain 6m 11s) Loss: 0.3750(0.4009) Grad: 0.0180  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 22s (remain 5m 44s) Loss: 0.3750(0.3994) Grad: 0.0207  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 49s (remain 5m 17s) Loss: 0.4333(0.3979) Grad: 0.0032  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 17s (remain 4m 50s) Loss: 0.4286(0.3969) Grad: 0.0034  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 44s (remain 4m 23s) Loss: 0.0000(0.3958) Grad: 0.1839  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 11s (remain 3m 56s) Loss: 0.4375(0.3947) Grad: 0.0024  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 38s (remain 3m 29s) Loss: 0.3333(0.3938) Grad: 0.0121  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 5s (remain 3m 2s) Loss: 0.4565(0.3936) Grad: 0.0024  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 32s (remain 2m 35s) Loss: 0.3571(0.3933) Grad: 0.0198  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 13m 59s (remain 2m 8s) Loss: 0.2500(0.3925) Grad: 0.0159  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 26s (remain 1m 41s) Loss: 0.4286(0.3922) Grad: 0.0010  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 14m 53s (remain 1m 14s) Loss: 0.4167(0.3915) Grad: 0.0042  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 20s (remain 0m 47s) Loss: 0.4412(0.3912) Grad: 0.0019  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 47s (remain 0m 20s) Loss: 0.0000(0.3908) Grad: 1.3358  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 7s (remain 0m 0s) Loss: 0.3571(0.3910) Grad: 0.0329  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 0s) Loss: 0.4167(0.4167) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4091(0.3875) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4167(0.3874) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4545(0.3822) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3805) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3750(0.3803) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.4667(0.3834) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0000(0.3828) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3834) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4286(0.3842) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3571(0.3839) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.2500(0.3805) \n","EVAL: [1191/1192] Elapsed 2m 50s (remain 0m 0s) Loss: 0.0000(0.3737) \n","Epoch 1 - avg_train_loss: 0.3910  avg_val_loss: 0.3737  time: 1144s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 35m 36s) Loss: 0.4524(0.4524) Grad: 0.0330  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 28s (remain 16m 31s) Loss: 0.4000(0.3967) Grad: 0.0110  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 56s (remain 15m 47s) Loss: 0.4231(0.3868) Grad: 0.0037  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 23s (remain 15m 11s) Loss: 0.3750(0.3814) Grad: 0.0080  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 50s (remain 14m 37s) Loss: 0.3000(0.3811) Grad: 0.0203  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 17s (remain 14m 6s) Loss: 0.1667(0.3802) Grad: 0.0194  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 44s (remain 13m 36s) Loss: 0.3889(0.3805) Grad: 0.0121  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 11s (remain 13m 7s) Loss: 0.3000(0.3782) Grad: 0.0252  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 38s (remain 12m 38s) Loss: 0.4444(0.3758) Grad: 0.0026  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 6s (remain 12m 10s) Loss: 0.3333(0.3762) Grad: 0.0608  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 33s (remain 11m 42s) Loss: 0.4231(0.3764) Grad: 0.0017  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 0s (remain 11m 14s) Loss: 0.2500(0.3763) Grad: 0.0098  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 27s (remain 10m 46s) Loss: 0.1667(0.3757) Grad: 0.0179  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 54s (remain 10m 19s) Loss: 0.3000(0.3758) Grad: 0.0251  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 21s (remain 9m 51s) Loss: 0.3571(0.3748) Grad: 0.0057  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.3571(0.3757) Grad: 0.0641  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 15s (remain 8m 57s) Loss: 0.3889(0.3757) Grad: 0.0049  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.4231(0.3756) Grad: 0.0017  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 9s (remain 8m 2s) Loss: 0.1667(0.3755) Grad: 0.0450  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 36s (remain 7m 35s) Loss: 0.4545(0.3753) Grad: 0.0006  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.4615(0.3753) Grad: 0.0055  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 31s (remain 6m 40s) Loss: 0.2500(0.3747) Grad: 0.0174  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 9m 58s (remain 6m 13s) Loss: 0.4286(0.3744) Grad: 0.0031  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.2500(0.3742) Grad: 0.0170  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 52s (remain 5m 18s) Loss: 0.4444(0.3744) Grad: 0.0009  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 19s (remain 4m 51s) Loss: 0.4167(0.3741) Grad: 0.0000  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.4333(0.3744) Grad: 0.0017  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.4231(0.3743) Grad: 0.0009  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.4000(0.3741) Grad: 0.0052  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.4000(0.3739) Grad: 0.0086  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.4000(0.3735) Grad: 0.0016  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.4500(0.3738) Grad: 0.0004  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.3333(0.3738) Grad: 0.0075  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.4000(0.3737) Grad: 0.0028  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.4333(0.3738) Grad: 0.0028  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 49s (remain 0m 20s) Loss: 0.4444(0.3736) Grad: 0.0000  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 9s (remain 0m 0s) Loss: 0.2500(0.3737) Grad: 0.0171  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 49s) Loss: 0.4167(0.4167) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4091(0.3875) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4167(0.3874) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4545(0.3822) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3805) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3750(0.3803) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4667(0.3834) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0000(0.3828) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3834) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4286(0.3842) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.3571(0.3839) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.2500(0.3805) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.3737) \n","Epoch 2 - avg_train_loss: 0.3737  avg_val_loss: 0.3737  time: 1147s\n","Epoch 2 - Score: 0.0000\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 32m 44s) Loss: 0.0000(0.0000) Grad: 0.0518  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 27s (remain 15m 52s) Loss: 0.3889(0.3744) Grad: 0.0019  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 54s (remain 15m 19s) Loss: 0.3571(0.3770) Grad: 0.0056  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 21s (remain 14m 51s) Loss: 0.2500(0.3846) Grad: 0.0244  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.4333(0.3871) Grad: 0.0012  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 16s (remain 13m 55s) Loss: 0.3571(0.3865) Grad: 0.0385  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.3750(0.3858) Grad: 0.0044  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 10s (remain 13m 0s) Loss: 0.4333(0.3854) Grad: 0.0012  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 37s (remain 12m 34s) Loss: 0.3750(0.3834) Grad: 0.0043  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.4091(0.3840) Grad: 0.0013  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 32s (remain 11m 39s) Loss: 0.3571(0.3823) Grad: 0.0056  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 59s (remain 11m 12s) Loss: 0.4412(0.3820) Grad: 0.0009  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 26s (remain 10m 44s) Loss: 0.4500(0.3823) Grad: 0.0004  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.3333(0.3812) Grad: 0.0075  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.4167(0.3821) Grad: 0.0011  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.4375(0.3822) Grad: 0.0011  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 14s (remain 8m 56s) Loss: 0.4333(0.3805) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.3000(0.3803) Grad: 0.0110  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 8s (remain 8m 1s) Loss: 0.4412(0.3797) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.3571(0.3803) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.3571(0.3802) Grad: 0.0080  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.4167(0.3791) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 9m 57s (remain 6m 13s) Loss: 0.4333(0.3797) Grad: 0.0023  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.4231(0.3792) Grad: 0.0016  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.4500(0.3789) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.4091(0.3787) Grad: 0.0023  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 45s (remain 4m 24s) Loss: 0.4524(0.3781) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.1667(0.3780) Grad: 0.0307  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.4000(0.3778) Grad: 0.0027  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.4500(0.3778) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.4000(0.3774) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.4286(0.3768) Grad: 0.0020  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.4524(0.3772) Grad: 0.0000  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.3333(0.3770) Grad: 0.0077  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.3000(0.3770) Grad: 0.0061  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 49s (remain 0m 20s) Loss: 0.3889(0.3772) Grad: 0.0019  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.3889(0.3774) Grad: 0.0000  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 12s) Loss: 0.4167(0.4167) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4091(0.3875) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4167(0.3874) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.4545(0.3822) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3805) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3750(0.3803) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4667(0.3834) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 10s) Loss: 0.0000(0.3828) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3834) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4286(0.3842) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.3571(0.3839) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.2500(0.3805) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.3737) \n","Epoch 3 - avg_train_loss: 0.3774  avg_val_loss: 0.3737  time: 1147s\n","Epoch 3 - Score: 0.0000\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 34m 29s) Loss: 0.4444(0.4444) Grad: 0.0000  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 27s (remain 15m 54s) Loss: 0.3333(0.3802) Grad: 0.0075  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 54s (remain 15m 21s) Loss: 0.3571(0.3812) Grad: 0.0032  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 21s (remain 14m 51s) Loss: 0.4412(0.3817) Grad: 0.0009  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.3333(0.3825) Grad: 0.0108  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 16s (remain 13m 55s) Loss: 0.3333(0.3808) Grad: 0.0108  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.0000(0.3778) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 10s (remain 13m 0s) Loss: 0.3333(0.3787) Grad: 0.0044  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 37s (remain 12m 33s) Loss: 0.3571(0.3755) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.3571(0.3756) Grad: 0.0032  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 31s (remain 11m 38s) Loss: 0.3889(0.3759) Grad: 0.0019  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 58s (remain 11m 11s) Loss: 0.4000(0.3770) Grad: 0.0039  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 25s (remain 10m 44s) Loss: 0.3750(0.3767) Grad: 0.0062  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.3889(0.3777) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.3571(0.3779) Grad: 0.0056  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.4167(0.3784) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 14s (remain 8m 55s) Loss: 0.4500(0.3784) Grad: 0.0004  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.4565(0.3779) Grad: 0.0007  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 8s (remain 8m 1s) Loss: 0.2500(0.3774) Grad: 0.0096  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.0000(0.3769) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.4474(0.3770) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.4000(0.3762) Grad: 0.0039  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 9m 57s (remain 6m 12s) Loss: 0.4286(0.3764) Grad: 0.0008  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.4286(0.3760) Grad: 0.0014  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.3750(0.3758) Grad: 0.0061  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.3750(0.3750) Grad: 0.0043  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 45s (remain 4m 24s) Loss: 0.3889(0.3751) Grad: 0.0019  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.4167(0.3749) Grad: 0.0027  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.4000(0.3752) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.2500(0.3756) Grad: 0.0315  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.4231(0.3759) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.4286(0.3760) Grad: 0.0020  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.4600(0.3755) Grad: 0.0002  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.4655(0.3760) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.4412(0.3761) Grad: 0.0005  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.4722(0.3764) Grad: 0.0001  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.3889(0.3764) Grad: 0.0065  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 4s) Loss: 0.4167(0.4167) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4091(0.3875) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4167(0.3874) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4545(0.3822) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3805) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3750(0.3803) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4667(0.3834) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0000(0.3828) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3834) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4286(0.3842) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.3571(0.3839) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.2500(0.3805) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.3737) \n","Epoch 4 - avg_train_loss: 0.3764  avg_val_loss: 0.3737  time: 1159s\n","Epoch 4 - Score: 0.0000\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 32m 7s) Loss: 0.3889(0.3889) Grad: 0.0079  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 27s (remain 15m 51s) Loss: 0.4231(0.3639) Grad: 0.0000  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 54s (remain 15m 19s) Loss: 0.3333(0.3641) Grad: 0.0076  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 21s (remain 14m 50s) Loss: 0.3889(0.3646) Grad: 0.0077  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 49s (remain 14m 24s) Loss: 0.3889(0.3705) Grad: 0.0035  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 16s (remain 13m 56s) Loss: 0.3333(0.3720) Grad: 0.0076  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.2500(0.3727) Grad: 0.0097  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 10s (remain 13m 1s) Loss: 0.3750(0.3726) Grad: 0.0000  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 37s (remain 12m 33s) Loss: 0.4412(0.3708) Grad: 0.0005  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.4615(0.3719) Grad: 0.0004  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 31s (remain 11m 39s) Loss: 0.4545(0.3727) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 59s (remain 11m 11s) Loss: 0.4000(0.3727) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 26s (remain 10m 44s) Loss: 0.0000(0.3734) Grad: 0.0395  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.0000(0.3730) Grad: 0.1356  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.4231(0.3736) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.3750(0.3741) Grad: 0.0024  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 14s (remain 8m 55s) Loss: 0.4167(0.3742) Grad: 0.0011  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.3000(0.3747) Grad: 0.0157  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 8s (remain 8m 1s) Loss: 0.4286(0.3744) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.3571(0.3755) Grad: 0.0056  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.4000(0.3754) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.4643(0.3753) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 9m 57s (remain 6m 12s) Loss: 0.3889(0.3758) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.4231(0.3768) Grad: 0.0016  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.4091(0.3766) Grad: 0.0022  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.4091(0.3763) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 45s (remain 4m 24s) Loss: 0.4412(0.3759) Grad: 0.0005  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 12s (remain 3m 57s) Loss: 0.3889(0.3760) Grad: 0.0019  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.3333(0.3759) Grad: 0.0223  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.3571(0.3761) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.3571(0.3761) Grad: 0.0078  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.4000(0.3758) Grad: 0.0039  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.4286(0.3754) Grad: 0.0031  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.3571(0.3753) Grad: 0.0031  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.4565(0.3754) Grad: 0.0000  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 49s (remain 0m 20s) Loss: 0.3000(0.3757) Grad: 0.0250  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 9s (remain 0m 0s) Loss: 0.3000(0.3754) Grad: 0.0110  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 0s) Loss: 0.4167(0.4167) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4091(0.3875) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4167(0.3874) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4545(0.3822) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3805) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3750(0.3803) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4667(0.3834) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.0000(0.3828) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4412(0.3834) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4286(0.3842) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3571(0.3839) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.2500(0.3805) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0000(0.3737) \n","Epoch 5 - avg_train_loss: 0.3754  avg_val_loss: 0.3737  time: 1158s\n","Epoch 5 - Score: 0.0000\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 35m 18s) Loss: 0.4947(0.4947) Grad: 2419.1206  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 27s (remain 15m 58s) Loss: 0.4915(0.4824) Grad: 3778.2021  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 55s (remain 15m 24s) Loss: 0.4708(0.4819) Grad: 10869.9629  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 22s (remain 14m 54s) Loss: 0.4802(0.4810) Grad: 4478.8931  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 49s (remain 14m 26s) Loss: 0.4647(0.4801) Grad: 8591.6836  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 16s (remain 13m 58s) Loss: 0.4334(0.4721) Grad: 651.9650  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 43s (remain 13m 31s) Loss: 0.3572(0.4553) Grad: 14.5033  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 11s (remain 13m 3s) Loss: 0.1667(0.4443) Grad: 43.1480  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 38s (remain 12m 36s) Loss: 0.4167(0.4376) Grad: 1.8979  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 5s (remain 12m 8s) Loss: 0.3889(0.4303) Grad: 9.7995  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 32s (remain 11m 41s) Loss: 0.3889(0.4254) Grad: 1.4827  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 59s (remain 11m 13s) Loss: 0.4167(0.4204) Grad: 0.5269  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 26s (remain 10m 46s) Loss: 0.3333(0.4153) Grad: 2.3317  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 54s (remain 10m 19s) Loss: 0.3889(0.4117) Grad: 0.6499  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 21s (remain 9m 51s) Loss: 0.4091(0.4104) Grad: 0.4652  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.3889(0.4081) Grad: 0.4426  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 15s (remain 8m 57s) Loss: 0.4333(0.4068) Grad: 0.0575  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 42s (remain 8m 30s) Loss: 0.3571(0.4042) Grad: 0.3049  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 10s (remain 8m 2s) Loss: 0.4643(0.4019) Grad: 0.0046  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 37s (remain 7m 35s) Loss: 0.3333(0.4011) Grad: 0.1714  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 4s (remain 7m 8s) Loss: 0.3750(0.4002) Grad: 0.0458  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 31s (remain 6m 41s) Loss: 0.4167(0.3987) Grad: 0.0242  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 9m 58s (remain 6m 13s) Loss: 0.4000(0.3982) Grad: 0.0360  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.1667(0.3971) Grad: 0.0954  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 53s (remain 5m 19s) Loss: 0.4091(0.3962) Grad: 0.0099  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 20s (remain 4m 52s) Loss: 0.4286(0.3953) Grad: 0.0028  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 47s (remain 4m 24s) Loss: 0.3889(0.3944) Grad: 0.0164  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 14s (remain 3m 57s) Loss: 0.4474(0.3937) Grad: 0.0019  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 41s (remain 3m 30s) Loss: 0.4231(0.3928) Grad: 0.0029  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 9s (remain 3m 3s) Loss: 0.4286(0.3921) Grad: 0.0898  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 36s (remain 2m 36s) Loss: 0.4167(0.3915) Grad: 0.0018  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.4524(0.3909) Grad: 0.0008  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 30s (remain 1m 41s) Loss: 0.2500(0.3901) Grad: 0.0084  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 14m 57s (remain 1m 14s) Loss: 0.4167(0.3895) Grad: 0.0009  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 24s (remain 0m 47s) Loss: 0.3571(0.3890) Grad: 0.0087  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 51s (remain 0m 20s) Loss: 0.4655(0.3885) Grad: 0.0001  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 12s (remain 0m 0s) Loss: 0.4000(0.3884) Grad: 0.0061  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 31s) Loss: 0.3571(0.3571) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.3571(0.3894) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 24s) Loss: 0.4231(0.3860) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.4444(0.3694) \n","EVAL: [400/1192] Elapsed 0m 58s (remain 1m 54s) Loss: 0.4444(0.3716) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3333(0.3754) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4091(0.3766) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 10s) Loss: 0.3000(0.3772) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.3780) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4375(0.3791) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.4167(0.3801) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4286(0.3777) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3724) \n","Epoch 1 - avg_train_loss: 0.3884  avg_val_loss: 0.3724  time: 1168s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 36m 40s) Loss: 0.3571(0.3571) Grad: 0.0161  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 28s (remain 16m 27s) Loss: 0.3571(0.3763) Grad: 0.0032  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 56s (remain 15m 50s) Loss: 0.3333(0.3767) Grad: 0.0075  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 23s (remain 15m 10s) Loss: 0.4500(0.3737) Grad: 0.0013  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 51s (remain 14m 39s) Loss: 0.3333(0.3740) Grad: 0.0207  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 18s (remain 14m 7s) Loss: 0.3889(0.3736) Grad: 0.0094  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 45s (remain 13m 38s) Loss: 0.1667(0.3728) Grad: 0.2170  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 12s (remain 13m 8s) Loss: 0.4091(0.3733) Grad: 0.0023  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 39s (remain 12m 40s) Loss: 0.4778(0.3721) Grad: 0.0001  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 6s (remain 12m 11s) Loss: 0.4000(0.3734) Grad: 0.0015  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 33s (remain 11m 43s) Loss: 0.4167(0.3750) Grad: 0.0035  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 0s (remain 11m 15s) Loss: 0.4091(0.3757) Grad: 0.0022  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 27s (remain 10m 48s) Loss: 0.4167(0.3763) Grad: 0.0036  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 55s (remain 10m 20s) Loss: 0.1667(0.3760) Grad: 0.0000  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 22s (remain 9m 52s) Loss: 0.3333(0.3749) Grad: 0.0043  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 49s (remain 9m 25s) Loss: 0.3571(0.3746) Grad: 0.0168  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 16s (remain 8m 57s) Loss: 0.4091(0.3746) Grad: 0.0013  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 43s (remain 8m 30s) Loss: 0.4091(0.3741) Grad: 0.0000  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 10s (remain 8m 3s) Loss: 0.3000(0.3744) Grad: 0.0251  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 37s (remain 7m 35s) Loss: 0.3000(0.3745) Grad: 0.0062  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 4s (remain 7m 8s) Loss: 0.3333(0.3743) Grad: 0.0141  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 32s (remain 6m 41s) Loss: 0.4375(0.3744) Grad: 0.0015  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 9m 59s (remain 6m 13s) Loss: 0.4375(0.3747) Grad: 0.0025  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 26s (remain 5m 46s) Loss: 0.3000(0.3751) Grad: 0.0000  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 53s (remain 5m 19s) Loss: 0.4231(0.3757) Grad: 0.0030  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 20s (remain 4m 52s) Loss: 0.4333(0.3760) Grad: 0.0084  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 47s (remain 4m 24s) Loss: 0.4000(0.3759) Grad: 0.0000  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 14s (remain 3m 57s) Loss: 0.4444(0.3759) Grad: 0.0005  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 41s (remain 3m 30s) Loss: 0.4286(0.3756) Grad: 0.0000  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 8s (remain 3m 3s) Loss: 0.4167(0.3759) Grad: 0.0027  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 35s (remain 2m 36s) Loss: 0.4231(0.3761) Grad: 0.0016  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.4000(0.3762) Grad: 0.0000  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 30s (remain 1m 41s) Loss: 0.3889(0.3755) Grad: 0.0048  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 14m 57s (remain 1m 14s) Loss: 0.3750(0.3755) Grad: 0.0000  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 24s (remain 0m 47s) Loss: 0.4000(0.3755) Grad: 0.0015  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 51s (remain 0m 20s) Loss: 0.3333(0.3758) Grad: 0.0043  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 11s (remain 0m 0s) Loss: 0.2500(0.3758) Grad: 0.0094  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 9s) Loss: 0.3571(0.3571) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.3571(0.3894) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4231(0.3860) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4444(0.3694) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3716) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3333(0.3754) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4091(0.3766) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 10s) Loss: 0.3000(0.3772) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.3780) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4375(0.3791) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.4167(0.3801) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4286(0.3777) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3724) \n","Epoch 2 - avg_train_loss: 0.3758  avg_val_loss: 0.3724  time: 1160s\n","Epoch 2 - Score: 0.0000\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 33m 17s) Loss: 0.4375(0.4375) Grad: 0.0098  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 27s (remain 15m 53s) Loss: 0.4375(0.3896) Grad: 0.0015  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 54s (remain 15m 20s) Loss: 0.3750(0.3750) Grad: 0.0024  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 21s (remain 14m 51s) Loss: 0.4167(0.3769) Grad: 0.0026  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.3571(0.3782) Grad: 0.0056  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 16s (remain 13m 56s) Loss: 0.3889(0.3802) Grad: 0.0019  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.3571(0.3788) Grad: 0.0055  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 10s (remain 13m 0s) Loss: 0.4000(0.3772) Grad: 0.0051  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 37s (remain 12m 34s) Loss: 0.3750(0.3772) Grad: 0.0081  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.3571(0.3777) Grad: 0.0000  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 32s (remain 11m 39s) Loss: 0.4231(0.3763) Grad: 0.0000  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 59s (remain 11m 12s) Loss: 0.4231(0.3772) Grad: 0.0000  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 26s (remain 10m 44s) Loss: 0.3889(0.3762) Grad: 0.0080  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.4000(0.3757) Grad: 0.0000  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.4167(0.3761) Grad: 0.0011  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.3750(0.3751) Grad: 0.0024  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 14s (remain 8m 55s) Loss: 0.3750(0.3753) Grad: 0.0061  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.4500(0.3745) Grad: 0.0010  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 8s (remain 8m 1s) Loss: 0.3571(0.3743) Grad: 0.0031  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 35s (remain 7m 34s) Loss: 0.4231(0.3738) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 2s (remain 7m 7s) Loss: 0.4286(0.3741) Grad: 0.0020  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 30s (remain 6m 39s) Loss: 0.4167(0.3748) Grad: 0.0027  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 9m 57s (remain 6m 12s) Loss: 0.4500(0.3746) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.3750(0.3749) Grad: 0.0065  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.4286(0.3751) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.3571(0.3752) Grad: 0.0055  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 45s (remain 4m 24s) Loss: 0.3571(0.3748) Grad: 0.0080  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 12s (remain 3m 57s) Loss: 0.3750(0.3748) Grad: 0.0024  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 39s (remain 3m 30s) Loss: 0.4474(0.3753) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.4286(0.3752) Grad: 0.0020  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.0000(0.3750) Grad: 0.0727  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.4524(0.3748) Grad: 0.0006  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.4545(0.3751) Grad: 0.0000  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.3889(0.3757) Grad: 0.0153  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.3571(0.3762) Grad: 0.0031  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 49s (remain 0m 20s) Loss: 0.4333(0.3766) Grad: 0.0000  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 9s (remain 0m 0s) Loss: 0.2500(0.3767) Grad: 0.0094  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 58s) Loss: 0.3571(0.3571) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.3571(0.3894) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4231(0.3860) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4444(0.3694) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3716) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3333(0.3754) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4091(0.3766) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.3000(0.3772) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.3780) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4375(0.3791) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.4167(0.3801) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4286(0.3777) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3724) \n","Epoch 3 - avg_train_loss: 0.3767  avg_val_loss: 0.3724  time: 1158s\n","Epoch 3 - Score: 0.0000\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 32m 45s) Loss: 0.4333(0.4333) Grad: 0.0107  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 27s (remain 15m 52s) Loss: 0.3750(0.3703) Grad: 0.0000  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 54s (remain 15m 18s) Loss: 0.3750(0.3748) Grad: 0.0000  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 21s (remain 14m 50s) Loss: 0.4167(0.3789) Grad: 0.0010  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 48s (remain 14m 22s) Loss: 0.3333(0.3748) Grad: 0.0042  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 16s (remain 13m 54s) Loss: 0.4412(0.3774) Grad: 0.0010  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 43s (remain 13m 27s) Loss: 0.4167(0.3761) Grad: 0.0027  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 10s (remain 13m 0s) Loss: 0.4091(0.3759) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 37s (remain 12m 32s) Loss: 0.4444(0.3742) Grad: 0.0023  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 4s (remain 12m 5s) Loss: 0.3333(0.3743) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 31s (remain 11m 38s) Loss: 0.3750(0.3745) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 58s (remain 11m 11s) Loss: 0.3750(0.3743) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 25s (remain 10m 43s) Loss: 0.4444(0.3735) Grad: 0.0005  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.3750(0.3717) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.4167(0.3726) Grad: 0.0019  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 47s (remain 9m 22s) Loss: 0.4375(0.3731) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 14s (remain 8m 55s) Loss: 0.4333(0.3733) Grad: 0.0007  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.0000(0.3744) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 8s (remain 8m 1s) Loss: 0.4091(0.3737) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 35s (remain 7m 34s) Loss: 0.4524(0.3735) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 2s (remain 7m 7s) Loss: 0.4643(0.3741) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 29s (remain 6m 39s) Loss: 0.4091(0.3749) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 9m 57s (remain 6m 12s) Loss: 0.4500(0.3752) Grad: 0.0004  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.4474(0.3751) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.4231(0.3752) Grad: 0.0016  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.1667(0.3758) Grad: 0.0175  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 45s (remain 4m 24s) Loss: 0.0000(0.3758) Grad: 0.0999  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 12s (remain 3m 57s) Loss: 0.4000(0.3758) Grad: 0.0015  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 39s (remain 3m 30s) Loss: 0.3750(0.3759) Grad: 0.0042  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.4000(0.3755) Grad: 0.0027  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.3889(0.3752) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.3000(0.3754) Grad: 0.0252  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.1667(0.3751) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.4688(0.3754) Grad: 0.0002  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.3750(0.3755) Grad: 0.0042  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 49s (remain 0m 20s) Loss: 0.4375(0.3755) Grad: 0.0038  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 9s (remain 0m 0s) Loss: 0.4333(0.3757) Grad: 0.0007  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 20s) Loss: 0.3571(0.3571) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.3571(0.3894) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4231(0.3860) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.4444(0.3694) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3716) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3333(0.3754) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4091(0.3766) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 10s) Loss: 0.3000(0.3772) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.3780) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4375(0.3791) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.4167(0.3801) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4286(0.3777) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3724) \n","Epoch 4 - avg_train_loss: 0.3757  avg_val_loss: 0.3724  time: 1158s\n","Epoch 4 - Score: 0.0000\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 33m 47s) Loss: 0.3000(0.3000) Grad: 0.0007  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 27s (remain 15m 52s) Loss: 0.4231(0.3751) Grad: 0.0009  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 54s (remain 15m 20s) Loss: 0.3000(0.3685) Grad: 0.0216  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 22s (remain 14m 53s) Loss: 0.4524(0.3683) Grad: 0.0012  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 49s (remain 14m 24s) Loss: 0.3571(0.3711) Grad: 0.0055  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 16s (remain 13m 56s) Loss: 0.2500(0.3708) Grad: 0.0256  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 43s (remain 13m 29s) Loss: 0.4333(0.3685) Grad: 0.0007  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 10s (remain 13m 1s) Loss: 0.4615(0.3714) Grad: 0.0002  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 37s (remain 12m 34s) Loss: 0.2500(0.3725) Grad: 0.0175  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.4545(0.3737) Grad: 0.0013  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 32s (remain 11m 39s) Loss: 0.0000(0.3719) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 59s (remain 11m 12s) Loss: 0.4333(0.3719) Grad: 0.0093  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 26s (remain 10m 44s) Loss: 0.3750(0.3732) Grad: 0.0024  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.4167(0.3742) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.3333(0.3744) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.3333(0.3744) Grad: 0.0077  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 14s (remain 8m 55s) Loss: 0.0000(0.3743) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.3571(0.3738) Grad: 0.0031  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 9s (remain 8m 1s) Loss: 0.4167(0.3734) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.4333(0.3734) Grad: 0.0047  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.4545(0.3736) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.3750(0.3736) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 9m 57s (remain 6m 13s) Loss: 0.4412(0.3733) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.4444(0.3732) Grad: 0.0005  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.3750(0.3739) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.4474(0.3738) Grad: 0.0011  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 45s (remain 4m 24s) Loss: 0.3000(0.3740) Grad: 0.0060  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.3333(0.3738) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.4000(0.3737) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.3000(0.3735) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.0000(0.3733) Grad: 0.0705  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.3750(0.3732) Grad: 0.0060  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.2500(0.3732) Grad: 0.0101  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 14m 56s (remain 1m 14s) Loss: 0.2500(0.3732) Grad: 0.0195  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 23s (remain 0m 47s) Loss: 0.4286(0.3735) Grad: 0.0014  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.0000(0.3737) Grad: 0.0000  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.3571(0.3740) Grad: 0.0080  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 32s) Loss: 0.3571(0.3571) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.3571(0.3894) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 24s) Loss: 0.4231(0.3860) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.4444(0.3694) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.4444(0.3716) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.3333(0.3754) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4091(0.3766) \n","EVAL: [700/1192] Elapsed 1m 41s (remain 1m 10s) Loss: 0.3000(0.3772) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0000(0.3780) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4375(0.3791) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.4167(0.3801) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.4286(0.3777) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3724) \n","Epoch 5 - avg_train_loss: 0.3740  avg_val_loss: 0.3724  time: 1159s\n","Epoch 5 - Score: 0.0000\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 44m 56s) Loss: 0.4861(0.4861) Grad: 4485.5430  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 28s (remain 16m 3s) Loss: 0.4881(0.4840) Grad: 4737.8687  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 55s (remain 15m 26s) Loss: 0.4756(0.4839) Grad: 7886.7026  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 22s (remain 14m 55s) Loss: 0.4855(0.4832) Grad: 6008.6670  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 49s (remain 14m 27s) Loss: 0.4898(0.4823) Grad: 6630.8970  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 16s (remain 13m 59s) Loss: 0.4456(0.4806) Grad: 31406.0391  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 43s (remain 13m 30s) Loss: 0.3335(0.4712) Grad: 207.1209  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 11s (remain 13m 3s) Loss: 0.1667(0.4588) Grad: 92.7818  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 38s (remain 12m 35s) Loss: 0.1667(0.4488) Grad: 44.3657  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 5s (remain 12m 8s) Loss: 0.3750(0.4400) Grad: 2.8432  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 32s (remain 11m 40s) Loss: 0.3750(0.4332) Grad: 2.3200  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 59s (remain 11m 13s) Loss: 0.4474(0.4286) Grad: 0.1974  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 26s (remain 10m 45s) Loss: 0.2500(0.4250) Grad: 7.0935  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 54s (remain 10m 18s) Loss: 0.3571(0.4205) Grad: 1.1561  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 21s (remain 9m 51s) Loss: 0.4000(0.4168) Grad: 0.4145  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.4677(0.4140) Grad: 0.0216  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 15s (remain 8m 56s) Loss: 0.4444(0.4111) Grad: 0.0654  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.4714(0.4078) Grad: 0.0099  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 9s (remain 8m 2s) Loss: 0.4412(0.4063) Grad: 0.0162  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 36s (remain 7m 35s) Loss: 0.0000(0.4049) Grad: 1.8296  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.3889(0.4034) Grad: 0.0569  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.1667(0.4019) Grad: 0.4347  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 9m 58s (remain 6m 13s) Loss: 0.1667(0.4001) Grad: 0.2656  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.3750(0.3993) Grad: 0.0172  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 52s (remain 5m 18s) Loss: 0.3889(0.3975) Grad: 0.0096  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 19s (remain 4m 51s) Loss: 0.3333(0.3964) Grad: 0.0301  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.4474(0.3959) Grad: 0.0009  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.4286(0.3948) Grad: 0.0043  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.3000(0.3946) Grad: 0.0149  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 7s (remain 3m 3s) Loss: 0.4444(0.3939) Grad: 0.0024  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 35s (remain 2m 35s) Loss: 0.4412(0.3939) Grad: 0.0013  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 2s (remain 2m 8s) Loss: 0.4091(0.3927) Grad: 0.0050  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 29s (remain 1m 41s) Loss: 0.1667(0.3922) Grad: 0.0678  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 14m 56s (remain 1m 14s) Loss: 0.4167(0.3919) Grad: 0.0018  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 23s (remain 0m 47s) Loss: 0.4167(0.3916) Grad: 0.0030  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.4000(0.3912) Grad: 0.0054  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.4333(0.3909) Grad: 0.0014  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 51s) Loss: 0.4412(0.4412) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4375(0.3966) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4444(0.3927) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.3750(0.3789) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.3750(0.3772) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4600(0.3782) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4231(0.3785) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4412(0.3804) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4286(0.3810) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3816) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.3333(0.3796) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.3571(0.3756) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3716) \n","Epoch 1 - avg_train_loss: 0.3909  avg_val_loss: 0.3716  time: 1148s\n","Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 36m 33s) Loss: 0.4231(0.4231) Grad: 0.0035  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 28s (remain 16m 36s) Loss: 0.4091(0.3849) Grad: 0.0081  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 56s (remain 15m 51s) Loss: 0.4091(0.3840) Grad: 0.0052  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 24s (remain 15m 14s) Loss: 0.4412(0.3829) Grad: 0.0018  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 51s (remain 14m 40s) Loss: 0.3333(0.3850) Grad: 0.0177  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 18s (remain 14m 8s) Loss: 0.4231(0.3796) Grad: 0.0036  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 45s (remain 13m 39s) Loss: 0.4286(0.3787) Grad: 0.0026  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 12s (remain 13m 9s) Loss: 0.4375(0.3794) Grad: 0.0024  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 39s (remain 12m 41s) Loss: 0.4524(0.3800) Grad: 0.0014  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 6s (remain 12m 12s) Loss: 0.3000(0.3803) Grad: 0.0157  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 34s (remain 11m 44s) Loss: 0.3889(0.3795) Grad: 0.0048  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 1s (remain 11m 16s) Loss: 0.4000(0.3793) Grad: 0.0028  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 28s (remain 10m 49s) Loss: 0.4231(0.3788) Grad: 0.0009  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 55s (remain 10m 21s) Loss: 0.3571(0.3786) Grad: 0.0175  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 22s (remain 9m 53s) Loss: 0.3571(0.3787) Grad: 0.0055  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 49s (remain 9m 26s) Loss: 0.4333(0.3787) Grad: 0.0023  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 16s (remain 8m 58s) Loss: 0.4412(0.3783) Grad: 0.0010  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 44s (remain 8m 31s) Loss: 0.4333(0.3783) Grad: 0.0012  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 11s (remain 8m 3s) Loss: 0.2500(0.3775) Grad: 0.0396  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 38s (remain 7m 36s) Loss: 0.3750(0.3773) Grad: 0.0061  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 5s (remain 7m 9s) Loss: 0.4333(0.3773) Grad: 0.0007  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 32s (remain 6m 41s) Loss: 0.4286(0.3774) Grad: 0.0000  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 9m 59s (remain 6m 14s) Loss: 0.4231(0.3774) Grad: 0.0031  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 27s (remain 5m 47s) Loss: 0.4167(0.3779) Grad: 0.0110  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 54s (remain 5m 19s) Loss: 0.4091(0.3775) Grad: 0.0052  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 21s (remain 4m 52s) Loss: 0.4714(0.3777) Grad: 0.0039  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 48s (remain 4m 25s) Loss: 0.4167(0.3774) Grad: 0.0019  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 15s (remain 3m 58s) Loss: 0.4167(0.3772) Grad: 0.0035  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.4630(0.3773) Grad: 0.0005  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 9s (remain 3m 3s) Loss: 0.4286(0.3773) Grad: 0.0032  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 37s (remain 2m 36s) Loss: 0.4167(0.3775) Grad: 0.0019  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 4s (remain 2m 9s) Loss: 0.4286(0.3772) Grad: 0.0026  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 31s (remain 1m 41s) Loss: 0.4167(0.3773) Grad: 0.0052  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 14m 58s (remain 1m 14s) Loss: 0.3571(0.3771) Grad: 0.0104  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 25s (remain 0m 47s) Loss: 0.3889(0.3772) Grad: 0.0034  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 52s (remain 0m 20s) Loss: 0.4375(0.3768) Grad: 0.0011  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 12s (remain 0m 0s) Loss: 0.4286(0.3765) Grad: 0.0026  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 30s) Loss: 0.4412(0.4412) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.4375(0.3966) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4444(0.3927) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.3750(0.3789) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.3750(0.3772) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4600(0.3782) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4231(0.3785) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4412(0.3804) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4286(0.3810) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3816) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3333(0.3796) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.3571(0.3756) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3716) \n","Epoch 2 - avg_train_loss: 0.3765  avg_val_loss: 0.3716  time: 1150s\n","Epoch 2 - Score: 0.0000\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 32m 36s) Loss: 0.3000(0.3000) Grad: 0.0175  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 27s (remain 15m 53s) Loss: 0.2500(0.3777) Grad: 0.0184  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 54s (remain 15m 20s) Loss: 0.4286(0.3806) Grad: 0.0000  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 21s (remain 14m 51s) Loss: 0.4412(0.3840) Grad: 0.0005  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.4600(0.3810) Grad: 0.0000  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 16s (remain 13m 55s) Loss: 0.4412(0.3813) Grad: 0.0009  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.1667(0.3790) Grad: 0.0556  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 10s (remain 13m 0s) Loss: 0.4000(0.3771) Grad: 0.0039  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 37s (remain 12m 33s) Loss: 0.3889(0.3768) Grad: 0.0033  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 4s (remain 12m 7s) Loss: 0.4231(0.3789) Grad: 0.0009  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 32s (remain 11m 39s) Loss: 0.4231(0.3793) Grad: 0.0017  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 59s (remain 11m 12s) Loss: 0.4231(0.3795) Grad: 0.0095  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 26s (remain 10m 45s) Loss: 0.4000(0.3794) Grad: 0.0000  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.3889(0.3790) Grad: 0.0034  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.1667(0.3786) Grad: 0.0176  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.4444(0.3775) Grad: 0.0008  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 14s (remain 8m 56s) Loss: 0.4333(0.3775) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.4375(0.3775) Grad: 0.0006  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 9s (remain 8m 1s) Loss: 0.4091(0.3768) Grad: 0.0023  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.3333(0.3771) Grad: 0.4449  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.4412(0.3769) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.2500(0.3763) Grad: 0.0000  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 9m 57s (remain 6m 13s) Loss: 0.4412(0.3768) Grad: 0.0005  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.4091(0.3770) Grad: 0.0023  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 52s (remain 5m 18s) Loss: 0.3889(0.3771) Grad: 0.0036  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 19s (remain 4m 51s) Loss: 0.4000(0.3770) Grad: 0.0015  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.4167(0.3773) Grad: 0.0027  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.4333(0.3775) Grad: 0.0000  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.3889(0.3772) Grad: 0.0020  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 7s (remain 3m 3s) Loss: 0.3889(0.3770) Grad: 0.0257  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 35s (remain 2m 35s) Loss: 0.3333(0.3772) Grad: 0.0143  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 2s (remain 2m 8s) Loss: 0.3571(0.3769) Grad: 0.0056  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 29s (remain 1m 41s) Loss: 0.3750(0.3768) Grad: 0.0000  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 14m 56s (remain 1m 14s) Loss: 0.4091(0.3763) Grad: 0.0042  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 23s (remain 0m 47s) Loss: 0.0000(0.3768) Grad: 0.0406  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.4286(0.3766) Grad: 0.0000  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.4167(0.3767) Grad: 0.0011  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 35s) Loss: 0.4412(0.4412) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.4375(0.3966) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4444(0.3927) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.3750(0.3789) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.3750(0.3772) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4600(0.3782) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4231(0.3785) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4412(0.3804) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4286(0.3810) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3816) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3333(0.3796) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.3571(0.3756) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3716) \n","Epoch 3 - avg_train_loss: 0.3767  avg_val_loss: 0.3716  time: 1148s\n","Epoch 3 - Score: 0.0000\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 35m 22s) Loss: 0.4000(0.4000) Grad: 0.0035  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 27s (remain 15m 55s) Loss: 0.4231(0.3784) Grad: 0.0016  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 54s (remain 15m 21s) Loss: 0.4091(0.3794) Grad: 0.0000  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 22s (remain 14m 52s) Loss: 0.3000(0.3747) Grad: 0.0109  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 49s (remain 14m 24s) Loss: 0.4474(0.3736) Grad: 0.0004  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 16s (remain 13m 56s) Loss: 0.4000(0.3759) Grad: 0.0039  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.4730(0.3774) Grad: 0.0001  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 10s (remain 13m 1s) Loss: 0.4412(0.3788) Grad: 0.0000  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 37s (remain 12m 34s) Loss: 0.4375(0.3789) Grad: 0.0011  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.4286(0.3789) Grad: 0.0014  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 32s (remain 11m 39s) Loss: 0.4231(0.3777) Grad: 0.0009  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 59s (remain 11m 12s) Loss: 0.4167(0.3770) Grad: 0.0029  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 26s (remain 10m 44s) Loss: 0.4524(0.3779) Grad: 0.0003  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.4333(0.3770) Grad: 0.0007  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.4474(0.3770) Grad: 0.0040  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.3750(0.3775) Grad: 0.0043  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 15s (remain 8m 56s) Loss: 0.4000(0.3762) Grad: 0.0050  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.3571(0.3766) Grad: 0.0000  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 9s (remain 8m 1s) Loss: 0.4167(0.3762) Grad: 0.0019  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.3571(0.3769) Grad: 0.0031  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.3750(0.3774) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.4231(0.3779) Grad: 0.0000  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 9m 57s (remain 6m 13s) Loss: 0.3889(0.3776) Grad: 0.0112  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.3750(0.3779) Grad: 0.0024  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 52s (remain 5m 18s) Loss: 0.4091(0.3770) Grad: 0.0013  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 19s (remain 4m 51s) Loss: 0.4091(0.3771) Grad: 0.0032  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.3750(0.3773) Grad: 0.0042  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.3333(0.3766) Grad: 0.0042  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.3571(0.3770) Grad: 0.0058  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 8s (remain 3m 3s) Loss: 0.2500(0.3774) Grad: 0.0098  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 35s (remain 2m 35s) Loss: 0.4286(0.3773) Grad: 0.0008  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 2s (remain 2m 8s) Loss: 0.4167(0.3770) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 29s (remain 1m 41s) Loss: 0.3333(0.3768) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 14m 56s (remain 1m 14s) Loss: 0.3750(0.3767) Grad: 0.0024  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 23s (remain 0m 47s) Loss: 0.3889(0.3771) Grad: 0.0000  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.4231(0.3768) Grad: 0.0009  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.3750(0.3767) Grad: 0.0024  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 41s) Loss: 0.4412(0.4412) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 40s) Loss: 0.4375(0.3966) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.4444(0.3927) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 9s) Loss: 0.3750(0.3789) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.3750(0.3772) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.4600(0.3782) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.4231(0.3785) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4412(0.3804) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.4286(0.3810) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3816) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.3333(0.3796) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.3571(0.3756) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.3750(0.3716) \n","Epoch 4 - avg_train_loss: 0.3767  avg_val_loss: 0.3716  time: 1148s\n","Epoch 4 - Score: 0.0000\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 33m 57s) Loss: 0.3000(0.3000) Grad: 0.0089  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 27s (remain 16m 1s) Loss: 0.3333(0.3716) Grad: 0.0044  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 55s (remain 15m 26s) Loss: 0.3750(0.3763) Grad: 0.0051  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 22s (remain 14m 57s) Loss: 0.1667(0.3737) Grad: 0.0174  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 49s (remain 14m 28s) Loss: 0.1667(0.3752) Grad: 0.0000  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 17s (remain 14m 1s) Loss: 0.3000(0.3780) Grad: 0.0113  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 44s (remain 13m 33s) Loss: 0.4286(0.3783) Grad: 0.0014  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 11s (remain 13m 6s) Loss: 0.3750(0.3773) Grad: 0.0000  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 39s (remain 12m 39s) Loss: 0.3571(0.3765) Grad: 0.0103  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 6s (remain 12m 11s) Loss: 0.1667(0.3746) Grad: 0.0171  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 33s (remain 11m 44s) Loss: 0.4375(0.3761) Grad: 0.0033  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 1s (remain 11m 16s) Loss: 0.4375(0.3770) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 28s (remain 10m 49s) Loss: 0.4333(0.3766) Grad: 0.0027  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 55s (remain 10m 21s) Loss: 0.4375(0.3767) Grad: 0.0094  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 22s (remain 9m 54s) Loss: 0.4000(0.3775) Grad: 0.0000  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 50s (remain 9m 26s) Loss: 0.4000(0.3766) Grad: 0.0039  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.4091(0.3770) Grad: 0.0013  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 44s (remain 8m 31s) Loss: 0.3571(0.3771) Grad: 0.0033  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 11s (remain 8m 4s) Loss: 0.4167(0.3776) Grad: 0.0019  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.4091(0.3782) Grad: 0.0013  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 6s (remain 7m 9s) Loss: 0.3750(0.3777) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 33s (remain 6m 42s) Loss: 0.4000(0.3776) Grad: 0.0000  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 0s (remain 6m 15s) Loss: 0.4286(0.3775) Grad: 0.0008  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 28s (remain 5m 47s) Loss: 0.4375(0.3776) Grad: 0.0006  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 55s (remain 5m 20s) Loss: 0.3750(0.3774) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 22s (remain 4m 53s) Loss: 0.4375(0.3782) Grad: 0.0011  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 49s (remain 4m 25s) Loss: 0.4231(0.3773) Grad: 0.0000  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 17s (remain 3m 58s) Loss: 0.2500(0.3773) Grad: 0.0407  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 44s (remain 3m 31s) Loss: 0.3333(0.3774) Grad: 0.0054  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.4167(0.3777) Grad: 0.0011  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 38s (remain 2m 36s) Loss: 0.2500(0.3775) Grad: 0.0170  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 5s (remain 2m 9s) Loss: 0.2500(0.3773) Grad: 0.0097  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 33s (remain 1m 42s) Loss: 0.3333(0.3768) Grad: 0.0076  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 0s (remain 1m 14s) Loss: 0.4091(0.3768) Grad: 0.0012  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 27s (remain 0m 47s) Loss: 0.4444(0.3769) Grad: 0.0005  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 54s (remain 0m 20s) Loss: 0.4091(0.3767) Grad: 0.0000  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 15s (remain 0m 0s) Loss: 0.4091(0.3769) Grad: 0.0043  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 35s) Loss: 0.4412(0.4412) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.4375(0.3966) \n","EVAL: [200/1192] Elapsed 0m 28s (remain 2m 22s) Loss: 0.4444(0.3927) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.3750(0.3789) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.3750(0.3772) \n","EVAL: [500/1192] Elapsed 1m 11s (remain 1m 39s) Loss: 0.4600(0.3782) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.4231(0.3785) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.4412(0.3804) \n","EVAL: [800/1192] Elapsed 1m 54s (remain 0m 56s) Loss: 0.4286(0.3810) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.4333(0.3816) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.3333(0.3796) \n","EVAL: [1100/1192] Elapsed 2m 37s (remain 0m 13s) Loss: 0.3571(0.3756) \n","EVAL: [1191/1192] Elapsed 2m 50s (remain 0m 0s) Loss: 0.3750(0.3716) \n","Epoch 5 - avg_train_loss: 0.3769  avg_val_loss: 0.3716  time: 1151s\n","Epoch 5 - Score: 0.0000\n","Best thres: 0.5, Score: 0.0000\n","Best thres: 0.5, Score: 0.0000\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4629262a603244db9ef8d03d4f2a0779"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6317fe9bb984c24a458c3ea9037bba6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de78ec21942f418487b281a34ab7f3fe"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c7e83e3722c4ae89428ca490fc753ca"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp062.ipynb","provenance":[{"file_id":"1_Dpi1wisNPHuDrE0qcWzSpkQldH3JxA8","timestamp":1648039098210},{"file_id":"10yG4L3_nzpdL2CDwqxa9r-KWq6jYkWfl","timestamp":1647960989099}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"938ee232963b4f8a940a9ae7b5ae6c19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c1d2c1d32dc4b839f4cbcc6107b7b22","IPY_MODEL_e6b2f50dd6a94bec84fd501df4573853","IPY_MODEL_78584d62586b4dcc97c2aeaf8bb896ed"],"layout":"IPY_MODEL_5b0f30da0d4147dcb7e5349a8eeb5831"}},"0c1d2c1d32dc4b839f4cbcc6107b7b22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9961154a7a7e41d7aaf78b066bfba7db","placeholder":"​","style":"IPY_MODEL_382746446ecc420b8b59c6f93afab990","value":"100%"}},"e6b2f50dd6a94bec84fd501df4573853":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_243ef0ab0f344337865fe231e8992d9b","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9de60ddef1549b0a08616928619a39b","value":42146}},"78584d62586b4dcc97c2aeaf8bb896ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e3edd16a5ee40a2bcfd9d2a6896d6fa","placeholder":"​","style":"IPY_MODEL_2deee6cd567a40b8a072a7af5de0ccf0","value":" 42146/42146 [00:36&lt;00:00, 1983.49it/s]"}},"5b0f30da0d4147dcb7e5349a8eeb5831":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9961154a7a7e41d7aaf78b066bfba7db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"382746446ecc420b8b59c6f93afab990":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"243ef0ab0f344337865fe231e8992d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9de60ddef1549b0a08616928619a39b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e3edd16a5ee40a2bcfd9d2a6896d6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2deee6cd567a40b8a072a7af5de0ccf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ff6bc209c7540718c53c7782f5366e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1016356e8ba644f8abf726ba83a02ff7","IPY_MODEL_9ecc6315278f430d97b848584e53b9fd","IPY_MODEL_c8880ca56e8c4e0cb890243dcf662815"],"layout":"IPY_MODEL_561571b6c65e46f9b156118de46721aa"}},"1016356e8ba644f8abf726ba83a02ff7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4ca92c4a4824b54aa95dda817736cd8","placeholder":"​","style":"IPY_MODEL_a4b5bc59f19e4c2a8ebe9a5f54fe8069","value":"100%"}},"9ecc6315278f430d97b848584e53b9fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6589c9349b34393a05fdf32a6d47e71","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_544a611b8ef2467988340118c35e5363","value":143}},"c8880ca56e8c4e0cb890243dcf662815":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29192b46c6bd492199042bb162ec568c","placeholder":"​","style":"IPY_MODEL_7d38f3c6055a47258c45e09435ab7c74","value":" 143/143 [00:00&lt;00:00, 2606.78it/s]"}},"561571b6c65e46f9b156118de46721aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4ca92c4a4824b54aa95dda817736cd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4b5bc59f19e4c2a8ebe9a5f54fe8069":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6589c9349b34393a05fdf32a6d47e71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"544a611b8ef2467988340118c35e5363":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29192b46c6bd492199042bb162ec568c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d38f3c6055a47258c45e09435ab7c74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4629262a603244db9ef8d03d4f2a0779":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_959ead905cbd42439ecfe660b87b6d0d","IPY_MODEL_a65b63d56ff34ff8b05d12c7fa674740","IPY_MODEL_6506b7740ab9428c844661b4b6cb8576"],"layout":"IPY_MODEL_4cbd0f0154414f8c8972260fa5c0b5b3"}},"959ead905cbd42439ecfe660b87b6d0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d76472e5e97482a9539ccbf7a2fdfe0","placeholder":"​","style":"IPY_MODEL_5461fb13f4954fd6a7b5fe60febd8667","value":"Downloading: 100%"}},"a65b63d56ff34ff8b05d12c7fa674740":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_647e72343bc840fd91654e5838be66a0","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b671fde322314b6a9198de134f0e19b7","value":1627284589}},"6506b7740ab9428c844661b4b6cb8576":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb3e6cadf7d046eb980d484ab3ab211a","placeholder":"​","style":"IPY_MODEL_e180a8fd7405478094277a8ebd2f65a5","value":" 1.52G/1.52G [53:50&lt;00:00, 1.72MB/s]"}},"4cbd0f0154414f8c8972260fa5c0b5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d76472e5e97482a9539ccbf7a2fdfe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5461fb13f4954fd6a7b5fe60febd8667":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"647e72343bc840fd91654e5838be66a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b671fde322314b6a9198de134f0e19b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb3e6cadf7d046eb980d484ab3ab211a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e180a8fd7405478094277a8ebd2f65a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6317fe9bb984c24a458c3ea9037bba6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5bf72f58dda4d0b8f43b1e441dd9832","IPY_MODEL_1f040707d6304e13b584ed04ffce98ec","IPY_MODEL_947d23a6f96243b3b75ad45e5ce363e7"],"layout":"IPY_MODEL_e694185281054c55aa5656bf67676da9"}},"f5bf72f58dda4d0b8f43b1e441dd9832":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45d834a99f4a45a78a1f2fa342807efb","placeholder":"​","style":"IPY_MODEL_9f078db1d3574ebe9bc75417601c1119","value":"100%"}},"1f040707d6304e13b584ed04ffce98ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28347a9064804c7e9661d8c33158e643","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_919f245d5c0142c88e7914fec1de7d97","value":2}},"947d23a6f96243b3b75ad45e5ce363e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4597715dcb3e4f859336ac72806b5772","placeholder":"​","style":"IPY_MODEL_26f5525964c449a593e52bad121dc705","value":" 2/2 [00:02&lt;00:00,  1.30it/s]"}},"e694185281054c55aa5656bf67676da9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d834a99f4a45a78a1f2fa342807efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f078db1d3574ebe9bc75417601c1119":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28347a9064804c7e9661d8c33158e643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919f245d5c0142c88e7914fec1de7d97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4597715dcb3e4f859336ac72806b5772":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26f5525964c449a593e52bad121dc705":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de78ec21942f418487b281a34ab7f3fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73772b0c8aa74ef7b68a47a4a2b08fd4","IPY_MODEL_5f408da9a97a4f5581a99e4c3298495f","IPY_MODEL_fc5cadacc92f4131ba56c6b95535ac22"],"layout":"IPY_MODEL_3ae740f8381e40bf975030bc4b2b85d2"}},"73772b0c8aa74ef7b68a47a4a2b08fd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_948099f4dbac47f5bc8c03f3f0fdb5dd","placeholder":"​","style":"IPY_MODEL_13212f48ceac484aadd2c214dfcdf90b","value":"100%"}},"5f408da9a97a4f5581a99e4c3298495f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90efa2cc48464cf88e7f27a7f38822a7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e652bbe14b44206916f1276a6c94664","value":2}},"fc5cadacc92f4131ba56c6b95535ac22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_185884c747d0439aac6a6a2ba24305df","placeholder":"​","style":"IPY_MODEL_618d917c35e64365ae08c92a0a8e525e","value":" 2/2 [00:01&lt;00:00,  1.82it/s]"}},"3ae740f8381e40bf975030bc4b2b85d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"948099f4dbac47f5bc8c03f3f0fdb5dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13212f48ceac484aadd2c214dfcdf90b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90efa2cc48464cf88e7f27a7f38822a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e652bbe14b44206916f1276a6c94664":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"185884c747d0439aac6a6a2ba24305df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"618d917c35e64365ae08c92a0a8e525e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c7e83e3722c4ae89428ca490fc753ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a9bc80c699b48bb81bc76a7eb9ba529","IPY_MODEL_c0102ec4687242b1953420e74a2c685f","IPY_MODEL_60b473a07d4741b4844db2473ca61edd"],"layout":"IPY_MODEL_8a74dbac965a46ea826757667ad15b71"}},"6a9bc80c699b48bb81bc76a7eb9ba529":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf5fd7fc1d564a2faedc7e0ac913f551","placeholder":"​","style":"IPY_MODEL_c2d819eb10244122a922467b49590977","value":"100%"}},"c0102ec4687242b1953420e74a2c685f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67e285e8b50c475db8ea0ac1b6838786","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24f7c1442a4b45ee955c825698754ec6","value":2}},"60b473a07d4741b4844db2473ca61edd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0e4e8754d8640119acca8b8904fcc69","placeholder":"​","style":"IPY_MODEL_f2aec39a3aea4e8aaf6b62ab07a1c3c4","value":" 2/2 [00:02&lt;00:00,  1.35it/s]"}},"8a74dbac965a46ea826757667ad15b71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf5fd7fc1d564a2faedc7e0ac913f551":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2d819eb10244122a922467b49590977":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67e285e8b50c475db8ea0ac1b6838786":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24f7c1442a4b45ee955c825698754ec6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0e4e8754d8640119acca8b8904fcc69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2aec39a3aea4e8aaf6b62ab07a1c3c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}