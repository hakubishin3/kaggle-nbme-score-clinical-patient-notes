{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sufficient-barrel",
   "metadata": {
    "id": "blind-kingdom"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-dimension",
   "metadata": {
    "id": "antique-glenn"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-daily",
   "metadata": {
    "id": "bored-ministry"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "welcome-battle",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1646833650360,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "deadly-confidence"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp038\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supported-firmware",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1646833650361,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "aware-worcester"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"roberta-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "encouraging-davis",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1646833650361,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "personalized-death"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-asthma",
   "metadata": {
    "id": "cardiovascular-neutral"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "headed-container",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11851,
     "status": "ok",
     "timestamp": 1646833662206,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "checked-boards",
    "outputId": "aa696b05-81a7-4542-9bcf-8697d76fa0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "    !pip install sentencepiece\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decreased-heritage",
   "metadata": {
    "executionInfo": {
     "elapsed": 1786,
     "status": "ok",
     "timestamp": 1646833663988,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "iGai035Rvu1Z"
   },
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "if CFG.env == \"colab\":\n",
    "    input_dir = Path(\"./drive/MyDrive/00.kaggle/input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n",
    "else:\n",
    "    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)\n",
    "    \n",
    "    \n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smooth-contractor",
   "metadata": {
    "executionInfo": {
     "elapsed": 2402,
     "status": "ok",
     "timestamp": 1646833666387,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "vital-mexico"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-playback",
   "metadata": {
    "id": "economic-ladder"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patent-penalty",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646833666388,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "desperate-keyboard"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-housing",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646833666829,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "flexible-wednesday"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "integrated-adobe",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646833666830,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "logical-chemistry"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "danish-series",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646833666830,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "gorgeous-record"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-laser",
   "metadata": {
    "id": "frozen-africa"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "first-baghdad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1646833667277,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "shaped-metallic",
    "outputId": "3ca77078-abfd-40bb-a583-f4f99af73d96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "warming-broadway",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646833667278,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "visible-australia"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-lunch",
   "metadata": {
    "id": "hydraulic-gibson"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "large-webmaster",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646833667278,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "interpreted-northeast"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "legitimate-commander",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646833667279,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "martial-blind",
    "outputId": "aa0b17ad-208a-49bc-80e4-a11162a83414"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worse-gregory",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1646833667279,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "electoral-favor"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "featured-funeral",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1646833667279,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "reported-parade",
    "outputId": "a2aadb35-754c-4201-8f81-8e11a15ca5f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-saskatchewan",
   "metadata": {
    "id": "enabling-relevance"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fiscal-facing",
   "metadata": {
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1646833667766,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "mature-coalition"
   },
   "outputs": [],
   "source": [
    "def get_groupkfold(df, group_name):\n",
    "    groups = df[group_name].unique()\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=CFG.n_fold,\n",
    "        shuffle=True,\n",
    "        random_state=CFG.seed,\n",
    "    )\n",
    "    folds_ids = []\n",
    "    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n",
    "        val_group = groups[val_group_idx]\n",
    "        is_val = df[group_name].isin(val_group)\n",
    "        val_idx = df[is_val].index\n",
    "        df.loc[val_idx, \"fold\"] = int(i_fold)\n",
    "\n",
    "    df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "copyrighted-first",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646833667766,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "every-minutes",
    "outputId": "441e031e-2217-4c9e-fc16-4f7a44d9f767"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    2902\n",
       "1    2894\n",
       "2    2813\n",
       "3    2791\n",
       "4    2900\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_groupkfold(train, \"pn_num\")\n",
    "display(train.groupby(\"fold\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-angel",
   "metadata": {
    "id": "subjective-entrance"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "divine-samba",
   "metadata": {
    "executionInfo": {
     "elapsed": 4060,
     "status": "ok",
     "timestamp": 1646833671823,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "dramatic-afghanistan"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\", trim_offsets=False)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name, trim_offsets=False)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sweet-register",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1646833671825,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "04e9A2qMm5oo",
    "outputId": "91180f22-7870-44d4-fbc3-2d381f548fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'', 0, 0\n",
      "'dad', 0, 3\n",
      "' with', 3, 8\n",
      "' recent', 8, 15\n",
      "' heart', 15, 21\n",
      "' attack', 21, 28\n",
      "'', 0, 0\n",
      "ans\n",
      "\n",
      "'', 0, 0\n",
      "'dad', 0, 3\n",
      "' with', 3, 8\n",
      "' recent', 8, 15\n",
      "' heart', 15, 21\n",
      "' attack', 21, 28\n",
      "'', 0, 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = 'dad with recent heart attack'\n",
    "encode = tokenizer(tmp, return_offsets_mapping=True)\n",
    "for (start,end) in encode['offset_mapping']:\n",
    "    print(f\"'{tmp[start:end]}', {start}, {end}\")\n",
    "\n",
    "print(\"ans\")\n",
    "print(\"\"\"\n",
    "'', 0, 0\n",
    "'dad', 0, 3\n",
    "' with', 3, 8\n",
    "' recent', 8, 15\n",
    "' heart', 15, 21\n",
    "' attack', 21, 28\n",
    "'', 0, 0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-colorado",
   "metadata": {
    "id": "divided-arrow"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "placed-departure",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "44b9d3c534154fa88508a62ec05a1677",
      "e827424c1f7c46f4879f1fe53c1dacec",
      "63fdd31ea0244522a43e7c5823644ca9",
      "baf432788ac7423581cbc9f87e9bc74d",
      "59edbb1a33bf475b88ddb3db7998b3ad",
      "3a1dbe5568dc4a23b7ec750ca9639c45",
      "3cbb6e9995cb46479b7e517ec75c9c84",
      "938bb517508d4d8bb09cac2b214b7176",
      "fba1e7bf5c58413fb4a0db7e42268735",
      "5ff9158efd1545809619a09d61b069a2",
      "c6fbce429db5400f84b7a21b4fdcdcee"
     ]
    },
    "executionInfo": {
     "elapsed": 39260,
     "status": "ok",
     "timestamp": 1646833711079,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "immune-campbell",
    "outputId": "945d04b7-57d2-4594-b620-fa9bf46bed64"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724f94f5edaf40f58b998ad51cbfa266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 433\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "challenging-burner",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "7436e1e0dedd44479aee6d2d55bd12cf",
      "c5cb391342724eda9af945eb9f397d89",
      "e6439467ff394e92921326df863ff506",
      "630c3a3411944c1eb16320f83f506735",
      "5139830224f6498b8d0c0dee47549b8b",
      "46de594cfccf4a32aa50c1ce058f8972",
      "f1fe406393d149a39c633ff3558d68e0",
      "f338908c4aac421ca6dfab9458e1a157",
      "5de1e2c3d7584c488792455f4700ebf9",
      "30f5d19e109d419ea2d355d2cf69c8bf",
      "aed16ca47bcf404f8b888e89c094018d"
     ]
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1646833711079,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "northern-branch",
    "outputId": "563dfe87-7179-4305-b61a-6a1b075016b2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b61e19f9ec4d13ac43309a583366f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 30\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hungry-mongolia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1646833711080,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "oriental-jacksonville",
    "outputId": "6273bb45-3101-4b2a-ea84-13f2b9226377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 466\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "shaped-contractor",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1646833711081,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "flexible-trainer"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "velvet-speaker",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1646833711081,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "stock-robertson"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-reservoir",
   "metadata": {
    "id": "chemical-lucas"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "polyphonic-basic",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1646833711082,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "animated-array"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/pytorch_model.bin\"\n",
    "            state_dict = torch.load(path)\n",
    "            itpt.load_state_dict(state_dict, strict=False)\n",
    "            self.backbone = itpt.roberta\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-founder",
   "metadata": {
    "id": "thorough-bristol"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "juvenile-source",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1646833711082,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "n8Z5UnO9cCxW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65938\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hollow-buddy",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1646833711082,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "talented-quantity"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "lucky-panel",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1646833711083,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "figured-cooperative"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "spoken-tenant",
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1646833711567,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "played-pointer"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "false-guard",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1646833711568,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "brazilian-nigeria"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False)\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    #criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    criterion = FocalLoss(reduce=False)\n",
    "    best_score = -1 * np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-controversy",
   "metadata": {
    "id": "bearing-switch"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dependent-ghana",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646833711568,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "desperate-crime"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    score = scoring(oof_df, th=0.5)\n",
    "    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n",
    "    best_thres = get_best_thres(oof_df)\n",
    "    score = scoring(oof_df, th=best_thres)\n",
    "    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            test_token_probs = inference_fn(test_dataloader, model, device)\n",
    "            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n",
    "            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_token_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "median-acoustic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9a891d0d85d3457ab68796d0a727d839",
      "689d7f7b71344a59919aa1b7f5d69f8c",
      "b06135dc48eb4200ace2954020809c91",
      "b5d0bcb01a044fb08d824c504f62aed7",
      "fc7861e0ab0347a594ecb866a88abf85",
      "92fcbf34967f4811919b8ff0a860718c",
      "7d7ec9c04a6943859d8676063e012d04",
      "e61f8fcff6c34f42921f52d5b6b44fd5",
      "021bed17d3464417bcb9c43b3e79b19d",
      "76c2c1bb6b484fe091b7252959c65ee7",
      "6c7609ae3a814a50a2cc93a3fcdda2ed",
      "cbe63b3c954d465dbc0443ef62d6ea9b",
      "8dfa173a72a048a993a252ce2d9f7b00",
      "1cf4f0a3a0394628b9e0f02305579f5d",
      "c1c9c5bfd0084c8fa6c2cb48e3db2a60",
      "08ea123b20594ef782823b8ba176823a",
      "bccaa1763daa4f508968f7d8b040f0f3",
      "d916490a60424ee2adb63d6f5f286992",
      "47fd68de2fe74dd084647533038cf8ef",
      "99a2e96958fb43329539ca82761890d0",
      "8fd6df45f015489e98f65771081eef9a",
      "0c18277b3ae84cf9822e3f95aeebe53b",
      "030f41fd0e8f403482000a835c735928",
      "2de7b56103464351990e89417317df23",
      "d22af96aa4754966b87ea666d1f56519",
      "eba56a23967a415c99b0bf8db861a317",
      "0f2a217bf02b46e28792127c9f4a95ac",
      "ab13678726ab4f948a99c2ceea3ba1e2",
      "0979fe347c0e401790c70ed3d9787f07",
      "f3a75f8c95984d50a0b8dc37ed5cbd4e",
      "2b106055c7764d19a925a79ae5d68ca9",
      "fec5c0964350463cada500d54d5676ad",
      "ce5bb524f60f48eda173baf3aa083d85",
      "3915f6b0649c4770ae1536a7dee377dd",
      "c606df8ba9694c77871cafb980b5efe7",
      "c7c862c2b65b40a8b99c4681883359e2",
      "3aa7689f39a04484af82c5d8f4a2cf4f",
      "3ea013a5c12c4c5b8db5817acc149158",
      "d318eea186224fc3b410f24f58d616ee",
      "9e57d9425199415bb21bbd47d27456bd",
      "81d5ed83bd63414da868cad0719ef42e",
      "4561dc6fbe07488db770757f7601b5ec",
      "9e985af3c39d482d8479a50194c76e0b",
      "cbdacff28e58463ebe011b2c475c4c91",
      "94731f6d7b6246b59fec5d9d7c0bc0c9",
      "2cb0a1ef1fe544d2a51d66f4e52ad308",
      "701afc1555dd4f4a979ff25777bbe1e2",
      "b69047db6673409ea77d3be42eecc0c3",
      "38ac5233693d49aaa5c5bdc0e8d8c369",
      "966f90d6a9eb4fef98be68528fc26534",
      "ec98b9b2ea6a48469795091805920f00",
      "f6e4552dbd234366a09db818399ac153",
      "eefff4e1f7434c8d8739f7c11d684d7f",
      "d7ac1d0c9cfa484a99eb8aae57b4185e",
      "66d81e5664b7426686533c2ced4f3dab"
     ]
    },
    "id": "graduate-vision",
    "outputId": "3963d430-4d1e-4bf8-e932-c37916f58ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2849] Elapsed 0m 1s (remain 55m 22s) Loss: 0.1936(0.1936) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2849] Elapsed 0m 33s (remain 15m 0s) Loss: 0.0447(0.1449) Grad: 9138.5469  LR: 0.000001  \n",
      "Epoch: [1][200/2849] Elapsed 1m 5s (remain 14m 25s) Loss: 0.0088(0.0876) Grad: 730.5958  LR: 0.000003  \n",
      "Epoch: [1][300/2849] Elapsed 1m 37s (remain 13m 49s) Loss: 0.0130(0.0630) Grad: 568.9602  LR: 0.000004  \n",
      "Epoch: [1][400/2849] Elapsed 2m 9s (remain 13m 13s) Loss: 0.0240(0.0502) Grad: 2976.6287  LR: 0.000006  \n",
      "Epoch: [1][500/2849] Elapsed 2m 42s (remain 12m 40s) Loss: 0.0063(0.0420) Grad: 1213.3868  LR: 0.000007  \n",
      "Epoch: [1][600/2849] Elapsed 3m 14s (remain 12m 7s) Loss: 0.0029(0.0362) Grad: 1033.3453  LR: 0.000008  \n",
      "Epoch: [1][700/2849] Elapsed 3m 46s (remain 11m 34s) Loss: 0.0036(0.0320) Grad: 1467.7467  LR: 0.000010  \n",
      "Epoch: [1][800/2849] Elapsed 4m 19s (remain 11m 3s) Loss: 0.0036(0.0285) Grad: 1528.2101  LR: 0.000011  \n",
      "Epoch: [1][900/2849] Elapsed 4m 52s (remain 10m 31s) Loss: 0.0011(0.0259) Grad: 341.3248  LR: 0.000013  \n",
      "Epoch: [1][1000/2849] Elapsed 5m 24s (remain 9m 59s) Loss: 0.0014(0.0237) Grad: 399.3974  LR: 0.000014  \n",
      "Epoch: [1][1100/2849] Elapsed 5m 56s (remain 9m 26s) Loss: 0.0022(0.0219) Grad: 458.3088  LR: 0.000015  \n",
      "Epoch: [1][1200/2849] Elapsed 6m 29s (remain 8m 54s) Loss: 0.0024(0.0204) Grad: 580.3350  LR: 0.000017  \n",
      "Epoch: [1][1300/2849] Elapsed 7m 3s (remain 8m 24s) Loss: 0.0019(0.0190) Grad: 1374.6476  LR: 0.000018  \n",
      "Epoch: [1][1400/2849] Elapsed 7m 37s (remain 7m 52s) Loss: 0.0023(0.0179) Grad: 427.1913  LR: 0.000020  \n",
      "Epoch: [1][1500/2849] Elapsed 8m 9s (remain 7m 19s) Loss: 0.0165(0.0170) Grad: 3879.7483  LR: 0.000020  \n",
      "Epoch: [1][1600/2849] Elapsed 8m 41s (remain 6m 46s) Loss: 0.0031(0.0161) Grad: 503.8679  LR: 0.000020  \n",
      "Epoch: [1][1700/2849] Elapsed 9m 12s (remain 6m 13s) Loss: 0.0029(0.0153) Grad: 658.9445  LR: 0.000020  \n",
      "Epoch: [1][1800/2849] Elapsed 9m 44s (remain 5m 40s) Loss: 0.0061(0.0146) Grad: 1483.9159  LR: 0.000019  \n",
      "Epoch: [1][1900/2849] Elapsed 10m 16s (remain 5m 7s) Loss: 0.0004(0.0140) Grad: 110.6159  LR: 0.000019  \n",
      "Epoch: [1][2000/2849] Elapsed 10m 48s (remain 4m 34s) Loss: 0.0010(0.0134) Grad: 248.2637  LR: 0.000019  \n",
      "Epoch: [1][2100/2849] Elapsed 11m 20s (remain 4m 2s) Loss: 0.0003(0.0129) Grad: 120.3838  LR: 0.000019  \n",
      "Epoch: [1][2200/2849] Elapsed 11m 54s (remain 3m 30s) Loss: 0.0033(0.0124) Grad: 2633.9070  LR: 0.000019  \n",
      "Epoch: [1][2300/2849] Elapsed 12m 26s (remain 2m 57s) Loss: 0.0023(0.0120) Grad: 341.0246  LR: 0.000019  \n",
      "Epoch: [1][2400/2849] Elapsed 12m 57s (remain 2m 25s) Loss: 0.0029(0.0116) Grad: 394.3810  LR: 0.000018  \n",
      "Epoch: [1][2500/2849] Elapsed 13m 29s (remain 1m 52s) Loss: 0.0000(0.0113) Grad: 18.0125  LR: 0.000018  \n",
      "Epoch: [1][2600/2849] Elapsed 14m 1s (remain 1m 20s) Loss: 0.0005(0.0109) Grad: 83.4559  LR: 0.000018  \n",
      "Epoch: [1][2700/2849] Elapsed 14m 34s (remain 0m 47s) Loss: 0.0058(0.0106) Grad: 650.9833  LR: 0.000018  \n",
      "Epoch: [1][2800/2849] Elapsed 15m 7s (remain 0m 15s) Loss: 0.0022(0.0103) Grad: 706.9055  LR: 0.000018  \n",
      "Epoch: [1][2848/2849] Elapsed 15m 22s (remain 0m 0s) Loss: 0.0008(0.0101) Grad: 127.0871  LR: 0.000018  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 4m 57s) Loss: 0.0007(0.0007) \n",
      "EVAL: [100/726] Elapsed 0m 20s (remain 2m 4s) Loss: 0.0012(0.0018) \n",
      "EVAL: [200/726] Elapsed 0m 40s (remain 1m 45s) Loss: 0.0004(0.0019) \n",
      "EVAL: [300/726] Elapsed 0m 59s (remain 1m 24s) Loss: 0.0012(0.0018) \n",
      "EVAL: [400/726] Elapsed 1m 20s (remain 1m 5s) Loss: 0.0022(0.0022) \n",
      "EVAL: [500/726] Elapsed 1m 41s (remain 0m 45s) Loss: 0.0024(0.0022) \n",
      "EVAL: [600/726] Elapsed 2m 1s (remain 0m 25s) Loss: 0.0011(0.0021) \n",
      "EVAL: [700/726] Elapsed 2m 20s (remain 0m 5s) Loss: 0.0006(0.0020) \n",
      "EVAL: [725/726] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0002(0.0020) \n",
      "Epoch 1 - avg_train_loss: 0.0101  avg_val_loss: 0.0020  time: 1074s\n",
      "Epoch 1 - Score: 0.8334\n",
      "Epoch 1 - Save Best Score: 0.8334 Model\n",
      "Epoch: [2][0/2849] Elapsed 0m 0s (remain 25m 43s) Loss: 0.0010(0.0010) Grad: 2812.1152  LR: 0.000018  \n",
      "Epoch: [2][100/2849] Elapsed 0m 32s (remain 14m 53s) Loss: 0.0010(0.0018) Grad: 2536.4302  LR: 0.000018  \n",
      "Epoch: [2][200/2849] Elapsed 1m 6s (remain 14m 29s) Loss: 0.0001(0.0019) Grad: 559.2919  LR: 0.000017  \n",
      "Epoch: [2][300/2849] Elapsed 1m 39s (remain 13m 58s) Loss: 0.0000(0.0019) Grad: 226.0000  LR: 0.000017  \n",
      "Epoch: [2][400/2849] Elapsed 2m 11s (remain 13m 24s) Loss: 0.0010(0.0018) Grad: 5853.7354  LR: 0.000017  \n",
      "Epoch: [2][500/2849] Elapsed 2m 44s (remain 12m 51s) Loss: 0.0018(0.0018) Grad: 9701.9424  LR: 0.000017  \n",
      "Epoch: [2][600/2849] Elapsed 3m 16s (remain 12m 16s) Loss: 0.0000(0.0018) Grad: 384.8518  LR: 0.000017  \n",
      "Epoch: [2][700/2849] Elapsed 3m 49s (remain 11m 42s) Loss: 0.0001(0.0019) Grad: 862.8840  LR: 0.000017  \n",
      "Epoch: [2][800/2849] Elapsed 4m 22s (remain 11m 10s) Loss: 0.0006(0.0019) Grad: 20652.2227  LR: 0.000017  \n",
      "Epoch: [2][900/2849] Elapsed 4m 55s (remain 10m 38s) Loss: 0.0116(0.0019) Grad: 173789.9531  LR: 0.000016  \n",
      "Epoch: [2][1000/2849] Elapsed 5m 27s (remain 10m 5s) Loss: 0.0012(0.0019) Grad: 10431.0234  LR: 0.000016  \n",
      "Epoch: [2][1100/2849] Elapsed 6m 0s (remain 9m 31s) Loss: 0.0008(0.0019) Grad: 10240.3799  LR: 0.000016  \n",
      "Epoch: [2][1200/2849] Elapsed 6m 33s (remain 8m 59s) Loss: 0.0072(0.0019) Grad: 18577.7793  LR: 0.000016  \n",
      "Epoch: [2][1300/2849] Elapsed 7m 6s (remain 8m 26s) Loss: 0.0023(0.0020) Grad: 16903.0469  LR: 0.000016  \n",
      "Epoch: [2][1400/2849] Elapsed 7m 38s (remain 7m 53s) Loss: 0.0055(0.0020) Grad: 45957.3867  LR: 0.000016  \n",
      "Epoch: [2][1500/2849] Elapsed 8m 11s (remain 7m 21s) Loss: 0.0025(0.0019) Grad: 8477.3701  LR: 0.000015  \n",
      "Epoch: [2][1600/2849] Elapsed 8m 46s (remain 6m 50s) Loss: 0.0005(0.0020) Grad: 3416.8606  LR: 0.000015  \n",
      "Epoch: [2][1700/2849] Elapsed 9m 19s (remain 6m 17s) Loss: 0.0013(0.0020) Grad: 7087.9829  LR: 0.000015  \n",
      "Epoch: [2][1800/2849] Elapsed 9m 51s (remain 5m 44s) Loss: 0.0001(0.0019) Grad: 1428.5693  LR: 0.000015  \n",
      "Epoch: [2][1900/2849] Elapsed 10m 24s (remain 5m 11s) Loss: 0.0034(0.0020) Grad: 40365.7305  LR: 0.000015  \n",
      "Epoch: [2][2000/2849] Elapsed 10m 56s (remain 4m 38s) Loss: 0.0022(0.0019) Grad: 14983.3408  LR: 0.000015  \n",
      "Epoch: [2][2100/2849] Elapsed 11m 29s (remain 4m 5s) Loss: 0.0054(0.0019) Grad: 15654.8330  LR: 0.000014  \n",
      "Epoch: [2][2200/2849] Elapsed 12m 2s (remain 3m 32s) Loss: 0.0001(0.0020) Grad: 742.2848  LR: 0.000014  \n",
      "Epoch: [2][2300/2849] Elapsed 12m 37s (remain 3m 0s) Loss: 0.0063(0.0020) Grad: 34817.7539  LR: 0.000014  \n",
      "Epoch: [2][2400/2849] Elapsed 13m 13s (remain 2m 28s) Loss: 0.0000(0.0019) Grad: 128.6239  LR: 0.000014  \n",
      "Epoch: [2][2500/2849] Elapsed 13m 47s (remain 1m 55s) Loss: 0.0004(0.0019) Grad: 3189.9185  LR: 0.000014  \n",
      "Epoch: [2][2600/2849] Elapsed 14m 19s (remain 1m 21s) Loss: 0.0011(0.0019) Grad: 3604.1990  LR: 0.000014  \n",
      "Epoch: [2][2700/2849] Elapsed 14m 51s (remain 0m 48s) Loss: 0.0005(0.0019) Grad: 2246.9988  LR: 0.000014  \n",
      "Epoch: [2][2800/2849] Elapsed 15m 24s (remain 0m 15s) Loss: 0.0002(0.0019) Grad: 4968.0840  LR: 0.000013  \n",
      "Epoch: [2][2848/2849] Elapsed 15m 39s (remain 0m 0s) Loss: 0.0001(0.0019) Grad: 1462.6752  LR: 0.000013  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 14s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/726] Elapsed 0m 20s (remain 2m 4s) Loss: 0.0019(0.0026) \n",
      "EVAL: [200/726] Elapsed 0m 40s (remain 1m 45s) Loss: 0.0000(0.0026) \n",
      "EVAL: [300/726] Elapsed 1m 0s (remain 1m 24s) Loss: 0.0000(0.0025) \n",
      "EVAL: [400/726] Elapsed 1m 20s (remain 1m 4s) Loss: 0.0036(0.0031) \n",
      "EVAL: [500/726] Elapsed 1m 40s (remain 0m 44s) Loss: 0.0019(0.0030) \n",
      "EVAL: [600/726] Elapsed 2m 0s (remain 0m 25s) Loss: 0.0003(0.0028) \n",
      "EVAL: [700/726] Elapsed 2m 20s (remain 0m 5s) Loss: 0.0001(0.0027) \n",
      "EVAL: [725/726] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0000(0.0027) \n",
      "Epoch 2 - avg_train_loss: 0.0019  avg_val_loss: 0.0027  time: 1091s\n",
      "Epoch 2 - Score: 0.8645\n",
      "Epoch 2 - Save Best Score: 0.8645 Model\n",
      "Epoch: [3][0/2849] Elapsed 0m 0s (remain 27m 11s) Loss: 0.0040(0.0040) Grad: 6055.6948  LR: 0.000013  \n",
      "Epoch: [3][100/2849] Elapsed 0m 33s (remain 14m 58s) Loss: 0.0011(0.0013) Grad: 5945.9937  LR: 0.000013  \n",
      "Epoch: [3][200/2849] Elapsed 1m 5s (remain 14m 19s) Loss: 0.0002(0.0015) Grad: 1464.0302  LR: 0.000013  \n",
      "Epoch: [3][300/2849] Elapsed 1m 39s (remain 13m 59s) Loss: 0.0006(0.0016) Grad: 3734.1008  LR: 0.000013  \n",
      "Epoch: [3][400/2849] Elapsed 2m 11s (remain 13m 25s) Loss: 0.0000(0.0015) Grad: 47.4257  LR: 0.000013  \n",
      "Epoch: [3][500/2849] Elapsed 2m 44s (remain 12m 49s) Loss: 0.0001(0.0015) Grad: 575.7167  LR: 0.000013  \n",
      "Epoch: [3][600/2849] Elapsed 3m 16s (remain 12m 16s) Loss: 0.0045(0.0015) Grad: 15929.9326  LR: 0.000012  \n",
      "Epoch: [3][700/2849] Elapsed 3m 50s (remain 11m 44s) Loss: 0.0052(0.0016) Grad: 24869.3320  LR: 0.000012  \n",
      "Epoch: [3][800/2849] Elapsed 4m 23s (remain 11m 14s) Loss: 0.0048(0.0016) Grad: 27613.3145  LR: 0.000012  \n",
      "Epoch: [3][900/2849] Elapsed 4m 55s (remain 10m 39s) Loss: 0.0042(0.0015) Grad: 29301.4141  LR: 0.000012  \n",
      "Epoch: [3][1000/2849] Elapsed 5m 28s (remain 10m 5s) Loss: 0.0000(0.0015) Grad: 118.8221  LR: 0.000012  \n",
      "Epoch: [3][1100/2849] Elapsed 6m 0s (remain 9m 32s) Loss: 0.0000(0.0016) Grad: 68.8645  LR: 0.000012  \n",
      "Epoch: [3][1200/2849] Elapsed 6m 32s (remain 8m 59s) Loss: 0.0016(0.0016) Grad: 10303.6621  LR: 0.000011  \n",
      "Epoch: [3][1300/2849] Elapsed 7m 5s (remain 8m 25s) Loss: 0.0088(0.0016) Grad: 17335.0449  LR: 0.000011  \n",
      "Epoch: [3][1400/2849] Elapsed 7m 38s (remain 7m 54s) Loss: 0.0004(0.0016) Grad: 2913.4121  LR: 0.000011  \n",
      "Epoch: [3][1500/2849] Elapsed 8m 13s (remain 7m 22s) Loss: 0.0030(0.0016) Grad: 7229.7891  LR: 0.000011  \n",
      "Epoch: [3][1600/2849] Elapsed 8m 45s (remain 6m 49s) Loss: 0.0015(0.0016) Grad: 19800.7969  LR: 0.000011  \n",
      "Epoch: [3][1700/2849] Elapsed 9m 18s (remain 6m 16s) Loss: 0.0049(0.0016) Grad: 24148.0918  LR: 0.000011  \n",
      "Epoch: [3][1800/2849] Elapsed 9m 50s (remain 5m 43s) Loss: 0.0001(0.0015) Grad: 2720.8933  LR: 0.000011  \n",
      "Epoch: [3][1900/2849] Elapsed 10m 23s (remain 5m 11s) Loss: 0.0002(0.0015) Grad: 2691.5596  LR: 0.000010  \n",
      "Epoch: [3][2000/2849] Elapsed 10m 56s (remain 4m 38s) Loss: 0.0028(0.0016) Grad: 6089.6450  LR: 0.000010  \n",
      "Epoch: [3][2100/2849] Elapsed 11m 28s (remain 4m 5s) Loss: 0.0004(0.0016) Grad: 1948.6467  LR: 0.000010  \n",
      "Epoch: [3][2200/2849] Elapsed 12m 1s (remain 3m 32s) Loss: 0.0004(0.0016) Grad: 2755.9712  LR: 0.000010  \n",
      "Epoch: [3][2300/2849] Elapsed 12m 33s (remain 2m 59s) Loss: 0.0031(0.0015) Grad: 16121.7178  LR: 0.000010  \n",
      "Epoch: [3][2400/2849] Elapsed 13m 6s (remain 2m 26s) Loss: 0.0002(0.0015) Grad: 4127.0620  LR: 0.000010  \n",
      "Epoch: [3][2500/2849] Elapsed 13m 39s (remain 1m 53s) Loss: 0.0026(0.0015) Grad: 26945.0898  LR: 0.000009  \n",
      "Epoch: [3][2600/2849] Elapsed 14m 11s (remain 1m 21s) Loss: 0.0012(0.0015) Grad: 10012.6914  LR: 0.000009  \n",
      "Epoch: [3][2700/2849] Elapsed 14m 43s (remain 0m 48s) Loss: 0.0023(0.0015) Grad: 13740.4043  LR: 0.000009  \n",
      "Epoch: [3][2800/2849] Elapsed 15m 15s (remain 0m 15s) Loss: 0.0029(0.0015) Grad: 16414.0957  LR: 0.000009  \n",
      "Epoch: [3][2848/2849] Elapsed 15m 31s (remain 0m 0s) Loss: 0.0007(0.0015) Grad: 4908.2666  LR: 0.000009  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 4s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/726] Elapsed 0m 20s (remain 2m 5s) Loss: 0.0008(0.0032) \n",
      "EVAL: [200/726] Elapsed 0m 40s (remain 1m 45s) Loss: 0.0000(0.0030) \n",
      "EVAL: [300/726] Elapsed 1m 0s (remain 1m 25s) Loss: 0.0000(0.0028) \n",
      "EVAL: [400/726] Elapsed 1m 20s (remain 1m 5s) Loss: 0.0029(0.0036) \n",
      "EVAL: [500/726] Elapsed 1m 40s (remain 0m 45s) Loss: 0.0016(0.0035) \n",
      "EVAL: [600/726] Elapsed 2m 0s (remain 0m 25s) Loss: 0.0007(0.0032) \n",
      "EVAL: [700/726] Elapsed 2m 20s (remain 0m 5s) Loss: 0.0004(0.0031) \n",
      "EVAL: [725/726] Elapsed 2m 25s (remain 0m 0s) Loss: 0.0000(0.0030) \n",
      "Epoch 3 - avg_train_loss: 0.0015  avg_val_loss: 0.0030  time: 1082s\n",
      "Epoch 3 - Score: 0.8716\n",
      "Epoch 3 - Save Best Score: 0.8716 Model\n",
      "Epoch: [4][0/2849] Elapsed 0m 0s (remain 29m 31s) Loss: 0.0014(0.0014) Grad: 11750.1973  LR: 0.000009  \n",
      "Epoch: [4][100/2849] Elapsed 0m 33s (remain 15m 10s) Loss: 0.0000(0.0011) Grad: 433.8919  LR: 0.000009  \n",
      "Epoch: [4][200/2849] Elapsed 1m 5s (remain 14m 23s) Loss: 0.0001(0.0011) Grad: 1000.9788  LR: 0.000009  \n",
      "Epoch: [4][300/2849] Elapsed 1m 38s (remain 13m 54s) Loss: 0.0075(0.0011) Grad: 39005.7656  LR: 0.000008  \n",
      "Epoch: [4][400/2849] Elapsed 2m 11s (remain 13m 21s) Loss: 0.0002(0.0012) Grad: 3047.5830  LR: 0.000008  \n",
      "Epoch: [4][500/2849] Elapsed 2m 43s (remain 12m 47s) Loss: 0.0035(0.0012) Grad: 14688.8145  LR: 0.000008  \n",
      "Epoch: [4][600/2849] Elapsed 3m 16s (remain 12m 14s) Loss: 0.0018(0.0013) Grad: 12633.9971  LR: 0.000008  \n",
      "Epoch: [4][700/2849] Elapsed 3m 48s (remain 11m 41s) Loss: 0.0023(0.0013) Grad: 3204.2354  LR: 0.000008  \n",
      "Epoch: [4][800/2849] Elapsed 4m 22s (remain 11m 10s) Loss: 0.0008(0.0014) Grad: 5018.0747  LR: 0.000008  \n",
      "Epoch: [4][900/2849] Elapsed 4m 55s (remain 10m 38s) Loss: 0.0000(0.0014) Grad: 272.7022  LR: 0.000007  \n",
      "Epoch: [4][1000/2849] Elapsed 5m 27s (remain 10m 5s) Loss: 0.0009(0.0014) Grad: 3830.1326  LR: 0.000007  \n",
      "Epoch: [4][1100/2849] Elapsed 6m 0s (remain 9m 31s) Loss: 0.0005(0.0014) Grad: 3857.6970  LR: 0.000007  \n",
      "Epoch: [4][1200/2849] Elapsed 6m 32s (remain 8m 58s) Loss: 0.0030(0.0014) Grad: 18569.1426  LR: 0.000007  \n",
      "Epoch: [4][1300/2849] Elapsed 7m 4s (remain 8m 25s) Loss: 0.0022(0.0013) Grad: 11067.0303  LR: 0.000007  \n",
      "Epoch: [4][1400/2849] Elapsed 7m 37s (remain 7m 52s) Loss: 0.0043(0.0013) Grad: 56807.1406  LR: 0.000007  \n",
      "Epoch: [4][1500/2849] Elapsed 8m 9s (remain 7m 19s) Loss: 0.0002(0.0013) Grad: 1114.2135  LR: 0.000007  \n",
      "Epoch: [4][1600/2849] Elapsed 8m 42s (remain 6m 46s) Loss: 0.0001(0.0013) Grad: 445.3803  LR: 0.000006  \n",
      "Epoch: [4][1700/2849] Elapsed 9m 15s (remain 6m 14s) Loss: 0.0002(0.0013) Grad: 1893.8392  LR: 0.000006  \n",
      "Epoch: [4][1800/2849] Elapsed 9m 48s (remain 5m 42s) Loss: 0.0003(0.0013) Grad: 12524.7119  LR: 0.000006  \n",
      "Epoch: [4][1900/2849] Elapsed 10m 20s (remain 5m 9s) Loss: 0.0000(0.0013) Grad: 71.4138  LR: 0.000006  \n",
      "Epoch: [4][2000/2849] Elapsed 10m 53s (remain 4m 36s) Loss: 0.0001(0.0013) Grad: 1529.7289  LR: 0.000006  \n",
      "Epoch: [4][2100/2849] Elapsed 11m 25s (remain 4m 3s) Loss: 0.0005(0.0013) Grad: 3715.9529  LR: 0.000006  \n",
      "Epoch: [4][2200/2849] Elapsed 11m 58s (remain 3m 31s) Loss: 0.0022(0.0013) Grad: 12002.0908  LR: 0.000005  \n",
      "Epoch: [4][2300/2849] Elapsed 12m 30s (remain 2m 58s) Loss: 0.0022(0.0013) Grad: 28328.2324  LR: 0.000005  \n",
      "Epoch: [4][2400/2849] Elapsed 13m 3s (remain 2m 26s) Loss: 0.0003(0.0013) Grad: 5425.0884  LR: 0.000005  \n",
      "Epoch: [4][2500/2849] Elapsed 13m 36s (remain 1m 53s) Loss: 0.0034(0.0013) Grad: 24863.2168  LR: 0.000005  \n",
      "Epoch: [4][2600/2849] Elapsed 14m 9s (remain 1m 20s) Loss: 0.0008(0.0013) Grad: 8161.4473  LR: 0.000005  \n",
      "Epoch: [4][2700/2849] Elapsed 14m 41s (remain 0m 48s) Loss: 0.0000(0.0013) Grad: 91.1207  LR: 0.000005  \n",
      "Epoch: [4][2800/2849] Elapsed 15m 14s (remain 0m 15s) Loss: 0.0001(0.0013) Grad: 1404.9260  LR: 0.000005  \n",
      "Epoch: [4][2848/2849] Elapsed 15m 29s (remain 0m 0s) Loss: 0.0013(0.0013) Grad: 18141.0605  LR: 0.000004  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 9s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/726] Elapsed 0m 20s (remain 2m 4s) Loss: 0.0005(0.0033) \n",
      "EVAL: [200/726] Elapsed 0m 40s (remain 1m 46s) Loss: 0.0000(0.0030) \n",
      "EVAL: [300/726] Elapsed 1m 0s (remain 1m 25s) Loss: 0.0000(0.0029) \n",
      "EVAL: [400/726] Elapsed 1m 20s (remain 1m 5s) Loss: 0.0022(0.0037) \n",
      "EVAL: [500/726] Elapsed 1m 40s (remain 0m 45s) Loss: 0.0026(0.0037) \n",
      "EVAL: [600/726] Elapsed 2m 1s (remain 0m 25s) Loss: 0.0008(0.0034) \n",
      "EVAL: [700/726] Elapsed 2m 21s (remain 0m 5s) Loss: 0.0001(0.0033) \n",
      "EVAL: [725/726] Elapsed 2m 26s (remain 0m 0s) Loss: 0.0000(0.0032) \n",
      "Epoch 4 - avg_train_loss: 0.0013  avg_val_loss: 0.0032  time: 1081s\n",
      "Epoch 4 - Score: 0.8710\n",
      "Epoch: [5][0/2849] Elapsed 0m 0s (remain 26m 21s) Loss: 0.0000(0.0000) Grad: 996.2787  LR: 0.000004  \n",
      "Epoch: [5][100/2849] Elapsed 0m 33s (remain 15m 4s) Loss: 0.0000(0.0015) Grad: 64.0851  LR: 0.000004  \n",
      "Epoch: [5][200/2849] Elapsed 1m 6s (remain 14m 35s) Loss: 0.0014(0.0015) Grad: 12011.6758  LR: 0.000004  \n",
      "Epoch: [5][300/2849] Elapsed 1m 39s (remain 14m 0s) Loss: 0.0049(0.0014) Grad: 17736.5781  LR: 0.000004  \n",
      "Epoch: [5][400/2849] Elapsed 2m 11s (remain 13m 22s) Loss: 0.0000(0.0012) Grad: 8.7163  LR: 0.000004  \n",
      "Epoch: [5][500/2849] Elapsed 2m 44s (remain 12m 52s) Loss: 0.0000(0.0012) Grad: 359.1134  LR: 0.000004  \n",
      "Epoch: [5][600/2849] Elapsed 3m 17s (remain 12m 17s) Loss: 0.0000(0.0011) Grad: 314.4785  LR: 0.000004  \n",
      "Epoch: [5][700/2849] Elapsed 3m 49s (remain 11m 43s) Loss: 0.0001(0.0011) Grad: 2086.8220  LR: 0.000003  \n",
      "Epoch: [5][800/2849] Elapsed 4m 21s (remain 11m 9s) Loss: 0.0001(0.0011) Grad: 1812.0459  LR: 0.000003  \n",
      "Epoch: [5][900/2849] Elapsed 4m 53s (remain 10m 35s) Loss: 0.0005(0.0012) Grad: 3129.1060  LR: 0.000003  \n",
      "Epoch: [5][1000/2849] Elapsed 5m 26s (remain 10m 2s) Loss: 0.0000(0.0011) Grad: 36.3420  LR: 0.000003  \n",
      "Epoch: [5][1100/2849] Elapsed 5m 59s (remain 9m 30s) Loss: 0.0008(0.0011) Grad: 10072.2822  LR: 0.000003  \n",
      "Epoch: [5][1200/2849] Elapsed 6m 32s (remain 8m 57s) Loss: 0.0012(0.0011) Grad: 7846.3066  LR: 0.000003  \n",
      "Epoch: [5][1300/2849] Elapsed 7m 4s (remain 8m 25s) Loss: 0.0000(0.0011) Grad: 415.7144  LR: 0.000002  \n",
      "Epoch: [5][1400/2849] Elapsed 7m 36s (remain 7m 51s) Loss: 0.0009(0.0011) Grad: 6315.9824  LR: 0.000002  \n",
      "Epoch: [5][1500/2849] Elapsed 8m 8s (remain 7m 18s) Loss: 0.0001(0.0011) Grad: 1136.6647  LR: 0.000002  \n",
      "Epoch: [5][1600/2849] Elapsed 8m 41s (remain 6m 46s) Loss: 0.0011(0.0011) Grad: 15576.7832  LR: 0.000002  \n",
      "Epoch: [5][1700/2849] Elapsed 9m 14s (remain 6m 14s) Loss: 0.0008(0.0011) Grad: 10488.1914  LR: 0.000002  \n",
      "Epoch: [5][1800/2849] Elapsed 9m 47s (remain 5m 41s) Loss: 0.0000(0.0011) Grad: 473.3369  LR: 0.000002  \n",
      "Epoch: [5][1900/2849] Elapsed 10m 19s (remain 5m 8s) Loss: 0.0000(0.0011) Grad: 673.7538  LR: 0.000001  \n",
      "Epoch: [5][2000/2849] Elapsed 10m 51s (remain 4m 36s) Loss: 0.0000(0.0011) Grad: 91.9925  LR: 0.000001  \n",
      "Epoch: [5][2100/2849] Elapsed 11m 23s (remain 4m 3s) Loss: 0.0005(0.0011) Grad: 3379.4631  LR: 0.000001  \n",
      "Epoch: [5][2200/2849] Elapsed 11m 55s (remain 3m 30s) Loss: 0.0007(0.0011) Grad: 21694.4316  LR: 0.000001  \n",
      "Epoch: [5][2300/2849] Elapsed 12m 28s (remain 2m 58s) Loss: 0.0000(0.0011) Grad: 560.2730  LR: 0.000001  \n",
      "Epoch: [5][2400/2849] Elapsed 13m 3s (remain 2m 26s) Loss: 0.0000(0.0011) Grad: 14.1181  LR: 0.000001  \n",
      "Epoch: [5][2500/2849] Elapsed 13m 35s (remain 1m 53s) Loss: 0.0001(0.0011) Grad: 1058.6953  LR: 0.000001  \n",
      "Epoch: [5][2600/2849] Elapsed 14m 7s (remain 1m 20s) Loss: 0.0000(0.0011) Grad: 41.5408  LR: 0.000000  \n",
      "Epoch: [5][2700/2849] Elapsed 14m 40s (remain 0m 48s) Loss: 0.0000(0.0011) Grad: 295.4924  LR: 0.000000  \n",
      "Epoch: [5][2800/2849] Elapsed 15m 12s (remain 0m 15s) Loss: 0.0004(0.0011) Grad: 9234.2891  LR: 0.000000  \n",
      "Epoch: [5][2848/2849] Elapsed 15m 27s (remain 0m 0s) Loss: 0.0049(0.0011) Grad: 4735.6001  LR: 0.000000  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 35s) Loss: 0.0001(0.0001) \n",
      "EVAL: [100/726] Elapsed 0m 20s (remain 2m 7s) Loss: 0.0006(0.0034) \n",
      "EVAL: [200/726] Elapsed 0m 40s (remain 1m 46s) Loss: 0.0000(0.0032) \n",
      "EVAL: [300/726] Elapsed 1m 0s (remain 1m 25s) Loss: 0.0000(0.0031) \n",
      "EVAL: [400/726] Elapsed 1m 20s (remain 1m 5s) Loss: 0.0027(0.0038) \n",
      "EVAL: [500/726] Elapsed 1m 41s (remain 0m 45s) Loss: 0.0064(0.0037) \n",
      "EVAL: [600/726] Elapsed 2m 1s (remain 0m 25s) Loss: 0.0010(0.0035) \n",
      "EVAL: [700/726] Elapsed 2m 21s (remain 0m 5s) Loss: 0.0002(0.0033) \n",
      "EVAL: [725/726] Elapsed 2m 26s (remain 0m 0s) Loss: 0.0000(0.0033) \n",
      "Epoch 5 - avg_train_loss: 0.0011  avg_val_loss: 0.0033  time: 1080s\n",
      "Epoch 5 - Score: 0.8723\n",
      "Epoch 5 - Save Best Score: 0.8723 Model\n",
      "========== fold: 1 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2851] Elapsed 0m 0s (remain 27m 14s) Loss: 0.1059(0.1059) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2851] Elapsed 0m 34s (remain 15m 31s) Loss: 0.0465(0.1010) Grad: 18607.1230  LR: 0.000001  \n",
      "Epoch: [1][200/2851] Elapsed 1m 6s (remain 14m 40s) Loss: 0.0099(0.0629) Grad: 865.9667  LR: 0.000003  \n",
      "Epoch: [1][300/2851] Elapsed 1m 39s (remain 13m 58s) Loss: 0.0180(0.0464) Grad: 2404.4170  LR: 0.000004  \n",
      "Epoch: [1][400/2851] Elapsed 2m 11s (remain 13m 22s) Loss: 0.0067(0.0383) Grad: 865.2833  LR: 0.000006  \n",
      "Epoch: [1][500/2851] Elapsed 2m 43s (remain 12m 46s) Loss: 0.0130(0.0333) Grad: 1213.4725  LR: 0.000007  \n",
      "Epoch: [1][600/2851] Elapsed 3m 16s (remain 12m 15s) Loss: 0.0053(0.0294) Grad: 1401.1307  LR: 0.000008  \n",
      "Epoch: [1][700/2851] Elapsed 3m 49s (remain 11m 43s) Loss: 0.0021(0.0263) Grad: 1447.5074  LR: 0.000010  \n",
      "Epoch: [1][800/2851] Elapsed 4m 23s (remain 11m 15s) Loss: 0.0058(0.0238) Grad: 2808.5391  LR: 0.000011  \n",
      "Epoch: [1][900/2851] Elapsed 4m 56s (remain 10m 41s) Loss: 0.0083(0.0218) Grad: 2905.5806  LR: 0.000013  \n",
      "Epoch: [1][1000/2851] Elapsed 5m 28s (remain 10m 7s) Loss: 0.0033(0.0200) Grad: 1438.7670  LR: 0.000014  \n",
      "Epoch: [1][1100/2851] Elapsed 6m 0s (remain 9m 33s) Loss: 0.0045(0.0186) Grad: 4293.5894  LR: 0.000015  \n",
      "Epoch: [1][1200/2851] Elapsed 6m 33s (remain 9m 0s) Loss: 0.0072(0.0173) Grad: 3637.3418  LR: 0.000017  \n",
      "Epoch: [1][1300/2851] Elapsed 7m 5s (remain 8m 27s) Loss: 0.0142(0.0163) Grad: 4329.4658  LR: 0.000018  \n",
      "Epoch: [1][1400/2851] Elapsed 7m 38s (remain 7m 54s) Loss: 0.0023(0.0154) Grad: 1105.5070  LR: 0.000020  \n",
      "Epoch: [1][1500/2851] Elapsed 8m 10s (remain 7m 21s) Loss: 0.0051(0.0146) Grad: 3505.3171  LR: 0.000020  \n",
      "Epoch: [1][1600/2851] Elapsed 8m 43s (remain 6m 48s) Loss: 0.0024(0.0139) Grad: 1724.1813  LR: 0.000020  \n",
      "Epoch: [1][1700/2851] Elapsed 9m 16s (remain 6m 15s) Loss: 0.0026(0.0133) Grad: 1724.1859  LR: 0.000020  \n",
      "Epoch: [1][1800/2851] Elapsed 9m 48s (remain 5m 43s) Loss: 0.0006(0.0127) Grad: 328.8942  LR: 0.000019  \n",
      "Epoch: [1][1900/2851] Elapsed 10m 20s (remain 5m 10s) Loss: 0.0057(0.0122) Grad: 3220.4424  LR: 0.000019  \n",
      "Epoch: [1][2000/2851] Elapsed 10m 53s (remain 4m 37s) Loss: 0.0004(0.0117) Grad: 642.1007  LR: 0.000019  \n",
      "Epoch: [1][2100/2851] Elapsed 11m 26s (remain 4m 5s) Loss: 0.0011(0.0113) Grad: 318.7077  LR: 0.000019  \n",
      "Epoch: [1][2200/2851] Elapsed 11m 58s (remain 3m 32s) Loss: 0.0001(0.0109) Grad: 89.9867  LR: 0.000019  \n",
      "Epoch: [1][2300/2851] Elapsed 12m 30s (remain 2m 59s) Loss: 0.0022(0.0106) Grad: 607.4379  LR: 0.000019  \n",
      "Epoch: [1][2400/2851] Elapsed 13m 2s (remain 2m 26s) Loss: 0.0038(0.0103) Grad: 921.3024  LR: 0.000018  \n",
      "Epoch: [1][2500/2851] Elapsed 13m 35s (remain 1m 54s) Loss: 0.0042(0.0100) Grad: 4801.7163  LR: 0.000018  \n",
      "Epoch: [1][2600/2851] Elapsed 14m 6s (remain 1m 21s) Loss: 0.0007(0.0097) Grad: 332.3725  LR: 0.000018  \n",
      "Epoch: [1][2700/2851] Elapsed 14m 38s (remain 0m 48s) Loss: 0.0014(0.0094) Grad: 408.6241  LR: 0.000018  \n",
      "Epoch: [1][2800/2851] Elapsed 15m 10s (remain 0m 16s) Loss: 0.0040(0.0092) Grad: 2624.6868  LR: 0.000018  \n",
      "Epoch: [1][2850/2851] Elapsed 15m 26s (remain 0m 0s) Loss: 0.0023(0.0091) Grad: 866.6807  LR: 0.000018  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 14s) Loss: 0.0003(0.0003) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0007(0.0021) \n",
      "EVAL: [200/724] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0001(0.0024) \n",
      "EVAL: [300/724] Elapsed 1m 2s (remain 1m 27s) Loss: 0.0001(0.0022) \n",
      "EVAL: [400/724] Elapsed 1m 22s (remain 1m 6s) Loss: 0.0000(0.0022) \n",
      "EVAL: [500/724] Elapsed 1m 42s (remain 0m 45s) Loss: 0.0014(0.0024) \n",
      "EVAL: [600/724] Elapsed 2m 2s (remain 0m 25s) Loss: 0.0011(0.0024) \n",
      "EVAL: [700/724] Elapsed 2m 22s (remain 0m 4s) Loss: 0.0000(0.0022) \n",
      "EVAL: [723/724] Elapsed 2m 26s (remain 0m 0s) Loss: 0.0002(0.0021) \n",
      "Epoch 1 - avg_train_loss: 0.0091  avg_val_loss: 0.0021  time: 1078s\n",
      "Epoch 1 - Score: 0.8514\n",
      "Epoch 1 - Save Best Score: 0.8514 Model\n",
      "Epoch: [2][0/2851] Elapsed 0m 0s (remain 26m 51s) Loss: 0.0011(0.0011) Grad: 5739.1201  LR: 0.000018  \n",
      "Epoch: [2][100/2851] Elapsed 0m 33s (remain 15m 18s) Loss: 0.0009(0.0016) Grad: 3208.4387  LR: 0.000018  \n",
      "Epoch: [2][200/2851] Elapsed 1m 6s (remain 14m 38s) Loss: 0.0001(0.0022) Grad: 1606.6235  LR: 0.000017  \n",
      "Epoch: [2][300/2851] Elapsed 1m 39s (remain 14m 0s) Loss: 0.0003(0.0020) Grad: 1612.2166  LR: 0.000017  \n",
      "Epoch: [2][400/2851] Elapsed 2m 11s (remain 13m 24s) Loss: 0.0004(0.0021) Grad: 2145.7898  LR: 0.000017  \n",
      "Epoch: [2][500/2851] Elapsed 2m 43s (remain 12m 49s) Loss: 0.0011(0.0021) Grad: 4416.7437  LR: 0.000017  \n",
      "Epoch: [2][600/2851] Elapsed 3m 16s (remain 12m 14s) Loss: 0.0040(0.0021) Grad: 21069.0488  LR: 0.000017  \n",
      "Epoch: [2][700/2851] Elapsed 3m 49s (remain 11m 42s) Loss: 0.0010(0.0022) Grad: 5456.2212  LR: 0.000017  \n",
      "Epoch: [2][800/2851] Elapsed 4m 22s (remain 11m 12s) Loss: 0.0022(0.0022) Grad: 10872.3623  LR: 0.000017  \n",
      "Epoch: [2][900/2851] Elapsed 4m 56s (remain 10m 41s) Loss: 0.0009(0.0021) Grad: 6791.3252  LR: 0.000016  \n",
      "Epoch: [2][1000/2851] Elapsed 5m 29s (remain 10m 8s) Loss: 0.0034(0.0021) Grad: 18522.7324  LR: 0.000016  \n",
      "Epoch: [2][1100/2851] Elapsed 6m 2s (remain 9m 36s) Loss: 0.0002(0.0021) Grad: 1002.4871  LR: 0.000016  \n",
      "Epoch: [2][1200/2851] Elapsed 6m 35s (remain 9m 3s) Loss: 0.0001(0.0021) Grad: 950.9404  LR: 0.000016  \n",
      "Epoch: [2][1300/2851] Elapsed 7m 8s (remain 8m 30s) Loss: 0.0017(0.0021) Grad: 8094.1870  LR: 0.000016  \n",
      "Epoch: [2][1400/2851] Elapsed 7m 41s (remain 7m 57s) Loss: 0.0004(0.0021) Grad: 3286.7722  LR: 0.000016  \n",
      "Epoch: [2][1500/2851] Elapsed 8m 13s (remain 7m 24s) Loss: 0.0024(0.0021) Grad: 7769.8965  LR: 0.000015  \n",
      "Epoch: [2][1600/2851] Elapsed 8m 46s (remain 6m 51s) Loss: 0.0015(0.0021) Grad: 8116.6636  LR: 0.000015  \n",
      "Epoch: [2][1700/2851] Elapsed 9m 19s (remain 6m 18s) Loss: 0.0026(0.0021) Grad: 10447.1484  LR: 0.000015  \n",
      "Epoch: [2][1800/2851] Elapsed 9m 53s (remain 5m 45s) Loss: 0.0001(0.0021) Grad: 2056.1621  LR: 0.000015  \n",
      "Epoch: [2][1900/2851] Elapsed 10m 25s (remain 5m 12s) Loss: 0.0031(0.0021) Grad: 17858.8809  LR: 0.000015  \n",
      "Epoch: [2][2000/2851] Elapsed 10m 58s (remain 4m 39s) Loss: 0.0003(0.0020) Grad: 2111.3376  LR: 0.000015  \n",
      "Epoch: [2][2100/2851] Elapsed 11m 30s (remain 4m 6s) Loss: 0.0013(0.0020) Grad: 3347.8301  LR: 0.000015  \n",
      "Epoch: [2][2200/2851] Elapsed 12m 2s (remain 3m 33s) Loss: 0.0018(0.0020) Grad: 7247.0371  LR: 0.000014  \n",
      "Epoch: [2][2300/2851] Elapsed 12m 36s (remain 3m 0s) Loss: 0.0016(0.0020) Grad: 21836.0801  LR: 0.000014  \n",
      "Epoch: [2][2400/2851] Elapsed 13m 12s (remain 2m 28s) Loss: 0.0000(0.0020) Grad: 115.1790  LR: 0.000014  \n",
      "Epoch: [2][2500/2851] Elapsed 13m 45s (remain 1m 55s) Loss: 0.0055(0.0020) Grad: 21319.0254  LR: 0.000014  \n",
      "Epoch: [2][2600/2851] Elapsed 14m 17s (remain 1m 22s) Loss: 0.0016(0.0020) Grad: 8531.8506  LR: 0.000014  \n",
      "Epoch: [2][2700/2851] Elapsed 14m 50s (remain 0m 49s) Loss: 0.0019(0.0020) Grad: 11173.5420  LR: 0.000014  \n",
      "Epoch: [2][2800/2851] Elapsed 15m 23s (remain 0m 16s) Loss: 0.0014(0.0020) Grad: 8071.5415  LR: 0.000013  \n",
      "Epoch: [2][2850/2851] Elapsed 15m 39s (remain 0m 0s) Loss: 0.0003(0.0020) Grad: 1911.7074  LR: 0.000013  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 19s) Loss: 0.0003(0.0003) \n",
      "EVAL: [100/724] Elapsed 0m 20s (remain 2m 8s) Loss: 0.0019(0.0027) \n",
      "EVAL: [200/724] Elapsed 0m 41s (remain 1m 48s) Loss: 0.0000(0.0029) \n",
      "EVAL: [300/724] Elapsed 1m 1s (remain 1m 27s) Loss: 0.0000(0.0027) \n",
      "EVAL: [400/724] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0000(0.0027) \n",
      "EVAL: [500/724] Elapsed 1m 43s (remain 0m 46s) Loss: 0.0057(0.0033) \n",
      "EVAL: [600/724] Elapsed 2m 3s (remain 0m 25s) Loss: 0.0002(0.0031) \n",
      "EVAL: [700/724] Elapsed 2m 23s (remain 0m 4s) Loss: 0.0000(0.0028) \n",
      "EVAL: [723/724] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0000(0.0028) \n",
      "Epoch 2 - avg_train_loss: 0.0020  avg_val_loss: 0.0028  time: 1093s\n",
      "Epoch 2 - Score: 0.8728\n",
      "Epoch 2 - Save Best Score: 0.8728 Model\n",
      "Epoch: [3][0/2851] Elapsed 0m 0s (remain 30m 40s) Loss: 0.0003(0.0003) Grad: 6402.5327  LR: 0.000013  \n",
      "Epoch: [3][100/2851] Elapsed 0m 34s (remain 15m 52s) Loss: 0.0006(0.0019) Grad: 3169.7190  LR: 0.000013  \n",
      "Epoch: [3][200/2851] Elapsed 1m 7s (remain 14m 53s) Loss: 0.0000(0.0017) Grad: 161.6941  LR: 0.000013  \n",
      "Epoch: [3][300/2851] Elapsed 1m 40s (remain 14m 7s) Loss: 0.0001(0.0016) Grad: 1278.4730  LR: 0.000013  \n",
      "Epoch: [3][400/2851] Elapsed 2m 12s (remain 13m 29s) Loss: 0.0000(0.0017) Grad: 173.7828  LR: 0.000013  \n",
      "Epoch: [3][500/2851] Elapsed 2m 44s (remain 12m 52s) Loss: 0.0014(0.0017) Grad: 6596.6357  LR: 0.000013  \n",
      "Epoch: [3][600/2851] Elapsed 3m 17s (remain 12m 17s) Loss: 0.0002(0.0018) Grad: 1415.2795  LR: 0.000012  \n",
      "Epoch: [3][700/2851] Elapsed 3m 49s (remain 11m 43s) Loss: 0.0017(0.0018) Grad: 8250.4502  LR: 0.000012  \n",
      "Epoch: [3][800/2851] Elapsed 4m 23s (remain 11m 13s) Loss: 0.0162(0.0018) Grad: 49581.8281  LR: 0.000012  \n",
      "Epoch: [3][900/2851] Elapsed 4m 58s (remain 10m 46s) Loss: 0.0017(0.0018) Grad: 10635.7227  LR: 0.000012  \n",
      "Epoch: [3][1000/2851] Elapsed 5m 31s (remain 10m 11s) Loss: 0.0010(0.0017) Grad: 8866.3838  LR: 0.000012  \n",
      "Epoch: [3][1100/2851] Elapsed 6m 3s (remain 9m 37s) Loss: 0.0003(0.0017) Grad: 1380.1863  LR: 0.000012  \n",
      "Epoch: [3][1200/2851] Elapsed 6m 35s (remain 9m 3s) Loss: 0.0003(0.0017) Grad: 3009.5938  LR: 0.000011  \n",
      "Epoch: [3][1300/2851] Elapsed 7m 8s (remain 8m 30s) Loss: 0.0000(0.0017) Grad: 240.5679  LR: 0.000011  \n",
      "Epoch: [3][1400/2851] Elapsed 7m 41s (remain 7m 57s) Loss: 0.0009(0.0017) Grad: 2660.1409  LR: 0.000011  \n",
      "Epoch: [3][1500/2851] Elapsed 8m 13s (remain 7m 24s) Loss: 0.0015(0.0017) Grad: 2688.8037  LR: 0.000011  \n",
      "Epoch: [3][1600/2851] Elapsed 8m 46s (remain 6m 50s) Loss: 0.0014(0.0017) Grad: 31805.3145  LR: 0.000011  \n",
      "Epoch: [3][1700/2851] Elapsed 9m 18s (remain 6m 17s) Loss: 0.0004(0.0017) Grad: 4220.8760  LR: 0.000011  \n",
      "Epoch: [3][1800/2851] Elapsed 9m 50s (remain 5m 44s) Loss: 0.0010(0.0017) Grad: 4387.3853  LR: 0.000011  \n",
      "Epoch: [3][1900/2851] Elapsed 10m 23s (remain 5m 11s) Loss: 0.0003(0.0017) Grad: 8758.8066  LR: 0.000010  \n",
      "Epoch: [3][2000/2851] Elapsed 10m 56s (remain 4m 39s) Loss: 0.0029(0.0017) Grad: 28263.3594  LR: 0.000010  \n",
      "Epoch: [3][2100/2851] Elapsed 11m 29s (remain 4m 6s) Loss: 0.0016(0.0017) Grad: 5403.8999  LR: 0.000010  \n",
      "Epoch: [3][2200/2851] Elapsed 12m 1s (remain 3m 33s) Loss: 0.0005(0.0017) Grad: 4155.5435  LR: 0.000010  \n",
      "Epoch: [3][2300/2851] Elapsed 12m 34s (remain 3m 0s) Loss: 0.0010(0.0017) Grad: 3758.3271  LR: 0.000010  \n",
      "Epoch: [3][2400/2851] Elapsed 13m 7s (remain 2m 27s) Loss: 0.0001(0.0017) Grad: 1258.4927  LR: 0.000010  \n",
      "Epoch: [3][2500/2851] Elapsed 13m 40s (remain 1m 54s) Loss: 0.0014(0.0017) Grad: 26114.0645  LR: 0.000009  \n",
      "Epoch: [3][2600/2851] Elapsed 14m 12s (remain 1m 21s) Loss: 0.0033(0.0017) Grad: 10055.9990  LR: 0.000009  \n",
      "Epoch: [3][2700/2851] Elapsed 14m 45s (remain 0m 49s) Loss: 0.0000(0.0017) Grad: 278.2107  LR: 0.000009  \n",
      "Epoch: [3][2800/2851] Elapsed 15m 18s (remain 0m 16s) Loss: 0.0012(0.0017) Grad: 8373.7129  LR: 0.000009  \n",
      "Epoch: [3][2850/2851] Elapsed 15m 34s (remain 0m 0s) Loss: 0.0106(0.0016) Grad: 33145.7031  LR: 0.000009  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 26s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0009(0.0024) \n",
      "EVAL: [200/724] Elapsed 0m 41s (remain 1m 48s) Loss: 0.0000(0.0027) \n",
      "EVAL: [300/724] Elapsed 1m 1s (remain 1m 26s) Loss: 0.0000(0.0025) \n",
      "EVAL: [400/724] Elapsed 1m 21s (remain 1m 5s) Loss: 0.0000(0.0025) \n",
      "EVAL: [500/724] Elapsed 1m 41s (remain 0m 45s) Loss: 0.0041(0.0030) \n",
      "EVAL: [600/724] Elapsed 2m 2s (remain 0m 25s) Loss: 0.0001(0.0029) \n",
      "EVAL: [700/724] Elapsed 2m 22s (remain 0m 4s) Loss: 0.0000(0.0027) \n",
      "EVAL: [723/724] Elapsed 2m 26s (remain 0m 0s) Loss: 0.0000(0.0026) \n",
      "Epoch 3 - avg_train_loss: 0.0016  avg_val_loss: 0.0026  time: 1086s\n",
      "Epoch 3 - Score: 0.8792\n",
      "Epoch 3 - Save Best Score: 0.8792 Model\n",
      "Epoch: [4][0/2851] Elapsed 0m 0s (remain 29m 29s) Loss: 0.0001(0.0001) Grad: 1460.2137  LR: 0.000009  \n",
      "Epoch: [4][100/2851] Elapsed 0m 32s (remain 14m 55s) Loss: 0.0001(0.0018) Grad: 832.0266  LR: 0.000009  \n",
      "Epoch: [4][200/2851] Elapsed 1m 5s (remain 14m 18s) Loss: 0.0016(0.0014) Grad: 15650.1982  LR: 0.000009  \n",
      "Epoch: [4][300/2851] Elapsed 1m 37s (remain 13m 47s) Loss: 0.0004(0.0013) Grad: 3254.6431  LR: 0.000008  \n",
      "Epoch: [4][400/2851] Elapsed 2m 10s (remain 13m 17s) Loss: 0.0031(0.0014) Grad: 18948.3398  LR: 0.000008  \n",
      "Epoch: [4][500/2851] Elapsed 2m 44s (remain 12m 49s) Loss: 0.0006(0.0013) Grad: 8014.0591  LR: 0.000008  \n",
      "Epoch: [4][600/2851] Elapsed 3m 16s (remain 12m 14s) Loss: 0.0000(0.0013) Grad: 505.4130  LR: 0.000008  \n",
      "Epoch: [4][700/2851] Elapsed 3m 48s (remain 11m 40s) Loss: 0.0000(0.0013) Grad: 41.0572  LR: 0.000008  \n",
      "Epoch: [4][800/2851] Elapsed 4m 20s (remain 11m 7s) Loss: 0.0045(0.0014) Grad: 23724.7773  LR: 0.000008  \n",
      "Epoch: [4][900/2851] Elapsed 4m 55s (remain 10m 40s) Loss: 0.0000(0.0014) Grad: 2196.0374  LR: 0.000007  \n",
      "Epoch: [4][1000/2851] Elapsed 5m 31s (remain 10m 12s) Loss: 0.0017(0.0014) Grad: 7980.0776  LR: 0.000007  \n",
      "Epoch: [4][1100/2851] Elapsed 6m 7s (remain 9m 43s) Loss: 0.0006(0.0014) Grad: 3939.5261  LR: 0.000007  \n",
      "Epoch: [4][1200/2851] Elapsed 6m 42s (remain 9m 12s) Loss: 0.0002(0.0014) Grad: 2896.8438  LR: 0.000007  \n",
      "Epoch: [4][1300/2851] Elapsed 7m 14s (remain 8m 38s) Loss: 0.0014(0.0014) Grad: 5835.4810  LR: 0.000007  \n",
      "Epoch: [4][1400/2851] Elapsed 7m 47s (remain 8m 3s) Loss: 0.0030(0.0014) Grad: 14814.4365  LR: 0.000007  \n",
      "Epoch: [4][1500/2851] Elapsed 8m 19s (remain 7m 28s) Loss: 0.0007(0.0014) Grad: 2982.1479  LR: 0.000007  \n",
      "Epoch: [4][1600/2851] Elapsed 8m 51s (remain 6m 54s) Loss: 0.0005(0.0014) Grad: 5034.6216  LR: 0.000006  \n",
      "Epoch: [4][1700/2851] Elapsed 9m 24s (remain 6m 21s) Loss: 0.0000(0.0013) Grad: 14.4418  LR: 0.000006  \n",
      "Epoch: [4][1800/2851] Elapsed 9m 57s (remain 5m 48s) Loss: 0.0009(0.0013) Grad: 14430.2598  LR: 0.000006  \n",
      "Epoch: [4][1900/2851] Elapsed 10m 29s (remain 5m 14s) Loss: 0.0002(0.0013) Grad: 2760.3105  LR: 0.000006  \n",
      "Epoch: [4][2000/2851] Elapsed 11m 1s (remain 4m 41s) Loss: 0.0018(0.0013) Grad: 8373.0039  LR: 0.000006  \n",
      "Epoch: [4][2100/2851] Elapsed 11m 34s (remain 4m 7s) Loss: 0.0000(0.0013) Grad: 173.0755  LR: 0.000006  \n",
      "Epoch: [4][2200/2851] Elapsed 12m 7s (remain 3m 34s) Loss: 0.0016(0.0014) Grad: 9481.5615  LR: 0.000005  \n",
      "Epoch: [4][2300/2851] Elapsed 12m 40s (remain 3m 1s) Loss: 0.0000(0.0014) Grad: 88.5186  LR: 0.000005  \n",
      "Epoch: [4][2400/2851] Elapsed 13m 12s (remain 2m 28s) Loss: 0.0006(0.0014) Grad: 4102.4507  LR: 0.000005  \n",
      "Epoch: [4][2500/2851] Elapsed 13m 44s (remain 1m 55s) Loss: 0.0029(0.0014) Grad: 13113.6709  LR: 0.000005  \n",
      "Epoch: [4][2600/2851] Elapsed 14m 16s (remain 1m 22s) Loss: 0.0010(0.0014) Grad: 7972.4185  LR: 0.000005  \n",
      "Epoch: [4][2700/2851] Elapsed 14m 50s (remain 0m 49s) Loss: 0.0001(0.0014) Grad: 1175.2941  LR: 0.000005  \n",
      "Epoch: [4][2800/2851] Elapsed 15m 24s (remain 0m 16s) Loss: 0.0000(0.0014) Grad: 326.6269  LR: 0.000005  \n",
      "Epoch: [4][2850/2851] Elapsed 15m 40s (remain 0m 0s) Loss: 0.0006(0.0014) Grad: 7882.1099  LR: 0.000004  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 6m 25s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/724] Elapsed 0m 20s (remain 2m 8s) Loss: 0.0013(0.0024) \n",
      "EVAL: [200/724] Elapsed 0m 41s (remain 1m 46s) Loss: 0.0000(0.0028) \n",
      "EVAL: [300/724] Elapsed 1m 0s (remain 1m 25s) Loss: 0.0000(0.0026) \n",
      "EVAL: [400/724] Elapsed 1m 21s (remain 1m 5s) Loss: 0.0000(0.0027) \n",
      "EVAL: [500/724] Elapsed 1m 41s (remain 0m 45s) Loss: 0.0051(0.0032) \n",
      "EVAL: [600/724] Elapsed 2m 2s (remain 0m 25s) Loss: 0.0001(0.0031) \n",
      "EVAL: [700/724] Elapsed 2m 22s (remain 0m 4s) Loss: 0.0000(0.0028) \n",
      "EVAL: [723/724] Elapsed 2m 26s (remain 0m 0s) Loss: 0.0000(0.0028) \n",
      "Epoch 4 - avg_train_loss: 0.0014  avg_val_loss: 0.0028  time: 1093s\n",
      "Epoch 4 - Score: 0.8785\n",
      "Epoch: [5][0/2851] Elapsed 0m 0s (remain 29m 32s) Loss: 0.0000(0.0000) Grad: 1050.6628  LR: 0.000004  \n",
      "Epoch: [5][100/2851] Elapsed 0m 33s (remain 15m 0s) Loss: 0.0001(0.0013) Grad: 589.6122  LR: 0.000004  \n",
      "Epoch: [5][200/2851] Elapsed 1m 4s (remain 14m 15s) Loss: 0.0000(0.0012) Grad: 453.5632  LR: 0.000004  \n",
      "Epoch: [5][300/2851] Elapsed 1m 36s (remain 13m 39s) Loss: 0.0000(0.0012) Grad: 10.4856  LR: 0.000004  \n",
      "Epoch: [5][400/2851] Elapsed 2m 10s (remain 13m 14s) Loss: 0.0001(0.0012) Grad: 2068.1584  LR: 0.000004  \n",
      "Epoch: [5][500/2851] Elapsed 2m 43s (remain 12m 49s) Loss: 0.0002(0.0012) Grad: 2049.3567  LR: 0.000004  \n",
      "Epoch: [5][600/2851] Elapsed 3m 16s (remain 12m 14s) Loss: 0.0001(0.0013) Grad: 736.9716  LR: 0.000004  \n",
      "Epoch: [5][700/2851] Elapsed 3m 48s (remain 11m 42s) Loss: 0.0008(0.0013) Grad: 14005.9287  LR: 0.000003  \n",
      "Epoch: [5][800/2851] Elapsed 4m 22s (remain 11m 10s) Loss: 0.0004(0.0013) Grad: 5153.4814  LR: 0.000003  \n",
      "Epoch: [5][900/2851] Elapsed 4m 55s (remain 10m 39s) Loss: 0.0003(0.0012) Grad: 2559.6926  LR: 0.000003  \n",
      "Epoch: [5][1000/2851] Elapsed 5m 27s (remain 10m 6s) Loss: 0.0007(0.0013) Grad: 15279.7646  LR: 0.000003  \n",
      "Epoch: [5][1100/2851] Elapsed 5m 59s (remain 9m 31s) Loss: 0.0000(0.0013) Grad: 105.3638  LR: 0.000003  \n",
      "Epoch: [5][1200/2851] Elapsed 6m 31s (remain 8m 58s) Loss: 0.0024(0.0013) Grad: 7418.2104  LR: 0.000003  \n",
      "Epoch: [5][1300/2851] Elapsed 7m 3s (remain 8m 25s) Loss: 0.0003(0.0013) Grad: 6654.4146  LR: 0.000002  \n",
      "Epoch: [5][1400/2851] Elapsed 7m 36s (remain 7m 52s) Loss: 0.0005(0.0013) Grad: 7399.3486  LR: 0.000002  \n",
      "Epoch: [5][1500/2851] Elapsed 8m 9s (remain 7m 20s) Loss: 0.0001(0.0013) Grad: 1740.6639  LR: 0.000002  \n",
      "Epoch: [5][1600/2851] Elapsed 8m 43s (remain 6m 48s) Loss: 0.0013(0.0013) Grad: 7378.3711  LR: 0.000002  \n",
      "Epoch: [5][1700/2851] Elapsed 9m 16s (remain 6m 16s) Loss: 0.0006(0.0012) Grad: 6421.0371  LR: 0.000002  \n",
      "Epoch: [5][1800/2851] Elapsed 9m 49s (remain 5m 43s) Loss: 0.0007(0.0012) Grad: 7230.3174  LR: 0.000002  \n",
      "Epoch: [5][1900/2851] Elapsed 10m 22s (remain 5m 10s) Loss: 0.0048(0.0012) Grad: 54891.1211  LR: 0.000001  \n",
      "Epoch: [5][2000/2851] Elapsed 10m 54s (remain 4m 37s) Loss: 0.0006(0.0012) Grad: 3505.7793  LR: 0.000001  \n",
      "Epoch: [5][2100/2851] Elapsed 11m 27s (remain 4m 5s) Loss: 0.0000(0.0012) Grad: 73.7696  LR: 0.000001  \n",
      "Epoch: [5][2200/2851] Elapsed 12m 0s (remain 3m 32s) Loss: 0.0000(0.0012) Grad: 33.5830  LR: 0.000001  \n",
      "Epoch: [5][2300/2851] Elapsed 12m 32s (remain 2m 59s) Loss: 0.0002(0.0012) Grad: 5420.9019  LR: 0.000001  \n",
      "Epoch: [5][2400/2851] Elapsed 13m 4s (remain 2m 27s) Loss: 0.0000(0.0012) Grad: 13.2400  LR: 0.000001  \n",
      "Epoch: [5][2500/2851] Elapsed 13m 37s (remain 1m 54s) Loss: 0.0000(0.0012) Grad: 187.4694  LR: 0.000001  \n",
      "Epoch: [5][2600/2851] Elapsed 14m 10s (remain 1m 21s) Loss: 0.0000(0.0012) Grad: 680.2015  LR: 0.000000  \n",
      "Epoch: [5][2700/2851] Elapsed 14m 42s (remain 0m 48s) Loss: 0.0062(0.0012) Grad: 9900.5322  LR: 0.000000  \n",
      "Epoch: [5][2800/2851] Elapsed 15m 14s (remain 0m 16s) Loss: 0.0002(0.0012) Grad: 5126.8887  LR: 0.000000  \n",
      "Epoch: [5][2850/2851] Elapsed 15m 30s (remain 0m 0s) Loss: 0.0000(0.0012) Grad: 105.8848  LR: 0.000000  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 16s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0020(0.0028) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 53s) Loss: 0.0000(0.0032) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0000(0.0031) \n",
      "EVAL: [400/724] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0000(0.0031) \n",
      "EVAL: [500/724] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0063(0.0038) \n",
      "EVAL: [600/724] Elapsed 2m 5s (remain 0m 25s) Loss: 0.0000(0.0036) \n",
      "EVAL: [700/724] Elapsed 2m 24s (remain 0m 4s) Loss: 0.0000(0.0033) \n",
      "EVAL: [723/724] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0032) \n",
      "Epoch 5 - avg_train_loss: 0.0012  avg_val_loss: 0.0032  time: 1085s\n",
      "Epoch 5 - Score: 0.8824\n",
      "Epoch 5 - Save Best Score: 0.8824 Model\n",
      "========== fold: 2 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2871] Elapsed 0m 0s (remain 28m 54s) Loss: 0.0730(0.0730) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2871] Elapsed 0m 33s (remain 15m 13s) Loss: 0.0312(0.0482) Grad: 21952.0957  LR: 0.000001  \n",
      "Epoch: [1][200/2871] Elapsed 1m 6s (remain 14m 40s) Loss: 0.0133(0.0334) Grad: 2974.5764  LR: 0.000003  \n",
      "Epoch: [1][300/2871] Elapsed 1m 38s (remain 14m 3s) Loss: 0.0179(0.0273) Grad: 4358.9126  LR: 0.000004  \n",
      "Epoch: [1][400/2871] Elapsed 2m 11s (remain 13m 29s) Loss: 0.0101(0.0241) Grad: 2830.8347  LR: 0.000006  \n",
      "Epoch: [1][500/2871] Elapsed 2m 43s (remain 12m 54s) Loss: 0.0046(0.0219) Grad: 4256.4355  LR: 0.000007  \n",
      "Epoch: [1][600/2871] Elapsed 3m 16s (remain 12m 22s) Loss: 0.0106(0.0201) Grad: 4523.2188  LR: 0.000008  \n",
      "Epoch: [1][700/2871] Elapsed 3m 49s (remain 11m 50s) Loss: 0.0022(0.0184) Grad: 1971.8605  LR: 0.000010  \n",
      "Epoch: [1][800/2871] Elapsed 4m 21s (remain 11m 16s) Loss: 0.0068(0.0169) Grad: 16334.3691  LR: 0.000011  \n",
      "Epoch: [1][900/2871] Elapsed 4m 54s (remain 10m 44s) Loss: 0.0007(0.0157) Grad: 967.7870  LR: 0.000013  \n",
      "Epoch: [1][1000/2871] Elapsed 5m 27s (remain 10m 12s) Loss: 0.0013(0.0147) Grad: 1954.4265  LR: 0.000014  \n",
      "Epoch: [1][1100/2871] Elapsed 6m 2s (remain 9m 42s) Loss: 0.0049(0.0138) Grad: 3187.9526  LR: 0.000015  \n",
      "Epoch: [1][1200/2871] Elapsed 6m 35s (remain 9m 9s) Loss: 0.0064(0.0130) Grad: 7718.5186  LR: 0.000017  \n",
      "Epoch: [1][1300/2871] Elapsed 7m 7s (remain 8m 36s) Loss: 0.0015(0.0123) Grad: 1335.8800  LR: 0.000018  \n",
      "Epoch: [1][1400/2871] Elapsed 7m 40s (remain 8m 2s) Loss: 0.0126(0.0117) Grad: 18103.4980  LR: 0.000020  \n",
      "Epoch: [1][1500/2871] Elapsed 8m 13s (remain 7m 30s) Loss: 0.0032(0.0111) Grad: 4110.5107  LR: 0.000020  \n",
      "Epoch: [1][1600/2871] Elapsed 8m 46s (remain 6m 57s) Loss: 0.0029(0.0107) Grad: 2907.4509  LR: 0.000020  \n",
      "Epoch: [1][1700/2871] Elapsed 9m 19s (remain 6m 24s) Loss: 0.0016(0.0103) Grad: 2515.4707  LR: 0.000020  \n",
      "Epoch: [1][1800/2871] Elapsed 9m 52s (remain 5m 51s) Loss: 0.0011(0.0099) Grad: 1291.8030  LR: 0.000019  \n",
      "Epoch: [1][1900/2871] Elapsed 10m 24s (remain 5m 18s) Loss: 0.0004(0.0096) Grad: 421.5536  LR: 0.000019  \n",
      "Epoch: [1][2000/2871] Elapsed 10m 56s (remain 4m 45s) Loss: 0.0056(0.0092) Grad: 8442.1494  LR: 0.000019  \n",
      "Epoch: [1][2100/2871] Elapsed 11m 29s (remain 4m 12s) Loss: 0.0011(0.0089) Grad: 1647.9478  LR: 0.000019  \n",
      "Epoch: [1][2200/2871] Elapsed 12m 3s (remain 3m 40s) Loss: 0.0163(0.0087) Grad: 17073.8809  LR: 0.000019  \n",
      "Epoch: [1][2300/2871] Elapsed 12m 36s (remain 3m 7s) Loss: 0.0008(0.0084) Grad: 881.4275  LR: 0.000019  \n",
      "Epoch: [1][2400/2871] Elapsed 13m 8s (remain 2m 34s) Loss: 0.0019(0.0082) Grad: 3109.8804  LR: 0.000019  \n",
      "Epoch: [1][2500/2871] Elapsed 13m 42s (remain 2m 1s) Loss: 0.0009(0.0080) Grad: 653.4450  LR: 0.000018  \n",
      "Epoch: [1][2600/2871] Elapsed 14m 14s (remain 1m 28s) Loss: 0.0007(0.0078) Grad: 1348.9149  LR: 0.000018  \n",
      "Epoch: [1][2700/2871] Elapsed 14m 46s (remain 0m 55s) Loss: 0.0164(0.0076) Grad: 13016.8203  LR: 0.000018  \n",
      "Epoch: [1][2800/2871] Elapsed 15m 18s (remain 0m 22s) Loss: 0.0018(0.0074) Grad: 2391.8101  LR: 0.000018  \n",
      "Epoch: [1][2870/2871] Elapsed 15m 41s (remain 0m 0s) Loss: 0.0067(0.0073) Grad: 8193.9141  LR: 0.000018  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 33s) Loss: 0.0010(0.0010) \n",
      "EVAL: [100/704] Elapsed 0m 20s (remain 2m 2s) Loss: 0.0028(0.0022) \n",
      "EVAL: [200/704] Elapsed 0m 40s (remain 1m 41s) Loss: 0.0000(0.0021) \n",
      "EVAL: [300/704] Elapsed 1m 0s (remain 1m 21s) Loss: 0.0002(0.0021) \n",
      "EVAL: [400/704] Elapsed 1m 20s (remain 1m 0s) Loss: 0.0018(0.0024) \n",
      "EVAL: [500/704] Elapsed 1m 40s (remain 0m 40s) Loss: 0.0017(0.0026) \n",
      "EVAL: [600/704] Elapsed 2m 1s (remain 0m 20s) Loss: 0.0001(0.0027) \n",
      "EVAL: [700/704] Elapsed 2m 20s (remain 0m 0s) Loss: 0.0001(0.0025) \n",
      "EVAL: [703/704] Elapsed 2m 21s (remain 0m 0s) Loss: 0.0000(0.0025) \n",
      "Epoch 1 - avg_train_loss: 0.0073  avg_val_loss: 0.0025  time: 1088s\n",
      "Epoch 1 - Score: 0.8317\n",
      "Epoch 1 - Save Best Score: 0.8317 Model\n",
      "Epoch: [2][0/2871] Elapsed 0m 0s (remain 25m 58s) Loss: 0.0010(0.0010) Grad: 3822.9626  LR: 0.000018  \n",
      "Epoch: [2][100/2871] Elapsed 0m 33s (remain 15m 6s) Loss: 0.0006(0.0015) Grad: 2092.0105  LR: 0.000018  \n",
      "Epoch: [2][200/2871] Elapsed 1m 5s (remain 14m 30s) Loss: 0.0008(0.0016) Grad: 3454.8940  LR: 0.000017  \n",
      "Epoch: [2][300/2871] Elapsed 1m 37s (remain 13m 55s) Loss: 0.0015(0.0016) Grad: 9921.3818  LR: 0.000017  \n",
      "Epoch: [2][400/2871] Elapsed 2m 11s (remain 13m 29s) Loss: 0.0025(0.0018) Grad: 11533.0410  LR: 0.000017  \n",
      "Epoch: [2][500/2871] Elapsed 2m 46s (remain 13m 9s) Loss: 0.0013(0.0018) Grad: 6912.0010  LR: 0.000017  \n",
      "Epoch: [2][600/2871] Elapsed 3m 20s (remain 12m 35s) Loss: 0.0014(0.0019) Grad: 8300.3418  LR: 0.000017  \n",
      "Epoch: [2][700/2871] Elapsed 3m 52s (remain 11m 59s) Loss: 0.0006(0.0019) Grad: 2314.5454  LR: 0.000017  \n",
      "Epoch: [2][800/2871] Elapsed 4m 24s (remain 11m 23s) Loss: 0.0026(0.0020) Grad: 14663.0850  LR: 0.000017  \n",
      "Epoch: [2][900/2871] Elapsed 4m 57s (remain 10m 49s) Loss: 0.0010(0.0020) Grad: 13445.9463  LR: 0.000016  \n",
      "Epoch: [2][1000/2871] Elapsed 5m 29s (remain 10m 15s) Loss: 0.0016(0.0020) Grad: 38229.4414  LR: 0.000016  \n",
      "Epoch: [2][1100/2871] Elapsed 6m 2s (remain 9m 42s) Loss: 0.0002(0.0020) Grad: 1025.6990  LR: 0.000016  \n",
      "Epoch: [2][1200/2871] Elapsed 6m 35s (remain 9m 10s) Loss: 0.0002(0.0021) Grad: 2990.0051  LR: 0.000016  \n",
      "Epoch: [2][1300/2871] Elapsed 7m 8s (remain 8m 37s) Loss: 0.0085(0.0021) Grad: 58385.6875  LR: 0.000016  \n",
      "Epoch: [2][1400/2871] Elapsed 7m 41s (remain 8m 4s) Loss: 0.0018(0.0021) Grad: 12014.2568  LR: 0.000016  \n",
      "Epoch: [2][1500/2871] Elapsed 8m 14s (remain 7m 31s) Loss: 0.0009(0.0022) Grad: 4208.3994  LR: 0.000015  \n",
      "Epoch: [2][1600/2871] Elapsed 8m 47s (remain 6m 58s) Loss: 0.0034(0.0022) Grad: 15016.8926  LR: 0.000015  \n",
      "Epoch: [2][1700/2871] Elapsed 9m 20s (remain 6m 25s) Loss: 0.0003(0.0022) Grad: 1681.0580  LR: 0.000015  \n",
      "Epoch: [2][1800/2871] Elapsed 9m 52s (remain 5m 52s) Loss: 0.0011(0.0022) Grad: 7142.4375  LR: 0.000015  \n",
      "Epoch: [2][1900/2871] Elapsed 10m 26s (remain 5m 19s) Loss: 0.0015(0.0021) Grad: 6503.1030  LR: 0.000015  \n",
      "Epoch: [2][2000/2871] Elapsed 11m 0s (remain 4m 47s) Loss: 0.0074(0.0022) Grad: 83804.9453  LR: 0.000015  \n",
      "Epoch: [2][2100/2871] Elapsed 11m 35s (remain 4m 14s) Loss: 0.0008(0.0021) Grad: 20972.5977  LR: 0.000015  \n",
      "Epoch: [2][2200/2871] Elapsed 12m 8s (remain 3m 41s) Loss: 0.0038(0.0021) Grad: 37633.3945  LR: 0.000014  \n",
      "Epoch: [2][2300/2871] Elapsed 12m 41s (remain 3m 8s) Loss: 0.0002(0.0021) Grad: 1574.4895  LR: 0.000014  \n",
      "Epoch: [2][2400/2871] Elapsed 13m 13s (remain 2m 35s) Loss: 0.0015(0.0022) Grad: 6483.7627  LR: 0.000014  \n",
      "Epoch: [2][2500/2871] Elapsed 13m 45s (remain 2m 2s) Loss: 0.0013(0.0022) Grad: 9572.3652  LR: 0.000014  \n",
      "Epoch: [2][2600/2871] Elapsed 14m 18s (remain 1m 29s) Loss: 0.0001(0.0022) Grad: 616.8571  LR: 0.000014  \n",
      "Epoch: [2][2700/2871] Elapsed 14m 52s (remain 0m 56s) Loss: 0.0003(0.0022) Grad: 2090.8716  LR: 0.000014  \n",
      "Epoch: [2][2800/2871] Elapsed 15m 24s (remain 0m 23s) Loss: 0.0033(0.0022) Grad: 21934.9785  LR: 0.000013  \n",
      "Epoch: [2][2870/2871] Elapsed 15m 47s (remain 0m 0s) Loss: 0.0000(0.0022) Grad: 109.3871  LR: 0.000013  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 21s) Loss: 0.0006(0.0006) \n",
      "EVAL: [100/704] Elapsed 0m 20s (remain 2m 2s) Loss: 0.0018(0.0021) \n",
      "EVAL: [200/704] Elapsed 0m 40s (remain 1m 41s) Loss: 0.0000(0.0021) \n",
      "EVAL: [300/704] Elapsed 1m 0s (remain 1m 21s) Loss: 0.0001(0.0021) \n",
      "EVAL: [400/704] Elapsed 1m 20s (remain 1m 0s) Loss: 0.0024(0.0023) \n",
      "EVAL: [500/704] Elapsed 1m 40s (remain 0m 40s) Loss: 0.0014(0.0026) \n",
      "EVAL: [600/704] Elapsed 2m 2s (remain 0m 20s) Loss: 0.0000(0.0027) \n",
      "EVAL: [700/704] Elapsed 2m 23s (remain 0m 0s) Loss: 0.0000(0.0025) \n",
      "EVAL: [703/704] Elapsed 2m 24s (remain 0m 0s) Loss: 0.0000(0.0025) \n",
      "Epoch 2 - avg_train_loss: 0.0022  avg_val_loss: 0.0025  time: 1097s\n",
      "Epoch 2 - Score: 0.8532\n",
      "Epoch 2 - Save Best Score: 0.8532 Model\n",
      "Epoch: [3][0/2871] Elapsed 0m 0s (remain 29m 34s) Loss: 0.0027(0.0027) Grad: 13918.9668  LR: 0.000013  \n",
      "Epoch: [3][100/2871] Elapsed 0m 32s (remain 14m 58s) Loss: 0.0000(0.0016) Grad: 160.7117  LR: 0.000013  \n",
      "Epoch: [3][200/2871] Elapsed 1m 5s (remain 14m 24s) Loss: 0.0049(0.0018) Grad: 10600.9580  LR: 0.000013  \n",
      "Epoch: [3][300/2871] Elapsed 1m 38s (remain 13m 59s) Loss: 0.0004(0.0018) Grad: 6420.7021  LR: 0.000013  \n",
      "Epoch: [3][400/2871] Elapsed 2m 11s (remain 13m 29s) Loss: 0.0026(0.0017) Grad: 78194.7969  LR: 0.000013  \n",
      "Epoch: [3][500/2871] Elapsed 2m 43s (remain 12m 55s) Loss: 0.0205(0.0017) Grad: 124063.9453  LR: 0.000013  \n",
      "Epoch: [3][600/2871] Elapsed 3m 16s (remain 12m 22s) Loss: 0.0016(0.0017) Grad: 4316.3311  LR: 0.000012  \n",
      "Epoch: [3][700/2871] Elapsed 3m 49s (remain 11m 50s) Loss: 0.0002(0.0017) Grad: 4996.8638  LR: 0.000012  \n",
      "Epoch: [3][800/2871] Elapsed 4m 21s (remain 11m 15s) Loss: 0.0003(0.0016) Grad: 4493.1567  LR: 0.000012  \n",
      "Epoch: [3][900/2871] Elapsed 4m 53s (remain 10m 42s) Loss: 0.0002(0.0016) Grad: 2696.9199  LR: 0.000012  \n",
      "Epoch: [3][1000/2871] Elapsed 5m 26s (remain 10m 10s) Loss: 0.0000(0.0016) Grad: 209.8666  LR: 0.000012  \n",
      "Epoch: [3][1100/2871] Elapsed 6m 1s (remain 9m 40s) Loss: 0.0000(0.0016) Grad: 78.0130  LR: 0.000012  \n",
      "Epoch: [3][1200/2871] Elapsed 6m 34s (remain 9m 8s) Loss: 0.0003(0.0017) Grad: 2331.9998  LR: 0.000011  \n",
      "Epoch: [3][1300/2871] Elapsed 7m 7s (remain 8m 35s) Loss: 0.0016(0.0017) Grad: 13097.1865  LR: 0.000011  \n",
      "Epoch: [3][1400/2871] Elapsed 7m 39s (remain 8m 1s) Loss: 0.0000(0.0017) Grad: 215.0459  LR: 0.000011  \n",
      "Epoch: [3][1500/2871] Elapsed 8m 11s (remain 7m 28s) Loss: 0.0051(0.0017) Grad: 20473.6641  LR: 0.000011  \n",
      "Epoch: [3][1600/2871] Elapsed 8m 43s (remain 6m 55s) Loss: 0.0004(0.0017) Grad: 3410.8076  LR: 0.000011  \n",
      "Epoch: [3][1700/2871] Elapsed 9m 16s (remain 6m 22s) Loss: 0.0002(0.0017) Grad: 1838.3734  LR: 0.000011  \n",
      "Epoch: [3][1800/2871] Elapsed 9m 49s (remain 5m 50s) Loss: 0.0006(0.0017) Grad: 4593.7944  LR: 0.000011  \n",
      "Epoch: [3][1900/2871] Elapsed 10m 23s (remain 5m 18s) Loss: 0.0015(0.0017) Grad: 8609.6582  LR: 0.000010  \n",
      "Epoch: [3][2000/2871] Elapsed 10m 55s (remain 4m 44s) Loss: 0.0017(0.0017) Grad: 12743.5244  LR: 0.000010  \n",
      "Epoch: [3][2100/2871] Elapsed 11m 27s (remain 4m 11s) Loss: 0.0005(0.0017) Grad: 2138.5952  LR: 0.000010  \n",
      "Epoch: [3][2200/2871] Elapsed 12m 1s (remain 3m 39s) Loss: 0.0000(0.0017) Grad: 361.2186  LR: 0.000010  \n",
      "Epoch: [3][2300/2871] Elapsed 12m 34s (remain 3m 6s) Loss: 0.0000(0.0017) Grad: 120.7309  LR: 0.000010  \n",
      "Epoch: [3][2400/2871] Elapsed 13m 6s (remain 2m 34s) Loss: 0.0000(0.0017) Grad: 50.4566  LR: 0.000010  \n",
      "Epoch: [3][2500/2871] Elapsed 13m 39s (remain 2m 1s) Loss: 0.0026(0.0017) Grad: 9601.9775  LR: 0.000009  \n",
      "Epoch: [3][2600/2871] Elapsed 14m 12s (remain 1m 28s) Loss: 0.0014(0.0017) Grad: 14645.0693  LR: 0.000009  \n",
      "Epoch: [3][2700/2871] Elapsed 14m 45s (remain 0m 55s) Loss: 0.0001(0.0017) Grad: 558.8989  LR: 0.000009  \n",
      "Epoch: [3][2800/2871] Elapsed 15m 18s (remain 0m 22s) Loss: 0.0003(0.0017) Grad: 3458.4302  LR: 0.000009  \n",
      "Epoch: [3][2870/2871] Elapsed 15m 42s (remain 0m 0s) Loss: 0.0006(0.0017) Grad: 2451.3479  LR: 0.000009  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 36s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/704] Elapsed 0m 20s (remain 2m 2s) Loss: 0.0003(0.0028) \n",
      "EVAL: [200/704] Elapsed 0m 40s (remain 1m 41s) Loss: 0.0000(0.0027) \n",
      "EVAL: [300/704] Elapsed 1m 0s (remain 1m 21s) Loss: 0.0002(0.0025) \n",
      "EVAL: [400/704] Elapsed 1m 20s (remain 1m 0s) Loss: 0.0095(0.0028) \n",
      "EVAL: [500/704] Elapsed 1m 40s (remain 0m 40s) Loss: 0.0026(0.0030) \n",
      "EVAL: [600/704] Elapsed 2m 0s (remain 0m 20s) Loss: 0.0000(0.0030) \n",
      "EVAL: [700/704] Elapsed 2m 21s (remain 0m 0s) Loss: 0.0000(0.0028) \n",
      "EVAL: [703/704] Elapsed 2m 21s (remain 0m 0s) Loss: 0.0000(0.0028) \n",
      "Epoch 3 - avg_train_loss: 0.0017  avg_val_loss: 0.0028  time: 1089s\n",
      "Epoch 3 - Score: 0.8538\n",
      "Epoch 3 - Save Best Score: 0.8538 Model\n",
      "Epoch: [4][0/2871] Elapsed 0m 0s (remain 29m 41s) Loss: 0.0003(0.0003) Grad: 1952.2141  LR: 0.000009  \n",
      "Epoch: [4][100/2871] Elapsed 0m 35s (remain 16m 26s) Loss: 0.0010(0.0014) Grad: 12170.6436  LR: 0.000009  \n",
      "Epoch: [4][200/2871] Elapsed 1m 10s (remain 15m 38s) Loss: 0.0000(0.0012) Grad: 90.1227  LR: 0.000009  \n",
      "Epoch: [4][300/2871] Elapsed 1m 42s (remain 14m 38s) Loss: 0.0005(0.0013) Grad: 3895.4905  LR: 0.000008  \n",
      "Epoch: [4][400/2871] Elapsed 2m 15s (remain 13m 52s) Loss: 0.0002(0.0013) Grad: 2779.3945  LR: 0.000008  \n",
      "Epoch: [4][500/2871] Elapsed 2m 47s (remain 13m 11s) Loss: 0.0014(0.0014) Grad: 25240.7676  LR: 0.000008  \n",
      "Epoch: [4][600/2871] Elapsed 3m 19s (remain 12m 35s) Loss: 0.0006(0.0014) Grad: 8734.7500  LR: 0.000008  \n",
      "Epoch: [4][700/2871] Elapsed 3m 52s (remain 12m 0s) Loss: 0.0000(0.0014) Grad: 108.6689  LR: 0.000008  \n",
      "Epoch: [4][800/2871] Elapsed 4m 25s (remain 11m 26s) Loss: 0.0011(0.0015) Grad: 14322.6055  LR: 0.000008  \n",
      "Epoch: [4][900/2871] Elapsed 4m 58s (remain 10m 51s) Loss: 0.0005(0.0015) Grad: 8178.7417  LR: 0.000007  \n",
      "Epoch: [4][1000/2871] Elapsed 5m 30s (remain 10m 17s) Loss: 0.0055(0.0014) Grad: 22673.4199  LR: 0.000007  \n",
      "Epoch: [4][1100/2871] Elapsed 6m 2s (remain 9m 42s) Loss: 0.0008(0.0014) Grad: 6490.6543  LR: 0.000007  \n",
      "Epoch: [4][1200/2871] Elapsed 6m 34s (remain 9m 8s) Loss: 0.0001(0.0014) Grad: 1329.4178  LR: 0.000007  \n",
      "Epoch: [4][1300/2871] Elapsed 7m 7s (remain 8m 36s) Loss: 0.0026(0.0014) Grad: 26468.1055  LR: 0.000007  \n",
      "Epoch: [4][1400/2871] Elapsed 7m 42s (remain 8m 5s) Loss: 0.0000(0.0015) Grad: 75.8436  LR: 0.000007  \n",
      "Epoch: [4][1500/2871] Elapsed 8m 15s (remain 7m 32s) Loss: 0.0000(0.0015) Grad: 162.4002  LR: 0.000007  \n",
      "Epoch: [4][1600/2871] Elapsed 8m 48s (remain 6m 58s) Loss: 0.0047(0.0015) Grad: 19908.0332  LR: 0.000006  \n",
      "Epoch: [4][1700/2871] Elapsed 9m 20s (remain 6m 25s) Loss: 0.0023(0.0015) Grad: 23182.7871  LR: 0.000006  \n",
      "Epoch: [4][1800/2871] Elapsed 9m 53s (remain 5m 52s) Loss: 0.0005(0.0015) Grad: 3624.3430  LR: 0.000006  \n",
      "Epoch: [4][1900/2871] Elapsed 10m 25s (remain 5m 19s) Loss: 0.0001(0.0015) Grad: 2016.9181  LR: 0.000006  \n",
      "Epoch: [4][2000/2871] Elapsed 10m 58s (remain 4m 46s) Loss: 0.0145(0.0015) Grad: 27595.3750  LR: 0.000006  \n",
      "Epoch: [4][2100/2871] Elapsed 11m 31s (remain 4m 13s) Loss: 0.0184(0.0015) Grad: 50155.1445  LR: 0.000006  \n",
      "Epoch: [4][2200/2871] Elapsed 12m 4s (remain 3m 40s) Loss: 0.0014(0.0015) Grad: 5764.8164  LR: 0.000005  \n",
      "Epoch: [4][2300/2871] Elapsed 12m 36s (remain 3m 7s) Loss: 0.0004(0.0015) Grad: 973.1970  LR: 0.000005  \n",
      "Epoch: [4][2400/2871] Elapsed 13m 8s (remain 2m 34s) Loss: 0.0000(0.0015) Grad: 138.8932  LR: 0.000005  \n",
      "Epoch: [4][2500/2871] Elapsed 13m 40s (remain 2m 1s) Loss: 0.0007(0.0015) Grad: 2699.6484  LR: 0.000005  \n",
      "Epoch: [4][2600/2871] Elapsed 14m 13s (remain 1m 28s) Loss: 0.0005(0.0015) Grad: 2331.4924  LR: 0.000005  \n",
      "Epoch: [4][2700/2871] Elapsed 14m 46s (remain 0m 55s) Loss: 0.0001(0.0015) Grad: 1325.3654  LR: 0.000005  \n",
      "Epoch: [4][2800/2871] Elapsed 15m 19s (remain 0m 22s) Loss: 0.0021(0.0015) Grad: 6204.4004  LR: 0.000005  \n",
      "Epoch: [4][2870/2871] Elapsed 15m 41s (remain 0m 0s) Loss: 0.0011(0.0014) Grad: 3643.8870  LR: 0.000004  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 19s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/704] Elapsed 0m 20s (remain 2m 1s) Loss: 0.0003(0.0027) \n",
      "EVAL: [200/704] Elapsed 0m 40s (remain 1m 41s) Loss: 0.0000(0.0025) \n",
      "EVAL: [300/704] Elapsed 1m 0s (remain 1m 20s) Loss: 0.0000(0.0025) \n",
      "EVAL: [400/704] Elapsed 1m 20s (remain 1m 0s) Loss: 0.0025(0.0029) \n",
      "EVAL: [500/704] Elapsed 1m 40s (remain 0m 40s) Loss: 0.0024(0.0032) \n",
      "EVAL: [600/704] Elapsed 2m 0s (remain 0m 20s) Loss: 0.0000(0.0032) \n",
      "EVAL: [700/704] Elapsed 2m 20s (remain 0m 0s) Loss: 0.0000(0.0030) \n",
      "EVAL: [703/704] Elapsed 2m 20s (remain 0m 0s) Loss: 0.0000(0.0030) \n",
      "Epoch 4 - avg_train_loss: 0.0014  avg_val_loss: 0.0030  time: 1088s\n",
      "Epoch 4 - Score: 0.8657\n",
      "Epoch 4 - Save Best Score: 0.8657 Model\n",
      "Epoch: [5][0/2871] Elapsed 0m 0s (remain 30m 57s) Loss: 0.0015(0.0015) Grad: 8958.8184  LR: 0.000004  \n",
      "Epoch: [5][100/2871] Elapsed 0m 33s (remain 15m 29s) Loss: 0.0003(0.0010) Grad: 2890.4451  LR: 0.000004  \n",
      "Epoch: [5][200/2871] Elapsed 1m 8s (remain 15m 9s) Loss: 0.0032(0.0013) Grad: 31882.5234  LR: 0.000004  \n",
      "Epoch: [5][300/2871] Elapsed 1m 40s (remain 14m 20s) Loss: 0.0001(0.0015) Grad: 734.7314  LR: 0.000004  \n",
      "Epoch: [5][400/2871] Elapsed 2m 13s (remain 13m 39s) Loss: 0.0005(0.0013) Grad: 3472.8708  LR: 0.000004  \n",
      "Epoch: [5][500/2871] Elapsed 2m 45s (remain 13m 3s) Loss: 0.0006(0.0013) Grad: 34891.8828  LR: 0.000004  \n",
      "Epoch: [5][600/2871] Elapsed 3m 19s (remain 12m 32s) Loss: 0.0000(0.0013) Grad: 34.9176  LR: 0.000004  \n",
      "Epoch: [5][700/2871] Elapsed 3m 51s (remain 11m 57s) Loss: 0.0002(0.0013) Grad: 6153.6299  LR: 0.000003  \n",
      "Epoch: [5][800/2871] Elapsed 4m 24s (remain 11m 23s) Loss: 0.0240(0.0013) Grad: 94533.8906  LR: 0.000003  \n",
      "Epoch: [5][900/2871] Elapsed 4m 57s (remain 10m 50s) Loss: 0.0012(0.0013) Grad: 10197.9834  LR: 0.000003  \n",
      "Epoch: [5][1000/2871] Elapsed 5m 29s (remain 10m 15s) Loss: 0.0022(0.0013) Grad: 10695.5898  LR: 0.000003  \n",
      "Epoch: [5][1100/2871] Elapsed 6m 1s (remain 9m 41s) Loss: 0.0000(0.0013) Grad: 411.1291  LR: 0.000003  \n",
      "Epoch: [5][1200/2871] Elapsed 6m 34s (remain 9m 8s) Loss: 0.0030(0.0013) Grad: 16888.9277  LR: 0.000003  \n",
      "Epoch: [5][1300/2871] Elapsed 7m 6s (remain 8m 34s) Loss: 0.0000(0.0013) Grad: 90.1427  LR: 0.000002  \n",
      "Epoch: [5][1400/2871] Elapsed 7m 40s (remain 8m 2s) Loss: 0.0000(0.0012) Grad: 165.2433  LR: 0.000002  \n",
      "Epoch: [5][1500/2871] Elapsed 8m 12s (remain 7m 29s) Loss: 0.0008(0.0012) Grad: 4308.9482  LR: 0.000002  \n",
      "Epoch: [5][1600/2871] Elapsed 8m 44s (remain 6m 56s) Loss: 0.0000(0.0012) Grad: 69.7364  LR: 0.000002  \n",
      "Epoch: [5][1700/2871] Elapsed 9m 17s (remain 6m 23s) Loss: 0.0003(0.0012) Grad: 3083.2761  LR: 0.000002  \n",
      "Epoch: [5][1800/2871] Elapsed 9m 49s (remain 5m 50s) Loss: 0.0000(0.0012) Grad: 360.0288  LR: 0.000002  \n",
      "Epoch: [5][1900/2871] Elapsed 10m 21s (remain 5m 17s) Loss: 0.0026(0.0012) Grad: 7276.7173  LR: 0.000002  \n",
      "Epoch: [5][2000/2871] Elapsed 10m 54s (remain 4m 44s) Loss: 0.0001(0.0012) Grad: 861.5212  LR: 0.000001  \n",
      "Epoch: [5][2100/2871] Elapsed 11m 26s (remain 4m 11s) Loss: 0.0001(0.0012) Grad: 640.0159  LR: 0.000001  \n",
      "Epoch: [5][2200/2871] Elapsed 12m 0s (remain 3m 39s) Loss: 0.0002(0.0012) Grad: 1911.6105  LR: 0.000001  \n",
      "Epoch: [5][2300/2871] Elapsed 12m 32s (remain 3m 6s) Loss: 0.0009(0.0012) Grad: 15204.6172  LR: 0.000001  \n",
      "Epoch: [5][2400/2871] Elapsed 13m 4s (remain 2m 33s) Loss: 0.0006(0.0012) Grad: 4744.6289  LR: 0.000001  \n",
      "Epoch: [5][2500/2871] Elapsed 13m 37s (remain 2m 0s) Loss: 0.0027(0.0012) Grad: 13935.2383  LR: 0.000001  \n",
      "Epoch: [5][2600/2871] Elapsed 14m 9s (remain 1m 28s) Loss: 0.0000(0.0012) Grad: 104.8302  LR: 0.000000  \n",
      "Epoch: [5][2700/2871] Elapsed 14m 41s (remain 0m 55s) Loss: 0.0291(0.0012) Grad: 90339.9766  LR: 0.000000  \n",
      "Epoch: [5][2800/2871] Elapsed 15m 14s (remain 0m 22s) Loss: 0.0000(0.0012) Grad: 322.9553  LR: 0.000000  \n",
      "Epoch: [5][2870/2871] Elapsed 15m 37s (remain 0m 0s) Loss: 0.0000(0.0012) Grad: 479.9072  LR: 0.000000  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 30s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/704] Elapsed 0m 20s (remain 2m 3s) Loss: 0.0005(0.0028) \n",
      "EVAL: [200/704] Elapsed 0m 40s (remain 1m 42s) Loss: 0.0000(0.0027) \n",
      "EVAL: [300/704] Elapsed 1m 0s (remain 1m 21s) Loss: 0.0000(0.0028) \n",
      "EVAL: [400/704] Elapsed 1m 20s (remain 1m 0s) Loss: 0.0058(0.0033) \n",
      "EVAL: [500/704] Elapsed 1m 40s (remain 0m 40s) Loss: 0.0026(0.0036) \n",
      "EVAL: [600/704] Elapsed 2m 1s (remain 0m 20s) Loss: 0.0000(0.0036) \n",
      "EVAL: [700/704] Elapsed 2m 22s (remain 0m 0s) Loss: 0.0000(0.0034) \n",
      "EVAL: [703/704] Elapsed 2m 22s (remain 0m 0s) Loss: 0.0000(0.0034) \n",
      "Epoch 5 - avg_train_loss: 0.0012  avg_val_loss: 0.0034  time: 1085s\n",
      "Epoch 5 - Score: 0.8657\n",
      "========== fold: 3 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2877] Elapsed 0m 0s (remain 27m 50s) Loss: 0.3690(0.3690) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2877] Elapsed 0m 35s (remain 16m 2s) Loss: 0.1151(0.3027) Grad: 13149.0547  LR: 0.000001  \n",
      "Epoch: [1][200/2877] Elapsed 1m 7s (remain 14m 53s) Loss: 0.0114(0.1731) Grad: 454.0056  LR: 0.000003  \n",
      "Epoch: [1][300/2877] Elapsed 1m 38s (remain 14m 7s) Loss: 0.0126(0.1205) Grad: 1167.4860  LR: 0.000004  \n",
      "Epoch: [1][400/2877] Elapsed 2m 10s (remain 13m 26s) Loss: 0.0126(0.0937) Grad: 604.1294  LR: 0.000006  \n",
      "Epoch: [1][500/2877] Elapsed 2m 42s (remain 12m 52s) Loss: 0.0095(0.0770) Grad: 748.6717  LR: 0.000007  \n",
      "Epoch: [1][600/2877] Elapsed 3m 15s (remain 12m 21s) Loss: 0.0049(0.0655) Grad: 579.0276  LR: 0.000008  \n",
      "Epoch: [1][700/2877] Elapsed 3m 47s (remain 11m 46s) Loss: 0.0044(0.0571) Grad: 442.0397  LR: 0.000010  \n",
      "Epoch: [1][800/2877] Elapsed 4m 19s (remain 11m 12s) Loss: 0.0019(0.0506) Grad: 155.4422  LR: 0.000011  \n",
      "Epoch: [1][900/2877] Elapsed 4m 51s (remain 10m 38s) Loss: 0.0019(0.0455) Grad: 212.0321  LR: 0.000013  \n",
      "Epoch: [1][1000/2877] Elapsed 5m 23s (remain 10m 6s) Loss: 0.0022(0.0413) Grad: 928.2754  LR: 0.000014  \n",
      "Epoch: [1][1100/2877] Elapsed 5m 55s (remain 9m 33s) Loss: 0.0034(0.0380) Grad: 377.4321  LR: 0.000015  \n",
      "Epoch: [1][1200/2877] Elapsed 6m 27s (remain 9m 1s) Loss: 0.0060(0.0352) Grad: 2680.4551  LR: 0.000017  \n",
      "Epoch: [1][1300/2877] Elapsed 6m 59s (remain 8m 28s) Loss: 0.0004(0.0327) Grad: 60.9942  LR: 0.000018  \n",
      "Epoch: [1][1400/2877] Elapsed 7m 31s (remain 7m 55s) Loss: 0.0068(0.0306) Grad: 1534.1809  LR: 0.000019  \n",
      "Epoch: [1][1500/2877] Elapsed 8m 2s (remain 7m 22s) Loss: 0.0029(0.0288) Grad: 257.9259  LR: 0.000020  \n",
      "Epoch: [1][1600/2877] Elapsed 8m 34s (remain 6m 50s) Loss: 0.0020(0.0272) Grad: 315.4667  LR: 0.000020  \n",
      "Epoch: [1][1700/2877] Elapsed 9m 7s (remain 6m 18s) Loss: 0.0052(0.0257) Grad: 635.4569  LR: 0.000020  \n",
      "Epoch: [1][1800/2877] Elapsed 9m 41s (remain 5m 47s) Loss: 0.0027(0.0245) Grad: 428.8230  LR: 0.000019  \n",
      "Epoch: [1][1900/2877] Elapsed 10m 15s (remain 5m 15s) Loss: 0.0006(0.0233) Grad: 131.5748  LR: 0.000019  \n",
      "Epoch: [1][2000/2877] Elapsed 10m 46s (remain 4m 43s) Loss: 0.0009(0.0223) Grad: 137.2788  LR: 0.000019  \n",
      "Epoch: [1][2100/2877] Elapsed 11m 18s (remain 4m 10s) Loss: 0.0027(0.0214) Grad: 339.6583  LR: 0.000019  \n",
      "Epoch: [1][2200/2877] Elapsed 11m 49s (remain 3m 38s) Loss: 0.0074(0.0205) Grad: 1083.1234  LR: 0.000019  \n",
      "Epoch: [1][2300/2877] Elapsed 12m 22s (remain 3m 5s) Loss: 0.0015(0.0197) Grad: 316.5544  LR: 0.000019  \n",
      "Epoch: [1][2400/2877] Elapsed 12m 56s (remain 2m 33s) Loss: 0.0041(0.0190) Grad: 192.1371  LR: 0.000019  \n",
      "Epoch: [1][2500/2877] Elapsed 13m 28s (remain 2m 1s) Loss: 0.0007(0.0184) Grad: 92.3027  LR: 0.000018  \n",
      "Epoch: [1][2600/2877] Elapsed 14m 0s (remain 1m 29s) Loss: 0.0009(0.0178) Grad: 148.3768  LR: 0.000018  \n",
      "Epoch: [1][2700/2877] Elapsed 14m 32s (remain 0m 56s) Loss: 0.0003(0.0172) Grad: 52.5632  LR: 0.000018  \n",
      "Epoch: [1][2800/2877] Elapsed 15m 4s (remain 0m 24s) Loss: 0.0117(0.0167) Grad: 873.8329  LR: 0.000018  \n",
      "Epoch: [1][2876/2877] Elapsed 15m 28s (remain 0m 0s) Loss: 0.0003(0.0163) Grad: 34.6047  LR: 0.000018  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 34s) Loss: 0.0039(0.0039) \n",
      "EVAL: [100/698] Elapsed 0m 20s (remain 2m 2s) Loss: 0.0011(0.0015) \n",
      "EVAL: [200/698] Elapsed 0m 40s (remain 1m 40s) Loss: 0.0012(0.0021) \n",
      "EVAL: [300/698] Elapsed 1m 0s (remain 1m 19s) Loss: 0.0005(0.0019) \n",
      "EVAL: [400/698] Elapsed 1m 20s (remain 0m 59s) Loss: 0.0049(0.0022) \n",
      "EVAL: [500/698] Elapsed 1m 40s (remain 0m 39s) Loss: 0.0013(0.0022) \n",
      "EVAL: [600/698] Elapsed 2m 1s (remain 0m 19s) Loss: 0.0016(0.0021) \n",
      "EVAL: [697/698] Elapsed 2m 20s (remain 0m 0s) Loss: 0.0000(0.0020) \n",
      "Epoch 1 - avg_train_loss: 0.0163  avg_val_loss: 0.0020  time: 1075s\n",
      "Epoch 1 - Score: 0.8279\n",
      "Epoch 1 - Save Best Score: 0.8279 Model\n",
      "Epoch: [2][0/2877] Elapsed 0m 0s (remain 27m 3s) Loss: 0.0016(0.0016) Grad: 8224.2314  LR: 0.000018  \n",
      "Epoch: [2][100/2877] Elapsed 0m 33s (remain 15m 27s) Loss: 0.0002(0.0018) Grad: 1086.7933  LR: 0.000018  \n",
      "Epoch: [2][200/2877] Elapsed 1m 5s (remain 14m 37s) Loss: 0.0002(0.0020) Grad: 1198.3223  LR: 0.000017  \n",
      "Epoch: [2][300/2877] Elapsed 1m 38s (remain 13m 59s) Loss: 0.0005(0.0020) Grad: 3532.9250  LR: 0.000017  \n",
      "Epoch: [2][400/2877] Elapsed 2m 10s (remain 13m 27s) Loss: 0.0040(0.0019) Grad: 13385.8418  LR: 0.000017  \n",
      "Epoch: [2][500/2877] Elapsed 2m 44s (remain 12m 58s) Loss: 0.0004(0.0019) Grad: 2247.9766  LR: 0.000017  \n",
      "Epoch: [2][600/2877] Elapsed 3m 16s (remain 12m 25s) Loss: 0.0002(0.0019) Grad: 969.2457  LR: 0.000017  \n",
      "Epoch: [2][700/2877] Elapsed 3m 49s (remain 11m 52s) Loss: 0.0021(0.0020) Grad: 8774.6338  LR: 0.000017  \n",
      "Epoch: [2][800/2877] Elapsed 4m 21s (remain 11m 18s) Loss: 0.0049(0.0019) Grad: 22651.0156  LR: 0.000017  \n",
      "Epoch: [2][900/2877] Elapsed 4m 54s (remain 10m 45s) Loss: 0.0025(0.0019) Grad: 9493.0557  LR: 0.000016  \n",
      "Epoch: [2][1000/2877] Elapsed 5m 27s (remain 10m 13s) Loss: 0.0004(0.0019) Grad: 1829.4733  LR: 0.000016  \n",
      "Epoch: [2][1100/2877] Elapsed 6m 0s (remain 9m 41s) Loss: 0.0037(0.0019) Grad: 19533.0996  LR: 0.000016  \n",
      "Epoch: [2][1200/2877] Elapsed 6m 32s (remain 9m 8s) Loss: 0.0003(0.0019) Grad: 3050.7839  LR: 0.000016  \n",
      "Epoch: [2][1300/2877] Elapsed 7m 5s (remain 8m 35s) Loss: 0.0001(0.0019) Grad: 815.2758  LR: 0.000016  \n",
      "Epoch: [2][1400/2877] Elapsed 7m 37s (remain 8m 2s) Loss: 0.0060(0.0019) Grad: 21029.0742  LR: 0.000016  \n",
      "Epoch: [2][1500/2877] Elapsed 8m 10s (remain 7m 30s) Loss: 0.0015(0.0019) Grad: 9614.5234  LR: 0.000015  \n",
      "Epoch: [2][1600/2877] Elapsed 8m 43s (remain 6m 57s) Loss: 0.0001(0.0020) Grad: 739.5817  LR: 0.000015  \n",
      "Epoch: [2][1700/2877] Elapsed 9m 15s (remain 6m 24s) Loss: 0.0011(0.0020) Grad: 19411.5332  LR: 0.000015  \n",
      "Epoch: [2][1800/2877] Elapsed 9m 48s (remain 5m 51s) Loss: 0.0008(0.0020) Grad: 3923.5940  LR: 0.000015  \n",
      "Epoch: [2][1900/2877] Elapsed 10m 21s (remain 5m 18s) Loss: 0.0039(0.0020) Grad: 13708.9609  LR: 0.000015  \n",
      "Epoch: [2][2000/2877] Elapsed 10m 53s (remain 4m 46s) Loss: 0.0084(0.0020) Grad: 16204.4365  LR: 0.000015  \n",
      "Epoch: [2][2100/2877] Elapsed 11m 27s (remain 4m 13s) Loss: 0.0003(0.0020) Grad: 1726.3379  LR: 0.000015  \n",
      "Epoch: [2][2200/2877] Elapsed 12m 0s (remain 3m 41s) Loss: 0.0005(0.0020) Grad: 2958.5808  LR: 0.000014  \n",
      "Epoch: [2][2300/2877] Elapsed 12m 32s (remain 3m 8s) Loss: 0.0000(0.0020) Grad: 249.1517  LR: 0.000014  \n",
      "Epoch: [2][2400/2877] Elapsed 13m 5s (remain 2m 35s) Loss: 0.0000(0.0020) Grad: 440.4375  LR: 0.000014  \n",
      "Epoch: [2][2500/2877] Elapsed 13m 37s (remain 2m 2s) Loss: 0.0001(0.0020) Grad: 854.6825  LR: 0.000014  \n",
      "Epoch: [2][2600/2877] Elapsed 14m 9s (remain 1m 30s) Loss: 0.0001(0.0020) Grad: 1047.8849  LR: 0.000014  \n",
      "Epoch: [2][2700/2877] Elapsed 14m 42s (remain 0m 57s) Loss: 0.0006(0.0020) Grad: 6158.7695  LR: 0.000014  \n",
      "Epoch: [2][2800/2877] Elapsed 15m 15s (remain 0m 24s) Loss: 0.0180(0.0020) Grad: 45063.8750  LR: 0.000013  \n",
      "Epoch: [2][2876/2877] Elapsed 15m 40s (remain 0m 0s) Loss: 0.0000(0.0019) Grad: 86.7584  LR: 0.000013  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 49s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/698] Elapsed 0m 20s (remain 2m 2s) Loss: 0.0004(0.0014) \n",
      "EVAL: [200/698] Elapsed 0m 40s (remain 1m 41s) Loss: 0.0065(0.0022) \n",
      "EVAL: [300/698] Elapsed 1m 1s (remain 1m 20s) Loss: 0.0003(0.0021) \n",
      "EVAL: [400/698] Elapsed 1m 21s (remain 1m 0s) Loss: 0.0121(0.0023) \n",
      "EVAL: [500/698] Elapsed 1m 42s (remain 0m 40s) Loss: 0.0011(0.0023) \n",
      "EVAL: [600/698] Elapsed 2m 2s (remain 0m 19s) Loss: 0.0010(0.0022) \n",
      "EVAL: [697/698] Elapsed 2m 22s (remain 0m 0s) Loss: 0.0000(0.0022) \n",
      "Epoch 2 - avg_train_loss: 0.0019  avg_val_loss: 0.0022  time: 1088s\n",
      "Epoch 2 - Score: 0.8665\n",
      "Epoch 2 - Save Best Score: 0.8665 Model\n",
      "Epoch: [3][0/2877] Elapsed 0m 0s (remain 31m 58s) Loss: 0.0008(0.0008) Grad: 6631.2148  LR: 0.000013  \n",
      "Epoch: [3][100/2877] Elapsed 0m 34s (remain 15m 46s) Loss: 0.0085(0.0013) Grad: 30495.0332  LR: 0.000013  \n",
      "Epoch: [3][200/2877] Elapsed 1m 7s (remain 14m 52s) Loss: 0.0003(0.0014) Grad: 1803.7843  LR: 0.000013  \n",
      "Epoch: [3][300/2877] Elapsed 1m 41s (remain 14m 27s) Loss: 0.0000(0.0014) Grad: 230.5937  LR: 0.000013  \n",
      "Epoch: [3][400/2877] Elapsed 2m 14s (remain 13m 48s) Loss: 0.0005(0.0014) Grad: 3146.5256  LR: 0.000013  \n",
      "Epoch: [3][500/2877] Elapsed 2m 46s (remain 13m 10s) Loss: 0.0010(0.0014) Grad: 4855.4492  LR: 0.000013  \n",
      "Epoch: [3][600/2877] Elapsed 3m 18s (remain 12m 33s) Loss: 0.0013(0.0014) Grad: 7484.0288  LR: 0.000012  \n",
      "Epoch: [3][700/2877] Elapsed 3m 51s (remain 11m 57s) Loss: 0.0006(0.0014) Grad: 3923.5020  LR: 0.000012  \n",
      "Epoch: [3][800/2877] Elapsed 4m 23s (remain 11m 22s) Loss: 0.0001(0.0014) Grad: 739.2137  LR: 0.000012  \n",
      "Epoch: [3][900/2877] Elapsed 4m 56s (remain 10m 50s) Loss: 0.0009(0.0013) Grad: 8087.5522  LR: 0.000012  \n",
      "Epoch: [3][1000/2877] Elapsed 5m 30s (remain 10m 19s) Loss: 0.0008(0.0014) Grad: 4071.3286  LR: 0.000012  \n",
      "Epoch: [3][1100/2877] Elapsed 6m 2s (remain 9m 45s) Loss: 0.0021(0.0014) Grad: 11215.5645  LR: 0.000012  \n",
      "Epoch: [3][1200/2877] Elapsed 6m 35s (remain 9m 11s) Loss: 0.0004(0.0014) Grad: 2343.1948  LR: 0.000011  \n",
      "Epoch: [3][1300/2877] Elapsed 7m 7s (remain 8m 37s) Loss: 0.0000(0.0015) Grad: 387.5091  LR: 0.000011  \n",
      "Epoch: [3][1400/2877] Elapsed 7m 40s (remain 8m 4s) Loss: 0.0000(0.0014) Grad: 945.5474  LR: 0.000011  \n",
      "Epoch: [3][1500/2877] Elapsed 8m 13s (remain 7m 32s) Loss: 0.0039(0.0015) Grad: 13260.0361  LR: 0.000011  \n",
      "Epoch: [3][1600/2877] Elapsed 8m 46s (remain 6m 59s) Loss: 0.0008(0.0015) Grad: 13079.4238  LR: 0.000011  \n",
      "Epoch: [3][1700/2877] Elapsed 9m 19s (remain 6m 26s) Loss: 0.0192(0.0015) Grad: 51319.1211  LR: 0.000011  \n",
      "Epoch: [3][1800/2877] Elapsed 9m 51s (remain 5m 53s) Loss: 0.0008(0.0015) Grad: 2891.9233  LR: 0.000011  \n",
      "Epoch: [3][1900/2877] Elapsed 10m 23s (remain 5m 20s) Loss: 0.0002(0.0015) Grad: 1891.2424  LR: 0.000010  \n",
      "Epoch: [3][2000/2877] Elapsed 10m 57s (remain 4m 47s) Loss: 0.0006(0.0015) Grad: 2651.6929  LR: 0.000010  \n",
      "Epoch: [3][2100/2877] Elapsed 11m 31s (remain 4m 15s) Loss: 0.0000(0.0015) Grad: 165.4818  LR: 0.000010  \n",
      "Epoch: [3][2200/2877] Elapsed 12m 4s (remain 3m 42s) Loss: 0.0010(0.0015) Grad: 3218.5093  LR: 0.000010  \n",
      "Epoch: [3][2300/2877] Elapsed 12m 36s (remain 3m 9s) Loss: 0.0001(0.0015) Grad: 627.6641  LR: 0.000010  \n",
      "Epoch: [3][2400/2877] Elapsed 13m 8s (remain 2m 36s) Loss: 0.0000(0.0015) Grad: 78.6174  LR: 0.000010  \n",
      "Epoch: [3][2500/2877] Elapsed 13m 40s (remain 2m 3s) Loss: 0.0001(0.0015) Grad: 2055.5999  LR: 0.000009  \n",
      "Epoch: [3][2600/2877] Elapsed 14m 14s (remain 1m 30s) Loss: 0.0177(0.0015) Grad: 69368.5547  LR: 0.000009  \n",
      "Epoch: [3][2700/2877] Elapsed 14m 46s (remain 0m 57s) Loss: 0.0002(0.0015) Grad: 3307.8240  LR: 0.000009  \n",
      "Epoch: [3][2800/2877] Elapsed 15m 18s (remain 0m 24s) Loss: 0.0011(0.0015) Grad: 6533.5107  LR: 0.000009  \n",
      "Epoch: [3][2876/2877] Elapsed 15m 43s (remain 0m 0s) Loss: 0.0000(0.0015) Grad: 361.8353  LR: 0.000009  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 42s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 8s) Loss: 0.0002(0.0016) \n",
      "EVAL: [200/698] Elapsed 0m 41s (remain 1m 43s) Loss: 0.0020(0.0023) \n",
      "EVAL: [300/698] Elapsed 1m 1s (remain 1m 21s) Loss: 0.0002(0.0022) \n",
      "EVAL: [400/698] Elapsed 1m 21s (remain 1m 0s) Loss: 0.0117(0.0024) \n",
      "EVAL: [500/698] Elapsed 1m 42s (remain 0m 40s) Loss: 0.0023(0.0024) \n",
      "EVAL: [600/698] Elapsed 2m 2s (remain 0m 19s) Loss: 0.0019(0.0023) \n",
      "EVAL: [697/698] Elapsed 2m 21s (remain 0m 0s) Loss: 0.0000(0.0022) \n",
      "Epoch 3 - avg_train_loss: 0.0015  avg_val_loss: 0.0022  time: 1090s\n",
      "Epoch 3 - Score: 0.8787\n",
      "Epoch 3 - Save Best Score: 0.8787 Model\n",
      "Epoch: [4][0/2877] Elapsed 0m 0s (remain 29m 32s) Loss: 0.0015(0.0015) Grad: 30832.8984  LR: 0.000009  \n",
      "Epoch: [4][100/2877] Elapsed 0m 35s (remain 16m 9s) Loss: 0.0001(0.0012) Grad: 1080.0582  LR: 0.000009  \n",
      "Epoch: [4][200/2877] Elapsed 1m 8s (remain 15m 15s) Loss: 0.0005(0.0012) Grad: 4614.7100  LR: 0.000009  \n",
      "Epoch: [4][300/2877] Elapsed 1m 41s (remain 14m 25s) Loss: 0.0019(0.0012) Grad: 9450.4980  LR: 0.000008  \n",
      "Epoch: [4][400/2877] Elapsed 2m 13s (remain 13m 45s) Loss: 0.0002(0.0012) Grad: 1250.5720  LR: 0.000008  \n",
      "Epoch: [4][500/2877] Elapsed 2m 49s (remain 13m 21s) Loss: 0.0026(0.0011) Grad: 21457.8145  LR: 0.000008  \n",
      "Epoch: [4][600/2877] Elapsed 3m 21s (remain 12m 42s) Loss: 0.0031(0.0013) Grad: 17859.1484  LR: 0.000008  \n",
      "Epoch: [4][700/2877] Elapsed 3m 53s (remain 12m 4s) Loss: 0.0012(0.0012) Grad: 20933.1641  LR: 0.000008  \n",
      "Epoch: [4][800/2877] Elapsed 4m 25s (remain 11m 28s) Loss: 0.0011(0.0014) Grad: 8541.0996  LR: 0.000008  \n",
      "Epoch: [4][900/2877] Elapsed 4m 59s (remain 10m 56s) Loss: 0.0000(0.0014) Grad: 80.5990  LR: 0.000007  \n",
      "Epoch: [4][1000/2877] Elapsed 5m 33s (remain 10m 25s) Loss: 0.0002(0.0014) Grad: 1008.0535  LR: 0.000007  \n",
      "Epoch: [4][1100/2877] Elapsed 6m 6s (remain 9m 51s) Loss: 0.0000(0.0014) Grad: 41.6086  LR: 0.000007  \n",
      "Epoch: [4][1200/2877] Elapsed 6m 39s (remain 9m 16s) Loss: 0.0005(0.0014) Grad: 4581.4297  LR: 0.000007  \n",
      "Epoch: [4][1300/2877] Elapsed 7m 11s (remain 8m 42s) Loss: 0.0000(0.0013) Grad: 125.0571  LR: 0.000007  \n",
      "Epoch: [4][1400/2877] Elapsed 7m 43s (remain 8m 8s) Loss: 0.0007(0.0014) Grad: 14648.6924  LR: 0.000007  \n",
      "Epoch: [4][1500/2877] Elapsed 8m 16s (remain 7m 34s) Loss: 0.0004(0.0014) Grad: 5502.3955  LR: 0.000007  \n",
      "Epoch: [4][1600/2877] Elapsed 8m 48s (remain 7m 1s) Loss: 0.0004(0.0013) Grad: 2346.1787  LR: 0.000006  \n",
      "Epoch: [4][1700/2877] Elapsed 9m 21s (remain 6m 27s) Loss: 0.0003(0.0014) Grad: 2642.7627  LR: 0.000006  \n",
      "Epoch: [4][1800/2877] Elapsed 9m 55s (remain 5m 56s) Loss: 0.0001(0.0014) Grad: 425.4841  LR: 0.000006  \n",
      "Epoch: [4][1900/2877] Elapsed 10m 31s (remain 5m 24s) Loss: 0.0006(0.0014) Grad: 3149.6479  LR: 0.000006  \n",
      "Epoch: [4][2000/2877] Elapsed 11m 4s (remain 4m 50s) Loss: 0.0001(0.0013) Grad: 1164.1470  LR: 0.000006  \n",
      "Epoch: [4][2100/2877] Elapsed 11m 36s (remain 4m 17s) Loss: 0.0005(0.0014) Grad: 4432.4873  LR: 0.000006  \n",
      "Epoch: [4][2200/2877] Elapsed 12m 9s (remain 3m 44s) Loss: 0.0003(0.0013) Grad: 2672.1135  LR: 0.000005  \n",
      "Epoch: [4][2300/2877] Elapsed 12m 42s (remain 3m 10s) Loss: 0.0001(0.0013) Grad: 805.0554  LR: 0.000005  \n",
      "Epoch: [4][2400/2877] Elapsed 13m 14s (remain 2m 37s) Loss: 0.0071(0.0013) Grad: 19859.0176  LR: 0.000005  \n",
      "Epoch: [4][2500/2877] Elapsed 13m 47s (remain 2m 4s) Loss: 0.0003(0.0013) Grad: 1544.3176  LR: 0.000005  \n",
      "Epoch: [4][2600/2877] Elapsed 14m 19s (remain 1m 31s) Loss: 0.0000(0.0013) Grad: 54.3460  LR: 0.000005  \n",
      "Epoch: [4][2700/2877] Elapsed 14m 51s (remain 0m 58s) Loss: 0.0010(0.0013) Grad: 6708.2607  LR: 0.000005  \n",
      "Epoch: [4][2800/2877] Elapsed 15m 24s (remain 0m 25s) Loss: 0.0007(0.0013) Grad: 4000.5876  LR: 0.000005  \n",
      "Epoch: [4][2876/2877] Elapsed 15m 49s (remain 0m 0s) Loss: 0.0005(0.0013) Grad: 5577.6943  LR: 0.000004  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 45s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/698] Elapsed 0m 20s (remain 2m 3s) Loss: 0.0003(0.0019) \n",
      "EVAL: [200/698] Elapsed 0m 41s (remain 1m 41s) Loss: 0.0028(0.0028) \n",
      "EVAL: [300/698] Elapsed 1m 0s (remain 1m 20s) Loss: 0.0002(0.0028) \n",
      "EVAL: [400/698] Elapsed 1m 20s (remain 0m 59s) Loss: 0.0210(0.0030) \n",
      "EVAL: [500/698] Elapsed 1m 41s (remain 0m 40s) Loss: 0.0020(0.0030) \n",
      "EVAL: [600/698] Elapsed 2m 3s (remain 0m 19s) Loss: 0.0010(0.0028) \n",
      "EVAL: [697/698] Elapsed 2m 24s (remain 0m 0s) Loss: 0.0000(0.0028) \n",
      "Epoch 4 - avg_train_loss: 0.0013  avg_val_loss: 0.0028  time: 1099s\n",
      "Epoch 4 - Score: 0.8791\n",
      "Epoch 4 - Save Best Score: 0.8791 Model\n",
      "Epoch: [5][0/2877] Elapsed 0m 0s (remain 30m 2s) Loss: 0.0002(0.0002) Grad: 2777.2856  LR: 0.000004  \n",
      "Epoch: [5][100/2877] Elapsed 0m 33s (remain 15m 7s) Loss: 0.0009(0.0011) Grad: 10611.5557  LR: 0.000004  \n",
      "Epoch: [5][200/2877] Elapsed 1m 6s (remain 14m 51s) Loss: 0.0025(0.0011) Grad: 8424.9004  LR: 0.000004  \n",
      "Epoch: [5][300/2877] Elapsed 1m 39s (remain 14m 9s) Loss: 0.0016(0.0009) Grad: 7898.1807  LR: 0.000004  \n",
      "Epoch: [5][400/2877] Elapsed 2m 11s (remain 13m 30s) Loss: 0.0005(0.0010) Grad: 5403.3535  LR: 0.000004  \n",
      "Epoch: [5][500/2877] Elapsed 2m 44s (remain 13m 1s) Loss: 0.0000(0.0010) Grad: 44.2531  LR: 0.000004  \n",
      "Epoch: [5][600/2877] Elapsed 3m 17s (remain 12m 27s) Loss: 0.0000(0.0010) Grad: 72.3284  LR: 0.000004  \n",
      "Epoch: [5][700/2877] Elapsed 3m 49s (remain 11m 53s) Loss: 0.0001(0.0011) Grad: 801.3369  LR: 0.000003  \n",
      "Epoch: [5][800/2877] Elapsed 4m 22s (remain 11m 20s) Loss: 0.0000(0.0011) Grad: 63.9595  LR: 0.000003  \n",
      "Epoch: [5][900/2877] Elapsed 4m 56s (remain 10m 50s) Loss: 0.0000(0.0011) Grad: 22.4967  LR: 0.000003  \n",
      "Epoch: [5][1000/2877] Elapsed 5m 29s (remain 10m 16s) Loss: 0.0004(0.0011) Grad: 3748.3254  LR: 0.000003  \n",
      "Epoch: [5][1100/2877] Elapsed 6m 1s (remain 9m 42s) Loss: 0.0025(0.0011) Grad: 15786.2871  LR: 0.000003  \n",
      "Epoch: [5][1200/2877] Elapsed 6m 32s (remain 9m 8s) Loss: 0.0001(0.0011) Grad: 675.1791  LR: 0.000003  \n",
      "Epoch: [5][1300/2877] Elapsed 7m 5s (remain 8m 34s) Loss: 0.0008(0.0010) Grad: 5871.8208  LR: 0.000002  \n",
      "Epoch: [5][1400/2877] Elapsed 7m 38s (remain 8m 3s) Loss: 0.0003(0.0010) Grad: 2885.8020  LR: 0.000002  \n",
      "Epoch: [5][1500/2877] Elapsed 8m 12s (remain 7m 31s) Loss: 0.0000(0.0011) Grad: 50.6224  LR: 0.000002  \n",
      "Epoch: [5][1600/2877] Elapsed 8m 44s (remain 6m 58s) Loss: 0.0004(0.0011) Grad: 3510.1863  LR: 0.000002  \n",
      "Epoch: [5][1700/2877] Elapsed 9m 16s (remain 6m 25s) Loss: 0.0000(0.0011) Grad: 190.1570  LR: 0.000002  \n",
      "Epoch: [5][1800/2877] Elapsed 9m 49s (remain 5m 51s) Loss: 0.0021(0.0011) Grad: 11035.0566  LR: 0.000002  \n",
      "Epoch: [5][1900/2877] Elapsed 10m 22s (remain 5m 19s) Loss: 0.0001(0.0011) Grad: 2794.1130  LR: 0.000002  \n",
      "Epoch: [5][2000/2877] Elapsed 10m 58s (remain 4m 48s) Loss: 0.0006(0.0011) Grad: 6053.3999  LR: 0.000001  \n",
      "Epoch: [5][2100/2877] Elapsed 11m 31s (remain 4m 15s) Loss: 0.0005(0.0011) Grad: 8296.0195  LR: 0.000001  \n",
      "Epoch: [5][2200/2877] Elapsed 12m 3s (remain 3m 42s) Loss: 0.0001(0.0011) Grad: 527.7756  LR: 0.000001  \n",
      "Epoch: [5][2300/2877] Elapsed 12m 35s (remain 3m 9s) Loss: 0.0004(0.0012) Grad: 6582.0405  LR: 0.000001  \n",
      "Epoch: [5][2400/2877] Elapsed 13m 8s (remain 2m 36s) Loss: 0.0000(0.0012) Grad: 96.0281  LR: 0.000001  \n",
      "Epoch: [5][2500/2877] Elapsed 13m 40s (remain 2m 3s) Loss: 0.0028(0.0011) Grad: 30996.0762  LR: 0.000001  \n",
      "Epoch: [5][2600/2877] Elapsed 14m 13s (remain 1m 30s) Loss: 0.0000(0.0012) Grad: 575.2379  LR: 0.000000  \n",
      "Epoch: [5][2700/2877] Elapsed 14m 47s (remain 0m 57s) Loss: 0.0000(0.0012) Grad: 75.4089  LR: 0.000000  \n",
      "Epoch: [5][2800/2877] Elapsed 15m 20s (remain 0m 24s) Loss: 0.0003(0.0011) Grad: 1770.6498  LR: 0.000000  \n",
      "Epoch: [5][2876/2877] Elapsed 15m 44s (remain 0m 0s) Loss: 0.0019(0.0011) Grad: 14054.2324  LR: 0.000000  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 6m 9s) Loss: 0.0002(0.0002) \n",
      "EVAL: [100/698] Elapsed 0m 22s (remain 2m 10s) Loss: 0.0002(0.0020) \n",
      "EVAL: [200/698] Elapsed 0m 43s (remain 1m 47s) Loss: 0.0001(0.0030) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0001(0.0030) \n",
      "EVAL: [400/698] Elapsed 1m 24s (remain 1m 2s) Loss: 0.0197(0.0033) \n",
      "EVAL: [500/698] Elapsed 1m 44s (remain 0m 41s) Loss: 0.0028(0.0032) \n",
      "EVAL: [600/698] Elapsed 2m 4s (remain 0m 20s) Loss: 0.0012(0.0030) \n",
      "EVAL: [697/698] Elapsed 2m 23s (remain 0m 0s) Loss: 0.0000(0.0029) \n",
      "Epoch 5 - avg_train_loss: 0.0011  avg_val_loss: 0.0029  time: 1093s\n",
      "Epoch 5 - Score: 0.8827\n",
      "Epoch 5 - Save Best Score: 0.8827 Model\n",
      "========== fold: 4 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2850] Elapsed 0m 0s (remain 26m 49s) Loss: 0.1450(0.1450) Grad: inf  LR: 0.000000  \n",
      "Epoch: [1][100/2850] Elapsed 0m 34s (remain 15m 30s) Loss: 0.0429(0.1159) Grad: 17258.6621  LR: 0.000001  \n",
      "Epoch: [1][200/2850] Elapsed 1m 7s (remain 14m 48s) Loss: 0.0037(0.0722) Grad: 1816.6184  LR: 0.000003  \n",
      "Epoch: [1][300/2850] Elapsed 1m 41s (remain 14m 18s) Loss: 0.0125(0.0525) Grad: 1301.2280  LR: 0.000004  \n",
      "Epoch: [1][400/2850] Elapsed 2m 13s (remain 13m 35s) Loss: 0.0131(0.0428) Grad: 1110.1782  LR: 0.000006  \n",
      "Epoch: [1][500/2850] Elapsed 2m 46s (remain 12m 58s) Loss: 0.0065(0.0367) Grad: 1739.8688  LR: 0.000007  \n",
      "Epoch: [1][600/2850] Elapsed 3m 18s (remain 12m 23s) Loss: 0.0125(0.0325) Grad: 1893.8602  LR: 0.000008  \n",
      "Epoch: [1][700/2850] Elapsed 3m 52s (remain 11m 51s) Loss: 0.0110(0.0291) Grad: 3701.7454  LR: 0.000010  \n",
      "Epoch: [1][800/2850] Elapsed 4m 24s (remain 11m 16s) Loss: 0.0054(0.0263) Grad: 2933.6245  LR: 0.000011  \n",
      "Epoch: [1][900/2850] Elapsed 4m 57s (remain 10m 42s) Loss: 0.0023(0.0239) Grad: 2106.2048  LR: 0.000013  \n",
      "Epoch: [1][1000/2850] Elapsed 5m 29s (remain 10m 8s) Loss: 0.0063(0.0220) Grad: 2506.4216  LR: 0.000014  \n",
      "Epoch: [1][1100/2850] Elapsed 6m 2s (remain 9m 35s) Loss: 0.0050(0.0205) Grad: 2469.4424  LR: 0.000015  \n",
      "Epoch: [1][1200/2850] Elapsed 6m 35s (remain 9m 3s) Loss: 0.0060(0.0191) Grad: 3905.9021  LR: 0.000017  \n",
      "Epoch: [1][1300/2850] Elapsed 7m 9s (remain 8m 31s) Loss: 0.0003(0.0179) Grad: 246.0242  LR: 0.000018  \n",
      "Epoch: [1][1400/2850] Elapsed 7m 42s (remain 7m 58s) Loss: 0.0009(0.0168) Grad: 572.9266  LR: 0.000020  \n",
      "Epoch: [1][1500/2850] Elapsed 8m 15s (remain 7m 25s) Loss: 0.0010(0.0160) Grad: 1174.5728  LR: 0.000020  \n",
      "Epoch: [1][1600/2850] Elapsed 8m 47s (remain 6m 51s) Loss: 0.0050(0.0152) Grad: 1043.4943  LR: 0.000020  \n",
      "Epoch: [1][1700/2850] Elapsed 9m 19s (remain 6m 17s) Loss: 0.0006(0.0144) Grad: 2026.5436  LR: 0.000020  \n",
      "Epoch: [1][1800/2850] Elapsed 9m 53s (remain 5m 45s) Loss: 0.0023(0.0138) Grad: 1445.0144  LR: 0.000019  \n",
      "Epoch: [1][1900/2850] Elapsed 10m 26s (remain 5m 12s) Loss: 0.0035(0.0132) Grad: 1125.3606  LR: 0.000019  \n",
      "Epoch: [1][2000/2850] Elapsed 10m 57s (remain 4m 39s) Loss: 0.0009(0.0128) Grad: 295.1323  LR: 0.000019  \n",
      "Epoch: [1][2100/2850] Elapsed 11m 30s (remain 4m 5s) Loss: 0.0038(0.0123) Grad: 4407.2993  LR: 0.000019  \n",
      "Epoch: [1][2200/2850] Elapsed 12m 2s (remain 3m 33s) Loss: 0.0006(0.0118) Grad: 387.7567  LR: 0.000019  \n",
      "Epoch: [1][2300/2850] Elapsed 12m 37s (remain 3m 0s) Loss: 0.0003(0.0115) Grad: 211.7716  LR: 0.000019  \n",
      "Epoch: [1][2400/2850] Elapsed 13m 10s (remain 2m 27s) Loss: 0.0014(0.0111) Grad: 1347.1317  LR: 0.000018  \n",
      "Epoch: [1][2500/2850] Elapsed 13m 42s (remain 1m 54s) Loss: 0.0028(0.0107) Grad: 1466.6881  LR: 0.000018  \n",
      "Epoch: [1][2600/2850] Elapsed 14m 14s (remain 1m 21s) Loss: 0.0008(0.0104) Grad: 1650.3951  LR: 0.000018  \n",
      "Epoch: [1][2700/2850] Elapsed 14m 46s (remain 0m 48s) Loss: 0.0002(0.0101) Grad: 113.9465  LR: 0.000018  \n",
      "Epoch: [1][2800/2850] Elapsed 15m 18s (remain 0m 16s) Loss: 0.0013(0.0099) Grad: 364.7737  LR: 0.000018  \n",
      "Epoch: [1][2849/2850] Elapsed 15m 34s (remain 0m 0s) Loss: 0.0006(0.0097) Grad: 633.0605  LR: 0.000018  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 56s) Loss: 0.0042(0.0042) \n",
      "EVAL: [100/725] Elapsed 0m 20s (remain 2m 6s) Loss: 0.0003(0.0023) \n",
      "EVAL: [200/725] Elapsed 0m 40s (remain 1m 46s) Loss: 0.0024(0.0026) \n",
      "EVAL: [300/725] Elapsed 1m 0s (remain 1m 25s) Loss: 0.0039(0.0022) \n",
      "EVAL: [400/725] Elapsed 1m 20s (remain 1m 5s) Loss: 0.0380(0.0025) \n",
      "EVAL: [500/725] Elapsed 1m 40s (remain 0m 44s) Loss: 0.0019(0.0025) \n",
      "EVAL: [600/725] Elapsed 2m 1s (remain 0m 24s) Loss: 0.0018(0.0024) \n",
      "EVAL: [700/725] Elapsed 2m 21s (remain 0m 4s) Loss: 0.0005(0.0023) \n",
      "EVAL: [724/725] Elapsed 2m 26s (remain 0m 0s) Loss: 0.0049(0.0022) \n",
      "Epoch 1 - avg_train_loss: 0.0097  avg_val_loss: 0.0022  time: 1086s\n",
      "Epoch 1 - Score: 0.8427\n",
      "Epoch 1 - Save Best Score: 0.8427 Model\n",
      "Epoch: [2][0/2850] Elapsed 0m 0s (remain 26m 46s) Loss: 0.0019(0.0019) Grad: 3282.9448  LR: 0.000018  \n",
      "Epoch: [2][100/2850] Elapsed 0m 33s (remain 15m 5s) Loss: 0.0014(0.0018) Grad: 5029.8940  LR: 0.000018  \n",
      "Epoch: [2][200/2850] Elapsed 1m 5s (remain 14m 23s) Loss: 0.0029(0.0019) Grad: 20752.5586  LR: 0.000017  \n",
      "Epoch: [2][300/2850] Elapsed 1m 38s (remain 13m 51s) Loss: 0.0352(0.0018) Grad: 29779.3027  LR: 0.000017  \n",
      "Epoch: [2][400/2850] Elapsed 2m 11s (remain 13m 22s) Loss: 0.0000(0.0019) Grad: 272.7821  LR: 0.000017  \n",
      "Epoch: [2][500/2850] Elapsed 2m 46s (remain 12m 59s) Loss: 0.0004(0.0022) Grad: 1896.3678  LR: 0.000017  \n",
      "Epoch: [2][600/2850] Elapsed 3m 21s (remain 12m 32s) Loss: 0.0009(0.0021) Grad: 6796.7490  LR: 0.000017  \n",
      "Epoch: [2][700/2850] Elapsed 3m 53s (remain 11m 56s) Loss: 0.0010(0.0022) Grad: 7664.4224  LR: 0.000017  \n",
      "Epoch: [2][800/2850] Elapsed 4m 26s (remain 11m 20s) Loss: 0.0005(0.0021) Grad: 3246.8318  LR: 0.000017  \n",
      "Epoch: [2][900/2850] Elapsed 4m 58s (remain 10m 45s) Loss: 0.0110(0.0021) Grad: 24973.3340  LR: 0.000016  \n",
      "Epoch: [2][1000/2850] Elapsed 5m 32s (remain 10m 13s) Loss: 0.0135(0.0021) Grad: 41339.2109  LR: 0.000016  \n",
      "Epoch: [2][1100/2850] Elapsed 6m 6s (remain 9m 42s) Loss: 0.0037(0.0021) Grad: 3320.9480  LR: 0.000016  \n",
      "Epoch: [2][1200/2850] Elapsed 6m 39s (remain 9m 8s) Loss: 0.0025(0.0020) Grad: 7136.9580  LR: 0.000016  \n",
      "Epoch: [2][1300/2850] Elapsed 7m 11s (remain 8m 33s) Loss: 0.0033(0.0020) Grad: 5383.2139  LR: 0.000016  \n",
      "Epoch: [2][1400/2850] Elapsed 7m 44s (remain 8m 0s) Loss: 0.0017(0.0021) Grad: 4609.8047  LR: 0.000016  \n",
      "Epoch: [2][1500/2850] Elapsed 8m 17s (remain 7m 26s) Loss: 0.0003(0.0021) Grad: 769.5312  LR: 0.000015  \n",
      "Epoch: [2][1600/2850] Elapsed 8m 50s (remain 6m 54s) Loss: 0.0001(0.0020) Grad: 472.9510  LR: 0.000015  \n",
      "Epoch: [2][1700/2850] Elapsed 9m 23s (remain 6m 20s) Loss: 0.0041(0.0020) Grad: 14876.4648  LR: 0.000015  \n",
      "Epoch: [2][1800/2850] Elapsed 9m 55s (remain 5m 47s) Loss: 0.0039(0.0021) Grad: 7356.1934  LR: 0.000015  \n",
      "Epoch: [2][1900/2850] Elapsed 10m 28s (remain 5m 13s) Loss: 0.0010(0.0020) Grad: 1654.3286  LR: 0.000015  \n",
      "Epoch: [2][2000/2850] Elapsed 11m 0s (remain 4m 40s) Loss: 0.0005(0.0021) Grad: 3191.1882  LR: 0.000015  \n",
      "Epoch: [2][2100/2850] Elapsed 11m 33s (remain 4m 7s) Loss: 0.0001(0.0021) Grad: 553.8715  LR: 0.000015  \n",
      "Epoch: [2][2200/2850] Elapsed 12m 6s (remain 3m 34s) Loss: 0.0030(0.0021) Grad: 11077.0820  LR: 0.000014  \n",
      "Epoch: [2][2300/2850] Elapsed 12m 38s (remain 3m 1s) Loss: 0.0002(0.0021) Grad: 776.8851  LR: 0.000014  \n",
      "Epoch: [2][2400/2850] Elapsed 13m 11s (remain 2m 28s) Loss: 0.0011(0.0020) Grad: 1776.6512  LR: 0.000014  \n",
      "Epoch: [2][2500/2850] Elapsed 13m 45s (remain 1m 55s) Loss: 0.0008(0.0020) Grad: 1867.1450  LR: 0.000014  \n",
      "Epoch: [2][2600/2850] Elapsed 14m 18s (remain 1m 22s) Loss: 0.0009(0.0020) Grad: 1983.8900  LR: 0.000014  \n",
      "Epoch: [2][2700/2850] Elapsed 14m 51s (remain 0m 49s) Loss: 0.0000(0.0021) Grad: 119.2080  LR: 0.000014  \n",
      "Epoch: [2][2800/2850] Elapsed 15m 23s (remain 0m 16s) Loss: 0.0005(0.0020) Grad: 695.5608  LR: 0.000013  \n",
      "Epoch: [2][2849/2850] Elapsed 15m 39s (remain 0m 0s) Loss: 0.0176(0.0020) Grad: 18235.9004  LR: 0.000013  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 9s) Loss: 0.0034(0.0034) \n",
      "EVAL: [100/725] Elapsed 0m 20s (remain 2m 5s) Loss: 0.0003(0.0025) \n",
      "EVAL: [200/725] Elapsed 0m 40s (remain 1m 46s) Loss: 0.0009(0.0028) \n",
      "EVAL: [300/725] Elapsed 1m 1s (remain 1m 26s) Loss: 0.0042(0.0024) \n",
      "EVAL: [400/725] Elapsed 1m 21s (remain 1m 5s) Loss: 0.0132(0.0025) \n",
      "EVAL: [500/725] Elapsed 1m 41s (remain 0m 45s) Loss: 0.0019(0.0025) \n",
      "EVAL: [600/725] Elapsed 2m 3s (remain 0m 25s) Loss: 0.0010(0.0025) \n",
      "EVAL: [700/725] Elapsed 2m 25s (remain 0m 4s) Loss: 0.0000(0.0023) \n",
      "EVAL: [724/725] Elapsed 2m 30s (remain 0m 0s) Loss: 0.0053(0.0023) \n",
      "Epoch 2 - avg_train_loss: 0.0020  avg_val_loss: 0.0023  time: 1095s\n",
      "Epoch 2 - Score: 0.8672\n",
      "Epoch 2 - Save Best Score: 0.8672 Model\n",
      "Epoch: [3][0/2850] Elapsed 0m 0s (remain 29m 55s) Loss: 0.0002(0.0002) Grad: 2229.0715  LR: 0.000013  \n",
      "Epoch: [3][100/2850] Elapsed 0m 33s (remain 15m 1s) Loss: 0.0000(0.0015) Grad: 490.5292  LR: 0.000013  \n",
      "Epoch: [3][200/2850] Elapsed 1m 5s (remain 14m 18s) Loss: 0.0001(0.0013) Grad: 926.4033  LR: 0.000013  \n",
      "Epoch: [3][300/2850] Elapsed 1m 37s (remain 13m 45s) Loss: 0.0001(0.0015) Grad: 658.4609  LR: 0.000013  \n",
      "Epoch: [3][400/2850] Elapsed 2m 11s (remain 13m 22s) Loss: 0.0009(0.0015) Grad: 7866.4570  LR: 0.000013  \n",
      "Epoch: [3][500/2850] Elapsed 2m 46s (remain 13m 2s) Loss: 0.0009(0.0015) Grad: 3849.0266  LR: 0.000013  \n",
      "Epoch: [3][600/2850] Elapsed 3m 21s (remain 12m 34s) Loss: 0.0002(0.0015) Grad: 1201.8813  LR: 0.000012  \n",
      "Epoch: [3][700/2850] Elapsed 3m 54s (remain 11m 58s) Loss: 0.0001(0.0015) Grad: 622.0693  LR: 0.000012  \n",
      "Epoch: [3][800/2850] Elapsed 4m 26s (remain 11m 21s) Loss: 0.0037(0.0016) Grad: 10286.5645  LR: 0.000012  \n",
      "Epoch: [3][900/2850] Elapsed 5m 0s (remain 10m 49s) Loss: 0.0018(0.0016) Grad: 7522.3125  LR: 0.000012  \n",
      "Epoch: [3][1000/2850] Elapsed 5m 33s (remain 10m 16s) Loss: 0.0007(0.0016) Grad: 3870.7476  LR: 0.000012  \n",
      "Epoch: [3][1100/2850] Elapsed 6m 5s (remain 9m 41s) Loss: 0.0000(0.0016) Grad: 153.2775  LR: 0.000012  \n",
      "Epoch: [3][1200/2850] Elapsed 6m 38s (remain 9m 6s) Loss: 0.0027(0.0016) Grad: 12433.6104  LR: 0.000011  \n",
      "Epoch: [3][1300/2850] Elapsed 7m 11s (remain 8m 33s) Loss: 0.0174(0.0016) Grad: 47019.1367  LR: 0.000011  \n",
      "Epoch: [3][1400/2850] Elapsed 7m 43s (remain 7m 59s) Loss: 0.0000(0.0015) Grad: 178.7761  LR: 0.000011  \n",
      "Epoch: [3][1500/2850] Elapsed 8m 17s (remain 7m 26s) Loss: 0.0004(0.0015) Grad: 2520.8730  LR: 0.000011  \n",
      "Epoch: [3][1600/2850] Elapsed 8m 52s (remain 6m 55s) Loss: 0.0000(0.0015) Grad: 160.7122  LR: 0.000011  \n",
      "Epoch: [3][1700/2850] Elapsed 9m 26s (remain 6m 22s) Loss: 0.0018(0.0015) Grad: 18356.3867  LR: 0.000011  \n",
      "Epoch: [3][1800/2850] Elapsed 9m 59s (remain 5m 49s) Loss: 0.0011(0.0015) Grad: 3259.9473  LR: 0.000011  \n",
      "Epoch: [3][1900/2850] Elapsed 10m 31s (remain 5m 15s) Loss: 0.0018(0.0016) Grad: 6575.1616  LR: 0.000010  \n",
      "Epoch: [3][2000/2850] Elapsed 11m 4s (remain 4m 41s) Loss: 0.0000(0.0016) Grad: 28.0646  LR: 0.000010  \n",
      "Epoch: [3][2100/2850] Elapsed 11m 37s (remain 4m 8s) Loss: 0.0047(0.0016) Grad: 11861.1875  LR: 0.000010  \n",
      "Epoch: [3][2200/2850] Elapsed 12m 10s (remain 3m 35s) Loss: 0.0092(0.0016) Grad: 10506.5068  LR: 0.000010  \n",
      "Epoch: [3][2300/2850] Elapsed 12m 42s (remain 3m 1s) Loss: 0.0009(0.0016) Grad: 4398.3071  LR: 0.000010  \n",
      "Epoch: [3][2400/2850] Elapsed 13m 14s (remain 2m 28s) Loss: 0.0032(0.0016) Grad: 6109.7969  LR: 0.000010  \n",
      "Epoch: [3][2500/2850] Elapsed 13m 46s (remain 1m 55s) Loss: 0.0020(0.0016) Grad: 93037.2891  LR: 0.000009  \n",
      "Epoch: [3][2600/2850] Elapsed 14m 20s (remain 1m 22s) Loss: 0.0007(0.0016) Grad: 4040.8982  LR: 0.000009  \n",
      "Epoch: [3][2700/2850] Elapsed 14m 53s (remain 0m 49s) Loss: 0.0000(0.0016) Grad: 13.9239  LR: 0.000009  \n",
      "Epoch: [3][2800/2850] Elapsed 15m 26s (remain 0m 16s) Loss: 0.0042(0.0016) Grad: 11894.1758  LR: 0.000009  \n",
      "Epoch: [3][2849/2850] Elapsed 15m 41s (remain 0m 0s) Loss: 0.0007(0.0016) Grad: 9357.0615  LR: 0.000009  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 15s) Loss: 0.0084(0.0084) \n",
      "EVAL: [100/725] Elapsed 0m 20s (remain 2m 6s) Loss: 0.0004(0.0025) \n",
      "EVAL: [200/725] Elapsed 0m 41s (remain 1m 47s) Loss: 0.0009(0.0029) \n",
      "EVAL: [300/725] Elapsed 1m 1s (remain 1m 27s) Loss: 0.0071(0.0025) \n",
      "EVAL: [400/725] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0151(0.0026) \n",
      "EVAL: [500/725] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0038(0.0026) \n",
      "EVAL: [600/725] Elapsed 2m 5s (remain 0m 25s) Loss: 0.0024(0.0025) \n",
      "EVAL: [700/725] Elapsed 2m 25s (remain 0m 4s) Loss: 0.0001(0.0024) \n",
      "EVAL: [724/725] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0048(0.0024) \n",
      "Epoch 3 - avg_train_loss: 0.0016  avg_val_loss: 0.0024  time: 1097s\n",
      "Epoch 3 - Score: 0.8758\n",
      "Epoch 3 - Save Best Score: 0.8758 Model\n",
      "Epoch: [4][0/2850] Elapsed 0m 0s (remain 29m 59s) Loss: 0.0010(0.0010) Grad: 5907.4253  LR: 0.000009  \n",
      "Epoch: [4][100/2850] Elapsed 0m 35s (remain 15m 56s) Loss: 0.0002(0.0007) Grad: 3118.4478  LR: 0.000009  \n",
      "Epoch: [4][200/2850] Elapsed 1m 7s (remain 14m 49s) Loss: 0.0007(0.0010) Grad: 4646.2495  LR: 0.000009  \n",
      "Epoch: [4][300/2850] Elapsed 1m 39s (remain 14m 4s) Loss: 0.0002(0.0011) Grad: 6823.2056  LR: 0.000008  \n",
      "Epoch: [4][400/2850] Elapsed 2m 12s (remain 13m 27s) Loss: 0.0010(0.0011) Grad: 6003.2363  LR: 0.000008  \n",
      "Epoch: [4][500/2850] Elapsed 2m 44s (remain 12m 50s) Loss: 0.0021(0.0011) Grad: 15291.4355  LR: 0.000008  \n",
      "Epoch: [4][600/2850] Elapsed 3m 16s (remain 12m 16s) Loss: 0.0104(0.0012) Grad: 23443.6152  LR: 0.000008  \n",
      "Epoch: [4][700/2850] Elapsed 3m 50s (remain 11m 46s) Loss: 0.0000(0.0011) Grad: 111.5163  LR: 0.000008  \n",
      "Epoch: [4][800/2850] Elapsed 4m 22s (remain 11m 11s) Loss: 0.0013(0.0012) Grad: 4685.2285  LR: 0.000008  \n",
      "Epoch: [4][900/2850] Elapsed 4m 56s (remain 10m 41s) Loss: 0.0001(0.0012) Grad: 751.1559  LR: 0.000007  \n",
      "Epoch: [4][1000/2850] Elapsed 5m 29s (remain 10m 8s) Loss: 0.0029(0.0012) Grad: 4546.8154  LR: 0.000007  \n",
      "Epoch: [4][1100/2850] Elapsed 6m 1s (remain 9m 34s) Loss: 0.0014(0.0012) Grad: 7970.3442  LR: 0.000007  \n",
      "Epoch: [4][1200/2850] Elapsed 6m 33s (remain 9m 0s) Loss: 0.0002(0.0012) Grad: 1921.6436  LR: 0.000007  \n",
      "Epoch: [4][1300/2850] Elapsed 7m 6s (remain 8m 27s) Loss: 0.0008(0.0012) Grad: 3486.9521  LR: 0.000007  \n",
      "Epoch: [4][1400/2850] Elapsed 7m 38s (remain 7m 54s) Loss: 0.0000(0.0012) Grad: 477.9760  LR: 0.000007  \n",
      "Epoch: [4][1500/2850] Elapsed 8m 14s (remain 7m 23s) Loss: 0.0019(0.0012) Grad: 6159.3423  LR: 0.000007  \n",
      "Epoch: [4][1600/2850] Elapsed 8m 47s (remain 6m 51s) Loss: 0.0010(0.0012) Grad: 4118.4834  LR: 0.000006  \n",
      "Epoch: [4][1700/2850] Elapsed 9m 19s (remain 6m 17s) Loss: 0.0020(0.0012) Grad: 34057.8516  LR: 0.000006  \n",
      "Epoch: [4][1800/2850] Elapsed 9m 52s (remain 5m 44s) Loss: 0.0000(0.0012) Grad: 755.3345  LR: 0.000006  \n",
      "Epoch: [4][1900/2850] Elapsed 10m 24s (remain 5m 11s) Loss: 0.0000(0.0012) Grad: 18.2768  LR: 0.000006  \n",
      "Epoch: [4][2000/2850] Elapsed 10m 56s (remain 4m 38s) Loss: 0.0107(0.0012) Grad: 24531.9805  LR: 0.000006  \n",
      "Epoch: [4][2100/2850] Elapsed 11m 29s (remain 4m 5s) Loss: 0.0002(0.0012) Grad: 1087.2616  LR: 0.000006  \n",
      "Epoch: [4][2200/2850] Elapsed 12m 4s (remain 3m 33s) Loss: 0.0000(0.0012) Grad: 191.2459  LR: 0.000005  \n",
      "Epoch: [4][2300/2850] Elapsed 12m 36s (remain 3m 0s) Loss: 0.0002(0.0012) Grad: 2123.4351  LR: 0.000005  \n",
      "Epoch: [4][2400/2850] Elapsed 13m 9s (remain 2m 27s) Loss: 0.0000(0.0012) Grad: 161.9357  LR: 0.000005  \n",
      "Epoch: [4][2500/2850] Elapsed 13m 41s (remain 1m 54s) Loss: 0.0000(0.0012) Grad: 138.2935  LR: 0.000005  \n",
      "Epoch: [4][2600/2850] Elapsed 14m 13s (remain 1m 21s) Loss: 0.0009(0.0013) Grad: 3914.7878  LR: 0.000005  \n",
      "Epoch: [4][2700/2850] Elapsed 14m 45s (remain 0m 48s) Loss: 0.0003(0.0013) Grad: 3435.8767  LR: 0.000005  \n",
      "Epoch: [4][2800/2850] Elapsed 15m 18s (remain 0m 16s) Loss: 0.0002(0.0013) Grad: 1978.2760  LR: 0.000005  \n",
      "Epoch: [4][2849/2850] Elapsed 15m 34s (remain 0m 0s) Loss: 0.0008(0.0013) Grad: 4754.0225  LR: 0.000004  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 28s) Loss: 0.0092(0.0092) \n",
      "EVAL: [100/725] Elapsed 0m 20s (remain 2m 6s) Loss: 0.0007(0.0027) \n",
      "EVAL: [200/725] Elapsed 0m 40s (remain 1m 46s) Loss: 0.0009(0.0032) \n",
      "EVAL: [300/725] Elapsed 1m 0s (remain 1m 25s) Loss: 0.0051(0.0027) \n",
      "EVAL: [400/725] Elapsed 1m 20s (remain 1m 5s) Loss: 0.0192(0.0029) \n",
      "EVAL: [500/725] Elapsed 1m 41s (remain 0m 45s) Loss: 0.0043(0.0030) \n",
      "EVAL: [600/725] Elapsed 2m 2s (remain 0m 25s) Loss: 0.0038(0.0029) \n",
      "EVAL: [700/725] Elapsed 2m 22s (remain 0m 4s) Loss: 0.0000(0.0027) \n",
      "EVAL: [724/725] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0057(0.0027) \n",
      "Epoch 4 - avg_train_loss: 0.0013  avg_val_loss: 0.0027  time: 1087s\n",
      "Epoch 4 - Score: 0.8740\n",
      "Epoch: [5][0/2850] Elapsed 0m 0s (remain 26m 46s) Loss: 0.0001(0.0001) Grad: 890.3228  LR: 0.000004  \n",
      "Epoch: [5][100/2850] Elapsed 0m 33s (remain 15m 4s) Loss: 0.0001(0.0009) Grad: 1473.5416  LR: 0.000004  \n",
      "Epoch: [5][200/2850] Elapsed 1m 5s (remain 14m 25s) Loss: 0.0005(0.0011) Grad: 4269.6270  LR: 0.000004  \n",
      "Epoch: [5][300/2850] Elapsed 1m 37s (remain 13m 48s) Loss: 0.0012(0.0011) Grad: 7716.6611  LR: 0.000004  \n",
      "Epoch: [5][400/2850] Elapsed 2m 10s (remain 13m 15s) Loss: 0.0016(0.0010) Grad: 12612.7666  LR: 0.000004  \n",
      "Epoch: [5][500/2850] Elapsed 2m 42s (remain 12m 42s) Loss: 0.0000(0.0010) Grad: 35.2891  LR: 0.000004  \n",
      "Epoch: [5][600/2850] Elapsed 3m 14s (remain 12m 9s) Loss: 0.0013(0.0010) Grad: 6067.1763  LR: 0.000004  \n",
      "Epoch: [5][700/2850] Elapsed 3m 46s (remain 11m 35s) Loss: 0.0006(0.0010) Grad: 4438.3770  LR: 0.000003  \n",
      "Epoch: [5][800/2850] Elapsed 4m 18s (remain 11m 2s) Loss: 0.0020(0.0011) Grad: 12712.2646  LR: 0.000003  \n",
      "Epoch: [5][900/2850] Elapsed 4m 51s (remain 10m 30s) Loss: 0.0005(0.0011) Grad: 4995.3218  LR: 0.000003  \n",
      "Epoch: [5][1000/2850] Elapsed 5m 23s (remain 9m 57s) Loss: 0.0019(0.0011) Grad: 4038.3083  LR: 0.000003  \n",
      "Epoch: [5][1100/2850] Elapsed 5m 56s (remain 9m 26s) Loss: 0.0000(0.0011) Grad: 150.4507  LR: 0.000003  \n",
      "Epoch: [5][1200/2850] Elapsed 6m 29s (remain 8m 54s) Loss: 0.0000(0.0010) Grad: 29.8628  LR: 0.000003  \n",
      "Epoch: [5][1300/2850] Elapsed 7m 1s (remain 8m 22s) Loss: 0.0241(0.0011) Grad: 63978.1953  LR: 0.000002  \n",
      "Epoch: [5][1400/2850] Elapsed 7m 33s (remain 7m 49s) Loss: 0.0002(0.0011) Grad: 2848.7354  LR: 0.000002  \n",
      "Epoch: [5][1500/2850] Elapsed 8m 5s (remain 7m 16s) Loss: 0.0004(0.0011) Grad: 3985.0098  LR: 0.000002  \n",
      "Epoch: [5][1600/2850] Elapsed 8m 37s (remain 6m 43s) Loss: 0.0024(0.0012) Grad: 30191.4766  LR: 0.000002  \n",
      "Epoch: [5][1700/2850] Elapsed 9m 10s (remain 6m 11s) Loss: 0.0029(0.0011) Grad: 16815.7070  LR: 0.000002  \n",
      "Epoch: [5][1800/2850] Elapsed 9m 42s (remain 5m 39s) Loss: 0.0003(0.0011) Grad: 6745.8735  LR: 0.000002  \n",
      "Epoch: [5][1900/2850] Elapsed 10m 15s (remain 5m 7s) Loss: 0.0001(0.0011) Grad: 724.5244  LR: 0.000001  \n",
      "Epoch: [5][2000/2850] Elapsed 10m 47s (remain 4m 34s) Loss: 0.0001(0.0011) Grad: 797.7648  LR: 0.000001  \n",
      "Epoch: [5][2100/2850] Elapsed 11m 19s (remain 4m 2s) Loss: 0.0002(0.0011) Grad: 2116.1045  LR: 0.000001  \n",
      "Epoch: [5][2200/2850] Elapsed 11m 51s (remain 3m 29s) Loss: 0.0000(0.0011) Grad: 462.7102  LR: 0.000001  \n",
      "Epoch: [5][2300/2850] Elapsed 12m 23s (remain 2m 57s) Loss: 0.0006(0.0011) Grad: 3737.0144  LR: 0.000001  \n",
      "Epoch: [5][2400/2850] Elapsed 12m 56s (remain 2m 25s) Loss: 0.0053(0.0011) Grad: 45438.5234  LR: 0.000001  \n",
      "Epoch: [5][2500/2850] Elapsed 13m 31s (remain 1m 53s) Loss: 0.0000(0.0011) Grad: 111.5853  LR: 0.000001  \n",
      "Epoch: [5][2600/2850] Elapsed 14m 6s (remain 1m 21s) Loss: 0.0001(0.0011) Grad: 802.1134  LR: 0.000000  \n",
      "Epoch: [5][2700/2850] Elapsed 14m 38s (remain 0m 48s) Loss: 0.0000(0.0011) Grad: 549.3108  LR: 0.000000  \n",
      "Epoch: [5][2800/2850] Elapsed 15m 12s (remain 0m 15s) Loss: 0.0006(0.0011) Grad: 3971.3130  LR: 0.000000  \n",
      "Epoch: [5][2849/2850] Elapsed 15m 30s (remain 0m 0s) Loss: 0.0017(0.0011) Grad: 9926.9746  LR: 0.000000  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 46s) Loss: 0.0096(0.0096) \n",
      "EVAL: [100/725] Elapsed 0m 22s (remain 2m 16s) Loss: 0.0007(0.0030) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0009(0.0036) \n",
      "EVAL: [300/725] Elapsed 1m 2s (remain 1m 27s) Loss: 0.0066(0.0030) \n",
      "EVAL: [400/725] Elapsed 1m 22s (remain 1m 6s) Loss: 0.0177(0.0033) \n",
      "EVAL: [500/725] Elapsed 1m 42s (remain 0m 45s) Loss: 0.0040(0.0033) \n",
      "EVAL: [600/725] Elapsed 2m 3s (remain 0m 25s) Loss: 0.0043(0.0033) \n",
      "EVAL: [700/725] Elapsed 2m 23s (remain 0m 4s) Loss: 0.0000(0.0031) \n",
      "EVAL: [724/725] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0059(0.0031) \n",
      "Epoch 5 - avg_train_loss: 0.0011  avg_val_loss: 0.0031  time: 1084s\n",
      "Epoch 5 - Score: 0.8727\n",
      "Best thres: 0.5, Score: 0.8758\n",
      "Best thres: 0.4748046875, Score: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from pretrained\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CustomModel:\n\tMissing key(s) in state_dict: \"backbone.pooler.dense.weight\", \"backbone.pooler.dense.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-0f687401855c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mtest_token_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold{i_fold}_{i}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_token_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CustomModel:\n\tMissing key(s) in state_dict: \"backbone.pooler.dense.weight\", \"backbone.pooler.dense.bias\". "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp032.ipynb",
   "provenance": [
    {
     "file_id": "1hTEk26Dv4lh67pdHGaEsQ5C3Lpm9St9B",
     "timestamp": 1646827917764
    },
    {
     "file_id": "14l7vjaEJdKkFlJXP9EmrgKriPn4mqCbY",
     "timestamp": 1646539060597
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "021bed17d3464417bcb9c43b3e79b19d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "030f41fd0e8f403482000a835c735928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d22af96aa4754966b87ea666d1f56519",
       "IPY_MODEL_eba56a23967a415c99b0bf8db861a317",
       "IPY_MODEL_0f2a217bf02b46e28792127c9f4a95ac"
      ],
      "layout": "IPY_MODEL_2de7b56103464351990e89417317df23"
     }
    },
    "08ea123b20594ef782823b8ba176823a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c18277b3ae84cf9822e3f95aeebe53b",
      "placeholder": "​",
      "style": "IPY_MODEL_8fd6df45f015489e98f65771081eef9a",
      "value": " 2/2 [00:01&lt;00:00,  1.24s/it]"
     }
    },
    "0979fe347c0e401790c70ed3d9787f07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c18277b3ae84cf9822e3f95aeebe53b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f2a217bf02b46e28792127c9f4a95ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce5bb524f60f48eda173baf3aa083d85",
      "placeholder": "​",
      "style": "IPY_MODEL_fec5c0964350463cada500d54d5676ad",
      "value": " 2/2 [00:01&lt;00:00,  1.18s/it]"
     }
    },
    "1cf4f0a3a0394628b9e0f02305579f5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d916490a60424ee2adb63d6f5f286992",
      "placeholder": "​",
      "style": "IPY_MODEL_bccaa1763daa4f508968f7d8b040f0f3",
      "value": "100%"
     }
    },
    "2b106055c7764d19a925a79ae5d68ca9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cb0a1ef1fe544d2a51d66f4e52ad308": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2de7b56103464351990e89417317df23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f5d19e109d419ea2d355d2cf69c8bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38ac5233693d49aaa5c5bdc0e8d8c369": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66d81e5664b7426686533c2ced4f3dab",
      "placeholder": "​",
      "style": "IPY_MODEL_d7ac1d0c9cfa484a99eb8aae57b4185e",
      "value": " 2/2 [00:02&lt;00:00,  1.61s/it]"
     }
    },
    "3915f6b0649c4770ae1536a7dee377dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c7c862c2b65b40a8b99c4681883359e2",
       "IPY_MODEL_3aa7689f39a04484af82c5d8f4a2cf4f",
       "IPY_MODEL_3ea013a5c12c4c5b8db5817acc149158"
      ],
      "layout": "IPY_MODEL_c606df8ba9694c77871cafb980b5efe7"
     }
    },
    "3a1dbe5568dc4a23b7ec750ca9639c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3aa7689f39a04484af82c5d8f4a2cf4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4561dc6fbe07488db770757f7601b5ec",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81d5ed83bd63414da868cad0719ef42e",
      "value": 2
     }
    },
    "3cbb6e9995cb46479b7e517ec75c9c84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ea013a5c12c4c5b8db5817acc149158": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbdacff28e58463ebe011b2c475c4c91",
      "placeholder": "​",
      "style": "IPY_MODEL_9e985af3c39d482d8479a50194c76e0b",
      "value": " 2/2 [00:01&lt;00:00,  1.33s/it]"
     }
    },
    "44b9d3c534154fa88508a62ec05a1677": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63fdd31ea0244522a43e7c5823644ca9",
       "IPY_MODEL_baf432788ac7423581cbc9f87e9bc74d",
       "IPY_MODEL_59edbb1a33bf475b88ddb3db7998b3ad"
      ],
      "layout": "IPY_MODEL_e827424c1f7c46f4879f1fe53c1dacec"
     }
    },
    "4561dc6fbe07488db770757f7601b5ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46de594cfccf4a32aa50c1ce058f8972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47fd68de2fe74dd084647533038cf8ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5139830224f6498b8d0c0dee47549b8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aed16ca47bcf404f8b888e89c094018d",
      "placeholder": "​",
      "style": "IPY_MODEL_30f5d19e109d419ea2d355d2cf69c8bf",
      "value": " 143/143 [00:00&lt;00:00, 2083.17it/s]"
     }
    },
    "59edbb1a33bf475b88ddb3db7998b3ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6fbce429db5400f84b7a21b4fdcdcee",
      "placeholder": "​",
      "style": "IPY_MODEL_5ff9158efd1545809619a09d61b069a2",
      "value": " 42146/42146 [00:39&lt;00:00, 2130.64it/s]"
     }
    },
    "5de1e2c3d7584c488792455f4700ebf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ff9158efd1545809619a09d61b069a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "630c3a3411944c1eb16320f83f506735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de1e2c3d7584c488792455f4700ebf9",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f338908c4aac421ca6dfab9458e1a157",
      "value": 143
     }
    },
    "63fdd31ea0244522a43e7c5823644ca9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cbb6e9995cb46479b7e517ec75c9c84",
      "placeholder": "​",
      "style": "IPY_MODEL_3a1dbe5568dc4a23b7ec750ca9639c45",
      "value": "100%"
     }
    },
    "66d81e5664b7426686533c2ced4f3dab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "689d7f7b71344a59919aa1b7f5d69f8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c7609ae3a814a50a2cc93a3fcdda2ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "701afc1555dd4f4a979ff25777bbe1e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec98b9b2ea6a48469795091805920f00",
      "placeholder": "​",
      "style": "IPY_MODEL_966f90d6a9eb4fef98be68528fc26534",
      "value": "100%"
     }
    },
    "7436e1e0dedd44479aee6d2d55bd12cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6439467ff394e92921326df863ff506",
       "IPY_MODEL_630c3a3411944c1eb16320f83f506735",
       "IPY_MODEL_5139830224f6498b8d0c0dee47549b8b"
      ],
      "layout": "IPY_MODEL_c5cb391342724eda9af945eb9f397d89"
     }
    },
    "76c2c1bb6b484fe091b7252959c65ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d7ec9c04a6943859d8676063e012d04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81d5ed83bd63414da868cad0719ef42e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8dfa173a72a048a993a252ce2d9f7b00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fd6df45f015489e98f65771081eef9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92fcbf34967f4811919b8ff0a860718c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "938bb517508d4d8bb09cac2b214b7176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94731f6d7b6246b59fec5d9d7c0bc0c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_701afc1555dd4f4a979ff25777bbe1e2",
       "IPY_MODEL_b69047db6673409ea77d3be42eecc0c3",
       "IPY_MODEL_38ac5233693d49aaa5c5bdc0e8d8c369"
      ],
      "layout": "IPY_MODEL_2cb0a1ef1fe544d2a51d66f4e52ad308"
     }
    },
    "966f90d6a9eb4fef98be68528fc26534": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99a2e96958fb43329539ca82761890d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a891d0d85d3457ab68796d0a727d839": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b06135dc48eb4200ace2954020809c91",
       "IPY_MODEL_b5d0bcb01a044fb08d824c504f62aed7",
       "IPY_MODEL_fc7861e0ab0347a594ecb866a88abf85"
      ],
      "layout": "IPY_MODEL_689d7f7b71344a59919aa1b7f5d69f8c"
     }
    },
    "9e57d9425199415bb21bbd47d27456bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e985af3c39d482d8479a50194c76e0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab13678726ab4f948a99c2ceea3ba1e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aed16ca47bcf404f8b888e89c094018d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b06135dc48eb4200ace2954020809c91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d7ec9c04a6943859d8676063e012d04",
      "placeholder": "​",
      "style": "IPY_MODEL_92fcbf34967f4811919b8ff0a860718c",
      "value": "Downloading: 100%"
     }
    },
    "b5d0bcb01a044fb08d824c504f62aed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_021bed17d3464417bcb9c43b3e79b19d",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e61f8fcff6c34f42921f52d5b6b44fd5",
      "value": 1425941629
     }
    },
    "b69047db6673409ea77d3be42eecc0c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eefff4e1f7434c8d8739f7c11d684d7f",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6e4552dbd234366a09db818399ac153",
      "value": 2
     }
    },
    "baf432788ac7423581cbc9f87e9bc74d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fba1e7bf5c58413fb4a0db7e42268735",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_938bb517508d4d8bb09cac2b214b7176",
      "value": 42146
     }
    },
    "bccaa1763daa4f508968f7d8b040f0f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1c9c5bfd0084c8fa6c2cb48e3db2a60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a2e96958fb43329539ca82761890d0",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47fd68de2fe74dd084647533038cf8ef",
      "value": 2
     }
    },
    "c5cb391342724eda9af945eb9f397d89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c606df8ba9694c77871cafb980b5efe7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6fbce429db5400f84b7a21b4fdcdcee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7c862c2b65b40a8b99c4681883359e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e57d9425199415bb21bbd47d27456bd",
      "placeholder": "​",
      "style": "IPY_MODEL_d318eea186224fc3b410f24f58d616ee",
      "value": "100%"
     }
    },
    "cbdacff28e58463ebe011b2c475c4c91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbe63b3c954d465dbc0443ef62d6ea9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1cf4f0a3a0394628b9e0f02305579f5d",
       "IPY_MODEL_c1c9c5bfd0084c8fa6c2cb48e3db2a60",
       "IPY_MODEL_08ea123b20594ef782823b8ba176823a"
      ],
      "layout": "IPY_MODEL_8dfa173a72a048a993a252ce2d9f7b00"
     }
    },
    "ce5bb524f60f48eda173baf3aa083d85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22af96aa4754966b87ea666d1f56519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0979fe347c0e401790c70ed3d9787f07",
      "placeholder": "​",
      "style": "IPY_MODEL_ab13678726ab4f948a99c2ceea3ba1e2",
      "value": "100%"
     }
    },
    "d318eea186224fc3b410f24f58d616ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7ac1d0c9cfa484a99eb8aae57b4185e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d916490a60424ee2adb63d6f5f286992": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e61f8fcff6c34f42921f52d5b6b44fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6439467ff394e92921326df863ff506": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1fe406393d149a39c633ff3558d68e0",
      "placeholder": "​",
      "style": "IPY_MODEL_46de594cfccf4a32aa50c1ce058f8972",
      "value": "100%"
     }
    },
    "e827424c1f7c46f4879f1fe53c1dacec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eba56a23967a415c99b0bf8db861a317": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b106055c7764d19a925a79ae5d68ca9",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3a75f8c95984d50a0b8dc37ed5cbd4e",
      "value": 2
     }
    },
    "ec98b9b2ea6a48469795091805920f00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eefff4e1f7434c8d8739f7c11d684d7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1fe406393d149a39c633ff3558d68e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f338908c4aac421ca6dfab9458e1a157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f3a75f8c95984d50a0b8dc37ed5cbd4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6e4552dbd234366a09db818399ac153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fba1e7bf5c58413fb4a0db7e42268735": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc7861e0ab0347a594ecb866a88abf85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c7609ae3a814a50a2cc93a3fcdda2ed",
      "placeholder": "​",
      "style": "IPY_MODEL_76c2c1bb6b484fe091b7252959c65ee7",
      "value": " 1.33G/1.33G [00:25&lt;00:00, 59.8MB/s]"
     }
    },
    "fec5c0964350463cada500d54d5676ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
