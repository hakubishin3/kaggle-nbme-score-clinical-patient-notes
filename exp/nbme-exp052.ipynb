{"cells":[{"cell_type":"markdown","id":"brave-teach","metadata":{"id":"brave-teach"},"source":["## References"]},{"cell_type":"markdown","id":"orange-toilet","metadata":{"id":"orange-toilet"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"serious-sending","metadata":{"id":"serious-sending"},"source":["## Configurations"]},{"cell_type":"code","execution_count":null,"id":"august-providence","metadata":{"id":"august-providence"},"outputs":[],"source":["EXP_NAME = \"nbme-exp052\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":null,"id":"cathedral-horror","metadata":{"id":"cathedral-horror"},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    mixout=0.3\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=2\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=4\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":null,"id":"armed-norfolk","metadata":{"id":"armed-norfolk"},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"atlantic-warrant","metadata":{"id":"atlantic-warrant"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":null,"id":"federal-marsh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"federal-marsh","outputId":"f9346175-e640-49b2-a6b0-c622deb4aeb8","executionInfo":{"status":"ok","timestamp":1647655709449,"user_tz":-540,"elapsed":7100,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.49)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":null,"id":"recent-harrison","metadata":{"id":"recent-harrison"},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"technical-story","metadata":{"id":"technical-story"},"source":["## Utilities"]},{"cell_type":"code","execution_count":null,"id":"understanding-trial","metadata":{"id":"understanding-trial"},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":null,"id":"pursuant-lover","metadata":{"id":"pursuant-lover"},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":null,"id":"matched-hollow","metadata":{"id":"matched-hollow"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"id":"weighted-screw","metadata":{"id":"weighted-screw"},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"following-passport","metadata":{"id":"following-passport"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"id":"absent-performance","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"absent-performance","outputId":"6f3d4f78-8896-41fd-ece4-7ecc32abcf54","executionInfo":{"status":"ok","timestamp":1647655720166,"user_tz":-540,"elapsed":314,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":null,"id":"automated-proportion","metadata":{"id":"automated-proportion"},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"preceding-january","metadata":{"id":"preceding-january"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"monetary-camera","metadata":{"id":"monetary-camera"},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":null,"id":"fitted-current","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fitted-current","outputId":"a5e58bfb-f1ad-4e05-d447-cf6bcbb86a74","executionInfo":{"status":"ok","timestamp":1647655720167,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":null,"id":"australian-vehicle","metadata":{"id":"australian-vehicle"},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":null,"id":"devoted-peter","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"devoted-peter","outputId":"262eaf9a-30c1-4edb-8be1-09797300e6a0","executionInfo":{"status":"ok","timestamp":1647655720469,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"incorrect-honey","metadata":{"id":"incorrect-honey"},"source":["## CV split"]},{"cell_type":"code","execution_count":null,"id":"adjacent-antibody","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"adjacent-antibody","outputId":"1537dca9-78e8-4a87-b8a2-e9b9a0ed3e2d","executionInfo":{"status":"ok","timestamp":1647655720469,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"breathing-state","metadata":{"id":"breathing-state"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":null,"id":"former-beast","metadata":{"id":"former-beast"},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDMSkwTNgOOh","executionInfo":{"status":"ok","timestamp":1647655725286,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"722f5dcb-04a1-4ac2-95c1-9abd298acdfc"},"id":"TDMSkwTNgOOh","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}]},{"cell_type":"markdown","id":"employed-foster","metadata":{"id":"employed-foster"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":null,"id":"biblical-mailing","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["6a615c2e2f1843f3b51283e2bfcada8f","3ea63ebbfdc24e6b88417ccac25cb7d1","d76adf0a9c054f8cad8b986e9d78ea97","17d3db9626a64c38b8770c431d67aa1d","3eaa1793fdf34f06b280fc6c411d1c6b","7fc1df1cc6fb40c89e86dda946a1a6fa","ff9783e20a904010ac244a59d490b473","0bdd8d49d59f4e7ea6d2a91d14f3d5fe","9736800471d742f4885c4a9f2ee8ef1d","5a102765c4f0440aae5a131b58c98922","38ddb5c2a4874bb28390f59ce9032d44"]},"id":"biblical-mailing","outputId":"f90a50ef-304e-439c-89d7-98a9f1b6b8a7","executionInfo":{"status":"ok","timestamp":1647655762673,"user_tz":-540,"elapsed":37394,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a615c2e2f1843f3b51283e2bfcada8f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":null,"id":"renewable-mercury","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["22e0095c30334cd78b44f92f93bb9cfd","a726661b55ee453585c3ab4070c5bfb4","7689a308f52144b89ce85bf887457255","313878de873e41e0b67e91545fdda913","51327e49428a48789973aecb6b8b8970","cfec3dca89d448b58ca46e5e0f6b52d2","8a4eb3e7b261445b87025b13ee2a68e5","6b8ec6bf22f84ec2881389eb40e0bdf8","036856b948374f90b1975ebed920dc63","1f1639b3a81047f09c905b5b3a07bc53","80d88c56ce15482c81fe700e024447d9"]},"id":"renewable-mercury","outputId":"abcfb076-6582-4713-94ce-64a7749afb83","executionInfo":{"status":"ok","timestamp":1647655762674,"user_tz":-540,"elapsed":24,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e0095c30334cd78b44f92f93bb9cfd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":null,"id":"latin-burlington","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"latin-burlington","outputId":"f97c6a66-10c2-4b17-b00b-c8916d0edf2a","executionInfo":{"status":"ok","timestamp":1647655762675,"user_tz":-540,"elapsed":22,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":null,"id":"minor-stock","metadata":{"id":"minor-stock"},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":null,"id":"decimal-schema","metadata":{"id":"decimal-schema"},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"exceptional-vertical","metadata":{"id":"exceptional-vertical"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"id":"dynamic-fifteen","metadata":{"id":"dynamic-fifteen"},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            #path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size * 4, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"hidden_states\"]\n","        h = torch.cat([h[-1*i][:, :] for i in range(1, 4 + 1)], dim=2)  # concatenate\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"driving-commercial","metadata":{"id":"driving-commercial"},"source":["## Training"]},{"cell_type":"code","source":["import math\n","from torch.autograd.function import InplaceFunction\n","from torch.nn import Parameter\n","import torch.nn.init as init\n","\n","class Mixout(InplaceFunction):\n","    @staticmethod\n","    def _make_noise(input):\n","        return input.new().resize_as_(input)\n","\n","    @classmethod\n","    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n","        if p < 0 or p > 1:\n","            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\" \" but got {}\".format(p))\n","        if target is not None and input.size() != target.size():\n","            raise ValueError(\n","                \"A target tensor size must match with a input tensor size {},\"\n","                \" but got {}\".format(input.size(), target.size())\n","            )\n","        ctx.p = p\n","        ctx.training = training\n","\n","        if ctx.p == 0 or not ctx.training:\n","            return input\n","\n","        if target is None:\n","            target = cls._make_noise(input)\n","            target.fill_(0)\n","        target = target.to(input.device)\n","\n","        if inplace:\n","            ctx.mark_dirty(input)\n","            output = input\n","        else:\n","            output = input.clone()\n","\n","        ctx.noise = cls._make_noise(input)\n","        if len(ctx.noise.size()) == 1:\n","            ctx.noise.bernoulli_(1 - ctx.p)\n","        else:\n","            ctx.noise[0].bernoulli_(1 - ctx.p)\n","            ctx.noise = ctx.noise[0].repeat(input.size()[0], 1)\n","        ctx.noise.expand_as(input)\n","\n","        if ctx.p == 1:\n","            output = target\n","        else:\n","            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        if ctx.p > 0 and ctx.training:\n","            return grad_output * ctx.noise, None, None, None, None\n","        else:\n","            return grad_output, None, None, None, None\n","\n","\n","def mixout(input, target=None, p=0.0, training=False, inplace=False):\n","    return Mixout.apply(input, target, p, training, inplace)\n","\n","\n","class MixLinear(torch.nn.Module):\n","    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n","    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n","        super(MixLinear, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = Parameter(torch.Tensor(out_features, in_features))\n","        if bias:\n","            self.bias = Parameter(torch.Tensor(out_features))\n","        else:\n","            self.register_parameter(\"bias\", None)\n","        self.reset_parameters()\n","        self.target = target\n","        self.p = p\n","\n","    def reset_parameters(self):\n","        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","        if self.bias is not None:\n","            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n","            bound = 1 / math.sqrt(fan_in)\n","            init.uniform_(self.bias, -bound, bound)\n","\n","    def forward(self, input):\n","        return F.linear(input, mixout(self.weight, self.target, self.p, self.training), self.bias)\n","\n","    def extra_repr(self):\n","        type = \"drop\" if self.target is None else \"mix\"\n","        return \"{}={}, in_features={}, out_features={}, bias={}\".format(\n","            type + \"out\", self.p, self.in_features, self.out_features, self.bias is not None\n","        )\n","\n","\n","def replace_mixout(model):\n","    for sup_module in model.modules():\n","        for name, module in sup_module.named_children():\n","            if isinstance(module, nn.Dropout):\n","                module.p = 0.0\n","            if isinstance(module, nn.Linear):\n","                target_state_dict = module.state_dict()\n","                bias = True if module.bias is not None else False\n","                new_module = MixLinear(\n","                    module.in_features, module.out_features, bias, target_state_dict[\"weight\"], CFG.mixout\n","                )\n","                new_module.load_state_dict(target_state_dict)\n","                setattr(sup_module, name, new_module)\n","    return model"],"metadata":{"id":"GqZSJBMF6B1n"},"id":"GqZSJBMF6B1n","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"cathedral-component","metadata":{"id":"cathedral-component"},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":null,"id":"expired-wilson","metadata":{"id":"expired-wilson"},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":null,"id":"chinese-sympathy","metadata":{"id":"chinese-sympathy"},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":null,"id":"healthy-sleep","metadata":{"id":"healthy-sleep"},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    model = replace_mixout(model)  # mixout\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"balanced-novel","metadata":{"id":"balanced-novel"},"source":["## Main"]},{"cell_type":"code","execution_count":null,"id":"sound-silly","metadata":{"id":"sound-silly"},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":31,"id":"reduced-indication","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"reduced-indication","outputId":"50564418-2b90-4c2a-efb6-170d85f47601","executionInfo":{"status":"error","timestamp":1647740435523,"user_tz":-540,"elapsed":258,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 119m 53s) Loss: 0.4338(0.4338) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 5s (remain 56m 49s) Loss: 0.2034(0.3614) Grad: 8948.4941  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 8s (remain 54m 54s) Loss: 0.3175(0.3273) Grad: 15350.2012  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 11s (remain 53m 38s) Loss: 0.1665(0.2830) Grad: 8276.1172  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 14s (remain 52m 24s) Loss: 0.0447(0.2325) Grad: 2429.9414  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 16s (remain 51m 11s) Loss: 0.0042(0.1909) Grad: 131.2831  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 18s (remain 50m 1s) Loss: 0.0375(0.1626) Grad: 519.3590  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 21s (remain 48m 54s) Loss: 0.0330(0.1422) Grad: 496.1915  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 23s (remain 47m 48s) Loss: 0.0471(0.1268) Grad: 759.9916  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 26s (remain 46m 43s) Loss: 0.0214(0.1147) Grad: 395.6323  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 28s (remain 45m 38s) Loss: 0.0341(0.1045) Grad: 468.1655  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 30s (remain 44m 32s) Loss: 0.0014(0.0960) Grad: 157.7163  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 33s (remain 43m 29s) Loss: 0.0203(0.0887) Grad: 1303.5966  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 35s (remain 42m 25s) Loss: 0.0018(0.0824) Grad: 102.2951  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 37s (remain 41m 21s) Loss: 0.0041(0.0772) Grad: 293.3203  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 40s (remain 40m 18s) Loss: 0.0024(0.0725) Grad: 118.6474  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 42s (remain 39m 14s) Loss: 0.0031(0.0684) Grad: 224.8259  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 44s (remain 38m 11s) Loss: 0.0021(0.0647) Grad: 106.7871  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 46s (remain 37m 7s) Loss: 0.0030(0.0615) Grad: 165.3424  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 48s (remain 36m 4s) Loss: 0.0080(0.0585) Grad: 1619.3584  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 51s (remain 35m 1s) Loss: 0.0134(0.0559) Grad: 824.1201  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 53s (remain 33m 59s) Loss: 0.0001(0.0534) Grad: 19.6805  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 55s (remain 32m 56s) Loss: 0.0008(0.0513) Grad: 102.3498  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 23m 58s (remain 31m 53s) Loss: 0.0070(0.0493) Grad: 354.1060  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 25m 0s (remain 30m 50s) Loss: 0.0033(0.0474) Grad: 216.7705  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 26m 2s (remain 29m 47s) Loss: 0.0015(0.0457) Grad: 81.4457  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 27m 4s (remain 28m 44s) Loss: 0.0044(0.0442) Grad: 454.3148  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 28m 7s (remain 27m 42s) Loss: 0.0005(0.0428) Grad: 40.8698  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 29m 9s (remain 26m 39s) Loss: 0.0006(0.0414) Grad: 70.3474  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 30m 11s (remain 25m 36s) Loss: 0.0060(0.0401) Grad: 264.5296  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 31m 13s (remain 24m 34s) Loss: 0.0027(0.0389) Grad: 257.6861  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 32m 15s (remain 23m 31s) Loss: 0.0019(0.0378) Grad: 141.1378  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 33m 17s (remain 22m 28s) Loss: 0.0007(0.0368) Grad: 51.4517  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 34m 20s (remain 21m 26s) Loss: 0.0008(0.0358) Grad: 78.6190  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 35m 22s (remain 20m 23s) Loss: 0.0001(0.0349) Grad: 10.4654  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 36m 24s (remain 19m 21s) Loss: 0.0035(0.0340) Grad: 150.0872  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 37m 27s (remain 18m 19s) Loss: 0.0140(0.0332) Grad: 522.1778  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 38m 30s (remain 17m 16s) Loss: 0.0022(0.0324) Grad: 73.7435  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 39m 32s (remain 16m 14s) Loss: 0.0070(0.0317) Grad: 361.3708  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 40m 35s (remain 15m 12s) Loss: 0.0000(0.0309) Grad: 3.9967  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 41m 37s (remain 14m 9s) Loss: 0.0003(0.0303) Grad: 29.6533  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 42m 40s (remain 13m 7s) Loss: 0.0006(0.0297) Grad: 47.6730  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 43m 43s (remain 12m 4s) Loss: 0.0008(0.0290) Grad: 75.2139  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 44m 45s (remain 11m 2s) Loss: 0.0023(0.0284) Grad: 143.8333  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 45m 48s (remain 10m 0s) Loss: 0.0034(0.0278) Grad: 164.5033  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 46m 50s (remain 8m 57s) Loss: 0.0028(0.0273) Grad: 175.0954  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 47m 53s (remain 7m 55s) Loss: 0.0017(0.0268) Grad: 108.2433  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 48m 55s (remain 6m 52s) Loss: 0.0023(0.0263) Grad: 166.0802  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 49m 58s (remain 5m 50s) Loss: 0.0021(0.0258) Grad: 303.3671  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 51m 0s (remain 4m 47s) Loss: 0.0002(0.0254) Grad: 22.5804  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 52m 3s (remain 3m 45s) Loss: 0.0002(0.0249) Grad: 18.8202  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 53m 6s (remain 2m 43s) Loss: 0.0282(0.0245) Grad: 1674.8069  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 54m 8s (remain 1m 40s) Loss: 0.0000(0.0241) Grad: 9.4948  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 55m 11s (remain 0m 38s) Loss: 0.0034(0.0237) Grad: 159.4707  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 55m 49s (remain 0m 0s) Loss: 0.0083(0.0235) Grad: 362.1348  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 37s) Loss: 0.0004(0.0004) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 31s) Loss: 0.0009(0.0031) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 15s) Loss: 0.0031(0.0032) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0117(0.0030) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 49s) Loss: 0.0036(0.0031) \n","EVAL: [500/1788] Elapsed 1m 1s (remain 2m 36s) Loss: 0.0003(0.0033) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0033(0.0032) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 11s) Loss: 0.0045(0.0030) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0028(0.0029) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0075(0.0031) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0011(0.0034) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0004(0.0038) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0032(0.0038) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0003(0.0038) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0004(0.0038) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0005(0.0038) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0001(0.0037) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0029(0.0036) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0020(0.0035) \n","Epoch 1 - avg_train_loss: 0.0235  avg_val_loss: 0.0035  time: 3578s\n","Epoch 1 - Score: 0.8457\n","Epoch 1 - Save Best Score: 0.8457 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 96m 5s) Loss: 0.0004(0.0004) Grad: 1031.3075  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 8s (remain 59m 16s) Loss: 0.0018(0.0035) Grad: 5949.9985  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 10s (remain 56m 0s) Loss: 0.0000(0.0032) Grad: 48.1814  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 13s (remain 54m 14s) Loss: 0.0029(0.0033) Grad: 15064.0723  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 16s (remain 52m 52s) Loss: 0.0004(0.0032) Grad: 1573.6166  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 19s (remain 51m 38s) Loss: 0.0000(0.0031) Grad: 12.7472  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 22s (remain 50m 26s) Loss: 0.0008(0.0031) Grad: 2337.4775  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 24s (remain 49m 17s) Loss: 0.0066(0.0029) Grad: 20870.6816  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 27s (remain 48m 7s) Loss: 0.0009(0.0029) Grad: 4023.8186  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 29s (remain 46m 58s) Loss: 0.0122(0.0031) Grad: 31864.7383  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 31s (remain 45m 52s) Loss: 0.0000(0.0031) Grad: 102.2343  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 34s (remain 44m 46s) Loss: 0.0020(0.0031) Grad: 8368.9004  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 36s (remain 43m 42s) Loss: 0.0008(0.0032) Grad: 2209.3118  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 39s (remain 42m 38s) Loss: 0.0013(0.0032) Grad: 4589.8706  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 42s (remain 41m 35s) Loss: 0.0071(0.0033) Grad: 23393.6406  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 45s (remain 40m 31s) Loss: 0.0018(0.0033) Grad: 7451.0757  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 48s (remain 39m 28s) Loss: 0.0000(0.0032) Grad: 163.3303  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 50s (remain 38m 24s) Loss: 0.0021(0.0032) Grad: 10428.1230  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 53s (remain 37m 21s) Loss: 0.0000(0.0032) Grad: 122.9983  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 56s (remain 36m 18s) Loss: 0.0071(0.0033) Grad: 22419.6367  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 58s (remain 35m 14s) Loss: 0.0000(0.0032) Grad: 185.0791  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 22m 1s (remain 34m 11s) Loss: 0.0070(0.0032) Grad: 10592.9014  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 23m 4s (remain 33m 7s) Loss: 0.0000(0.0032) Grad: 21.5940  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 24m 6s (remain 32m 4s) Loss: 0.0036(0.0032) Grad: 23655.2109  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 25m 8s (remain 31m 0s) Loss: 0.0305(0.0032) Grad: 33761.2188  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 26m 11s (remain 29m 57s) Loss: 0.0000(0.0032) Grad: 35.8722  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 27m 13s (remain 28m 54s) Loss: 0.0012(0.0032) Grad: 7779.2231  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 28m 15s (remain 27m 50s) Loss: 0.0000(0.0032) Grad: 181.8037  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 29m 18s (remain 26m 47s) Loss: 0.0101(0.0032) Grad: 20106.6016  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 30m 21s (remain 25m 44s) Loss: 0.0022(0.0032) Grad: 5163.3325  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 31m 23s (remain 24m 41s) Loss: 0.0022(0.0031) Grad: 5798.6528  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 32m 26s (remain 23m 39s) Loss: 0.0000(0.0031) Grad: 54.8775  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 33m 28s (remain 22m 36s) Loss: 0.0003(0.0031) Grad: 12836.5234  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 34m 30s (remain 21m 32s) Loss: 0.0002(0.0032) Grad: 1903.9078  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 35m 33s (remain 20m 30s) Loss: 0.0001(0.0032) Grad: 883.5497  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 36m 35s (remain 19m 27s) Loss: 0.0000(0.0032) Grad: 19.0606  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 37m 37s (remain 18m 24s) Loss: 0.0000(0.0031) Grad: 59.0834  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 38m 40s (remain 17m 21s) Loss: 0.0038(0.0031) Grad: 7028.1226  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 39m 42s (remain 16m 18s) Loss: 0.0000(0.0032) Grad: 325.3411  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 40m 45s (remain 15m 15s) Loss: 0.0013(0.0032) Grad: 6440.6069  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 41m 47s (remain 14m 12s) Loss: 0.0002(0.0032) Grad: 907.3600  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 42m 50s (remain 13m 10s) Loss: 0.0000(0.0032) Grad: 18.5585  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 43m 52s (remain 12m 7s) Loss: 0.0000(0.0032) Grad: 19.2383  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 44m 55s (remain 11m 4s) Loss: 0.0003(0.0032) Grad: 1717.3372  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 45m 57s (remain 10m 2s) Loss: 0.0108(0.0032) Grad: 155122.6094  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 47m 0s (remain 8m 59s) Loss: 0.0000(0.0032) Grad: 15.7556  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 48m 3s (remain 7m 56s) Loss: 0.0000(0.0032) Grad: 187.3382  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 49m 6s (remain 6m 54s) Loss: 0.0100(0.0032) Grad: 43953.1641  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 50m 8s (remain 5m 51s) Loss: 0.0016(0.0032) Grad: 3998.4824  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 51m 11s (remain 4m 48s) Loss: 0.0009(0.0032) Grad: 4563.7085  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 52m 13s (remain 3m 46s) Loss: 0.0104(0.0032) Grad: 18118.3809  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 53m 16s (remain 2m 43s) Loss: 0.0154(0.0032) Grad: 24791.9316  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 54m 18s (remain 1m 40s) Loss: 0.0027(0.0032) Grad: 10974.9131  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 55m 21s (remain 0m 38s) Loss: 0.0000(0.0032) Grad: 4.8556  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 55m 59s (remain 0m 0s) Loss: 0.0001(0.0032) Grad: 1173.6692  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 12s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0000(0.0033) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0000(0.0037) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0109(0.0034) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0047(0.0037) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0039) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0034(0.0038) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0006(0.0035) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0030(0.0033) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0276(0.0035) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0000(0.0039) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0000(0.0046) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0004(0.0046) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0000(0.0045) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0000(0.0045) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0001(0.0045) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0000(0.0043) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0007(0.0042) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0000(0.0042) \n","Epoch 2 - avg_train_loss: 0.0032  avg_val_loss: 0.0042  time: 3581s\n","Epoch 2 - Score: 0.8680\n","Epoch 2 - Save Best Score: 0.8680 Model\n","Epoch: [3][0/5362] Elapsed 0m 1s (remain 98m 0s) Loss: 0.0000(0.0000) Grad: 996.0571  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 8s (remain 59m 9s) Loss: 0.0005(0.0018) Grad: 2948.1606  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 10s (remain 55m 55s) Loss: 0.0010(0.0020) Grad: 10952.8984  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 13s (remain 54m 8s) Loss: 0.0024(0.0023) Grad: 13462.1357  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 15s (remain 52m 39s) Loss: 0.0007(0.0022) Grad: 5681.6841  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 17s (remain 51m 25s) Loss: 0.0000(0.0022) Grad: 14.5876  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 20s (remain 50m 15s) Loss: 0.0011(0.0024) Grad: 2364.4099  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 23s (remain 49m 7s) Loss: 0.0000(0.0024) Grad: 210.4647  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 26s (remain 48m 2s) Loss: 0.0007(0.0027) Grad: 3225.2458  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 28s (remain 46m 56s) Loss: 0.0006(0.0027) Grad: 2338.5454  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 31s (remain 45m 51s) Loss: 0.0003(0.0028) Grad: 1201.1455  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 34s (remain 44m 47s) Loss: 0.0014(0.0027) Grad: 22661.7656  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 37s (remain 43m 43s) Loss: 0.0001(0.0027) Grad: 253.6215  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 39s (remain 42m 38s) Loss: 0.0257(0.0028) Grad: 24532.2715  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 42s (remain 41m 34s) Loss: 0.0009(0.0027) Grad: 3677.3186  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 44s (remain 40m 30s) Loss: 0.0201(0.0027) Grad: 25310.1191  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 47s (remain 39m 26s) Loss: 0.0024(0.0028) Grad: 5172.7090  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 17m 49s (remain 38m 22s) Loss: 0.0071(0.0028) Grad: 19601.6230  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 18m 52s (remain 37m 19s) Loss: 0.0005(0.0029) Grad: 3120.9587  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 19m 54s (remain 36m 15s) Loss: 0.0000(0.0028) Grad: 27.1801  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 20m 57s (remain 35m 12s) Loss: 0.0098(0.0028) Grad: 22795.3555  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 21m 59s (remain 34m 8s) Loss: 0.0000(0.0029) Grad: 149.0966  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 23m 2s (remain 33m 5s) Loss: 0.0000(0.0029) Grad: 3.7044  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 24m 5s (remain 32m 2s) Loss: 0.0163(0.0028) Grad: 60145.6094  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 25m 7s (remain 30m 59s) Loss: 0.0037(0.0028) Grad: 5782.7139  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 26m 10s (remain 29m 56s) Loss: 0.0000(0.0027) Grad: 14.6442  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 27m 13s (remain 28m 53s) Loss: 0.0000(0.0027) Grad: 133.4213  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 28m 15s (remain 27m 50s) Loss: 0.0000(0.0027) Grad: 135.0927  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 29m 18s (remain 26m 47s) Loss: 0.0001(0.0027) Grad: 599.3892  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 30m 20s (remain 25m 44s) Loss: 0.0012(0.0028) Grad: 4087.6516  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 31m 23s (remain 24m 41s) Loss: 0.0000(0.0027) Grad: 48.8979  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 32m 25s (remain 23m 38s) Loss: 0.0000(0.0028) Grad: 64.3779  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 33m 28s (remain 22m 35s) Loss: 0.0302(0.0027) Grad: 162181.8438  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 34m 31s (remain 21m 33s) Loss: 0.0065(0.0027) Grad: 8433.2939  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 35m 33s (remain 20m 30s) Loss: 0.0053(0.0028) Grad: 44400.9102  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 36m 36s (remain 19m 27s) Loss: 0.0000(0.0028) Grad: 51.8071  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 37m 39s (remain 18m 24s) Loss: 0.0070(0.0028) Grad: 14568.6631  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 38m 41s (remain 17m 22s) Loss: 0.0005(0.0028) Grad: 2438.4802  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 39m 44s (remain 16m 19s) Loss: 0.0056(0.0027) Grad: 16850.1816  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 40m 47s (remain 15m 16s) Loss: 0.0000(0.0027) Grad: 5.9600  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 41m 49s (remain 14m 13s) Loss: 0.0000(0.0027) Grad: 53.4674  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 42m 51s (remain 13m 10s) Loss: 0.0005(0.0027) Grad: 11220.0791  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 43m 53s (remain 12m 7s) Loss: 0.0001(0.0028) Grad: 794.1190  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 44m 55s (remain 11m 5s) Loss: 0.0000(0.0027) Grad: 14.7290  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 45m 58s (remain 10m 2s) Loss: 0.0000(0.0027) Grad: 15.5044  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 47m 0s (remain 8m 59s) Loss: 0.0000(0.0027) Grad: 8.8721  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 48m 3s (remain 7m 56s) Loss: 0.0000(0.0028) Grad: 18.8141  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 49m 6s (remain 6m 54s) Loss: 0.0002(0.0027) Grad: 7513.0605  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 50m 8s (remain 5m 51s) Loss: 0.0009(0.0027) Grad: 11075.8330  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 51m 11s (remain 4m 48s) Loss: 0.0000(0.0027) Grad: 18.5192  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 52m 13s (remain 3m 46s) Loss: 0.0000(0.0027) Grad: 31.6551  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 53m 15s (remain 2m 43s) Loss: 0.0018(0.0027) Grad: 22273.6465  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 54m 18s (remain 1m 40s) Loss: 0.0096(0.0027) Grad: 36523.5352  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 55m 21s (remain 0m 38s) Loss: 0.0000(0.0027) Grad: 66.2903  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 55m 59s (remain 0m 0s) Loss: 0.0000(0.0027) Grad: 990.4080  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 32s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0000(0.0037) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 14s) Loss: 0.0000(0.0039) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0200(0.0038) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0048(0.0040) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0040) \n","EVAL: [600/1788] Elapsed 1m 13s (remain 2m 24s) Loss: 0.0025(0.0038) \n","EVAL: [700/1788] Elapsed 1m 25s (remain 2m 11s) Loss: 0.0012(0.0036) \n","EVAL: [800/1788] Elapsed 1m 37s (remain 1m 59s) Loss: 0.0033(0.0034) \n","EVAL: [900/1788] Elapsed 1m 49s (remain 1m 47s) Loss: 0.0003(0.0036) \n","EVAL: [1000/1788] Elapsed 2m 1s (remain 1m 35s) Loss: 0.0000(0.0040) \n","EVAL: [1100/1788] Elapsed 2m 13s (remain 1m 23s) Loss: 0.0000(0.0048) \n","EVAL: [1200/1788] Elapsed 2m 25s (remain 1m 10s) Loss: 0.0004(0.0048) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0000(0.0048) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0000(0.0048) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0047) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0046) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0022(0.0045) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0000(0.0044) \n","Epoch 3 - avg_train_loss: 0.0027  avg_val_loss: 0.0044  time: 3581s\n","Epoch 3 - Score: 0.8737\n","Epoch 3 - Save Best Score: 0.8737 Model\n","Epoch: [4][0/5362] Elapsed 0m 1s (remain 92m 3s) Loss: 0.0000(0.0000) Grad: 1003.9731  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 8s (remain 59m 28s) Loss: 0.0218(0.0034) Grad: 16696.4648  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 11s (remain 56m 6s) Loss: 0.0000(0.0023) Grad: 26.5920  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 13s (remain 54m 17s) Loss: 0.0000(0.0026) Grad: 102.8245  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 16s (remain 52m 51s) Loss: 0.0002(0.0022) Grad: 1669.8074  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 18s (remain 51m 35s) Loss: 0.0001(0.0021) Grad: 527.9730  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 21s (remain 50m 25s) Loss: 0.0004(0.0021) Grad: 1874.2031  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 24s (remain 49m 17s) Loss: 0.0000(0.0020) Grad: 37.3122  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 27s (remain 48m 9s) Loss: 0.0001(0.0019) Grad: 978.2908  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 29s (remain 47m 2s) Loss: 0.0000(0.0018) Grad: 25.7217  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 32s (remain 45m 55s) Loss: 0.0025(0.0019) Grad: 83900.2344  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 34s (remain 44m 49s) Loss: 0.0000(0.0019) Grad: 122.5666  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 37s (remain 43m 43s) Loss: 0.0133(0.0019) Grad: 32015.7266  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 39s (remain 42m 39s) Loss: 0.0000(0.0019) Grad: 50.1737  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 42s (remain 41m 35s) Loss: 0.0195(0.0020) Grad: 14637.2793  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 45s (remain 40m 32s) Loss: 0.0009(0.0020) Grad: 2737.9678  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 48s (remain 39m 28s) Loss: 0.0000(0.0020) Grad: 35.1098  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 50s (remain 38m 24s) Loss: 0.0000(0.0020) Grad: 7.3725  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 53s (remain 37m 20s) Loss: 0.0011(0.0020) Grad: 6353.3652  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 55s (remain 36m 17s) Loss: 0.0000(0.0020) Grad: 7.7153  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 58s (remain 35m 14s) Loss: 0.0004(0.0019) Grad: 4995.3833  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 22m 1s (remain 34m 10s) Loss: 0.0022(0.0020) Grad: 11239.1650  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 23m 3s (remain 33m 6s) Loss: 0.0000(0.0020) Grad: 104.4698  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 24m 5s (remain 32m 3s) Loss: 0.0000(0.0020) Grad: 218.0017  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 25m 8s (remain 31m 0s) Loss: 0.0087(0.0020) Grad: 9299.4971  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 26m 11s (remain 29m 57s) Loss: 0.0000(0.0021) Grad: 5.1435  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 27m 13s (remain 28m 53s) Loss: 0.0039(0.0021) Grad: 25227.8418  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 28m 15s (remain 27m 50s) Loss: 0.0000(0.0021) Grad: 46.9295  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 29m 18s (remain 26m 47s) Loss: 0.0000(0.0021) Grad: 97.1349  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 30m 20s (remain 25m 44s) Loss: 0.0000(0.0021) Grad: 4.4562  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 31m 22s (remain 24m 41s) Loss: 0.0001(0.0022) Grad: 359.4138  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 32m 25s (remain 23m 38s) Loss: 0.0000(0.0022) Grad: 5.0432  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 33m 27s (remain 22m 35s) Loss: 0.0000(0.0022) Grad: 45.8596  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 34m 30s (remain 21m 32s) Loss: 0.0000(0.0022) Grad: 274.7973  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 35m 32s (remain 20m 29s) Loss: 0.0001(0.0022) Grad: 323.8864  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 36m 34s (remain 19m 26s) Loss: 0.0007(0.0022) Grad: 4199.8564  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 37m 36s (remain 18m 23s) Loss: 0.0013(0.0023) Grad: 4498.1631  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 38m 38s (remain 17m 20s) Loss: 0.0058(0.0023) Grad: 16966.7109  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 39m 40s (remain 16m 17s) Loss: 0.0002(0.0022) Grad: 2207.2278  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 40m 42s (remain 15m 14s) Loss: 0.0002(0.0022) Grad: 2476.9104  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 41m 44s (remain 14m 12s) Loss: 0.0001(0.0022) Grad: 672.2449  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 42m 46s (remain 13m 9s) Loss: 0.0000(0.0022) Grad: 32.9073  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 43m 49s (remain 12m 6s) Loss: 0.0000(0.0022) Grad: 12.7450  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 44m 51s (remain 11m 3s) Loss: 0.0028(0.0022) Grad: 13598.8057  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 45m 53s (remain 10m 1s) Loss: 0.0003(0.0022) Grad: 2077.8308  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 46m 55s (remain 8m 58s) Loss: 0.0000(0.0023) Grad: 63.8282  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 47m 57s (remain 7m 55s) Loss: 0.0000(0.0023) Grad: 21.8115  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 48m 59s (remain 6m 53s) Loss: 0.0044(0.0023) Grad: 12860.8613  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 50m 2s (remain 5m 50s) Loss: 0.0044(0.0023) Grad: 10457.6211  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 51m 4s (remain 4m 48s) Loss: 0.0000(0.0023) Grad: 73.7200  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 52m 6s (remain 3m 45s) Loss: 0.0001(0.0023) Grad: 2036.1550  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 53m 8s (remain 2m 43s) Loss: 0.0008(0.0023) Grad: 7320.9761  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 54m 10s (remain 1m 40s) Loss: 0.0008(0.0023) Grad: 2795.6597  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 55m 12s (remain 0m 38s) Loss: 0.0002(0.0023) Grad: 783.6425  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 55m 50s (remain 0m 0s) Loss: 0.0000(0.0023) Grad: 20.1230  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 46s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0000(0.0039) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0000(0.0041) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0150(0.0038) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0052(0.0042) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0043) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0021(0.0041) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0004(0.0038) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0033(0.0036) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0001(0.0038) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0000(0.0042) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0000(0.0052) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0002(0.0051) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0000(0.0052) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0000(0.0051) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0000(0.0050) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0000(0.0049) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0023(0.0048) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0000(0.0047) \n","Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0047  time: 3571s\n","Epoch 4 - Score: 0.8787\n","Epoch 4 - Save Best Score: 0.8787 Model\n","Epoch: [5][0/5362] Elapsed 0m 1s (remain 94m 1s) Loss: 0.0033(0.0033) Grad: 42925.3672  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 7s (remain 58m 34s) Loss: 0.0065(0.0015) Grad: 24778.8887  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 9s (remain 55m 19s) Loss: 0.0000(0.0021) Grad: 138.2115  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 11s (remain 53m 35s) Loss: 0.0021(0.0019) Grad: 7669.2305  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 13s (remain 52m 14s) Loss: 0.0000(0.0021) Grad: 31.3556  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 15s (remain 50m 59s) Loss: 0.0000(0.0020) Grad: 3.9600  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 17s (remain 49m 46s) Loss: 0.0005(0.0019) Grad: 2999.2710  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 19s (remain 48m 39s) Loss: 0.0000(0.0019) Grad: 75.8464  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 20s (remain 47m 32s) Loss: 0.0043(0.0019) Grad: 10300.4277  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 22s (remain 46m 26s) Loss: 0.0100(0.0020) Grad: 35378.1133  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 24s (remain 45m 22s) Loss: 0.0003(0.0022) Grad: 2374.0601  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 27s (remain 44m 19s) Loss: 0.0009(0.0021) Grad: 6546.5283  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 29s (remain 43m 15s) Loss: 0.0000(0.0020) Grad: 18.5391  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 31s (remain 42m 13s) Loss: 0.0000(0.0019) Grad: 20.0777  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 33s (remain 41m 10s) Loss: 0.0014(0.0020) Grad: 13936.2510  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 35s (remain 40m 7s) Loss: 0.0000(0.0020) Grad: 18.6949  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 37s (remain 39m 4s) Loss: 0.0026(0.0019) Grad: 15227.7637  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 39s (remain 38m 1s) Loss: 0.0000(0.0019) Grad: 81.9514  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 41s (remain 36m 58s) Loss: 0.0000(0.0019) Grad: 11.4556  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 43s (remain 35m 55s) Loss: 0.0331(0.0019) Grad: 151256.4531  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 45s (remain 34m 52s) Loss: 0.0007(0.0019) Grad: 6773.1021  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 48s (remain 33m 50s) Loss: 0.0004(0.0020) Grad: 3738.3962  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 50s (remain 32m 47s) Loss: 0.0000(0.0020) Grad: 62.6812  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 52s (remain 31m 45s) Loss: 0.0000(0.0020) Grad: 19.0914  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 54s (remain 30m 42s) Loss: 0.0002(0.0020) Grad: 1882.0034  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 56s (remain 29m 40s) Loss: 0.0000(0.0020) Grad: 3.4848  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 58s (remain 28m 37s) Loss: 0.0006(0.0020) Grad: 19551.3574  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 28m 0s (remain 27m 35s) Loss: 0.0000(0.0020) Grad: 278.5610  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 29m 2s (remain 26m 32s) Loss: 0.0000(0.0020) Grad: 26.4525  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 30m 4s (remain 25m 30s) Loss: 0.0090(0.0020) Grad: 12992.2393  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 31m 7s (remain 24m 28s) Loss: 0.0000(0.0020) Grad: 197.9741  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 32m 9s (remain 23m 26s) Loss: 0.0000(0.0020) Grad: 3.6197  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 33m 11s (remain 22m 24s) Loss: 0.0000(0.0020) Grad: 31.6004  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 34m 13s (remain 21m 22s) Loss: 0.0000(0.0020) Grad: 3.8103  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 35m 15s (remain 20m 19s) Loss: 0.0001(0.0020) Grad: 2355.4307  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 36m 17s (remain 19m 17s) Loss: 0.0000(0.0020) Grad: 8.5932  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 37m 19s (remain 18m 15s) Loss: 0.0000(0.0020) Grad: 3.5866  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 38m 21s (remain 17m 12s) Loss: 0.0001(0.0020) Grad: 565.3113  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 39m 22s (remain 16m 10s) Loss: 0.0131(0.0020) Grad: 13941.1279  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 40m 24s (remain 15m 8s) Loss: 0.0000(0.0019) Grad: 6.9561  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 41m 26s (remain 14m 5s) Loss: 0.0000(0.0019) Grad: 4.4947  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 42m 28s (remain 13m 3s) Loss: 0.0000(0.0019) Grad: 46.4261  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 43m 30s (remain 12m 1s) Loss: 0.0148(0.0020) Grad: 37928.9102  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 44m 32s (remain 10m 59s) Loss: 0.0202(0.0020) Grad: 40247.5000  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 45m 34s (remain 9m 57s) Loss: 0.0000(0.0020) Grad: 4.8619  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 46m 36s (remain 8m 54s) Loss: 0.0322(0.0020) Grad: 63150.6953  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 47m 38s (remain 7m 52s) Loss: 0.0000(0.0020) Grad: 29.1437  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 48m 40s (remain 6m 50s) Loss: 0.0000(0.0020) Grad: 18.4186  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 49m 42s (remain 5m 48s) Loss: 0.0047(0.0020) Grad: 20963.5977  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 50m 44s (remain 4m 46s) Loss: 0.0000(0.0020) Grad: 129.2338  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 51m 46s (remain 3m 44s) Loss: 0.0000(0.0020) Grad: 40.2996  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 52m 48s (remain 2m 42s) Loss: 0.0000(0.0020) Grad: 14.9633  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 53m 51s (remain 1m 40s) Loss: 0.0000(0.0020) Grad: 16.1418  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 54m 54s (remain 0m 37s) Loss: 0.0000(0.0020) Grad: 12.7203  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 55m 31s (remain 0m 0s) Loss: 0.0001(0.0020) Grad: 318.8570  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 16s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0000(0.0040) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0000(0.0043) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0139(0.0039) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0052(0.0043) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0000(0.0044) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0027(0.0042) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0003(0.0039) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0028(0.0037) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0003(0.0039) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0000(0.0043) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0000(0.0053) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0004(0.0053) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0000(0.0053) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0000(0.0052) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0000(0.0052) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0050) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0019(0.0049) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0000(0.0048) \n","Epoch 5 - avg_train_loss: 0.0020  avg_val_loss: 0.0048  time: 3556s\n","Epoch 5 - Score: 0.8802\n","Epoch 5 - Save Best Score: 0.8802 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 98m 33s) Loss: 0.5674(0.5674) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 7s (remain 58m 55s) Loss: 0.1849(0.3274) Grad: 28295.3047  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 10s (remain 55m 49s) Loss: 0.2934(0.2970) Grad: 27924.9629  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 12s (remain 54m 4s) Loss: 0.2386(0.2595) Grad: 26962.6641  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 15s (remain 52m 40s) Loss: 0.0399(0.2180) Grad: 3599.7166  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 17s (remain 51m 23s) Loss: 0.0227(0.1812) Grad: 404.7910  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 20s (remain 50m 11s) Loss: 0.0232(0.1542) Grad: 752.6306  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 22s (remain 49m 3s) Loss: 0.0053(0.1349) Grad: 742.6840  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 25s (remain 47m 57s) Loss: 0.0030(0.1204) Grad: 488.0500  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 27s (remain 46m 50s) Loss: 0.0110(0.1088) Grad: 451.3106  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 30s (remain 45m 45s) Loss: 0.0233(0.0995) Grad: 1656.4308  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 32s (remain 44m 40s) Loss: 0.0055(0.0914) Grad: 405.4685  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 34s (remain 43m 35s) Loss: 0.0214(0.0845) Grad: 2566.1931  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 37s (remain 42m 30s) Loss: 0.0063(0.0786) Grad: 1062.7157  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 39s (remain 41m 26s) Loss: 0.0045(0.0735) Grad: 442.5409  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 41s (remain 40m 23s) Loss: 0.0029(0.0691) Grad: 217.2867  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 44s (remain 39m 19s) Loss: 0.0086(0.0654) Grad: 1493.2040  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 46s (remain 38m 16s) Loss: 0.0021(0.0620) Grad: 204.7851  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 49s (remain 37m 12s) Loss: 0.0421(0.0589) Grad: 3745.9976  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 51s (remain 36m 9s) Loss: 0.0025(0.0561) Grad: 492.0861  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 53s (remain 35m 5s) Loss: 0.0022(0.0536) Grad: 427.9362  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 56s (remain 34m 2s) Loss: 0.0063(0.0513) Grad: 618.8846  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 58s (remain 32m 59s) Loss: 0.0012(0.0492) Grad: 401.6888  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 24m 0s (remain 31m 56s) Loss: 0.0064(0.0473) Grad: 1260.6448  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 25m 2s (remain 30m 52s) Loss: 0.0091(0.0455) Grad: 1471.7682  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 26m 3s (remain 29m 48s) Loss: 0.0051(0.0439) Grad: 1369.4410  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 27m 5s (remain 28m 45s) Loss: 0.0059(0.0424) Grad: 1022.0010  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 28m 6s (remain 27m 41s) Loss: 0.0004(0.0410) Grad: 156.2074  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 29m 8s (remain 26m 38s) Loss: 0.0040(0.0397) Grad: 547.2057  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 30m 9s (remain 25m 35s) Loss: 0.0005(0.0385) Grad: 97.2044  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 31m 10s (remain 24m 31s) Loss: 0.0243(0.0373) Grad: 3644.0493  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 32m 12s (remain 23m 28s) Loss: 0.0070(0.0363) Grad: 860.3757  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 33m 13s (remain 22m 25s) Loss: 0.0001(0.0353) Grad: 37.9534  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 34m 14s (remain 21m 22s) Loss: 0.0001(0.0344) Grad: 47.1501  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 35m 15s (remain 20m 19s) Loss: 0.0005(0.0335) Grad: 88.8878  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 36m 16s (remain 19m 17s) Loss: 0.0021(0.0326) Grad: 386.8421  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 37m 17s (remain 18m 14s) Loss: 0.0025(0.0318) Grad: 634.4526  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 38m 18s (remain 17m 11s) Loss: 0.0006(0.0311) Grad: 99.3204  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 39m 19s (remain 16m 9s) Loss: 0.0012(0.0304) Grad: 125.9590  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 40m 20s (remain 15m 6s) Loss: 0.0193(0.0297) Grad: 2137.9263  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 41m 21s (remain 14m 4s) Loss: 0.0021(0.0291) Grad: 274.3718  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 42m 22s (remain 13m 1s) Loss: 0.0000(0.0285) Grad: 7.5286  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 43m 23s (remain 11m 59s) Loss: 0.0031(0.0279) Grad: 750.1771  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 44m 25s (remain 10m 57s) Loss: 0.0201(0.0274) Grad: 3063.0515  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 45m 26s (remain 9m 55s) Loss: 0.0004(0.0268) Grad: 172.4173  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 46m 27s (remain 8m 53s) Loss: 0.0045(0.0263) Grad: 828.7316  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 47m 28s (remain 7m 51s) Loss: 0.0002(0.0258) Grad: 44.7471  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 48m 29s (remain 6m 49s) Loss: 0.0003(0.0254) Grad: 131.9386  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 49m 30s (remain 5m 47s) Loss: 0.0007(0.0249) Grad: 159.5772  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 50m 31s (remain 4m 45s) Loss: 0.0001(0.0245) Grad: 15.7290  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 51m 33s (remain 3m 43s) Loss: 0.0041(0.0240) Grad: 458.4943  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 52m 34s (remain 2m 41s) Loss: 0.0104(0.0236) Grad: 2479.1487  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 53m 35s (remain 1m 39s) Loss: 0.0026(0.0232) Grad: 286.1720  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 54m 36s (remain 0m 37s) Loss: 0.0005(0.0229) Grad: 99.3901  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 55m 14s (remain 0m 0s) Loss: 0.0090(0.0226) Grad: 1485.0465  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 15m 13s) Loss: 0.0009(0.0009) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0016(0.0025) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0020(0.0027) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0009(0.0029) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0084(0.0041) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0002(0.0045) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0073(0.0043) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0024(0.0042) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0001(0.0040) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0612(0.0040) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0029(0.0042) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0008(0.0044) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0028(0.0043) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0030(0.0042) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0042) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0001(0.0042) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0024(0.0040) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0000(0.0039) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0100(0.0038) \n","Epoch 1 - avg_train_loss: 0.0226  avg_val_loss: 0.0038  time: 3533s\n","Epoch 1 - Score: 0.8504\n","Epoch 1 - Save Best Score: 0.8504 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 98m 22s) Loss: 0.0007(0.0007) Grad: 1651.7345  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 6s (remain 57m 55s) Loss: 0.0001(0.0023) Grad: 204.2332  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 8s (remain 54m 50s) Loss: 0.0000(0.0021) Grad: 6.5121  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 9s (remain 53m 3s) Loss: 0.0085(0.0022) Grad: 15176.7061  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 10s (remain 51m 39s) Loss: 0.0167(0.0027) Grad: 14157.5029  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 11s (remain 50m 25s) Loss: 0.0009(0.0028) Grad: 3168.6519  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 13s (remain 49m 16s) Loss: 0.0049(0.0028) Grad: 6948.7686  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 14s (remain 48m 9s) Loss: 0.0061(0.0030) Grad: 13914.7480  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 15s (remain 47m 2s) Loss: 0.0000(0.0030) Grad: 47.3604  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 17s (remain 45m 57s) Loss: 0.0000(0.0031) Grad: 21.6735  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 18s (remain 44m 53s) Loss: 0.0154(0.0031) Grad: 21506.9531  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 20s (remain 43m 51s) Loss: 0.0008(0.0030) Grad: 2993.3303  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 21s (remain 42m 48s) Loss: 0.0003(0.0030) Grad: 3970.9102  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 23s (remain 41m 47s) Loss: 0.0000(0.0031) Grad: 133.5332  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 24s (remain 40m 43s) Loss: 0.0070(0.0031) Grad: 11325.1973  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 25s (remain 39m 40s) Loss: 0.0026(0.0030) Grad: 3956.4014  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 26s (remain 38m 38s) Loss: 0.0003(0.0030) Grad: 1934.6193  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 28s (remain 37m 36s) Loss: 0.0003(0.0030) Grad: 1590.9150  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 31s (remain 36m 36s) Loss: 0.0101(0.0030) Grad: 29156.3320  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 33s (remain 35m 36s) Loss: 0.0051(0.0030) Grad: 18543.7695  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 36s (remain 34m 36s) Loss: 0.0001(0.0030) Grad: 588.0945  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 21m 38s (remain 33m 36s) Loss: 0.0047(0.0031) Grad: 27120.0527  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 22m 41s (remain 32m 35s) Loss: 0.0026(0.0030) Grad: 7933.1382  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 23m 43s (remain 31m 33s) Loss: 0.0010(0.0031) Grad: 3924.8228  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 24m 45s (remain 30m 31s) Loss: 0.0000(0.0031) Grad: 66.0553  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 25m 48s (remain 29m 30s) Loss: 0.0000(0.0030) Grad: 15.9940  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 26m 49s (remain 28m 28s) Loss: 0.0045(0.0030) Grad: 28117.8418  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 27m 52s (remain 27m 27s) Loss: 0.0054(0.0031) Grad: 27276.1348  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 28m 53s (remain 26m 25s) Loss: 0.0005(0.0031) Grad: 4686.5015  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 29m 55s (remain 25m 23s) Loss: 0.0015(0.0031) Grad: 13093.8584  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 30m 57s (remain 24m 21s) Loss: 0.0095(0.0031) Grad: 34398.8359  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 32m 0s (remain 23m 20s) Loss: 0.0034(0.0031) Grad: 11329.7129  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 33m 2s (remain 22m 18s) Loss: 0.0070(0.0031) Grad: 6261.8198  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 34m 4s (remain 21m 16s) Loss: 0.0011(0.0031) Grad: 5774.6323  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 35m 6s (remain 20m 14s) Loss: 0.0063(0.0031) Grad: 15388.7783  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 36m 8s (remain 19m 12s) Loss: 0.0014(0.0032) Grad: 14277.5781  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 37m 10s (remain 18m 10s) Loss: 0.0002(0.0032) Grad: 946.0145  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 38m 12s (remain 17m 8s) Loss: 0.0006(0.0031) Grad: 3560.8486  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 39m 13s (remain 16m 6s) Loss: 0.0004(0.0032) Grad: 3941.2695  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 40m 15s (remain 15m 4s) Loss: 0.0016(0.0031) Grad: 8168.1934  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 41m 17s (remain 14m 2s) Loss: 0.0000(0.0031) Grad: 40.0054  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 42m 19s (remain 13m 0s) Loss: 0.0008(0.0031) Grad: 3639.0999  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 43m 20s (remain 11m 58s) Loss: 0.0014(0.0031) Grad: 4387.2910  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 44m 22s (remain 10m 56s) Loss: 0.0003(0.0031) Grad: 6345.9644  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 45m 24s (remain 9m 54s) Loss: 0.0000(0.0031) Grad: 32.8498  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 46m 25s (remain 8m 52s) Loss: 0.0000(0.0032) Grad: 31.6166  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 47m 27s (remain 7m 50s) Loss: 0.0012(0.0032) Grad: 4863.8931  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 48m 29s (remain 6m 49s) Loss: 0.0044(0.0031) Grad: 20164.7266  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 49m 30s (remain 5m 47s) Loss: 0.0101(0.0031) Grad: 39903.8086  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 50m 32s (remain 4m 45s) Loss: 0.0020(0.0031) Grad: 19360.1289  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 51m 33s (remain 3m 43s) Loss: 0.0001(0.0031) Grad: 792.1735  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 52m 35s (remain 2m 41s) Loss: 0.0154(0.0031) Grad: 28654.9453  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 53m 36s (remain 1m 39s) Loss: 0.0000(0.0032) Grad: 123.2406  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 54m 38s (remain 0m 37s) Loss: 0.0003(0.0031) Grad: 2451.4644  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 55m 16s (remain 0m 0s) Loss: 0.0195(0.0031) Grad: 18115.9688  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 54s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 27s) Loss: 0.0010(0.0030) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0058(0.0032) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0001(0.0034) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0092(0.0052) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0000(0.0056) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0117(0.0054) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0030(0.0052) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0050) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0670(0.0050) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0010(0.0053) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0002(0.0055) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0023(0.0054) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0002(0.0053) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0052) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0051) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0004(0.0049) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0000(0.0048) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0250(0.0046) \n","Epoch 2 - avg_train_loss: 0.0031  avg_val_loss: 0.0046  time: 3539s\n","Epoch 2 - Score: 0.8696\n","Epoch 2 - Save Best Score: 0.8696 Model\n","Epoch: [3][0/5362] Elapsed 0m 1s (remain 98m 14s) Loss: 0.0000(0.0000) Grad: 994.4786  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 6s (remain 57m 46s) Loss: 0.0004(0.0025) Grad: 3331.1235  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 7s (remain 54m 38s) Loss: 0.0000(0.0029) Grad: 203.0296  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 8s (remain 52m 56s) Loss: 0.0000(0.0025) Grad: 21.5452  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 10s (remain 51m 38s) Loss: 0.0000(0.0028) Grad: 25.1814  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 12s (remain 50m 28s) Loss: 0.0000(0.0029) Grad: 117.7532  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 13s (remain 49m 22s) Loss: 0.0044(0.0027) Grad: 12850.1953  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 15s (remain 48m 16s) Loss: 0.0007(0.0028) Grad: 3415.3564  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 16s (remain 47m 9s) Loss: 0.0024(0.0028) Grad: 6617.9092  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 18s (remain 46m 5s) Loss: 0.0143(0.0028) Grad: 32705.3066  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 20s (remain 45m 3s) Loss: 0.0140(0.0029) Grad: 40564.7070  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 21s (remain 43m 59s) Loss: 0.0000(0.0028) Grad: 69.2003  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 23s (remain 42m 55s) Loss: 0.0003(0.0028) Grad: 5138.5801  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 24s (remain 41m 52s) Loss: 0.0059(0.0027) Grad: 8886.1631  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 26s (remain 40m 48s) Loss: 0.0002(0.0027) Grad: 612.1903  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 27s (remain 39m 47s) Loss: 0.0000(0.0027) Grad: 5.8427  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 29s (remain 38m 44s) Loss: 0.0002(0.0028) Grad: 1239.4805  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 17m 30s (remain 37m 41s) Loss: 0.0025(0.0028) Grad: 6186.9741  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 18m 32s (remain 36m 38s) Loss: 0.0000(0.0028) Grad: 12.1446  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 19m 33s (remain 35m 36s) Loss: 0.0019(0.0028) Grad: 8028.0327  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 20m 35s (remain 34m 34s) Loss: 0.0003(0.0028) Grad: 2637.7495  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 21m 36s (remain 33m 32s) Loss: 0.0001(0.0028) Grad: 590.2574  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 22m 38s (remain 32m 30s) Loss: 0.0015(0.0028) Grad: 5271.0610  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 23m 39s (remain 31m 28s) Loss: 0.0058(0.0028) Grad: 11447.1279  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 24m 41s (remain 30m 26s) Loss: 0.0009(0.0027) Grad: 13230.4766  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 25m 42s (remain 29m 24s) Loss: 0.0000(0.0028) Grad: 87.9056  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 26m 44s (remain 28m 22s) Loss: 0.0000(0.0028) Grad: 76.5547  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 27m 45s (remain 27m 20s) Loss: 0.0000(0.0028) Grad: 205.9431  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 28m 46s (remain 26m 18s) Loss: 0.0018(0.0028) Grad: 26060.2520  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 29m 48s (remain 25m 17s) Loss: 0.0020(0.0027) Grad: 4803.6787  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 30m 49s (remain 24m 15s) Loss: 0.0004(0.0027) Grad: 8603.5615  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 31m 51s (remain 23m 13s) Loss: 0.0000(0.0027) Grad: 3.8577  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 32m 52s (remain 22m 11s) Loss: 0.0180(0.0027) Grad: 36978.0898  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 33m 54s (remain 21m 10s) Loss: 0.0000(0.0027) Grad: 9.0726  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 34m 55s (remain 20m 8s) Loss: 0.0000(0.0027) Grad: 216.1486  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 35m 57s (remain 19m 6s) Loss: 0.0031(0.0027) Grad: 18270.1523  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 36m 58s (remain 18m 5s) Loss: 0.0006(0.0026) Grad: 1946.7372  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 38m 0s (remain 17m 3s) Loss: 0.0031(0.0026) Grad: 6983.2881  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 39m 1s (remain 16m 1s) Loss: 0.0000(0.0026) Grad: 19.9548  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 40m 2s (remain 14m 59s) Loss: 0.0001(0.0027) Grad: 487.9943  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 41m 4s (remain 13m 58s) Loss: 0.0027(0.0027) Grad: 8465.6592  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 42m 5s (remain 12m 56s) Loss: 0.0050(0.0028) Grad: 4982.5894  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 43m 7s (remain 11m 54s) Loss: 0.0038(0.0027) Grad: 5510.7041  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 44m 8s (remain 10m 53s) Loss: 0.0025(0.0027) Grad: 9753.9707  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 45m 9s (remain 9m 51s) Loss: 0.0008(0.0027) Grad: 3124.4324  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 46m 11s (remain 8m 50s) Loss: 0.0032(0.0027) Grad: 5245.3398  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 47m 12s (remain 7m 48s) Loss: 0.0000(0.0027) Grad: 24.5044  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 48m 14s (remain 6m 46s) Loss: 0.0000(0.0027) Grad: 26.3986  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 49m 15s (remain 5m 45s) Loss: 0.0031(0.0027) Grad: 21886.2070  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 50m 16s (remain 4m 43s) Loss: 0.0024(0.0027) Grad: 27679.8125  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 51m 16s (remain 3m 42s) Loss: 0.0000(0.0027) Grad: 10.3414  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 52m 17s (remain 2m 40s) Loss: 0.0069(0.0027) Grad: 24990.1172  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 53m 18s (remain 1m 39s) Loss: 0.0000(0.0027) Grad: 67.8691  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 54m 18s (remain 0m 37s) Loss: 0.0000(0.0027) Grad: 21.6550  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 54m 56s (remain 0m 0s) Loss: 0.0004(0.0027) Grad: 1201.9207  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 35s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0002(0.0033) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0014(0.0030) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0000(0.0031) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0118(0.0049) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0000(0.0054) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0128(0.0051) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0039(0.0049) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0047) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0627(0.0047) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0008(0.0051) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 21s) Loss: 0.0004(0.0054) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 9s) Loss: 0.0059(0.0053) \n","EVAL: [1300/1788] Elapsed 2m 34s (remain 0m 57s) Loss: 0.0003(0.0052) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 46s) Loss: 0.0000(0.0050) \n","EVAL: [1500/1788] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0000(0.0049) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0005(0.0048) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0000(0.0046) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0280(0.0044) \n","Epoch 3 - avg_train_loss: 0.0027  avg_val_loss: 0.0044  time: 3514s\n","Epoch 3 - Score: 0.8792\n","Epoch 3 - Save Best Score: 0.8792 Model\n","Epoch: [4][0/5362] Elapsed 0m 1s (remain 91m 34s) Loss: 0.0000(0.0000) Grad: 1000.4719  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 6s (remain 57m 19s) Loss: 0.0000(0.0015) Grad: 70.5419  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 6s (remain 54m 14s) Loss: 0.0000(0.0020) Grad: 241.5214  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 7s (remain 52m 35s) Loss: 0.0048(0.0019) Grad: 8541.1260  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 9s (remain 51m 21s) Loss: 0.0000(0.0018) Grad: 17.4791  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 10s (remain 50m 8s) Loss: 0.0000(0.0017) Grad: 39.7800  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 10s (remain 48m 58s) Loss: 0.0004(0.0018) Grad: 5037.7705  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 11s (remain 47m 50s) Loss: 0.0024(0.0017) Grad: 8776.9238  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 12s (remain 46m 45s) Loss: 0.0000(0.0018) Grad: 36.9779  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 13s (remain 45m 40s) Loss: 0.0015(0.0018) Grad: 6069.0913  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 14s (remain 44m 37s) Loss: 0.0047(0.0018) Grad: 11881.6689  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 15s (remain 43m 33s) Loss: 0.0001(0.0019) Grad: 699.1763  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 16s (remain 42m 30s) Loss: 0.0000(0.0019) Grad: 232.2834  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 17s (remain 41m 28s) Loss: 0.0005(0.0019) Grad: 3131.4082  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 18s (remain 40m 26s) Loss: 0.0000(0.0019) Grad: 216.5877  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 18s (remain 39m 23s) Loss: 0.0000(0.0020) Grad: 45.3888  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 19s (remain 38m 21s) Loss: 0.0002(0.0020) Grad: 1756.3685  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 20s (remain 37m 19s) Loss: 0.0002(0.0020) Grad: 1609.3766  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 21s (remain 36m 17s) Loss: 0.0000(0.0021) Grad: 41.7418  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 21s (remain 35m 15s) Loss: 0.0000(0.0022) Grad: 14.4830  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 23s (remain 34m 14s) Loss: 0.0002(0.0021) Grad: 3281.2317  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 21m 23s (remain 33m 12s) Loss: 0.0001(0.0021) Grad: 402.5839  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 22m 24s (remain 32m 11s) Loss: 0.0000(0.0021) Grad: 5.1746  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 23m 25s (remain 31m 10s) Loss: 0.0005(0.0021) Grad: 8795.4023  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 24m 26s (remain 30m 8s) Loss: 0.0041(0.0021) Grad: 4926.7720  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 25m 27s (remain 29m 7s) Loss: 0.0039(0.0021) Grad: 21875.5938  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 26m 28s (remain 28m 6s) Loss: 0.0000(0.0022) Grad: 154.7254  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 27m 29s (remain 27m 4s) Loss: 0.0001(0.0022) Grad: 634.0654  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 28m 30s (remain 26m 3s) Loss: 0.0000(0.0022) Grad: 14.9852  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 29m 30s (remain 25m 2s) Loss: 0.0002(0.0022) Grad: 7171.5005  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 30m 31s (remain 24m 1s) Loss: 0.0012(0.0022) Grad: 6432.2871  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 31m 33s (remain 23m 0s) Loss: 0.0000(0.0022) Grad: 9.5014  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 32m 34s (remain 21m 59s) Loss: 0.0000(0.0022) Grad: 10.3700  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 33m 34s (remain 20m 57s) Loss: 0.0032(0.0022) Grad: 14363.7520  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 34m 36s (remain 19m 57s) Loss: 0.0000(0.0022) Grad: 4.1379  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 35m 38s (remain 18m 56s) Loss: 0.0007(0.0022) Grad: 3346.8003  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 36m 39s (remain 17m 55s) Loss: 0.0000(0.0022) Grad: 170.0699  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 37m 41s (remain 16m 54s) Loss: 0.0000(0.0022) Grad: 15.7198  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 38m 42s (remain 15m 53s) Loss: 0.0040(0.0022) Grad: 45139.9062  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 39m 44s (remain 14m 53s) Loss: 0.0000(0.0023) Grad: 64.3773  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 40m 46s (remain 13m 52s) Loss: 0.0000(0.0023) Grad: 194.7084  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 41m 48s (remain 12m 51s) Loss: 0.0005(0.0023) Grad: 5691.4888  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 42m 50s (remain 11m 50s) Loss: 0.0014(0.0023) Grad: 5999.1904  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 43m 52s (remain 10m 49s) Loss: 0.0000(0.0022) Grad: 183.3744  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 44m 53s (remain 9m 48s) Loss: 0.0002(0.0022) Grad: 1681.8121  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 45m 54s (remain 8m 46s) Loss: 0.0000(0.0022) Grad: 10.8235  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 46m 56s (remain 7m 45s) Loss: 0.0000(0.0022) Grad: 17.5340  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 47m 58s (remain 6m 44s) Loss: 0.0074(0.0022) Grad: 17487.0820  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 49m 0s (remain 5m 43s) Loss: 0.0111(0.0022) Grad: 51959.6172  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 50m 2s (remain 4m 42s) Loss: 0.0009(0.0022) Grad: 11842.9697  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 51m 3s (remain 3m 41s) Loss: 0.0000(0.0022) Grad: 15.7568  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 52m 5s (remain 2m 39s) Loss: 0.0000(0.0022) Grad: 16.6156  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 53m 6s (remain 1m 38s) Loss: 0.0001(0.0022) Grad: 703.5803  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 54m 8s (remain 0m 37s) Loss: 0.0002(0.0022) Grad: 2988.2415  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 54m 46s (remain 0m 0s) Loss: 0.0000(0.0022) Grad: 839.7515  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 35s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0001(0.0033) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0016(0.0033) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0000(0.0035) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0160(0.0053) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 34s) Loss: 0.0000(0.0059) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0151(0.0056) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0045(0.0055) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0052) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0765(0.0052) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0006(0.0057) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 21s) Loss: 0.0000(0.0060) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 9s) Loss: 0.0096(0.0058) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0004(0.0057) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 46s) Loss: 0.0000(0.0055) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0054) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0004(0.0053) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0000(0.0051) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0271(0.0049) \n","Epoch 4 - avg_train_loss: 0.0022  avg_val_loss: 0.0049  time: 3505s\n","Epoch 4 - Score: 0.8810\n","Epoch 4 - Save Best Score: 0.8810 Model\n","Epoch: [5][0/5362] Elapsed 0m 1s (remain 94m 11s) Loss: 0.0000(0.0000) Grad: 840.8419  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 6s (remain 57m 51s) Loss: 0.0000(0.0019) Grad: 29.0930  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 8s (remain 54m 48s) Loss: 0.0000(0.0021) Grad: 8.9026  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 8s (remain 52m 57s) Loss: 0.0000(0.0019) Grad: 13.3232  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 9s (remain 51m 31s) Loss: 0.0000(0.0018) Grad: 4.3392  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 10s (remain 50m 14s) Loss: 0.0328(0.0020) Grad: 32892.6562  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 11s (remain 49m 2s) Loss: 0.0040(0.0019) Grad: 11257.0674  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 12s (remain 47m 55s) Loss: 0.0000(0.0018) Grad: 3.8112  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 13s (remain 46m 50s) Loss: 0.0004(0.0018) Grad: 2340.4822  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 14s (remain 45m 46s) Loss: 0.0000(0.0018) Grad: 4.4054  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 15s (remain 44m 41s) Loss: 0.0220(0.0017) Grad: 49817.0195  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 16s (remain 43m 37s) Loss: 0.0000(0.0018) Grad: 15.3012  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 17s (remain 42m 34s) Loss: 0.0000(0.0018) Grad: 71.6925  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 17s (remain 41m 30s) Loss: 0.0044(0.0017) Grad: 4804.9771  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 18s (remain 40m 28s) Loss: 0.0001(0.0017) Grad: 261.2320  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 19s (remain 39m 25s) Loss: 0.0000(0.0018) Grad: 213.4854  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 20s (remain 38m 23s) Loss: 0.0010(0.0018) Grad: 8259.4414  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 21s (remain 37m 21s) Loss: 0.0000(0.0019) Grad: 63.5978  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 21s (remain 36m 18s) Loss: 0.0080(0.0019) Grad: 46524.7500  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 22s (remain 35m 16s) Loss: 0.0000(0.0019) Grad: 5.6766  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 23s (remain 34m 14s) Loss: 0.0106(0.0019) Grad: 11037.1816  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 23s (remain 33m 12s) Loss: 0.0000(0.0018) Grad: 7.4502  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 24s (remain 32m 11s) Loss: 0.0000(0.0018) Grad: 2.3558  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 25s (remain 31m 9s) Loss: 0.0005(0.0019) Grad: 4135.2520  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 26s (remain 30m 8s) Loss: 0.0000(0.0019) Grad: 1.8203  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 27s (remain 29m 7s) Loss: 0.0019(0.0019) Grad: 11491.2324  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 27s (remain 28m 5s) Loss: 0.0036(0.0020) Grad: 5522.2095  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 27m 28s (remain 27m 4s) Loss: 0.0000(0.0020) Grad: 18.3018  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 28m 29s (remain 26m 3s) Loss: 0.0003(0.0020) Grad: 2825.2524  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 29m 30s (remain 25m 1s) Loss: 0.0000(0.0020) Grad: 451.9581  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 30m 31s (remain 24m 0s) Loss: 0.0001(0.0020) Grad: 683.9639  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 31m 31s (remain 22m 59s) Loss: 0.0041(0.0020) Grad: 12258.0244  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 32m 32s (remain 21m 58s) Loss: 0.0000(0.0020) Grad: 22.1649  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 33m 33s (remain 20m 57s) Loss: 0.0000(0.0020) Grad: 2.7112  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 34m 34s (remain 19m 56s) Loss: 0.0000(0.0020) Grad: 183.9358  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 35m 35s (remain 18m 55s) Loss: 0.0000(0.0020) Grad: 19.1207  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 36m 36s (remain 17m 53s) Loss: 0.0004(0.0020) Grad: 1731.7449  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 37m 36s (remain 16m 52s) Loss: 0.0000(0.0020) Grad: 8.5298  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 38m 37s (remain 15m 51s) Loss: 0.0014(0.0020) Grad: 7043.8037  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 39m 38s (remain 14m 50s) Loss: 0.0025(0.0020) Grad: 22097.1406  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 40m 39s (remain 13m 49s) Loss: 0.0000(0.0020) Grad: 59.9290  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 41m 40s (remain 12m 48s) Loss: 0.0000(0.0021) Grad: 228.3237  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 42m 40s (remain 11m 47s) Loss: 0.0123(0.0021) Grad: 64655.0859  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 43m 41s (remain 10m 46s) Loss: 0.0000(0.0021) Grad: 27.4120  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 44m 42s (remain 9m 45s) Loss: 0.0018(0.0021) Grad: 31403.9570  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 45m 42s (remain 8m 44s) Loss: 0.0128(0.0020) Grad: 25217.0625  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 46m 43s (remain 7m 43s) Loss: 0.0001(0.0020) Grad: 1949.3999  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 47m 44s (remain 6m 42s) Loss: 0.0000(0.0021) Grad: 18.6376  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 48m 45s (remain 5m 41s) Loss: 0.0000(0.0020) Grad: 44.0708  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 49m 46s (remain 4m 40s) Loss: 0.0030(0.0020) Grad: 56088.9297  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 50m 47s (remain 3m 39s) Loss: 0.0001(0.0020) Grad: 1177.1245  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 51m 48s (remain 2m 39s) Loss: 0.0003(0.0020) Grad: 2933.4917  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 52m 49s (remain 1m 38s) Loss: 0.0010(0.0020) Grad: 6570.6294  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 53m 49s (remain 0m 37s) Loss: 0.0000(0.0020) Grad: 8.7599  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 54m 26s (remain 0m 0s) Loss: 0.0006(0.0020) Grad: 11626.4707  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 26s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0001(0.0039) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 9s) Loss: 0.0005(0.0035) \n","EVAL: [300/1788] Elapsed 0m 35s (remain 2m 57s) Loss: 0.0000(0.0036) \n","EVAL: [400/1788] Elapsed 0m 47s (remain 2m 45s) Loss: 0.0153(0.0054) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0000(0.0060) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0163(0.0057) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 8s) Loss: 0.0043(0.0055) \n","EVAL: [800/1788] Elapsed 1m 34s (remain 1m 56s) Loss: 0.0000(0.0052) \n","EVAL: [900/1788] Elapsed 1m 46s (remain 1m 45s) Loss: 0.0690(0.0052) \n","EVAL: [1000/1788] Elapsed 1m 58s (remain 1m 33s) Loss: 0.0005(0.0058) \n","EVAL: [1100/1788] Elapsed 2m 10s (remain 1m 21s) Loss: 0.0001(0.0061) \n","EVAL: [1200/1788] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0101(0.0060) \n","EVAL: [1300/1788] Elapsed 2m 34s (remain 0m 57s) Loss: 0.0002(0.0058) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 46s) Loss: 0.0000(0.0056) \n","EVAL: [1500/1788] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0000(0.0055) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0003(0.0053) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0000(0.0052) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0287(0.0050) \n","Epoch 5 - avg_train_loss: 0.0020  avg_val_loss: 0.0050  time: 3485s\n","Epoch 5 - Score: 0.8811\n","Epoch 5 - Save Best Score: 0.8811 Model\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 121m 14s) Loss: 0.2624(0.2624) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 3s (remain 55m 10s) Loss: 0.1696(0.2782) Grad: 14339.6455  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 4s (remain 53m 5s) Loss: 0.2493(0.2655) Grad: 11848.2021  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 4s (remain 51m 50s) Loss: 0.0622(0.2250) Grad: 2549.2158  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 6s (remain 50m 45s) Loss: 0.0431(0.1825) Grad: 878.0704  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 7s (remain 49m 47s) Loss: 0.0258(0.1503) Grad: 275.5955  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 9s (remain 48m 47s) Loss: 0.0069(0.1288) Grad: 173.4691  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 10s (remain 47m 42s) Loss: 0.0169(0.1133) Grad: 202.4743  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 11s (remain 46m 39s) Loss: 0.0255(0.1015) Grad: 406.1709  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 12s (remain 45m 35s) Loss: 0.0331(0.0922) Grad: 533.2047  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 13s (remain 44m 33s) Loss: 0.0060(0.0845) Grad: 295.1204  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 14s (remain 43m 30s) Loss: 0.0045(0.0780) Grad: 219.6971  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 15s (remain 42m 27s) Loss: 0.0020(0.0723) Grad: 101.7633  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 16s (remain 41m 25s) Loss: 0.0024(0.0673) Grad: 182.1213  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 17s (remain 40m 23s) Loss: 0.0022(0.0631) Grad: 123.8577  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 17s (remain 39m 20s) Loss: 0.0082(0.0594) Grad: 464.7251  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 18s (remain 38m 18s) Loss: 0.0028(0.0561) Grad: 452.3272  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 19s (remain 37m 17s) Loss: 0.0133(0.0532) Grad: 1279.7587  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 20s (remain 36m 15s) Loss: 0.0006(0.0505) Grad: 46.4249  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 21s (remain 35m 14s) Loss: 0.0033(0.0481) Grad: 281.9446  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 22s (remain 34m 12s) Loss: 0.0016(0.0460) Grad: 156.2729  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 22s (remain 33m 11s) Loss: 0.0081(0.0440) Grad: 788.3150  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 23s (remain 32m 9s) Loss: 0.0006(0.0422) Grad: 66.1723  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 23m 24s (remain 31m 8s) Loss: 0.0007(0.0406) Grad: 115.6130  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 24m 25s (remain 30m 7s) Loss: 0.0009(0.0392) Grad: 87.3969  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 25m 26s (remain 29m 6s) Loss: 0.0075(0.0378) Grad: 446.8089  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 26m 27s (remain 28m 4s) Loss: 0.0076(0.0365) Grad: 516.0209  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 27m 27s (remain 27m 3s) Loss: 0.0087(0.0354) Grad: 419.6814  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 28m 29s (remain 26m 2s) Loss: 0.0023(0.0343) Grad: 177.6533  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 29m 30s (remain 25m 2s) Loss: 0.0167(0.0333) Grad: 795.3755  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 30m 33s (remain 24m 2s) Loss: 0.0012(0.0324) Grad: 528.2374  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 31m 34s (remain 23m 1s) Loss: 0.0003(0.0315) Grad: 40.7845  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 32m 35s (remain 22m 0s) Loss: 0.0059(0.0306) Grad: 255.0978  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 33m 37s (remain 20m 59s) Loss: 0.0038(0.0298) Grad: 508.5351  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 34m 39s (remain 19m 58s) Loss: 0.0006(0.0290) Grad: 39.4484  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 35m 40s (remain 18m 57s) Loss: 0.0107(0.0283) Grad: 299.0629  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 36m 41s (remain 17m 56s) Loss: 0.0003(0.0276) Grad: 34.0032  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 37m 43s (remain 16m 55s) Loss: 0.0006(0.0270) Grad: 66.6468  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 38m 44s (remain 15m 54s) Loss: 0.0035(0.0264) Grad: 162.6880  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 39m 45s (remain 14m 53s) Loss: 0.0002(0.0258) Grad: 32.1558  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 40m 46s (remain 13m 52s) Loss: 0.0029(0.0253) Grad: 253.1616  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 41m 47s (remain 12m 50s) Loss: 0.0078(0.0248) Grad: 487.0119  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 42m 48s (remain 11m 49s) Loss: 0.0102(0.0243) Grad: 371.3524  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 43m 49s (remain 10m 48s) Loss: 0.0052(0.0238) Grad: 291.8999  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 44m 50s (remain 9m 47s) Loss: 0.0003(0.0234) Grad: 29.0993  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 45m 50s (remain 8m 46s) Loss: 0.0083(0.0229) Grad: 1039.4962  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 46m 51s (remain 7m 45s) Loss: 0.0000(0.0225) Grad: 0.9012  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 47m 52s (remain 6m 43s) Loss: 0.0004(0.0221) Grad: 29.9319  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 48m 53s (remain 5m 42s) Loss: 0.0099(0.0217) Grad: 1608.6804  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 49m 53s (remain 4m 41s) Loss: 0.0013(0.0213) Grad: 144.0723  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 50m 54s (remain 3m 40s) Loss: 0.0006(0.0210) Grad: 177.3577  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 51m 55s (remain 2m 39s) Loss: 0.0020(0.0207) Grad: 140.3734  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 52m 56s (remain 1m 38s) Loss: 0.0003(0.0203) Grad: 37.3819  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 53m 57s (remain 0m 37s) Loss: 0.0286(0.0200) Grad: 952.2310  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 54m 33s (remain 0m 0s) Loss: 0.0000(0.0199) Grad: 33.2445  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 15m 11s) Loss: 0.0008(0.0008) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 27s) Loss: 0.0004(0.0029) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0036(0.0031) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0038(0.0029) \n","EVAL: [400/1788] Elapsed 0m 47s (remain 2m 45s) Loss: 0.0000(0.0030) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0133(0.0032) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0035(0.0033) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0043(0.0031) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0005(0.0030) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0034(0.0032) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0200(0.0035) \n","EVAL: [1100/1788] Elapsed 2m 10s (remain 1m 21s) Loss: 0.0003(0.0037) \n","EVAL: [1200/1788] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0001(0.0037) \n","EVAL: [1300/1788] Elapsed 2m 34s (remain 0m 57s) Loss: 0.0025(0.0037) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 45s) Loss: 0.0250(0.0037) \n","EVAL: [1500/1788] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0154(0.0037) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0000(0.0037) \n","EVAL: [1700/1788] Elapsed 3m 21s (remain 0m 10s) Loss: 0.0005(0.0036) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0009(0.0035) \n","Epoch 1 - avg_train_loss: 0.0199  avg_val_loss: 0.0035  time: 3492s\n","Epoch 1 - Score: 0.8373\n","Epoch 1 - Save Best Score: 0.8373 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 100m 33s) Loss: 0.0385(0.0385) Grad: 39970.9141  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 5s (remain 57m 4s) Loss: 0.0013(0.0033) Grad: 2320.8364  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 6s (remain 54m 10s) Loss: 0.0001(0.0035) Grad: 515.6456  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 7s (remain 52m 29s) Loss: 0.0048(0.0033) Grad: 12733.5635  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 8s (remain 51m 9s) Loss: 0.0005(0.0034) Grad: 3687.3357  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 8s (remain 49m 56s) Loss: 0.0000(0.0037) Grad: 222.6243  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 9s (remain 48m 49s) Loss: 0.0000(0.0036) Grad: 118.5744  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 11s (remain 47m 46s) Loss: 0.0013(0.0035) Grad: 4236.6284  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 11s (remain 46m 40s) Loss: 0.0020(0.0034) Grad: 7434.2578  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 12s (remain 45m 36s) Loss: 0.0000(0.0033) Grad: 176.7657  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 13s (remain 44m 33s) Loss: 0.0001(0.0033) Grad: 559.9091  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 14s (remain 43m 29s) Loss: 0.0032(0.0033) Grad: 7527.4678  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 15s (remain 42m 27s) Loss: 0.0000(0.0034) Grad: 14.2017  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 16s (remain 41m 25s) Loss: 0.0008(0.0034) Grad: 3376.1294  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 17s (remain 40m 24s) Loss: 0.0028(0.0034) Grad: 8049.8208  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 18s (remain 39m 21s) Loss: 0.0000(0.0034) Grad: 109.7046  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 19s (remain 38m 20s) Loss: 0.0002(0.0033) Grad: 1301.8990  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 20s (remain 37m 20s) Loss: 0.0033(0.0033) Grad: 5643.1494  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 21s (remain 36m 18s) Loss: 0.0000(0.0032) Grad: 95.4570  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 22s (remain 35m 17s) Loss: 0.0000(0.0032) Grad: 46.2140  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 23s (remain 34m 15s) Loss: 0.0000(0.0032) Grad: 150.9559  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 21m 24s (remain 33m 14s) Loss: 0.0001(0.0032) Grad: 461.0655  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 22m 25s (remain 32m 12s) Loss: 0.0014(0.0031) Grad: 6384.7466  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 23m 26s (remain 31m 11s) Loss: 0.0005(0.0032) Grad: 2788.2068  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 24m 27s (remain 30m 9s) Loss: 0.0000(0.0032) Grad: 19.4822  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 25m 28s (remain 29m 9s) Loss: 0.0076(0.0032) Grad: 19785.3301  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 26m 30s (remain 28m 7s) Loss: 0.0000(0.0032) Grad: 64.4971  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 27m 30s (remain 27m 6s) Loss: 0.0000(0.0032) Grad: 175.0401  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 28m 32s (remain 26m 5s) Loss: 0.0000(0.0031) Grad: 7.3093  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 29m 32s (remain 25m 4s) Loss: 0.0000(0.0031) Grad: 128.0053  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 30m 34s (remain 24m 2s) Loss: 0.0000(0.0032) Grad: 16.7995  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 31m 35s (remain 23m 1s) Loss: 0.0006(0.0032) Grad: 2467.2837  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 32m 36s (remain 22m 0s) Loss: 0.0085(0.0031) Grad: 21066.2852  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 33m 37s (remain 20m 59s) Loss: 0.0080(0.0032) Grad: 23233.6309  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 34m 39s (remain 19m 58s) Loss: 0.0000(0.0032) Grad: 87.3792  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 35m 39s (remain 18m 57s) Loss: 0.0008(0.0031) Grad: 3498.9797  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 36m 40s (remain 17m 56s) Loss: 0.0000(0.0031) Grad: 181.4620  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 37m 41s (remain 16m 55s) Loss: 0.0024(0.0032) Grad: 8143.6470  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 38m 42s (remain 15m 53s) Loss: 0.0022(0.0032) Grad: 4867.2554  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 39m 44s (remain 14m 52s) Loss: 0.0359(0.0032) Grad: 30008.0684  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 40m 45s (remain 13m 51s) Loss: 0.0044(0.0032) Grad: 4583.7847  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 41m 45s (remain 12m 50s) Loss: 0.0003(0.0032) Grad: 1035.2208  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 42m 46s (remain 11m 49s) Loss: 0.0003(0.0032) Grad: 1701.6545  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 43m 47s (remain 10m 48s) Loss: 0.0018(0.0031) Grad: 5481.0913  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 44m 48s (remain 9m 47s) Loss: 0.0003(0.0031) Grad: 1762.4672  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 45m 49s (remain 8m 45s) Loss: 0.0000(0.0031) Grad: 194.7156  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 46m 50s (remain 7m 44s) Loss: 0.0000(0.0031) Grad: 8.1496  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 47m 51s (remain 6m 43s) Loss: 0.0111(0.0031) Grad: 39281.8516  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 48m 52s (remain 5m 42s) Loss: 0.0000(0.0031) Grad: 162.2749  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 49m 53s (remain 4m 41s) Loss: 0.0004(0.0031) Grad: 4130.2822  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 50m 54s (remain 3m 40s) Loss: 0.0113(0.0030) Grad: 23439.3613  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 51m 55s (remain 2m 39s) Loss: 0.0020(0.0030) Grad: 3950.0918  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 52m 56s (remain 1m 38s) Loss: 0.0012(0.0030) Grad: 10080.4424  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 53m 57s (remain 0m 37s) Loss: 0.0001(0.0030) Grad: 1436.9984  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 54m 35s (remain 0m 0s) Loss: 0.0001(0.0030) Grad: 1360.1497  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 18s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 27s) Loss: 0.0000(0.0038) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0063(0.0039) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0047(0.0036) \n","EVAL: [400/1788] Elapsed 0m 47s (remain 2m 45s) Loss: 0.0000(0.0036) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0241(0.0041) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0004(0.0041) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0039(0.0039) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0036) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0032(0.0038) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0021(0.0040) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 21s) Loss: 0.0000(0.0042) \n","EVAL: [1200/1788] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0000(0.0042) \n","EVAL: [1300/1788] Elapsed 2m 34s (remain 0m 57s) Loss: 0.0003(0.0042) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 46s) Loss: 0.0221(0.0042) \n","EVAL: [1500/1788] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0241(0.0041) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0000(0.0040) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0001(0.0039) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0001(0.0039) \n","Epoch 2 - avg_train_loss: 0.0030  avg_val_loss: 0.0039  time: 3493s\n","Epoch 2 - Score: 0.8800\n","Epoch 2 - Save Best Score: 0.8800 Model\n","Epoch: [3][0/5362] Elapsed 0m 1s (remain 97m 35s) Loss: 0.0009(0.0009) Grad: 7387.2358  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 5s (remain 56m 52s) Loss: 0.0014(0.0023) Grad: 3500.8667  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 6s (remain 54m 8s) Loss: 0.0000(0.0027) Grad: 77.4408  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 7s (remain 52m 34s) Loss: 0.0002(0.0027) Grad: 779.8665  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 8s (remain 51m 19s) Loss: 0.0006(0.0028) Grad: 1939.8777  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 9s (remain 50m 7s) Loss: 0.0000(0.0026) Grad: 10.5793  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 11s (remain 49m 2s) Loss: 0.0043(0.0027) Grad: 15218.7031  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 12s (remain 47m 56s) Loss: 0.0000(0.0026) Grad: 5.4633  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 13s (remain 46m 50s) Loss: 0.0000(0.0027) Grad: 318.2547  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 14s (remain 45m 45s) Loss: 0.0003(0.0027) Grad: 2458.5403  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 15s (remain 44m 41s) Loss: 0.0103(0.0028) Grad: 28770.1621  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 16s (remain 43m 38s) Loss: 0.0001(0.0027) Grad: 750.1944  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 17s (remain 42m 35s) Loss: 0.0000(0.0028) Grad: 20.7413  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 18s (remain 41m 32s) Loss: 0.0006(0.0028) Grad: 1915.7208  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 19s (remain 40m 29s) Loss: 0.0010(0.0028) Grad: 3280.1851  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 20s (remain 39m 29s) Loss: 0.0001(0.0027) Grad: 262.9349  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 22s (remain 38m 27s) Loss: 0.0043(0.0028) Grad: 11482.6768  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 17m 23s (remain 37m 24s) Loss: 0.0007(0.0027) Grad: 2809.9478  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 18m 23s (remain 36m 22s) Loss: 0.0000(0.0027) Grad: 7.0048  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 19m 25s (remain 35m 21s) Loss: 0.0001(0.0027) Grad: 465.3369  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 20m 26s (remain 34m 19s) Loss: 0.0000(0.0028) Grad: 243.5365  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 21m 27s (remain 33m 17s) Loss: 0.0073(0.0027) Grad: 12944.0303  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 22m 28s (remain 32m 16s) Loss: 0.0000(0.0027) Grad: 10.8852  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 23m 29s (remain 31m 14s) Loss: 0.0162(0.0027) Grad: 39131.3477  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 24m 30s (remain 30m 13s) Loss: 0.0000(0.0027) Grad: 35.3006  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 25m 31s (remain 29m 11s) Loss: 0.0011(0.0027) Grad: 6878.8818  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 26m 32s (remain 28m 10s) Loss: 0.0004(0.0027) Grad: 2317.1006  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 27m 33s (remain 27m 8s) Loss: 0.0007(0.0027) Grad: 4324.1182  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 28m 34s (remain 26m 7s) Loss: 0.0093(0.0027) Grad: 30359.1875  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 29m 35s (remain 25m 6s) Loss: 0.0000(0.0027) Grad: 232.1010  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 30m 36s (remain 24m 4s) Loss: 0.0023(0.0027) Grad: 25910.2109  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 31m 37s (remain 23m 3s) Loss: 0.0039(0.0026) Grad: 7808.8140  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 32m 38s (remain 22m 1s) Loss: 0.0000(0.0026) Grad: 14.2564  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 33m 39s (remain 21m 0s) Loss: 0.0018(0.0026) Grad: 12508.3125  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 34m 40s (remain 19m 59s) Loss: 0.0054(0.0026) Grad: 73078.8906  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 35m 41s (remain 18m 58s) Loss: 0.0005(0.0027) Grad: 2338.8608  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 36m 42s (remain 17m 56s) Loss: 0.0002(0.0027) Grad: 1841.5531  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 37m 42s (remain 16m 55s) Loss: 0.0029(0.0027) Grad: 7000.6333  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 38m 43s (remain 15m 54s) Loss: 0.0005(0.0027) Grad: 2479.8623  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 39m 44s (remain 14m 53s) Loss: 0.0089(0.0027) Grad: 28025.3242  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 40m 46s (remain 13m 52s) Loss: 0.0000(0.0027) Grad: 2.9480  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 41m 46s (remain 12m 50s) Loss: 0.0011(0.0027) Grad: 5765.9170  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 42m 47s (remain 11m 49s) Loss: 0.0000(0.0027) Grad: 17.3641  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 43m 49s (remain 10m 48s) Loss: 0.0079(0.0027) Grad: 11705.8330  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 44m 50s (remain 9m 47s) Loss: 0.0000(0.0027) Grad: 67.0884  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 45m 51s (remain 8m 46s) Loss: 0.0000(0.0026) Grad: 4.0388  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 46m 52s (remain 7m 45s) Loss: 0.0000(0.0026) Grad: 138.7380  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 47m 53s (remain 6m 44s) Loss: 0.0040(0.0026) Grad: 18290.1973  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 48m 54s (remain 5m 42s) Loss: 0.0000(0.0027) Grad: 15.0385  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 49m 55s (remain 4m 41s) Loss: 0.0000(0.0027) Grad: 7.7016  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 50m 56s (remain 3m 40s) Loss: 0.0151(0.0027) Grad: 63934.8047  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 51m 57s (remain 2m 39s) Loss: 0.0000(0.0027) Grad: 8.5709  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 52m 58s (remain 1m 38s) Loss: 0.0016(0.0027) Grad: 8047.6514  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 53m 59s (remain 0m 37s) Loss: 0.0021(0.0027) Grad: 9596.7285  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 54m 36s (remain 0m 0s) Loss: 0.0020(0.0027) Grad: 3387.2798  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 46s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 27s) Loss: 0.0000(0.0037) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0071(0.0040) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0025(0.0038) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0000(0.0037) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0255(0.0040) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0007(0.0040) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0019(0.0040) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0037) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0039(0.0038) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0016(0.0040) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0042) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0000(0.0042) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0008(0.0042) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0278(0.0042) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0326(0.0041) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0039) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0004(0.0039) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0001(0.0038) \n","Epoch 3 - avg_train_loss: 0.0027  avg_val_loss: 0.0038  time: 3496s\n","Epoch 3 - Score: 0.8864\n","Epoch 3 - Save Best Score: 0.8864 Model\n","Epoch: [4][0/5362] Elapsed 0m 1s (remain 93m 31s) Loss: 0.0117(0.0117) Grad: 15014.5850  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 6s (remain 57m 35s) Loss: 0.0000(0.0013) Grad: 107.4056  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 7s (remain 54m 33s) Loss: 0.0000(0.0016) Grad: 15.0948  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 8s (remain 52m 51s) Loss: 0.0019(0.0022) Grad: 5757.1812  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 9s (remain 51m 27s) Loss: 0.0000(0.0020) Grad: 15.2922  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 10s (remain 50m 14s) Loss: 0.0046(0.0020) Grad: 18913.9707  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 11s (remain 49m 6s) Loss: 0.0031(0.0021) Grad: 9224.5498  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 12s (remain 47m 59s) Loss: 0.0038(0.0021) Grad: 16567.2578  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 14s (remain 46m 54s) Loss: 0.0009(0.0022) Grad: 3920.5999  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 15s (remain 45m 50s) Loss: 0.0000(0.0022) Grad: 28.6190  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 16s (remain 44m 46s) Loss: 0.0050(0.0023) Grad: 29371.6484  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 17s (remain 43m 42s) Loss: 0.0000(0.0022) Grad: 36.2635  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 18s (remain 42m 39s) Loss: 0.0000(0.0022) Grad: 4.6381  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 19s (remain 41m 36s) Loss: 0.0001(0.0022) Grad: 1265.8602  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 20s (remain 40m 34s) Loss: 0.0026(0.0022) Grad: 7452.0757  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 22s (remain 39m 31s) Loss: 0.0000(0.0023) Grad: 58.1711  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 23s (remain 38m 29s) Loss: 0.0000(0.0023) Grad: 7.6385  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 24s (remain 37m 27s) Loss: 0.0000(0.0023) Grad: 155.5524  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 25s (remain 36m 26s) Loss: 0.0000(0.0022) Grad: 3.8572  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 26s (remain 35m 24s) Loss: 0.0105(0.0022) Grad: 14359.5654  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 27s (remain 34m 22s) Loss: 0.0000(0.0022) Grad: 771.3343  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 21m 29s (remain 33m 20s) Loss: 0.0000(0.0022) Grad: 3.0240  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 22m 30s (remain 32m 19s) Loss: 0.0002(0.0022) Grad: 1322.3677  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 23m 31s (remain 31m 17s) Loss: 0.0037(0.0022) Grad: 14763.7939  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 24m 32s (remain 30m 16s) Loss: 0.0000(0.0022) Grad: 61.1123  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 25m 33s (remain 29m 14s) Loss: 0.0000(0.0022) Grad: 3.9766  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 26m 34s (remain 28m 13s) Loss: 0.0019(0.0022) Grad: 5576.6646  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 27m 35s (remain 27m 11s) Loss: 0.0001(0.0022) Grad: 498.3896  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 28m 36s (remain 26m 9s) Loss: 0.0007(0.0022) Grad: 7892.2163  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 29m 38s (remain 25m 8s) Loss: 0.0042(0.0022) Grad: 15923.7275  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 30m 39s (remain 24m 6s) Loss: 0.0000(0.0022) Grad: 3.8473  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 31m 40s (remain 23m 5s) Loss: 0.0000(0.0022) Grad: 26.4353  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 32m 41s (remain 22m 4s) Loss: 0.0029(0.0023) Grad: 4822.5791  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 33m 42s (remain 21m 2s) Loss: 0.0255(0.0023) Grad: 55053.2617  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 34m 43s (remain 20m 1s) Loss: 0.0000(0.0023) Grad: 6.1379  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 35m 44s (remain 18m 59s) Loss: 0.0000(0.0023) Grad: 4.7577  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 36m 45s (remain 17m 58s) Loss: 0.0003(0.0023) Grad: 2136.2986  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 37m 46s (remain 16m 57s) Loss: 0.0114(0.0023) Grad: 51284.2969  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 38m 47s (remain 15m 55s) Loss: 0.0000(0.0023) Grad: 3.8024  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 39m 48s (remain 14m 54s) Loss: 0.0119(0.0023) Grad: 18643.6602  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 40m 49s (remain 13m 53s) Loss: 0.0047(0.0023) Grad: 5580.5034  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 41m 50s (remain 12m 51s) Loss: 0.0001(0.0023) Grad: 771.2542  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 42m 51s (remain 11m 50s) Loss: 0.0006(0.0023) Grad: 3611.6333  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 43m 52s (remain 10m 49s) Loss: 0.0036(0.0023) Grad: 11723.1846  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 44m 53s (remain 9m 48s) Loss: 0.0023(0.0023) Grad: 6465.0405  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 45m 54s (remain 8m 46s) Loss: 0.0005(0.0023) Grad: 2499.6401  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 46m 55s (remain 7m 45s) Loss: 0.0000(0.0023) Grad: 138.1855  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 47m 56s (remain 6m 44s) Loss: 0.0000(0.0023) Grad: 80.7976  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 48m 57s (remain 5m 43s) Loss: 0.0000(0.0024) Grad: 19.6259  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 49m 58s (remain 4m 42s) Loss: 0.0015(0.0024) Grad: 5649.5386  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 50m 59s (remain 3m 40s) Loss: 0.0066(0.0024) Grad: 16006.0449  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 52m 0s (remain 2m 39s) Loss: 0.0000(0.0023) Grad: 186.1844  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 53m 1s (remain 1m 38s) Loss: 0.0000(0.0023) Grad: 558.4775  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 54m 2s (remain 0m 37s) Loss: 0.0017(0.0023) Grad: 6792.7754  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 54m 39s (remain 0m 0s) Loss: 0.0001(0.0023) Grad: 1073.9008  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 18s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0000(0.0040) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0083(0.0044) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0021(0.0041) \n","EVAL: [400/1788] Elapsed 0m 47s (remain 2m 46s) Loss: 0.0000(0.0040) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0294(0.0043) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0004(0.0043) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0030(0.0042) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 58s) Loss: 0.0000(0.0039) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0082(0.0040) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0011(0.0042) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0044) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0000(0.0045) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0001(0.0044) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0263(0.0044) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0355(0.0043) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0041) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0005(0.0040) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0000(0.0040) \n","Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0040  time: 3498s\n","Epoch 4 - Score: 0.8903\n","Epoch 4 - Save Best Score: 0.8903 Model\n","Epoch: [5][0/5362] Elapsed 0m 1s (remain 90m 38s) Loss: 0.0000(0.0000) Grad: 1237.3900  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 6s (remain 57m 21s) Loss: 0.0061(0.0019) Grad: 66874.6875  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 7s (remain 54m 24s) Loss: 0.0107(0.0024) Grad: 13544.5342  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 8s (remain 52m 42s) Loss: 0.0001(0.0026) Grad: 529.3630  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 9s (remain 51m 24s) Loss: 0.0048(0.0024) Grad: 44548.5391  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 10s (remain 50m 13s) Loss: 0.0000(0.0023) Grad: 76.9424  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 11s (remain 49m 4s) Loss: 0.0000(0.0021) Grad: 54.3818  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 12s (remain 47m 56s) Loss: 0.0002(0.0021) Grad: 2570.6365  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 13s (remain 46m 51s) Loss: 0.0000(0.0020) Grad: 1.0455  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 14s (remain 45m 47s) Loss: 0.0000(0.0019) Grad: 19.2626  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 16s (remain 44m 44s) Loss: 0.0000(0.0018) Grad: 61.8921  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 17s (remain 43m 42s) Loss: 0.0001(0.0018) Grad: 2927.9036  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 18s (remain 42m 39s) Loss: 0.0001(0.0018) Grad: 329.0879  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 19s (remain 41m 36s) Loss: 0.0009(0.0017) Grad: 2763.1506  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 21s (remain 40m 35s) Loss: 0.0034(0.0018) Grad: 9923.4414  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 22s (remain 39m 33s) Loss: 0.0000(0.0018) Grad: 2.3101  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 23s (remain 38m 30s) Loss: 0.0000(0.0018) Grad: 1.9152  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 24s (remain 37m 28s) Loss: 0.0000(0.0019) Grad: 11.6009  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 26s (remain 36m 26s) Loss: 0.0000(0.0019) Grad: 7.8302  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 27s (remain 35m 24s) Loss: 0.0009(0.0019) Grad: 10250.8301  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 28s (remain 34m 22s) Loss: 0.0000(0.0019) Grad: 6.8345  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 29s (remain 33m 20s) Loss: 0.0000(0.0019) Grad: 1.1583  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 30s (remain 32m 19s) Loss: 0.0022(0.0019) Grad: 7777.6890  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 31s (remain 31m 17s) Loss: 0.0019(0.0019) Grad: 18486.5781  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 32s (remain 30m 16s) Loss: 0.0032(0.0019) Grad: 9146.2168  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 33s (remain 29m 14s) Loss: 0.0000(0.0019) Grad: 28.4332  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 35s (remain 28m 13s) Loss: 0.0000(0.0019) Grad: 9.7903  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 27m 36s (remain 27m 11s) Loss: 0.0000(0.0019) Grad: 396.8370  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 28m 37s (remain 26m 10s) Loss: 0.0000(0.0019) Grad: 9.7710  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 29m 38s (remain 25m 8s) Loss: 0.0000(0.0019) Grad: 7.9239  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 30m 39s (remain 24m 7s) Loss: 0.0002(0.0019) Grad: 5444.1748  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 31m 40s (remain 23m 5s) Loss: 0.0000(0.0019) Grad: 3.1451  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 32m 41s (remain 22m 4s) Loss: 0.0211(0.0019) Grad: 34915.9648  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 33m 42s (remain 21m 2s) Loss: 0.0000(0.0019) Grad: 4.1430  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 34m 44s (remain 20m 1s) Loss: 0.0010(0.0019) Grad: 11678.8359  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 35m 45s (remain 19m 0s) Loss: 0.0000(0.0019) Grad: 9.2004  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 36m 46s (remain 17m 58s) Loss: 0.0000(0.0019) Grad: 49.8765  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 37m 47s (remain 16m 57s) Loss: 0.0282(0.0019) Grad: 53807.2656  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 38m 48s (remain 15m 56s) Loss: 0.0000(0.0019) Grad: 27.8526  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 39m 49s (remain 14m 54s) Loss: 0.0001(0.0019) Grad: 463.6534  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 40m 50s (remain 13m 53s) Loss: 0.0000(0.0019) Grad: 20.5948  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 41m 51s (remain 12m 52s) Loss: 0.0000(0.0019) Grad: 16.5832  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 42m 52s (remain 11m 51s) Loss: 0.0000(0.0019) Grad: 54.5703  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 43m 54s (remain 10m 49s) Loss: 0.0000(0.0019) Grad: 80.3785  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 44m 55s (remain 9m 48s) Loss: 0.0001(0.0019) Grad: 1187.3677  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 45m 56s (remain 8m 47s) Loss: 0.0010(0.0019) Grad: 15960.6855  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 46m 57s (remain 7m 46s) Loss: 0.0052(0.0019) Grad: 5823.6992  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 47m 58s (remain 6m 44s) Loss: 0.0000(0.0019) Grad: 117.7325  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 49m 0s (remain 5m 43s) Loss: 0.0000(0.0019) Grad: 25.2158  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 50m 0s (remain 4m 42s) Loss: 0.0011(0.0019) Grad: 3471.8862  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 51m 2s (remain 3m 41s) Loss: 0.0000(0.0020) Grad: 3.4897  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 52m 3s (remain 2m 39s) Loss: 0.0000(0.0020) Grad: 5.3916  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 53m 3s (remain 1m 38s) Loss: 0.0000(0.0020) Grad: 2.5377  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 54m 4s (remain 0m 37s) Loss: 0.0008(0.0020) Grad: 7095.7144  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 54m 41s (remain 0m 0s) Loss: 0.0000(0.0020) Grad: 125.3832  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 35s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0000(0.0045) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0073(0.0048) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0027(0.0045) \n","EVAL: [400/1788] Elapsed 0m 47s (remain 2m 46s) Loss: 0.0000(0.0043) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0304(0.0047) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0004(0.0047) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0045(0.0046) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0043) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0054(0.0044) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0010(0.0046) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 21s) Loss: 0.0000(0.0049) \n","EVAL: [1200/1788] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0000(0.0049) \n","EVAL: [1300/1788] Elapsed 2m 34s (remain 0m 57s) Loss: 0.0002(0.0049) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 46s) Loss: 0.0327(0.0048) \n","EVAL: [1500/1788] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0433(0.0047) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0000(0.0045) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0003(0.0044) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0000(0.0044) \n","Epoch 5 - avg_train_loss: 0.0020  avg_val_loss: 0.0044  time: 3500s\n","Epoch 5 - Score: 0.8900\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 94m 48s) Loss: 0.1720(0.1720) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 1s (remain 53m 48s) Loss: 0.3105(0.2676) Grad: 45995.2383  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 2s (remain 52m 36s) Loss: 0.2110(0.2445) Grad: 38734.9453  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 3s (remain 51m 33s) Loss: 0.0997(0.2111) Grad: 11645.8086  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 4s (remain 50m 30s) Loss: 0.0616(0.1737) Grad: 8102.0132  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 5s (remain 49m 28s) Loss: 0.0314(0.1437) Grad: 792.9434  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 6s (remain 48m 26s) Loss: 0.0131(0.1231) Grad: 333.0724  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 7s (remain 47m 25s) Loss: 0.0349(0.1087) Grad: 1008.7404  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 9s (remain 46m 25s) Loss: 0.0098(0.0976) Grad: 464.5700  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 10s (remain 45m 23s) Loss: 0.0344(0.0887) Grad: 1060.6915  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 11s (remain 44m 23s) Loss: 0.0012(0.0812) Grad: 253.2288  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 12s (remain 43m 21s) Loss: 0.0043(0.0748) Grad: 1116.2885  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 13s (remain 42m 20s) Loss: 0.0022(0.0694) Grad: 613.1270  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 14s (remain 41m 20s) Loss: 0.0403(0.0647) Grad: 2177.3992  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 15s (remain 40m 19s) Loss: 0.0036(0.0606) Grad: 744.5353  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 16s (remain 39m 18s) Loss: 0.0029(0.0570) Grad: 334.0226  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 17s (remain 38m 17s) Loss: 0.0071(0.0539) Grad: 683.9620  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 18s (remain 37m 16s) Loss: 0.0254(0.0512) Grad: 2643.1653  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 20s (remain 36m 15s) Loss: 0.0023(0.0487) Grad: 452.5241  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 21s (remain 35m 14s) Loss: 0.0154(0.0465) Grad: 1201.8298  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 22s (remain 34m 13s) Loss: 0.0028(0.0445) Grad: 920.7815  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 23s (remain 33m 12s) Loss: 0.0040(0.0426) Grad: 740.0340  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 24s (remain 32m 10s) Loss: 0.0001(0.0408) Grad: 29.3329  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 23m 25s (remain 31m 9s) Loss: 0.0137(0.0393) Grad: 1647.2120  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 24m 27s (remain 30m 9s) Loss: 0.0026(0.0379) Grad: 846.7902  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 25m 27s (remain 29m 7s) Loss: 0.0006(0.0366) Grad: 113.9285  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 26m 28s (remain 28m 6s) Loss: 0.0360(0.0354) Grad: 7222.7236  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 27m 29s (remain 27m 5s) Loss: 0.0001(0.0343) Grad: 45.2499  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 28m 30s (remain 26m 4s) Loss: 0.0035(0.0333) Grad: 661.8609  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 29m 31s (remain 25m 3s) Loss: 0.0039(0.0323) Grad: 408.1543  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 30m 32s (remain 24m 1s) Loss: 0.0008(0.0314) Grad: 97.3879  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 31m 33s (remain 23m 0s) Loss: 0.0000(0.0305) Grad: 23.3919  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 32m 34s (remain 21m 59s) Loss: 0.0027(0.0297) Grad: 214.2960  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 33m 35s (remain 20m 58s) Loss: 0.0064(0.0289) Grad: 962.4463  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 34m 36s (remain 19m 57s) Loss: 0.0004(0.0282) Grad: 78.6108  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 35m 37s (remain 18m 56s) Loss: 0.0007(0.0275) Grad: 443.7230  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 36m 38s (remain 17m 55s) Loss: 0.0062(0.0268) Grad: 499.7033  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 37m 39s (remain 16m 54s) Loss: 0.0011(0.0262) Grad: 171.1485  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 38m 40s (remain 15m 53s) Loss: 0.0040(0.0256) Grad: 338.0973  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 39m 41s (remain 14m 52s) Loss: 0.0001(0.0251) Grad: 29.9123  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 40m 42s (remain 13m 50s) Loss: 0.0011(0.0246) Grad: 251.3178  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 41m 43s (remain 12m 49s) Loss: 0.0172(0.0241) Grad: 1858.1552  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 42m 44s (remain 11m 48s) Loss: 0.0008(0.0236) Grad: 140.4315  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 43m 45s (remain 10m 47s) Loss: 0.0046(0.0231) Grad: 2218.5017  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 44m 46s (remain 9m 46s) Loss: 0.0002(0.0227) Grad: 48.1207  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 45m 47s (remain 8m 45s) Loss: 0.0021(0.0223) Grad: 337.6502  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 46m 48s (remain 7m 44s) Loss: 0.0001(0.0219) Grad: 26.6048  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 47m 49s (remain 6m 43s) Loss: 0.0012(0.0215) Grad: 179.6244  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 48m 50s (remain 5m 42s) Loss: 0.0002(0.0212) Grad: 33.3002  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 49m 51s (remain 4m 41s) Loss: 0.0005(0.0208) Grad: 99.3184  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 50m 52s (remain 3m 40s) Loss: 0.0000(0.0205) Grad: 13.2196  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 51m 53s (remain 2m 39s) Loss: 0.0135(0.0201) Grad: 1525.9952  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 52m 54s (remain 1m 38s) Loss: 0.0009(0.0198) Grad: 121.2076  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 53m 54s (remain 0m 37s) Loss: 0.0072(0.0195) Grad: 299.9666  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 54m 32s (remain 0m 0s) Loss: 0.0066(0.0193) Grad: 902.0309  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 23m 9s) Loss: 0.0008(0.0008) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 30s) Loss: 0.0009(0.0026) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0002(0.0028) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0064(0.0029) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0001(0.0031) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0001(0.0032) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0000(0.0031) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 10s) Loss: 0.0011(0.0029) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0037(0.0028) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0003(0.0032) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0067(0.0038) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 21s) Loss: 0.0017(0.0040) \n","EVAL: [1200/1788] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0063(0.0041) \n","EVAL: [1300/1788] Elapsed 2m 34s (remain 0m 57s) Loss: 0.0004(0.0041) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 46s) Loss: 0.0035(0.0040) \n","EVAL: [1500/1788] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0004(0.0040) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0013(0.0039) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0009(0.0038) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0002(0.0037) \n","Epoch 1 - avg_train_loss: 0.0193  avg_val_loss: 0.0037  time: 3490s\n","Epoch 1 - Score: 0.8500\n","Epoch 1 - Save Best Score: 0.8500 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 102m 17s) Loss: 0.0059(0.0059) Grad: 8696.9570  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 6s (remain 57m 33s) Loss: 0.0000(0.0031) Grad: 277.1638  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 7s (remain 54m 32s) Loss: 0.0196(0.0045) Grad: 68867.7344  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 8s (remain 52m 49s) Loss: 0.0101(0.0036) Grad: 20785.7051  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 9s (remain 51m 26s) Loss: 0.0094(0.0039) Grad: 20395.4297  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 10s (remain 50m 15s) Loss: 0.0000(0.0038) Grad: 122.4526  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 12s (remain 49m 8s) Loss: 0.0000(0.0038) Grad: 32.5009  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 13s (remain 48m 1s) Loss: 0.0000(0.0039) Grad: 16.1049  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 14s (remain 46m 56s) Loss: 0.0000(0.0038) Grad: 12.1799  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 15s (remain 45m 52s) Loss: 0.0000(0.0036) Grad: 41.3413  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 16s (remain 44m 47s) Loss: 0.0001(0.0034) Grad: 213.5358  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 18s (remain 43m 44s) Loss: 0.0001(0.0035) Grad: 705.9940  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 19s (remain 42m 41s) Loss: 0.0001(0.0034) Grad: 371.1511  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 20s (remain 41m 38s) Loss: 0.0001(0.0034) Grad: 365.6914  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 21s (remain 40m 35s) Loss: 0.0006(0.0034) Grad: 1611.1801  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 22s (remain 39m 33s) Loss: 0.0000(0.0034) Grad: 72.7118  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 24s (remain 38m 31s) Loss: 0.0001(0.0035) Grad: 225.8834  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 25s (remain 37m 29s) Loss: 0.0006(0.0035) Grad: 867.0399  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 26s (remain 36m 27s) Loss: 0.0032(0.0034) Grad: 2132.4148  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 27s (remain 35m 26s) Loss: 0.0068(0.0034) Grad: 7635.9170  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 29s (remain 34m 24s) Loss: 0.0172(0.0034) Grad: 18725.6895  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 21m 30s (remain 33m 22s) Loss: 0.0002(0.0034) Grad: 1315.2875  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 22m 31s (remain 32m 20s) Loss: 0.0081(0.0034) Grad: 17036.1133  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 23m 32s (remain 31m 19s) Loss: 0.0015(0.0034) Grad: 3979.5588  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 24m 33s (remain 30m 17s) Loss: 0.0000(0.0034) Grad: 79.8216  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 25m 34s (remain 29m 15s) Loss: 0.0000(0.0033) Grad: 7.7095  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 26m 36s (remain 28m 14s) Loss: 0.0004(0.0033) Grad: 1545.6736  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 27m 37s (remain 27m 12s) Loss: 0.0004(0.0033) Grad: 1022.9380  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 28m 38s (remain 26m 11s) Loss: 0.0128(0.0033) Grad: 9487.3232  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 29m 39s (remain 25m 9s) Loss: 0.0011(0.0033) Grad: 1574.1112  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 30m 40s (remain 24m 8s) Loss: 0.0003(0.0033) Grad: 645.9935  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 31m 41s (remain 23m 6s) Loss: 0.0008(0.0033) Grad: 1830.6533  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 32m 43s (remain 22m 5s) Loss: 0.0031(0.0033) Grad: 5815.8887  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 33m 44s (remain 21m 3s) Loss: 0.0000(0.0033) Grad: 4.1142  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 34m 45s (remain 20m 2s) Loss: 0.0031(0.0033) Grad: 3455.1775  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 35m 46s (remain 19m 1s) Loss: 0.0045(0.0033) Grad: 5800.4209  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 36m 48s (remain 17m 59s) Loss: 0.0001(0.0033) Grad: 304.2285  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 37m 49s (remain 16m 58s) Loss: 0.0000(0.0033) Grad: 20.0349  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 38m 50s (remain 15m 57s) Loss: 0.0001(0.0033) Grad: 269.7229  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 39m 51s (remain 14m 55s) Loss: 0.0016(0.0033) Grad: 4107.1406  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 40m 52s (remain 13m 54s) Loss: 0.0056(0.0033) Grad: 8013.2344  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 41m 53s (remain 12m 52s) Loss: 0.0003(0.0033) Grad: 648.9606  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 42m 55s (remain 11m 51s) Loss: 0.0117(0.0033) Grad: 11018.4541  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 43m 56s (remain 10m 50s) Loss: 0.0049(0.0033) Grad: 5719.5479  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 44m 57s (remain 9m 49s) Loss: 0.0010(0.0033) Grad: 3809.5769  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 45m 58s (remain 8m 47s) Loss: 0.0131(0.0033) Grad: 8246.4971  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 46m 59s (remain 7m 46s) Loss: 0.0002(0.0033) Grad: 348.7658  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 48m 1s (remain 6m 45s) Loss: 0.0000(0.0033) Grad: 89.0180  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 49m 2s (remain 5m 43s) Loss: 0.0011(0.0033) Grad: 1220.5756  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 50m 3s (remain 4m 42s) Loss: 0.0006(0.0033) Grad: 1788.6711  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 51m 4s (remain 3m 41s) Loss: 0.0000(0.0033) Grad: 57.3625  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 52m 5s (remain 2m 39s) Loss: 0.0084(0.0032) Grad: 11706.1895  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 53m 6s (remain 1m 38s) Loss: 0.0000(0.0033) Grad: 95.8988  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 54m 7s (remain 0m 37s) Loss: 0.0001(0.0032) Grad: 98.2222  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 54m 44s (remain 0m 0s) Loss: 0.0038(0.0032) Grad: 3856.6682  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 38s) Loss: 0.0012(0.0012) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0116(0.0034) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0003(0.0031) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0059(0.0030) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0000(0.0031) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0000(0.0032) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0000(0.0032) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0009(0.0032) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 58s) Loss: 0.0046(0.0031) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 46s) Loss: 0.0002(0.0033) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0021(0.0035) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0006(0.0038) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0085(0.0039) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0002(0.0038) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0020(0.0038) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0037) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0015(0.0037) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0009(0.0036) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0000(0.0036) \n","Epoch 2 - avg_train_loss: 0.0032  avg_val_loss: 0.0036  time: 3503s\n","Epoch 2 - Score: 0.8780\n","Epoch 2 - Save Best Score: 0.8780 Model\n","Epoch: [3][0/5362] Elapsed 0m 1s (remain 94m 7s) Loss: 0.0000(0.0000) Grad: 999.2670  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 6s (remain 57m 22s) Loss: 0.0005(0.0027) Grad: 2624.3445  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 7s (remain 54m 25s) Loss: 0.0002(0.0023) Grad: 611.8074  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 8s (remain 52m 45s) Loss: 0.0001(0.0024) Grad: 773.6932  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 9s (remain 51m 23s) Loss: 0.0000(0.0027) Grad: 129.8926  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 10s (remain 50m 12s) Loss: 0.0075(0.0030) Grad: 26742.9844  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 11s (remain 49m 3s) Loss: 0.0002(0.0029) Grad: 1750.6650  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 12s (remain 47m 54s) Loss: 0.0000(0.0027) Grad: 39.9335  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 13s (remain 46m 51s) Loss: 0.0003(0.0026) Grad: 1661.0289  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 14s (remain 45m 46s) Loss: 0.0001(0.0026) Grad: 321.4925  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 15s (remain 44m 42s) Loss: 0.0013(0.0027) Grad: 5743.9297  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 16s (remain 43m 39s) Loss: 0.0000(0.0026) Grad: 209.1029  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 17s (remain 42m 36s) Loss: 0.0000(0.0025) Grad: 24.6867  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 19s (remain 41m 34s) Loss: 0.0000(0.0026) Grad: 65.8990  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 20s (remain 40m 32s) Loss: 0.0000(0.0025) Grad: 40.7414  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 21s (remain 39m 30s) Loss: 0.0000(0.0025) Grad: 7.8128  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 22s (remain 38m 28s) Loss: 0.0000(0.0025) Grad: 3.6268  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 17m 23s (remain 37m 26s) Loss: 0.0000(0.0025) Grad: 178.1447  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 18m 24s (remain 36m 24s) Loss: 0.0000(0.0026) Grad: 11.2273  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 19m 25s (remain 35m 22s) Loss: 0.0078(0.0025) Grad: 13555.6729  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 20m 26s (remain 34m 20s) Loss: 0.0083(0.0025) Grad: 30689.0156  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 21m 28s (remain 33m 19s) Loss: 0.0004(0.0025) Grad: 1930.1161  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 22m 29s (remain 32m 17s) Loss: 0.0008(0.0026) Grad: 3707.8215  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 23m 30s (remain 31m 15s) Loss: 0.0000(0.0026) Grad: 20.6538  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 24m 31s (remain 30m 14s) Loss: 0.0079(0.0027) Grad: 11645.1455  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 25m 31s (remain 29m 12s) Loss: 0.0000(0.0027) Grad: 9.0381  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 26m 33s (remain 28m 11s) Loss: 0.0000(0.0027) Grad: 430.7351  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 27m 34s (remain 27m 9s) Loss: 0.0000(0.0026) Grad: 76.5149  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 28m 35s (remain 26m 8s) Loss: 0.0025(0.0026) Grad: 5248.6475  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 29m 36s (remain 25m 6s) Loss: 0.0031(0.0026) Grad: 13409.6475  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 30m 37s (remain 24m 5s) Loss: 0.0000(0.0026) Grad: 39.8171  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 31m 38s (remain 23m 4s) Loss: 0.0000(0.0026) Grad: 27.8487  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 32m 39s (remain 22m 2s) Loss: 0.0004(0.0026) Grad: 5263.1221  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 33m 40s (remain 21m 1s) Loss: 0.0009(0.0026) Grad: 4289.0244  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 34m 41s (remain 20m 0s) Loss: 0.0038(0.0026) Grad: 13629.4941  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 35m 42s (remain 18m 59s) Loss: 0.0000(0.0026) Grad: 56.1557  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 36m 44s (remain 17m 57s) Loss: 0.0002(0.0026) Grad: 785.4637  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 37m 45s (remain 16m 56s) Loss: 0.0012(0.0025) Grad: 2787.8096  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 38m 46s (remain 15m 55s) Loss: 0.0098(0.0025) Grad: 27839.2969  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 39m 47s (remain 14m 54s) Loss: 0.0000(0.0025) Grad: 616.5612  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 40m 48s (remain 13m 52s) Loss: 0.0000(0.0025) Grad: 3.6838  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 41m 49s (remain 12m 51s) Loss: 0.0002(0.0025) Grad: 2038.5879  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 42m 50s (remain 11m 50s) Loss: 0.0002(0.0026) Grad: 2438.7844  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 43m 51s (remain 10m 49s) Loss: 0.0000(0.0026) Grad: 212.0324  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 44m 52s (remain 9m 47s) Loss: 0.0000(0.0026) Grad: 4.1789  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 45m 53s (remain 8m 46s) Loss: 0.0011(0.0026) Grad: 6291.4316  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 46m 54s (remain 7m 45s) Loss: 0.0199(0.0026) Grad: 35030.1562  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 47m 55s (remain 6m 44s) Loss: 0.0000(0.0026) Grad: 46.8923  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 48m 56s (remain 5m 43s) Loss: 0.0000(0.0026) Grad: 85.2801  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 49m 57s (remain 4m 41s) Loss: 0.0000(0.0026) Grad: 44.8547  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 50m 58s (remain 3m 40s) Loss: 0.0004(0.0026) Grad: 9640.7402  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 51m 59s (remain 2m 39s) Loss: 0.0001(0.0026) Grad: 398.1685  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 53m 0s (remain 1m 38s) Loss: 0.0000(0.0026) Grad: 59.6717  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 54m 1s (remain 0m 37s) Loss: 0.0000(0.0026) Grad: 13.6898  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 54m 38s (remain 0m 0s) Loss: 0.0616(0.0026) Grad: 76852.4609  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 35s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 24s) Loss: 0.0130(0.0040) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0002(0.0038) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0028(0.0035) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0001(0.0036) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0001(0.0039) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 22s) Loss: 0.0000(0.0038) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 10s) Loss: 0.0002(0.0038) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0050(0.0037) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0001(0.0038) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0054(0.0041) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 21s) Loss: 0.0007(0.0043) \n","EVAL: [1200/1788] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0121(0.0044) \n","EVAL: [1300/1788] Elapsed 2m 34s (remain 0m 57s) Loss: 0.0000(0.0044) \n","EVAL: [1400/1788] Elapsed 2m 46s (remain 0m 46s) Loss: 0.0013(0.0043) \n","EVAL: [1500/1788] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0000(0.0043) \n","EVAL: [1600/1788] Elapsed 3m 10s (remain 0m 22s) Loss: 0.0037(0.0043) \n","EVAL: [1700/1788] Elapsed 3m 22s (remain 0m 10s) Loss: 0.0005(0.0043) \n","EVAL: [1787/1788] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0000(0.0042) \n","Epoch 3 - avg_train_loss: 0.0026  avg_val_loss: 0.0042  time: 3497s\n","Epoch 3 - Score: 0.8799\n","Epoch 3 - Save Best Score: 0.8799 Model\n","Epoch: [4][0/5362] Elapsed 0m 1s (remain 95m 45s) Loss: 0.0000(0.0000) Grad: 998.5010  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 5s (remain 57m 16s) Loss: 0.0379(0.0018) Grad: 143000.1875  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 7s (remain 54m 23s) Loss: 0.0000(0.0025) Grad: 50.9114  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 8s (remain 52m 45s) Loss: 0.0000(0.0022) Grad: 170.2651  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 9s (remain 51m 22s) Loss: 0.0024(0.0026) Grad: 6483.6411  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 10s (remain 50m 13s) Loss: 0.0002(0.0023) Grad: 735.7273  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 11s (remain 49m 6s) Loss: 0.0065(0.0023) Grad: 16916.2832  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 13s (remain 48m 2s) Loss: 0.0000(0.0024) Grad: 300.0023  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 14s (remain 46m 58s) Loss: 0.0007(0.0023) Grad: 11554.6631  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 16s (remain 45m 53s) Loss: 0.0000(0.0022) Grad: 10.4151  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 17s (remain 44m 49s) Loss: 0.0000(0.0023) Grad: 4.2968  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 18s (remain 43m 46s) Loss: 0.0041(0.0024) Grad: 4523.6353  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 19s (remain 42m 43s) Loss: 0.0002(0.0024) Grad: 1464.6573  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 21s (remain 41m 40s) Loss: 0.0002(0.0023) Grad: 907.0090  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 22s (remain 40m 37s) Loss: 0.0027(0.0024) Grad: 10423.2002  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 23s (remain 39m 34s) Loss: 0.0003(0.0024) Grad: 2831.2354  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 24s (remain 38m 32s) Loss: 0.0000(0.0024) Grad: 250.3462  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 25s (remain 37m 29s) Loss: 0.0000(0.0023) Grad: 20.3901  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 26s (remain 36m 27s) Loss: 0.0002(0.0023) Grad: 966.4698  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 27s (remain 35m 25s) Loss: 0.0040(0.0023) Grad: 25374.5898  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 29s (remain 34m 25s) Loss: 0.0000(0.0023) Grad: 16.0649  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 21m 32s (remain 33m 25s) Loss: 0.0000(0.0023) Grad: 127.3915  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 22m 34s (remain 32m 24s) Loss: 0.0000(0.0023) Grad: 11.4428  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 23m 36s (remain 31m 24s) Loss: 0.0095(0.0024) Grad: 13192.3447  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 24m 38s (remain 30m 23s) Loss: 0.0027(0.0023) Grad: 17342.5820  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 25m 40s (remain 29m 22s) Loss: 0.0000(0.0023) Grad: 6.0648  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 26m 43s (remain 28m 21s) Loss: 0.0000(0.0023) Grad: 3.4943  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 27m 45s (remain 27m 20s) Loss: 0.0000(0.0023) Grad: 15.4984  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 28m 47s (remain 26m 19s) Loss: 0.0000(0.0023) Grad: 27.7276  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 29m 49s (remain 25m 18s) Loss: 0.0032(0.0023) Grad: 14270.5781  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 30m 51s (remain 24m 16s) Loss: 0.0004(0.0023) Grad: 3843.7017  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 31m 53s (remain 23m 15s) Loss: 0.0001(0.0023) Grad: 501.1086  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 32m 55s (remain 22m 13s) Loss: 0.0000(0.0023) Grad: 8.7730  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 33m 57s (remain 21m 12s) Loss: 0.0000(0.0023) Grad: 26.6786  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 34m 59s (remain 20m 10s) Loss: 0.0001(0.0022) Grad: 541.7734  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 36m 2s (remain 19m 9s) Loss: 0.0001(0.0022) Grad: 399.7342  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 37m 4s (remain 18m 7s) Loss: 0.0002(0.0022) Grad: 2604.0005  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 38m 6s (remain 17m 6s) Loss: 0.0000(0.0022) Grad: 6.0245  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 39m 8s (remain 16m 4s) Loss: 0.0012(0.0023) Grad: 30375.1797  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 40m 10s (remain 15m 2s) Loss: 0.0000(0.0023) Grad: 8.5528  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 41m 13s (remain 14m 1s) Loss: 0.0000(0.0023) Grad: 7.2989  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 42m 15s (remain 12m 59s) Loss: 0.0000(0.0023) Grad: 365.7959  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 43m 17s (remain 11m 57s) Loss: 0.0014(0.0023) Grad: 7976.1206  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 44m 19s (remain 10m 56s) Loss: 0.0001(0.0023) Grad: 646.9929  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 45m 21s (remain 9m 54s) Loss: 0.0000(0.0023) Grad: 31.8692  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 46m 23s (remain 8m 52s) Loss: 0.0001(0.0023) Grad: 481.2638  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 47m 25s (remain 7m 50s) Loss: 0.0000(0.0023) Grad: 6.2894  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 48m 27s (remain 6m 48s) Loss: 0.0000(0.0023) Grad: 18.1585  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 49m 29s (remain 5m 47s) Loss: 0.0000(0.0023) Grad: 77.1506  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 50m 31s (remain 4m 45s) Loss: 0.0000(0.0023) Grad: 88.4657  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 51m 33s (remain 3m 43s) Loss: 0.0000(0.0023) Grad: 9.8741  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 52m 35s (remain 2m 41s) Loss: 0.0031(0.0023) Grad: 5231.4541  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 53m 37s (remain 1m 39s) Loss: 0.0043(0.0023) Grad: 6767.6592  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 54m 39s (remain 0m 37s) Loss: 0.0002(0.0023) Grad: 3861.6565  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 55m 17s (remain 0m 0s) Loss: 0.0131(0.0023) Grad: 32042.5371  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 40s) Loss: 0.0002(0.0002) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 28s) Loss: 0.0074(0.0037) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0004(0.0036) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0097(0.0034) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 47s) Loss: 0.0000(0.0036) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0038) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0000(0.0037) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0001(0.0037) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0029(0.0035) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0000(0.0038) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0110(0.0042) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0005(0.0044) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0131(0.0045) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0000(0.0045) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0023(0.0045) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0044) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0017(0.0044) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0009(0.0044) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0000(0.0043) \n","Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0043  time: 3536s\n","Epoch 4 - Score: 0.8857\n","Epoch 4 - Save Best Score: 0.8857 Model\n","Epoch: [5][0/5362] Elapsed 0m 1s (remain 91m 1s) Loss: 0.0000(0.0000) Grad: 995.6760  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 7s (remain 58m 36s) Loss: 0.0000(0.0016) Grad: 270.6426  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 9s (remain 55m 24s) Loss: 0.0000(0.0021) Grad: 4.9718  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 11s (remain 53m 39s) Loss: 0.0014(0.0022) Grad: 7600.1963  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 13s (remain 52m 15s) Loss: 0.0000(0.0019) Grad: 59.2993  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 15s (remain 51m 1s) Loss: 0.0000(0.0020) Grad: 24.8855  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 17s (remain 49m 53s) Loss: 0.0000(0.0019) Grad: 13.6138  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 19s (remain 48m 45s) Loss: 0.0002(0.0018) Grad: 787.8100  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 22s (remain 47m 40s) Loss: 0.0000(0.0019) Grad: 13.3076  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 25s (remain 46m 37s) Loss: 0.0000(0.0018) Grad: 64.0055  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 27s (remain 45m 35s) Loss: 0.0000(0.0018) Grad: 7.0073  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 29s (remain 44m 29s) Loss: 0.0013(0.0017) Grad: 5779.0156  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 32s (remain 43m 25s) Loss: 0.0000(0.0019) Grad: 100.0800  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 34s (remain 42m 23s) Loss: 0.0000(0.0020) Grad: 2.2764  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 37s (remain 41m 21s) Loss: 0.0000(0.0021) Grad: 30.2588  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 39s (remain 40m 17s) Loss: 0.0000(0.0021) Grad: 3.0791  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 42s (remain 39m 14s) Loss: 0.0019(0.0021) Grad: 3678.0964  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 44s (remain 38m 11s) Loss: 0.0000(0.0021) Grad: 3.8663  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 45s (remain 37m 6s) Loss: 0.0034(0.0021) Grad: 11075.8154  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 47s (remain 36m 1s) Loss: 0.0000(0.0021) Grad: 19.1358  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 48s (remain 34m 57s) Loss: 0.0000(0.0021) Grad: 267.2109  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 49s (remain 33m 53s) Loss: 0.0000(0.0020) Grad: 174.0739  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 51s (remain 32m 49s) Loss: 0.0000(0.0020) Grad: 93.0585  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 52s (remain 31m 45s) Loss: 0.0000(0.0020) Grad: 308.4353  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 54s (remain 30m 43s) Loss: 0.0000(0.0020) Grad: 1.3687  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 57s (remain 29m 41s) Loss: 0.0000(0.0020) Grad: 6.1082  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 59s (remain 28m 38s) Loss: 0.0029(0.0020) Grad: 12234.1270  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 28m 1s (remain 27m 36s) Loss: 0.0040(0.0019) Grad: 22818.3184  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 29m 3s (remain 26m 33s) Loss: 0.0004(0.0019) Grad: 4013.9673  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 30m 5s (remain 25m 31s) Loss: 0.0003(0.0020) Grad: 2549.9302  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 31m 6s (remain 24m 28s) Loss: 0.0000(0.0020) Grad: 5.6231  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 32m 8s (remain 23m 26s) Loss: 0.0000(0.0020) Grad: 1.9793  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 33m 11s (remain 22m 24s) Loss: 0.0000(0.0020) Grad: 187.8613  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 34m 13s (remain 21m 22s) Loss: 0.0047(0.0020) Grad: 12545.2686  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 35m 15s (remain 20m 20s) Loss: 0.0000(0.0020) Grad: 4.8812  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 36m 18s (remain 19m 17s) Loss: 0.0000(0.0020) Grad: 250.4504  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 37m 20s (remain 18m 15s) Loss: 0.0011(0.0020) Grad: 7352.4683  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 38m 23s (remain 17m 13s) Loss: 0.0000(0.0020) Grad: 219.5570  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 39m 25s (remain 16m 11s) Loss: 0.0000(0.0020) Grad: 199.0897  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 40m 28s (remain 15m 9s) Loss: 0.0010(0.0020) Grad: 8168.6509  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 41m 30s (remain 14m 7s) Loss: 0.0000(0.0020) Grad: 138.3029  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 42m 32s (remain 13m 4s) Loss: 0.0000(0.0020) Grad: 78.8529  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 43m 35s (remain 12m 2s) Loss: 0.0042(0.0019) Grad: 22946.2656  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 44m 37s (remain 11m 0s) Loss: 0.0004(0.0019) Grad: 5257.1875  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 45m 40s (remain 9m 58s) Loss: 0.0000(0.0020) Grad: 2.5405  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 46m 42s (remain 8m 56s) Loss: 0.0000(0.0020) Grad: 9.8615  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 47m 45s (remain 7m 53s) Loss: 0.0027(0.0020) Grad: 12816.4609  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 48m 47s (remain 6m 51s) Loss: 0.0000(0.0020) Grad: 1.9845  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 49m 50s (remain 5m 49s) Loss: 0.0006(0.0019) Grad: 4425.1021  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 50m 52s (remain 4m 47s) Loss: 0.0000(0.0019) Grad: 27.6351  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 51m 55s (remain 3m 44s) Loss: 0.0000(0.0019) Grad: 25.7033  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 52m 57s (remain 2m 42s) Loss: 0.0000(0.0019) Grad: 19.0896  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 54m 0s (remain 1m 40s) Loss: 0.0000(0.0020) Grad: 45.8289  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 55m 2s (remain 0m 38s) Loss: 0.0000(0.0020) Grad: 14.7921  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 55m 41s (remain 0m 0s) Loss: 0.0000(0.0020) Grad: 30.3132  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 24s) Loss: 0.0002(0.0002) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 29s) Loss: 0.0016(0.0039) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 13s) Loss: 0.0001(0.0038) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 0s) Loss: 0.0029(0.0035) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 47s) Loss: 0.0000(0.0037) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0040) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0000(0.0040) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0000(0.0040) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0052(0.0038) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0000(0.0040) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0092(0.0043) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0011(0.0046) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0141(0.0047) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0000(0.0047) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0033(0.0046) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0000(0.0046) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0010(0.0046) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0007(0.0045) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0000(0.0045) \n","Epoch 5 - avg_train_loss: 0.0020  avg_val_loss: 0.0045  time: 3561s\n","Epoch 5 - Score: 0.8860\n","Epoch 5 - Save Best Score: 0.8860 Model\n","Best thres: 0.5, Score: 0.8844\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-30-0f687401855c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best thres: 0.5, Score: {score:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mbest_thres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best thres: {best_thres}, Score: {score:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2b9726cbc1dd>\u001b[0m in \u001b[0;36mget_best_thres\u001b[0;34m(oof_df)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mbest_thres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Nelder-Mead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_thres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2b9726cbc1dd>\u001b[0m in \u001b[0;36mf1_opt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_best_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf1_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mbest_thres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Nelder-Mead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2b9726cbc1dd>\u001b[0m in \u001b[0;36mscoring\u001b[0;34m(df, th)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtoken_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mchar_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_char_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pn_history\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mpredicted_location_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predicted_location_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_location_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2b9726cbc1dd>\u001b[0m in \u001b[0;36mget_char_probs\u001b[0;34m(texts, token_probs, tokenizer)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mreturn_offsets_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         )\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moffset_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offset_mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2479\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2482\u001b[0m             )\n\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m             \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m         )\n\u001b[1;32m   2535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m         \u001b[0;31m# Test if we have a padding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2337\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mPaddingStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDO_NOT_PAD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2338\u001b[0m             raise ValueError(\n\u001b[1;32m   2339\u001b[0m                 \u001b[0;34m\"Asking to pad but the tokenizer does not have a padding token. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad_token_id\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using pad_token, but it is not set yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp052.ipynb","provenance":[{"file_id":"17d5VktGiKlzZFZ4DX0Xh1M3Yr83oZpnY","timestamp":1647654875373}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6a615c2e2f1843f3b51283e2bfcada8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ea63ebbfdc24e6b88417ccac25cb7d1","IPY_MODEL_d76adf0a9c054f8cad8b986e9d78ea97","IPY_MODEL_17d3db9626a64c38b8770c431d67aa1d"],"layout":"IPY_MODEL_3eaa1793fdf34f06b280fc6c411d1c6b"}},"3ea63ebbfdc24e6b88417ccac25cb7d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fc1df1cc6fb40c89e86dda946a1a6fa","placeholder":"​","style":"IPY_MODEL_ff9783e20a904010ac244a59d490b473","value":"100%"}},"d76adf0a9c054f8cad8b986e9d78ea97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bdd8d49d59f4e7ea6d2a91d14f3d5fe","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9736800471d742f4885c4a9f2ee8ef1d","value":42146}},"17d3db9626a64c38b8770c431d67aa1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a102765c4f0440aae5a131b58c98922","placeholder":"​","style":"IPY_MODEL_38ddb5c2a4874bb28390f59ce9032d44","value":" 42146/42146 [00:37&lt;00:00, 1947.37it/s]"}},"3eaa1793fdf34f06b280fc6c411d1c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fc1df1cc6fb40c89e86dda946a1a6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff9783e20a904010ac244a59d490b473":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bdd8d49d59f4e7ea6d2a91d14f3d5fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9736800471d742f4885c4a9f2ee8ef1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a102765c4f0440aae5a131b58c98922":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38ddb5c2a4874bb28390f59ce9032d44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22e0095c30334cd78b44f92f93bb9cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a726661b55ee453585c3ab4070c5bfb4","IPY_MODEL_7689a308f52144b89ce85bf887457255","IPY_MODEL_313878de873e41e0b67e91545fdda913"],"layout":"IPY_MODEL_51327e49428a48789973aecb6b8b8970"}},"a726661b55ee453585c3ab4070c5bfb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfec3dca89d448b58ca46e5e0f6b52d2","placeholder":"​","style":"IPY_MODEL_8a4eb3e7b261445b87025b13ee2a68e5","value":"100%"}},"7689a308f52144b89ce85bf887457255":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b8ec6bf22f84ec2881389eb40e0bdf8","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_036856b948374f90b1975ebed920dc63","value":143}},"313878de873e41e0b67e91545fdda913":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f1639b3a81047f09c905b5b3a07bc53","placeholder":"​","style":"IPY_MODEL_80d88c56ce15482c81fe700e024447d9","value":" 143/143 [00:00&lt;00:00, 2170.41it/s]"}},"51327e49428a48789973aecb6b8b8970":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfec3dca89d448b58ca46e5e0f6b52d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a4eb3e7b261445b87025b13ee2a68e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b8ec6bf22f84ec2881389eb40e0bdf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"036856b948374f90b1975ebed920dc63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f1639b3a81047f09c905b5b3a07bc53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80d88c56ce15482c81fe700e024447d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}