{"cells":[{"cell_type":"markdown","id":"blind-kingdom","metadata":{"id":"blind-kingdom"},"source":["## References"]},{"cell_type":"markdown","id":"antique-glenn","metadata":{"id":"antique-glenn"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"bored-ministry","metadata":{"id":"bored-ministry"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"deadly-confidence","metadata":{"id":"deadly-confidence","executionInfo":{"status":"ok","timestamp":1646874713761,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp037\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"aware-worcester","metadata":{"id":"aware-worcester","executionInfo":{"status":"ok","timestamp":1646874713762,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"funnel-transformer/large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=2\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=5\n","    train_fold=[0, 1, 2, 3, 4]\n","    seed=71\n","    gradient_accumulation_steps=4\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"personalized-death","metadata":{"id":"personalized-death","executionInfo":{"status":"ok","timestamp":1646874713762,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"cardiovascular-neutral","metadata":{"id":"cardiovascular-neutral"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"checked-boards","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32894,"status":"ok","timestamp":1646874746651,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"checked-boards","outputId":"de22793f-5f77-4065-d2c9-b33f9361cf85"},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Mounted at /content/drive\n","Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 75.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 77.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 82.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 3.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers\n","    !pip install sentencepiece\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","source":["# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n","# This must be done before importing transformers\n","import shutil\n","from pathlib import Path\n","\n","if CFG.env == \"colab\":\n","    input_dir = Path(\"./drive/MyDrive/00.kaggle/input/deberta-v2-3-fast-tokenizer\")\n","    transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","else:\n","    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n","    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)\n","    \n","    \n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"],"metadata":{"id":"iGai035Rvu1Z","executionInfo":{"status":"ok","timestamp":1646874753348,"user_tz":-540,"elapsed":6703,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"iGai035Rvu1Z","execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"id":"vital-mexico","metadata":{"id":"vital-mexico","executionInfo":{"status":"ok","timestamp":1646874755762,"user_tz":-540,"elapsed":2426,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"economic-ladder","metadata":{"id":"economic-ladder"},"source":["## Utilities"]},{"cell_type":"code","execution_count":7,"id":"desperate-keyboard","metadata":{"id":"desperate-keyboard","executionInfo":{"status":"ok","timestamp":1646874755762,"user_tz":-540,"elapsed":3,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":8,"id":"flexible-wednesday","metadata":{"id":"flexible-wednesday","executionInfo":{"status":"ok","timestamp":1646874756198,"user_tz":-540,"elapsed":438,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":9,"id":"logical-chemistry","metadata":{"id":"logical-chemistry","executionInfo":{"status":"ok","timestamp":1646874756198,"user_tz":-540,"elapsed":3,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":10,"id":"gorgeous-record","metadata":{"id":"gorgeous-record","executionInfo":{"status":"ok","timestamp":1646874756198,"user_tz":-540,"elapsed":3,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"frozen-africa","metadata":{"id":"frozen-africa"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":11,"id":"shaped-metallic","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2293,"status":"ok","timestamp":1646874758489,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"shaped-metallic","outputId":"c84eb18c-41d3-4f92-bb9f-b425776ed0d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":11}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":12,"id":"visible-australia","metadata":{"id":"visible-australia","executionInfo":{"status":"ok","timestamp":1646874758490,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"hydraulic-gibson","metadata":{"id":"hydraulic-gibson"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":13,"id":"interpreted-northeast","metadata":{"id":"interpreted-northeast","executionInfo":{"status":"ok","timestamp":1646874758490,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":14,"id":"martial-blind","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1646874758490,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"martial-blind","outputId":"6f664006-d6c3-4009-98ee-a6d112f85c67"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":14}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":15,"id":"electoral-favor","metadata":{"id":"electoral-favor","executionInfo":{"status":"ok","timestamp":1646874758900,"user_tz":-540,"elapsed":413,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":16,"id":"reported-parade","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1646874758900,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"reported-parade","outputId":"6792aeb9-1a08-4dce-c604-b9231ab2c7a7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"enabling-relevance","metadata":{"id":"enabling-relevance"},"source":["## CV split"]},{"cell_type":"code","execution_count":17,"id":"mature-coalition","metadata":{"id":"mature-coalition","executionInfo":{"status":"ok","timestamp":1646874758900,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def get_groupkfold(df, group_name):\n","    groups = df[group_name].unique()\n","\n","    kf = KFold(\n","        n_splits=CFG.n_fold,\n","        shuffle=True,\n","        random_state=CFG.seed,\n","    )\n","    folds_ids = []\n","    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n","        val_group = groups[val_group_idx]\n","        is_val = df[group_name].isin(val_group)\n","        val_idx = df[is_val].index\n","        df.loc[val_idx, \"fold\"] = int(i_fold)\n","\n","    df[\"fold\"] = df[\"fold\"].astype(int)\n","    return df"]},{"cell_type":"code","execution_count":18,"id":"every-minutes","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1646874758900,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"every-minutes","outputId":"06f637f8-6b3d-460d-8b8f-4c14de965bd8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    2902\n","1    2894\n","2    2813\n","3    2791\n","4    2900\n","dtype: int64"]},"metadata":{}}],"source":["train = get_groupkfold(train, \"pn_num\")\n","display(train.groupby(\"fold\").size())"]},{"cell_type":"markdown","id":"subjective-entrance","metadata":{"id":"subjective-entrance"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":19,"id":"dramatic-afghanistan","metadata":{"id":"dramatic-afghanistan","executionInfo":{"status":"ok","timestamp":1646874760614,"user_tz":-540,"elapsed":1717,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["612e4a1a771b4d659ef1b3db83054599","55fa8a639b4542398a797bc2f0f567bd","a744f1a3ba3b4fd1be1df10d85aa91e7","d70036f5fae341f988dec16ddbdf41e6","5a6129eda0c9449caa86b87fc391de28","67e9efb0715a44348398de8a895fdf84","048034f7c5544ed487124923e2dca3dc","67cac14aeaee41929173b49032ef44d0","ff875872fd2b4cefa62161c2f246dc7f","a78dedf799c94ff9a4b31b4fbf599a31","fd9d0a8afcef48fb887252de480124b3","966960f2a29040b1af06fc5ac38757a4","dd01876e868b458dbfab1bfd1d669a4c","c4ad8a36b54f465183ff56bc752fd283","f00e93809bd54046812ecf34f237b66e","6372dc68a39144208ecacc73c598a1ce","0311bed871884b899350ba23425e4419","dfed55aea32f40dba0351e518ab140ce","96ac95b2289742e5ae0661af77b8a748","844181c2a5234b77901c450b36f29f2d","156f58c7eb714ea4bf66c4f4f39b1a64","689c51fef3194bc5adb8977cfc3c97a2","fd003d350d5e4d63a2ab989f0764bb13","714316cb9edc442f8ced8f5a3f9bbafc","87afec360bdb4c119ab7b33e4b95351d","261110d2368f4bdf8424b2e8286d7ca5","12f929c7bc1d47d58ce1da731f99c191","cfcf5a299a694e7abb333746666f5fde","85f1373bead64d21a38554b1e743096c","86462e6ca7674c5c8bb38c0cf3d6c161","2bf588c1f7cf487da74808f76ba0dbeb","db48a2a8389c4f0c952d02f0a4e28731","8074f6121ea2472788bb4bba4c63f8d3","cebd962b7ef743359f54f204c73a8afd","54f47f8a40a74c59b1273d86f1a79b49","426927fcf0cf45ac8466890e46967760","02116b42bf8843dea5d9fa2ec294212c","b682a31509864d5184e2e579d8ed2c9a","c3a5bbca477b49869080aad9ed408bbc","0845273645fc4baaa3a3e343cfacca99","aea948e9a2c34c6f9dbfd00812e19927","8730f949a264402b887bdcf5f414310b","94a184c03d7a4fe6a6f13a7a4de66c42","1f03b6850e3c4ccf8afb4e9bc784a933","4df8e85e0e3648efa39a7d7de5df3b11","8f0a3c6f550849afbe89be5f7923fb81","95c006e1dbd745519311cc4eb8076116","a291b4a847af498e955942fc39c46ca3","aa776fc997c243ad87b62fac17ce6b14","c033a9e845e24d10977890b5805a6185","58d24c8da4b74ff6a426baebdad35f8b","5604abf7dbb343bca7d033da546667a9","50ffe8003e0943ccaa4bc972d407f925","0de44383c93b488a94b941ca205a3e0b","6be9318999534dccbb97498d1ac44873"]},"outputId":"46b6b60a-01a3-4d15-bc54-cba61fb6b6fa"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"612e4a1a771b4d659ef1b3db83054599","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/153 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"966960f2a29040b1af06fc5ac38757a4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/701 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd003d350d5e4d63a2ab989f0764bb13","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cebd962b7ef743359f54f204c73a8afd","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4df8e85e0e3648efa39a7d7de5df3b11","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/153 [00:00<?, ?B/s]"]},"metadata":{}}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\", trim_offsets=False)\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name, trim_offsets=False)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04e9A2qMm5oo","executionInfo":{"status":"ok","timestamp":1646874760615,"user_tz":-540,"elapsed":3,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"70adea7c-b82a-4d9e-d2ac-43c23256c120"},"id":"04e9A2qMm5oo","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["'', 0, 0\n","'dad', 0, 3\n","'with', 4, 8\n","'recent', 9, 15\n","'heart', 16, 21\n","'attack', 22, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}]},{"cell_type":"markdown","id":"divided-arrow","metadata":{"id":"divided-arrow"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":21,"id":"immune-campbell","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["aac52c65e6b247de875bedbdc0ff0d37","b3842fdce121446c9c49b49fd04a040a","06de9ab83d3b445fa301e5258ad1ac94","05a585e0b8e646c6b72f6317459885fb","14efb89eebe64495a4c4f954f4547e90","c4142255a970473bbabb6bb8e7440169","d1fa81fe427f496fb85fcae361d22f62","b2913f73357549a0b81c42bcad2ed2dd","47b3f6582e984ee9bc7fecd2e90a069f","e751cb60a7824bec870ebd566766e8a2","0ffeaa9612cd44899b83e7496ce90e57"]},"executionInfo":{"elapsed":21068,"status":"ok","timestamp":1646874781681,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"immune-campbell","outputId":"7d9168c0-50c5-407e-dcee-accb04b4b7db"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aac52c65e6b247de875bedbdc0ff0d37","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 312\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":22,"id":"northern-branch","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["6b29f655d6de492cb44df391c427bb62","76e9303c8c2a4794a8532f074ffe874d","0a5bbd27b2eb412f8ee963911d4aa83f","59e314ec165948f7a8f9bb3b816292ab","91720bb01f4a42a9ad2093ccd5332dff","106d1242a8dd45e1861f9578b3c4b195","4ff8116295644f8488652bf7251cf517","0ac942423e8a47f98817bbcd59427227","dedc59f3343e4d08893c533e744f95d0","b40dda0deb324379823c61ad8d2eabf4","f53bae23760b4c09bc1f0e5defcff03a"]},"executionInfo":{"elapsed":584,"status":"ok","timestamp":1646874782242,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"northern-branch","outputId":"e66d43c9-2733-4b9d-8ff9-0c9e0f27ebf4"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b29f655d6de492cb44df391c427bb62","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 29\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":23,"id":"oriental-jacksonville","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646874782242,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"oriental-jacksonville","outputId":"352ccf4a-39bc-4bdf-ff1a-313810d6db81"},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 344\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":24,"id":"flexible-trainer","metadata":{"id":"flexible-trainer","executionInfo":{"status":"ok","timestamp":1646874782243,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":25,"id":"stock-robertson","metadata":{"id":"stock-robertson","executionInfo":{"status":"ok","timestamp":1646874782243,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"chemical-lucas","metadata":{"id":"chemical-lucas"},"source":["## Model"]},{"cell_type":"code","execution_count":26,"id":"animated-array","metadata":{"id":"animated-array","executionInfo":{"status":"ok","timestamp":1646874782243,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            self.backbone = AutoModel.from_config(self.model_config)\n","\n","        \"\"\"\n","        itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","        #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n","        path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","        state_dict = torch.load(path)\n","        itpt.load_state_dict(state_dict)\n","        self.backbone = itpt.deberta\n","        print(f\"Load weight from {path}\")\n","        \"\"\"\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"thorough-bristol","metadata":{"id":"thorough-bristol"},"source":["## Training"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class FocalLoss(nn.Module):\n","    \"\"\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65938\n","    \"\"\"\n","    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.logits = logits\n","        self.reduce = reduce\n","\n","    def forward(self, inputs, targets):\n","        if self.logits:\n","            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n","        else:\n","            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n","        pt = torch.exp(-BCE_loss)\n","        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n","\n","        if self.reduce:\n","            return torch.mean(F_loss)\n","        else:\n","            return F_loss"],"metadata":{"id":"n8Z5UnO9cCxW","executionInfo":{"status":"ok","timestamp":1646874782243,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"n8Z5UnO9cCxW","execution_count":27,"outputs":[]},{"cell_type":"code","execution_count":28,"id":"talented-quantity","metadata":{"id":"talented-quantity","executionInfo":{"status":"ok","timestamp":1646874782243,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":29,"id":"figured-cooperative","metadata":{"id":"figured-cooperative","executionInfo":{"status":"ok","timestamp":1646874782243,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":30,"id":"played-pointer","metadata":{"id":"played-pointer","executionInfo":{"status":"ok","timestamp":1646874782244,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":31,"id":"brazilian-nigeria","metadata":{"id":"brazilian-nigeria","executionInfo":{"status":"ok","timestamp":1646874782244,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    #criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    criterion = FocalLoss(reduce=False)\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"bearing-switch","metadata":{"id":"bearing-switch"},"source":["## Main"]},{"cell_type":"code","execution_count":32,"id":"desperate-crime","metadata":{"id":"desperate-crime","executionInfo":{"status":"ok","timestamp":1646874782244,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"id":"graduate-vision","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5df6089f4aee431890a16861520172f7","cf61db0ffa8445209128443daba2503f","52133c1059504f52aa510cb78285b89d","7b1972f1a07a4b198047efc1bd1805e6","eff781c55a1447bcb8b32bfd952aa25e","4db5ea8868ce493cad995f08a3e889f1","23b2e991b32248c7a726f3453f311508","19c3c5c87e234104bd7110d8980136bc","c1817f6ff9d246a49d2c4128c9516fd7","5a1ca917a99e4c00b60797f5fd6de910","9381924d3d4d4bd0801db96217d30153"]},"id":"graduate-vision","outputId":"74fde912-8026-4f57-c347-7ed6dfb143ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5df6089f4aee431890a16861520172f7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n","Epoch: [1][0/5699] Elapsed 0m 0s (remain 71m 47s) Loss: 0.1119(0.1119) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/5699] Elapsed 0m 20s (remain 19m 9s) Loss: 0.0475(0.0825) Grad: 20027.5801  LR: 0.000001  \n","Epoch: [1][200/5699] Elapsed 0m 40s (remain 18m 32s) Loss: 0.0515(0.0721) Grad: 25155.6172  LR: 0.000001  \n","Epoch: [1][300/5699] Elapsed 1m 0s (remain 18m 5s) Loss: 0.0255(0.0587) Grad: 14366.6719  LR: 0.000002  \n","Epoch: [1][400/5699] Elapsed 1m 20s (remain 17m 41s) Loss: 0.0096(0.0466) Grad: 1601.1755  LR: 0.000003  \n","Epoch: [1][500/5699] Elapsed 1m 40s (remain 17m 20s) Loss: 0.0078(0.0385) Grad: 1372.2954  LR: 0.000004  \n","Epoch: [1][600/5699] Elapsed 2m 0s (remain 16m 59s) Loss: 0.0017(0.0331) Grad: 566.3190  LR: 0.000004  \n","Epoch: [1][700/5699] Elapsed 2m 20s (remain 16m 38s) Loss: 0.0024(0.0291) Grad: 856.7144  LR: 0.000005  \n","Epoch: [1][800/5699] Elapsed 2m 39s (remain 16m 17s) Loss: 0.0026(0.0260) Grad: 4087.1121  LR: 0.000006  \n","Epoch: [1][900/5699] Elapsed 2m 59s (remain 15m 57s) Loss: 0.0035(0.0236) Grad: 9316.2939  LR: 0.000006  \n","Epoch: [1][1000/5699] Elapsed 3m 19s (remain 15m 36s) Loss: 0.0018(0.0218) Grad: 617.6012  LR: 0.000007  \n","Epoch: [1][1100/5699] Elapsed 3m 39s (remain 15m 16s) Loss: 0.0021(0.0201) Grad: 2676.5037  LR: 0.000008  \n","Epoch: [1][1200/5699] Elapsed 3m 59s (remain 14m 56s) Loss: 0.0007(0.0187) Grad: 965.1860  LR: 0.000008  \n","Epoch: [1][1300/5699] Elapsed 4m 19s (remain 14m 36s) Loss: 0.0006(0.0175) Grad: 560.5313  LR: 0.000009  \n","Epoch: [1][1400/5699] Elapsed 4m 39s (remain 14m 16s) Loss: 0.0014(0.0164) Grad: 4874.9150  LR: 0.000010  \n","Epoch: [1][1500/5699] Elapsed 4m 59s (remain 13m 57s) Loss: 0.0007(0.0155) Grad: 2460.9656  LR: 0.000011  \n","Epoch: [1][1600/5699] Elapsed 5m 19s (remain 13m 37s) Loss: 0.0008(0.0147) Grad: 685.1900  LR: 0.000011  \n","Epoch: [1][1700/5699] Elapsed 5m 39s (remain 13m 17s) Loss: 0.0018(0.0140) Grad: 909.5322  LR: 0.000012  \n","Epoch: [1][1800/5699] Elapsed 5m 59s (remain 12m 57s) Loss: 0.0081(0.0134) Grad: 1622.9064  LR: 0.000013  \n","Epoch: [1][1900/5699] Elapsed 6m 18s (remain 12m 36s) Loss: 0.0019(0.0129) Grad: 473.0954  LR: 0.000013  \n","Epoch: [1][2000/5699] Elapsed 6m 38s (remain 12m 17s) Loss: 0.0003(0.0124) Grad: 1045.7174  LR: 0.000014  \n","Epoch: [1][2100/5699] Elapsed 6m 58s (remain 11m 57s) Loss: 0.0017(0.0119) Grad: 1262.6335  LR: 0.000015  \n","Epoch: [1][2200/5699] Elapsed 7m 18s (remain 11m 37s) Loss: 0.0052(0.0115) Grad: 2275.4810  LR: 0.000015  \n","Epoch: [1][2300/5699] Elapsed 7m 38s (remain 11m 17s) Loss: 0.0019(0.0111) Grad: 2115.1150  LR: 0.000016  \n","Epoch: [1][2400/5699] Elapsed 7m 58s (remain 10m 57s) Loss: 0.0070(0.0107) Grad: 1940.0759  LR: 0.000017  \n","Epoch: [1][2500/5699] Elapsed 8m 18s (remain 10m 37s) Loss: 0.0025(0.0104) Grad: 1086.9183  LR: 0.000018  \n","Epoch: [1][2600/5699] Elapsed 8m 38s (remain 10m 17s) Loss: 0.0007(0.0101) Grad: 448.3653  LR: 0.000018  \n","Epoch: [1][2700/5699] Elapsed 8m 58s (remain 9m 57s) Loss: 0.0001(0.0098) Grad: 95.2192  LR: 0.000019  \n","Epoch: [1][2800/5699] Elapsed 9m 18s (remain 9m 37s) Loss: 0.0004(0.0095) Grad: 349.6366  LR: 0.000020  \n","Epoch: [1][2900/5699] Elapsed 9m 38s (remain 9m 17s) Loss: 0.0014(0.0093) Grad: 889.1895  LR: 0.000020  \n","Epoch: [1][3000/5699] Elapsed 9m 58s (remain 8m 57s) Loss: 0.0060(0.0090) Grad: 3212.8677  LR: 0.000020  \n","Epoch: [1][3100/5699] Elapsed 10m 18s (remain 8m 37s) Loss: 0.0004(0.0088) Grad: 301.4196  LR: 0.000020  \n","Epoch: [1][3200/5699] Elapsed 10m 38s (remain 8m 17s) Loss: 0.0004(0.0086) Grad: 189.3085  LR: 0.000020  \n","Epoch: [1][3300/5699] Elapsed 10m 58s (remain 7m 58s) Loss: 0.0006(0.0084) Grad: 422.0559  LR: 0.000020  \n","Epoch: [1][3400/5699] Elapsed 11m 18s (remain 7m 38s) Loss: 0.0015(0.0082) Grad: 1117.2511  LR: 0.000020  \n","Epoch: [1][3500/5699] Elapsed 11m 37s (remain 7m 18s) Loss: 0.0013(0.0080) Grad: 1042.6199  LR: 0.000019  \n","Epoch: [1][3600/5699] Elapsed 11m 57s (remain 6m 58s) Loss: 0.0008(0.0079) Grad: 466.9484  LR: 0.000019  \n","Epoch: [1][3700/5699] Elapsed 12m 17s (remain 6m 38s) Loss: 0.0009(0.0077) Grad: 533.4629  LR: 0.000019  \n","Epoch: [1][3800/5699] Elapsed 12m 37s (remain 6m 18s) Loss: 0.0046(0.0075) Grad: 2283.9424  LR: 0.000019  \n","Epoch: [1][3900/5699] Elapsed 12m 57s (remain 5m 58s) Loss: 0.0001(0.0074) Grad: 103.3590  LR: 0.000019  \n","Epoch: [1][4000/5699] Elapsed 13m 17s (remain 5m 38s) Loss: 0.0004(0.0072) Grad: 234.5414  LR: 0.000019  \n","Epoch: [1][4100/5699] Elapsed 13m 37s (remain 5m 18s) Loss: 0.0013(0.0071) Grad: 737.5724  LR: 0.000019  \n","Epoch: [1][4200/5699] Elapsed 13m 57s (remain 4m 58s) Loss: 0.0036(0.0070) Grad: 3330.0991  LR: 0.000019  \n","Epoch: [1][4300/5699] Elapsed 14m 17s (remain 4m 38s) Loss: 0.0016(0.0069) Grad: 2458.9500  LR: 0.000019  \n","Epoch: [1][4400/5699] Elapsed 14m 37s (remain 4m 18s) Loss: 0.0021(0.0068) Grad: 1555.7089  LR: 0.000019  \n","Epoch: [1][4500/5699] Elapsed 14m 57s (remain 3m 58s) Loss: 0.0002(0.0066) Grad: 217.2110  LR: 0.000019  \n","Epoch: [1][4600/5699] Elapsed 15m 17s (remain 3m 38s) Loss: 0.0080(0.0065) Grad: 2902.4346  LR: 0.000019  \n","Epoch: [1][4700/5699] Elapsed 15m 37s (remain 3m 18s) Loss: 0.0004(0.0064) Grad: 216.4023  LR: 0.000019  \n","Epoch: [1][4800/5699] Elapsed 15m 57s (remain 2m 59s) Loss: 0.0033(0.0063) Grad: 3620.7332  LR: 0.000018  \n","Epoch: [1][4900/5699] Elapsed 16m 17s (remain 2m 39s) Loss: 0.0022(0.0062) Grad: 748.5084  LR: 0.000018  \n","Epoch: [1][5000/5699] Elapsed 16m 37s (remain 2m 19s) Loss: 0.0183(0.0061) Grad: 18574.6660  LR: 0.000018  \n","Epoch: [1][5100/5699] Elapsed 16m 57s (remain 1m 59s) Loss: 0.0188(0.0060) Grad: 4736.9478  LR: 0.000018  \n","Epoch: [1][5200/5699] Elapsed 17m 17s (remain 1m 39s) Loss: 0.0016(0.0059) Grad: 882.8925  LR: 0.000018  \n","Epoch: [1][5300/5699] Elapsed 17m 37s (remain 1m 19s) Loss: 0.0006(0.0059) Grad: 319.7013  LR: 0.000018  \n","Epoch: [1][5400/5699] Elapsed 17m 57s (remain 0m 59s) Loss: 0.0047(0.0058) Grad: 2918.4199  LR: 0.000018  \n","Epoch: [1][5500/5699] Elapsed 18m 17s (remain 0m 39s) Loss: 0.0001(0.0057) Grad: 50.5059  LR: 0.000018  \n","Epoch: [1][5600/5699] Elapsed 18m 37s (remain 0m 19s) Loss: 0.0002(0.0056) Grad: 127.1664  LR: 0.000018  \n","Epoch: [1][5698/5699] Elapsed 18m 57s (remain 0m 0s) Loss: 0.0000(0.0056) Grad: 210.0658  LR: 0.000018  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 8m 33s) Loss: 0.0002(0.0002) \n","EVAL: [100/1451] Elapsed 0m 7s (remain 1m 41s) Loss: 0.0152(0.0011) \n","EVAL: [200/1451] Elapsed 0m 14s (remain 1m 31s) Loss: 0.0006(0.0010) \n","EVAL: [300/1451] Elapsed 0m 21s (remain 1m 23s) Loss: 0.0001(0.0012) \n","EVAL: [400/1451] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0027(0.0013) \n","EVAL: [500/1451] Elapsed 0m 36s (remain 1m 8s) Loss: 0.0001(0.0013) \n","EVAL: [600/1451] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0001(0.0012) \n","EVAL: [700/1451] Elapsed 0m 50s (remain 0m 54s) Loss: 0.0262(0.0014) \n","EVAL: [800/1451] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0015(0.0015) \n","EVAL: [900/1451] Elapsed 1m 4s (remain 0m 39s) Loss: 0.0003(0.0015) \n","EVAL: [1000/1451] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0043(0.0015) \n","EVAL: [1100/1451] Elapsed 1m 19s (remain 0m 25s) Loss: 0.0041(0.0015) \n","EVAL: [1200/1451] Elapsed 1m 26s (remain 0m 18s) Loss: 0.0016(0.0014) \n","EVAL: [1300/1451] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0006(0.0014) \n","EVAL: [1400/1451] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0005(0.0014) \n","EVAL: [1450/1451] Elapsed 1m 44s (remain 0m 0s) Loss: 0.0001(0.0014) \n","Epoch 1 - avg_train_loss: 0.0056  avg_val_loss: 0.0014  time: 1245s\n","Epoch 1 - Score: 0.7008\n","Epoch 1 - Save Best Score: 0.7008 Model\n","Epoch: [2][0/5699] Elapsed 0m 0s (remain 46m 42s) Loss: 0.0002(0.0002) Grad: 491.7846  LR: 0.000018  \n","Epoch: [2][100/5699] Elapsed 0m 20s (remain 19m 21s) Loss: 0.0001(0.0011) Grad: 456.1357  LR: 0.000018  \n","Epoch: [2][200/5699] Elapsed 0m 41s (remain 18m 45s) Loss: 0.0000(0.0015) Grad: 123.8364  LR: 0.000018  \n","Epoch: [2][300/5699] Elapsed 1m 1s (remain 18m 18s) Loss: 0.0189(0.0018) Grad: 37925.8711  LR: 0.000018  \n","Epoch: [2][400/5699] Elapsed 1m 21s (remain 17m 53s) Loss: 0.0006(0.0017) Grad: 961.9033  LR: 0.000017  \n","Epoch: [2][500/5699] Elapsed 1m 41s (remain 17m 31s) Loss: 0.0001(0.0017) Grad: 384.9077  LR: 0.000017  \n","Epoch: [2][600/5699] Elapsed 2m 1s (remain 17m 9s) Loss: 0.0000(0.0016) Grad: 164.9646  LR: 0.000017  \n","Epoch: [2][700/5699] Elapsed 2m 21s (remain 16m 48s) Loss: 0.0021(0.0017) Grad: 32123.8398  LR: 0.000017  \n","Epoch: [2][800/5699] Elapsed 2m 41s (remain 16m 26s) Loss: 0.0014(0.0016) Grad: 4940.6201  LR: 0.000017  \n","Epoch: [2][900/5699] Elapsed 3m 1s (remain 16m 6s) Loss: 0.0053(0.0016) Grad: 27508.7891  LR: 0.000017  \n","Epoch: [2][1000/5699] Elapsed 3m 21s (remain 15m 46s) Loss: 0.0002(0.0016) Grad: 1055.8295  LR: 0.000017  \n","Epoch: [2][1100/5699] Elapsed 3m 41s (remain 15m 26s) Loss: 0.0002(0.0015) Grad: 565.5919  LR: 0.000017  \n","Epoch: [2][1200/5699] Elapsed 4m 1s (remain 15m 5s) Loss: 0.0026(0.0015) Grad: 14100.4307  LR: 0.000017  \n","Epoch: [2][1300/5699] Elapsed 4m 21s (remain 14m 45s) Loss: 0.0009(0.0014) Grad: 4857.5239  LR: 0.000017  \n","Epoch: [2][1400/5699] Elapsed 4m 42s (remain 14m 25s) Loss: 0.0000(0.0014) Grad: 8.6035  LR: 0.000017  \n","Epoch: [2][1500/5699] Elapsed 5m 2s (remain 14m 4s) Loss: 0.0004(0.0014) Grad: 1022.7153  LR: 0.000017  \n","Epoch: [2][1600/5699] Elapsed 5m 22s (remain 13m 44s) Loss: 0.0000(0.0014) Grad: 62.2096  LR: 0.000017  \n","Epoch: [2][1700/5699] Elapsed 5m 42s (remain 13m 23s) Loss: 0.0002(0.0013) Grad: 543.2790  LR: 0.000016  \n","Epoch: [2][1800/5699] Elapsed 6m 2s (remain 13m 3s) Loss: 0.0003(0.0013) Grad: 2579.0659  LR: 0.000016  \n","Epoch: [2][1900/5699] Elapsed 6m 22s (remain 12m 43s) Loss: 0.0002(0.0013) Grad: 963.5654  LR: 0.000016  \n","Epoch: [2][2000/5699] Elapsed 6m 42s (remain 12m 23s) Loss: 0.0000(0.0013) Grad: 119.2324  LR: 0.000016  \n","Epoch: [2][2100/5699] Elapsed 7m 2s (remain 12m 3s) Loss: 0.0016(0.0013) Grad: 6586.7104  LR: 0.000016  \n","Epoch: [2][2200/5699] Elapsed 7m 22s (remain 11m 43s) Loss: 0.0075(0.0014) Grad: 17479.6172  LR: 0.000016  \n","Epoch: [2][2300/5699] Elapsed 7m 42s (remain 11m 22s) Loss: 0.0002(0.0013) Grad: 1078.8015  LR: 0.000016  \n","Epoch: [2][2400/5699] Elapsed 8m 2s (remain 11m 2s) Loss: 0.0018(0.0013) Grad: 7966.8755  LR: 0.000016  \n","Epoch: [2][2500/5699] Elapsed 8m 22s (remain 10m 42s) Loss: 0.0031(0.0013) Grad: 6986.3657  LR: 0.000016  \n","Epoch: [2][2600/5699] Elapsed 8m 42s (remain 10m 22s) Loss: 0.0001(0.0013) Grad: 1936.8242  LR: 0.000016  \n","Epoch: [2][2700/5699] Elapsed 9m 2s (remain 10m 2s) Loss: 0.0001(0.0013) Grad: 673.7725  LR: 0.000016  \n","Epoch: [2][2800/5699] Elapsed 9m 22s (remain 9m 42s) Loss: 0.0048(0.0013) Grad: 10928.0859  LR: 0.000016  \n","Epoch: [2][2900/5699] Elapsed 9m 43s (remain 9m 22s) Loss: 0.0001(0.0013) Grad: 657.7216  LR: 0.000016  \n","Epoch: [2][3000/5699] Elapsed 10m 3s (remain 9m 2s) Loss: 0.0001(0.0013) Grad: 2125.4731  LR: 0.000015  \n","Epoch: [2][3100/5699] Elapsed 10m 23s (remain 8m 42s) Loss: 0.0001(0.0013) Grad: 358.0887  LR: 0.000015  \n","Epoch: [2][3200/5699] Elapsed 10m 43s (remain 8m 22s) Loss: 0.0002(0.0013) Grad: 513.3285  LR: 0.000015  \n","Epoch: [2][3300/5699] Elapsed 11m 3s (remain 8m 1s) Loss: 0.0000(0.0013) Grad: 118.7202  LR: 0.000015  \n","Epoch: [2][3400/5699] Elapsed 11m 23s (remain 7m 41s) Loss: 0.0000(0.0013) Grad: 177.3675  LR: 0.000015  \n","Epoch: [2][3500/5699] Elapsed 11m 43s (remain 7m 21s) Loss: 0.0036(0.0013) Grad: 14439.0264  LR: 0.000015  \n","Epoch: [2][3600/5699] Elapsed 12m 3s (remain 7m 1s) Loss: 0.0029(0.0013) Grad: 4905.7568  LR: 0.000015  \n","Epoch: [2][3700/5699] Elapsed 12m 24s (remain 6m 41s) Loss: 0.0040(0.0013) Grad: 2688.4543  LR: 0.000015  \n","Epoch: [2][3800/5699] Elapsed 12m 44s (remain 6m 21s) Loss: 0.0002(0.0013) Grad: 1761.0485  LR: 0.000015  \n","Epoch: [2][3900/5699] Elapsed 13m 4s (remain 6m 1s) Loss: 0.0000(0.0013) Grad: 274.6010  LR: 0.000015  \n","Epoch: [2][4000/5699] Elapsed 13m 24s (remain 5m 41s) Loss: 0.0010(0.0013) Grad: 1932.0275  LR: 0.000015  \n","Epoch: [2][4100/5699] Elapsed 13m 44s (remain 5m 21s) Loss: 0.0017(0.0013) Grad: 4622.8657  LR: 0.000015  \n","Epoch: [2][4200/5699] Elapsed 14m 4s (remain 5m 1s) Loss: 0.0030(0.0013) Grad: 6402.0483  LR: 0.000015  \n","Epoch: [2][4300/5699] Elapsed 14m 24s (remain 4m 41s) Loss: 0.0003(0.0013) Grad: 1635.5771  LR: 0.000014  \n","Epoch: [2][4400/5699] Elapsed 14m 44s (remain 4m 20s) Loss: 0.0014(0.0013) Grad: 2044.4730  LR: 0.000014  \n","Epoch: [2][4500/5699] Elapsed 15m 4s (remain 4m 0s) Loss: 0.0001(0.0013) Grad: 310.3780  LR: 0.000014  \n","Epoch: [2][4600/5699] Elapsed 15m 24s (remain 3m 40s) Loss: 0.0011(0.0013) Grad: 2395.6667  LR: 0.000014  \n","Epoch: [2][4700/5699] Elapsed 15m 44s (remain 3m 20s) Loss: 0.0005(0.0013) Grad: 969.2092  LR: 0.000014  \n","Epoch: [2][4800/5699] Elapsed 16m 5s (remain 3m 0s) Loss: 0.0005(0.0013) Grad: 1444.4663  LR: 0.000014  \n","Epoch: [2][4900/5699] Elapsed 16m 25s (remain 2m 40s) Loss: 0.0000(0.0013) Grad: 117.8100  LR: 0.000014  \n","Epoch: [2][5000/5699] Elapsed 16m 45s (remain 2m 20s) Loss: 0.0000(0.0013) Grad: 240.3789  LR: 0.000014  \n","Epoch: [2][5100/5699] Elapsed 17m 5s (remain 2m 0s) Loss: 0.0011(0.0013) Grad: 2152.5327  LR: 0.000014  \n","Epoch: [2][5200/5699] Elapsed 17m 25s (remain 1m 40s) Loss: 0.0000(0.0013) Grad: 58.1670  LR: 0.000014  \n","Epoch: [2][5300/5699] Elapsed 17m 45s (remain 1m 20s) Loss: 0.0008(0.0013) Grad: 5301.5288  LR: 0.000014  \n","Epoch: [2][5400/5699] Elapsed 18m 5s (remain 0m 59s) Loss: 0.0000(0.0013) Grad: 91.2154  LR: 0.000014  \n","Epoch: [2][5500/5699] Elapsed 18m 25s (remain 0m 39s) Loss: 0.0002(0.0013) Grad: 1197.8956  LR: 0.000013  \n","Epoch: [2][5600/5699] Elapsed 18m 46s (remain 0m 19s) Loss: 0.0027(0.0013) Grad: 4068.7461  LR: 0.000013  \n","Epoch: [2][5698/5699] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0057(0.0013) Grad: 5611.5962  LR: 0.000013  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 8m 19s) Loss: 0.0000(0.0000) \n","EVAL: [100/1451] Elapsed 0m 7s (remain 1m 41s) Loss: 0.0176(0.0016) \n","EVAL: [200/1451] Elapsed 0m 14s (remain 1m 31s) Loss: 0.0020(0.0014) \n","EVAL: [300/1451] Elapsed 0m 21s (remain 1m 23s) Loss: 0.0000(0.0015) \n","EVAL: [400/1451] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0015) \n","EVAL: [500/1451] Elapsed 0m 36s (remain 1m 8s) Loss: 0.0000(0.0015) \n","EVAL: [600/1451] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0014) \n","EVAL: [700/1451] Elapsed 0m 50s (remain 0m 54s) Loss: 0.0460(0.0017) \n","EVAL: [800/1451] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0014(0.0019) \n","EVAL: [900/1451] Elapsed 1m 5s (remain 0m 39s) Loss: 0.0001(0.0019) \n","EVAL: [1000/1451] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0054(0.0018) \n","EVAL: [1100/1451] Elapsed 1m 19s (remain 0m 25s) Loss: 0.0109(0.0018) \n","EVAL: [1200/1451] Elapsed 1m 26s (remain 0m 18s) Loss: 0.0007(0.0017) \n","EVAL: [1300/1451] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0002(0.0017) \n","EVAL: [1400/1451] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0002(0.0017) \n","EVAL: [1450/1451] Elapsed 1m 44s (remain 0m 0s) Loss: 0.0000(0.0016) \n","Epoch 2 - avg_train_loss: 0.0013  avg_val_loss: 0.0016  time: 1254s\n","Epoch 2 - Score: 0.7135\n","Epoch 2 - Save Best Score: 0.7135 Model\n","Epoch: [3][0/5699] Elapsed 0m 0s (remain 46m 13s) Loss: 0.0029(0.0029) Grad: 6023.7378  LR: 0.000013  \n","Epoch: [3][100/5699] Elapsed 0m 21s (remain 19m 48s) Loss: 0.0001(0.0007) Grad: 1264.6963  LR: 0.000013  \n","Epoch: [3][200/5699] Elapsed 0m 41s (remain 18m 52s) Loss: 0.0014(0.0011) Grad: 3596.9246  LR: 0.000013  \n","Epoch: [3][300/5699] Elapsed 1m 1s (remain 18m 20s) Loss: 0.0000(0.0010) Grad: 163.4120  LR: 0.000013  \n","Epoch: [3][400/5699] Elapsed 1m 21s (remain 17m 56s) Loss: 0.0001(0.0011) Grad: 262.6724  LR: 0.000013  \n","Epoch: [3][500/5699] Elapsed 1m 41s (remain 17m 33s) Loss: 0.0005(0.0011) Grad: 2142.7456  LR: 0.000013  \n","Epoch: [3][600/5699] Elapsed 2m 1s (remain 17m 10s) Loss: 0.0062(0.0011) Grad: 10542.4863  LR: 0.000013  \n","Epoch: [3][700/5699] Elapsed 2m 21s (remain 16m 48s) Loss: 0.0002(0.0011) Grad: 2939.2231  LR: 0.000013  \n","Epoch: [3][800/5699] Elapsed 2m 41s (remain 16m 27s) Loss: 0.0000(0.0011) Grad: 19.7739  LR: 0.000013  \n","Epoch: [3][900/5699] Elapsed 3m 1s (remain 16m 5s) Loss: 0.0011(0.0010) Grad: 11452.4043  LR: 0.000013  \n","Epoch: [3][1000/5699] Elapsed 3m 21s (remain 15m 44s) Loss: 0.0001(0.0010) Grad: 568.9271  LR: 0.000013  \n","Epoch: [3][1100/5699] Elapsed 3m 41s (remain 15m 23s) Loss: 0.0004(0.0010) Grad: 1556.5680  LR: 0.000012  \n","Epoch: [3][1200/5699] Elapsed 4m 1s (remain 15m 3s) Loss: 0.0000(0.0010) Grad: 78.7735  LR: 0.000012  \n","Epoch: [3][1300/5699] Elapsed 4m 21s (remain 14m 42s) Loss: 0.0007(0.0011) Grad: 3113.5999  LR: 0.000012  \n","Epoch: [3][1400/5699] Elapsed 4m 41s (remain 14m 22s) Loss: 0.0027(0.0011) Grad: 4970.2642  LR: 0.000012  \n","Epoch: [3][1500/5699] Elapsed 5m 1s (remain 14m 2s) Loss: 0.0018(0.0011) Grad: 3677.5095  LR: 0.000012  \n","Epoch: [3][1600/5699] Elapsed 5m 21s (remain 13m 41s) Loss: 0.0000(0.0010) Grad: 42.2561  LR: 0.000012  \n","Epoch: [3][1700/5699] Elapsed 5m 41s (remain 13m 21s) Loss: 0.0001(0.0010) Grad: 595.9604  LR: 0.000012  \n","Epoch: [3][1800/5699] Elapsed 6m 0s (remain 13m 1s) Loss: 0.0000(0.0010) Grad: 5.6493  LR: 0.000012  \n","Epoch: [3][1900/5699] Elapsed 6m 20s (remain 12m 41s) Loss: 0.0001(0.0010) Grad: 506.2458  LR: 0.000012  \n","Epoch: [3][2000/5699] Elapsed 6m 40s (remain 12m 20s) Loss: 0.0004(0.0010) Grad: 1545.4999  LR: 0.000012  \n","Epoch: [3][2100/5699] Elapsed 7m 0s (remain 12m 0s) Loss: 0.0000(0.0010) Grad: 6.8170  LR: 0.000012  \n","Epoch: [3][2200/5699] Elapsed 7m 20s (remain 11m 40s) Loss: 0.0001(0.0010) Grad: 600.3077  LR: 0.000012  \n","Epoch: [3][2300/5699] Elapsed 7m 40s (remain 11m 20s) Loss: 0.0027(0.0010) Grad: 9251.2148  LR: 0.000012  \n","Epoch: [3][2400/5699] Elapsed 8m 0s (remain 11m 0s) Loss: 0.0001(0.0010) Grad: 544.0676  LR: 0.000011  \n","Epoch: [3][2500/5699] Elapsed 8m 20s (remain 10m 40s) Loss: 0.0000(0.0010) Grad: 190.7100  LR: 0.000011  \n","Epoch: [3][2600/5699] Elapsed 8m 40s (remain 10m 19s) Loss: 0.0001(0.0010) Grad: 312.8260  LR: 0.000011  \n","Epoch: [3][2700/5699] Elapsed 9m 0s (remain 9m 59s) Loss: 0.0003(0.0010) Grad: 1732.2433  LR: 0.000011  \n","Epoch: [3][2800/5699] Elapsed 9m 20s (remain 9m 39s) Loss: 0.0002(0.0010) Grad: 814.1097  LR: 0.000011  \n","Epoch: [3][2900/5699] Elapsed 9m 40s (remain 9m 19s) Loss: 0.0000(0.0010) Grad: 70.1815  LR: 0.000011  \n","Epoch: [3][3000/5699] Elapsed 10m 0s (remain 8m 59s) Loss: 0.0064(0.0010) Grad: 14664.1279  LR: 0.000011  \n","Epoch: [3][3100/5699] Elapsed 10m 20s (remain 8m 39s) Loss: 0.0007(0.0010) Grad: 2664.5701  LR: 0.000011  \n","Epoch: [3][3200/5699] Elapsed 10m 40s (remain 8m 19s) Loss: 0.0001(0.0010) Grad: 694.6601  LR: 0.000011  \n","Epoch: [3][3300/5699] Elapsed 10m 59s (remain 7m 59s) Loss: 0.0001(0.0010) Grad: 616.9678  LR: 0.000011  \n","Epoch: [3][3400/5699] Elapsed 11m 20s (remain 7m 39s) Loss: 0.0002(0.0010) Grad: 738.3995  LR: 0.000011  \n","Epoch: [3][3500/5699] Elapsed 11m 40s (remain 7m 19s) Loss: 0.0000(0.0010) Grad: 6.4182  LR: 0.000011  \n","Epoch: [3][3600/5699] Elapsed 12m 0s (remain 6m 59s) Loss: 0.0001(0.0010) Grad: 903.7972  LR: 0.000011  \n","Epoch: [3][3700/5699] Elapsed 12m 19s (remain 6m 39s) Loss: 0.0001(0.0010) Grad: 892.8721  LR: 0.000010  \n","Epoch: [3][3800/5699] Elapsed 12m 40s (remain 6m 19s) Loss: 0.0046(0.0010) Grad: 4955.9609  LR: 0.000010  \n","Epoch: [3][3900/5699] Elapsed 13m 0s (remain 5m 59s) Loss: 0.0076(0.0010) Grad: 150822.0000  LR: 0.000010  \n","Epoch: [3][4000/5699] Elapsed 13m 20s (remain 5m 39s) Loss: 0.0005(0.0010) Grad: 1222.7852  LR: 0.000010  \n","Epoch: [3][4100/5699] Elapsed 13m 40s (remain 5m 19s) Loss: 0.0001(0.0010) Grad: 218.1508  LR: 0.000010  \n","Epoch: [3][4200/5699] Elapsed 14m 0s (remain 4m 59s) Loss: 0.0000(0.0010) Grad: 32.0818  LR: 0.000010  \n","Epoch: [3][4300/5699] Elapsed 14m 20s (remain 4m 39s) Loss: 0.0002(0.0010) Grad: 790.2309  LR: 0.000010  \n","Epoch: [3][4400/5699] Elapsed 14m 40s (remain 4m 19s) Loss: 0.0000(0.0010) Grad: 58.4138  LR: 0.000010  \n","Epoch: [3][4500/5699] Elapsed 15m 0s (remain 3m 59s) Loss: 0.0015(0.0010) Grad: 3737.2021  LR: 0.000010  \n","Epoch: [3][4600/5699] Elapsed 15m 20s (remain 3m 39s) Loss: 0.0000(0.0010) Grad: 45.0810  LR: 0.000010  \n","Epoch: [3][4700/5699] Elapsed 15m 40s (remain 3m 19s) Loss: 0.0011(0.0010) Grad: 2563.1848  LR: 0.000010  \n","Epoch: [3][4800/5699] Elapsed 16m 0s (remain 2m 59s) Loss: 0.0002(0.0010) Grad: 703.5131  LR: 0.000010  \n","Epoch: [3][4900/5699] Elapsed 16m 20s (remain 2m 39s) Loss: 0.0000(0.0010) Grad: 8.0415  LR: 0.000010  \n","Epoch: [3][5000/5699] Elapsed 16m 40s (remain 2m 19s) Loss: 0.0017(0.0010) Grad: 10536.5381  LR: 0.000009  \n","Epoch: [3][5100/5699] Elapsed 17m 0s (remain 1m 59s) Loss: 0.0000(0.0010) Grad: 128.3792  LR: 0.000009  \n","Epoch: [3][5200/5699] Elapsed 17m 20s (remain 1m 39s) Loss: 0.0002(0.0010) Grad: 799.2574  LR: 0.000009  \n","Epoch: [3][5300/5699] Elapsed 17m 39s (remain 1m 19s) Loss: 0.0001(0.0010) Grad: 370.2028  LR: 0.000009  \n","Epoch: [3][5400/5699] Elapsed 17m 59s (remain 0m 59s) Loss: 0.0006(0.0010) Grad: 1796.2068  LR: 0.000009  \n","Epoch: [3][5500/5699] Elapsed 18m 19s (remain 0m 39s) Loss: 0.0005(0.0010) Grad: 2683.5122  LR: 0.000009  \n","Epoch: [3][5600/5699] Elapsed 18m 39s (remain 0m 19s) Loss: 0.0000(0.0010) Grad: 139.7581  LR: 0.000009  \n","Epoch: [3][5698/5699] Elapsed 18m 59s (remain 0m 0s) Loss: 0.0072(0.0010) Grad: 17178.0195  LR: 0.000009  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 8m 21s) Loss: 0.0000(0.0000) \n","EVAL: [100/1451] Elapsed 0m 7s (remain 1m 41s) Loss: 0.0163(0.0016) \n","EVAL: [200/1451] Elapsed 0m 14s (remain 1m 31s) Loss: 0.0022(0.0015) \n","EVAL: [300/1451] Elapsed 0m 21s (remain 1m 23s) Loss: 0.0000(0.0015) \n","EVAL: [400/1451] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0014) \n","EVAL: [500/1451] Elapsed 0m 36s (remain 1m 9s) Loss: 0.0000(0.0014) \n","EVAL: [600/1451] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0014) \n","EVAL: [700/1451] Elapsed 0m 50s (remain 0m 54s) Loss: 0.0473(0.0015) \n","EVAL: [800/1451] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0003(0.0017) \n","EVAL: [900/1451] Elapsed 1m 4s (remain 0m 39s) Loss: 0.0001(0.0018) \n","EVAL: [1000/1451] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0050(0.0017) \n","EVAL: [1100/1451] Elapsed 1m 19s (remain 0m 25s) Loss: 0.0094(0.0017) \n","EVAL: [1200/1451] Elapsed 1m 26s (remain 0m 17s) Loss: 0.0013(0.0016) \n","EVAL: [1300/1451] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0002(0.0016) \n","EVAL: [1400/1451] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0002(0.0016) \n","EVAL: [1450/1451] Elapsed 1m 44s (remain 0m 0s) Loss: 0.0000(0.0015) \n","Epoch 3 - avg_train_loss: 0.0010  avg_val_loss: 0.0015  time: 1247s\n","Epoch 3 - Score: 0.7291\n","Epoch 3 - Save Best Score: 0.7291 Model\n","Epoch: [4][0/5699] Elapsed 0m 0s (remain 46m 35s) Loss: 0.0004(0.0004) Grad: 1483.0138  LR: 0.000009  \n","Epoch: [4][100/5699] Elapsed 0m 21s (remain 19m 44s) Loss: 0.0019(0.0008) Grad: 4430.8086  LR: 0.000009  \n","Epoch: [4][200/5699] Elapsed 0m 41s (remain 18m 53s) Loss: 0.0001(0.0007) Grad: 1701.5071  LR: 0.000009  \n","Epoch: [4][300/5699] Elapsed 1m 1s (remain 18m 20s) Loss: 0.0000(0.0007) Grad: 27.2935  LR: 0.000009  \n","Epoch: [4][400/5699] Elapsed 1m 21s (remain 17m 54s) Loss: 0.0000(0.0007) Grad: 6.9631  LR: 0.000009  \n","Epoch: [4][500/5699] Elapsed 1m 41s (remain 17m 32s) Loss: 0.0000(0.0007) Grad: 9.0462  LR: 0.000008  \n","Epoch: [4][600/5699] Elapsed 2m 1s (remain 17m 10s) Loss: 0.0014(0.0007) Grad: 4148.7295  LR: 0.000008  \n","Epoch: [4][700/5699] Elapsed 2m 21s (remain 16m 47s) Loss: 0.0008(0.0007) Grad: 1687.9122  LR: 0.000008  \n","Epoch: [4][800/5699] Elapsed 2m 41s (remain 16m 28s) Loss: 0.0001(0.0007) Grad: 561.6658  LR: 0.000008  \n","Epoch: [4][900/5699] Elapsed 3m 1s (remain 16m 7s) Loss: 0.0000(0.0007) Grad: 105.6301  LR: 0.000008  \n","Epoch: [4][1000/5699] Elapsed 3m 21s (remain 15m 46s) Loss: 0.0000(0.0007) Grad: 20.8432  LR: 0.000008  \n","Epoch: [4][1100/5699] Elapsed 3m 41s (remain 15m 25s) Loss: 0.0000(0.0008) Grad: 107.4723  LR: 0.000008  \n","Epoch: [4][1200/5699] Elapsed 4m 1s (remain 15m 5s) Loss: 0.0019(0.0008) Grad: 6302.3052  LR: 0.000008  \n","Epoch: [4][1300/5699] Elapsed 4m 21s (remain 14m 44s) Loss: 0.0002(0.0008) Grad: 6787.2739  LR: 0.000008  \n","Epoch: [4][1400/5699] Elapsed 4m 41s (remain 14m 24s) Loss: 0.0000(0.0008) Grad: 683.5658  LR: 0.000008  \n","Epoch: [4][1500/5699] Elapsed 5m 1s (remain 14m 4s) Loss: 0.0031(0.0008) Grad: 10639.7314  LR: 0.000008  \n","Epoch: [4][1600/5699] Elapsed 5m 21s (remain 13m 44s) Loss: 0.0007(0.0008) Grad: 7731.1401  LR: 0.000008  \n","Epoch: [4][1700/5699] Elapsed 5m 42s (remain 13m 24s) Loss: 0.0000(0.0008) Grad: 168.3757  LR: 0.000008  \n","Epoch: [4][1800/5699] Elapsed 6m 2s (remain 13m 4s) Loss: 0.0001(0.0008) Grad: 523.7343  LR: 0.000007  \n","Epoch: [4][1900/5699] Elapsed 6m 22s (remain 12m 43s) Loss: 0.0000(0.0008) Grad: 47.1317  LR: 0.000007  \n","Epoch: [4][2000/5699] Elapsed 6m 42s (remain 12m 23s) Loss: 0.0005(0.0008) Grad: 4713.1548  LR: 0.000007  \n","Epoch: [4][2100/5699] Elapsed 7m 2s (remain 12m 3s) Loss: 0.0000(0.0008) Grad: 1.8163  LR: 0.000007  \n","Epoch: [4][2200/5699] Elapsed 7m 22s (remain 11m 43s) Loss: 0.0008(0.0008) Grad: 3168.1086  LR: 0.000007  \n","Epoch: [4][2300/5699] Elapsed 7m 42s (remain 11m 22s) Loss: 0.0005(0.0008) Grad: 1491.5635  LR: 0.000007  \n","Epoch: [4][2400/5699] Elapsed 8m 2s (remain 11m 2s) Loss: 0.0008(0.0008) Grad: 4078.6721  LR: 0.000007  \n","Epoch: [4][2500/5699] Elapsed 8m 22s (remain 10m 42s) Loss: 0.0001(0.0008) Grad: 333.2556  LR: 0.000007  \n","Epoch: [4][2600/5699] Elapsed 8m 42s (remain 10m 21s) Loss: 0.0000(0.0008) Grad: 9.1564  LR: 0.000007  \n","Epoch: [4][2700/5699] Elapsed 9m 2s (remain 10m 1s) Loss: 0.0000(0.0008) Grad: 91.4644  LR: 0.000007  \n","Epoch: [4][2800/5699] Elapsed 9m 22s (remain 9m 41s) Loss: 0.0000(0.0008) Grad: 11.7403  LR: 0.000007  \n","Epoch: [4][2900/5699] Elapsed 9m 42s (remain 9m 21s) Loss: 0.0009(0.0008) Grad: 3103.9133  LR: 0.000007  \n","Epoch: [4][3000/5699] Elapsed 10m 2s (remain 9m 1s) Loss: 0.0000(0.0008) Grad: 9.8152  LR: 0.000007  \n","Epoch: [4][3100/5699] Elapsed 10m 22s (remain 8m 41s) Loss: 0.0002(0.0008) Grad: 1531.9874  LR: 0.000006  \n","Epoch: [4][3200/5699] Elapsed 10m 42s (remain 8m 21s) Loss: 0.0003(0.0008) Grad: 1397.9397  LR: 0.000006  \n","Epoch: [4][3300/5699] Elapsed 11m 2s (remain 8m 1s) Loss: 0.0000(0.0008) Grad: 51.0236  LR: 0.000006  \n","Epoch: [4][3400/5699] Elapsed 11m 22s (remain 7m 40s) Loss: 0.0001(0.0008) Grad: 863.3508  LR: 0.000006  \n","Epoch: [4][3500/5699] Elapsed 11m 42s (remain 7m 20s) Loss: 0.0000(0.0008) Grad: 13.7215  LR: 0.000006  \n","Epoch: [4][3600/5699] Elapsed 12m 2s (remain 7m 0s) Loss: 0.0000(0.0008) Grad: 32.4969  LR: 0.000006  \n","Epoch: [4][3700/5699] Elapsed 12m 22s (remain 6m 40s) Loss: 0.0000(0.0008) Grad: 5.5885  LR: 0.000006  \n","Epoch: [4][3800/5699] Elapsed 12m 42s (remain 6m 20s) Loss: 0.0001(0.0008) Grad: 2310.3318  LR: 0.000006  \n","Epoch: [4][3900/5699] Elapsed 13m 2s (remain 6m 0s) Loss: 0.0001(0.0008) Grad: 266.4406  LR: 0.000006  \n","Epoch: [4][4000/5699] Elapsed 13m 21s (remain 5m 40s) Loss: 0.0000(0.0008) Grad: 38.5512  LR: 0.000006  \n","Epoch: [4][4100/5699] Elapsed 13m 41s (remain 5m 20s) Loss: 0.0131(0.0008) Grad: 20507.0020  LR: 0.000006  \n","Epoch: [4][4200/5699] Elapsed 14m 1s (remain 5m 0s) Loss: 0.0000(0.0008) Grad: 14.9599  LR: 0.000006  \n","Epoch: [4][4300/5699] Elapsed 14m 21s (remain 4m 40s) Loss: 0.0000(0.0008) Grad: 90.3605  LR: 0.000006  \n","Epoch: [4][4400/5699] Elapsed 14m 41s (remain 4m 20s) Loss: 0.0003(0.0008) Grad: 7210.6748  LR: 0.000005  \n","Epoch: [4][4500/5699] Elapsed 15m 1s (remain 4m 0s) Loss: 0.0000(0.0008) Grad: 160.6646  LR: 0.000005  \n","Epoch: [4][4600/5699] Elapsed 15m 21s (remain 3m 39s) Loss: 0.0000(0.0008) Grad: 19.4026  LR: 0.000005  \n","Epoch: [4][4700/5699] Elapsed 15m 41s (remain 3m 19s) Loss: 0.0002(0.0008) Grad: 1196.9763  LR: 0.000005  \n","Epoch: [4][4800/5699] Elapsed 16m 1s (remain 2m 59s) Loss: 0.0020(0.0008) Grad: 8070.7065  LR: 0.000005  \n","Epoch: [4][4900/5699] Elapsed 16m 21s (remain 2m 39s) Loss: 0.0000(0.0008) Grad: 137.9646  LR: 0.000005  \n","Epoch: [4][5000/5699] Elapsed 16m 42s (remain 2m 19s) Loss: 0.0042(0.0008) Grad: 19533.9746  LR: 0.000005  \n","Epoch: [4][5100/5699] Elapsed 17m 2s (remain 1m 59s) Loss: 0.0039(0.0008) Grad: 4628.5103  LR: 0.000005  \n","Epoch: [4][5200/5699] Elapsed 17m 22s (remain 1m 39s) Loss: 0.0012(0.0008) Grad: 5811.9961  LR: 0.000005  \n","Epoch: [4][5300/5699] Elapsed 17m 42s (remain 1m 19s) Loss: 0.0001(0.0008) Grad: 959.8075  LR: 0.000005  \n","Epoch: [4][5400/5699] Elapsed 18m 2s (remain 0m 59s) Loss: 0.0000(0.0008) Grad: 4.0730  LR: 0.000005  \n","Epoch: [4][5500/5699] Elapsed 18m 22s (remain 0m 39s) Loss: 0.0000(0.0008) Grad: 48.2199  LR: 0.000005  \n","Epoch: [4][5600/5699] Elapsed 18m 42s (remain 0m 19s) Loss: 0.0014(0.0008) Grad: 8174.1289  LR: 0.000005  \n","Epoch: [4][5698/5699] Elapsed 19m 2s (remain 0m 0s) Loss: 0.0004(0.0008) Grad: 1487.6643  LR: 0.000004  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 8m 22s) Loss: 0.0000(0.0000) \n","EVAL: [100/1451] Elapsed 0m 7s (remain 1m 41s) Loss: 0.0192(0.0018) \n","EVAL: [200/1451] Elapsed 0m 14s (remain 1m 32s) Loss: 0.0009(0.0014) \n","EVAL: [300/1451] Elapsed 0m 22s (remain 1m 24s) Loss: 0.0000(0.0015) \n","EVAL: [400/1451] Elapsed 0m 29s (remain 1m 17s) Loss: 0.0000(0.0014) \n","EVAL: [500/1451] Elapsed 0m 36s (remain 1m 9s) Loss: 0.0000(0.0015) \n","EVAL: [600/1451] Elapsed 0m 43s (remain 1m 2s) Loss: 0.0000(0.0014) \n","EVAL: [700/1451] Elapsed 0m 51s (remain 0m 54s) Loss: 0.0345(0.0016) \n","EVAL: [800/1451] Elapsed 0m 58s (remain 0m 47s) Loss: 0.0006(0.0018) \n","EVAL: [900/1451] Elapsed 1m 5s (remain 0m 39s) Loss: 0.0000(0.0018) \n","EVAL: [1000/1451] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0049(0.0017) \n","EVAL: [1100/1451] Elapsed 1m 19s (remain 0m 25s) Loss: 0.0117(0.0016) \n","EVAL: [1200/1451] Elapsed 1m 27s (remain 0m 18s) Loss: 0.0006(0.0016) \n","EVAL: [1300/1451] Elapsed 1m 34s (remain 0m 10s) Loss: 0.0001(0.0015) \n","EVAL: [1400/1451] Elapsed 1m 41s (remain 0m 3s) Loss: 0.0003(0.0015) \n","EVAL: [1450/1451] Elapsed 1m 44s (remain 0m 0s) Loss: 0.0000(0.0015) \n","Epoch 4 - avg_train_loss: 0.0008  avg_val_loss: 0.0015  time: 1251s\n","Epoch 4 - Score: 0.7357\n","Epoch 4 - Save Best Score: 0.7357 Model\n","Epoch: [5][0/5699] Elapsed 0m 0s (remain 47m 33s) Loss: 0.0002(0.0002) Grad: 1289.5649  LR: 0.000004  \n","Epoch: [5][100/5699] Elapsed 0m 21s (remain 19m 31s) Loss: 0.0000(0.0008) Grad: 18.4823  LR: 0.000004  \n","Epoch: [5][200/5699] Elapsed 0m 41s (remain 18m 47s) Loss: 0.0000(0.0007) Grad: 14.6071  LR: 0.000004  \n","Epoch: [5][300/5699] Elapsed 1m 1s (remain 18m 17s) Loss: 0.0003(0.0007) Grad: 2487.2839  LR: 0.000004  \n","Epoch: [5][400/5699] Elapsed 1m 21s (remain 17m 52s) Loss: 0.0001(0.0008) Grad: 1212.2451  LR: 0.000004  \n","Epoch: [5][500/5699] Elapsed 1m 41s (remain 17m 29s) Loss: 0.0001(0.0007) Grad: 720.3296  LR: 0.000004  \n","Epoch: [5][600/5699] Elapsed 2m 1s (remain 17m 7s) Loss: 0.0009(0.0007) Grad: 3170.4941  LR: 0.000004  \n","Epoch: [5][700/5699] Elapsed 2m 21s (remain 16m 45s) Loss: 0.0000(0.0007) Grad: 24.1051  LR: 0.000004  \n","Epoch: [5][800/5699] Elapsed 2m 41s (remain 16m 24s) Loss: 0.0001(0.0006) Grad: 435.1006  LR: 0.000004  \n","Epoch: [5][900/5699] Elapsed 3m 1s (remain 16m 4s) Loss: 0.0000(0.0006) Grad: 8.5356  LR: 0.000004  \n","Epoch: [5][1000/5699] Elapsed 3m 21s (remain 15m 44s) Loss: 0.0000(0.0006) Grad: 18.7330  LR: 0.000004  \n","Epoch: [5][1100/5699] Elapsed 3m 41s (remain 15m 23s) Loss: 0.0000(0.0006) Grad: 2.4561  LR: 0.000004  \n","Epoch: [5][1200/5699] Elapsed 4m 1s (remain 15m 3s) Loss: 0.0002(0.0006) Grad: 1915.1278  LR: 0.000004  \n","Epoch: [5][1300/5699] Elapsed 4m 21s (remain 14m 43s) Loss: 0.0000(0.0006) Grad: 20.3444  LR: 0.000003  \n","Epoch: [5][1400/5699] Elapsed 4m 41s (remain 14m 22s) Loss: 0.0000(0.0006) Grad: 8.7836  LR: 0.000003  \n","Epoch: [5][1500/5699] Elapsed 5m 1s (remain 14m 2s) Loss: 0.0015(0.0006) Grad: 10213.0566  LR: 0.000003  \n","Epoch: [5][1600/5699] Elapsed 5m 21s (remain 13m 42s) Loss: 0.0002(0.0006) Grad: 2522.0886  LR: 0.000003  \n","Epoch: [5][1700/5699] Elapsed 5m 41s (remain 13m 21s) Loss: 0.0000(0.0006) Grad: 66.9254  LR: 0.000003  \n","Epoch: [5][1800/5699] Elapsed 6m 1s (remain 13m 1s) Loss: 0.0001(0.0006) Grad: 805.1293  LR: 0.000003  \n","Epoch: [5][1900/5699] Elapsed 6m 21s (remain 12m 41s) Loss: 0.0002(0.0006) Grad: 1489.7728  LR: 0.000003  \n","Epoch: [5][2000/5699] Elapsed 6m 41s (remain 12m 21s) Loss: 0.0000(0.0006) Grad: 33.1514  LR: 0.000003  \n","Epoch: [5][2100/5699] Elapsed 7m 1s (remain 12m 1s) Loss: 0.0000(0.0006) Grad: 6.0343  LR: 0.000003  \n","Epoch: [5][2200/5699] Elapsed 7m 21s (remain 11m 41s) Loss: 0.0000(0.0006) Grad: 29.1586  LR: 0.000003  \n","Epoch: [5][2300/5699] Elapsed 7m 41s (remain 11m 21s) Loss: 0.0000(0.0006) Grad: 220.2725  LR: 0.000003  \n","Epoch: [5][2400/5699] Elapsed 8m 1s (remain 11m 1s) Loss: 0.0017(0.0006) Grad: 11041.2617  LR: 0.000003  \n","Epoch: [5][2500/5699] Elapsed 8m 21s (remain 10m 41s) Loss: 0.0001(0.0006) Grad: 1717.6349  LR: 0.000002  \n","Epoch: [5][2600/5699] Elapsed 8m 41s (remain 10m 21s) Loss: 0.0002(0.0006) Grad: 1408.8308  LR: 0.000002  \n","Epoch: [5][2700/5699] Elapsed 9m 1s (remain 10m 1s) Loss: 0.0000(0.0006) Grad: 23.9445  LR: 0.000002  \n","Epoch: [5][2800/5699] Elapsed 9m 21s (remain 9m 40s) Loss: 0.0000(0.0006) Grad: 42.8708  LR: 0.000002  \n","Epoch: [5][2900/5699] Elapsed 9m 41s (remain 9m 20s) Loss: 0.0000(0.0006) Grad: 2.5926  LR: 0.000002  \n","Epoch: [5][3000/5699] Elapsed 10m 1s (remain 9m 0s) Loss: 0.0000(0.0006) Grad: 4.1337  LR: 0.000002  \n","Epoch: [5][3100/5699] Elapsed 10m 21s (remain 8m 40s) Loss: 0.0000(0.0006) Grad: 152.5849  LR: 0.000002  \n","Epoch: [5][3200/5699] Elapsed 10m 41s (remain 8m 20s) Loss: 0.0010(0.0006) Grad: 3121.2732  LR: 0.000002  \n","Epoch: [5][3300/5699] Elapsed 11m 1s (remain 8m 0s) Loss: 0.0089(0.0006) Grad: 8669.4414  LR: 0.000002  \n","Epoch: [5][3400/5699] Elapsed 11m 21s (remain 7m 40s) Loss: 0.0073(0.0006) Grad: 6361.5776  LR: 0.000002  \n","Epoch: [5][3500/5699] Elapsed 11m 41s (remain 7m 20s) Loss: 0.0091(0.0006) Grad: 20342.2539  LR: 0.000002  \n","Epoch: [5][3600/5699] Elapsed 12m 1s (remain 7m 0s) Loss: 0.0011(0.0006) Grad: 3493.2576  LR: 0.000002  \n","Epoch: [5][3700/5699] Elapsed 12m 21s (remain 6m 40s) Loss: 0.0112(0.0006) Grad: 20664.3379  LR: 0.000002  \n","Epoch: [5][3800/5699] Elapsed 12m 41s (remain 6m 20s) Loss: 0.0000(0.0006) Grad: 168.5538  LR: 0.000001  \n","Epoch: [5][3900/5699] Elapsed 13m 1s (remain 6m 0s) Loss: 0.0000(0.0006) Grad: 6.3089  LR: 0.000001  \n","Epoch: [5][4000/5699] Elapsed 13m 21s (remain 5m 40s) Loss: 0.0005(0.0006) Grad: 7743.0771  LR: 0.000001  \n","Epoch: [5][4100/5699] Elapsed 13m 41s (remain 5m 20s) Loss: 0.0029(0.0006) Grad: 49072.1133  LR: 0.000001  \n","Epoch: [5][4200/5699] Elapsed 14m 1s (remain 5m 0s) Loss: 0.0000(0.0006) Grad: 1347.8423  LR: 0.000001  \n","Epoch: [5][4300/5699] Elapsed 14m 21s (remain 4m 40s) Loss: 0.0000(0.0006) Grad: 29.1107  LR: 0.000001  \n","Epoch: [5][4400/5699] Elapsed 14m 41s (remain 4m 20s) Loss: 0.0000(0.0006) Grad: 217.1024  LR: 0.000001  \n","Epoch: [5][4500/5699] Elapsed 15m 1s (remain 3m 59s) Loss: 0.0000(0.0006) Grad: 5.8732  LR: 0.000001  \n","Epoch: [5][4600/5699] Elapsed 15m 21s (remain 3m 39s) Loss: 0.0000(0.0006) Grad: 11.0755  LR: 0.000001  \n","Epoch: [5][4700/5699] Elapsed 15m 41s (remain 3m 19s) Loss: 0.0000(0.0006) Grad: 154.8815  LR: 0.000001  \n","Epoch: [5][4800/5699] Elapsed 16m 1s (remain 2m 59s) Loss: 0.0017(0.0006) Grad: 3886.1904  LR: 0.000001  \n","Epoch: [5][4900/5699] Elapsed 16m 21s (remain 2m 39s) Loss: 0.0000(0.0006) Grad: 11.7256  LR: 0.000001  \n","Epoch: [5][5000/5699] Elapsed 16m 41s (remain 2m 19s) Loss: 0.0000(0.0006) Grad: 2.2904  LR: 0.000001  \n","Epoch: [5][5100/5699] Elapsed 17m 1s (remain 1m 59s) Loss: 0.0003(0.0006) Grad: 2070.5093  LR: 0.000000  \n","Epoch: [5][5200/5699] Elapsed 17m 20s (remain 1m 39s) Loss: 0.0000(0.0006) Grad: 10.1879  LR: 0.000000  \n","Epoch: [5][5300/5699] Elapsed 17m 40s (remain 1m 19s) Loss: 0.0002(0.0006) Grad: 1485.0071  LR: 0.000000  \n","Epoch: [5][5400/5699] Elapsed 18m 0s (remain 0m 59s) Loss: 0.0000(0.0006) Grad: 54.9821  LR: 0.000000  \n","Epoch: [5][5500/5699] Elapsed 18m 20s (remain 0m 39s) Loss: 0.0000(0.0006) Grad: 7.7551  LR: 0.000000  \n","Epoch: [5][5600/5699] Elapsed 18m 40s (remain 0m 19s) Loss: 0.0000(0.0006) Grad: 25.1178  LR: 0.000000  \n","Epoch: [5][5698/5699] Elapsed 19m 0s (remain 0m 0s) Loss: 0.0000(0.0006) Grad: 841.2953  LR: 0.000000  \n","EVAL: [0/1451] Elapsed 0m 0s (remain 8m 18s) Loss: 0.0000(0.0000) \n","EVAL: [100/1451] Elapsed 0m 7s (remain 1m 40s) Loss: 0.0191(0.0020) \n","EVAL: [200/1451] Elapsed 0m 14s (remain 1m 31s) Loss: 0.0008(0.0016) \n","EVAL: [300/1451] Elapsed 0m 21s (remain 1m 23s) Loss: 0.0000(0.0016) \n","EVAL: [400/1451] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0016) \n","EVAL: [500/1451] Elapsed 0m 36s (remain 1m 8s) Loss: 0.0000(0.0016) \n","EVAL: [600/1451] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0015) \n","EVAL: [700/1451] Elapsed 0m 50s (remain 0m 54s) Loss: 0.0472(0.0018) \n","EVAL: [800/1451] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0003(0.0020) \n","EVAL: [900/1451] Elapsed 1m 4s (remain 0m 39s) Loss: 0.0000(0.0020) \n","EVAL: [1000/1451] Elapsed 1m 11s (remain 0m 32s) Loss: 0.0059(0.0019) \n","EVAL: [1100/1451] Elapsed 1m 19s (remain 0m 25s) Loss: 0.0119(0.0019) \n","EVAL: [1200/1451] Elapsed 1m 26s (remain 0m 17s) Loss: 0.0006(0.0018) \n","EVAL: [1300/1451] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0000(0.0017) \n","EVAL: [1400/1451] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0006(0.0017) \n","EVAL: [1450/1451] Elapsed 1m 43s (remain 0m 0s) Loss: 0.0000(0.0017) \n","Epoch 5 - avg_train_loss: 0.0006  avg_val_loss: 0.0017  time: 1248s\n","Epoch 5 - Score: 0.7392\n","Epoch 5 - Save Best Score: 0.7392 Model\n","========== fold: 1 training ==========\n","Load weight from pretrained\n","Epoch: [1][0/5703] Elapsed 0m 0s (remain 49m 18s) Loss: 0.0750(0.0750) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/5703] Elapsed 0m 21s (remain 19m 35s) Loss: 0.0662(0.0591) Grad: 30838.3965  LR: 0.000001  \n","Epoch: [1][200/5703] Elapsed 0m 41s (remain 18m 47s) Loss: 0.0657(0.0502) Grad: 32722.3496  LR: 0.000001  \n","Epoch: [1][300/5703] Elapsed 1m 1s (remain 18m 18s) Loss: 0.0092(0.0410) Grad: 3578.8997  LR: 0.000002  \n","Epoch: [1][400/5703] Elapsed 1m 21s (remain 17m 53s) Loss: 0.0099(0.0329) Grad: 1433.5706  LR: 0.000003  \n","Epoch: [1][500/5703] Elapsed 1m 41s (remain 17m 30s) Loss: 0.0045(0.0276) Grad: 752.8220  LR: 0.000004  \n","Epoch: [1][600/5703] Elapsed 2m 1s (remain 17m 9s) Loss: 0.0023(0.0241) Grad: 594.7349  LR: 0.000004  \n","Epoch: [1][700/5703] Elapsed 2m 21s (remain 16m 47s) Loss: 0.0045(0.0214) Grad: 1577.4393  LR: 0.000005  \n","Epoch: [1][800/5703] Elapsed 2m 41s (remain 16m 26s) Loss: 0.0013(0.0193) Grad: 4122.5439  LR: 0.000006  \n","Epoch: [1][900/5703] Elapsed 3m 1s (remain 16m 5s) Loss: 0.0005(0.0176) Grad: 788.5968  LR: 0.000006  \n","Epoch: [1][1000/5703] Elapsed 3m 21s (remain 15m 45s) Loss: 0.0026(0.0162) Grad: 2057.7605  LR: 0.000007  \n","Epoch: [1][1100/5703] Elapsed 3m 41s (remain 15m 24s) Loss: 0.0007(0.0150) Grad: 533.7432  LR: 0.000008  \n","Epoch: [1][1200/5703] Elapsed 4m 1s (remain 15m 4s) Loss: 0.0112(0.0141) Grad: 2616.8926  LR: 0.000008  \n","Epoch: [1][1300/5703] Elapsed 4m 21s (remain 14m 44s) Loss: 0.0028(0.0133) Grad: 4545.9956  LR: 0.000009  \n","Epoch: [1][1400/5703] Elapsed 4m 41s (remain 14m 23s) Loss: 0.0060(0.0125) Grad: 7552.3896  LR: 0.000010  \n","Epoch: [1][1500/5703] Elapsed 5m 1s (remain 14m 3s) Loss: 0.0014(0.0120) Grad: 1209.8804  LR: 0.000011  \n","Epoch: [1][1600/5703] Elapsed 5m 21s (remain 13m 43s) Loss: 0.0010(0.0114) Grad: 3591.7695  LR: 0.000011  \n","Epoch: [1][1700/5703] Elapsed 5m 41s (remain 13m 23s) Loss: 0.0025(0.0109) Grad: 2168.7556  LR: 0.000012  \n","Epoch: [1][1800/5703] Elapsed 6m 1s (remain 13m 3s) Loss: 0.0014(0.0105) Grad: 1285.2463  LR: 0.000013  \n","Epoch: [1][1900/5703] Elapsed 6m 21s (remain 12m 43s) Loss: 0.0001(0.0100) Grad: 185.0233  LR: 0.000013  \n","Epoch: [1][2000/5703] Elapsed 6m 41s (remain 12m 23s) Loss: 0.0008(0.0097) Grad: 537.9950  LR: 0.000014  \n","Epoch: [1][2100/5703] Elapsed 7m 1s (remain 12m 3s) Loss: 0.0007(0.0093) Grad: 983.5148  LR: 0.000015  \n","Epoch: [1][2200/5703] Elapsed 7m 22s (remain 11m 43s) Loss: 0.0009(0.0090) Grad: 500.3404  LR: 0.000015  \n","Epoch: [1][2300/5703] Elapsed 7m 42s (remain 11m 23s) Loss: 0.0002(0.0088) Grad: 167.6680  LR: 0.000016  \n","Epoch: [1][2400/5703] Elapsed 8m 2s (remain 11m 3s) Loss: 0.0039(0.0085) Grad: 3344.1177  LR: 0.000017  \n","Epoch: [1][2500/5703] Elapsed 8m 22s (remain 10m 43s) Loss: 0.0006(0.0082) Grad: 2850.7979  LR: 0.000018  \n","Epoch: [1][2600/5703] Elapsed 8m 42s (remain 10m 23s) Loss: 0.0020(0.0080) Grad: 1785.5845  LR: 0.000018  \n","Epoch: [1][2700/5703] Elapsed 9m 2s (remain 10m 3s) Loss: 0.0009(0.0078) Grad: 1043.2666  LR: 0.000019  \n","Epoch: [1][2800/5703] Elapsed 9m 22s (remain 9m 42s) Loss: 0.0050(0.0076) Grad: 1008.8559  LR: 0.000020  \n","Epoch: [1][2900/5703] Elapsed 9m 42s (remain 9m 22s) Loss: 0.0013(0.0074) Grad: 628.4085  LR: 0.000020  \n","Epoch: [1][3000/5703] Elapsed 10m 2s (remain 9m 2s) Loss: 0.0006(0.0072) Grad: 6710.8081  LR: 0.000020  \n","Epoch: [1][3100/5703] Elapsed 10m 22s (remain 8m 42s) Loss: 0.0002(0.0071) Grad: 186.7205  LR: 0.000020  \n","Epoch: [1][3200/5703] Elapsed 10m 42s (remain 8m 22s) Loss: 0.0013(0.0069) Grad: 1190.6561  LR: 0.000020  \n","Epoch: [1][3300/5703] Elapsed 11m 2s (remain 8m 2s) Loss: 0.0001(0.0068) Grad: 75.9934  LR: 0.000020  \n","Epoch: [1][3400/5703] Elapsed 11m 22s (remain 7m 42s) Loss: 0.0022(0.0066) Grad: 822.7114  LR: 0.000020  \n","Epoch: [1][3500/5703] Elapsed 11m 42s (remain 7m 22s) Loss: 0.0045(0.0065) Grad: 4363.9790  LR: 0.000019  \n","Epoch: [1][3600/5703] Elapsed 12m 3s (remain 7m 2s) Loss: 0.0025(0.0064) Grad: 7899.1147  LR: 0.000019  \n","Epoch: [1][3700/5703] Elapsed 12m 23s (remain 6m 41s) Loss: 0.0010(0.0062) Grad: 949.9557  LR: 0.000019  \n","Epoch: [1][3800/5703] Elapsed 12m 43s (remain 6m 21s) Loss: 0.0069(0.0061) Grad: 2298.9187  LR: 0.000019  \n","Epoch: [1][3900/5703] Elapsed 13m 3s (remain 6m 1s) Loss: 0.0008(0.0060) Grad: 572.3199  LR: 0.000019  \n","Epoch: [1][4000/5703] Elapsed 13m 23s (remain 5m 41s) Loss: 0.0000(0.0059) Grad: 24.2467  LR: 0.000019  \n","Epoch: [1][4100/5703] Elapsed 13m 43s (remain 5m 21s) Loss: 0.0003(0.0058) Grad: 372.5318  LR: 0.000019  \n","Epoch: [1][4200/5703] Elapsed 14m 3s (remain 5m 1s) Loss: 0.0016(0.0057) Grad: 649.7845  LR: 0.000019  \n","Epoch: [1][4300/5703] Elapsed 14m 23s (remain 4m 41s) Loss: 0.0028(0.0056) Grad: 3061.2964  LR: 0.000019  \n","Epoch: [1][4400/5703] Elapsed 14m 43s (remain 4m 21s) Loss: 0.0001(0.0055) Grad: 106.6116  LR: 0.000019  \n","Epoch: [1][4500/5703] Elapsed 15m 3s (remain 4m 1s) Loss: 0.0000(0.0054) Grad: 12.7802  LR: 0.000019  \n","Epoch: [1][4600/5703] Elapsed 15m 23s (remain 3m 41s) Loss: 0.0000(0.0054) Grad: 35.3903  LR: 0.000019  \n","Epoch: [1][4700/5703] Elapsed 15m 43s (remain 3m 21s) Loss: 0.0005(0.0053) Grad: 375.7861  LR: 0.000019  \n","Epoch: [1][4800/5703] Elapsed 16m 3s (remain 3m 1s) Loss: 0.0071(0.0052) Grad: 4105.6011  LR: 0.000018  \n","Epoch: [1][4900/5703] Elapsed 16m 23s (remain 2m 40s) Loss: 0.0001(0.0051) Grad: 100.5678  LR: 0.000018  \n","Epoch: [1][5000/5703] Elapsed 16m 43s (remain 2m 20s) Loss: 0.0000(0.0051) Grad: 24.8842  LR: 0.000018  \n","Epoch: [1][5100/5703] Elapsed 17m 3s (remain 2m 0s) Loss: 0.0004(0.0050) Grad: 219.7236  LR: 0.000018  \n","Epoch: [1][5200/5703] Elapsed 17m 24s (remain 1m 40s) Loss: 0.0007(0.0049) Grad: 866.2477  LR: 0.000018  \n","Epoch: [1][5300/5703] Elapsed 17m 44s (remain 1m 20s) Loss: 0.0002(0.0049) Grad: 181.5290  LR: 0.000018  \n","Epoch: [1][5400/5703] Elapsed 18m 4s (remain 1m 0s) Loss: 0.0001(0.0048) Grad: 100.5875  LR: 0.000018  \n","Epoch: [1][5500/5703] Elapsed 18m 24s (remain 0m 40s) Loss: 0.0066(0.0048) Grad: 3086.8545  LR: 0.000018  \n","Epoch: [1][5600/5703] Elapsed 18m 44s (remain 0m 20s) Loss: 0.0004(0.0047) Grad: 185.6793  LR: 0.000018  \n","Epoch: [1][5700/5703] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0135(0.0047) Grad: 6581.6587  LR: 0.000018  \n","Epoch: [1][5702/5703] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0012(0.0046) Grad: 1739.3352  LR: 0.000018  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 8m 41s) Loss: 0.0002(0.0002) \n","EVAL: [100/1447] Elapsed 0m 7s (remain 1m 40s) Loss: 0.0007(0.0010) \n","EVAL: [200/1447] Elapsed 0m 14s (remain 1m 30s) Loss: 0.0025(0.0011) \n","EVAL: [300/1447] Elapsed 0m 22s (remain 1m 23s) Loss: 0.0020(0.0012) \n","EVAL: [400/1447] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0013) \n","EVAL: [500/1447] Elapsed 0m 36s (remain 1m 8s) Loss: 0.0002(0.0013) \n","EVAL: [600/1447] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0013) \n","EVAL: [700/1447] Elapsed 0m 50s (remain 0m 53s) Loss: 0.0000(0.0013) \n","EVAL: [800/1447] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0000(0.0014) \n","EVAL: [900/1447] Elapsed 1m 5s (remain 0m 39s) Loss: 0.0011(0.0015) \n","EVAL: [1000/1447] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0019(0.0015) \n","EVAL: [1100/1447] Elapsed 1m 19s (remain 0m 24s) Loss: 0.0004(0.0015) \n","EVAL: [1200/1447] Elapsed 1m 26s (remain 0m 17s) Loss: 0.0000(0.0015) \n","EVAL: [1300/1447] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0001(0.0014) \n","EVAL: [1400/1447] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0001(0.0014) \n","EVAL: [1446/1447] Elapsed 1m 43s (remain 0m 0s) Loss: 0.0001(0.0014) \n","Epoch 1 - avg_train_loss: 0.0046  avg_val_loss: 0.0014  time: 1253s\n","Epoch 1 - Score: 0.6909\n","Epoch 1 - Save Best Score: 0.6909 Model\n","Epoch: [2][0/5703] Elapsed 0m 0s (remain 47m 43s) Loss: 0.0003(0.0003) Grad: 1246.0175  LR: 0.000018  \n","Epoch: [2][100/5703] Elapsed 0m 21s (remain 20m 13s) Loss: 0.0006(0.0012) Grad: 1924.5385  LR: 0.000018  \n","Epoch: [2][200/5703] Elapsed 0m 42s (remain 19m 16s) Loss: 0.0001(0.0014) Grad: 309.8554  LR: 0.000018  \n","Epoch: [2][300/5703] Elapsed 1m 2s (remain 18m 40s) Loss: 0.0000(0.0012) Grad: 61.7462  LR: 0.000018  \n","Epoch: [2][400/5703] Elapsed 1m 22s (remain 18m 13s) Loss: 0.0000(0.0013) Grad: 208.5535  LR: 0.000017  \n","Epoch: [2][500/5703] Elapsed 1m 42s (remain 17m 48s) Loss: 0.0000(0.0012) Grad: 135.1621  LR: 0.000017  \n","Epoch: [2][600/5703] Elapsed 2m 3s (remain 17m 25s) Loss: 0.0004(0.0013) Grad: 1918.1146  LR: 0.000017  \n","Epoch: [2][700/5703] Elapsed 2m 23s (remain 17m 2s) Loss: 0.0002(0.0013) Grad: 883.2856  LR: 0.000017  \n","Epoch: [2][800/5703] Elapsed 2m 43s (remain 16m 40s) Loss: 0.0022(0.0013) Grad: 6566.4805  LR: 0.000017  \n","Epoch: [2][900/5703] Elapsed 3m 3s (remain 16m 19s) Loss: 0.0007(0.0013) Grad: 1830.5865  LR: 0.000017  \n","Epoch: [2][1000/5703] Elapsed 3m 23s (remain 15m 57s) Loss: 0.0000(0.0014) Grad: 229.9965  LR: 0.000017  \n","Epoch: [2][1100/5703] Elapsed 3m 44s (remain 15m 36s) Loss: 0.0002(0.0014) Grad: 696.4840  LR: 0.000017  \n","Epoch: [2][1200/5703] Elapsed 4m 4s (remain 15m 15s) Loss: 0.0006(0.0013) Grad: 2852.8518  LR: 0.000017  \n","Epoch: [2][1300/5703] Elapsed 4m 24s (remain 14m 55s) Loss: 0.0001(0.0013) Grad: 463.8547  LR: 0.000017  \n","Epoch: [2][1400/5703] Elapsed 4m 44s (remain 14m 34s) Loss: 0.0001(0.0013) Grad: 486.3352  LR: 0.000017  \n","Epoch: [2][1500/5703] Elapsed 5m 4s (remain 14m 13s) Loss: 0.0009(0.0013) Grad: 2437.3247  LR: 0.000017  \n","Epoch: [2][1600/5703] Elapsed 5m 25s (remain 13m 53s) Loss: 0.0000(0.0013) Grad: 18.8191  LR: 0.000017  \n","Epoch: [2][1700/5703] Elapsed 5m 45s (remain 13m 32s) Loss: 0.0050(0.0013) Grad: 13859.2754  LR: 0.000016  \n","Epoch: [2][1800/5703] Elapsed 6m 5s (remain 13m 12s) Loss: 0.0003(0.0013) Grad: 804.8655  LR: 0.000016  \n","Epoch: [2][1900/5703] Elapsed 6m 25s (remain 12m 51s) Loss: 0.0000(0.0013) Grad: 150.6671  LR: 0.000016  \n","Epoch: [2][2000/5703] Elapsed 6m 46s (remain 12m 31s) Loss: 0.0018(0.0013) Grad: 2823.3689  LR: 0.000016  \n","Epoch: [2][2100/5703] Elapsed 7m 6s (remain 12m 11s) Loss: 0.0000(0.0013) Grad: 197.2604  LR: 0.000016  \n","Epoch: [2][2200/5703] Elapsed 7m 26s (remain 11m 51s) Loss: 0.0000(0.0013) Grad: 51.7072  LR: 0.000016  \n","Epoch: [2][2300/5703] Elapsed 7m 47s (remain 11m 30s) Loss: 0.0133(0.0013) Grad: 35009.8281  LR: 0.000016  \n","Epoch: [2][2400/5703] Elapsed 8m 7s (remain 11m 10s) Loss: 0.0000(0.0013) Grad: 91.9962  LR: 0.000016  \n","Epoch: [2][2500/5703] Elapsed 8m 27s (remain 10m 50s) Loss: 0.0000(0.0013) Grad: 69.6868  LR: 0.000016  \n","Epoch: [2][2600/5703] Elapsed 8m 47s (remain 10m 29s) Loss: 0.0000(0.0013) Grad: 40.3491  LR: 0.000016  \n","Epoch: [2][2700/5703] Elapsed 9m 8s (remain 10m 9s) Loss: 0.0054(0.0013) Grad: 4716.9873  LR: 0.000016  \n","Epoch: [2][2800/5703] Elapsed 9m 28s (remain 9m 48s) Loss: 0.0002(0.0013) Grad: 598.6675  LR: 0.000016  \n","Epoch: [2][2900/5703] Elapsed 9m 48s (remain 9m 28s) Loss: 0.0000(0.0013) Grad: 45.9655  LR: 0.000016  \n","Epoch: [2][3000/5703] Elapsed 10m 9s (remain 9m 8s) Loss: 0.0008(0.0013) Grad: 3054.5046  LR: 0.000015  \n","Epoch: [2][3100/5703] Elapsed 10m 29s (remain 8m 48s) Loss: 0.0119(0.0013) Grad: 34719.5781  LR: 0.000015  \n","Epoch: [2][3200/5703] Elapsed 10m 49s (remain 8m 27s) Loss: 0.0000(0.0013) Grad: 47.2265  LR: 0.000015  \n","Epoch: [2][3300/5703] Elapsed 11m 9s (remain 8m 7s) Loss: 0.0006(0.0013) Grad: 2017.7335  LR: 0.000015  \n","Epoch: [2][3400/5703] Elapsed 11m 30s (remain 7m 47s) Loss: 0.0002(0.0013) Grad: 645.2825  LR: 0.000015  \n","Epoch: [2][3500/5703] Elapsed 11m 50s (remain 7m 26s) Loss: 0.0000(0.0013) Grad: 26.2637  LR: 0.000015  \n","Epoch: [2][3600/5703] Elapsed 12m 10s (remain 7m 6s) Loss: 0.0017(0.0013) Grad: 5089.5786  LR: 0.000015  \n","Epoch: [2][3700/5703] Elapsed 12m 30s (remain 6m 46s) Loss: 0.0011(0.0013) Grad: 2043.9928  LR: 0.000015  \n","Epoch: [2][3800/5703] Elapsed 12m 51s (remain 6m 25s) Loss: 0.0002(0.0013) Grad: 535.0312  LR: 0.000015  \n","Epoch: [2][3900/5703] Elapsed 13m 11s (remain 6m 5s) Loss: 0.0013(0.0013) Grad: 5258.3652  LR: 0.000015  \n","Epoch: [2][4000/5703] Elapsed 13m 31s (remain 5m 45s) Loss: 0.0002(0.0013) Grad: 990.5670  LR: 0.000015  \n","Epoch: [2][4100/5703] Elapsed 13m 51s (remain 5m 24s) Loss: 0.0001(0.0013) Grad: 426.4201  LR: 0.000015  \n","Epoch: [2][4200/5703] Elapsed 14m 12s (remain 5m 4s) Loss: 0.0001(0.0013) Grad: 1280.1016  LR: 0.000015  \n","Epoch: [2][4300/5703] Elapsed 14m 32s (remain 4m 44s) Loss: 0.0037(0.0013) Grad: 75483.6094  LR: 0.000014  \n","Epoch: [2][4400/5703] Elapsed 14m 52s (remain 4m 24s) Loss: 0.0000(0.0013) Grad: 74.8063  LR: 0.000014  \n","Epoch: [2][4500/5703] Elapsed 15m 12s (remain 4m 3s) Loss: 0.0000(0.0013) Grad: 171.9254  LR: 0.000014  \n","Epoch: [2][4600/5703] Elapsed 15m 32s (remain 3m 43s) Loss: 0.0037(0.0013) Grad: 21707.2695  LR: 0.000014  \n","Epoch: [2][4700/5703] Elapsed 15m 53s (remain 3m 23s) Loss: 0.0001(0.0013) Grad: 511.5203  LR: 0.000014  \n","Epoch: [2][4800/5703] Elapsed 16m 13s (remain 3m 2s) Loss: 0.0031(0.0013) Grad: 5251.9976  LR: 0.000014  \n","Epoch: [2][4900/5703] Elapsed 16m 33s (remain 2m 42s) Loss: 0.0005(0.0013) Grad: 1121.3318  LR: 0.000014  \n","Epoch: [2][5000/5703] Elapsed 16m 53s (remain 2m 22s) Loss: 0.0000(0.0013) Grad: 6.3678  LR: 0.000014  \n","Epoch: [2][5100/5703] Elapsed 17m 14s (remain 2m 2s) Loss: 0.0000(0.0013) Grad: 7.3439  LR: 0.000014  \n","Epoch: [2][5200/5703] Elapsed 17m 34s (remain 1m 41s) Loss: 0.0015(0.0013) Grad: 3010.0959  LR: 0.000014  \n","Epoch: [2][5300/5703] Elapsed 17m 54s (remain 1m 21s) Loss: 0.0024(0.0013) Grad: 9164.3262  LR: 0.000014  \n","Epoch: [2][5400/5703] Elapsed 18m 14s (remain 1m 1s) Loss: 0.0000(0.0013) Grad: 278.8300  LR: 0.000014  \n","Epoch: [2][5500/5703] Elapsed 18m 34s (remain 0m 40s) Loss: 0.0000(0.0013) Grad: 42.7166  LR: 0.000013  \n","Epoch: [2][5600/5703] Elapsed 18m 55s (remain 0m 20s) Loss: 0.0004(0.0013) Grad: 5456.5781  LR: 0.000013  \n","Epoch: [2][5700/5703] Elapsed 19m 15s (remain 0m 0s) Loss: 0.0004(0.0013) Grad: 1684.8149  LR: 0.000013  \n","Epoch: [2][5702/5703] Elapsed 19m 15s (remain 0m 0s) Loss: 0.0005(0.0013) Grad: 1913.6671  LR: 0.000013  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 8m 33s) Loss: 0.0002(0.0002) \n","EVAL: [100/1447] Elapsed 0m 7s (remain 1m 39s) Loss: 0.0011(0.0011) \n","EVAL: [200/1447] Elapsed 0m 14s (remain 1m 30s) Loss: 0.0009(0.0013) \n","EVAL: [300/1447] Elapsed 0m 21s (remain 1m 23s) Loss: 0.0025(0.0014) \n","EVAL: [400/1447] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0015) \n","EVAL: [500/1447] Elapsed 0m 36s (remain 1m 8s) Loss: 0.0000(0.0015) \n","EVAL: [600/1447] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0014) \n","EVAL: [700/1447] Elapsed 0m 50s (remain 0m 54s) Loss: 0.0000(0.0015) \n","EVAL: [800/1447] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0000(0.0015) \n","EVAL: [900/1447] Elapsed 1m 5s (remain 0m 39s) Loss: 0.0017(0.0016) \n","EVAL: [1000/1447] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0023(0.0016) \n","EVAL: [1100/1447] Elapsed 1m 19s (remain 0m 25s) Loss: 0.0001(0.0016) \n","EVAL: [1200/1447] Elapsed 1m 26s (remain 0m 17s) Loss: 0.0002(0.0016) \n","EVAL: [1300/1447] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0000(0.0015) \n","EVAL: [1400/1447] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0000(0.0014) \n","EVAL: [1446/1447] Elapsed 1m 44s (remain 0m 0s) Loss: 0.0000(0.0014) \n","Epoch 2 - avg_train_loss: 0.0013  avg_val_loss: 0.0014  time: 1264s\n","Epoch 2 - Score: 0.7115\n","Epoch 2 - Save Best Score: 0.7115 Model\n","Epoch: [3][0/5703] Elapsed 0m 0s (remain 46m 57s) Loss: 0.0001(0.0001) Grad: 1083.6587  LR: 0.000013  \n","Epoch: [3][100/5703] Elapsed 0m 21s (remain 19m 53s) Loss: 0.0001(0.0006) Grad: 393.1617  LR: 0.000013  \n","Epoch: [3][200/5703] Elapsed 0m 41s (remain 19m 2s) Loss: 0.0021(0.0006) Grad: 4627.7036  LR: 0.000013  \n","Epoch: [3][300/5703] Elapsed 1m 1s (remain 18m 27s) Loss: 0.0000(0.0009) Grad: 150.0142  LR: 0.000013  \n","Epoch: [3][400/5703] Elapsed 1m 21s (remain 18m 0s) Loss: 0.0000(0.0009) Grad: 54.7059  LR: 0.000013  \n","Epoch: [3][500/5703] Elapsed 1m 41s (remain 17m 36s) Loss: 0.0002(0.0009) Grad: 556.1824  LR: 0.000013  \n","Epoch: [3][600/5703] Elapsed 2m 1s (remain 17m 14s) Loss: 0.0000(0.0009) Grad: 189.3862  LR: 0.000013  \n","Epoch: [3][700/5703] Elapsed 2m 21s (remain 16m 52s) Loss: 0.0000(0.0009) Grad: 323.0490  LR: 0.000013  \n","Epoch: [3][800/5703] Elapsed 2m 41s (remain 16m 30s) Loss: 0.0002(0.0010) Grad: 1529.4890  LR: 0.000013  \n","Epoch: [3][900/5703] Elapsed 3m 1s (remain 16m 9s) Loss: 0.0017(0.0010) Grad: 7849.7012  LR: 0.000013  \n","Epoch: [3][1000/5703] Elapsed 3m 21s (remain 15m 48s) Loss: 0.0004(0.0010) Grad: 1644.0999  LR: 0.000013  \n","Epoch: [3][1100/5703] Elapsed 3m 41s (remain 15m 27s) Loss: 0.0000(0.0010) Grad: 48.3886  LR: 0.000012  \n","Epoch: [3][1200/5703] Elapsed 4m 1s (remain 15m 7s) Loss: 0.0000(0.0010) Grad: 19.3455  LR: 0.000012  \n","Epoch: [3][1300/5703] Elapsed 4m 22s (remain 14m 46s) Loss: 0.0000(0.0010) Grad: 308.8985  LR: 0.000012  \n","Epoch: [3][1400/5703] Elapsed 4m 42s (remain 14m 26s) Loss: 0.0000(0.0010) Grad: 87.2234  LR: 0.000012  \n","Epoch: [3][1500/5703] Elapsed 5m 2s (remain 14m 6s) Loss: 0.0000(0.0010) Grad: 14.5859  LR: 0.000012  \n","Epoch: [3][1600/5703] Elapsed 5m 22s (remain 13m 45s) Loss: 0.0000(0.0010) Grad: 10.4301  LR: 0.000012  \n","Epoch: [3][1700/5703] Elapsed 5m 42s (remain 13m 25s) Loss: 0.0007(0.0010) Grad: 3340.1294  LR: 0.000012  \n","Epoch: [3][1800/5703] Elapsed 6m 2s (remain 13m 5s) Loss: 0.0000(0.0010) Grad: 254.4027  LR: 0.000012  \n","Epoch: [3][1900/5703] Elapsed 6m 22s (remain 12m 44s) Loss: 0.0025(0.0010) Grad: 6845.2461  LR: 0.000012  \n","Epoch: [3][2000/5703] Elapsed 6m 42s (remain 12m 24s) Loss: 0.0004(0.0010) Grad: 1146.5836  LR: 0.000012  \n","Epoch: [3][2100/5703] Elapsed 7m 2s (remain 12m 4s) Loss: 0.0004(0.0010) Grad: 1142.0437  LR: 0.000012  \n","Epoch: [3][2200/5703] Elapsed 7m 22s (remain 11m 44s) Loss: 0.0001(0.0010) Grad: 499.9894  LR: 0.000012  \n","Epoch: [3][2300/5703] Elapsed 7m 42s (remain 11m 24s) Loss: 0.0009(0.0010) Grad: 3993.2878  LR: 0.000012  \n","Epoch: [3][2400/5703] Elapsed 8m 2s (remain 11m 3s) Loss: 0.0004(0.0010) Grad: 2170.3655  LR: 0.000011  \n","Epoch: [3][2500/5703] Elapsed 8m 22s (remain 10m 43s) Loss: 0.0000(0.0010) Grad: 6.4688  LR: 0.000011  \n","Epoch: [3][2600/5703] Elapsed 8m 42s (remain 10m 23s) Loss: 0.0000(0.0010) Grad: 82.5763  LR: 0.000011  \n","Epoch: [3][2700/5703] Elapsed 9m 2s (remain 10m 3s) Loss: 0.0000(0.0010) Grad: 13.4020  LR: 0.000011  \n","Epoch: [3][2800/5703] Elapsed 9m 22s (remain 9m 43s) Loss: 0.0056(0.0010) Grad: 5292.7739  LR: 0.000011  \n","Epoch: [3][2900/5703] Elapsed 9m 42s (remain 9m 23s) Loss: 0.0005(0.0010) Grad: 1175.8628  LR: 0.000011  \n","Epoch: [3][3000/5703] Elapsed 10m 3s (remain 9m 2s) Loss: 0.0060(0.0010) Grad: 17392.3711  LR: 0.000011  \n","Epoch: [3][3100/5703] Elapsed 10m 23s (remain 8m 42s) Loss: 0.0000(0.0010) Grad: 17.9558  LR: 0.000011  \n","Epoch: [3][3200/5703] Elapsed 10m 43s (remain 8m 22s) Loss: 0.0000(0.0010) Grad: 30.6726  LR: 0.000011  \n","Epoch: [3][3300/5703] Elapsed 11m 3s (remain 8m 2s) Loss: 0.0001(0.0011) Grad: 1616.0461  LR: 0.000011  \n","Epoch: [3][3400/5703] Elapsed 11m 23s (remain 7m 42s) Loss: 0.0002(0.0010) Grad: 932.3948  LR: 0.000011  \n","Epoch: [3][3500/5703] Elapsed 11m 43s (remain 7m 22s) Loss: 0.0004(0.0010) Grad: 1223.8093  LR: 0.000011  \n","Epoch: [3][3600/5703] Elapsed 12m 3s (remain 7m 2s) Loss: 0.0001(0.0010) Grad: 752.8167  LR: 0.000011  \n","Epoch: [3][3700/5703] Elapsed 12m 23s (remain 6m 42s) Loss: 0.0002(0.0010) Grad: 1064.6949  LR: 0.000010  \n","Epoch: [3][3800/5703] Elapsed 12m 43s (remain 6m 22s) Loss: 0.0048(0.0010) Grad: 8240.8789  LR: 0.000010  \n","Epoch: [3][3900/5703] Elapsed 13m 3s (remain 6m 2s) Loss: 0.0000(0.0010) Grad: 46.0449  LR: 0.000010  \n","Epoch: [3][4000/5703] Elapsed 13m 23s (remain 5m 42s) Loss: 0.0000(0.0010) Grad: 38.8649  LR: 0.000010  \n","Epoch: [3][4100/5703] Elapsed 13m 44s (remain 5m 21s) Loss: 0.0003(0.0010) Grad: 2740.7505  LR: 0.000010  \n","Epoch: [3][4200/5703] Elapsed 14m 4s (remain 5m 1s) Loss: 0.0000(0.0011) Grad: 17.5614  LR: 0.000010  \n","Epoch: [3][4300/5703] Elapsed 14m 24s (remain 4m 41s) Loss: 0.0001(0.0010) Grad: 326.6380  LR: 0.000010  \n","Epoch: [3][4400/5703] Elapsed 14m 44s (remain 4m 21s) Loss: 0.0000(0.0011) Grad: 70.9803  LR: 0.000010  \n","Epoch: [3][4500/5703] Elapsed 15m 4s (remain 4m 1s) Loss: 0.0096(0.0011) Grad: 13044.5869  LR: 0.000010  \n","Epoch: [3][4600/5703] Elapsed 15m 24s (remain 3m 41s) Loss: 0.0000(0.0010) Grad: 8.4177  LR: 0.000010  \n","Epoch: [3][4700/5703] Elapsed 15m 44s (remain 3m 21s) Loss: 0.0024(0.0011) Grad: 8021.3208  LR: 0.000010  \n","Epoch: [3][4800/5703] Elapsed 16m 4s (remain 3m 1s) Loss: 0.0006(0.0011) Grad: 1453.6875  LR: 0.000010  \n","Epoch: [3][4900/5703] Elapsed 16m 24s (remain 2m 41s) Loss: 0.0000(0.0010) Grad: 71.3613  LR: 0.000010  \n","Epoch: [3][5000/5703] Elapsed 16m 44s (remain 2m 21s) Loss: 0.0000(0.0010) Grad: 10.3528  LR: 0.000009  \n","Epoch: [3][5100/5703] Elapsed 17m 4s (remain 2m 0s) Loss: 0.0001(0.0010) Grad: 414.1661  LR: 0.000009  \n","Epoch: [3][5200/5703] Elapsed 17m 24s (remain 1m 40s) Loss: 0.0000(0.0010) Grad: 45.0965  LR: 0.000009  \n","Epoch: [3][5300/5703] Elapsed 17m 44s (remain 1m 20s) Loss: 0.0002(0.0010) Grad: 478.4082  LR: 0.000009  \n","Epoch: [3][5400/5703] Elapsed 18m 5s (remain 1m 0s) Loss: 0.0001(0.0010) Grad: 359.9720  LR: 0.000009  \n","Epoch: [3][5500/5703] Elapsed 18m 25s (remain 0m 40s) Loss: 0.0003(0.0010) Grad: 3015.4314  LR: 0.000009  \n","Epoch: [3][5600/5703] Elapsed 18m 45s (remain 0m 20s) Loss: 0.0000(0.0010) Grad: 15.0217  LR: 0.000009  \n","Epoch: [3][5700/5703] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0000(0.0010) Grad: 19.5943  LR: 0.000009  \n","Epoch: [3][5702/5703] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0001(0.0010) Grad: 1134.4156  LR: 0.000009  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 8m 31s) Loss: 0.0000(0.0000) \n","EVAL: [100/1447] Elapsed 0m 7s (remain 1m 40s) Loss: 0.0011(0.0014) \n","EVAL: [200/1447] Elapsed 0m 14s (remain 1m 31s) Loss: 0.0008(0.0014) \n","EVAL: [300/1447] Elapsed 0m 22s (remain 1m 24s) Loss: 0.0026(0.0014) \n","EVAL: [400/1447] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0015) \n","EVAL: [500/1447] Elapsed 0m 36s (remain 1m 9s) Loss: 0.0000(0.0015) \n","EVAL: [600/1447] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0015) \n","EVAL: [700/1447] Elapsed 0m 50s (remain 0m 54s) Loss: 0.0000(0.0015) \n","EVAL: [800/1447] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0000(0.0015) \n","EVAL: [900/1447] Elapsed 1m 5s (remain 0m 39s) Loss: 0.0023(0.0017) \n","EVAL: [1000/1447] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0014(0.0017) \n","EVAL: [1100/1447] Elapsed 1m 19s (remain 0m 24s) Loss: 0.0001(0.0017) \n","EVAL: [1200/1447] Elapsed 1m 26s (remain 0m 17s) Loss: 0.0000(0.0016) \n","EVAL: [1300/1447] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0000(0.0015) \n","EVAL: [1400/1447] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0000(0.0015) \n","EVAL: [1446/1447] Elapsed 1m 43s (remain 0m 0s) Loss: 0.0000(0.0014) \n","Epoch 3 - avg_train_loss: 0.0010  avg_val_loss: 0.0014  time: 1253s\n","Epoch 3 - Score: 0.7337\n","Epoch 3 - Save Best Score: 0.7337 Model\n","Epoch: [4][0/5703] Elapsed 0m 0s (remain 47m 40s) Loss: 0.0000(0.0000) Grad: 1006.8167  LR: 0.000009  \n","Epoch: [4][100/5703] Elapsed 0m 21s (remain 19m 26s) Loss: 0.0025(0.0006) Grad: 5494.3389  LR: 0.000009  \n","Epoch: [4][200/5703] Elapsed 0m 41s (remain 18m 45s) Loss: 0.0017(0.0007) Grad: 8909.9912  LR: 0.000009  \n","Epoch: [4][300/5703] Elapsed 1m 1s (remain 18m 18s) Loss: 0.0015(0.0007) Grad: 13152.6494  LR: 0.000009  \n","Epoch: [4][400/5703] Elapsed 1m 21s (remain 17m 55s) Loss: 0.0003(0.0007) Grad: 1306.0823  LR: 0.000009  \n","Epoch: [4][500/5703] Elapsed 1m 41s (remain 17m 33s) Loss: 0.0001(0.0009) Grad: 595.0585  LR: 0.000008  \n","Epoch: [4][600/5703] Elapsed 2m 1s (remain 17m 10s) Loss: 0.0000(0.0008) Grad: 29.1071  LR: 0.000008  \n","Epoch: [4][700/5703] Elapsed 2m 21s (remain 16m 49s) Loss: 0.0000(0.0008) Grad: 95.4028  LR: 0.000008  \n","Epoch: [4][800/5703] Elapsed 2m 41s (remain 16m 29s) Loss: 0.0015(0.0008) Grad: 4990.6089  LR: 0.000008  \n","Epoch: [4][900/5703] Elapsed 3m 1s (remain 16m 9s) Loss: 0.0000(0.0008) Grad: 16.3773  LR: 0.000008  \n","Epoch: [4][1000/5703] Elapsed 3m 22s (remain 15m 49s) Loss: 0.0000(0.0008) Grad: 144.7793  LR: 0.000008  \n","Epoch: [4][1100/5703] Elapsed 3m 42s (remain 15m 28s) Loss: 0.0000(0.0008) Grad: 5.9826  LR: 0.000008  \n","Epoch: [4][1200/5703] Elapsed 4m 2s (remain 15m 7s) Loss: 0.0002(0.0008) Grad: 543.6144  LR: 0.000008  \n","Epoch: [4][1300/5703] Elapsed 4m 22s (remain 14m 47s) Loss: 0.0000(0.0008) Grad: 5.4014  LR: 0.000008  \n","Epoch: [4][1400/5703] Elapsed 4m 42s (remain 14m 27s) Loss: 0.0000(0.0008) Grad: 38.5881  LR: 0.000008  \n","Epoch: [4][1500/5703] Elapsed 5m 2s (remain 14m 6s) Loss: 0.0039(0.0008) Grad: 17612.5352  LR: 0.000008  \n","Epoch: [4][1600/5703] Elapsed 5m 22s (remain 13m 46s) Loss: 0.0002(0.0008) Grad: 2306.5767  LR: 0.000008  \n","Epoch: [4][1700/5703] Elapsed 5m 42s (remain 13m 26s) Loss: 0.0000(0.0008) Grad: 41.9738  LR: 0.000008  \n","Epoch: [4][1800/5703] Elapsed 6m 2s (remain 13m 5s) Loss: 0.0000(0.0008) Grad: 177.8649  LR: 0.000007  \n","Epoch: [4][1900/5703] Elapsed 6m 22s (remain 12m 45s) Loss: 0.0000(0.0008) Grad: 4.7751  LR: 0.000007  \n","Epoch: [4][2000/5703] Elapsed 6m 42s (remain 12m 24s) Loss: 0.0051(0.0008) Grad: 14444.5127  LR: 0.000007  \n","Epoch: [4][2100/5703] Elapsed 7m 2s (remain 12m 4s) Loss: 0.0000(0.0008) Grad: 46.7069  LR: 0.000007  \n","Epoch: [4][2200/5703] Elapsed 7m 22s (remain 11m 44s) Loss: 0.0005(0.0008) Grad: 3636.9102  LR: 0.000007  \n","Epoch: [4][2300/5703] Elapsed 7m 42s (remain 11m 24s) Loss: 0.0035(0.0008) Grad: 5728.0698  LR: 0.000007  \n","Epoch: [4][2400/5703] Elapsed 8m 2s (remain 11m 3s) Loss: 0.0000(0.0008) Grad: 91.5426  LR: 0.000007  \n","Epoch: [4][2500/5703] Elapsed 8m 22s (remain 10m 43s) Loss: 0.0068(0.0008) Grad: 25856.4980  LR: 0.000007  \n","Epoch: [4][2600/5703] Elapsed 8m 42s (remain 10m 23s) Loss: 0.0003(0.0008) Grad: 1431.2268  LR: 0.000007  \n","Epoch: [4][2700/5703] Elapsed 9m 2s (remain 10m 3s) Loss: 0.0001(0.0008) Grad: 974.8333  LR: 0.000007  \n","Epoch: [4][2800/5703] Elapsed 9m 23s (remain 9m 43s) Loss: 0.0000(0.0008) Grad: 447.6133  LR: 0.000007  \n","Epoch: [4][2900/5703] Elapsed 9m 43s (remain 9m 23s) Loss: 0.0132(0.0008) Grad: 24239.0352  LR: 0.000007  \n","Epoch: [4][3000/5703] Elapsed 10m 2s (remain 9m 2s) Loss: 0.0000(0.0008) Grad: 314.9695  LR: 0.000007  \n","Epoch: [4][3100/5703] Elapsed 10m 22s (remain 8m 42s) Loss: 0.0004(0.0008) Grad: 2478.2112  LR: 0.000006  \n","Epoch: [4][3200/5703] Elapsed 10m 43s (remain 8m 22s) Loss: 0.0015(0.0008) Grad: 6499.1416  LR: 0.000006  \n","Epoch: [4][3300/5703] Elapsed 11m 3s (remain 8m 2s) Loss: 0.0000(0.0008) Grad: 2.2395  LR: 0.000006  \n","Epoch: [4][3400/5703] Elapsed 11m 23s (remain 7m 42s) Loss: 0.0001(0.0008) Grad: 1786.1167  LR: 0.000006  \n","Epoch: [4][3500/5703] Elapsed 11m 43s (remain 7m 22s) Loss: 0.0026(0.0008) Grad: 6688.3350  LR: 0.000006  \n","Epoch: [4][3600/5703] Elapsed 12m 3s (remain 7m 2s) Loss: 0.0009(0.0008) Grad: 2905.0679  LR: 0.000006  \n","Epoch: [4][3700/5703] Elapsed 12m 23s (remain 6m 42s) Loss: 0.0000(0.0008) Grad: 24.9351  LR: 0.000006  \n","Epoch: [4][3800/5703] Elapsed 12m 43s (remain 6m 22s) Loss: 0.0000(0.0008) Grad: 22.0697  LR: 0.000006  \n","Epoch: [4][3900/5703] Elapsed 13m 3s (remain 6m 2s) Loss: 0.0000(0.0008) Grad: 48.2880  LR: 0.000006  \n","Epoch: [4][4000/5703] Elapsed 13m 23s (remain 5m 41s) Loss: 0.0000(0.0008) Grad: 79.0436  LR: 0.000006  \n","Epoch: [4][4100/5703] Elapsed 13m 43s (remain 5m 21s) Loss: 0.0002(0.0008) Grad: 829.4857  LR: 0.000006  \n","Epoch: [4][4200/5703] Elapsed 14m 3s (remain 5m 1s) Loss: 0.0001(0.0008) Grad: 842.6249  LR: 0.000006  \n","Epoch: [4][4300/5703] Elapsed 14m 23s (remain 4m 41s) Loss: 0.0001(0.0008) Grad: 344.3026  LR: 0.000006  \n","Epoch: [4][4400/5703] Elapsed 14m 43s (remain 4m 21s) Loss: 0.0000(0.0008) Grad: 24.1918  LR: 0.000005  \n","Epoch: [4][4500/5703] Elapsed 15m 3s (remain 4m 1s) Loss: 0.0003(0.0008) Grad: 1773.2108  LR: 0.000005  \n","Epoch: [4][4600/5703] Elapsed 15m 24s (remain 3m 41s) Loss: 0.0001(0.0008) Grad: 927.0751  LR: 0.000005  \n","Epoch: [4][4700/5703] Elapsed 15m 43s (remain 3m 21s) Loss: 0.0000(0.0008) Grad: 46.7049  LR: 0.000005  \n","Epoch: [4][4800/5703] Elapsed 16m 3s (remain 3m 1s) Loss: 0.0001(0.0008) Grad: 336.7839  LR: 0.000005  \n","Epoch: [4][4900/5703] Elapsed 16m 23s (remain 2m 41s) Loss: 0.0000(0.0008) Grad: 8.4367  LR: 0.000005  \n","Epoch: [4][5000/5703] Elapsed 16m 44s (remain 2m 20s) Loss: 0.0001(0.0008) Grad: 276.5797  LR: 0.000005  \n","Epoch: [4][5100/5703] Elapsed 17m 4s (remain 2m 0s) Loss: 0.0015(0.0008) Grad: 4111.5625  LR: 0.000005  \n","Epoch: [4][5200/5703] Elapsed 17m 24s (remain 1m 40s) Loss: 0.0000(0.0008) Grad: 7.9209  LR: 0.000005  \n","Epoch: [4][5300/5703] Elapsed 17m 44s (remain 1m 20s) Loss: 0.0003(0.0008) Grad: 1871.8563  LR: 0.000005  \n","Epoch: [4][5400/5703] Elapsed 18m 4s (remain 1m 0s) Loss: 0.0001(0.0008) Grad: 588.5142  LR: 0.000005  \n","Epoch: [4][5500/5703] Elapsed 18m 24s (remain 0m 40s) Loss: 0.0005(0.0008) Grad: 1647.3503  LR: 0.000005  \n","Epoch: [4][5600/5703] Elapsed 18m 44s (remain 0m 20s) Loss: 0.0001(0.0008) Grad: 480.3890  LR: 0.000005  \n","Epoch: [4][5700/5703] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0000(0.0008) Grad: 37.2051  LR: 0.000004  \n","Epoch: [4][5702/5703] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0000(0.0008) Grad: 489.1584  LR: 0.000004  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 8m 36s) Loss: 0.0001(0.0001) \n","EVAL: [100/1447] Elapsed 0m 7s (remain 1m 39s) Loss: 0.0011(0.0015) \n","EVAL: [200/1447] Elapsed 0m 14s (remain 1m 30s) Loss: 0.0007(0.0016) \n","EVAL: [300/1447] Elapsed 0m 21s (remain 1m 23s) Loss: 0.0025(0.0015) \n","EVAL: [400/1447] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0016) \n","EVAL: [500/1447] Elapsed 0m 36s (remain 1m 8s) Loss: 0.0000(0.0017) \n","EVAL: [600/1447] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0017) \n","EVAL: [700/1447] Elapsed 0m 50s (remain 0m 53s) Loss: 0.0000(0.0016) \n","EVAL: [800/1447] Elapsed 0m 57s (remain 0m 46s) Loss: 0.0000(0.0017) \n","EVAL: [900/1447] Elapsed 1m 5s (remain 0m 39s) Loss: 0.0021(0.0018) \n","EVAL: [1000/1447] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0013(0.0018) \n","EVAL: [1100/1447] Elapsed 1m 19s (remain 0m 24s) Loss: 0.0001(0.0018) \n","EVAL: [1200/1447] Elapsed 1m 26s (remain 0m 17s) Loss: 0.0038(0.0017) \n","EVAL: [1300/1447] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0000(0.0017) \n","EVAL: [1400/1447] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0000(0.0016) \n","EVAL: [1446/1447] Elapsed 1m 43s (remain 0m 0s) Loss: 0.0000(0.0016) \n","Epoch 4 - avg_train_loss: 0.0008  avg_val_loss: 0.0016  time: 1252s\n","Epoch 4 - Score: 0.7319\n","Epoch: [5][0/5703] Elapsed 0m 0s (remain 47m 17s) Loss: 0.0009(0.0009) Grad: 3514.3013  LR: 0.000004  \n","Epoch: [5][100/5703] Elapsed 0m 20s (remain 19m 6s) Loss: 0.0002(0.0008) Grad: 1503.1697  LR: 0.000004  \n","Epoch: [5][200/5703] Elapsed 0m 40s (remain 18m 37s) Loss: 0.0000(0.0005) Grad: 5.0043  LR: 0.000004  \n","Epoch: [5][300/5703] Elapsed 1m 0s (remain 18m 14s) Loss: 0.0024(0.0007) Grad: 7547.3970  LR: 0.000004  \n","Epoch: [5][400/5703] Elapsed 1m 21s (remain 17m 53s) Loss: 0.0019(0.0006) Grad: 5469.3799  LR: 0.000004  \n","Epoch: [5][500/5703] Elapsed 1m 41s (remain 17m 33s) Loss: 0.0001(0.0007) Grad: 588.5713  LR: 0.000004  \n","Epoch: [5][600/5703] Elapsed 2m 1s (remain 17m 12s) Loss: 0.0000(0.0007) Grad: 74.8527  LR: 0.000004  \n","Epoch: [5][700/5703] Elapsed 2m 21s (remain 16m 52s) Loss: 0.0001(0.0007) Grad: 583.2745  LR: 0.000004  \n","Epoch: [5][800/5703] Elapsed 2m 42s (remain 16m 31s) Loss: 0.0005(0.0007) Grad: 3167.1843  LR: 0.000004  \n","Epoch: [5][900/5703] Elapsed 3m 2s (remain 16m 11s) Loss: 0.0001(0.0007) Grad: 344.7344  LR: 0.000004  \n","Epoch: [5][1000/5703] Elapsed 3m 22s (remain 15m 51s) Loss: 0.0001(0.0007) Grad: 320.0934  LR: 0.000004  \n","Epoch: [5][1100/5703] Elapsed 3m 42s (remain 15m 30s) Loss: 0.0000(0.0007) Grad: 118.1572  LR: 0.000004  \n","Epoch: [5][1200/5703] Elapsed 4m 2s (remain 15m 10s) Loss: 0.0003(0.0007) Grad: 1289.9072  LR: 0.000004  \n","Epoch: [5][1300/5703] Elapsed 4m 23s (remain 14m 50s) Loss: 0.0008(0.0007) Grad: 3329.8364  LR: 0.000003  \n","Epoch: [5][1400/5703] Elapsed 4m 43s (remain 14m 29s) Loss: 0.0002(0.0007) Grad: 1842.0964  LR: 0.000003  \n","Epoch: [5][1500/5703] Elapsed 5m 3s (remain 14m 9s) Loss: 0.0003(0.0007) Grad: 1972.9008  LR: 0.000003  \n","Epoch: [5][1600/5703] Elapsed 5m 23s (remain 13m 49s) Loss: 0.0001(0.0006) Grad: 531.1556  LR: 0.000003  \n","Epoch: [5][1700/5703] Elapsed 5m 43s (remain 13m 28s) Loss: 0.0037(0.0007) Grad: 8737.3594  LR: 0.000003  \n","Epoch: [5][1800/5703] Elapsed 6m 4s (remain 13m 8s) Loss: 0.0000(0.0006) Grad: 6.3674  LR: 0.000003  \n","Epoch: [5][1900/5703] Elapsed 6m 24s (remain 12m 48s) Loss: 0.0004(0.0006) Grad: 2071.7080  LR: 0.000003  \n","Epoch: [5][2000/5703] Elapsed 6m 44s (remain 12m 28s) Loss: 0.0042(0.0006) Grad: 9010.3340  LR: 0.000003  \n","Epoch: [5][2100/5703] Elapsed 7m 4s (remain 12m 7s) Loss: 0.0001(0.0006) Grad: 520.9125  LR: 0.000003  \n","Epoch: [5][2200/5703] Elapsed 7m 24s (remain 11m 47s) Loss: 0.0002(0.0006) Grad: 1657.5760  LR: 0.000003  \n","Epoch: [5][2300/5703] Elapsed 7m 44s (remain 11m 27s) Loss: 0.0010(0.0006) Grad: 7212.2354  LR: 0.000003  \n","Epoch: [5][2400/5703] Elapsed 8m 5s (remain 11m 7s) Loss: 0.0001(0.0006) Grad: 531.8919  LR: 0.000003  \n","Epoch: [5][2500/5703] Elapsed 8m 25s (remain 10m 46s) Loss: 0.0006(0.0006) Grad: 1509.0277  LR: 0.000002  \n","Epoch: [5][2600/5703] Elapsed 8m 45s (remain 10m 26s) Loss: 0.0000(0.0006) Grad: 228.9961  LR: 0.000002  \n","Epoch: [5][2700/5703] Elapsed 9m 5s (remain 10m 6s) Loss: 0.0019(0.0006) Grad: 10056.1562  LR: 0.000002  \n","Epoch: [5][2800/5703] Elapsed 9m 26s (remain 9m 46s) Loss: 0.0004(0.0006) Grad: 1206.4379  LR: 0.000002  \n","Epoch: [5][2900/5703] Elapsed 9m 46s (remain 9m 26s) Loss: 0.0000(0.0006) Grad: 6.2266  LR: 0.000002  \n","Epoch: [5][3000/5703] Elapsed 10m 6s (remain 9m 6s) Loss: 0.0000(0.0006) Grad: 42.2440  LR: 0.000002  \n","Epoch: [5][3100/5703] Elapsed 10m 27s (remain 8m 46s) Loss: 0.0000(0.0006) Grad: 41.7968  LR: 0.000002  \n","Epoch: [5][3200/5703] Elapsed 10m 47s (remain 8m 25s) Loss: 0.0049(0.0006) Grad: 12132.5537  LR: 0.000002  \n","Epoch: [5][3300/5703] Elapsed 11m 7s (remain 8m 5s) Loss: 0.0000(0.0006) Grad: 43.8922  LR: 0.000002  \n","Epoch: [5][3400/5703] Elapsed 11m 27s (remain 7m 45s) Loss: 0.0003(0.0006) Grad: 929.9595  LR: 0.000002  \n","Epoch: [5][3500/5703] Elapsed 11m 48s (remain 7m 25s) Loss: 0.0061(0.0006) Grad: 14856.3750  LR: 0.000002  \n","Epoch: [5][3600/5703] Elapsed 12m 8s (remain 7m 5s) Loss: 0.0008(0.0006) Grad: 1618.9930  LR: 0.000002  \n","Epoch: [5][3700/5703] Elapsed 12m 28s (remain 6m 45s) Loss: 0.0001(0.0006) Grad: 1126.6339  LR: 0.000002  \n","Epoch: [5][3800/5703] Elapsed 12m 48s (remain 6m 24s) Loss: 0.0001(0.0006) Grad: 739.0271  LR: 0.000001  \n","Epoch: [5][3900/5703] Elapsed 13m 9s (remain 6m 4s) Loss: 0.0000(0.0006) Grad: 58.1064  LR: 0.000001  \n","Epoch: [5][4000/5703] Elapsed 13m 29s (remain 5m 44s) Loss: 0.0000(0.0006) Grad: 14.9237  LR: 0.000001  \n","Epoch: [5][4100/5703] Elapsed 13m 49s (remain 5m 24s) Loss: 0.0000(0.0006) Grad: 151.3900  LR: 0.000001  \n","Epoch: [5][4200/5703] Elapsed 14m 10s (remain 5m 3s) Loss: 0.0002(0.0006) Grad: 1389.8551  LR: 0.000001  \n","Epoch: [5][4300/5703] Elapsed 14m 30s (remain 4m 43s) Loss: 0.0000(0.0007) Grad: 4.3656  LR: 0.000001  \n","Epoch: [5][4400/5703] Elapsed 14m 50s (remain 4m 23s) Loss: 0.0000(0.0006) Grad: 256.0798  LR: 0.000001  \n","Epoch: [5][4500/5703] Elapsed 15m 10s (remain 4m 3s) Loss: 0.0000(0.0006) Grad: 33.4302  LR: 0.000001  \n","Epoch: [5][4600/5703] Elapsed 15m 30s (remain 3m 42s) Loss: 0.0000(0.0006) Grad: 6.8228  LR: 0.000001  \n","Epoch: [5][4700/5703] Elapsed 15m 51s (remain 3m 22s) Loss: 0.0000(0.0006) Grad: 228.3968  LR: 0.000001  \n","Epoch: [5][4800/5703] Elapsed 16m 11s (remain 3m 2s) Loss: 0.0000(0.0006) Grad: 3.5150  LR: 0.000001  \n","Epoch: [5][4900/5703] Elapsed 16m 31s (remain 2m 42s) Loss: 0.0001(0.0006) Grad: 440.5653  LR: 0.000001  \n","Epoch: [5][5000/5703] Elapsed 16m 51s (remain 2m 21s) Loss: 0.0015(0.0006) Grad: 18295.3711  LR: 0.000001  \n","Epoch: [5][5100/5703] Elapsed 17m 11s (remain 2m 1s) Loss: 0.0000(0.0006) Grad: 5.3533  LR: 0.000000  \n","Epoch: [5][5200/5703] Elapsed 17m 31s (remain 1m 41s) Loss: 0.0016(0.0006) Grad: 7635.6035  LR: 0.000000  \n","Epoch: [5][5300/5703] Elapsed 17m 51s (remain 1m 21s) Loss: 0.0106(0.0006) Grad: 28223.4980  LR: 0.000000  \n","Epoch: [5][5400/5703] Elapsed 18m 11s (remain 1m 1s) Loss: 0.0004(0.0006) Grad: 2347.1057  LR: 0.000000  \n","Epoch: [5][5500/5703] Elapsed 18m 32s (remain 0m 40s) Loss: 0.0000(0.0006) Grad: 17.6390  LR: 0.000000  \n","Epoch: [5][5600/5703] Elapsed 18m 52s (remain 0m 20s) Loss: 0.0000(0.0006) Grad: 19.5120  LR: 0.000000  \n","Epoch: [5][5700/5703] Elapsed 19m 12s (remain 0m 0s) Loss: 0.0000(0.0007) Grad: 6.8465  LR: 0.000000  \n","Epoch: [5][5702/5703] Elapsed 19m 13s (remain 0m 0s) Loss: 0.0000(0.0007) Grad: 293.5503  LR: 0.000000  \n","EVAL: [0/1447] Elapsed 0m 0s (remain 8m 24s) Loss: 0.0001(0.0001) \n","EVAL: [100/1447] Elapsed 0m 7s (remain 1m 40s) Loss: 0.0014(0.0015) \n","EVAL: [200/1447] Elapsed 0m 14s (remain 1m 31s) Loss: 0.0007(0.0017) \n","EVAL: [300/1447] Elapsed 0m 22s (remain 1m 24s) Loss: 0.0026(0.0017) \n","EVAL: [400/1447] Elapsed 0m 29s (remain 1m 16s) Loss: 0.0000(0.0018) \n","EVAL: [500/1447] Elapsed 0m 36s (remain 1m 9s) Loss: 0.0000(0.0019) \n","EVAL: [600/1447] Elapsed 0m 43s (remain 1m 1s) Loss: 0.0000(0.0019) \n","EVAL: [700/1447] Elapsed 0m 50s (remain 0m 54s) Loss: 0.0000(0.0018) \n","EVAL: [800/1447] Elapsed 0m 58s (remain 0m 46s) Loss: 0.0000(0.0018) \n","EVAL: [900/1447] Elapsed 1m 5s (remain 0m 39s) Loss: 0.0021(0.0020) \n","EVAL: [1000/1447] Elapsed 1m 12s (remain 0m 32s) Loss: 0.0007(0.0020) \n","EVAL: [1100/1447] Elapsed 1m 19s (remain 0m 25s) Loss: 0.0001(0.0020) \n","EVAL: [1200/1447] Elapsed 1m 26s (remain 0m 17s) Loss: 0.0001(0.0019) \n","EVAL: [1300/1447] Elapsed 1m 33s (remain 0m 10s) Loss: 0.0000(0.0018) \n","EVAL: [1400/1447] Elapsed 1m 40s (remain 0m 3s) Loss: 0.0000(0.0017) \n","EVAL: [1446/1447] Elapsed 1m 44s (remain 0m 0s) Loss: 0.0000(0.0017) \n","Epoch 5 - avg_train_loss: 0.0007  avg_val_loss: 0.0017  time: 1261s\n","Epoch 5 - Score: 0.7357\n","Epoch 5 - Save Best Score: 0.7357 Model\n","========== fold: 2 training ==========\n","Load weight from pretrained\n","Epoch: [1][0/5743] Elapsed 0m 0s (remain 49m 23s) Loss: 0.1053(0.1053) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/5743] Elapsed 0m 21s (remain 19m 51s) Loss: 0.1214(0.0708) Grad: 55188.3633  LR: 0.000001  \n","Epoch: [1][200/5743] Elapsed 0m 41s (remain 19m 1s) Loss: 0.0268(0.0611) Grad: 10797.1992  LR: 0.000001  \n","Epoch: [1][300/5743] Elapsed 1m 1s (remain 18m 31s) Loss: 0.0140(0.0491) Grad: 7822.4526  LR: 0.000002  \n","Epoch: [1][400/5743] Elapsed 1m 21s (remain 18m 7s) Loss: 0.0091(0.0389) Grad: 1715.6681  LR: 0.000003  \n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","name":"nbme-exp037.ipynb","provenance":[{"file_id":"1qwol903GhCTiow3XKBeeIsi5KaE1nBBA","timestamp":1646874544206},{"file_id":"1vgEPpbfdsmuzQojsPTUZHuy6nY-pyDBL","timestamp":1646828776868},{"file_id":"1hTEk26Dv4lh67pdHGaEsQ5C3Lpm9St9B","timestamp":1646827917764},{"file_id":"14l7vjaEJdKkFlJXP9EmrgKriPn4mqCbY","timestamp":1646539060597}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"612e4a1a771b4d659ef1b3db83054599":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_55fa8a639b4542398a797bc2f0f567bd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a744f1a3ba3b4fd1be1df10d85aa91e7","IPY_MODEL_d70036f5fae341f988dec16ddbdf41e6","IPY_MODEL_5a6129eda0c9449caa86b87fc391de28"]}},"55fa8a639b4542398a797bc2f0f567bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a744f1a3ba3b4fd1be1df10d85aa91e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67e9efb0715a44348398de8a895fdf84","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_048034f7c5544ed487124923e2dca3dc"}},"d70036f5fae341f988dec16ddbdf41e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_67cac14aeaee41929173b49032ef44d0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":153,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":153,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff875872fd2b4cefa62161c2f246dc7f"}},"5a6129eda0c9449caa86b87fc391de28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a78dedf799c94ff9a4b31b4fbf599a31","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 153/153 [00:00&lt;00:00, 5.75kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd9d0a8afcef48fb887252de480124b3"}},"67e9efb0715a44348398de8a895fdf84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"048034f7c5544ed487124923e2dca3dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67cac14aeaee41929173b49032ef44d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ff875872fd2b4cefa62161c2f246dc7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a78dedf799c94ff9a4b31b4fbf599a31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd9d0a8afcef48fb887252de480124b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"966960f2a29040b1af06fc5ac38757a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dd01876e868b458dbfab1bfd1d669a4c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c4ad8a36b54f465183ff56bc752fd283","IPY_MODEL_f00e93809bd54046812ecf34f237b66e","IPY_MODEL_6372dc68a39144208ecacc73c598a1ce"]}},"dd01876e868b458dbfab1bfd1d669a4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4ad8a36b54f465183ff56bc752fd283":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0311bed871884b899350ba23425e4419","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dfed55aea32f40dba0351e518ab140ce"}},"f00e93809bd54046812ecf34f237b66e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_96ac95b2289742e5ae0661af77b8a748","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":701,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":701,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_844181c2a5234b77901c450b36f29f2d"}},"6372dc68a39144208ecacc73c598a1ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_156f58c7eb714ea4bf66c4f4f39b1a64","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 701/701 [00:00&lt;00:00, 23.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_689c51fef3194bc5adb8977cfc3c97a2"}},"0311bed871884b899350ba23425e4419":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dfed55aea32f40dba0351e518ab140ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96ac95b2289742e5ae0661af77b8a748":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"844181c2a5234b77901c450b36f29f2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"156f58c7eb714ea4bf66c4f4f39b1a64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"689c51fef3194bc5adb8977cfc3c97a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd003d350d5e4d63a2ab989f0764bb13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_714316cb9edc442f8ced8f5a3f9bbafc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_87afec360bdb4c119ab7b33e4b95351d","IPY_MODEL_261110d2368f4bdf8424b2e8286d7ca5","IPY_MODEL_12f929c7bc1d47d58ce1da731f99c191"]}},"714316cb9edc442f8ced8f5a3f9bbafc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87afec360bdb4c119ab7b33e4b95351d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfcf5a299a694e7abb333746666f5fde","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_85f1373bead64d21a38554b1e743096c"}},"261110d2368f4bdf8424b2e8286d7ca5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_86462e6ca7674c5c8bb38c0cf3d6c161","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231485,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231485,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2bf588c1f7cf487da74808f76ba0dbeb"}},"12f929c7bc1d47d58ce1da731f99c191":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db48a2a8389c4f0c952d02f0a4e28731","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 1.97MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8074f6121ea2472788bb4bba4c63f8d3"}},"cfcf5a299a694e7abb333746666f5fde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"85f1373bead64d21a38554b1e743096c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86462e6ca7674c5c8bb38c0cf3d6c161":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2bf588c1f7cf487da74808f76ba0dbeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db48a2a8389c4f0c952d02f0a4e28731":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8074f6121ea2472788bb4bba4c63f8d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cebd962b7ef743359f54f204c73a8afd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_54f47f8a40a74c59b1273d86f1a79b49","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_426927fcf0cf45ac8466890e46967760","IPY_MODEL_02116b42bf8843dea5d9fa2ec294212c","IPY_MODEL_b682a31509864d5184e2e579d8ed2c9a"]}},"54f47f8a40a74c59b1273d86f1a79b49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"426927fcf0cf45ac8466890e46967760":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c3a5bbca477b49869080aad9ed408bbc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0845273645fc4baaa3a3e343cfacca99"}},"02116b42bf8843dea5d9fa2ec294212c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aea948e9a2c34c6f9dbfd00812e19927","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466260,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466260,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8730f949a264402b887bdcf5f414310b"}},"b682a31509864d5184e2e579d8ed2c9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_94a184c03d7a4fe6a6f13a7a4de66c42","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 455k/455k [00:00&lt;00:00, 3.24MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f03b6850e3c4ccf8afb4e9bc784a933"}},"c3a5bbca477b49869080aad9ed408bbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0845273645fc4baaa3a3e343cfacca99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aea948e9a2c34c6f9dbfd00812e19927":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8730f949a264402b887bdcf5f414310b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"94a184c03d7a4fe6a6f13a7a4de66c42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1f03b6850e3c4ccf8afb4e9bc784a933":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4df8e85e0e3648efa39a7d7de5df3b11":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8f0a3c6f550849afbe89be5f7923fb81","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_95c006e1dbd745519311cc4eb8076116","IPY_MODEL_a291b4a847af498e955942fc39c46ca3","IPY_MODEL_aa776fc997c243ad87b62fac17ce6b14"]}},"8f0a3c6f550849afbe89be5f7923fb81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95c006e1dbd745519311cc4eb8076116":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c033a9e845e24d10977890b5805a6185","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58d24c8da4b74ff6a426baebdad35f8b"}},"a291b4a847af498e955942fc39c46ca3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5604abf7dbb343bca7d033da546667a9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":153,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":153,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_50ffe8003e0943ccaa4bc972d407f925"}},"aa776fc997c243ad87b62fac17ce6b14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0de44383c93b488a94b941ca205a3e0b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 153/153 [00:00&lt;00:00, 5.66kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6be9318999534dccbb97498d1ac44873"}},"c033a9e845e24d10977890b5805a6185":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"58d24c8da4b74ff6a426baebdad35f8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5604abf7dbb343bca7d033da546667a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"50ffe8003e0943ccaa4bc972d407f925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0de44383c93b488a94b941ca205a3e0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6be9318999534dccbb97498d1ac44873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aac52c65e6b247de875bedbdc0ff0d37":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b3842fdce121446c9c49b49fd04a040a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_06de9ab83d3b445fa301e5258ad1ac94","IPY_MODEL_05a585e0b8e646c6b72f6317459885fb","IPY_MODEL_14efb89eebe64495a4c4f954f4547e90"]}},"b3842fdce121446c9c49b49fd04a040a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06de9ab83d3b445fa301e5258ad1ac94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c4142255a970473bbabb6bb8e7440169","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1fa81fe427f496fb85fcae361d22f62"}},"05a585e0b8e646c6b72f6317459885fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b2913f73357549a0b81c42bcad2ed2dd","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":42146,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":42146,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47b3f6582e984ee9bc7fecd2e90a069f"}},"14efb89eebe64495a4c4f954f4547e90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e751cb60a7824bec870ebd566766e8a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 42146/42146 [00:20&lt;00:00, 2169.34it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ffeaa9612cd44899b83e7496ce90e57"}},"c4142255a970473bbabb6bb8e7440169":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1fa81fe427f496fb85fcae361d22f62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2913f73357549a0b81c42bcad2ed2dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"47b3f6582e984ee9bc7fecd2e90a069f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e751cb60a7824bec870ebd566766e8a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0ffeaa9612cd44899b83e7496ce90e57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b29f655d6de492cb44df391c427bb62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_76e9303c8c2a4794a8532f074ffe874d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0a5bbd27b2eb412f8ee963911d4aa83f","IPY_MODEL_59e314ec165948f7a8f9bb3b816292ab","IPY_MODEL_91720bb01f4a42a9ad2093ccd5332dff"]}},"76e9303c8c2a4794a8532f074ffe874d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a5bbd27b2eb412f8ee963911d4aa83f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_106d1242a8dd45e1861f9578b3c4b195","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ff8116295644f8488652bf7251cf517"}},"59e314ec165948f7a8f9bb3b816292ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0ac942423e8a47f98817bbcd59427227","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":143,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":143,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dedc59f3343e4d08893c533e744f95d0"}},"91720bb01f4a42a9ad2093ccd5332dff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b40dda0deb324379823c61ad8d2eabf4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 143/143 [00:00&lt;00:00, 3623.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f53bae23760b4c09bc1f0e5defcff03a"}},"106d1242a8dd45e1861f9578b3c4b195":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ff8116295644f8488652bf7251cf517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ac942423e8a47f98817bbcd59427227":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dedc59f3343e4d08893c533e744f95d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b40dda0deb324379823c61ad8d2eabf4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f53bae23760b4c09bc1f0e5defcff03a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5df6089f4aee431890a16861520172f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cf61db0ffa8445209128443daba2503f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_52133c1059504f52aa510cb78285b89d","IPY_MODEL_7b1972f1a07a4b198047efc1bd1805e6","IPY_MODEL_eff781c55a1447bcb8b32bfd952aa25e"]}},"cf61db0ffa8445209128443daba2503f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52133c1059504f52aa510cb78285b89d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4db5ea8868ce493cad995f08a3e889f1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23b2e991b32248c7a726f3453f311508"}},"7b1972f1a07a4b198047efc1bd1805e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_19c3c5c87e234104bd7110d8980136bc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1544623145,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1544623145,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1817f6ff9d246a49d2c4128c9516fd7"}},"eff781c55a1447bcb8b32bfd952aa25e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5a1ca917a99e4c00b60797f5fd6de910","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.44G/1.44G [00:42&lt;00:00, 29.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9381924d3d4d4bd0801db96217d30153"}},"4db5ea8868ce493cad995f08a3e889f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23b2e991b32248c7a726f3453f311508":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19c3c5c87e234104bd7110d8980136bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c1817f6ff9d246a49d2c4128c9516fd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a1ca917a99e4c00b60797f5fd6de910":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9381924d3d4d4bd0801db96217d30153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":5}