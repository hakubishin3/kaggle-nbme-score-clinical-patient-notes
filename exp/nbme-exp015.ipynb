{"cells":[{"cell_type":"markdown","metadata":{"id":"aa1f8e80"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"c0138fac"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","metadata":{"id":"cf1dfda9"},"source":["## Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7a78d25"},"outputs":[],"source":["EXP_NAME = \"nbme-exp015\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ecc4e4d"},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-base\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=8\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=5\n","    train_fold=[0, 1, 2, 3, 4]\n","    seed=71\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3894c88b"},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","metadata":{"id":"31768c85"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32736,"status":"ok","timestamp":1646269363202,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"00e7d967","outputId":"bee9ad5f-3db9-498e-93ad-86fe65e685ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["colab\n","Mounted at /content/drive\n","Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 14.9 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 57.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,\u003e=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 51.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting pyyaml\u003e=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.3 MB/s \n","\u001b[?25hCollecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.7)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.7.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2021.10.8)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d726b7d9"},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"b6d82f71"},"source":["## Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95abbe2c"},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"832ee36d"},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -\u003e [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) \u003e 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob \u003e= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"918828a7"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d02a78e1"},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","metadata":{"id":"47266f39"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4461,"status":"ok","timestamp":1646269379455,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"20fed6da","outputId":"4a44dd22-4dff-4e9c-8c6d-8ee8d464876e"},"outputs":[{"data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e67d0132"},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","metadata":{"id":"47bca11a"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9c8e9ba"},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646269379456,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"7ef41e18","outputId":"c1fd5999-0e04-4190-dfbb-a79fa382f5c3"},"outputs":[{"data":{"text/plain":["((14300, 8), (5, 6))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8233df16"},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1646269379965,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"e9143e61","outputId":"163513af-5765-41a8-c76d-57345db463e6"},"outputs":[{"data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","metadata":{"id":"6bdc7949"},"source":["## CV split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4acf61d"},"outputs":[],"source":["def get_groupkfold(df, group_name):\n","    groups = df[group_name].unique()\n","\n","    kf = KFold(\n","        n_splits=CFG.n_fold,\n","        shuffle=True,\n","        random_state=CFG.seed,\n","    )\n","    folds_ids = []\n","    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n","        val_group = groups[val_group_idx]\n","        is_val = df[group_name].isin(val_group)\n","        val_idx = df[is_val].index\n","        df.loc[val_idx, \"fold\"] = int(i_fold)\n","\n","    df[\"fold\"] = df[\"fold\"].astype(int)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1646269379967,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"2ca0c08e","outputId":"43ad8f46-079c-4685-9adc-6b916aa4efda"},"outputs":[{"data":{"text/plain":["fold\n","0    2902\n","1    2894\n","2    2813\n","3    2791\n","4    2900\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["train = get_groupkfold(train, \"pn_num\")\n","display(train.groupby(\"fold\").size())"]},{"cell_type":"markdown","metadata":{"id":"a8560070"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"elapsed":7506,"status":"ok","timestamp":1646269387467,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"c316b13f","outputId":"4b1d3a4c-4331-4bae-f22a-f600b5926279"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27003f1063aa4b29ac9ed3ebf9c909eb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c4327893ecd45ee9f42abb647ab6c58","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/474 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29f256ee4f624c56a16e57cb8fbede74","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9613f09e3c545ed9c2a3d04a2a0c09c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"e689a7fc"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":29603,"status":"ok","timestamp":1646269417049,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"df31758e","outputId":"ad03cbd9-c7ea-4642-8868-a4637283a37a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54d9b03b832749e3a65ea8902ccc151a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42146 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1646269417050,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"3caff24a","outputId":"a79d4856-2b67-4fbc-997c-bde2abbe3e43"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"987fd6e2a61741ae9afb474219e27716","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1646269417050,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"756d83ff","outputId":"ca1dad92-1c38-4be3-fe22-7a4d77374f73"},"outputs":[{"name":"stdout","output_type":"stream","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls \u0026 sep \u0026 sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"054b899a"},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.case_nums = self.df[\"case_num\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length \u003e 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) \u0026 (start \u003c offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) \u0026 (end \u003c= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) \u0026 (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        case_num = self.case_nums[idx]\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, case_num, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1d58367c"},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.case_nums = self.df[\"case_num\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        case_num = self.case_nums[idx]\n","        return input_, case_num"]},{"cell_type":"markdown","metadata":{"id":"8c57abef"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54f92d89"},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"91401041"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5838,"status":"ok","timestamp":1646269422870,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"},"user_tz":-540},"id":"kJWX45WJZcKo","outputId":"207664fb-d1c0-445c-9f94-cb8129ef8ca8"},"outputs":[{"data":{"text/plain":["{0: 0.7781527309086365,\n"," 1: 0.9363829521309837,\n"," 2: 1.2530433695788026,\n"," 3: 0.9905761779777528,\n"," 4: 0.9248343957005374,\n"," 5: 1.4987126609173853,\n"," 6: 0.7837520309961254,\n"," 7: 0.7356080489938757,\n"," 8: 1.3420322459692537,\n"," 9: 0.7569053868266467}"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["labels = create_labels_for_scoring(train)\n","res = []\n","for i in labels:\n","    tot = 0\n","    for j in i:\n","        tot += j[1]-j[0]\n","    res.append(tot)\n","train[\"num_of_chars\"] = res\n","weights = dict((train.groupby('case_num')['num_of_chars'].sum()) / (train.groupby('case_num')['num_of_chars'].sum()).sum() * 10)\n","weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eda8175d"},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, case_nums, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        case_nums = torch.tensor([[num] * CFG.max_len for num in case_nums]).view(-1, 1).to(device)\n","        case_nums = torch.masked_select(case_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for case_num in case_nums:\n","            weight.append(weights[case_num.item()])\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c44b63a7"},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, case_nums, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        case_nums = torch.tensor([[num] * CFG.max_len for num in case_nums]).view(-1, 1).to(device)\n","        case_nums = torch.masked_select(case_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for case_num in case_nums:\n","            weight.append(weights[case_num.item()])\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze().detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4219ac38"},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for (inputs, case_nums) in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze().detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"014a76b7"},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score \u003e best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","metadata":{"id":"c38fb834"},"source":["## Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62d677cd"},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        #oof_df.to_csv(CFG.output_dir / \"oof_df.csv\", index=False)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1d4fcf7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1424] Elapsed 0m 1s (remain 26m 50s) Loss: 0.7020(0.7020) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1424] Elapsed 0m 32s (remain 7m 0s) Loss: 0.1537(0.5306) Grad: 9826.5586  LR: 0.000003  \n","Epoch: [1][200/1424] Elapsed 0m 57s (remain 5m 49s) Loss: 0.0855(0.3111) Grad: 1008.6454  LR: 0.000006  \n","Epoch: [1][300/1424] Elapsed 1m 21s (remain 5m 4s) Loss: 0.1221(0.2325) Grad: 2622.7297  LR: 0.000008  \n","Epoch: [1][400/1424] Elapsed 1m 45s (remain 4m 30s) Loss: 0.0155(0.1877) Grad: 931.0604  LR: 0.000011  \n","Epoch: [1][500/1424] Elapsed 2m 10s (remain 4m 0s) Loss: 0.0645(0.1566) Grad: 3433.0273  LR: 0.000014  \n","Epoch: [1][600/1424] Elapsed 2m 34s (remain 3m 32s) Loss: 0.0149(0.1349) Grad: 1421.9243  LR: 0.000017  \n","Epoch: [1][700/1424] Elapsed 2m 59s (remain 3m 4s) Loss: 0.0077(0.1189) Grad: 839.2306  LR: 0.000020  \n","Epoch: [1][800/1424] Elapsed 3m 23s (remain 2m 38s) Loss: 0.0112(0.1066) Grad: 1562.2113  LR: 0.000020  \n","Epoch: [1][900/1424] Elapsed 3m 47s (remain 2m 12s) Loss: 0.0166(0.0972) Grad: 1818.9559  LR: 0.000019  \n","Epoch: [1][1000/1424] Elapsed 4m 11s (remain 1m 46s) Loss: 0.0444(0.0893) Grad: 2899.1589  LR: 0.000019  \n","Epoch: [1][1100/1424] Elapsed 4m 36s (remain 1m 21s) Loss: 0.0046(0.0827) Grad: 1517.6644  LR: 0.000019  \n","Epoch: [1][1200/1424] Elapsed 5m 0s (remain 0m 55s) Loss: 0.0046(0.0773) Grad: 1282.3217  LR: 0.000018  \n","Epoch: [1][1300/1424] Elapsed 5m 24s (remain 0m 30s) Loss: 0.0120(0.0726) Grad: 1795.9537  LR: 0.000018  \n","Epoch: [1][1400/1424] Elapsed 5m 48s (remain 0m 5s) Loss: 0.0164(0.0685) Grad: 1149.1399  LR: 0.000018  \n","Epoch: [1][1423/1424] Elapsed 5m 54s (remain 0m 0s) Loss: 0.0185(0.0676) Grad: 2958.0969  LR: 0.000018  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 21s) Loss: 0.0120(0.0120) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 36s) Loss: 0.0144(0.0148) \n","EVAL: [200/363] Elapsed 0m 27s (remain 0m 22s) Loss: 0.0277(0.0183) \n","EVAL: [300/363] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0147(0.0164) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0029(0.0146) \n","Epoch 1 - avg_train_loss: 0.0676  avg_val_loss: 0.0146  time: 409s\n","Epoch 1 - Score: 0.8458\n","Epoch 1 - Save Best Score: 0.8458 Model\n","Epoch: [2][0/1424] Elapsed 0m 0s (remain 13m 42s) Loss: 0.0024(0.0024) Grad: 3733.0054  LR: 0.000018  \n","Epoch: [2][100/1424] Elapsed 0m 25s (remain 5m 30s) Loss: 0.0182(0.0127) Grad: 64295.8906  LR: 0.000017  \n","Epoch: [2][200/1424] Elapsed 0m 49s (remain 5m 2s) Loss: 0.0135(0.0120) Grad: 14377.9443  LR: 0.000017  \n","Epoch: [2][300/1424] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0036(0.0113) Grad: 23163.6699  LR: 0.000017  \n","Epoch: [2][400/1424] Elapsed 1m 38s (remain 4m 10s) Loss: 0.0071(0.0118) Grad: 17676.7910  LR: 0.000017  \n","Epoch: [2][500/1424] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0037(0.0122) Grad: 5344.2939  LR: 0.000016  \n","Epoch: [2][600/1424] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0025(0.0121) Grad: 11446.5908  LR: 0.000016  \n","Epoch: [2][700/1424] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0075(0.0122) Grad: 13677.5518  LR: 0.000016  \n","Epoch: [2][800/1424] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0140(0.0120) Grad: 29976.1406  LR: 0.000015  \n","Epoch: [2][900/1424] Elapsed 3m 39s (remain 2m 7s) Loss: 0.0087(0.0118) Grad: 16810.5723  LR: 0.000015  \n","Epoch: [2][1000/1424] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0081(0.0118) Grad: 14221.1445  LR: 0.000015  \n","Epoch: [2][1100/1424] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0123(0.0118) Grad: 13004.2637  LR: 0.000014  \n","Epoch: [2][1200/1424] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0404(0.0120) Grad: 35854.8125  LR: 0.000014  \n","Epoch: [2][1300/1424] Elapsed 5m 16s (remain 0m 29s) Loss: 0.0005(0.0120) Grad: 2150.0449  LR: 0.000014  \n","Epoch: [2][1400/1424] Elapsed 5m 40s (remain 0m 5s) Loss: 0.0070(0.0121) Grad: 47872.1016  LR: 0.000013  \n","Epoch: [2][1423/1424] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0097(0.0121) Grad: 35518.9688  LR: 0.000013  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 27s) Loss: 0.0072(0.0072) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 36s) Loss: 0.0086(0.0131) \n","EVAL: [200/363] Elapsed 0m 28s (remain 0m 22s) Loss: 0.0229(0.0177) \n","EVAL: [300/363] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0112(0.0155) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0036(0.0137) \n","Epoch 2 - avg_train_loss: 0.0121  avg_val_loss: 0.0137  time: 400s\n","Epoch 2 - Score: 0.8712\n","Epoch 2 - Save Best Score: 0.8712 Model\n","Epoch: [3][0/1424] Elapsed 0m 0s (remain 13m 52s) Loss: 0.0075(0.0075) Grad: 12029.1885  LR: 0.000013  \n","Epoch: [3][100/1424] Elapsed 0m 25s (remain 5m 31s) Loss: 0.0143(0.0075) Grad: 29270.7109  LR: 0.000013  \n","Epoch: [3][200/1424] Elapsed 0m 49s (remain 5m 1s) Loss: 0.0053(0.0088) Grad: 15251.1035  LR: 0.000013  \n","Epoch: [3][300/1424] Elapsed 1m 14s (remain 4m 36s) Loss: 0.0171(0.0092) Grad: 68494.6328  LR: 0.000012  \n","Epoch: [3][400/1424] Elapsed 1m 38s (remain 4m 10s) Loss: 0.0021(0.0093) Grad: 5996.7070  LR: 0.000012  \n","Epoch: [3][500/1424] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0031(0.0094) Grad: 7023.1162  LR: 0.000012  \n","Epoch: [3][600/1424] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0116(0.0094) Grad: 11158.9805  LR: 0.000011  \n","Epoch: [3][700/1424] Elapsed 2m 51s (remain 2m 56s) Loss: 0.0036(0.0096) Grad: 17645.9883  LR: 0.000011  \n","Epoch: [3][800/1424] Elapsed 3m 15s (remain 2m 31s) Loss: 0.0099(0.0095) Grad: 41679.4023  LR: 0.000011  \n","Epoch: [3][900/1424] Elapsed 3m 39s (remain 2m 7s) Loss: 0.0052(0.0094) Grad: 11114.5459  LR: 0.000011  \n","Epoch: [3][1000/1424] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0023(0.0094) Grad: 9496.7588  LR: 0.000010  \n","Epoch: [3][1100/1424] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0317(0.0094) Grad: 46974.2656  LR: 0.000010  \n","Epoch: [3][1200/1424] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0020(0.0094) Grad: 8605.6533  LR: 0.000010  \n","Epoch: [3][1300/1424] Elapsed 5m 16s (remain 0m 29s) Loss: 0.0272(0.0093) Grad: 34082.3945  LR: 0.000009  \n","Epoch: [3][1400/1424] Elapsed 5m 40s (remain 0m 5s) Loss: 0.0027(0.0093) Grad: 5126.3633  LR: 0.000009  \n","Epoch: [3][1423/1424] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0031(0.0093) Grad: 10120.3916  LR: 0.000009  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 32s) Loss: 0.0086(0.0086) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 36s) Loss: 0.0132(0.0126) \n","EVAL: [200/363] Elapsed 0m 28s (remain 0m 22s) Loss: 0.0140(0.0168) \n","EVAL: [300/363] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0040(0.0146) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0026(0.0129) \n","Epoch 3 - avg_train_loss: 0.0093  avg_val_loss: 0.0129  time: 400s\n","Epoch 3 - Score: 0.8780\n","Epoch 3 - Save Best Score: 0.8780 Model\n","Epoch: [4][0/1424] Elapsed 0m 0s (remain 13m 11s) Loss: 0.0026(0.0026) Grad: 6687.0127  LR: 0.000009  \n","Epoch: [4][100/1424] Elapsed 0m 25s (remain 5m 30s) Loss: 0.0109(0.0089) Grad: 16245.9941  LR: 0.000009  \n","Epoch: [4][200/1424] Elapsed 0m 49s (remain 5m 0s) Loss: 0.0001(0.0077) Grad: 678.3345  LR: 0.000008  \n","Epoch: [4][300/1424] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0016(0.0079) Grad: 10126.7168  LR: 0.000008  \n","Epoch: [4][400/1424] Elapsed 1m 38s (remain 4m 10s) Loss: 0.0029(0.0083) Grad: 5365.6426  LR: 0.000008  \n","Epoch: [4][500/1424] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0075(0.0080) Grad: 28799.3867  LR: 0.000007  \n","Epoch: [4][600/1424] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0004(0.0081) Grad: 1163.5199  LR: 0.000007  \n","Epoch: [4][700/1424] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0304(0.0082) Grad: 53795.6641  LR: 0.000007  \n","Epoch: [4][800/1424] Elapsed 3m 15s (remain 2m 31s) Loss: 0.0096(0.0080) Grad: 19460.0273  LR: 0.000006  \n","Epoch: [4][900/1424] Elapsed 3m 39s (remain 2m 7s) Loss: 0.1420(0.0081) Grad: 176967.3125  LR: 0.000006  \n","Epoch: [4][1000/1424] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0044(0.0080) Grad: 56173.9141  LR: 0.000006  \n","Epoch: [4][1100/1424] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0018(0.0078) Grad: 5676.8804  LR: 0.000005  \n","Epoch: [4][1200/1424] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0037(0.0076) Grad: 17189.8496  LR: 0.000005  \n","Epoch: [4][1300/1424] Elapsed 5m 16s (remain 0m 29s) Loss: 0.0022(0.0077) Grad: 6167.1953  LR: 0.000005  \n","Epoch: [4][1400/1424] Elapsed 5m 40s (remain 0m 5s) Loss: 0.0000(0.0077) Grad: 230.0518  LR: 0.000005  \n","Epoch: [4][1423/1424] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0016(0.0077) Grad: 13842.4893  LR: 0.000004  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 29s) Loss: 0.0072(0.0072) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 36s) Loss: 0.0136(0.0144) \n","EVAL: [200/363] Elapsed 0m 27s (remain 0m 22s) Loss: 0.0286(0.0183) \n","EVAL: [300/363] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0027(0.0159) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0039(0.0141) \n","Epoch 4 - avg_train_loss: 0.0077  avg_val_loss: 0.0141  time: 400s\n","Epoch 4 - Score: 0.8743\n","Epoch: [5][0/1424] Elapsed 0m 0s (remain 13m 36s) Loss: 0.0080(0.0080) Grad: 20735.2246  LR: 0.000004  \n","Epoch: [5][100/1424] Elapsed 0m 24s (remain 5m 24s) Loss: 0.0011(0.0050) Grad: 4378.1118  LR: 0.000004  \n","Epoch: [5][200/1424] Elapsed 0m 48s (remain 4m 57s) Loss: 0.0005(0.0055) Grad: 3019.6536  LR: 0.000004  \n","Epoch: [5][300/1424] Elapsed 1m 13s (remain 4m 32s) Loss: 0.0046(0.0062) Grad: 13520.3564  LR: 0.000004  \n","Epoch: [5][400/1424] Elapsed 1m 37s (remain 4m 8s) Loss: 0.0131(0.0066) Grad: 30966.5801  LR: 0.000003  \n","Epoch: [5][500/1424] Elapsed 2m 1s (remain 3m 44s) Loss: 0.0003(0.0064) Grad: 2409.3406  LR: 0.000003  \n","Epoch: [5][600/1424] Elapsed 2m 25s (remain 3m 19s) Loss: 0.0030(0.0066) Grad: 5090.9810  LR: 0.000003  \n","Epoch: [5][700/1424] Elapsed 2m 50s (remain 2m 55s) Loss: 0.0013(0.0067) Grad: 11448.6855  LR: 0.000002  \n","Epoch: [5][800/1424] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0001(0.0064) Grad: 419.8800  LR: 0.000002  \n","Epoch: [5][900/1424] Elapsed 3m 38s (remain 2m 6s) Loss: 0.0104(0.0062) Grad: 18761.7129  LR: 0.000002  \n","Epoch: [5][1000/1424] Elapsed 4m 2s (remain 1m 42s) Loss: 0.0306(0.0064) Grad: 53071.9531  LR: 0.000001  \n","Epoch: [5][1100/1424] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0010(0.0065) Grad: 4441.3384  LR: 0.000001  \n","Epoch: [5][1200/1424] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0127(0.0066) Grad: 58178.7031  LR: 0.000001  \n","Epoch: [5][1300/1424] Elapsed 5m 15s (remain 0m 29s) Loss: 0.0001(0.0066) Grad: 198.3207  LR: 0.000000  \n","Epoch: [5][1400/1424] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0012(0.0065) Grad: 7699.9790  LR: 0.000000  \n","Epoch: [5][1423/1424] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0012(0.0065) Grad: 12052.4238  LR: 0.000000  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 24s) Loss: 0.0052(0.0052) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 36s) Loss: 0.0163(0.0149) \n","EVAL: [200/363] Elapsed 0m 27s (remain 0m 22s) Loss: 0.0366(0.0190) \n","EVAL: [300/363] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0067(0.0167) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0036(0.0148) \n","Epoch 5 - avg_train_loss: 0.0065  avg_val_loss: 0.0148  time: 400s\n","Epoch 5 - Score: 0.8759\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1425] Elapsed 0m 0s (remain 12m 54s) Loss: 0.5864(0.5864) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1425] Elapsed 0m 24s (remain 5m 23s) Loss: 0.1992(0.4910) Grad: 23431.7324  LR: 0.000003  \n","Epoch: [1][200/1425] Elapsed 0m 48s (remain 4m 57s) Loss: 0.0452(0.2944) Grad: 843.5731  LR: 0.000006  \n","Epoch: [1][300/1425] Elapsed 1m 13s (remain 4m 32s) Loss: 0.0685(0.2208) Grad: 2086.2593  LR: 0.000008  \n","Epoch: [1][400/1425] Elapsed 1m 37s (remain 4m 8s) Loss: 0.0319(0.1799) Grad: 4648.9727  LR: 0.000011  \n","Epoch: [1][500/1425] Elapsed 2m 1s (remain 3m 44s) Loss: 0.0274(0.1514) Grad: 5803.9912  LR: 0.000014  \n","Epoch: [1][600/1425] Elapsed 2m 25s (remain 3m 19s) Loss: 0.0144(0.1308) Grad: 2002.0492  LR: 0.000017  \n","Epoch: [1][700/1425] Elapsed 2m 49s (remain 2m 55s) Loss: 0.0308(0.1152) Grad: 11472.0732  LR: 0.000020  \n","Epoch: [1][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0335(0.1038) Grad: 11889.9082  LR: 0.000020  \n","Epoch: [1][900/1425] Elapsed 3m 38s (remain 2m 6s) Loss: 0.0147(0.0943) Grad: 3541.2900  LR: 0.000019  \n","Epoch: [1][1000/1425] Elapsed 4m 2s (remain 1m 42s) Loss: 0.0224(0.0869) Grad: 5022.2363  LR: 0.000019  \n","Epoch: [1][1100/1425] Elapsed 4m 26s (remain 1m 18s) Loss: 0.0109(0.0806) Grad: 2529.7598  LR: 0.000019  \n","Epoch: [1][1200/1425] Elapsed 4m 50s (remain 0m 54s) Loss: 0.0076(0.0754) Grad: 2275.9758  LR: 0.000018  \n","Epoch: [1][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0058(0.0708) Grad: 1603.5792  LR: 0.000018  \n","Epoch: [1][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0010(0.0669) Grad: 324.2381  LR: 0.000018  \n","Epoch: [1][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0079(0.0661) Grad: 3014.7021  LR: 0.000018  \n","EVAL: [0/362] Elapsed 0m 0s (remain 3m 45s) Loss: 0.0045(0.0045) \n","EVAL: [100/362] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0038(0.0158) \n","EVAL: [200/362] Elapsed 0m 28s (remain 0m 22s) Loss: 0.0202(0.0148) \n","EVAL: [300/362] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0165(0.0154) \n","EVAL: [361/362] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0043(0.0142) \n","Epoch 1 - avg_train_loss: 0.0661  avg_val_loss: 0.0142  time: 399s\n","Epoch 1 - Score: 0.8395\n","Epoch 1 - Save Best Score: 0.8395 Model\n","Epoch: [2][0/1425] Elapsed 0m 0s (remain 13m 34s) Loss: 0.0031(0.0031) Grad: 8200.4150  LR: 0.000018  \n","Epoch: [2][100/1425] Elapsed 0m 25s (remain 5m 29s) Loss: 0.0046(0.0125) Grad: 11731.2061  LR: 0.000017  \n","Epoch: [2][200/1425] Elapsed 0m 49s (remain 5m 1s) Loss: 0.0154(0.0119) Grad: 31687.3711  LR: 0.000017  \n","Epoch: [2][300/1425] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0058(0.0113) Grad: 11098.5547  LR: 0.000017  \n","Epoch: [2][400/1425] Elapsed 1m 37s (remain 4m 10s) Loss: 0.0173(0.0116) Grad: 39344.3320  LR: 0.000017  \n","Epoch: [2][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0181(0.0122) Grad: 25019.5078  LR: 0.000016  \n","Epoch: [2][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0459(0.0122) Grad: 58656.6914  LR: 0.000016  \n","Epoch: [2][700/1425] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0116(0.0121) Grad: 17245.2227  LR: 0.000016  \n","Epoch: [2][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0150(0.0120) Grad: 26448.9531  LR: 0.000015  \n","Epoch: [2][900/1425] Elapsed 3m 38s (remain 2m 7s) Loss: 0.0089(0.0121) Grad: 18128.5938  LR: 0.000015  \n","Epoch: [2][1000/1425] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0015(0.0120) Grad: 12031.2666  LR: 0.000015  \n","Epoch: [2][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0304(0.0120) Grad: 30559.8965  LR: 0.000014  \n","Epoch: [2][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0018(0.0121) Grad: 3130.5293  LR: 0.000014  \n","Epoch: [2][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0262(0.0121) Grad: 53385.3594  LR: 0.000014  \n","Epoch: [2][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0061(0.0122) Grad: 10125.9873  LR: 0.000013  \n","Epoch: [2][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0082(0.0121) Grad: 16625.4316  LR: 0.000013  \n","EVAL: [0/362] Elapsed 0m 0s (remain 2m 31s) Loss: 0.0015(0.0015) \n","EVAL: [100/362] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0022(0.0131) \n","EVAL: [200/362] Elapsed 0m 28s (remain 0m 22s) Loss: 0.0151(0.0124) \n","EVAL: [300/362] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0066(0.0129) \n","EVAL: [361/362] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0029(0.0117) \n","Epoch 2 - avg_train_loss: 0.0121  avg_val_loss: 0.0117  time: 400s\n","Epoch 2 - Score: 0.8679\n","Epoch 2 - Save Best Score: 0.8679 Model\n","Epoch: [3][0/1425] Elapsed 0m 0s (remain 14m 13s) Loss: 0.0009(0.0009) Grad: 2634.7114  LR: 0.000013  \n","Epoch: [3][100/1425] Elapsed 0m 25s (remain 5m 31s) Loss: 0.0035(0.0093) Grad: 4476.2754  LR: 0.000013  \n","Epoch: [3][200/1425] Elapsed 0m 49s (remain 5m 1s) Loss: 0.0015(0.0085) Grad: 5685.9150  LR: 0.000013  \n","Epoch: [3][300/1425] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0008(0.0092) Grad: 4326.3276  LR: 0.000012  \n","Epoch: [3][400/1425] Elapsed 1m 37s (remain 4m 10s) Loss: 0.0284(0.0097) Grad: 53252.0625  LR: 0.000012  \n","Epoch: [3][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0020(0.0101) Grad: 5794.6494  LR: 0.000012  \n","Epoch: [3][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0046(0.0099) Grad: 10553.4404  LR: 0.000011  \n","Epoch: [3][700/1425] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0016(0.0101) Grad: 9663.4375  LR: 0.000011  \n","Epoch: [3][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0241(0.0102) Grad: 76411.6484  LR: 0.000011  \n","Epoch: [3][900/1425] Elapsed 3m 38s (remain 2m 7s) Loss: 0.0057(0.0101) Grad: 9431.0254  LR: 0.000011  \n","Epoch: [3][1000/1425] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0015(0.0100) Grad: 3428.0027  LR: 0.000010  \n","Epoch: [3][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0126(0.0099) Grad: 28699.0039  LR: 0.000010  \n","Epoch: [3][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0033(0.0099) Grad: 6750.4111  LR: 0.000010  \n","Epoch: [3][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0186(0.0098) Grad: 27010.2969  LR: 0.000009  \n","Epoch: [3][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0098(0.0096) Grad: 57939.9727  LR: 0.000009  \n","Epoch: [3][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0091(0.0096) Grad: 34603.5039  LR: 0.000009  \n","EVAL: [0/362] Elapsed 0m 0s (remain 2m 9s) Loss: 0.0010(0.0010) \n","EVAL: [100/362] Elapsed 0m 14s (remain 0m 36s) Loss: 0.0021(0.0145) \n","EVAL: [200/362] Elapsed 0m 28s (remain 0m 22s) Loss: 0.0027(0.0133) \n","EVAL: [300/362] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0017(0.0136) \n","EVAL: [361/362] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0044(0.0125) \n","Epoch 3 - avg_train_loss: 0.0096  avg_val_loss: 0.0125  time: 400s\n","Epoch 3 - Score: 0.8760\n","Epoch 3 - Save Best Score: 0.8760 Model\n","Epoch: [4][0/1425] Elapsed 0m 0s (remain 13m 47s) Loss: 0.0053(0.0053) Grad: 19512.6152  LR: 0.000009  \n","Epoch: [4][100/1425] Elapsed 0m 25s (remain 5m 31s) Loss: 0.0033(0.0061) Grad: 10526.9746  LR: 0.000009  \n","Epoch: [4][200/1425] Elapsed 0m 49s (remain 5m 0s) Loss: 0.0138(0.0065) Grad: 52902.8398  LR: 0.000008  \n","Epoch: [4][300/1425] Elapsed 1m 13s (remain 4m 34s) Loss: 0.0960(0.0067) Grad: 147673.5156  LR: 0.000008  \n","Epoch: [4][400/1425] Elapsed 1m 38s (remain 4m 10s) Loss: 0.0100(0.0075) Grad: 129510.4062  LR: 0.000008  \n","Epoch: [4][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0091(0.0074) Grad: 22925.4570  LR: 0.000007  \n","Epoch: [4][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0006(0.0075) Grad: 5095.8032  LR: 0.000007  \n","Epoch: [4][700/1425] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0106(0.0077) Grad: 36546.7148  LR: 0.000007  \n","Epoch: [4][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0012(0.0079) Grad: 5496.0469  LR: 0.000006  \n","Epoch: [4][900/1425] Elapsed 3m 39s (remain 2m 7s) Loss: 0.0035(0.0077) Grad: 12924.4180  LR: 0.000006  \n","Epoch: [4][1000/1425] Elapsed 4m 3s (remain 1m 43s) Loss: 0.0004(0.0078) Grad: 3723.8826  LR: 0.000006  \n","Epoch: [4][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0021(0.0078) Grad: 3569.7097  LR: 0.000005  \n","Epoch: [4][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0033(0.0077) Grad: 7370.1572  LR: 0.000005  \n","Epoch: [4][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0021(0.0077) Grad: 6548.0835  LR: 0.000005  \n","Epoch: [4][1400/1425] Elapsed 5m 40s (remain 0m 5s) Loss: 0.0025(0.0076) Grad: 5811.8882  LR: 0.000005  \n","Epoch: [4][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0030(0.0076) Grad: 17045.2578  LR: 0.000004  \n","EVAL: [0/362] Elapsed 0m 0s (remain 2m 19s) Loss: 0.0016(0.0016) \n","EVAL: [100/362] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0017(0.0142) \n","EVAL: [200/362] Elapsed 0m 28s (remain 0m 22s) Loss: 0.0049(0.0135) \n","EVAL: [300/362] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0006(0.0141) \n","EVAL: [361/362] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0024(0.0128) \n","Epoch 4 - avg_train_loss: 0.0076  avg_val_loss: 0.0128  time: 400s\n","Epoch 4 - Score: 0.8804\n","Epoch 4 - Save Best Score: 0.8804 Model\n","Epoch: [5][0/1425] Elapsed 0m 0s (remain 13m 10s) Loss: 0.0139(0.0139) Grad: 28950.5762  LR: 0.000004  \n","Epoch: [5][100/1425] Elapsed 0m 25s (remain 5m 32s) Loss: 0.0025(0.0072) Grad: 8179.0757  LR: 0.000004  \n","Epoch: [5][200/1425] Elapsed 0m 49s (remain 5m 1s) Loss: 0.0061(0.0075) Grad: 41123.8164  LR: 0.000004  \n","Epoch: [5][300/1425] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0035(0.0075) Grad: 16737.6016  LR: 0.000004  \n","Epoch: [5][400/1425] Elapsed 1m 37s (remain 4m 9s) Loss: 0.0100(0.0073) Grad: 24125.1328  LR: 0.000003  \n","Epoch: [5][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0334(0.0071) Grad: 45872.6484  LR: 0.000003  \n","Epoch: [5][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0034(0.0070) Grad: 15299.0469  LR: 0.000003  \n","Epoch: [5][700/1425] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0016(0.0069) Grad: 6195.7148  LR: 0.000002  \n","Epoch: [5][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0031(0.0069) Grad: 10901.2510  LR: 0.000002  \n","Epoch: [5][900/1425] Elapsed 3m 38s (remain 2m 7s) Loss: 0.0014(0.0068) Grad: 4299.1748  LR: 0.000002  \n","Epoch: [5][1000/1425] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0016(0.0067) Grad: 6563.7935  LR: 0.000001  \n","Epoch: [5][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0072(0.0067) Grad: 15087.1562  LR: 0.000001  \n","Epoch: [5][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0149(0.0066) Grad: 70467.7578  LR: 0.000001  \n","Epoch: [5][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0414(0.0066) Grad: 53445.9648  LR: 0.000000  \n","Epoch: [5][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0022(0.0065) Grad: 7467.8960  LR: 0.000000  \n","Epoch: [5][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0068(0.0065) Grad: 24709.2734  LR: 0.000000  \n","EVAL: [0/362] Elapsed 0m 0s (remain 2m 30s) Loss: 0.0013(0.0013) \n","EVAL: [100/362] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0014(0.0153) \n","EVAL: [200/362] Elapsed 0m 28s (remain 0m 22s) Loss: 0.0034(0.0143) \n","EVAL: [300/362] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0007(0.0151) \n","EVAL: [361/362] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0027(0.0137) \n","Epoch 5 - avg_train_loss: 0.0065  avg_val_loss: 0.0137  time: 400s\n","Epoch 5 - Score: 0.8797\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1435] Elapsed 0m 0s (remain 12m 40s) Loss: 0.8906(0.8906) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1435] Elapsed 0m 24s (remain 5m 25s) Loss: 0.1926(0.6424) Grad: 14456.3867  LR: 0.000003  \n","Epoch: [1][200/1435] Elapsed 0m 48s (remain 4m 59s) Loss: 0.1112(0.3669) Grad: 1675.5496  LR: 0.000006  \n","Epoch: [1][300/1435] Elapsed 1m 12s (remain 4m 34s) Loss: 0.0570(0.2700) Grad: 828.9312  LR: 0.000008  \n","Epoch: [1][400/1435] Elapsed 1m 37s (remain 4m 10s) Loss: 0.0342(0.2167) Grad: 2203.0879  LR: 0.000011  \n","Epoch: [1][500/1435] Elapsed 2m 1s (remain 3m 46s) Loss: 0.0407(0.1810) Grad: 4274.9297  LR: 0.000014  \n","Epoch: [1][600/1435] Elapsed 2m 25s (remain 3m 22s) Loss: 0.0273(0.1557) Grad: 1809.5077  LR: 0.000017  \n","Epoch: [1][700/1435] Elapsed 2m 49s (remain 2m 57s) Loss: 0.0184(0.1371) Grad: 1481.8645  LR: 0.000020  \n","Epoch: [1][800/1435] Elapsed 3m 13s (remain 2m 33s) Loss: 0.0219(0.1223) Grad: 1248.2528  LR: 0.000020  \n","Epoch: [1][900/1435] Elapsed 3m 38s (remain 2m 9s) Loss: 0.0055(0.1106) Grad: 754.3419  LR: 0.000019  \n","Epoch: [1][1000/1435] Elapsed 4m 2s (remain 1m 45s) Loss: 0.0097(0.1012) Grad: 1370.0781  LR: 0.000019  \n","Epoch: [1][1100/1435] Elapsed 4m 26s (remain 1m 20s) Loss: 0.0100(0.0936) Grad: 1029.5806  LR: 0.000019  \n","Epoch: [1][1200/1435] Elapsed 4m 50s (remain 0m 56s) Loss: 0.0295(0.0871) Grad: 2241.7859  LR: 0.000019  \n","Epoch: [1][1300/1435] Elapsed 5m 14s (remain 0m 32s) Loss: 0.0249(0.0816) Grad: 1990.8981  LR: 0.000018  \n","Epoch: [1][1400/1435] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0092(0.0770) Grad: 1199.2209  LR: 0.000018  \n","Epoch: [1][1434/1435] Elapsed 5m 47s (remain 0m 0s) Loss: 0.0392(0.0755) Grad: 2230.9011  LR: 0.000018  \n","EVAL: [0/352] Elapsed 0m 0s (remain 2m 18s) Loss: 0.0076(0.0076) \n","EVAL: [100/352] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0171(0.0122) \n","EVAL: [200/352] Elapsed 0m 27s (remain 0m 21s) Loss: 0.0162(0.0143) \n","EVAL: [300/352] Elapsed 0m 41s (remain 0m 7s) Loss: 0.0098(0.0155) \n","EVAL: [351/352] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0019(0.0145) \n","Epoch 1 - avg_train_loss: 0.0755  avg_val_loss: 0.0145  time: 400s\n","Epoch 1 - Score: 0.8315\n","Epoch 1 - Save Best Score: 0.8315 Model\n","Epoch: [2][0/1435] Elapsed 0m 0s (remain 14m 8s) Loss: 0.0160(0.0160) Grad: 23364.3867  LR: 0.000018  \n","Epoch: [2][100/1435] Elapsed 0m 25s (remain 5m 35s) Loss: 0.0681(0.0122) Grad: 79085.5234  LR: 0.000017  \n","Epoch: [2][200/1435] Elapsed 0m 49s (remain 5m 4s) Loss: 0.0033(0.0110) Grad: 5750.0444  LR: 0.000017  \n","Epoch: [2][300/1435] Elapsed 1m 13s (remain 4m 37s) Loss: 0.0035(0.0111) Grad: 58852.5156  LR: 0.000017  \n","Epoch: [2][400/1435] Elapsed 1m 37s (remain 4m 12s) Loss: 0.0064(0.0113) Grad: 12846.6914  LR: 0.000017  \n","Epoch: [2][500/1435] Elapsed 2m 2s (remain 3m 47s) Loss: 0.0069(0.0113) Grad: 13801.0996  LR: 0.000016  \n","Epoch: [2][600/1435] Elapsed 2m 26s (remain 3m 23s) Loss: 0.0036(0.0111) Grad: 9423.1064  LR: 0.000016  \n","Epoch: [2][700/1435] Elapsed 2m 50s (remain 2m 58s) Loss: 0.0072(0.0115) Grad: 6069.5020  LR: 0.000016  \n","Epoch: [2][800/1435] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0210(0.0114) Grad: 61689.0938  LR: 0.000015  \n","Epoch: [2][900/1435] Elapsed 3m 38s (remain 2m 9s) Loss: 0.0021(0.0113) Grad: 9600.6689  LR: 0.000015  \n","Epoch: [2][1000/1435] Elapsed 4m 3s (remain 1m 45s) Loss: 0.0045(0.0117) Grad: 7254.3359  LR: 0.000015  \n","Epoch: [2][1100/1435] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0297(0.0117) Grad: 34369.8398  LR: 0.000014  \n","Epoch: [2][1200/1435] Elapsed 4m 51s (remain 0m 56s) Loss: 0.0107(0.0118) Grad: 26886.6641  LR: 0.000014  \n","Epoch: [2][1300/1435] Elapsed 5m 15s (remain 0m 32s) Loss: 0.0025(0.0117) Grad: 4540.0806  LR: 0.000014  \n","Epoch: [2][1400/1435] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0119(0.0118) Grad: 16870.8359  LR: 0.000013  \n","Epoch: [2][1434/1435] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0228(0.0117) Grad: 25771.0527  LR: 0.000013  \n","EVAL: [0/352] Elapsed 0m 0s (remain 2m 12s) Loss: 0.0071(0.0071) \n","EVAL: [100/352] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0209(0.0107) \n","EVAL: [200/352] Elapsed 0m 28s (remain 0m 21s) Loss: 0.0255(0.0127) \n","EVAL: [300/352] Elapsed 0m 42s (remain 0m 7s) Loss: 0.0020(0.0142) \n","EVAL: [351/352] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0009(0.0133) \n","Epoch 2 - avg_train_loss: 0.0117  avg_val_loss: 0.0133  time: 401s\n","Epoch 2 - Score: 0.8595\n","Epoch 2 - Save Best Score: 0.8595 Model\n","Epoch: [3][0/1435] Elapsed 0m 0s (remain 13m 51s) Loss: 0.0101(0.0101) Grad: 28285.2891  LR: 0.000013  \n","Epoch: [3][100/1435] Elapsed 0m 25s (remain 5m 32s) Loss: 0.0459(0.0077) Grad: 37846.6562  LR: 0.000013  \n","Epoch: [3][200/1435] Elapsed 0m 49s (remain 5m 3s) Loss: 0.0122(0.0082) Grad: 32183.2227  LR: 0.000013  \n","Epoch: [3][300/1435] Elapsed 1m 13s (remain 4m 37s) Loss: 0.0111(0.0082) Grad: 17434.9277  LR: 0.000012  \n","Epoch: [3][400/1435] Elapsed 1m 37s (remain 4m 12s) Loss: 0.0106(0.0087) Grad: 24000.3047  LR: 0.000012  \n","Epoch: [3][500/1435] Elapsed 2m 2s (remain 3m 47s) Loss: 0.0063(0.0090) Grad: 11167.8027  LR: 0.000012  \n","Epoch: [3][600/1435] Elapsed 2m 26s (remain 3m 22s) Loss: 0.0009(0.0092) Grad: 4429.8931  LR: 0.000011  \n","Epoch: [3][700/1435] Elapsed 2m 50s (remain 2m 58s) Loss: 0.0092(0.0093) Grad: 24870.5508  LR: 0.000011  \n","Epoch: [3][800/1435] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0005(0.0092) Grad: 2396.7659  LR: 0.000011  \n","Epoch: [3][900/1435] Elapsed 3m 38s (remain 2m 9s) Loss: 0.0092(0.0092) Grad: 21892.9199  LR: 0.000011  \n","Epoch: [3][1000/1435] Elapsed 4m 3s (remain 1m 45s) Loss: 0.0130(0.0091) Grad: 18091.6641  LR: 0.000010  \n","Epoch: [3][1100/1435] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0184(0.0091) Grad: 28873.0918  LR: 0.000010  \n","Epoch: [3][1200/1435] Elapsed 4m 51s (remain 0m 56s) Loss: 0.0099(0.0091) Grad: 11198.8076  LR: 0.000010  \n","Epoch: [3][1300/1435] Elapsed 5m 15s (remain 0m 32s) Loss: 0.0005(0.0092) Grad: 5251.4536  LR: 0.000009  \n","Epoch: [3][1400/1435] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0097(0.0094) Grad: 12935.2158  LR: 0.000009  \n","Epoch: [3][1434/1435] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0173(0.0094) Grad: 32807.0195  LR: 0.000009  \n","EVAL: [0/352] Elapsed 0m 0s (remain 2m 32s) Loss: 0.0104(0.0104) \n","EVAL: [100/352] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0082(0.0103) \n","EVAL: [200/352] Elapsed 0m 28s (remain 0m 21s) Loss: 0.0216(0.0125) \n","EVAL: [300/352] Elapsed 0m 42s (remain 0m 7s) Loss: 0.0017(0.0140) \n","EVAL: [351/352] Elapsed 0m 49s (remain 0m 0s) Loss: 0.0002(0.0133) \n","Epoch 3 - avg_train_loss: 0.0094  avg_val_loss: 0.0133  time: 401s\n","Epoch 3 - Score: 0.8661\n","Epoch 3 - Save Best Score: 0.8661 Model\n","Epoch: [4][0/1435] Elapsed 0m 0s (remain 13m 55s) Loss: 0.0041(0.0041) Grad: 10108.4199  LR: 0.000009  \n","Epoch: [4][100/1435] Elapsed 0m 25s (remain 5m 33s) Loss: 0.0036(0.0059) Grad: 12042.6777  LR: 0.000009  \n","Epoch: [4][200/1435] Elapsed 0m 49s (remain 5m 3s) Loss: 0.0141(0.0069) Grad: 24925.1406  LR: 0.000008  \n","Epoch: [4][300/1435] Elapsed 1m 13s (remain 4m 37s) Loss: 0.0018(0.0069) Grad: 9080.3916  LR: 0.000008  \n","Epoch: [4][400/1435] Elapsed 1m 37s (remain 4m 12s) Loss: 0.0124(0.0074) Grad: 54922.5781  LR: 0.000008  \n","Epoch: [4][500/1435] Elapsed 2m 2s (remain 3m 47s) Loss: 0.0045(0.0073) Grad: 14651.6992  LR: 0.000007  \n","Epoch: [4][600/1435] Elapsed 2m 26s (remain 3m 23s) Loss: 0.0016(0.0074) Grad: 6489.9268  LR: 0.000007  \n","Epoch: [4][700/1435] Elapsed 2m 50s (remain 2m 58s) Loss: 0.0021(0.0073) Grad: 13847.7109  LR: 0.000007  \n","Epoch: [4][800/1435] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0084(0.0074) Grad: 23444.8359  LR: 0.000006  \n","Epoch: [4][900/1435] Elapsed 3m 38s (remain 2m 9s) Loss: 0.0001(0.0073) Grad: 429.7568  LR: 0.000006  \n","Epoch: [4][1000/1435] Elapsed 4m 3s (remain 1m 45s) Loss: 0.0029(0.0073) Grad: 19153.5410  LR: 0.000006  \n","Epoch: [4][1100/1435] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0005(0.0075) Grad: 3041.5322  LR: 0.000005  \n","Epoch: [4][1200/1435] Elapsed 4m 51s (remain 0m 56s) Loss: 0.0050(0.0077) Grad: 16635.6348  LR: 0.000005  \n","Epoch: [4][1300/1435] Elapsed 5m 15s (remain 0m 32s) Loss: 0.0037(0.0076) Grad: 7450.7163  LR: 0.000005  \n","Epoch: [4][1400/1435] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0046(0.0075) Grad: 13819.1416  LR: 0.000005  \n","Epoch: [4][1434/1435] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0002(0.0076) Grad: 1063.1383  LR: 0.000004  \n","EVAL: [0/352] Elapsed 0m 0s (remain 2m 15s) Loss: 0.0127(0.0127) \n","EVAL: [100/352] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0103(0.0119) \n","EVAL: [200/352] Elapsed 0m 27s (remain 0m 21s) Loss: 0.0364(0.0141) \n","EVAL: [300/352] Elapsed 0m 41s (remain 0m 7s) Loss: 0.0016(0.0160) \n","EVAL: [351/352] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0004(0.0151) \n","Epoch 4 - avg_train_loss: 0.0076  avg_val_loss: 0.0151  time: 401s\n","Epoch 4 - Score: 0.8657\n","Epoch: [5][0/1435] Elapsed 0m 0s (remain 13m 14s) Loss: 0.0297(0.0297) Grad: 39124.8828  LR: 0.000004  \n","Epoch: [5][100/1435] Elapsed 0m 24s (remain 5m 29s) Loss: 0.0036(0.0053) Grad: 8346.3545  LR: 0.000004  \n","Epoch: [5][200/1435] Elapsed 0m 49s (remain 5m 1s) Loss: 0.0011(0.0054) Grad: 6676.8047  LR: 0.000004  \n","Epoch: [5][300/1435] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0110(0.0055) Grad: 6588.9028  LR: 0.000004  \n","Epoch: [5][400/1435] Elapsed 1m 37s (remain 4m 11s) Loss: 0.0042(0.0058) Grad: 13277.5674  LR: 0.000003  \n","Epoch: [5][500/1435] Elapsed 2m 1s (remain 3m 46s) Loss: 0.0029(0.0058) Grad: 10549.1035  LR: 0.000003  \n","Epoch: [5][600/1435] Elapsed 2m 25s (remain 3m 22s) Loss: 0.0001(0.0061) Grad: 607.5236  LR: 0.000003  \n","Epoch: [5][700/1435] Elapsed 2m 49s (remain 2m 58s) Loss: 0.0005(0.0063) Grad: 3653.4094  LR: 0.000002  \n","Epoch: [5][800/1435] Elapsed 3m 14s (remain 2m 33s) Loss: 0.0070(0.0063) Grad: 18726.2988  LR: 0.000002  \n","Epoch: [5][900/1435] Elapsed 3m 38s (remain 2m 9s) Loss: 0.0081(0.0062) Grad: 33522.0859  LR: 0.000002  \n","Epoch: [5][1000/1435] Elapsed 4m 2s (remain 1m 45s) Loss: 0.0047(0.0062) Grad: 42258.3203  LR: 0.000001  \n","Epoch: [5][1100/1435] Elapsed 4m 26s (remain 1m 20s) Loss: 0.0458(0.0063) Grad: 91974.7109  LR: 0.000001  \n","Epoch: [5][1200/1435] Elapsed 4m 50s (remain 0m 56s) Loss: 0.0132(0.0062) Grad: 9364.8525  LR: 0.000001  \n","Epoch: [5][1300/1435] Elapsed 5m 15s (remain 0m 32s) Loss: 0.0043(0.0063) Grad: 14895.9580  LR: 0.000000  \n","Epoch: [5][1400/1435] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0039(0.0064) Grad: 12532.4160  LR: 0.000000  \n","Epoch: [5][1434/1435] Elapsed 5m 47s (remain 0m 0s) Loss: 0.0022(0.0064) Grad: 8048.6240  LR: 0.000000  \n","EVAL: [0/352] Elapsed 0m 0s (remain 2m 15s) Loss: 0.0158(0.0158) \n","EVAL: [100/352] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0168(0.0124) \n","EVAL: [200/352] Elapsed 0m 28s (remain 0m 21s) Loss: 0.0426(0.0148) \n","EVAL: [300/352] Elapsed 0m 42s (remain 0m 7s) Loss: 0.0011(0.0167) \n","EVAL: [351/352] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0003(0.0158) \n","Epoch 5 - avg_train_loss: 0.0064  avg_val_loss: 0.0158  time: 401s\n","Epoch 5 - Score: 0.8678\n","Epoch 5 - Save Best Score: 0.8678 Model\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1438] Elapsed 0m 0s (remain 13m 20s) Loss: 0.6322(0.6322) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1438] Elapsed 0m 25s (remain 5m 33s) Loss: 0.1949(0.4918) Grad: 29737.8125  LR: 0.000003  \n","Epoch: [1][200/1438] Elapsed 0m 49s (remain 5m 4s) Loss: 0.1627(0.2917) Grad: 5502.7930  LR: 0.000006  \n","Epoch: [1][300/1438] Elapsed 1m 13s (remain 4m 37s) Loss: 0.0406(0.2197) Grad: 1239.6847  LR: 0.000008  \n","Epoch: [1][400/1438] Elapsed 1m 37s (remain 4m 12s) Loss: 0.0335(0.1810) Grad: 2954.3455  LR: 0.000011  \n","Epoch: [1][500/1438] Elapsed 2m 2s (remain 3m 48s) Loss: 0.0185(0.1521) Grad: 3953.0510  LR: 0.000014  \n","Epoch: [1][600/1438] Elapsed 2m 26s (remain 3m 23s) Loss: 0.0081(0.1318) Grad: 2415.6858  LR: 0.000017  \n","Epoch: [1][700/1438] Elapsed 2m 50s (remain 2m 59s) Loss: 0.0372(0.1166) Grad: 5492.0073  LR: 0.000019  \n","Epoch: [1][800/1438] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0195(0.1047) Grad: 2744.6565  LR: 0.000020  \n","Epoch: [1][900/1438] Elapsed 3m 38s (remain 2m 10s) Loss: 0.0039(0.0953) Grad: 1001.4932  LR: 0.000019  \n","Epoch: [1][1000/1438] Elapsed 4m 3s (remain 1m 46s) Loss: 0.0170(0.0877) Grad: 3744.8145  LR: 0.000019  \n","Epoch: [1][1100/1438] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0123(0.0811) Grad: 1988.8990  LR: 0.000019  \n","Epoch: [1][1200/1438] Elapsed 4m 51s (remain 0m 57s) Loss: 0.0250(0.0756) Grad: 3660.9214  LR: 0.000019  \n","Epoch: [1][1300/1438] Elapsed 5m 15s (remain 0m 33s) Loss: 0.0262(0.0710) Grad: 3462.8867  LR: 0.000018  \n","Epoch: [1][1400/1438] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0099(0.0670) Grad: 1611.9094  LR: 0.000018  \n","Epoch: [1][1437/1438] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0067(0.0657) Grad: 2333.4895  LR: 0.000018  \n","EVAL: [0/349] Elapsed 0m 0s (remain 2m 28s) Loss: 0.0033(0.0033) \n","EVAL: [100/349] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0309(0.0134) \n","EVAL: [200/349] Elapsed 0m 28s (remain 0m 20s) Loss: 0.0241(0.0153) \n","EVAL: [300/349] Elapsed 0m 42s (remain 0m 6s) Loss: 0.0132(0.0157) \n","EVAL: [348/349] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0009(0.0148) \n","Epoch 1 - avg_train_loss: 0.0657  avg_val_loss: 0.0148  time: 401s\n","Epoch 1 - Score: 0.8432\n","Epoch 1 - Save Best Score: 0.8432 Model\n","Epoch: [2][0/1438] Elapsed 0m 0s (remain 13m 23s) Loss: 0.0073(0.0073) Grad: 14051.6279  LR: 0.000018  \n","Epoch: [2][100/1438] Elapsed 0m 25s (remain 5m 33s) Loss: 0.0028(0.0124) Grad: 5970.1030  LR: 0.000017  \n","Epoch: [2][200/1438] Elapsed 0m 49s (remain 5m 4s) Loss: 0.0245(0.0131) Grad: 31887.8223  LR: 0.000017  \n","Epoch: [2][300/1438] Elapsed 1m 13s (remain 4m 38s) Loss: 0.0077(0.0130) Grad: 26866.1602  LR: 0.000017  \n","Epoch: [2][400/1438] Elapsed 1m 37s (remain 4m 13s) Loss: 0.0174(0.0124) Grad: 17022.1016  LR: 0.000017  \n","Epoch: [2][500/1438] Elapsed 2m 2s (remain 3m 48s) Loss: 0.0001(0.0121) Grad: 934.8892  LR: 0.000016  \n","Epoch: [2][600/1438] Elapsed 2m 26s (remain 3m 23s) Loss: 0.0061(0.0120) Grad: 18938.0625  LR: 0.000016  \n","Epoch: [2][700/1438] Elapsed 2m 50s (remain 2m 59s) Loss: 0.0057(0.0122) Grad: 8733.1201  LR: 0.000016  \n","Epoch: [2][800/1438] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0106(0.0124) Grad: 30032.9395  LR: 0.000015  \n","Epoch: [2][900/1438] Elapsed 3m 38s (remain 2m 10s) Loss: 0.0087(0.0122) Grad: 12903.0176  LR: 0.000015  \n","Epoch: [2][1000/1438] Elapsed 4m 3s (remain 1m 46s) Loss: 0.0063(0.0121) Grad: 24364.7637  LR: 0.000015  \n","Epoch: [2][1100/1438] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0115(0.0120) Grad: 18775.2168  LR: 0.000014  \n","Epoch: [2][1200/1438] Elapsed 4m 51s (remain 0m 57s) Loss: 0.0291(0.0121) Grad: 57138.3789  LR: 0.000014  \n","Epoch: [2][1300/1438] Elapsed 5m 15s (remain 0m 33s) Loss: 0.0072(0.0120) Grad: 11499.3291  LR: 0.000014  \n","Epoch: [2][1400/1438] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0054(0.0120) Grad: 12189.2998  LR: 0.000013  \n","Epoch: [2][1437/1438] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0187(0.0120) Grad: 35509.1133  LR: 0.000013  \n","EVAL: [0/349] Elapsed 0m 0s (remain 2m 15s) Loss: 0.0065(0.0065) \n","EVAL: [100/349] Elapsed 0m 14s (remain 0m 34s) Loss: 0.0358(0.0118) \n","EVAL: [200/349] Elapsed 0m 27s (remain 0m 20s) Loss: 0.0303(0.0132) \n","EVAL: [300/349] Elapsed 0m 42s (remain 0m 6s) Loss: 0.0126(0.0135) \n","EVAL: [348/349] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0002(0.0127) \n","Epoch 2 - avg_train_loss: 0.0120  avg_val_loss: 0.0127  time: 401s\n","Epoch 2 - Score: 0.8697\n","Epoch 2 - Save Best Score: 0.8697 Model\n","Epoch: [3][0/1438] Elapsed 0m 0s (remain 13m 12s) Loss: 0.0258(0.0258) Grad: 29496.2559  LR: 0.000013  \n","Epoch: [3][100/1438] Elapsed 0m 25s (remain 5m 32s) Loss: 0.0029(0.0118) Grad: 5651.3511  LR: 0.000013  \n","Epoch: [3][200/1438] Elapsed 0m 49s (remain 5m 3s) Loss: 0.0014(0.0101) Grad: 4977.0723  LR: 0.000013  \n","Epoch: [3][300/1438] Elapsed 1m 13s (remain 4m 37s) Loss: 0.0029(0.0096) Grad: 13550.4600  LR: 0.000012  \n","Epoch: [3][400/1438] Elapsed 1m 37s (remain 4m 13s) Loss: 0.0061(0.0102) Grad: 8897.5635  LR: 0.000012  \n","Epoch: [3][500/1438] Elapsed 2m 2s (remain 3m 48s) Loss: 0.0177(0.0101) Grad: 55648.2852  LR: 0.000012  \n","Epoch: [3][600/1438] Elapsed 2m 26s (remain 3m 23s) Loss: 0.0099(0.0100) Grad: 17304.9805  LR: 0.000011  \n","Epoch: [3][700/1438] Elapsed 2m 50s (remain 2m 59s) Loss: 0.0072(0.0099) Grad: 12805.2061  LR: 0.000011  \n","Epoch: [3][800/1438] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0010(0.0099) Grad: 2129.6829  LR: 0.000011  \n","Epoch: [3][900/1438] Elapsed 3m 38s (remain 2m 10s) Loss: 0.0096(0.0099) Grad: 22189.4922  LR: 0.000011  \n","Epoch: [3][1000/1438] Elapsed 4m 3s (remain 1m 46s) Loss: 0.0085(0.0098) Grad: 17298.9355  LR: 0.000010  \n","Epoch: [3][1100/1438] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0003(0.0098) Grad: 925.4197  LR: 0.000010  \n","Epoch: [3][1200/1438] Elapsed 4m 51s (remain 0m 57s) Loss: 0.0168(0.0098) Grad: 44973.4883  LR: 0.000010  \n","Epoch: [3][1300/1438] Elapsed 5m 15s (remain 0m 33s) Loss: 0.0136(0.0096) Grad: 15683.5635  LR: 0.000009  \n","Epoch: [3][1400/1438] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0034(0.0096) Grad: 14928.1172  LR: 0.000009  \n","Epoch: [3][1437/1438] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0226(0.0096) Grad: 17163.9121  LR: 0.000009  \n","EVAL: [0/349] Elapsed 0m 0s (remain 2m 28s) Loss: 0.0080(0.0080) \n","EVAL: [100/349] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0162(0.0113) \n","EVAL: [200/349] Elapsed 0m 28s (remain 0m 20s) Loss: 0.0327(0.0133) \n","EVAL: [300/349] Elapsed 0m 41s (remain 0m 6s) Loss: 0.0060(0.0137) \n","EVAL: [348/349] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0002(0.0130) \n","Epoch 3 - avg_train_loss: 0.0096  avg_val_loss: 0.0130  time: 401s\n","Epoch 3 - Score: 0.8701\n","Epoch 3 - Save Best Score: 0.8701 Model\n","Epoch: [4][0/1438] Elapsed 0m 0s (remain 13m 31s) Loss: 0.0006(0.0006) Grad: 2231.0916  LR: 0.000009  \n","Epoch: [4][100/1438] Elapsed 0m 25s (remain 5m 33s) Loss: 0.0024(0.0066) Grad: 6239.5200  LR: 0.000009  \n","Epoch: [4][200/1438] Elapsed 0m 49s (remain 5m 3s) Loss: 0.0021(0.0078) Grad: 10724.3672  LR: 0.000008  \n","Epoch: [4][300/1438] Elapsed 1m 13s (remain 4m 37s) Loss: 0.0026(0.0077) Grad: 7529.5186  LR: 0.000008  \n","Epoch: [4][400/1438] Elapsed 1m 37s (remain 4m 12s) Loss: 0.0027(0.0076) Grad: 3877.0920  LR: 0.000008  \n","Epoch: [4][500/1438] Elapsed 2m 2s (remain 3m 48s) Loss: 0.0056(0.0074) Grad: 9353.5010  LR: 0.000007  \n","Epoch: [4][600/1438] Elapsed 2m 26s (remain 3m 23s) Loss: 0.0140(0.0074) Grad: 69652.4688  LR: 0.000007  \n","Epoch: [4][700/1438] Elapsed 2m 50s (remain 2m 59s) Loss: 0.0006(0.0074) Grad: 2042.6860  LR: 0.000007  \n","Epoch: [4][800/1438] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0021(0.0074) Grad: 15472.3379  LR: 0.000006  \n","Epoch: [4][900/1438] Elapsed 3m 38s (remain 2m 10s) Loss: 0.0046(0.0077) Grad: 16871.1895  LR: 0.000006  \n","Epoch: [4][1000/1438] Elapsed 4m 3s (remain 1m 46s) Loss: 0.0025(0.0077) Grad: 8280.2646  LR: 0.000006  \n","Epoch: [4][1100/1438] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0065(0.0076) Grad: 13898.0566  LR: 0.000005  \n","Epoch: [4][1200/1438] Elapsed 4m 51s (remain 0m 57s) Loss: 0.0035(0.0077) Grad: 8700.8359  LR: 0.000005  \n","Epoch: [4][1300/1438] Elapsed 5m 15s (remain 0m 33s) Loss: 0.0034(0.0077) Grad: 14946.6221  LR: 0.000005  \n","Epoch: [4][1400/1438] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0034(0.0076) Grad: 23438.2676  LR: 0.000005  \n","Epoch: [4][1437/1438] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0142(0.0076) Grad: 16018.7344  LR: 0.000004  \n","EVAL: [0/349] Elapsed 0m 0s (remain 2m 31s) Loss: 0.0073(0.0073) \n","EVAL: [100/349] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0157(0.0124) \n","EVAL: [200/349] Elapsed 0m 28s (remain 0m 20s) Loss: 0.0462(0.0147) \n","EVAL: [300/349] Elapsed 0m 41s (remain 0m 6s) Loss: 0.0052(0.0148) \n","EVAL: [348/349] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0001(0.0141) \n","Epoch 4 - avg_train_loss: 0.0076  avg_val_loss: 0.0141  time: 401s\n","Epoch 4 - Score: 0.8762\n","Epoch 4 - Save Best Score: 0.8762 Model\n","Epoch: [5][0/1438] Elapsed 0m 0s (remain 14m 28s) Loss: 0.0012(0.0012) Grad: 3533.6204  LR: 0.000004  \n","Epoch: [5][100/1438] Elapsed 0m 25s (remain 5m 33s) Loss: 0.0070(0.0076) Grad: 30696.4766  LR: 0.000004  \n","Epoch: [5][200/1438] Elapsed 0m 49s (remain 5m 5s) Loss: 0.0040(0.0074) Grad: 20944.5215  LR: 0.000004  \n","Epoch: [5][300/1438] Elapsed 1m 13s (remain 4m 38s) Loss: 0.0021(0.0068) Grad: 9645.4561  LR: 0.000004  \n","Epoch: [5][400/1438] Elapsed 1m 37s (remain 4m 13s) Loss: 0.0172(0.0067) Grad: 28555.6953  LR: 0.000003  \n","Epoch: [5][500/1438] Elapsed 2m 2s (remain 3m 48s) Loss: 0.0005(0.0064) Grad: 4671.5967  LR: 0.000003  \n","Epoch: [5][600/1438] Elapsed 2m 26s (remain 3m 23s) Loss: 0.0224(0.0064) Grad: 32333.7520  LR: 0.000003  \n","Epoch: [5][700/1438] Elapsed 2m 50s (remain 2m 59s) Loss: 0.0042(0.0063) Grad: 9942.7852  LR: 0.000002  \n","Epoch: [5][800/1438] Elapsed 3m 14s (remain 2m 34s) Loss: 0.0028(0.0064) Grad: 27662.1289  LR: 0.000002  \n","Epoch: [5][900/1438] Elapsed 3m 38s (remain 2m 10s) Loss: 0.0001(0.0064) Grad: 1097.6188  LR: 0.000002  \n","Epoch: [5][1000/1438] Elapsed 4m 3s (remain 1m 46s) Loss: 0.0004(0.0066) Grad: 3715.4900  LR: 0.000001  \n","Epoch: [5][1100/1438] Elapsed 4m 27s (remain 1m 21s) Loss: 0.0008(0.0065) Grad: 5484.1699  LR: 0.000001  \n","Epoch: [5][1200/1438] Elapsed 4m 51s (remain 0m 57s) Loss: 0.0043(0.0064) Grad: 10043.6680  LR: 0.000001  \n","Epoch: [5][1300/1438] Elapsed 5m 15s (remain 0m 33s) Loss: 0.0097(0.0065) Grad: 55115.3008  LR: 0.000000  \n","Epoch: [5][1400/1438] Elapsed 5m 39s (remain 0m 8s) Loss: 0.0078(0.0065) Grad: 11337.1953  LR: 0.000000  \n","Epoch: [5][1437/1438] Elapsed 5m 48s (remain 0m 0s) Loss: 0.0024(0.0065) Grad: 7296.6182  LR: 0.000000  \n","EVAL: [0/349] Elapsed 0m 0s (remain 2m 27s) Loss: 0.0081(0.0081) \n","EVAL: [100/349] Elapsed 0m 14s (remain 0m 35s) Loss: 0.0204(0.0131) \n","EVAL: [200/349] Elapsed 0m 28s (remain 0m 20s) Loss: 0.0449(0.0158) \n","EVAL: [300/349] Elapsed 0m 42s (remain 0m 6s) Loss: 0.0052(0.0161) \n","EVAL: [348/349] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0000(0.0152) \n","Epoch 5 - avg_train_loss: 0.0065  avg_val_loss: 0.0152  time: 401s\n","Epoch 5 - Score: 0.8779\n","Epoch 5 - Save Best Score: 0.8779 Model\n","========== fold: 4 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp009/checkpoint-129000/pytorch_model.bin\n","Epoch: [1][0/1425] Elapsed 0m 0s (remain 13m 28s) Loss: 0.8457(0.8457) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/1425] Elapsed 0m 25s (remain 5m 30s) Loss: 0.2044(0.6574) Grad: 12126.1787  LR: 0.000003  \n","Epoch: [1][200/1425] Elapsed 0m 49s (remain 5m 0s) Loss: 0.0575(0.3760) Grad: 1201.3767  LR: 0.000006  \n","Epoch: [1][300/1425] Elapsed 1m 13s (remain 4m 34s) Loss: 0.0393(0.2751) Grad: 718.0475  LR: 0.000008  \n","Epoch: [1][400/1425] Elapsed 1m 37s (remain 4m 9s) Loss: 0.0771(0.2198) Grad: 3762.7864  LR: 0.000011  \n","Epoch: [1][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0301(0.1826) Grad: 4843.2871  LR: 0.000014  \n","Epoch: [1][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0251(0.1568) Grad: 4016.2148  LR: 0.000017  \n","Epoch: [1][700/1425] Elapsed 2m 50s (remain 2m 55s) Loss: 0.0123(0.1375) Grad: 856.3359  LR: 0.000020  \n","Epoch: [1][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0193(0.1230) Grad: 1620.2725  LR: 0.000020  \n","Epoch: [1][900/1425] Elapsed 3m 38s (remain 2m 7s) Loss: 0.0155(0.1117) Grad: 1715.3011  LR: 0.000019  \n","Epoch: [1][1000/1425] Elapsed 4m 2s (remain 1m 42s) Loss: 0.0137(0.1025) Grad: 1221.2018  LR: 0.000019  \n","Epoch: [1][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0074(0.0948) Grad: 768.6029  LR: 0.000019  \n","Epoch: [1][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0133(0.0883) Grad: 1019.5375  LR: 0.000018  \n","Epoch: [1][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0234(0.0828) Grad: 1658.8304  LR: 0.000018  \n","Epoch: [1][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0151(0.0780) Grad: 1186.9520  LR: 0.000018  \n","Epoch: [1][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0055(0.0769) Grad: 632.3326  LR: 0.000018  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 18s) Loss: 0.0148(0.0148) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0133(0.0154) \n","EVAL: [200/363] Elapsed 0m 28s (remain 0m 22s) Loss: 0.1753(0.0167) \n","EVAL: [300/363] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0079(0.0168) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0055(0.0150) \n","Epoch 1 - avg_train_loss: 0.0769  avg_val_loss: 0.0150  time: 400s\n","Epoch 1 - Score: 0.8326\n","Epoch 1 - Save Best Score: 0.8326 Model\n","Epoch: [2][0/1425] Elapsed 0m 0s (remain 14m 9s) Loss: 0.0066(0.0066) Grad: 8946.0762  LR: 0.000018  \n","Epoch: [2][100/1425] Elapsed 0m 25s (remain 5m 31s) Loss: 0.0044(0.0148) Grad: 8534.6602  LR: 0.000017  \n","Epoch: [2][200/1425] Elapsed 0m 49s (remain 5m 2s) Loss: 0.0012(0.0131) Grad: 5350.9399  LR: 0.000017  \n","Epoch: [2][300/1425] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0062(0.0124) Grad: 15071.8945  LR: 0.000017  \n","Epoch: [2][400/1425] Elapsed 1m 38s (remain 4m 10s) Loss: 0.0079(0.0124) Grad: 10518.3506  LR: 0.000017  \n","Epoch: [2][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0015(0.0127) Grad: 6300.1519  LR: 0.000016  \n","Epoch: [2][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0037(0.0122) Grad: 7312.3286  LR: 0.000016  \n","Epoch: [2][700/1425] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0065(0.0122) Grad: 12182.8770  LR: 0.000016  \n","Epoch: [2][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0020(0.0124) Grad: 5829.9370  LR: 0.000015  \n","Epoch: [2][900/1425] Elapsed 3m 39s (remain 2m 7s) Loss: 0.0065(0.0122) Grad: 15205.1963  LR: 0.000015  \n","Epoch: [2][1000/1425] Elapsed 4m 3s (remain 1m 43s) Loss: 0.0304(0.0122) Grad: 72895.7344  LR: 0.000015  \n","Epoch: [2][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0048(0.0121) Grad: 18470.1680  LR: 0.000014  \n","Epoch: [2][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0125(0.0122) Grad: 61440.8555  LR: 0.000014  \n","Epoch: [2][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0418(0.0122) Grad: 42997.3242  LR: 0.000014  \n","Epoch: [2][1400/1425] Elapsed 5m 40s (remain 0m 5s) Loss: 0.0036(0.0121) Grad: 7653.9927  LR: 0.000013  \n","Epoch: [2][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0004(0.0120) Grad: 1161.4139  LR: 0.000013  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 31s) Loss: 0.0098(0.0098) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0104(0.0140) \n","EVAL: [200/363] Elapsed 0m 28s (remain 0m 22s) Loss: 0.1807(0.0152) \n","EVAL: [300/363] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0065(0.0151) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0067(0.0133) \n","Epoch 2 - avg_train_loss: 0.0120  avg_val_loss: 0.0133  time: 401s\n","Epoch 2 - Score: 0.8700\n","Epoch 2 - Save Best Score: 0.8700 Model\n","Epoch: [3][0/1425] Elapsed 0m 0s (remain 14m 7s) Loss: 0.0080(0.0080) Grad: 22899.5645  LR: 0.000013  \n","Epoch: [3][100/1425] Elapsed 0m 25s (remain 5m 29s) Loss: 0.0207(0.0088) Grad: 83959.9922  LR: 0.000013  \n","Epoch: [3][200/1425] Elapsed 0m 49s (remain 5m 0s) Loss: 0.0024(0.0086) Grad: 21698.5195  LR: 0.000013  \n","Epoch: [3][300/1425] Elapsed 1m 13s (remain 4m 34s) Loss: 0.0089(0.0096) Grad: 24491.3691  LR: 0.000012  \n","Epoch: [3][400/1425] Elapsed 1m 37s (remain 4m 10s) Loss: 0.0135(0.0094) Grad: 51600.0664  LR: 0.000012  \n","Epoch: [3][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0237(0.0092) Grad: 37363.9844  LR: 0.000012  \n","Epoch: [3][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0076(0.0092) Grad: 13286.3008  LR: 0.000011  \n","Epoch: [3][700/1425] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0045(0.0092) Grad: 13723.8486  LR: 0.000011  \n","Epoch: [3][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0089(0.0092) Grad: 19843.5820  LR: 0.000011  \n","Epoch: [3][900/1425] Elapsed 3m 38s (remain 2m 7s) Loss: 0.0090(0.0093) Grad: 12367.9326  LR: 0.000011  \n","Epoch: [3][1000/1425] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0113(0.0093) Grad: 23368.7812  LR: 0.000010  \n","Epoch: [3][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0014(0.0094) Grad: 3314.8760  LR: 0.000010  \n","Epoch: [3][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0077(0.0093) Grad: 44621.9570  LR: 0.000010  \n","Epoch: [3][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0001(0.0094) Grad: 337.7645  LR: 0.000009  \n","Epoch: [3][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0003(0.0095) Grad: 3257.6799  LR: 0.000009  \n","Epoch: [3][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0024(0.0095) Grad: 6797.0596  LR: 0.000009  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 32s) Loss: 0.0101(0.0101) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0088(0.0133) \n","EVAL: [200/363] Elapsed 0m 28s (remain 0m 22s) Loss: 0.1936(0.0153) \n","EVAL: [300/363] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0120(0.0152) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0068(0.0134) \n","Epoch 3 - avg_train_loss: 0.0095  avg_val_loss: 0.0134  time: 400s\n","Epoch 3 - Score: 0.8708\n","Epoch 3 - Save Best Score: 0.8708 Model\n","Epoch: [4][0/1425] Elapsed 0m 0s (remain 14m 14s) Loss: 0.0006(0.0006) Grad: 2699.4878  LR: 0.000009  \n","Epoch: [4][100/1425] Elapsed 0m 25s (remain 5m 33s) Loss: 0.0061(0.0073) Grad: 9476.7510  LR: 0.000009  \n","Epoch: [4][200/1425] Elapsed 0m 49s (remain 5m 2s) Loss: 0.0052(0.0072) Grad: 8221.7207  LR: 0.000008  \n","Epoch: [4][300/1425] Elapsed 1m 13s (remain 4m 35s) Loss: 0.0091(0.0073) Grad: 28720.9922  LR: 0.000008  \n","Epoch: [4][400/1425] Elapsed 1m 37s (remain 4m 10s) Loss: 0.0081(0.0072) Grad: 36103.7617  LR: 0.000008  \n","Epoch: [4][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0021(0.0074) Grad: 10869.3115  LR: 0.000007  \n","Epoch: [4][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0020(0.0073) Grad: 11548.1416  LR: 0.000007  \n","Epoch: [4][700/1425] Elapsed 2m 50s (remain 2m 56s) Loss: 0.0416(0.0073) Grad: 89607.0312  LR: 0.000007  \n","Epoch: [4][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0070(0.0074) Grad: 11912.8613  LR: 0.000006  \n","Epoch: [4][900/1425] Elapsed 3m 38s (remain 2m 7s) Loss: 0.0035(0.0074) Grad: 16290.6357  LR: 0.000006  \n","Epoch: [4][1000/1425] Elapsed 4m 2s (remain 1m 42s) Loss: 0.0002(0.0074) Grad: 947.1772  LR: 0.000006  \n","Epoch: [4][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0056(0.0074) Grad: 25105.2539  LR: 0.000005  \n","Epoch: [4][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0004(0.0074) Grad: 1386.2539  LR: 0.000005  \n","Epoch: [4][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0114(0.0075) Grad: 31852.4512  LR: 0.000005  \n","Epoch: [4][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0047(0.0075) Grad: 25356.1152  LR: 0.000005  \n","Epoch: [4][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0164(0.0075) Grad: 46115.9648  LR: 0.000004  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 30s) Loss: 0.0112(0.0112) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0107(0.0141) \n","EVAL: [200/363] Elapsed 0m 28s (remain 0m 22s) Loss: 0.1547(0.0153) \n","EVAL: [300/363] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0126(0.0155) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0069(0.0136) \n","Epoch 4 - avg_train_loss: 0.0075  avg_val_loss: 0.0136  time: 400s\n","Epoch 4 - Score: 0.8748\n","Epoch 4 - Save Best Score: 0.8748 Model\n","Epoch: [5][0/1425] Elapsed 0m 0s (remain 14m 24s) Loss: 0.0014(0.0014) Grad: 12583.4121  LR: 0.000004  \n","Epoch: [5][100/1425] Elapsed 0m 25s (remain 5m 30s) Loss: 0.0073(0.0067) Grad: 19559.5996  LR: 0.000004  \n","Epoch: [5][200/1425] Elapsed 0m 49s (remain 5m 0s) Loss: 0.0032(0.0063) Grad: 39683.2500  LR: 0.000004  \n","Epoch: [5][300/1425] Elapsed 1m 13s (remain 4m 34s) Loss: 0.0030(0.0067) Grad: 11155.4092  LR: 0.000004  \n","Epoch: [5][400/1425] Elapsed 1m 37s (remain 4m 10s) Loss: 0.0009(0.0064) Grad: 2497.4119  LR: 0.000003  \n","Epoch: [5][500/1425] Elapsed 2m 2s (remain 3m 45s) Loss: 0.0001(0.0063) Grad: 1833.8262  LR: 0.000003  \n","Epoch: [5][600/1425] Elapsed 2m 26s (remain 3m 20s) Loss: 0.0001(0.0062) Grad: 588.6238  LR: 0.000003  \n","Epoch: [5][700/1425] Elapsed 2m 50s (remain 2m 55s) Loss: 0.0037(0.0062) Grad: 5998.8315  LR: 0.000002  \n","Epoch: [5][800/1425] Elapsed 3m 14s (remain 2m 31s) Loss: 0.0023(0.0062) Grad: 12574.5264  LR: 0.000002  \n","Epoch: [5][900/1425] Elapsed 3m 38s (remain 2m 7s) Loss: 0.0014(0.0062) Grad: 6038.4312  LR: 0.000002  \n","Epoch: [5][1000/1425] Elapsed 4m 3s (remain 1m 42s) Loss: 0.0159(0.0061) Grad: 52007.4258  LR: 0.000001  \n","Epoch: [5][1100/1425] Elapsed 4m 27s (remain 1m 18s) Loss: 0.0230(0.0062) Grad: 60467.6094  LR: 0.000001  \n","Epoch: [5][1200/1425] Elapsed 4m 51s (remain 0m 54s) Loss: 0.0001(0.0061) Grad: 922.7303  LR: 0.000001  \n","Epoch: [5][1300/1425] Elapsed 5m 15s (remain 0m 30s) Loss: 0.0041(0.0062) Grad: 14817.1162  LR: 0.000000  \n","Epoch: [5][1400/1425] Elapsed 5m 39s (remain 0m 5s) Loss: 0.0021(0.0063) Grad: 5691.5366  LR: 0.000000  \n","Epoch: [5][1424/1425] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0010(0.0063) Grad: 4003.8564  LR: 0.000000  \n","EVAL: [0/363] Elapsed 0m 0s (remain 2m 19s) Loss: 0.0118(0.0118) \n","EVAL: [100/363] Elapsed 0m 14s (remain 0m 37s) Loss: 0.0090(0.0154) \n","EVAL: [200/363] Elapsed 0m 28s (remain 0m 22s) Loss: 0.2392(0.0173) \n","EVAL: [300/363] Elapsed 0m 41s (remain 0m 8s) Loss: 0.0163(0.0173) \n","EVAL: [362/363] Elapsed 0m 50s (remain 0m 0s) Loss: 0.0071(0.0152) \n","Epoch 5 - avg_train_loss: 0.0063  avg_val_loss: 0.0152  time: 400s\n","Epoch 5 - Score: 0.8771\n","Epoch 5 - Save Best Score: 0.8771 Model\n","Best thres: 0.5, Score: 0.8762\n","Best thres: 0.4281249999999999, Score: 0.8765\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9453b11c67a14e418659d955403303d3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/533M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Load weight from pretrained\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"791bb207694c4049bd0429f20836500f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Load weight from pretrained\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa38813b7f79463d88f047bfa02c73ec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Exception ignored in: \u003cfunction _ConnectionBase.__del__ at 0x7f78f808b0e0\u003e\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Load weight from pretrained\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2b5b75c59944ceca947f3922627de09","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Load weight from pretrained\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e09aeb4b57e44e078cc50ec15e97c110","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Exception ignored in: \u003cfunction _ConnectionBase.__del__ at 0x7f78f808b0e0\u003e\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Load weight from pretrained\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eab44d78244c4f57a86a7cb3ea04c683","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Exception ignored in: \u003cfunction _ConnectionBase.__del__ at 0x7f78f808b0e0\u003e\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp015.ipynb","provenance":[{"file_id":"1Ki_klcxaZrsVzr5gSBbmm5PArM4mfZeQ","timestamp":1646269293737},{"file_id":"1v3I41Ql3KDNAvGIfYb7iRVxyrfNb1VXn","timestamp":1646219594965}],"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0004befed9514a2ea48fcb0c45558748":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01218ddbff2344849796baf097bd6190":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08000b688d2a4b538649b5cdbba700cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3e2884e25a44aaf8a03a2e4dfd0e8a8","placeholder":"​","style":"IPY_MODEL_ef34bf1439cb4a48b0df525dcd2b2b1c","value":"Downloading: 100%"}},"0a387e6f965f4fa2aef99ce333fdc5b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c92a7ed43c04d12bb2bcb256f1f1cb5","placeholder":"​","style":"IPY_MODEL_a99ec6f1cb9e4d02954b7bf38a93bd62","value":"Downloading: 100%"}},"0cfad39d29aa40f599ff6b2ec38deac5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bd985f4c121420caf705d0bc5ae4c25","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23ea189100994a4b97962439e043aa46","value":42146}},"17715620da58450dbc774307fd1e98d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"179426c693574b61ae01f93341bc65d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c41a49753df49ac8d8e64980d2d6bdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9c00c2dc9ae48d5be435ace0d6a9cb5","placeholder":"​","style":"IPY_MODEL_01218ddbff2344849796baf097bd6190","value":" 474/474 [00:00\u0026lt;00:00, 4.52kB/s]"}},"20d5fe1482264312a6f9c469a6f6050d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21881d10cd8d4d85ba2f6e7d61dd8932":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23ea189100994a4b97962439e043aa46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27003f1063aa4b29ac9ed3ebf9c909eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08000b688d2a4b538649b5cdbba700cc","IPY_MODEL_973c1f0389db46c484a2cafdd9ef609c","IPY_MODEL_e2bca5c53e304a76b5cde93985d38bf4"],"layout":"IPY_MODEL_cc7fda4b7c7a47d0804bf2e413600111"}},"29f256ee4f624c56a16e57cb8fbede74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f0a4ff0c7384f08b033f7a09c9d669a","IPY_MODEL_92198cecdcdf4f82a9d030fef17096b3","IPY_MODEL_93f1604310f6419e8cd803011e0d2077"],"layout":"IPY_MODEL_47abf43c1008454f8978b2f7794bcfb7"}},"3364494ae43b4df88c28e1a4ba53c2ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2291ba4b3c449db97bd5b2afeb9a81f","max":474,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a70bf7efaa804e64b7f57e366d969b85","value":474}},"34131f02602b46fda3457ba516eddc83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"370bdf022ac04918811cbef3224e16c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0004befed9514a2ea48fcb0c45558748","placeholder":"​","style":"IPY_MODEL_6ceefa876f90427a98415ef5737fe29e","value":" 143/143 [00:00\u0026lt;00:00, 1907.51it/s]"}},"3c4327893ecd45ee9f42abb647ab6c58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5db392c05ff4440888b21e346d22b6a","IPY_MODEL_3364494ae43b4df88c28e1a4ba53c2ea","IPY_MODEL_1c41a49753df49ac8d8e64980d2d6bdf"],"layout":"IPY_MODEL_ca17e7d540aa4bb5a1a93da18234f200"}},"3f0a4ff0c7384f08b033f7a09c9d669a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94fdd8d4404a4a12b6354a583b4a1906","placeholder":"​","style":"IPY_MODEL_8235e2d2e9664349959cb312b9ecc591","value":"Downloading: 100%"}},"479d661e03334fbb98d4520bd912429e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47abf43c1008454f8978b2f7794bcfb7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b935c606ad24f06903edef21a7e4949":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bafc6bb4a568412d91e08f380f3c6ac9","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9b0f3fa2ad940a08464d77576111ae6","value":456318}},"4bb0c535e149497aae8e4593ef0bb88b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d9b03b832749e3a65ea8902ccc151a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a968478f77484747a458bb876d7be864","IPY_MODEL_0cfad39d29aa40f599ff6b2ec38deac5","IPY_MODEL_c85a74decd36442aa93f7182bd976e45"],"layout":"IPY_MODEL_17715620da58450dbc774307fd1e98d1"}},"55361dc6ed414bfc8e5f372108161d8a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd985f4c121420caf705d0bc5ae4c25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60eeb5cc7b164d5882c60dccb7a56c0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61257badfe8446928aac2e5da886238f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfa7b843fc49471d9de6afa0710094a8","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c5865f100894b649c5c0b606fa93618","value":143}},"6ceefa876f90427a98415ef5737fe29e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6de3559f996048bfa0664728c4e56d1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f59ef9653634028a25a62e59dc06440","placeholder":"​","style":"IPY_MODEL_20d5fe1482264312a6f9c469a6f6050d","value":" 446k/446k [00:00\u0026lt;00:00, 887kB/s]"}},"7c92a7ed43c04d12bb2bcb256f1f1cb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f59ef9653634028a25a62e59dc06440":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8235e2d2e9664349959cb312b9ecc591":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"840199ab0cbf4c468717bcb2b1e4bc11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92198cecdcdf4f82a9d030fef17096b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34131f02602b46fda3457ba516eddc83","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c7bbfae26e34dc2be13902695d92a95","value":898825}},"93b4ea87fa754298859a8026ceb601fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93f1604310f6419e8cd803011e0d2077":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7cf0bbe01c346039c7d5ae5c1704ee9","placeholder":"​","style":"IPY_MODEL_60eeb5cc7b164d5882c60dccb7a56c0c","value":" 878k/878k [00:00\u0026lt;00:00, 2.37MB/s]"}},"94fdd8d4404a4a12b6354a583b4a1906":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"973c1f0389db46c484a2cafdd9ef609c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2f9470ad30d49eea6effd068d42e16a","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_840199ab0cbf4c468717bcb2b1e4bc11","value":52}},"987fd6e2a61741ae9afb474219e27716":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbc9daa879ee4e2d89346f1ed55f38c4","IPY_MODEL_61257badfe8446928aac2e5da886238f","IPY_MODEL_370bdf022ac04918811cbef3224e16c7"],"layout":"IPY_MODEL_21881d10cd8d4d85ba2f6e7d61dd8932"}},"9c5865f100894b649c5c0b606fa93618":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c7bbfae26e34dc2be13902695d92a95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a70bf7efaa804e64b7f57e366d969b85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7cf0bbe01c346039c7d5ae5c1704ee9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a968478f77484747a458bb876d7be864":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55361dc6ed414bfc8e5f372108161d8a","placeholder":"​","style":"IPY_MODEL_ca3f03aed94d4f8d86fb2126cfe1ac23","value":"100%"}},"a99ec6f1cb9e4d02954b7bf38a93bd62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9613f09e3c545ed9c2a3d04a2a0c09c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a387e6f965f4fa2aef99ce333fdc5b9","IPY_MODEL_4b935c606ad24f06903edef21a7e4949","IPY_MODEL_6de3559f996048bfa0664728c4e56d1c"],"layout":"IPY_MODEL_479d661e03334fbb98d4520bd912429e"}},"b9b0f3fa2ad940a08464d77576111ae6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bafc6bb4a568412d91e08f380f3c6ac9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be96c4c010cc417b82d055063c5bf65a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c034af6cc8934cf58644ddee9d462f4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f9470ad30d49eea6effd068d42e16a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c85a74decd36442aa93f7182bd976e45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f91b13a76e9940319cd3dd092aced855","placeholder":"​","style":"IPY_MODEL_ee6832622036437cb08b46677f908c38","value":" 42146/42146 [00:29\u0026lt;00:00, 2087.69it/s]"}},"ca17e7d540aa4bb5a1a93da18234f200":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca3f03aed94d4f8d86fb2126cfe1ac23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc7fda4b7c7a47d0804bf2e413600111":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3e2884e25a44aaf8a03a2e4dfd0e8a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5db392c05ff4440888b21e346d22b6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_179426c693574b61ae01f93341bc65d9","placeholder":"​","style":"IPY_MODEL_f6e7cb9ff374473a8d06193c0bd145d5","value":"Downloading: 100%"}},"dfa7b843fc49471d9de6afa0710094a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2bca5c53e304a76b5cde93985d38bf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c034af6cc8934cf58644ddee9d462f4d","placeholder":"​","style":"IPY_MODEL_4bb0c535e149497aae8e4593ef0bb88b","value":" 52.0/52.0 [00:00\u0026lt;00:00, 477B/s]"}},"e9c00c2dc9ae48d5be435ace0d6a9cb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee6832622036437cb08b46677f908c38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef34bf1439cb4a48b0df525dcd2b2b1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2291ba4b3c449db97bd5b2afeb9a81f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6e7cb9ff374473a8d06193c0bd145d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f91b13a76e9940319cd3dd092aced855":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc9daa879ee4e2d89346f1ed55f38c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93b4ea87fa754298859a8026ceb601fd","placeholder":"​","style":"IPY_MODEL_be96c4c010cc417b82d055063c5bf65a","value":"100%"}}}}},"nbformat":4,"nbformat_minor":5}