{"cells":[{"cell_type":"markdown","id":"brave-teach","metadata":{"id":"brave-teach"},"source":["## References"]},{"cell_type":"markdown","id":"orange-toilet","metadata":{"id":"orange-toilet"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"serious-sending","metadata":{"id":"serious-sending"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"august-providence","metadata":{"id":"august-providence","executionInfo":{"status":"ok","timestamp":1647514534352,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp048\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"cathedral-horror","metadata":{"id":"cathedral-horror","executionInfo":{"status":"ok","timestamp":1647514534353,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"armed-norfolk","metadata":{"id":"armed-norfolk","executionInfo":{"status":"ok","timestamp":1647514534353,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"atlantic-warrant","metadata":{"id":"atlantic-warrant"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"federal-marsh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"federal-marsh","outputId":"56d9a6b7-0d13-4141-9d48-3abdf4a5214b","executionInfo":{"status":"ok","timestamp":1647514541804,"user_tz":-540,"elapsed":7457,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.4.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.49)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"recent-harrison","metadata":{"id":"recent-harrison","executionInfo":{"status":"ok","timestamp":1647514553451,"user_tz":-540,"elapsed":11650,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"technical-story","metadata":{"id":"technical-story"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"understanding-trial","metadata":{"id":"understanding-trial","executionInfo":{"status":"ok","timestamp":1647514553451,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"pursuant-lover","metadata":{"id":"pursuant-lover","executionInfo":{"status":"ok","timestamp":1647514553452,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"matched-hollow","metadata":{"id":"matched-hollow","executionInfo":{"status":"ok","timestamp":1647514553452,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"weighted-screw","metadata":{"id":"weighted-screw","executionInfo":{"status":"ok","timestamp":1647514553453,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"following-passport","metadata":{"id":"following-passport"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"absent-performance","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"absent-performance","outputId":"7c0d84e0-c781-481f-980a-fe18d6973f9e","executionInfo":{"status":"ok","timestamp":1647514554506,"user_tz":-540,"elapsed":1058,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"automated-proportion","metadata":{"id":"automated-proportion","executionInfo":{"status":"ok","timestamp":1647514554506,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"preceding-january","metadata":{"id":"preceding-january"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"monetary-camera","metadata":{"id":"monetary-camera","executionInfo":{"status":"ok","timestamp":1647514554507,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"fitted-current","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fitted-current","outputId":"20ab854f-f425-4b74-b02f-69154960882f","executionInfo":{"status":"ok","timestamp":1647514554507,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"australian-vehicle","metadata":{"id":"australian-vehicle","executionInfo":{"status":"ok","timestamp":1647514555195,"user_tz":-540,"elapsed":692,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"devoted-peter","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"devoted-peter","outputId":"a9fa2c67-d76b-40f5-ab9d-6c138a47d129","executionInfo":{"status":"ok","timestamp":1647514555196,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"incorrect-honey","metadata":{"id":"incorrect-honey"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"adjacent-antibody","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"adjacent-antibody","outputId":"90e146ef-2301-4fdf-d1ec-851ecbb564fb","executionInfo":{"status":"ok","timestamp":1647514555196,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"breathing-state","metadata":{"id":"breathing-state"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"former-beast","metadata":{"id":"former-beast","executionInfo":{"status":"ok","timestamp":1647514559538,"user_tz":-540,"elapsed":4348,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDMSkwTNgOOh","executionInfo":{"status":"ok","timestamp":1647514559540,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"0086eaa9-057d-425c-ab98-dd64de72f59a"},"id":"TDMSkwTNgOOh","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}]},{"cell_type":"markdown","id":"employed-foster","metadata":{"id":"employed-foster"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":19,"id":"biblical-mailing","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["5e681c596edd41babf7beff766c5c8ad","7a1b765f207c4522acb2339cfb82f957","845e31e01a5d4fd59903151f41837b3b","3e70839747414fe485eb1f7082c3712d","40074485cbba42919a7227c6ad3387c0","fcf45caa4f1a41e4a6f5e631a5cd42b5","75a1d8073d20417abf7e073bb1b5505a","70b6035667644d2eac0e89b1fbef904e","e5d5f2ca6a034cd2b7ea6f05acbdf800","1659e9b3465c44a5a144027b1a4aeba9","b40fe842c0cc4c42bae96b6e3b3f1f5c"]},"id":"biblical-mailing","outputId":"3ce56511-b419-47ff-edc0-78026e6f1c46","executionInfo":{"status":"ok","timestamp":1647514600266,"user_tz":-540,"elapsed":40733,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e681c596edd41babf7beff766c5c8ad"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":20,"id":"renewable-mercury","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["482e836f26cf4e9b82548a2745155357","874f6bcfbf9a4427a36e2d512de220b3","e65984f737ed45479dbbad33ded31a3a","8e8a4f9fc79943179fd75bd89aa09ebb","c3f35f0b42a84a9db4409a3ac016aced","f8e498a67b134a99afc6863f2c9185c8","5083befca19b4f2394b38cb62a40960a","8c78cbc6bf414aa58c802707de688f53","46baddaf15d8450a8f9b081ee3f7b950","e58aa77e10254395ba3a595c22e701a6","e7c8da8989144074bd8c1d576bc772a3"]},"id":"renewable-mercury","outputId":"bb7f0836-549c-4fa0-d520-1522f0497870","executionInfo":{"status":"ok","timestamp":1647514600267,"user_tz":-540,"elapsed":12,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"482e836f26cf4e9b82548a2745155357"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":21,"id":"latin-burlington","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"latin-burlington","outputId":"e3c0d7c4-7a86-4c55-a9d4-1d0d5bbe49ff","executionInfo":{"status":"ok","timestamp":1647514600268,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":22,"id":"minor-stock","metadata":{"id":"minor-stock","executionInfo":{"status":"ok","timestamp":1647514600268,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":23,"id":"decimal-schema","metadata":{"id":"decimal-schema","executionInfo":{"status":"ok","timestamp":1647514600269,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"exceptional-vertical","metadata":{"id":"exceptional-vertical"},"source":["## Model"]},{"cell_type":"code","execution_count":24,"id":"dynamic-fifteen","metadata":{"id":"dynamic-fifteen","executionInfo":{"status":"ok","timestamp":1647514600746,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            #path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size * 4, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"hidden_states\"]\n","        h = torch.cat([h[-1*i][:, :] for i in range(1, 4 + 1)], dim=2)  # concatenate\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"driving-commercial","metadata":{"id":"driving-commercial"},"source":["## Training"]},{"cell_type":"code","execution_count":25,"id":"cathedral-component","metadata":{"id":"cathedral-component","executionInfo":{"status":"ok","timestamp":1647514600746,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":26,"id":"expired-wilson","metadata":{"id":"expired-wilson","executionInfo":{"status":"ok","timestamp":1647514600747,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":27,"id":"chinese-sympathy","metadata":{"id":"chinese-sympathy","executionInfo":{"status":"ok","timestamp":1647514600747,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":28,"id":"healthy-sleep","metadata":{"id":"healthy-sleep","executionInfo":{"status":"ok","timestamp":1647514600748,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"balanced-novel","metadata":{"id":"balanced-novel"},"source":["## Main"]},{"cell_type":"code","execution_count":29,"id":"sound-silly","metadata":{"id":"sound-silly","executionInfo":{"status":"ok","timestamp":1647514600748,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"id":"reduced-indication","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b7612c64baee4b8b912acb7e8eaf245d","7a8a3541789a4d13848a6b1d8a60c054","61555545ad8b490d8a8a7491d7fa1987","fb22a3b4bfd546b280af6fdbb9eed68c","1c274a1a846444ae8e5df1de12185f82","47c6c452787f443293ed9d3f960cc6ce","310cc481328e49499b4a402d7774978b","201c3a56a47a4e3d8b0923cd138d5c6c","34bf15acd50b4893b9c022b6702a6824","0664030521ee40f0aa559e98a7b544f2","cd06540a8e674b20ae19da95d329f690","1a0715b76dac4db99e051678e29922c2","fa56fd6662ed46a484c7a99e7b05a6d9","0f76e245a2f14b6e8589e3475009eece","10e922ea99744d3086faf7d2f2189c79","649688b4151949c490467c376e0d075c","b266911088c44615adb142701198f968","aa833f59a52a4b75bbeec4c0881c617c","0ef9b9a216ee4be0ab6f1b870ddf63f1","0d78bf2cd8c74cf1a1b0401ed0d3c931","ffd051b5ad9e41c7ae8f2f4730cd57ca","6f016d851bf842838c58c1d2fcb81b45","c08b011de94e488ba605612b27d609ff","a31b036c7bd74f1e8d86af1a63e922c4","b43419fcb785466fac40db8a85659eed","72d2598c2da641199191e58a339ae6f2","bbd2aeefb3e340e3973a7efab173f39b","0146c86fb9404b4cba43ab432254eb43","e8b87185c4ea48ee866038687b5d76b4","aeb9a41dc5e64876b74579c74fc43c64","4e4a083e73774d089a12e0be8b70b7bd","2302d2a80d1c42c198802d010b487629","edd524c299534431b31116951243346c"]},"id":"reduced-indication","outputId":"f2fdd1e2-6963-49ad-f78c-f4afe3010a70"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 1s (remain 61m 19s) Loss: 1.0361(1.0361) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 31s (remain 18m 5s) Loss: 0.5077(0.6904) Grad: 51213.1250  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 1m 2s (remain 17m 21s) Loss: 0.1377(0.5323) Grad: 9910.9033  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 33s (remain 17m 2s) Loss: 0.0414(0.3789) Grad: 1081.2637  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 2m 4s (remain 16m 27s) Loss: 0.0260(0.2930) Grad: 1258.8556  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 35s (remain 15m 52s) Loss: 0.0181(0.2424) Grad: 829.9347  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 3m 5s (remain 15m 19s) Loss: 0.0486(0.2063) Grad: 3691.7275  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 36s (remain 14m 48s) Loss: 0.0268(0.1794) Grad: 4565.7725  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 4m 7s (remain 14m 17s) Loss: 0.0058(0.1592) Grad: 534.1230  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 38s (remain 13m 46s) Loss: 0.0038(0.1435) Grad: 583.1598  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 5m 9s (remain 13m 15s) Loss: 0.0044(0.1305) Grad: 1914.9600  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 40s (remain 12m 44s) Loss: 0.0032(0.1196) Grad: 462.6579  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 6m 11s (remain 12m 14s) Loss: 0.0141(0.1106) Grad: 4673.9854  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 42s (remain 11m 43s) Loss: 0.0066(0.1029) Grad: 1524.4581  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 7m 13s (remain 11m 12s) Loss: 0.0023(0.0964) Grad: 679.1495  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 44s (remain 10m 41s) Loss: 0.0017(0.0906) Grad: 407.8016  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 8m 14s (remain 10m 9s) Loss: 0.0041(0.0857) Grad: 893.4397  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 45s (remain 9m 38s) Loss: 0.0002(0.0811) Grad: 98.4644  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 9m 15s (remain 9m 7s) Loss: 0.0089(0.0771) Grad: 1166.0389  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 46s (remain 8m 36s) Loss: 0.0077(0.0736) Grad: 675.5845  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 10m 16s (remain 8m 5s) Loss: 0.0035(0.0705) Grad: 463.5388  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 47s (remain 7m 33s) Loss: 0.0047(0.0676) Grad: 579.3981  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 11m 17s (remain 7m 3s) Loss: 0.0039(0.0649) Grad: 1552.7693  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 48s (remain 6m 32s) Loss: 0.0003(0.0625) Grad: 95.4231  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 12m 18s (remain 6m 1s) Loss: 0.0001(0.0602) Grad: 27.4338  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 48s (remain 5m 30s) Loss: 0.0055(0.0582) Grad: 1092.5806  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 13m 19s (remain 4m 59s) Loss: 0.0028(0.0564) Grad: 372.9163  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 49s (remain 4m 28s) Loss: 0.0002(0.0546) Grad: 69.6380  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 14m 19s (remain 3m 57s) Loss: 0.0009(0.0530) Grad: 154.5803  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 50s (remain 3m 26s) Loss: 0.0005(0.0514) Grad: 97.0253  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 15m 20s (remain 2m 56s) Loss: 0.0009(0.0500) Grad: 183.9256  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 50s (remain 2m 25s) Loss: 0.0032(0.0487) Grad: 401.5802  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 16m 20s (remain 1m 54s) Loss: 0.0015(0.0474) Grad: 320.5801  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 51s (remain 1m 23s) Loss: 0.0010(0.0461) Grad: 184.7450  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 17m 21s (remain 0m 53s) Loss: 0.0016(0.0450) Grad: 357.8864  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 17m 52s (remain 0m 22s) Loss: 0.0033(0.0439) Grad: 1232.7129  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0217(0.0431) Grad: 3743.4961  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 12s) Loss: 0.0008(0.0008) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 14s) Loss: 0.0072(0.0051) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 55s) Loss: 0.0133(0.0052) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0058(0.0054) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0028(0.0058) \n","EVAL: [500/1192] Elapsed 1m 29s (remain 2m 2s) Loss: 0.0096(0.0055) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 45s) Loss: 0.0211(0.0058) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0614(0.0075) \n","EVAL: [800/1192] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0071(0.0077) \n","EVAL: [900/1192] Elapsed 2m 40s (remain 0m 51s) Loss: 0.0161(0.0077) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0005(0.0076) \n","EVAL: [1100/1192] Elapsed 3m 15s (remain 0m 16s) Loss: 0.0048(0.0073) \n","EVAL: [1191/1192] Elapsed 3m 31s (remain 0m 0s) Loss: 0.0002(0.0070) \n","Epoch 1 - avg_train_loss: 0.0431  avg_val_loss: 0.0070  time: 1313s\n","Epoch 1 - Score: 0.8603\n","Epoch 1 - Save Best Score: 0.8603 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 38m 54s) Loss: 0.0067(0.0067) Grad: 18157.1426  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 34s (remain 19m 33s) Loss: 0.0079(0.0063) Grad: 49257.0664  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 5s (remain 18m 12s) Loss: 0.0003(0.0060) Grad: 1418.3705  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 35s (remain 17m 19s) Loss: 0.0001(0.0054) Grad: 268.4273  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 6s (remain 16m 38s) Loss: 0.0046(0.0058) Grad: 42694.5664  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 36s (remain 16m 0s) Loss: 0.0063(0.0058) Grad: 13617.8486  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 3m 7s (remain 15m 25s) Loss: 0.0011(0.0058) Grad: 8465.8555  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 37s (remain 14m 51s) Loss: 0.0005(0.0060) Grad: 1787.6053  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 4m 7s (remain 14m 18s) Loss: 0.0000(0.0061) Grad: 88.5884  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 38s (remain 13m 46s) Loss: 0.0283(0.0061) Grad: 32593.5684  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 5m 8s (remain 13m 13s) Loss: 0.0156(0.0065) Grad: 53388.6289  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 39s (remain 12m 42s) Loss: 0.0022(0.0064) Grad: 4790.5317  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 6m 9s (remain 12m 10s) Loss: 0.0128(0.0067) Grad: 17785.5664  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 39s (remain 11m 38s) Loss: 0.0044(0.0065) Grad: 9609.6719  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 7m 10s (remain 11m 7s) Loss: 0.0001(0.0064) Grad: 295.0386  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 40s (remain 10m 36s) Loss: 0.0073(0.0065) Grad: 13288.7979  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 8m 10s (remain 10m 5s) Loss: 0.0091(0.0065) Grad: 21194.4727  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 41s (remain 9m 34s) Loss: 0.0001(0.0065) Grad: 1732.8578  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 9m 11s (remain 9m 3s) Loss: 0.0086(0.0065) Grad: 22078.3301  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 41s (remain 8m 32s) Loss: 0.0042(0.0065) Grad: 60117.5430  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 10m 12s (remain 8m 1s) Loss: 0.0000(0.0065) Grad: 14.7337  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 42s (remain 7m 30s) Loss: 0.0003(0.0066) Grad: 2729.7500  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 11m 12s (remain 6m 59s) Loss: 0.0000(0.0066) Grad: 71.0581  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 42s (remain 6m 29s) Loss: 0.0002(0.0066) Grad: 3475.5366  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 12m 13s (remain 5m 58s) Loss: 0.0048(0.0066) Grad: 16923.7383  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 44s (remain 5m 28s) Loss: 0.0056(0.0065) Grad: 37254.1680  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 13m 15s (remain 4m 57s) Loss: 0.0000(0.0066) Grad: 48.1782  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 46s (remain 4m 27s) Loss: 0.0136(0.0066) Grad: 38795.7773  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 14m 17s (remain 3m 56s) Loss: 0.0001(0.0066) Grad: 276.3445  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 47s (remain 3m 26s) Loss: 0.0002(0.0065) Grad: 751.4619  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 15m 18s (remain 2m 55s) Loss: 0.0000(0.0065) Grad: 34.6427  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 49s (remain 2m 25s) Loss: 0.0011(0.0065) Grad: 4394.8867  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 16m 19s (remain 1m 54s) Loss: 0.0000(0.0065) Grad: 10.9593  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 50s (remain 1m 23s) Loss: 0.0037(0.0065) Grad: 17422.6934  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 17m 20s (remain 0m 53s) Loss: 0.0161(0.0065) Grad: 91700.0859  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 50s (remain 0m 22s) Loss: 0.0025(0.0065) Grad: 7900.5713  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 18m 13s (remain 0m 0s) Loss: 0.0006(0.0064) Grad: 2640.3501  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 21s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 14s) Loss: 0.0108(0.0066) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 55s) Loss: 0.0061(0.0064) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 37s) Loss: 0.0056(0.0065) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 19s) Loss: 0.0054(0.0066) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 1s) Loss: 0.0056(0.0061) \n","EVAL: [600/1192] Elapsed 1m 45s (remain 1m 43s) Loss: 0.0426(0.0066) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0748(0.0085) \n","EVAL: [800/1192] Elapsed 2m 20s (remain 1m 8s) Loss: 0.0008(0.0089) \n","EVAL: [900/1192] Elapsed 2m 38s (remain 0m 51s) Loss: 0.0055(0.0089) \n","EVAL: [1000/1192] Elapsed 2m 55s (remain 0m 33s) Loss: 0.0000(0.0087) \n","EVAL: [1100/1192] Elapsed 3m 13s (remain 0m 15s) Loss: 0.0068(0.0084) \n","EVAL: [1191/1192] Elapsed 3m 28s (remain 0m 0s) Loss: 0.0000(0.0081) \n","Epoch 2 - avg_train_loss: 0.0064  avg_val_loss: 0.0081  time: 1308s\n","Epoch 2 - Score: 0.8747\n","Epoch 2 - Save Best Score: 0.8747 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 36m 36s) Loss: 0.0095(0.0095) Grad: 17314.2520  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 33s (remain 19m 3s) Loss: 0.0066(0.0059) Grad: 16687.9043  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 4s (remain 17m 57s) Loss: 0.0006(0.0052) Grad: 3398.8369  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 34s (remain 17m 8s) Loss: 0.0001(0.0058) Grad: 951.2940  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 5s (remain 16m 29s) Loss: 0.0000(0.0060) Grad: 150.8230  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 35s (remain 15m 52s) Loss: 0.0082(0.0058) Grad: 40515.1719  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 5s (remain 15m 18s) Loss: 0.0006(0.0059) Grad: 2227.0259  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 35s (remain 14m 44s) Loss: 0.0000(0.0060) Grad: 33.3589  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 4m 6s (remain 14m 12s) Loss: 0.1475(0.0060) Grad: 215697.0312  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 36s (remain 13m 40s) Loss: 0.0082(0.0059) Grad: 18440.6699  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 5m 7s (remain 13m 9s) Loss: 0.0002(0.0059) Grad: 826.8409  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 37s (remain 12m 38s) Loss: 0.0001(0.0058) Grad: 211.4407  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 6m 8s (remain 12m 7s) Loss: 0.0027(0.0057) Grad: 9528.8555  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 38s (remain 11m 36s) Loss: 0.0002(0.0056) Grad: 2081.9087  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 7m 9s (remain 11m 5s) Loss: 0.0000(0.0056) Grad: 10.2212  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 39s (remain 10m 34s) Loss: 0.0028(0.0055) Grad: 22238.9492  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 8m 10s (remain 10m 4s) Loss: 0.0000(0.0054) Grad: 284.1075  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 40s (remain 9m 33s) Loss: 0.0049(0.0055) Grad: 18161.5586  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 9m 11s (remain 9m 2s) Loss: 0.0000(0.0054) Grad: 118.0530  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 42s (remain 8m 32s) Loss: 0.0075(0.0053) Grad: 19356.5801  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 10m 12s (remain 8m 1s) Loss: 0.0000(0.0053) Grad: 11.0107  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 43s (remain 7m 31s) Loss: 0.0000(0.0052) Grad: 11.1858  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 11m 13s (remain 7m 0s) Loss: 0.0000(0.0052) Grad: 100.9317  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 44s (remain 6m 30s) Loss: 0.0026(0.0052) Grad: 34856.1836  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 12m 15s (remain 5m 59s) Loss: 0.0020(0.0052) Grad: 5148.1597  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 45s (remain 5m 28s) Loss: 0.0087(0.0052) Grad: 34926.0977  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 13m 16s (remain 4m 58s) Loss: 0.0000(0.0052) Grad: 130.3503  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 46s (remain 4m 27s) Loss: 0.0000(0.0053) Grad: 36.6072  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 14m 17s (remain 3m 57s) Loss: 0.0012(0.0053) Grad: 5081.6245  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 48s (remain 3m 26s) Loss: 0.0298(0.0052) Grad: 47091.4375  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 15m 19s (remain 2m 55s) Loss: 0.0013(0.0052) Grad: 6785.3530  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 50s (remain 2m 25s) Loss: 0.0000(0.0051) Grad: 59.8990  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 16m 21s (remain 1m 54s) Loss: 0.0000(0.0051) Grad: 125.1296  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 52s (remain 1m 24s) Loss: 0.0045(0.0051) Grad: 8836.3271  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 17m 22s (remain 0m 53s) Loss: 0.0007(0.0050) Grad: 4433.5415  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 53s (remain 0m 22s) Loss: 0.0000(0.0051) Grad: 133.7123  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 18m 16s (remain 0m 0s) Loss: 0.0013(0.0051) Grad: 5731.1250  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 45s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 16s) Loss: 0.0103(0.0077) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 57s) Loss: 0.0235(0.0070) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 39s) Loss: 0.0106(0.0072) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0048(0.0073) \n","EVAL: [500/1192] Elapsed 1m 29s (remain 2m 3s) Loss: 0.0056(0.0065) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 45s) Loss: 0.0177(0.0070) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0785(0.0096) \n","EVAL: [800/1192] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0008(0.0098) \n","EVAL: [900/1192] Elapsed 2m 40s (remain 0m 51s) Loss: 0.0030(0.0098) \n","EVAL: [1000/1192] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0000(0.0095) \n","EVAL: [1100/1192] Elapsed 3m 16s (remain 0m 16s) Loss: 0.0298(0.0092) \n","EVAL: [1191/1192] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0000(0.0089) \n","Epoch 3 - avg_train_loss: 0.0051  avg_val_loss: 0.0089  time: 1315s\n","Epoch 3 - Score: 0.8725\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 40m 25s) Loss: 0.0000(0.0000) Grad: 1010.3442  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 31s (remain 18m 18s) Loss: 0.0000(0.0030) Grad: 68.5059  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 3s (remain 17m 40s) Loss: 0.0000(0.0043) Grad: 35.4489  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 34s (remain 17m 6s) Loss: 0.0000(0.0041) Grad: 144.2770  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 5s (remain 16m 33s) Loss: 0.0347(0.0041) Grad: 69845.2031  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 36s (remain 16m 1s) Loss: 0.0163(0.0043) Grad: 24721.7988  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 3m 7s (remain 15m 26s) Loss: 0.0018(0.0041) Grad: 7393.6675  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 37s (remain 14m 53s) Loss: 0.0000(0.0041) Grad: 30.7008  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 4m 9s (remain 14m 22s) Loss: 0.0000(0.0043) Grad: 517.7061  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 39s (remain 13m 50s) Loss: 0.0001(0.0043) Grad: 860.2507  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 5m 10s (remain 13m 18s) Loss: 0.0008(0.0041) Grad: 10093.0410  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 41s (remain 12m 46s) Loss: 0.0193(0.0040) Grad: 59682.1562  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 6m 11s (remain 12m 15s) Loss: 0.0000(0.0039) Grad: 11.8979  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 42s (remain 11m 43s) Loss: 0.0002(0.0039) Grad: 1325.7628  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 7m 13s (remain 11m 13s) Loss: 0.0000(0.0040) Grad: 38.5265  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 44s (remain 10m 42s) Loss: 0.0032(0.0040) Grad: 24782.2129  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 8m 15s (remain 10m 11s) Loss: 0.0000(0.0040) Grad: 39.9945  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 46s (remain 9m 40s) Loss: 0.0008(0.0040) Grad: 8996.2803  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 9m 17s (remain 9m 9s) Loss: 0.0511(0.0040) Grad: 355904.1562  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 48s (remain 8m 38s) Loss: 0.0006(0.0042) Grad: 9289.6963  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 10m 18s (remain 8m 6s) Loss: 0.0000(0.0041) Grad: 109.5134  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 49s (remain 7m 35s) Loss: 0.0001(0.0041) Grad: 416.1872  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 11m 20s (remain 7m 4s) Loss: 0.0000(0.0042) Grad: 43.0125  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 51s (remain 6m 33s) Loss: 0.0002(0.0042) Grad: 2264.4036  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 12m 22s (remain 6m 2s) Loss: 0.0135(0.0041) Grad: 27339.0801  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 52s (remain 5m 31s) Loss: 0.0000(0.0041) Grad: 36.8592  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 13m 23s (remain 5m 1s) Loss: 0.0000(0.0041) Grad: 11.3447  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 55s (remain 4m 30s) Loss: 0.0000(0.0042) Grad: 29.2506  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 14m 26s (remain 3m 59s) Loss: 0.0000(0.0042) Grad: 176.9544  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 57s (remain 3m 28s) Loss: 0.0004(0.0042) Grad: 3225.5828  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 15m 28s (remain 2m 57s) Loss: 0.0003(0.0042) Grad: 1473.0280  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 59s (remain 2m 26s) Loss: 0.0004(0.0042) Grad: 6444.2153  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 16m 29s (remain 1m 55s) Loss: 0.0015(0.0043) Grad: 4688.4526  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 17m 0s (remain 1m 24s) Loss: 0.0062(0.0043) Grad: 25465.2656  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 17m 31s (remain 0m 53s) Loss: 0.0051(0.0043) Grad: 31140.2148  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 18m 2s (remain 0m 22s) Loss: 0.0000(0.0043) Grad: 213.7090  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 18m 24s (remain 0m 0s) Loss: 0.0000(0.0043) Grad: 103.4655  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 20s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 16s) Loss: 0.0180(0.0085) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 56s) Loss: 0.0272(0.0081) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0044(0.0080) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0050(0.0078) \n","EVAL: [500/1192] Elapsed 1m 29s (remain 2m 3s) Loss: 0.0078(0.0071) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 45s) Loss: 0.0305(0.0076) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0868(0.0099) \n","EVAL: [800/1192] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0002(0.0105) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0009(0.0106) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0000(0.0104) \n","EVAL: [1100/1192] Elapsed 3m 15s (remain 0m 16s) Loss: 0.0105(0.0100) \n","EVAL: [1191/1192] Elapsed 3m 30s (remain 0m 0s) Loss: 0.0000(0.0098) \n","Epoch 4 - avg_train_loss: 0.0043  avg_val_loss: 0.0098  time: 1321s\n","Epoch 4 - Score: 0.8804\n","Epoch 4 - Save Best Score: 0.8804 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 38m 18s) Loss: 0.0000(0.0000) Grad: 121.9693  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 33s (remain 19m 24s) Loss: 0.0000(0.0040) Grad: 299.7061  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 4s (remain 18m 7s) Loss: 0.0000(0.0041) Grad: 3.6028  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 35s (remain 17m 17s) Loss: 0.0000(0.0037) Grad: 282.7736  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 2m 6s (remain 16m 37s) Loss: 0.0000(0.0039) Grad: 26.8539  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 37s (remain 16m 3s) Loss: 0.0000(0.0037) Grad: 7.4981  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 3m 7s (remain 15m 30s) Loss: 0.0000(0.0038) Grad: 16.5403  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 38s (remain 14m 57s) Loss: 0.0000(0.0038) Grad: 137.4118  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 4m 9s (remain 14m 24s) Loss: 0.0204(0.0036) Grad: 41946.7109  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 40s (remain 13m 51s) Loss: 0.0000(0.0037) Grad: 128.3475  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 5m 10s (remain 13m 19s) Loss: 0.0000(0.0037) Grad: 102.1539  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 41s (remain 12m 47s) Loss: 0.0012(0.0038) Grad: 4636.1826  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 6m 12s (remain 12m 15s) Loss: 0.0000(0.0037) Grad: 13.3188  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 43s (remain 11m 44s) Loss: 0.0030(0.0038) Grad: 18366.5059  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 7m 14s (remain 11m 13s) Loss: 0.0012(0.0038) Grad: 4571.3921  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 45s (remain 10m 43s) Loss: 0.0027(0.0038) Grad: 13291.4434  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 8m 16s (remain 10m 12s) Loss: 0.0000(0.0037) Grad: 148.2271  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 47s (remain 9m 41s) Loss: 0.0012(0.0037) Grad: 20214.0586  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 9m 18s (remain 9m 10s) Loss: 0.0113(0.0035) Grad: 41032.2656  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 49s (remain 8m 39s) Loss: 0.0015(0.0035) Grad: 25103.2734  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 10m 20s (remain 8m 8s) Loss: 0.0000(0.0036) Grad: 135.9327  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 51s (remain 7m 36s) Loss: 0.0000(0.0035) Grad: 150.6128  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 11m 21s (remain 7m 5s) Loss: 0.0000(0.0035) Grad: 40.3088  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 52s (remain 6m 34s) Loss: 0.0000(0.0035) Grad: 115.9729  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 12m 23s (remain 6m 3s) Loss: 0.0003(0.0035) Grad: 2899.2727  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 54s (remain 5m 32s) Loss: 0.0007(0.0035) Grad: 6282.1367  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 13m 25s (remain 5m 1s) Loss: 0.0000(0.0035) Grad: 6.6848  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 55s (remain 4m 30s) Loss: 0.0000(0.0034) Grad: 3.0091  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 14m 26s (remain 3m 59s) Loss: 0.0000(0.0034) Grad: 130.7696  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 56s (remain 3m 28s) Loss: 0.0000(0.0034) Grad: 57.8867  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 15m 27s (remain 2m 57s) Loss: 0.0191(0.0034) Grad: 17904.2695  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 58s (remain 2m 26s) Loss: 0.0131(0.0034) Grad: 103893.2500  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 16m 29s (remain 1m 55s) Loss: 0.0000(0.0034) Grad: 187.5062  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 59s (remain 1m 24s) Loss: 0.0000(0.0034) Grad: 68.9962  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 17m 30s (remain 0m 53s) Loss: 0.0000(0.0034) Grad: 78.9423  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 18m 1s (remain 0m 22s) Loss: 0.0002(0.0034) Grad: 1238.7720  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 18m 24s (remain 0m 0s) Loss: 0.0000(0.0033) Grad: 6.4287  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 38s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 15s) Loss: 0.0217(0.0091) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 56s) Loss: 0.0225(0.0088) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0051(0.0087) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0060(0.0085) \n","EVAL: [500/1192] Elapsed 1m 29s (remain 2m 2s) Loss: 0.0091(0.0079) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 44s) Loss: 0.0530(0.0084) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0960(0.0110) \n","EVAL: [800/1192] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0004(0.0116) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0021(0.0117) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0000(0.0114) \n","EVAL: [1100/1192] Elapsed 3m 15s (remain 0m 16s) Loss: 0.0176(0.0110) \n","EVAL: [1191/1192] Elapsed 3m 31s (remain 0m 0s) Loss: 0.0000(0.0107) \n","Epoch 5 - avg_train_loss: 0.0033  avg_val_loss: 0.0107  time: 1321s\n","Epoch 5 - Score: 0.8818\n","Epoch 5 - Save Best Score: 0.8818 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 49m 54s) Loss: 0.3353(0.3353) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 34s (remain 19m 33s) Loss: 0.4823(0.4649) Grad: 52564.2539  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 1m 5s (remain 18m 13s) Loss: 0.0892(0.3439) Grad: 18269.5664  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 36s (remain 17m 25s) Loss: 0.0491(0.2461) Grad: 1313.8358  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 2m 7s (remain 16m 47s) Loss: 0.0292(0.1946) Grad: 711.8967  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 38s (remain 16m 11s) Loss: 0.0364(0.1634) Grad: 1058.0204  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 3m 9s (remain 15m 36s) Loss: 0.0502(0.1412) Grad: 2303.0288  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 40s (remain 15m 2s) Loss: 0.0249(0.1243) Grad: 2664.5168  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 4m 11s (remain 14m 30s) Loss: 0.0179(0.1107) Grad: 2315.7996  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 42s (remain 13m 59s) Loss: 0.0125(0.1005) Grad: 1584.3594  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 5m 13s (remain 13m 27s) Loss: 0.0113(0.0920) Grad: 1762.9546  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 44s (remain 12m 54s) Loss: 0.0095(0.0848) Grad: 850.0384  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 6m 15s (remain 12m 22s) Loss: 0.0018(0.0786) Grad: 542.4558  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 46s (remain 11m 50s) Loss: 0.0127(0.0735) Grad: 4796.6138  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 7m 16s (remain 11m 17s) Loss: 0.0112(0.0688) Grad: 1130.7012  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 47s (remain 10m 45s) Loss: 0.0007(0.0649) Grad: 310.6833  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 8m 17s (remain 10m 13s) Loss: 0.0181(0.0616) Grad: 2213.9524  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 47s (remain 9m 41s) Loss: 0.0004(0.0585) Grad: 146.7349  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 9m 18s (remain 9m 9s) Loss: 0.0064(0.0558) Grad: 1683.2655  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 48s (remain 8m 38s) Loss: 0.0150(0.0534) Grad: 1402.0267  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 10m 18s (remain 8m 6s) Loss: 0.0003(0.0512) Grad: 59.8095  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 49s (remain 7m 35s) Loss: 0.0001(0.0493) Grad: 39.4549  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 11m 19s (remain 7m 4s) Loss: 0.0788(0.0475) Grad: 5678.3696  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 50s (remain 6m 33s) Loss: 0.0124(0.0458) Grad: 1392.5570  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 12m 20s (remain 6m 2s) Loss: 0.0002(0.0443) Grad: 69.9201  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 51s (remain 5m 31s) Loss: 0.0115(0.0428) Grad: 1163.1786  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 13m 22s (remain 5m 0s) Loss: 0.0001(0.0414) Grad: 49.3739  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 52s (remain 4m 29s) Loss: 0.0016(0.0401) Grad: 1180.0522  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 14m 23s (remain 3m 58s) Loss: 0.0051(0.0390) Grad: 1489.7780  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 54s (remain 3m 27s) Loss: 0.0053(0.0379) Grad: 461.2167  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 15m 25s (remain 2m 57s) Loss: 0.0003(0.0369) Grad: 85.2468  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 56s (remain 2m 26s) Loss: 0.0000(0.0360) Grad: 24.1790  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 16m 27s (remain 1m 55s) Loss: 0.0011(0.0351) Grad: 186.8701  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 58s (remain 1m 24s) Loss: 0.0132(0.0342) Grad: 4283.9150  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 17m 29s (remain 0m 53s) Loss: 0.0051(0.0334) Grad: 695.4241  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 18m 0s (remain 0m 22s) Loss: 0.0040(0.0326) Grad: 625.6371  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 18m 22s (remain 0m 0s) Loss: 0.0017(0.0321) Grad: 271.1168  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 16s) Loss: 0.0011(0.0011) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 16s) Loss: 0.0012(0.0051) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 55s) Loss: 0.0014(0.0057) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0070(0.0082) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0103(0.0084) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 2s) Loss: 0.0097(0.0080) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 44s) Loss: 0.1018(0.0081) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0223(0.0092) \n","EVAL: [800/1192] Elapsed 2m 21s (remain 1m 9s) Loss: 0.0091(0.0090) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0046(0.0088) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0004(0.0085) \n","EVAL: [1100/1192] Elapsed 3m 14s (remain 0m 16s) Loss: 0.0100(0.0081) \n","EVAL: [1191/1192] Elapsed 3m 30s (remain 0m 0s) Loss: 0.0129(0.0078) \n","Epoch 1 - avg_train_loss: 0.0321  avg_val_loss: 0.0078  time: 1319s\n","Epoch 1 - Score: 0.8426\n","Epoch 1 - Save Best Score: 0.8426 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 40m 32s) Loss: 0.0048(0.0048) Grad: 7249.7842  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 34s (remain 19m 35s) Loss: 0.0016(0.0056) Grad: 4060.8911  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 4s (remain 18m 10s) Loss: 0.0019(0.0052) Grad: 5985.9209  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 35s (remain 17m 18s) Loss: 0.0075(0.0055) Grad: 20998.3594  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 5s (remain 16m 36s) Loss: 0.0000(0.0060) Grad: 101.2973  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 36s (remain 16m 0s) Loss: 0.0026(0.0057) Grad: 5252.7778  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 3m 7s (remain 15m 26s) Loss: 0.0006(0.0057) Grad: 1134.0393  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 37s (remain 14m 52s) Loss: 0.0002(0.0062) Grad: 595.8696  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 4m 8s (remain 14m 19s) Loss: 0.0023(0.0062) Grad: 3220.9470  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 38s (remain 13m 46s) Loss: 0.0000(0.0060) Grad: 53.3678  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 5m 8s (remain 13m 14s) Loss: 0.0083(0.0059) Grad: 13208.3281  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 39s (remain 12m 42s) Loss: 0.0175(0.0060) Grad: 20904.5840  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 6m 10s (remain 12m 11s) Loss: 0.0161(0.0061) Grad: 60398.0859  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 40s (remain 11m 40s) Loss: 0.0063(0.0060) Grad: 6637.8887  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 7m 11s (remain 11m 9s) Loss: 0.0009(0.0060) Grad: 3596.8447  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 42s (remain 10m 38s) Loss: 0.0383(0.0060) Grad: 9275.4648  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 8m 12s (remain 10m 7s) Loss: 0.0061(0.0059) Grad: 5728.2427  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 43s (remain 9m 36s) Loss: 0.0005(0.0059) Grad: 1201.2574  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 9m 13s (remain 9m 5s) Loss: 0.0000(0.0060) Grad: 11.4337  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 44s (remain 8m 34s) Loss: 0.0000(0.0060) Grad: 98.8128  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 10m 15s (remain 8m 3s) Loss: 0.0076(0.0060) Grad: 26760.5781  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 45s (remain 7m 33s) Loss: 0.0223(0.0060) Grad: 14632.1309  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 11m 16s (remain 7m 2s) Loss: 0.0004(0.0059) Grad: 752.3026  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 46s (remain 6m 31s) Loss: 0.0065(0.0059) Grad: 4883.4873  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 12m 17s (remain 6m 0s) Loss: 0.0013(0.0059) Grad: 2222.0464  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 47s (remain 5m 29s) Loss: 0.0118(0.0059) Grad: 12098.2402  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 13m 18s (remain 4m 58s) Loss: 0.0004(0.0059) Grad: 2342.4573  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 48s (remain 4m 28s) Loss: 0.0058(0.0059) Grad: 8166.2266  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 14m 19s (remain 3m 57s) Loss: 0.0045(0.0060) Grad: 2486.2869  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 49s (remain 3m 26s) Loss: 0.0003(0.0059) Grad: 496.2571  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 15m 19s (remain 2m 55s) Loss: 0.0030(0.0060) Grad: 2360.0215  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 50s (remain 2m 25s) Loss: 0.0012(0.0060) Grad: 2500.5630  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 16m 20s (remain 1m 54s) Loss: 0.0060(0.0061) Grad: 6132.3496  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 51s (remain 1m 23s) Loss: 0.0030(0.0061) Grad: 4618.4995  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 17m 21s (remain 0m 53s) Loss: 0.0010(0.0061) Grad: 1602.9724  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 51s (remain 0m 22s) Loss: 0.0082(0.0061) Grad: 12831.9961  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0023(0.0061) Grad: 2911.0547  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 6s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 17s (remain 3m 13s) Loss: 0.0000(0.0068) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 54s) Loss: 0.0001(0.0063) \n","EVAL: [300/1192] Elapsed 0m 52s (remain 2m 36s) Loss: 0.0008(0.0097) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 18s) Loss: 0.0143(0.0097) \n","EVAL: [500/1192] Elapsed 1m 27s (remain 2m 0s) Loss: 0.0170(0.0092) \n","EVAL: [600/1192] Elapsed 1m 45s (remain 1m 43s) Loss: 0.1086(0.0092) \n","EVAL: [700/1192] Elapsed 2m 2s (remain 1m 25s) Loss: 0.0489(0.0106) \n","EVAL: [800/1192] Elapsed 2m 20s (remain 1m 8s) Loss: 0.0031(0.0103) \n","EVAL: [900/1192] Elapsed 2m 37s (remain 0m 50s) Loss: 0.0041(0.0101) \n","EVAL: [1000/1192] Elapsed 2m 55s (remain 0m 33s) Loss: 0.0000(0.0096) \n","EVAL: [1100/1192] Elapsed 3m 12s (remain 0m 15s) Loss: 0.0175(0.0091) \n","EVAL: [1191/1192] Elapsed 3m 28s (remain 0m 0s) Loss: 0.0229(0.0087) \n","Epoch 2 - avg_train_loss: 0.0061  avg_val_loss: 0.0087  time: 1317s\n","Epoch 2 - Score: 0.8760\n","Epoch 2 - Save Best Score: 0.8760 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 39m 14s) Loss: 0.0021(0.0021) Grad: 7880.7275  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 34s (remain 19m 52s) Loss: 0.0005(0.0069) Grad: 3808.3137  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 6s (remain 18m 39s) Loss: 0.0056(0.0063) Grad: 8569.6074  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 37s (remain 17m 43s) Loss: 0.0014(0.0060) Grad: 30558.8652  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 8s (remain 17m 0s) Loss: 0.0280(0.0056) Grad: 80499.2578  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 39s (remain 16m 20s) Loss: 0.0000(0.0055) Grad: 495.2986  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 10s (remain 15m 42s) Loss: 0.0305(0.0055) Grad: 82944.6406  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 41s (remain 15m 6s) Loss: 0.0015(0.0053) Grad: 5252.2744  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 4m 11s (remain 14m 31s) Loss: 0.0023(0.0053) Grad: 5290.4180  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 41s (remain 13m 56s) Loss: 0.0013(0.0052) Grad: 8532.2061  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 5m 12s (remain 13m 23s) Loss: 0.0365(0.0053) Grad: 68071.2422  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 42s (remain 12m 50s) Loss: 0.0000(0.0051) Grad: 121.2343  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 6m 13s (remain 12m 17s) Loss: 0.0001(0.0052) Grad: 420.2165  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 43s (remain 11m 45s) Loss: 0.0000(0.0052) Grad: 220.4246  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 7m 13s (remain 11m 13s) Loss: 0.0001(0.0052) Grad: 520.3498  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 44s (remain 10m 41s) Loss: 0.0009(0.0051) Grad: 3885.9670  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 8m 14s (remain 10m 9s) Loss: 0.0005(0.0053) Grad: 1697.2042  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 45s (remain 9m 38s) Loss: 0.0014(0.0051) Grad: 5509.2334  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 9m 15s (remain 9m 7s) Loss: 0.0000(0.0051) Grad: 124.0484  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 45s (remain 8m 35s) Loss: 0.0002(0.0051) Grad: 1236.3420  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 10m 16s (remain 8m 4s) Loss: 0.0002(0.0051) Grad: 652.4985  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 47s (remain 7m 34s) Loss: 0.0368(0.0052) Grad: 20738.4941  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 11m 17s (remain 7m 3s) Loss: 0.0027(0.0053) Grad: 7524.2349  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 48s (remain 6m 32s) Loss: 0.0058(0.0051) Grad: 2921.3369  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 12m 18s (remain 6m 1s) Loss: 0.0001(0.0052) Grad: 784.5228  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 49s (remain 5m 30s) Loss: 0.0000(0.0051) Grad: 41.5527  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 13m 19s (remain 4m 59s) Loss: 0.0040(0.0051) Grad: 11090.2725  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 50s (remain 4m 28s) Loss: 0.0002(0.0052) Grad: 661.4468  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 14m 21s (remain 3m 57s) Loss: 0.0000(0.0051) Grad: 5.3734  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 51s (remain 3m 27s) Loss: 0.0000(0.0051) Grad: 58.4388  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 15m 22s (remain 2m 56s) Loss: 0.0097(0.0051) Grad: 13991.7217  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 52s (remain 2m 25s) Loss: 0.0001(0.0051) Grad: 282.3208  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 16m 23s (remain 1m 54s) Loss: 0.0156(0.0051) Grad: 7246.2354  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 54s (remain 1m 24s) Loss: 0.0020(0.0051) Grad: 2981.2864  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 17m 24s (remain 0m 53s) Loss: 0.0011(0.0051) Grad: 2172.4421  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 55s (remain 0m 22s) Loss: 0.0010(0.0051) Grad: 2633.9397  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 18m 18s (remain 0m 0s) Loss: 0.0194(0.0051) Grad: 16204.0107  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 30s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 15s) Loss: 0.0000(0.0066) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 55s) Loss: 0.0001(0.0067) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 37s) Loss: 0.0008(0.0097) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 19s) Loss: 0.0213(0.0098) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 1s) Loss: 0.0148(0.0093) \n","EVAL: [600/1192] Elapsed 1m 45s (remain 1m 43s) Loss: 0.1135(0.0092) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0532(0.0110) \n","EVAL: [800/1192] Elapsed 2m 20s (remain 1m 8s) Loss: 0.0139(0.0107) \n","EVAL: [900/1192] Elapsed 2m 38s (remain 0m 51s) Loss: 0.0039(0.0103) \n","EVAL: [1000/1192] Elapsed 2m 56s (remain 0m 33s) Loss: 0.0000(0.0098) \n","EVAL: [1100/1192] Elapsed 3m 13s (remain 0m 16s) Loss: 0.0264(0.0093) \n","EVAL: [1191/1192] Elapsed 3m 29s (remain 0m 0s) Loss: 0.0269(0.0089) \n","Epoch 3 - avg_train_loss: 0.0051  avg_val_loss: 0.0089  time: 1314s\n","Epoch 3 - Score: 0.8772\n","Epoch 3 - Save Best Score: 0.8772 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 36m 29s) Loss: 0.0011(0.0011) Grad: 4019.4377  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 33s (remain 19m 1s) Loss: 0.0038(0.0024) Grad: 8556.8945  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 4s (remain 18m 1s) Loss: 0.0000(0.0027) Grad: 406.0749  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 34s (remain 17m 10s) Loss: 0.0605(0.0024) Grad: 68893.8203  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 5s (remain 16m 30s) Loss: 0.0001(0.0028) Grad: 665.2318  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 35s (remain 15m 54s) Loss: 0.0000(0.0031) Grad: 13.0463  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 3m 6s (remain 15m 20s) Loss: 0.0012(0.0036) Grad: 6371.1138  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 36s (remain 14m 47s) Loss: 0.0000(0.0037) Grad: 506.2263  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 4m 6s (remain 14m 14s) Loss: 0.0000(0.0034) Grad: 6.7080  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 37s (remain 13m 42s) Loss: 0.0000(0.0033) Grad: 12.8894  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 5m 7s (remain 13m 11s) Loss: 0.0000(0.0034) Grad: 66.1283  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 38s (remain 12m 40s) Loss: 0.0000(0.0035) Grad: 138.2521  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 6m 9s (remain 12m 10s) Loss: 0.0026(0.0036) Grad: 14986.1396  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 40s (remain 11m 39s) Loss: 0.0015(0.0037) Grad: 7607.8511  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 7m 11s (remain 11m 9s) Loss: 0.0000(0.0036) Grad: 202.2417  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 42s (remain 10m 38s) Loss: 0.0000(0.0036) Grad: 333.5960  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 8m 13s (remain 10m 8s) Loss: 0.0000(0.0035) Grad: 89.8956  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 44s (remain 9m 38s) Loss: 0.0000(0.0035) Grad: 36.3193  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 9m 15s (remain 9m 7s) Loss: 0.0026(0.0036) Grad: 4735.6782  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 47s (remain 8m 36s) Loss: 0.0000(0.0036) Grad: 13.6705  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 10m 18s (remain 8m 6s) Loss: 0.0001(0.0036) Grad: 675.5203  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 49s (remain 7m 35s) Loss: 0.0000(0.0035) Grad: 10.8558  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 11m 20s (remain 7m 4s) Loss: 0.0000(0.0036) Grad: 129.0978  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 50s (remain 6m 33s) Loss: 0.0000(0.0036) Grad: 80.2167  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 12m 21s (remain 6m 2s) Loss: 0.0004(0.0036) Grad: 2266.8374  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 51s (remain 5m 31s) Loss: 0.0039(0.0036) Grad: 12332.0918  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 13m 22s (remain 5m 0s) Loss: 0.0000(0.0038) Grad: 81.1670  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 52s (remain 4m 29s) Loss: 0.0018(0.0039) Grad: 9191.3232  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 14m 23s (remain 3m 58s) Loss: 0.0041(0.0038) Grad: 15980.8203  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 53s (remain 3m 27s) Loss: 0.0046(0.0039) Grad: 21562.1836  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 15m 24s (remain 2m 56s) Loss: 0.0016(0.0038) Grad: 6549.5015  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 54s (remain 2m 25s) Loss: 0.0000(0.0039) Grad: 173.3326  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 16m 25s (remain 1m 55s) Loss: 0.0022(0.0039) Grad: 9479.0400  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 16m 56s (remain 1m 24s) Loss: 0.0121(0.0040) Grad: 16188.7432  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 17m 26s (remain 0m 53s) Loss: 0.0015(0.0040) Grad: 8763.8135  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 17m 57s (remain 0m 22s) Loss: 0.0187(0.0040) Grad: 24852.9062  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 18m 19s (remain 0m 0s) Loss: 0.0004(0.0040) Grad: 3826.5623  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 54s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 17s (remain 3m 13s) Loss: 0.0000(0.0092) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 54s) Loss: 0.0000(0.0085) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 36s) Loss: 0.0002(0.0122) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 18s) Loss: 0.0274(0.0122) \n","EVAL: [500/1192] Elapsed 1m 27s (remain 2m 1s) Loss: 0.0183(0.0115) \n","EVAL: [600/1192] Elapsed 1m 45s (remain 1m 43s) Loss: 0.1155(0.0113) \n","EVAL: [700/1192] Elapsed 2m 2s (remain 1m 26s) Loss: 0.0515(0.0132) \n","EVAL: [800/1192] Elapsed 2m 20s (remain 1m 8s) Loss: 0.0193(0.0129) \n","EVAL: [900/1192] Elapsed 2m 37s (remain 0m 51s) Loss: 0.0021(0.0124) \n","EVAL: [1000/1192] Elapsed 2m 55s (remain 0m 33s) Loss: 0.0000(0.0117) \n","EVAL: [1100/1192] Elapsed 3m 13s (remain 0m 15s) Loss: 0.0184(0.0111) \n","EVAL: [1191/1192] Elapsed 3m 28s (remain 0m 0s) Loss: 0.0248(0.0106) \n","Epoch 4 - avg_train_loss: 0.0040  avg_val_loss: 0.0106  time: 1314s\n","Epoch 4 - Score: 0.8821\n","Epoch 4 - Save Best Score: 0.8821 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 37m 10s) Loss: 0.0001(0.0001) Grad: 2854.0039  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 35s (remain 20m 28s) Loss: 0.0093(0.0041) Grad: 31768.3594  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 6s (remain 18m 36s) Loss: 0.0000(0.0037) Grad: 8.4807  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 37s (remain 17m 35s) Loss: 0.0013(0.0042) Grad: 7939.7510  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 2m 7s (remain 16m 49s) Loss: 0.0000(0.0038) Grad: 34.5983  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 38s (remain 16m 9s) Loss: 0.0000(0.0042) Grad: 54.4571  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 3m 8s (remain 15m 32s) Loss: 0.0044(0.0038) Grad: 19117.7363  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 39s (remain 14m 58s) Loss: 0.0090(0.0037) Grad: 11799.8906  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 4m 9s (remain 14m 24s) Loss: 0.0000(0.0038) Grad: 114.2793  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 40s (remain 13m 51s) Loss: 0.0008(0.0036) Grad: 3415.9910  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 5m 10s (remain 13m 19s) Loss: 0.0000(0.0035) Grad: 7.3471  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 41s (remain 12m 47s) Loss: 0.0024(0.0036) Grad: 28568.4824  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 6m 12s (remain 12m 15s) Loss: 0.0000(0.0036) Grad: 158.1409  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 42s (remain 11m 43s) Loss: 0.0001(0.0035) Grad: 736.4725  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 7m 13s (remain 11m 12s) Loss: 0.0015(0.0034) Grad: 6264.4277  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 43s (remain 10m 40s) Loss: 0.0031(0.0034) Grad: 17246.8418  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 8m 14s (remain 10m 9s) Loss: 0.0010(0.0034) Grad: 6584.9551  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 44s (remain 9m 38s) Loss: 0.0001(0.0033) Grad: 843.7302  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 9m 15s (remain 9m 7s) Loss: 0.0001(0.0033) Grad: 973.5177  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 45s (remain 8m 36s) Loss: 0.0000(0.0033) Grad: 116.5804  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 10m 16s (remain 8m 5s) Loss: 0.0006(0.0032) Grad: 5489.1426  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 47s (remain 7m 34s) Loss: 0.0000(0.0032) Grad: 102.6470  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 11m 17s (remain 7m 3s) Loss: 0.0000(0.0031) Grad: 397.5616  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 48s (remain 6m 32s) Loss: 0.0000(0.0031) Grad: 20.7191  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 12m 18s (remain 6m 1s) Loss: 0.0099(0.0031) Grad: 17448.7480  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 49s (remain 5m 30s) Loss: 0.0000(0.0031) Grad: 208.5745  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 13m 19s (remain 4m 59s) Loss: 0.0006(0.0031) Grad: 8840.3623  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 50s (remain 4m 28s) Loss: 0.0000(0.0031) Grad: 41.4724  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 14m 20s (remain 3m 57s) Loss: 0.0016(0.0031) Grad: 22565.4258  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 51s (remain 3m 27s) Loss: 0.0001(0.0031) Grad: 554.1530  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 15m 22s (remain 2m 56s) Loss: 0.0080(0.0031) Grad: 25986.5391  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 53s (remain 2m 25s) Loss: 0.0029(0.0031) Grad: 6124.0449  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 16m 24s (remain 1m 54s) Loss: 0.0003(0.0032) Grad: 7833.1567  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 55s (remain 1m 24s) Loss: 0.0001(0.0031) Grad: 712.4251  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 17m 26s (remain 0m 53s) Loss: 0.0000(0.0032) Grad: 38.9585  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 17m 57s (remain 0m 22s) Loss: 0.0007(0.0032) Grad: 6216.4941  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 18m 20s (remain 0m 0s) Loss: 0.0000(0.0032) Grad: 59.4354  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 48s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 16s) Loss: 0.0000(0.0089) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 57s) Loss: 0.0000(0.0086) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 39s) Loss: 0.0002(0.0127) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0285(0.0129) \n","EVAL: [500/1192] Elapsed 1m 29s (remain 2m 2s) Loss: 0.0216(0.0121) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 45s) Loss: 0.1378(0.0121) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0564(0.0143) \n","EVAL: [800/1192] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0201(0.0139) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0009(0.0134) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0000(0.0127) \n","EVAL: [1100/1192] Elapsed 3m 15s (remain 0m 16s) Loss: 0.0176(0.0121) \n","EVAL: [1191/1192] Elapsed 3m 30s (remain 0m 0s) Loss: 0.0261(0.0115) \n","Epoch 5 - avg_train_loss: 0.0032  avg_val_loss: 0.0115  time: 1317s\n","Epoch 5 - Score: 0.8801\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 41m 7s) Loss: 0.4848(0.4848) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 31s (remain 17m 47s) Loss: 0.7751(0.7331) Grad: 72420.7344  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 1m 1s (remain 17m 11s) Loss: 0.1148(0.5488) Grad: 41889.9102  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 31s (remain 16m 39s) Loss: 0.0639(0.3896) Grad: 997.4575  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 2m 2s (remain 16m 9s) Loss: 0.0276(0.3021) Grad: 383.2756  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 33s (remain 15m 40s) Loss: 0.0646(0.2490) Grad: 820.0713  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 3m 3s (remain 15m 9s) Loss: 0.0078(0.2134) Grad: 324.3611  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 34s (remain 14m 38s) Loss: 0.0064(0.1862) Grad: 373.6756  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 4m 4s (remain 14m 8s) Loss: 0.0126(0.1653) Grad: 1271.5820  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 35s (remain 13m 37s) Loss: 0.0019(0.1484) Grad: 151.0936  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 5m 6s (remain 13m 7s) Loss: 0.0059(0.1351) Grad: 694.2391  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 36s (remain 12m 36s) Loss: 0.0114(0.1239) Grad: 961.6223  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 6m 7s (remain 12m 6s) Loss: 0.0201(0.1147) Grad: 931.0563  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 38s (remain 11m 35s) Loss: 0.0042(0.1064) Grad: 708.8400  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 7m 8s (remain 11m 4s) Loss: 0.0033(0.0995) Grad: 232.1821  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 38s (remain 10m 33s) Loss: 0.0041(0.0937) Grad: 438.3557  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 8m 9s (remain 10m 3s) Loss: 0.0128(0.0885) Grad: 980.7469  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 40s (remain 9m 33s) Loss: 0.0027(0.0840) Grad: 214.8618  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 9m 10s (remain 9m 2s) Loss: 0.0041(0.0796) Grad: 451.8154  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 41s (remain 8m 31s) Loss: 0.0021(0.0758) Grad: 217.0276  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 10m 11s (remain 8m 1s) Loss: 0.0000(0.0725) Grad: 4.9493  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 42s (remain 7m 30s) Loss: 0.0019(0.0696) Grad: 272.3589  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 11m 13s (remain 7m 0s) Loss: 0.0016(0.0668) Grad: 143.2491  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 43s (remain 6m 29s) Loss: 0.0003(0.0642) Grad: 49.9058  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 12m 14s (remain 5m 59s) Loss: 0.0024(0.0619) Grad: 171.3999  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 45s (remain 5m 28s) Loss: 0.0280(0.0597) Grad: 1202.6481  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 13m 16s (remain 4m 58s) Loss: 0.0228(0.0578) Grad: 1264.1619  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 46s (remain 4m 27s) Loss: 0.0005(0.0559) Grad: 76.1065  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 14m 17s (remain 3m 56s) Loss: 0.0141(0.0542) Grad: 1142.4495  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 47s (remain 3m 26s) Loss: 0.0016(0.0526) Grad: 118.7392  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 15m 18s (remain 2m 55s) Loss: 0.0019(0.0511) Grad: 150.8207  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 49s (remain 2m 25s) Loss: 0.0011(0.0497) Grad: 113.8002  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 16m 19s (remain 1m 54s) Loss: 0.0102(0.0483) Grad: 508.6071  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 50s (remain 1m 23s) Loss: 0.0004(0.0471) Grad: 31.3022  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 17m 20s (remain 0m 53s) Loss: 0.0030(0.0460) Grad: 257.6653  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 17m 51s (remain 0m 22s) Loss: 0.0008(0.0448) Grad: 152.5300  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0298(0.0440) Grad: 1102.4933  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 17s) Loss: 0.0003(0.0003) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 16s) Loss: 0.0268(0.0066) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 56s) Loss: 0.0092(0.0066) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0148(0.0068) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0013(0.0077) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 2s) Loss: 0.0003(0.0071) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 44s) Loss: 0.0094(0.0077) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 26s) Loss: 0.0046(0.0084) \n","EVAL: [800/1192] Elapsed 2m 21s (remain 1m 9s) Loss: 0.0000(0.0084) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0014(0.0082) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0260(0.0081) \n","EVAL: [1100/1192] Elapsed 3m 15s (remain 0m 16s) Loss: 0.0062(0.0078) \n","EVAL: [1191/1192] Elapsed 3m 31s (remain 0m 0s) Loss: 0.0008(0.0075) \n","Epoch 1 - avg_train_loss: 0.0440  avg_val_loss: 0.0075  time: 1311s\n","Epoch 1 - Score: 0.8624\n","Epoch 1 - Save Best Score: 0.8624 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 44m 40s) Loss: 0.0108(0.0108) Grad: 29508.1328  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 34s (remain 19m 39s) Loss: 0.0107(0.0072) Grad: 46510.7188  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 5s (remain 18m 19s) Loss: 0.0003(0.0064) Grad: 1075.5750  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 36s (remain 17m 30s) Loss: 0.0002(0.0062) Grad: 1051.5165  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 7s (remain 16m 50s) Loss: 0.0044(0.0068) Grad: 18851.7051  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 38s (remain 16m 14s) Loss: 0.0078(0.0062) Grad: 21592.9727  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 3m 9s (remain 15m 39s) Loss: 0.0001(0.0063) Grad: 312.9308  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 41s (remain 15m 6s) Loss: 0.0001(0.0064) Grad: 644.4964  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 4m 12s (remain 14m 34s) Loss: 0.0086(0.0066) Grad: 22489.0312  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 43s (remain 14m 1s) Loss: 0.0002(0.0066) Grad: 1802.8690  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 5m 14s (remain 13m 28s) Loss: 0.0000(0.0065) Grad: 84.4012  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 44s (remain 12m 55s) Loss: 0.0003(0.0064) Grad: 1856.8831  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 6m 15s (remain 12m 22s) Loss: 0.0001(0.0063) Grad: 541.8452  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 45s (remain 11m 49s) Loss: 0.0242(0.0065) Grad: 18870.8828  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 7m 16s (remain 11m 17s) Loss: 0.0070(0.0063) Grad: 21316.9570  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 46s (remain 10m 45s) Loss: 0.0016(0.0063) Grad: 5242.0640  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 8m 17s (remain 10m 13s) Loss: 0.0043(0.0061) Grad: 13857.9512  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 47s (remain 9m 41s) Loss: 0.0084(0.0062) Grad: 13316.8047  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 9m 18s (remain 9m 10s) Loss: 0.0018(0.0061) Grad: 3741.1086  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 49s (remain 8m 38s) Loss: 0.0005(0.0061) Grad: 2320.1462  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 10m 19s (remain 8m 7s) Loss: 0.0174(0.0061) Grad: 26150.9980  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 50s (remain 7m 36s) Loss: 0.0313(0.0061) Grad: 63934.0352  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 11m 20s (remain 7m 4s) Loss: 0.0041(0.0061) Grad: 71872.0938  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 50s (remain 6m 33s) Loss: 0.0094(0.0060) Grad: 22679.1816  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 12m 21s (remain 6m 2s) Loss: 0.0113(0.0061) Grad: 30270.8711  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 51s (remain 5m 31s) Loss: 0.0006(0.0061) Grad: 10111.0176  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 13m 22s (remain 5m 0s) Loss: 0.0066(0.0061) Grad: 16329.4580  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 52s (remain 4m 29s) Loss: 0.0423(0.0062) Grad: 102108.4219  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 14m 23s (remain 3m 58s) Loss: 0.0001(0.0061) Grad: 612.2311  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 53s (remain 3m 27s) Loss: 0.0003(0.0061) Grad: 1287.7906  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 15m 24s (remain 2m 56s) Loss: 0.0041(0.0061) Grad: 9959.3359  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 54s (remain 2m 25s) Loss: 0.0010(0.0061) Grad: 5064.0107  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 16m 25s (remain 1m 55s) Loss: 0.0000(0.0061) Grad: 22.9794  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 56s (remain 1m 24s) Loss: 0.0003(0.0061) Grad: 1343.4821  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 17m 26s (remain 0m 53s) Loss: 0.0023(0.0061) Grad: 19396.0215  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 57s (remain 0m 22s) Loss: 0.0002(0.0061) Grad: 1328.9884  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 18m 19s (remain 0m 0s) Loss: 0.0000(0.0061) Grad: 40.0335  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 44s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 16s) Loss: 0.0376(0.0083) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 57s) Loss: 0.0024(0.0077) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0170(0.0080) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0004(0.0079) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 2s) Loss: 0.0000(0.0075) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 44s) Loss: 0.0039(0.0077) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0032(0.0086) \n","EVAL: [800/1192] Elapsed 2m 21s (remain 1m 9s) Loss: 0.0000(0.0089) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0039(0.0089) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0312(0.0087) \n","EVAL: [1100/1192] Elapsed 3m 14s (remain 0m 16s) Loss: 0.0606(0.0083) \n","EVAL: [1191/1192] Elapsed 3m 30s (remain 0m 0s) Loss: 0.0000(0.0081) \n","Epoch 2 - avg_train_loss: 0.0061  avg_val_loss: 0.0081  time: 1321s\n","Epoch 2 - Score: 0.8742\n","Epoch 2 - Save Best Score: 0.8742 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 37m 22s) Loss: 0.0020(0.0020) Grad: 4248.2310  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 33s (remain 19m 19s) Loss: 0.0000(0.0050) Grad: 7.4142  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 4s (remain 18m 7s) Loss: 0.0000(0.0054) Grad: 109.7672  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 35s (remain 17m 15s) Loss: 0.0013(0.0055) Grad: 7888.1675  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 5s (remain 16m 34s) Loss: 0.0000(0.0052) Grad: 182.7346  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 36s (remain 15m 57s) Loss: 0.0000(0.0052) Grad: 325.8996  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 6s (remain 15m 23s) Loss: 0.0032(0.0050) Grad: 8139.8716  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 37s (remain 14m 52s) Loss: 0.0040(0.0052) Grad: 24940.4004  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 4m 8s (remain 14m 20s) Loss: 0.0000(0.0052) Grad: 16.0566  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 39s (remain 13m 48s) Loss: 0.0000(0.0052) Grad: 5.6951  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 5m 9s (remain 13m 16s) Loss: 0.0000(0.0052) Grad: 20.5494  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 40s (remain 12m 44s) Loss: 0.0071(0.0051) Grad: 18905.6191  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 6m 10s (remain 12m 12s) Loss: 0.0072(0.0052) Grad: 16745.4629  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 41s (remain 11m 41s) Loss: 0.0012(0.0051) Grad: 6035.6255  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 7m 11s (remain 11m 10s) Loss: 0.0396(0.0050) Grad: 62338.6328  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 42s (remain 10m 38s) Loss: 0.0000(0.0051) Grad: 587.2938  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 8m 12s (remain 10m 7s) Loss: 0.0000(0.0051) Grad: 24.2979  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 43s (remain 9m 36s) Loss: 0.0010(0.0051) Grad: 11418.1367  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 9m 14s (remain 9m 5s) Loss: 0.0000(0.0050) Grad: 97.9842  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 45s (remain 8m 35s) Loss: 0.0016(0.0050) Grad: 6052.7539  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 10m 16s (remain 8m 5s) Loss: 0.0084(0.0050) Grad: 10725.8652  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 47s (remain 7m 34s) Loss: 0.0001(0.0050) Grad: 385.8375  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 11m 19s (remain 7m 3s) Loss: 0.0076(0.0050) Grad: 11585.1777  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 49s (remain 6m 33s) Loss: 0.0013(0.0050) Grad: 6202.9414  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 12m 21s (remain 6m 2s) Loss: 0.0032(0.0050) Grad: 41440.3477  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 51s (remain 5m 31s) Loss: 0.0065(0.0050) Grad: 15737.3877  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 13m 21s (remain 5m 0s) Loss: 0.0227(0.0050) Grad: 35514.4102  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 52s (remain 4m 29s) Loss: 0.0090(0.0050) Grad: 16375.3867  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 14m 22s (remain 3m 58s) Loss: 0.0003(0.0049) Grad: 2270.9324  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 53s (remain 3m 27s) Loss: 0.0013(0.0049) Grad: 4300.8022  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 15m 23s (remain 2m 56s) Loss: 0.0002(0.0049) Grad: 703.9607  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 53s (remain 2m 25s) Loss: 0.0000(0.0049) Grad: 8.8363  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 16m 24s (remain 1m 55s) Loss: 0.0076(0.0049) Grad: 23448.8711  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 54s (remain 1m 24s) Loss: 0.0013(0.0048) Grad: 5861.4805  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 17m 24s (remain 0m 53s) Loss: 0.0001(0.0049) Grad: 1365.4321  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 55s (remain 0m 22s) Loss: 0.0006(0.0049) Grad: 2912.4749  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 18m 17s (remain 0m 0s) Loss: 0.0000(0.0049) Grad: 46.5499  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 3s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 14s) Loss: 0.0870(0.0093) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 56s) Loss: 0.0094(0.0089) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 37s) Loss: 0.0191(0.0092) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 19s) Loss: 0.0005(0.0092) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 1s) Loss: 0.0000(0.0087) \n","EVAL: [600/1192] Elapsed 1m 45s (remain 1m 44s) Loss: 0.0084(0.0087) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0040(0.0095) \n","EVAL: [800/1192] Elapsed 2m 20s (remain 1m 8s) Loss: 0.0000(0.0096) \n","EVAL: [900/1192] Elapsed 2m 38s (remain 0m 51s) Loss: 0.0017(0.0096) \n","EVAL: [1000/1192] Elapsed 2m 55s (remain 0m 33s) Loss: 0.0366(0.0093) \n","EVAL: [1100/1192] Elapsed 3m 13s (remain 0m 15s) Loss: 0.0507(0.0089) \n","EVAL: [1191/1192] Elapsed 3m 28s (remain 0m 0s) Loss: 0.0000(0.0086) \n","Epoch 3 - avg_train_loss: 0.0049  avg_val_loss: 0.0086  time: 1329s\n","Epoch 3 - Score: 0.8877\n","Epoch 3 - Save Best Score: 0.8877 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 37m 24s) Loss: 0.0120(0.0120) Grad: 17421.9844  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 33s (remain 18m 57s) Loss: 0.0003(0.0036) Grad: 2369.2500  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 3s (remain 17m 53s) Loss: 0.0014(0.0045) Grad: 8527.5273  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 34s (remain 17m 8s) Loss: 0.0072(0.0045) Grad: 16726.5410  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 5s (remain 16m 30s) Loss: 0.0000(0.0045) Grad: 176.7138  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 35s (remain 15m 54s) Loss: 0.0001(0.0046) Grad: 408.8811  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 3m 6s (remain 15m 21s) Loss: 0.0042(0.0044) Grad: 48611.2930  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 36s (remain 14m 48s) Loss: 0.0132(0.0041) Grad: 60841.6523  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 4m 7s (remain 14m 16s) Loss: 0.0009(0.0040) Grad: 5526.0249  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 37s (remain 13m 44s) Loss: 0.0080(0.0039) Grad: 57411.9531  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 5m 8s (remain 13m 12s) Loss: 0.0001(0.0039) Grad: 737.6116  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 38s (remain 12m 40s) Loss: 0.0011(0.0038) Grad: 9795.0518  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 6m 8s (remain 12m 9s) Loss: 0.0000(0.0038) Grad: 180.6189  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 39s (remain 11m 37s) Loss: 0.0000(0.0038) Grad: 39.6178  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 7m 9s (remain 11m 6s) Loss: 0.0000(0.0039) Grad: 25.8433  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 40s (remain 10m 35s) Loss: 0.0000(0.0039) Grad: 49.9849  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 8m 10s (remain 10m 4s) Loss: 0.0003(0.0039) Grad: 2160.2366  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 40s (remain 9m 33s) Loss: 0.0000(0.0040) Grad: 11.7891  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 9m 11s (remain 9m 3s) Loss: 0.0019(0.0040) Grad: 11718.5146  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 42s (remain 8m 32s) Loss: 0.0000(0.0041) Grad: 11.2294  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 10m 12s (remain 8m 1s) Loss: 0.0001(0.0041) Grad: 1215.7955  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 42s (remain 7m 30s) Loss: 0.0001(0.0040) Grad: 1143.4008  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 11m 13s (remain 7m 0s) Loss: 0.0000(0.0041) Grad: 4.2068  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 43s (remain 6m 29s) Loss: 0.0002(0.0041) Grad: 873.2682  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 12m 13s (remain 5m 58s) Loss: 0.0000(0.0041) Grad: 511.4008  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 43s (remain 5m 27s) Loss: 0.0251(0.0040) Grad: 91144.5156  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 13m 14s (remain 4m 57s) Loss: 0.0001(0.0041) Grad: 734.8342  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 44s (remain 4m 26s) Loss: 0.0013(0.0041) Grad: 9517.3594  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 14m 14s (remain 3m 56s) Loss: 0.0000(0.0042) Grad: 15.5526  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 45s (remain 3m 25s) Loss: 0.0000(0.0042) Grad: 44.5691  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 15m 15s (remain 2m 55s) Loss: 0.0028(0.0042) Grad: 14826.8574  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 46s (remain 2m 24s) Loss: 0.0012(0.0041) Grad: 6787.4297  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 16m 16s (remain 1m 54s) Loss: 0.0001(0.0041) Grad: 539.1188  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 16m 47s (remain 1m 23s) Loss: 0.0004(0.0041) Grad: 6642.7754  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 17m 18s (remain 0m 53s) Loss: 0.0088(0.0041) Grad: 46598.0625  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 17m 49s (remain 0m 22s) Loss: 0.0002(0.0041) Grad: 1773.3269  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 18m 11s (remain 0m 0s) Loss: 0.0000(0.0040) Grad: 117.7789  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 40s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 20s) Loss: 0.0665(0.0106) \n","EVAL: [200/1192] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0069(0.0098) \n","EVAL: [300/1192] Elapsed 0m 54s (remain 2m 40s) Loss: 0.0150(0.0101) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0001(0.0101) \n","EVAL: [500/1192] Elapsed 1m 29s (remain 2m 3s) Loss: 0.0000(0.0096) \n","EVAL: [600/1192] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0087(0.0096) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0042(0.0104) \n","EVAL: [800/1192] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0000(0.0105) \n","EVAL: [900/1192] Elapsed 2m 40s (remain 0m 51s) Loss: 0.0023(0.0104) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0001(0.0101) \n","EVAL: [1100/1192] Elapsed 3m 15s (remain 0m 16s) Loss: 0.0628(0.0096) \n","EVAL: [1191/1192] Elapsed 3m 31s (remain 0m 0s) Loss: 0.0000(0.0094) \n","Epoch 4 - avg_train_loss: 0.0040  avg_val_loss: 0.0094  time: 1313s\n","Epoch 4 - Score: 0.8875\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 35m 48s) Loss: 0.0003(0.0003) Grad: 6155.1499  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 31s (remain 17m 49s) Loss: 0.0041(0.0014) Grad: 48981.3047  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 1s (remain 17m 11s) Loss: 0.0003(0.0022) Grad: 1538.1559  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 31s (remain 16m 37s) Loss: 0.0000(0.0024) Grad: 18.7897  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 2m 1s (remain 16m 5s) Loss: 0.0000(0.0022) Grad: 5.6148  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 32s (remain 15m 35s) Loss: 0.0014(0.0026) Grad: 14011.0977  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 3m 2s (remain 15m 5s) Loss: 0.0001(0.0027) Grad: 1116.0620  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 33s (remain 14m 34s) Loss: 0.0000(0.0029) Grad: 7.7736  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 4m 3s (remain 14m 4s) Loss: 0.0000(0.0030) Grad: 2.5405  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 34s (remain 13m 33s) Loss: 0.0006(0.0030) Grad: 8865.8428  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 5m 4s (remain 13m 2s) Loss: 0.0000(0.0031) Grad: 19.3635  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 34s (remain 12m 32s) Loss: 0.0030(0.0029) Grad: 11391.2188  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 6m 4s (remain 12m 1s) Loss: 0.0001(0.0029) Grad: 3918.6348  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 35s (remain 11m 30s) Loss: 0.0002(0.0029) Grad: 5236.5225  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 7m 5s (remain 11m 0s) Loss: 0.0300(0.0031) Grad: 144681.4688  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 35s (remain 10m 29s) Loss: 0.0000(0.0032) Grad: 52.3172  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 8m 6s (remain 9m 59s) Loss: 0.0064(0.0032) Grad: 15787.0117  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 36s (remain 9m 29s) Loss: 0.0000(0.0033) Grad: 2.2254  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 9m 6s (remain 8m 58s) Loss: 0.0004(0.0034) Grad: 11425.9785  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 37s (remain 8m 28s) Loss: 0.0065(0.0033) Grad: 55376.0156  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 10m 7s (remain 7m 58s) Loss: 0.0013(0.0034) Grad: 10027.9287  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 38s (remain 7m 27s) Loss: 0.0100(0.0035) Grad: 32689.1582  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 11m 8s (remain 6m 57s) Loss: 0.0009(0.0035) Grad: 17163.3223  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 39s (remain 6m 27s) Loss: 0.0000(0.0034) Grad: 121.2370  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 12m 9s (remain 5m 56s) Loss: 0.0000(0.0034) Grad: 34.9027  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 40s (remain 5m 26s) Loss: 0.0001(0.0034) Grad: 1416.7679  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 13m 10s (remain 4m 55s) Loss: 0.0000(0.0034) Grad: 52.1729  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 40s (remain 4m 25s) Loss: 0.0243(0.0034) Grad: 42468.5547  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 14m 11s (remain 3m 55s) Loss: 0.0000(0.0034) Grad: 10.9500  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 41s (remain 3m 24s) Loss: 0.0001(0.0035) Grad: 788.2585  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 15m 11s (remain 2m 54s) Loss: 0.0004(0.0034) Grad: 5619.8423  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 42s (remain 2m 24s) Loss: 0.0000(0.0034) Grad: 2.9105  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 16m 12s (remain 1m 53s) Loss: 0.0001(0.0034) Grad: 1032.3313  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 42s (remain 1m 23s) Loss: 0.0000(0.0035) Grad: 26.6577  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 17m 13s (remain 0m 52s) Loss: 0.0000(0.0035) Grad: 3.3663  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 17m 43s (remain 0m 22s) Loss: 0.0016(0.0035) Grad: 122198.8281  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 18m 6s (remain 0m 0s) Loss: 0.0024(0.0034) Grad: 45112.7461  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 3s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 17s (remain 3m 14s) Loss: 0.0815(0.0118) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 54s) Loss: 0.0082(0.0106) \n","EVAL: [300/1192] Elapsed 0m 52s (remain 2m 36s) Loss: 0.0104(0.0108) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 18s) Loss: 0.0001(0.0107) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 1s) Loss: 0.0000(0.0101) \n","EVAL: [600/1192] Elapsed 1m 45s (remain 1m 43s) Loss: 0.0086(0.0101) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0044(0.0110) \n","EVAL: [800/1192] Elapsed 2m 20s (remain 1m 8s) Loss: 0.0000(0.0113) \n","EVAL: [900/1192] Elapsed 2m 37s (remain 0m 51s) Loss: 0.0037(0.0111) \n","EVAL: [1000/1192] Elapsed 2m 55s (remain 0m 33s) Loss: 0.0232(0.0107) \n","EVAL: [1100/1192] Elapsed 3m 13s (remain 0m 15s) Loss: 0.0611(0.0102) \n","EVAL: [1191/1192] Elapsed 3m 28s (remain 0m 0s) Loss: 0.0000(0.0100) \n","Epoch 5 - avg_train_loss: 0.0034  avg_val_loss: 0.0100  time: 1304s\n","Epoch 5 - Score: 0.8878\n","Epoch 5 - Save Best Score: 0.8878 Model\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 43m 29s) Loss: 0.4334(0.4334) Grad: inf  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 33s (remain 19m 1s) Loss: 0.4795(0.4173) Grad: 26211.4414  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 1m 3s (remain 17m 45s) Loss: 0.0501(0.3134) Grad: 2431.9390  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 33s (remain 16m 59s) Loss: 0.0183(0.2262) Grad: 429.7721  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 2m 3s (remain 16m 20s) Loss: 0.0266(0.1797) Grad: 420.8719  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 34s (remain 15m 46s) Loss: 0.0135(0.1511) Grad: 705.6623  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 3m 5s (remain 15m 16s) Loss: 0.0493(0.1305) Grad: 2185.0364  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 36s (remain 14m 45s) Loss: 0.0110(0.1144) Grad: 701.4093  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 4m 6s (remain 14m 15s) Loss: 0.0114(0.1022) Grad: 821.6508  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 37s (remain 13m 44s) Loss: 0.0099(0.0928) Grad: 667.5644  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 5m 8s (remain 13m 14s) Loss: 0.0013(0.0849) Grad: 144.7932  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 39s (remain 12m 43s) Loss: 0.0024(0.0782) Grad: 184.6254  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 6m 10s (remain 12m 12s) Loss: 0.0068(0.0726) Grad: 985.5845  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 6m 40s (remain 11m 40s) Loss: 0.0038(0.0679) Grad: 802.9009  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 7m 10s (remain 11m 8s) Loss: 0.0200(0.0638) Grad: 1413.2010  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 7m 41s (remain 10m 37s) Loss: 0.0025(0.0602) Grad: 319.1217  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 8m 11s (remain 10m 6s) Loss: 0.0007(0.0571) Grad: 92.3512  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 8m 41s (remain 9m 34s) Loss: 0.0024(0.0543) Grad: 271.3254  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 9m 12s (remain 9m 3s) Loss: 0.0127(0.0518) Grad: 666.5244  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 9m 42s (remain 8m 32s) Loss: 0.0082(0.0498) Grad: 1428.3505  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 10m 12s (remain 8m 2s) Loss: 0.0590(0.0478) Grad: 3497.1860  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 10m 43s (remain 7m 31s) Loss: 0.0027(0.0460) Grad: 278.9131  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 11m 13s (remain 7m 0s) Loss: 0.0026(0.0442) Grad: 208.4232  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 11m 43s (remain 6m 29s) Loss: 0.0037(0.0427) Grad: 280.2436  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 12m 13s (remain 5m 58s) Loss: 0.0563(0.0412) Grad: 3267.0032  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 12m 43s (remain 5m 27s) Loss: 0.0053(0.0399) Grad: 610.2330  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 13m 13s (remain 4m 57s) Loss: 0.0031(0.0388) Grad: 162.7060  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 13m 44s (remain 4m 26s) Loss: 0.0049(0.0376) Grad: 266.5312  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 14m 14s (remain 3m 56s) Loss: 0.0127(0.0365) Grad: 646.0008  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 14m 44s (remain 3m 25s) Loss: 0.0056(0.0356) Grad: 373.3744  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 15m 14s (remain 2m 54s) Loss: 0.0085(0.0346) Grad: 410.2844  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 15m 45s (remain 2m 24s) Loss: 0.0042(0.0338) Grad: 272.6144  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 16m 15s (remain 1m 53s) Loss: 0.0015(0.0329) Grad: 161.1031  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 16m 45s (remain 1m 23s) Loss: 0.0034(0.0321) Grad: 233.3293  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 17m 15s (remain 0m 52s) Loss: 0.0129(0.0314) Grad: 882.1841  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 17m 46s (remain 0m 22s) Loss: 0.0237(0.0307) Grad: 1141.9796  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 18m 8s (remain 0m 0s) Loss: 0.0061(0.0302) Grad: 542.6009  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 10m 7s) Loss: 0.0051(0.0051) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 15s) Loss: 0.0147(0.0051) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 55s) Loss: 0.0048(0.0050) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 37s) Loss: 0.0035(0.0057) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 19s) Loss: 0.0002(0.0060) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 2s) Loss: 0.0261(0.0057) \n","EVAL: [600/1192] Elapsed 1m 45s (remain 1m 44s) Loss: 0.0063(0.0060) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0048(0.0066) \n","EVAL: [800/1192] Elapsed 2m 20s (remain 1m 8s) Loss: 0.0073(0.0067) \n","EVAL: [900/1192] Elapsed 2m 38s (remain 0m 51s) Loss: 0.0040(0.0066) \n","EVAL: [1000/1192] Elapsed 2m 56s (remain 0m 33s) Loss: 0.0002(0.0064) \n","EVAL: [1100/1192] Elapsed 3m 13s (remain 0m 16s) Loss: 0.0223(0.0062) \n","EVAL: [1191/1192] Elapsed 3m 29s (remain 0m 0s) Loss: 0.0002(0.0060) \n","Epoch 1 - avg_train_loss: 0.0302  avg_val_loss: 0.0060  time: 1304s\n","Epoch 1 - Score: 0.8449\n","Epoch 1 - Save Best Score: 0.8449 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 40m 29s) Loss: 0.0053(0.0053) Grad: 11483.3115  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 32s (remain 18m 52s) Loss: 0.0000(0.0062) Grad: 327.4116  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 1m 4s (remain 17m 56s) Loss: 0.0065(0.0054) Grad: 15133.3330  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 34s (remain 17m 8s) Loss: 0.0047(0.0058) Grad: 7866.7505  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 2m 4s (remain 16m 28s) Loss: 0.0020(0.0059) Grad: 4695.8853  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 35s (remain 15m 53s) Loss: 0.0011(0.0055) Grad: 1339.1387  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 3m 5s (remain 15m 20s) Loss: 0.0074(0.0054) Grad: 12839.4639  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 36s (remain 14m 47s) Loss: 0.0003(0.0060) Grad: 598.6717  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 4m 7s (remain 14m 16s) Loss: 0.0002(0.0061) Grad: 625.0772  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 38s (remain 13m 45s) Loss: 0.0024(0.0061) Grad: 8774.2012  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 5m 8s (remain 13m 14s) Loss: 0.0039(0.0060) Grad: 2643.4053  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 39s (remain 12m 43s) Loss: 0.0001(0.0059) Grad: 65.3792  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 6m 10s (remain 12m 12s) Loss: 0.0002(0.0059) Grad: 219.2733  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 6m 41s (remain 11m 41s) Loss: 0.0051(0.0059) Grad: 8406.4805  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 7m 12s (remain 11m 10s) Loss: 0.0000(0.0059) Grad: 34.3601  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 7m 42s (remain 10m 39s) Loss: 0.0007(0.0060) Grad: 994.5027  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 8m 13s (remain 10m 8s) Loss: 0.0096(0.0060) Grad: 3457.2644  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 8m 43s (remain 9m 37s) Loss: 0.0022(0.0062) Grad: 1952.2688  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 9m 14s (remain 9m 6s) Loss: 0.0013(0.0061) Grad: 1279.8616  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 9m 44s (remain 8m 35s) Loss: 0.0035(0.0061) Grad: 1687.3448  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 10m 15s (remain 8m 4s) Loss: 0.0005(0.0061) Grad: 390.8384  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 10m 46s (remain 7m 33s) Loss: 0.0014(0.0060) Grad: 1212.7698  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 11m 17s (remain 7m 2s) Loss: 0.0455(0.0060) Grad: 5651.5000  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 11m 48s (remain 6m 32s) Loss: 0.0035(0.0060) Grad: 1429.6288  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 12m 19s (remain 6m 1s) Loss: 0.0022(0.0059) Grad: 1471.3445  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 12m 49s (remain 5m 30s) Loss: 0.0001(0.0060) Grad: 74.4797  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 13m 20s (remain 4m 59s) Loss: 0.0024(0.0060) Grad: 1319.7185  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 13m 51s (remain 4m 29s) Loss: 0.0017(0.0060) Grad: 2086.1382  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 14m 22s (remain 3m 58s) Loss: 0.0065(0.0059) Grad: 2660.7761  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 14m 52s (remain 3m 27s) Loss: 0.0084(0.0059) Grad: 6201.8076  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 15m 22s (remain 2m 56s) Loss: 0.0039(0.0060) Grad: 2109.7502  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 15m 53s (remain 2m 25s) Loss: 0.0001(0.0059) Grad: 105.7492  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 16m 23s (remain 1m 54s) Loss: 0.0031(0.0060) Grad: 3182.8281  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 16m 53s (remain 1m 24s) Loss: 0.0437(0.0060) Grad: 5380.3550  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 17m 24s (remain 0m 53s) Loss: 0.0027(0.0060) Grad: 1282.3124  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 17m 54s (remain 0m 22s) Loss: 0.0179(0.0059) Grad: 4973.4097  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 18m 16s (remain 0m 0s) Loss: 0.0101(0.0059) Grad: 3492.7881  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 12s) Loss: 0.0013(0.0013) \n","EVAL: [100/1192] Elapsed 0m 17s (remain 3m 14s) Loss: 0.0239(0.0061) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 55s) Loss: 0.0102(0.0056) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 37s) Loss: 0.0026(0.0059) \n","EVAL: [400/1192] Elapsed 1m 10s (remain 2m 19s) Loss: 0.0003(0.0063) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 2s) Loss: 0.0322(0.0057) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 44s) Loss: 0.0084(0.0059) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0022(0.0067) \n","EVAL: [800/1192] Elapsed 2m 21s (remain 1m 9s) Loss: 0.0114(0.0070) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0062(0.0070) \n","EVAL: [1000/1192] Elapsed 2m 56s (remain 0m 33s) Loss: 0.0000(0.0067) \n","EVAL: [1100/1192] Elapsed 3m 14s (remain 0m 16s) Loss: 0.0074(0.0065) \n","EVAL: [1191/1192] Elapsed 3m 30s (remain 0m 0s) Loss: 0.0000(0.0064) \n","Epoch 2 - avg_train_loss: 0.0059  avg_val_loss: 0.0064  time: 1312s\n","Epoch 2 - Score: 0.8756\n","Epoch 2 - Save Best Score: 0.8756 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 38m 31s) Loss: 0.0053(0.0053) Grad: 18825.8203  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 34s (remain 19m 32s) Loss: 0.0038(0.0038) Grad: 8010.9087  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 1m 4s (remain 18m 6s) Loss: 0.0000(0.0042) Grad: 18.5938  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 35s (remain 17m 14s) Loss: 0.0012(0.0041) Grad: 12249.3760  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 2m 5s (remain 16m 34s) Loss: 0.0000(0.0043) Grad: 18.5227  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 35s (remain 15m 57s) Loss: 0.0025(0.0044) Grad: 11476.7109  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 3m 6s (remain 15m 22s) Loss: 0.0000(0.0045) Grad: 393.3762  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 37s (remain 14m 51s) Loss: 0.0000(0.0047) Grad: 57.2361  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 4m 8s (remain 14m 19s) Loss: 0.0018(0.0045) Grad: 7207.9810  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 38s (remain 13m 47s) Loss: 0.0031(0.0044) Grad: 11605.5283  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 5m 9s (remain 13m 16s) Loss: 0.0012(0.0047) Grad: 7180.2920  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 40s (remain 12m 44s) Loss: 0.0000(0.0047) Grad: 23.2315  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 6m 10s (remain 12m 12s) Loss: 0.0037(0.0046) Grad: 13335.4600  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 6m 41s (remain 11m 41s) Loss: 0.0006(0.0045) Grad: 2729.0012  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 7m 11s (remain 11m 10s) Loss: 0.0000(0.0045) Grad: 27.9882  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 7m 42s (remain 10m 38s) Loss: 0.0000(0.0045) Grad: 146.5447  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 8m 12s (remain 10m 7s) Loss: 0.0005(0.0045) Grad: 2310.4807  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 8m 43s (remain 9m 36s) Loss: 0.0000(0.0044) Grad: 74.2766  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 9m 14s (remain 9m 5s) Loss: 0.0206(0.0045) Grad: 35409.7539  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 9m 44s (remain 8m 34s) Loss: 0.0001(0.0045) Grad: 507.7815  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 10m 15s (remain 8m 3s) Loss: 0.0001(0.0046) Grad: 602.7381  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 10m 45s (remain 7m 32s) Loss: 0.0001(0.0046) Grad: 490.3925  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 11m 16s (remain 7m 2s) Loss: 0.0005(0.0046) Grad: 2791.1680  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 11m 46s (remain 6m 31s) Loss: 0.0000(0.0046) Grad: 156.6248  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 12m 16s (remain 6m 0s) Loss: 0.0014(0.0046) Grad: 6395.9644  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 12m 47s (remain 5m 29s) Loss: 0.0001(0.0047) Grad: 991.0482  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 13m 17s (remain 4m 58s) Loss: 0.0003(0.0046) Grad: 1946.8425  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 13m 48s (remain 4m 27s) Loss: 0.0000(0.0046) Grad: 532.1462  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 14m 18s (remain 3m 57s) Loss: 0.0001(0.0046) Grad: 830.9362  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 14m 49s (remain 3m 26s) Loss: 0.0012(0.0046) Grad: 6292.3530  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 15m 19s (remain 2m 55s) Loss: 0.0020(0.0046) Grad: 4879.2505  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 15m 49s (remain 2m 25s) Loss: 0.0001(0.0046) Grad: 1503.0421  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 16m 20s (remain 1m 54s) Loss: 0.0032(0.0046) Grad: 19413.0449  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 16m 50s (remain 1m 23s) Loss: 0.0001(0.0045) Grad: 698.4445  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 17m 20s (remain 0m 53s) Loss: 0.0047(0.0045) Grad: 21768.7422  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 17m 51s (remain 0m 22s) Loss: 0.0234(0.0045) Grad: 38161.1367  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 18m 13s (remain 0m 0s) Loss: 0.0002(0.0046) Grad: 1328.5300  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 42s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 14s) Loss: 0.0419(0.0068) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 56s) Loss: 0.0021(0.0067) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 39s) Loss: 0.0068(0.0069) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0000(0.0076) \n","EVAL: [500/1192] Elapsed 1m 29s (remain 2m 3s) Loss: 0.0514(0.0074) \n","EVAL: [600/1192] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0086(0.0075) \n","EVAL: [700/1192] Elapsed 2m 5s (remain 1m 27s) Loss: 0.0027(0.0083) \n","EVAL: [800/1192] Elapsed 2m 22s (remain 1m 9s) Loss: 0.0131(0.0087) \n","EVAL: [900/1192] Elapsed 2m 40s (remain 0m 51s) Loss: 0.0047(0.0087) \n","EVAL: [1000/1192] Elapsed 2m 58s (remain 0m 34s) Loss: 0.0000(0.0084) \n","EVAL: [1100/1192] Elapsed 3m 16s (remain 0m 16s) Loss: 0.0237(0.0083) \n","EVAL: [1191/1192] Elapsed 3m 32s (remain 0m 0s) Loss: 0.0000(0.0082) \n","Epoch 3 - avg_train_loss: 0.0046  avg_val_loss: 0.0082  time: 1312s\n","Epoch 3 - Score: 0.8870\n","Epoch 3 - Save Best Score: 0.8870 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 40m 48s) Loss: 0.0000(0.0000) Grad: 1003.3921  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 34s (remain 19m 37s) Loss: 0.0000(0.0037) Grad: 30.5497  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 1m 5s (remain 18m 17s) Loss: 0.0022(0.0042) Grad: 16049.4785  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 35s (remain 17m 23s) Loss: 0.0001(0.0040) Grad: 304.1021  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 2m 6s (remain 16m 40s) Loss: 0.0000(0.0040) Grad: 11.1122  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 36s (remain 16m 2s) Loss: 0.0000(0.0038) Grad: 372.3491  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 3m 7s (remain 15m 26s) Loss: 0.0016(0.0037) Grad: 6086.5513  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 38s (remain 14m 53s) Loss: 0.0000(0.0037) Grad: 79.8231  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 4m 8s (remain 14m 20s) Loss: 0.0007(0.0039) Grad: 3493.3276  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 38s (remain 13m 47s) Loss: 0.0028(0.0040) Grad: 18603.8105  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 5m 9s (remain 13m 15s) Loss: 0.0000(0.0039) Grad: 31.4215  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 39s (remain 12m 43s) Loss: 0.0000(0.0040) Grad: 38.8521  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 6m 10s (remain 12m 11s) Loss: 0.0000(0.0038) Grad: 59.6949  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 6m 40s (remain 11m 40s) Loss: 0.0148(0.0039) Grad: 26349.0762  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 7m 11s (remain 11m 8s) Loss: 0.0004(0.0039) Grad: 2174.7234  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 7m 41s (remain 10m 37s) Loss: 0.0000(0.0038) Grad: 8.9067  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 8m 11s (remain 10m 6s) Loss: 0.0026(0.0036) Grad: 23735.9062  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 8m 42s (remain 9m 35s) Loss: 0.0008(0.0038) Grad: 12472.6992  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 9m 12s (remain 9m 4s) Loss: 0.0003(0.0038) Grad: 2144.1885  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 9m 43s (remain 8m 33s) Loss: 0.0013(0.0037) Grad: 5524.5220  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 10m 13s (remain 8m 2s) Loss: 0.0003(0.0037) Grad: 1224.0494  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 10m 43s (remain 7m 31s) Loss: 0.0000(0.0037) Grad: 72.6916  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 11m 14s (remain 7m 0s) Loss: 0.0024(0.0037) Grad: 10000.9004  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 11m 45s (remain 6m 30s) Loss: 0.0000(0.0037) Grad: 273.6476  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 12m 15s (remain 5m 59s) Loss: 0.0001(0.0036) Grad: 1935.2706  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 12m 46s (remain 5m 29s) Loss: 0.0002(0.0038) Grad: 2920.0615  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 13m 17s (remain 4m 58s) Loss: 0.0002(0.0037) Grad: 1931.8441  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 13m 47s (remain 4m 27s) Loss: 0.0000(0.0037) Grad: 67.4087  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 14m 18s (remain 3m 57s) Loss: 0.0349(0.0037) Grad: 186941.4531  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 14m 48s (remain 3m 26s) Loss: 0.0000(0.0037) Grad: 61.9864  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 15m 19s (remain 2m 55s) Loss: 0.0225(0.0037) Grad: 118755.4297  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 15m 49s (remain 2m 25s) Loss: 0.0017(0.0037) Grad: 6123.3911  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 16m 20s (remain 1m 54s) Loss: 0.0000(0.0037) Grad: 189.3671  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 16m 50s (remain 1m 23s) Loss: 0.0000(0.0037) Grad: 13.0314  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 17m 21s (remain 0m 53s) Loss: 0.0000(0.0037) Grad: 239.0325  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 17m 51s (remain 0m 22s) Loss: 0.0007(0.0037) Grad: 17511.2754  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0019(0.0037) Grad: 13277.6729  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 37s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 15s) Loss: 0.0426(0.0077) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 56s) Loss: 0.0049(0.0074) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0094(0.0079) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0000(0.0083) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 2s) Loss: 0.0519(0.0083) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 44s) Loss: 0.0075(0.0085) \n","EVAL: [700/1192] Elapsed 2m 3s (remain 1m 26s) Loss: 0.0029(0.0095) \n","EVAL: [800/1192] Elapsed 2m 21s (remain 1m 9s) Loss: 0.0113(0.0100) \n","EVAL: [900/1192] Elapsed 2m 38s (remain 0m 51s) Loss: 0.0092(0.0100) \n","EVAL: [1000/1192] Elapsed 2m 56s (remain 0m 33s) Loss: 0.0000(0.0096) \n","EVAL: [1100/1192] Elapsed 3m 14s (remain 0m 16s) Loss: 0.0460(0.0095) \n","EVAL: [1191/1192] Elapsed 3m 29s (remain 0m 0s) Loss: 0.0000(0.0093) \n","Epoch 4 - avg_train_loss: 0.0037  avg_val_loss: 0.0093  time: 1310s\n","Epoch 4 - Score: 0.8866\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 35m 28s) Loss: 0.0098(0.0098) Grad: 25698.5137  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 30s (remain 17m 45s) Loss: 0.0000(0.0017) Grad: 11.6181  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 1m 1s (remain 17m 11s) Loss: 0.0000(0.0023) Grad: 37.9687  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 32s (remain 16m 41s) Loss: 0.0000(0.0024) Grad: 182.0690  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 2m 2s (remain 16m 8s) Loss: 0.0000(0.0024) Grad: 155.9137  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 32s (remain 15m 38s) Loss: 0.0000(0.0025) Grad: 7.8884  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 3m 3s (remain 15m 7s) Loss: 0.0000(0.0025) Grad: 59.9072  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 34s (remain 14m 38s) Loss: 0.0000(0.0027) Grad: 8.9443  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 4m 4s (remain 14m 8s) Loss: 0.0000(0.0028) Grad: 139.6218  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 35s (remain 13m 37s) Loss: 0.0000(0.0034) Grad: 225.1785  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 5m 6s (remain 13m 8s) Loss: 0.0002(0.0031) Grad: 2600.8464  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 37s (remain 12m 38s) Loss: 0.0000(0.0032) Grad: 6.6894  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 6m 8s (remain 12m 8s) Loss: 0.0001(0.0032) Grad: 1393.1289  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 6m 39s (remain 11m 38s) Loss: 0.0000(0.0032) Grad: 31.8482  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 7m 10s (remain 11m 8s) Loss: 0.0039(0.0032) Grad: 14839.8174  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 7m 41s (remain 10m 37s) Loss: 0.0019(0.0032) Grad: 13833.4004  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 8m 12s (remain 10m 7s) Loss: 0.0072(0.0033) Grad: 58143.5234  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 8m 43s (remain 9m 37s) Loss: 0.0000(0.0032) Grad: 9.4298  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 9m 14s (remain 9m 6s) Loss: 0.0000(0.0032) Grad: 40.9248  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 9m 44s (remain 8m 35s) Loss: 0.0001(0.0031) Grad: 615.4883  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 10m 15s (remain 8m 4s) Loss: 0.0001(0.0031) Grad: 1690.9772  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 10m 45s (remain 7m 33s) Loss: 0.0020(0.0030) Grad: 12181.6006  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 11m 16s (remain 7m 2s) Loss: 0.0033(0.0030) Grad: 14879.2188  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 11m 46s (remain 6m 31s) Loss: 0.0035(0.0030) Grad: 14022.7129  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 12m 17s (remain 6m 0s) Loss: 0.0002(0.0030) Grad: 2048.2268  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 12m 47s (remain 5m 29s) Loss: 0.0000(0.0030) Grad: 9.7084  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 13m 18s (remain 4m 58s) Loss: 0.0007(0.0031) Grad: 13329.8350  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 13m 48s (remain 4m 28s) Loss: 0.0062(0.0031) Grad: 46305.9531  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 14m 18s (remain 3m 57s) Loss: 0.0000(0.0030) Grad: 217.8400  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 14m 49s (remain 3m 26s) Loss: 0.0000(0.0030) Grad: 234.6464  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 15m 19s (remain 2m 55s) Loss: 0.0000(0.0030) Grad: 66.2152  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 15m 50s (remain 2m 25s) Loss: 0.0010(0.0030) Grad: 11840.7158  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 16m 20s (remain 1m 54s) Loss: 0.0000(0.0030) Grad: 117.8196  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 16m 51s (remain 1m 23s) Loss: 0.0007(0.0029) Grad: 7074.6055  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 17m 21s (remain 0m 53s) Loss: 0.0153(0.0029) Grad: 35198.9297  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 17m 51s (remain 0m 22s) Loss: 0.0000(0.0029) Grad: 78.8544  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 18m 14s (remain 0m 0s) Loss: 0.0087(0.0029) Grad: 61213.9141  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 44s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 18s (remain 3m 17s) Loss: 0.0485(0.0090) \n","EVAL: [200/1192] Elapsed 0m 35s (remain 2m 57s) Loss: 0.0138(0.0083) \n","EVAL: [300/1192] Elapsed 0m 53s (remain 2m 38s) Loss: 0.0095(0.0088) \n","EVAL: [400/1192] Elapsed 1m 11s (remain 2m 20s) Loss: 0.0000(0.0093) \n","EVAL: [500/1192] Elapsed 1m 28s (remain 2m 2s) Loss: 0.0565(0.0091) \n","EVAL: [600/1192] Elapsed 1m 46s (remain 1m 44s) Loss: 0.0102(0.0095) \n","EVAL: [700/1192] Elapsed 2m 4s (remain 1m 27s) Loss: 0.0035(0.0106) \n","EVAL: [800/1192] Elapsed 2m 21s (remain 1m 9s) Loss: 0.0130(0.0110) \n","EVAL: [900/1192] Elapsed 2m 39s (remain 0m 51s) Loss: 0.0095(0.0110) \n","EVAL: [1000/1192] Elapsed 2m 57s (remain 0m 33s) Loss: 0.0000(0.0106) \n","EVAL: [1100/1192] Elapsed 3m 14s (remain 0m 16s) Loss: 0.0323(0.0105) \n","EVAL: [1191/1192] Elapsed 3m 30s (remain 0m 0s) Loss: 0.0000(0.0103) \n","Epoch 5 - avg_train_loss: 0.0029  avg_val_loss: 0.0103  time: 1311s\n","Epoch 5 - Score: 0.8857\n","Best thres: 0.5, Score: 0.8847\n","Best thres: 0.48906249999999996, Score: 0.8847\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7612c64baee4b8b912acb7e8eaf245d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0715b76dac4db99e051678e29922c2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08b011de94e488ba605612b27d609ff"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp048.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5e681c596edd41babf7beff766c5c8ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a1b765f207c4522acb2339cfb82f957","IPY_MODEL_845e31e01a5d4fd59903151f41837b3b","IPY_MODEL_3e70839747414fe485eb1f7082c3712d"],"layout":"IPY_MODEL_40074485cbba42919a7227c6ad3387c0"}},"7a1b765f207c4522acb2339cfb82f957":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcf45caa4f1a41e4a6f5e631a5cd42b5","placeholder":"​","style":"IPY_MODEL_75a1d8073d20417abf7e073bb1b5505a","value":"100%"}},"845e31e01a5d4fd59903151f41837b3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70b6035667644d2eac0e89b1fbef904e","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5d5f2ca6a034cd2b7ea6f05acbdf800","value":42146}},"3e70839747414fe485eb1f7082c3712d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1659e9b3465c44a5a144027b1a4aeba9","placeholder":"​","style":"IPY_MODEL_b40fe842c0cc4c42bae96b6e3b3f1f5c","value":" 42146/42146 [00:40&lt;00:00, 1924.43it/s]"}},"40074485cbba42919a7227c6ad3387c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcf45caa4f1a41e4a6f5e631a5cd42b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75a1d8073d20417abf7e073bb1b5505a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70b6035667644d2eac0e89b1fbef904e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5d5f2ca6a034cd2b7ea6f05acbdf800":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1659e9b3465c44a5a144027b1a4aeba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b40fe842c0cc4c42bae96b6e3b3f1f5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"482e836f26cf4e9b82548a2745155357":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_874f6bcfbf9a4427a36e2d512de220b3","IPY_MODEL_e65984f737ed45479dbbad33ded31a3a","IPY_MODEL_8e8a4f9fc79943179fd75bd89aa09ebb"],"layout":"IPY_MODEL_c3f35f0b42a84a9db4409a3ac016aced"}},"874f6bcfbf9a4427a36e2d512de220b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8e498a67b134a99afc6863f2c9185c8","placeholder":"​","style":"IPY_MODEL_5083befca19b4f2394b38cb62a40960a","value":"100%"}},"e65984f737ed45479dbbad33ded31a3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c78cbc6bf414aa58c802707de688f53","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46baddaf15d8450a8f9b081ee3f7b950","value":143}},"8e8a4f9fc79943179fd75bd89aa09ebb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e58aa77e10254395ba3a595c22e701a6","placeholder":"​","style":"IPY_MODEL_e7c8da8989144074bd8c1d576bc772a3","value":" 143/143 [00:00&lt;00:00, 2461.28it/s]"}},"c3f35f0b42a84a9db4409a3ac016aced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e498a67b134a99afc6863f2c9185c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5083befca19b4f2394b38cb62a40960a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c78cbc6bf414aa58c802707de688f53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46baddaf15d8450a8f9b081ee3f7b950":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e58aa77e10254395ba3a595c22e701a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c8da8989144074bd8c1d576bc772a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7612c64baee4b8b912acb7e8eaf245d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a8a3541789a4d13848a6b1d8a60c054","IPY_MODEL_61555545ad8b490d8a8a7491d7fa1987","IPY_MODEL_fb22a3b4bfd546b280af6fdbb9eed68c"],"layout":"IPY_MODEL_1c274a1a846444ae8e5df1de12185f82"}},"7a8a3541789a4d13848a6b1d8a60c054":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47c6c452787f443293ed9d3f960cc6ce","placeholder":"​","style":"IPY_MODEL_310cc481328e49499b4a402d7774978b","value":"Downloading: 100%"}},"61555545ad8b490d8a8a7491d7fa1987":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_201c3a56a47a4e3d8b0923cd138d5c6c","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34bf15acd50b4893b9c022b6702a6824","value":1627284589}},"fb22a3b4bfd546b280af6fdbb9eed68c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0664030521ee40f0aa559e98a7b544f2","placeholder":"​","style":"IPY_MODEL_cd06540a8e674b20ae19da95d329f690","value":" 1.52G/1.52G [01:12&lt;00:00, 24.2MB/s]"}},"1c274a1a846444ae8e5df1de12185f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47c6c452787f443293ed9d3f960cc6ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"310cc481328e49499b4a402d7774978b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"201c3a56a47a4e3d8b0923cd138d5c6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34bf15acd50b4893b9c022b6702a6824":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0664030521ee40f0aa559e98a7b544f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd06540a8e674b20ae19da95d329f690":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a0715b76dac4db99e051678e29922c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa56fd6662ed46a484c7a99e7b05a6d9","IPY_MODEL_0f76e245a2f14b6e8589e3475009eece","IPY_MODEL_10e922ea99744d3086faf7d2f2189c79"],"layout":"IPY_MODEL_649688b4151949c490467c376e0d075c"}},"fa56fd6662ed46a484c7a99e7b05a6d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b266911088c44615adb142701198f968","placeholder":"​","style":"IPY_MODEL_aa833f59a52a4b75bbeec4c0881c617c","value":"100%"}},"0f76e245a2f14b6e8589e3475009eece":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ef9b9a216ee4be0ab6f1b870ddf63f1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d78bf2cd8c74cf1a1b0401ed0d3c931","value":2}},"10e922ea99744d3086faf7d2f2189c79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffd051b5ad9e41c7ae8f2f4730cd57ca","placeholder":"​","style":"IPY_MODEL_6f016d851bf842838c58c1d2fcb81b45","value":" 2/2 [00:01&lt;00:00,  1.55it/s]"}},"649688b4151949c490467c376e0d075c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b266911088c44615adb142701198f968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa833f59a52a4b75bbeec4c0881c617c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ef9b9a216ee4be0ab6f1b870ddf63f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d78bf2cd8c74cf1a1b0401ed0d3c931":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffd051b5ad9e41c7ae8f2f4730cd57ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f016d851bf842838c58c1d2fcb81b45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c08b011de94e488ba605612b27d609ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a31b036c7bd74f1e8d86af1a63e922c4","IPY_MODEL_b43419fcb785466fac40db8a85659eed","IPY_MODEL_72d2598c2da641199191e58a339ae6f2"],"layout":"IPY_MODEL_bbd2aeefb3e340e3973a7efab173f39b"}},"a31b036c7bd74f1e8d86af1a63e922c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0146c86fb9404b4cba43ab432254eb43","placeholder":"​","style":"IPY_MODEL_e8b87185c4ea48ee866038687b5d76b4","value":"100%"}},"b43419fcb785466fac40db8a85659eed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb9a41dc5e64876b74579c74fc43c64","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e4a083e73774d089a12e0be8b70b7bd","value":2}},"72d2598c2da641199191e58a339ae6f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2302d2a80d1c42c198802d010b487629","placeholder":"​","style":"IPY_MODEL_edd524c299534431b31116951243346c","value":" 2/2 [00:02&lt;00:00,  1.41it/s]"}},"bbd2aeefb3e340e3973a7efab173f39b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0146c86fb9404b4cba43ab432254eb43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b87185c4ea48ee866038687b5d76b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb9a41dc5e64876b74579c74fc43c64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e4a083e73774d089a12e0be8b70b7bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2302d2a80d1c42c198802d010b487629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edd524c299534431b31116951243346c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}