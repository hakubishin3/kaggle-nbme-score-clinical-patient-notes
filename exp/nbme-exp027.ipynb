{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaging-technique",
   "metadata": {
    "id": "blind-kingdom"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-newcastle",
   "metadata": {
    "id": "antique-glenn"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-frederick",
   "metadata": {
    "id": "bored-ministry"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "typical-routine",
   "metadata": {
    "id": "deadly-confidence"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp027\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-withdrawal",
   "metadata": {
    "id": "aware-worcester"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"microsoft/deberta-v3-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=4\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "everyday-taiwan",
   "metadata": {
    "id": "personalized-death"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-montana",
   "metadata": {
    "id": "cardiovascular-neutral"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "taken-relationship",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "checked-boards",
    "outputId": "87364705-3e3f-4866-a538-14dfdc9c7e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install transformers\n",
    "    !pip install sentencepiece\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frank-reader",
   "metadata": {
    "id": "iGai035Rvu1Z"
   },
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "if CFG.env == \"colab\":\n",
    "    input_dir = Path(\"./drive/MyDrive/00.kaggle/input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n",
    "else:\n",
    "    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)\n",
    "    \n",
    "    \n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "casual-classic",
   "metadata": {
    "id": "vital-mexico"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-revolution",
   "metadata": {
    "id": "economic-ladder"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "structural-employer",
   "metadata": {
    "id": "desperate-keyboard"
   },
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "velvet-output",
   "metadata": {
    "id": "flexible-wednesday"
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n",
    "\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, token_probs, tokenizer):\n",
    "    res = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n",
    "        encoded = tokenizer(\n",
    "            text=text,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n",
    "            start, end = offset_mapping\n",
    "            res[i][start:end] = pred\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_predicted_location_str(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def scoring(df, th=0.5):\n",
    "    labels = create_labels_for_scoring(df)\n",
    "\n",
    "    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n",
    "    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n",
    "    preds = get_predictions(predicted_location_str)\n",
    "\n",
    "    score = get_score(labels, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_best_thres(oof_df):\n",
    "    def f1_opt(x):\n",
    "        return -1 * scoring(oof_df, th=x)\n",
    "\n",
    "    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n",
    "    return best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "swiss-commons",
   "metadata": {
    "id": "logical-chemistry"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sublime-theology",
   "metadata": {
    "id": "gorgeous-record"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-detector",
   "metadata": {
    "id": "frozen-africa"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "immune-forestry",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shaped-metallic",
    "outputId": "11a7cabc-1b4b-4b13-c8cc-95ce538868f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "otherwise-hardware",
   "metadata": {
    "id": "visible-australia"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-aircraft",
   "metadata": {
    "id": "hydraulic-gibson"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adverse-threshold",
   "metadata": {
    "id": "interpreted-northeast"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "\n",
    "\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "according-antibody",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "martial-blind",
    "outputId": "42a83988-2022-4dc2-a38e-7f156b490c5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 8), (5, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n",
    "test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "major-receiver",
   "metadata": {
    "id": "electoral-favor"
   },
   "outputs": [],
   "source": [
    "train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n",
    "train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "judicial-begin",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "reported-parade",
    "outputId": "60a64543-0419-4942-9673-73f0921c1d34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4399\n",
       "1    8181\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n",
    "display(train['annotation_length'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-labor",
   "metadata": {
    "id": "enabling-relevance"
   },
   "source": [
    "## CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "failing-casting",
   "metadata": {
    "id": "mature-coalition"
   },
   "outputs": [],
   "source": [
    "def get_groupkfold(df, group_name):\n",
    "    groups = df[group_name].unique()\n",
    "\n",
    "    kf = KFold(\n",
    "        n_splits=CFG.n_fold,\n",
    "        shuffle=True,\n",
    "        random_state=CFG.seed,\n",
    "    )\n",
    "    folds_ids = []\n",
    "    for i_fold, (_, val_group_idx) in enumerate(kf.split(groups)):\n",
    "        val_group = groups[val_group_idx]\n",
    "        is_val = df[group_name].isin(val_group)\n",
    "        val_idx = df[is_val].index\n",
    "        df.loc[val_idx, \"fold\"] = int(i_fold)\n",
    "\n",
    "    df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "second-traveler",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "every-minutes",
    "outputId": "b1991a8c-a884-4b5a-8ad9-58990576bef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    2902\n",
       "1    2894\n",
       "2    2813\n",
       "3    2791\n",
       "4    2900\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_groupkfold(train, \"pn_num\")\n",
    "display(train.groupby(\"fold\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-fountain",
   "metadata": {
    "id": "subjective-entrance"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sublime-inquiry",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dramatic-afghanistan",
    "outputId": "f56c7a0a-6282-4575-c71e-5e908bc30b95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n",
    "else:\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.pretrained_model_name)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-front",
   "metadata": {
    "id": "divided-arrow"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "north-cattle",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "661a9a315f8646a49162891ae47c69e7",
      "ef004a834af944abbd512fa3218642a1",
      "74fa3a6b51ad46958e58de5580cf5333",
      "810a830f3b6743b9b074867dd8e4e179",
      "7316ae87cfb849898eb022e100730ba2",
      "c7cb034c107247cba318475c9952b4ac",
      "7d891639f26644e8a05d7fe38d178245",
      "c8a7a19edb074139baefe21f1901d4f4",
      "7ed0ca5ee62d45d89050f3caf3d528c9",
      "0b48bd338cc94fe396aa1b736b9a2507",
      "2ddd9fc857b549a4ba446dd64a1dd1d4"
     ]
    },
    "id": "immune-campbell",
    "outputId": "6b41528b-6e83-4946-cbd5-62621fd1ad43"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac35a4dc3c6443aca1d3ba4c6ed8473a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 323\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(pn_history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "refined-vector",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f319feca977544738ff2400ab23a9276",
      "26b1a86ee1ff4ce2862c13d47be2b2d6",
      "9815ec90f12a4696a85db6dc629ec62a",
      "e032f2bf0bb241c2911087a6efe1ce0b",
      "19783f5141cb47f8aaa057fb01dda913",
      "953c495e9f64430cbdd9184bb0bd35cb",
      "7e210db5a5fe41f696351dc87d525ee4",
      "1ad701d95f084c98bd1bf0e9d7d498a9",
      "6d74dcf5002c4752af12a65c3aca2113",
      "1faca6dc4b0e43988d2f81cd209297be",
      "2c55e9e0223548fbbbe29b3e11e59d50"
     ]
    },
    "id": "northern-branch",
    "outputId": "82a35c47-ca3a-441a-ff12-3dc32603677d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3c20ea7b0d4bf58940478a89a0b5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 28\n"
     ]
    }
   ],
   "source": [
    "feature_text_lengths = []\n",
    "tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    feature_text_lengths.append(length)\n",
    "\n",
    "print(\"max length:\", np.max(feature_text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "delayed-friday",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oriental-jacksonville",
    "outputId": "0ccfd10a-251f-49de-ce35-c4db182768ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 354\n"
     ]
    }
   ],
   "source": [
    "CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n",
    "\n",
    "print(\"max length:\", CFG.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "annoying-smell",
   "metadata": {
    "id": "flexible-trainer"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "        self.annotation_lengths = self.df[\"annotation_length\"].values\n",
    "        self.locations = self.df[\"location\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def _create_label(self, pn_history, annotation_length, location_list):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        offset_mapping = encoded[\"offset_mapping\"]\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "\n",
    "        if annotation_length > 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(\";\")]:\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "retired-fundamentals",
   "metadata": {
    "id": "stock-robertson"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = self.cfg.tokenizer\n",
    "        self.max_len = self.cfg.max_len\n",
    "        self.feature_texts = self.df[\"feature_text\"].values\n",
    "        self.pn_historys = self.df[\"pn_history\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _create_input(self, pn_history, feature_text):\n",
    "        encoded = self.tokenizer(\n",
    "            text=pn_history,\n",
    "            text_pair=feature_text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "        for k, v in encoded.items():\n",
    "            encoded[k] = torch.tensor(v, dtype=torch.long)\n",
    "        return encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-ranch",
   "metadata": {
    "id": "chemical-lucas"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "indonesian-journalism",
   "metadata": {
    "id": "animated-array"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, model_config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_config_path is None:\n",
    "            self.model_config = AutoConfig.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "        else:\n",
    "            self.model_config = torch.load(model_config_path)\n",
    "\n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(\n",
    "                self.cfg.pretrained_model_name,\n",
    "                config=self.model_config,\n",
    "            )\n",
    "            print(f\"Load weight from pretrained\")\n",
    "        else:\n",
    "            #self.backbone = AutoModel.from_config(self.model_config)\n",
    "            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n",
    "            #path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp009/checkpoint-129000/pytorch_model.bin\")\n",
    "            path = \"../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\"\n",
    "            state_dict = torch.load(path)\n",
    "            itpt.load_state_dict(state_dict)\n",
    "            self.backbone = itpt.deberta\n",
    "            print(f\"Load weight from {path}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(self.cfg.dropout),\n",
    "            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        output = self.fc(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-probability",
   "metadata": {
    "id": "thorough-bristol"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "announced-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_grouped_parameters(model):\n",
    "    model_type = 'backbone'\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters()\n",
    "                       if 'lstm' in n\n",
    "                       or 'cnn' in n\n",
    "                       or 'fc' in n],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": 1e-3,\n",
    "        },\n",
    "    ]\n",
    "    num_layers = model.backbone.config.num_hidden_layers\n",
    "    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
    "    layers.reverse()\n",
    "    lr = CFG.lr\n",
    "    weight_decay = 0.95\n",
    "    for layer in layers:\n",
    "        lr *= weight_decay\n",
    "        optimizer_grouped_parameters += [\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": weight_decay,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "        ]\n",
    "    return optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "capital-responsibility",
   "metadata": {
    "id": "n8Z5UnO9cCxW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65938\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "warming-timber",
   "metadata": {
    "id": "talented-quantity"
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n",
    "                    loss=losses,\n",
    "                     grad_norm=grad_norm,\n",
    "                     lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "southwest-stupid",
   "metadata": {
    "id": "figured-cooperative"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (inputs, labels) in enumerate(val_dataloader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n",
    "\n",
    "        pos_nums = (labels == 1).sum(axis=1)\n",
    "        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n",
    "        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n",
    "        weight = []\n",
    "        for pos_num in pos_nums:\n",
    "            if pos_num == 0:\n",
    "                weight.append(3.0)\n",
    "            else:\n",
    "                weight.append(1.0)\n",
    "        weight = torch.tensor(weight).to(device)\n",
    "        loss = loss * weight\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                .format(\n",
    "                    step, len(val_dataloader),\n",
    "                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n",
    "                    loss=losses,\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "reserved-possibility",
   "metadata": {
    "id": "played-pointer"
   },
   "outputs": [],
   "source": [
    "def inference_fn(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "together-retention",
   "metadata": {
    "id": "brazilian-nigeria"
   },
   "outputs": [],
   "source": [
    "def train_loop(df, i_fold, device):\n",
    "    print(f\"========== fold: {i_fold} training ==========\")\n",
    "    train_idx = df[df[\"fold\"] != i_fold].index\n",
    "    val_idx = df[df[\"fold\"] == i_fold].index\n",
    "\n",
    "    train_folds = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_folds = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainingDataset(CFG, train_folds)\n",
    "    val_dataset = TrainingDataset(CFG, val_folds)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    #model = CustomModel(CFG, model_config_path=None, pretrained=True)\n",
    "    model = CustomModel(CFG, model_config_path=None, pretrained=False)\n",
    "    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    \"\"\"\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    optimizer_grouped_parameters = get_optimizer_grouped_parameters(model)\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        betas=CFG.betas,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n",
    "    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    #criterion = FocalLoss(reduce=False)\n",
    "    best_score = -1 * np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "        avg_loss = train_fn(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "        avg_val_loss, val_preds = valid_fn(\n",
    "            val_dataloader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n",
    "        score = scoring(val_folds, th=0.5)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-burns",
   "metadata": {
    "id": "bearing-switch"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "current-theme",
   "metadata": {
    "id": "desperate-crime"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                _oof_df = train_loop(train, i_fold, device)\n",
    "                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n",
    "        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    if CFG.submission:\n",
    "        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n",
    "    else:\n",
    "        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n",
    "\n",
    "    score = scoring(oof_df, th=0.5)\n",
    "    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n",
    "    best_thres = get_best_thres(oof_df)\n",
    "    score = scoring(oof_df, th=best_thres)\n",
    "    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n",
    "\n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(CFG, test)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        for i_fold in CFG.train_fold:\n",
    "            if CFG.submission:\n",
    "                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n",
    "                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n",
    "            else:\n",
    "                model = CustomModel(CFG, model_config_path=None, pretrained=False)\n",
    "                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n",
    "\n",
    "            state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            test_token_probs = inference_fn(test_dataloader, model, device)\n",
    "            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n",
    "            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n",
    "            predictions.append(test_char_probs)\n",
    "\n",
    "            del state, test_token_probs, model; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n",
    "        test[CFG.target_col] = predicted_location_str\n",
    "        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n",
    "        test[[CFG.id_col, CFG.target_col]].to_csv(\n",
    "            CFG.output_dir / \"submission.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "incredible-township",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f39640d290374992aa246753125a91de",
      "410c3733ee43430eb55278748d07bc45",
      "5292a911912d43c2b80919e486b99de9",
      "ce26114873ed4c96b5ea391a41b18f68",
      "bec237aed5184115b697ea257f7b0c9b",
      "3ca14e3fd6b84312b0af50a89d5ac7c1",
      "8234c7d9369644dea7e5c7e8fe436771",
      "5a3f361a320f480aa8a4115366073d32",
      "0f856d468c8a4c4c9c83b5b263745508",
      "490bfe688fe1419996b69f7de1cfee23",
      "789324d1692d4f478d5b95491b03fc22",
      "1193874a74974cc59982c8d5e3ced585",
      "84ea1506dcad4e01ad1cc35b76c0339a",
      "8e243ea82e59492fb5b845e51a56347a",
      "55ac42bee2ce4f00841b8bd49a7c552d",
      "2281dd4891c640a0b31c23976223f2ba",
      "6919ba0239084b04988e1de02316c76e",
      "548835fe547d4114bfd39e5fac680635",
      "5068fb514bf143ba812fe202c3e7a83d",
      "1e0d277fe44242e19e3bec17a1cb7280",
      "ab8e5c4cef00426fa0cf2fc25c51381a",
      "2b311e42f1294339a07248b31db0c26c",
      "fc3c6209df394eefa2df9ce8dbb56830",
      "3fb5b968d9ab4e88964b6b126c6023d9",
      "d240d13622c14726a5639d44ef2421ec",
      "9e66574c8c0343ffb0477891bfe5e892",
      "219090e2dd934c1296f12660ea69b161",
      "e7be4ec44f2a4183b295f486e250b414",
      "44650208feba4c118904c7efc9887532",
      "d1cd0285cfe34f188e9c779617d48448",
      "331b7288a5024ce3a5036af53eb75cec",
      "00419a15e9834e98b8a3459b62d01f8b",
      "05fdce5a55c1483a937d07a50bd9465e",
      "5536b7aaba7c41f28197e318b362ec75",
      "5ecd28892bb84432935145e27ac71de7",
      "3b50983bfae8445fa305d1edadd651af",
      "cdbf6aefee644006826f76e2f6722b07",
      "7c62f6a2b08c41a8bc3ecf2efa58c325",
      "8478e8bf8b6146b48e717b84c021e7ab",
      "b09413b459c8406882a16db62e8df9c0",
      "72a8b4ea52534d4e9feab6c6fdd72a77",
      "65d16c05424c4df0b79b5786be8bd5d1",
      "63aa4d26409d437fa76e5a156bb04791",
      "e48e5c946462499ab018748ccf80c5b5",
      "160e78a145894001b2a1295627d80df9",
      "008f77fefdba425ab2c755f515693e6f",
      "605151b49d7641a28ebd0ca083770c69",
      "8f8c8632070c4fa0a3182521f41e9c40",
      "dfb4641da88e47d3bafabbaa56bc6916",
      "537dee640701470c8fc3cc29e7940bee",
      "6dc964a8934744608f92a6af0f0f923f",
      "925a3ae98bd6488eb7cffdec89d768da",
      "d76610cad4f645f187b26f1b82733569",
      "b28fa99d1b1b4e4da668bcc50373e4cc",
      "b8554928c5f141de8dfb94c04c2dda03"
     ]
    },
    "id": "graduate-vision",
    "outputId": "2a3a96e3-9421-4bcd-d191-898f1c27a819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2849] Elapsed 0m 1s (remain 57m 56s) Loss: 1.0276(1.0276) Grad: inf  LR: 0.000001  \n",
      "Epoch: [1][100/2849] Elapsed 0m 38s (remain 17m 26s) Loss: 0.2451(0.5780) Grad: 12165.4629  LR: 0.000071  \n",
      "Epoch: [1][200/2849] Elapsed 1m 16s (remain 16m 43s) Loss: 0.0425(0.3789) Grad: 2304.4111  LR: 0.000141  \n",
      "Epoch: [1][300/2849] Elapsed 1m 52s (remain 15m 54s) Loss: 0.0188(0.2671) Grad: 411.2582  LR: 0.000211  \n",
      "Epoch: [1][400/2849] Elapsed 2m 28s (remain 15m 9s) Loss: 0.0295(0.2103) Grad: 743.2853  LR: 0.000282  \n",
      "Epoch: [1][500/2849] Elapsed 3m 5s (remain 14m 30s) Loss: 0.0407(0.1766) Grad: 619.4483  LR: 0.000352  \n",
      "Epoch: [1][600/2849] Elapsed 3m 42s (remain 13m 52s) Loss: 0.0412(0.1543) Grad: 594.7398  LR: 0.000422  \n",
      "Epoch: [1][700/2849] Elapsed 4m 19s (remain 13m 14s) Loss: 0.0834(0.1380) Grad: 1668.6151  LR: 0.000492  \n",
      "Epoch: [1][800/2849] Elapsed 4m 55s (remain 12m 36s) Loss: 0.0231(0.1249) Grad: 627.8131  LR: 0.000563  \n",
      "Epoch: [1][900/2849] Elapsed 5m 33s (remain 12m 0s) Loss: 0.0159(0.1140) Grad: 1493.8364  LR: 0.000633  \n",
      "Epoch: [1][1000/2849] Elapsed 6m 10s (remain 11m 24s) Loss: 0.0066(0.1046) Grad: 528.6396  LR: 0.000703  \n",
      "Epoch: [1][1100/2849] Elapsed 6m 47s (remain 10m 47s) Loss: 0.0042(0.0967) Grad: 676.7029  LR: 0.000773  \n",
      "Epoch: [1][1200/2849] Elapsed 7m 24s (remain 10m 10s) Loss: 0.0030(0.0897) Grad: 520.1855  LR: 0.000843  \n",
      "Epoch: [1][1300/2849] Elapsed 8m 1s (remain 9m 32s) Loss: 0.0252(0.0839) Grad: 2585.9973  LR: 0.000914  \n",
      "Epoch: [1][1400/2849] Elapsed 8m 38s (remain 8m 56s) Loss: 0.0136(0.0787) Grad: 2997.2905  LR: 0.000984  \n",
      "Epoch: [1][1500/2849] Elapsed 9m 16s (remain 8m 19s) Loss: 0.0159(0.0743) Grad: 2040.2469  LR: 0.000994  \n",
      "Epoch: [1][1600/2849] Elapsed 9m 53s (remain 7m 42s) Loss: 0.0148(0.0703) Grad: 1493.8983  LR: 0.000986  \n",
      "Epoch: [1][1700/2849] Elapsed 10m 30s (remain 7m 5s) Loss: 0.0007(0.0668) Grad: 223.2606  LR: 0.000978  \n",
      "Epoch: [1][1800/2849] Elapsed 11m 7s (remain 6m 28s) Loss: 0.0137(0.0636) Grad: 934.8119  LR: 0.000971  \n",
      "Epoch: [1][1900/2849] Elapsed 11m 44s (remain 5m 51s) Loss: 0.0032(0.0608) Grad: 803.3183  LR: 0.000963  \n",
      "Epoch: [1][2000/2849] Elapsed 12m 20s (remain 5m 14s) Loss: 0.0024(0.0583) Grad: 553.7163  LR: 0.000955  \n",
      "Epoch: [1][2100/2849] Elapsed 12m 57s (remain 4m 36s) Loss: 0.0015(0.0560) Grad: 310.5745  LR: 0.000947  \n",
      "Epoch: [1][2200/2849] Elapsed 13m 35s (remain 4m 0s) Loss: 0.0274(0.0540) Grad: 1897.8668  LR: 0.000939  \n",
      "Epoch: [1][2300/2849] Elapsed 14m 13s (remain 3m 23s) Loss: 0.0009(0.0521) Grad: 319.9376  LR: 0.000932  \n",
      "Epoch: [1][2400/2849] Elapsed 14m 50s (remain 2m 46s) Loss: 0.0064(0.0502) Grad: 1771.7671  LR: 0.000924  \n",
      "Epoch: [1][2500/2849] Elapsed 15m 27s (remain 2m 8s) Loss: 0.0253(0.0486) Grad: 3067.9795  LR: 0.000916  \n",
      "Epoch: [1][2600/2849] Elapsed 16m 4s (remain 1m 31s) Loss: 0.0031(0.0470) Grad: 527.7260  LR: 0.000908  \n",
      "Epoch: [1][2700/2849] Elapsed 16m 42s (remain 0m 54s) Loss: 0.0013(0.0456) Grad: 541.5980  LR: 0.000900  \n",
      "Epoch: [1][2800/2849] Elapsed 17m 19s (remain 0m 17s) Loss: 0.0017(0.0442) Grad: 308.7020  LR: 0.000893  \n",
      "Epoch: [1][2848/2849] Elapsed 17m 36s (remain 0m 0s) Loss: 0.0227(0.0436) Grad: 1167.1581  LR: 0.000889  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 5s) Loss: 0.0026(0.0026) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0038(0.0070) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0013(0.0071) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0002(0.0073) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0042(0.0087) \n",
      "EVAL: [500/726] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0245(0.0088) \n",
      "EVAL: [600/726] Elapsed 2m 6s (remain 0m 26s) Loss: 0.0026(0.0085) \n",
      "EVAL: [700/726] Elapsed 2m 27s (remain 0m 5s) Loss: 0.0019(0.0080) \n",
      "EVAL: [725/726] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0004(0.0079) \n",
      "Epoch 1 - avg_train_loss: 0.0436  avg_val_loss: 0.0079  time: 1214s\n",
      "Epoch 1 - Score: 0.8534\n",
      "Epoch 1 - Save Best Score: 0.8534 Model\n",
      "Epoch: [2][0/2849] Elapsed 0m 0s (remain 29m 18s) Loss: 0.0088(0.0088) Grad: 40594.9414  LR: 0.000889  \n",
      "Epoch: [2][100/2849] Elapsed 0m 37s (remain 17m 7s) Loss: 0.0003(0.0067) Grad: 1116.5112  LR: 0.000881  \n",
      "Epoch: [2][200/2849] Elapsed 1m 15s (remain 16m 28s) Loss: 0.0171(0.0066) Grad: 41794.7461  LR: 0.000873  \n",
      "Epoch: [2][300/2849] Elapsed 1m 52s (remain 15m 49s) Loss: 0.0002(0.0069) Grad: 859.9453  LR: 0.000865  \n",
      "Epoch: [2][400/2849] Elapsed 2m 29s (remain 15m 10s) Loss: 0.0067(0.0069) Grad: 26481.3418  LR: 0.000858  \n",
      "Epoch: [2][500/2849] Elapsed 3m 6s (remain 14m 36s) Loss: 0.0577(0.0068) Grad: 122486.4062  LR: 0.000850  \n",
      "Epoch: [2][600/2849] Elapsed 3m 44s (remain 13m 58s) Loss: 0.0023(0.0069) Grad: 8571.5840  LR: 0.000842  \n",
      "Epoch: [2][700/2849] Elapsed 4m 21s (remain 13m 20s) Loss: 0.0055(0.0071) Grad: 15163.9453  LR: 0.000834  \n",
      "Epoch: [2][800/2849] Elapsed 4m 58s (remain 12m 42s) Loss: 0.0023(0.0071) Grad: 9405.9531  LR: 0.000826  \n",
      "Epoch: [2][900/2849] Elapsed 5m 35s (remain 12m 6s) Loss: 0.0000(0.0070) Grad: 229.3326  LR: 0.000819  \n",
      "Epoch: [2][1000/2849] Elapsed 6m 15s (remain 11m 33s) Loss: 0.0019(0.0071) Grad: 15328.4795  LR: 0.000811  \n",
      "Epoch: [2][1100/2849] Elapsed 6m 53s (remain 10m 55s) Loss: 0.0002(0.0070) Grad: 1352.9115  LR: 0.000803  \n",
      "Epoch: [2][1200/2849] Elapsed 7m 30s (remain 10m 18s) Loss: 0.0003(0.0069) Grad: 894.5644  LR: 0.000795  \n",
      "Epoch: [2][1300/2849] Elapsed 8m 8s (remain 9m 41s) Loss: 0.0006(0.0068) Grad: 4061.5925  LR: 0.000787  \n",
      "Epoch: [2][1400/2849] Elapsed 8m 45s (remain 9m 3s) Loss: 0.0009(0.0069) Grad: 2365.4827  LR: 0.000780  \n",
      "Epoch: [2][1500/2849] Elapsed 9m 22s (remain 8m 25s) Loss: 0.0005(0.0070) Grad: 2145.6038  LR: 0.000772  \n",
      "Epoch: [2][1600/2849] Elapsed 10m 1s (remain 7m 48s) Loss: 0.0000(0.0070) Grad: 172.7638  LR: 0.000764  \n",
      "Epoch: [2][1700/2849] Elapsed 10m 40s (remain 7m 12s) Loss: 0.0286(0.0071) Grad: 28078.0801  LR: 0.000756  \n",
      "Epoch: [2][1800/2849] Elapsed 11m 17s (remain 6m 34s) Loss: 0.0102(0.0071) Grad: 20297.9453  LR: 0.000748  \n",
      "Epoch: [2][1900/2849] Elapsed 11m 56s (remain 5m 57s) Loss: 0.0022(0.0072) Grad: 4436.4087  LR: 0.000741  \n",
      "Epoch: [2][2000/2849] Elapsed 12m 33s (remain 5m 19s) Loss: 0.0009(0.0072) Grad: 2894.9878  LR: 0.000733  \n",
      "Epoch: [2][2100/2849] Elapsed 13m 10s (remain 4m 41s) Loss: 0.0012(0.0072) Grad: 12422.9590  LR: 0.000725  \n",
      "Epoch: [2][2200/2849] Elapsed 13m 48s (remain 4m 3s) Loss: 0.0072(0.0073) Grad: 77746.9062  LR: 0.000717  \n",
      "Epoch: [2][2300/2849] Elapsed 14m 27s (remain 3m 26s) Loss: 0.0024(0.0073) Grad: 14079.2744  LR: 0.000709  \n",
      "Epoch: [2][2400/2849] Elapsed 15m 6s (remain 2m 49s) Loss: 0.0005(0.0072) Grad: 1279.5973  LR: 0.000702  \n",
      "Epoch: [2][2500/2849] Elapsed 15m 42s (remain 2m 11s) Loss: 0.0022(0.0073) Grad: 3172.9495  LR: 0.000694  \n",
      "Epoch: [2][2600/2849] Elapsed 16m 19s (remain 1m 33s) Loss: 0.0008(0.0074) Grad: 3354.8640  LR: 0.000686  \n",
      "Epoch: [2][2700/2849] Elapsed 16m 56s (remain 0m 55s) Loss: 0.0005(0.0073) Grad: 4414.8359  LR: 0.000678  \n",
      "Epoch: [2][2800/2849] Elapsed 17m 34s (remain 0m 18s) Loss: 0.0381(0.0073) Grad: 28249.6719  LR: 0.000670  \n",
      "Epoch: [2][2848/2849] Elapsed 17m 51s (remain 0m 0s) Loss: 0.0001(0.0073) Grad: 573.7206  LR: 0.000667  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 13s) Loss: 0.0007(0.0007) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 10s) Loss: 0.0063(0.0089) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 49s) Loss: 0.0002(0.0089) \n",
      "EVAL: [300/726] Elapsed 1m 2s (remain 1m 28s) Loss: 0.0000(0.0089) \n",
      "EVAL: [400/726] Elapsed 1m 23s (remain 1m 7s) Loss: 0.0030(0.0108) \n",
      "EVAL: [500/726] Elapsed 1m 44s (remain 0m 46s) Loss: 0.0284(0.0108) \n",
      "EVAL: [600/726] Elapsed 2m 5s (remain 0m 26s) Loss: 0.0048(0.0103) \n",
      "EVAL: [700/726] Elapsed 2m 26s (remain 0m 5s) Loss: 0.0023(0.0097) \n",
      "EVAL: [725/726] Elapsed 2m 31s (remain 0m 0s) Loss: 0.0001(0.0096) \n",
      "Epoch 2 - avg_train_loss: 0.0073  avg_val_loss: 0.0096  time: 1229s\n",
      "Epoch 2 - Score: 0.8741\n",
      "Epoch 2 - Save Best Score: 0.8741 Model\n",
      "Epoch: [3][0/2849] Elapsed 0m 0s (remain 30m 3s) Loss: 0.0001(0.0001) Grad: 644.2272  LR: 0.000667  \n",
      "Epoch: [3][100/2849] Elapsed 0m 40s (remain 18m 35s) Loss: 0.0006(0.0058) Grad: 2291.6411  LR: 0.000659  \n",
      "Epoch: [3][200/2849] Elapsed 1m 18s (remain 17m 9s) Loss: 0.0099(0.0062) Grad: 24639.0684  LR: 0.000651  \n",
      "Epoch: [3][300/2849] Elapsed 1m 55s (remain 16m 13s) Loss: 0.0320(0.0059) Grad: 23728.8164  LR: 0.000643  \n",
      "Epoch: [3][400/2849] Elapsed 2m 32s (remain 15m 29s) Loss: 0.0083(0.0057) Grad: 11091.7637  LR: 0.000635  \n",
      "Epoch: [3][500/2849] Elapsed 3m 12s (remain 15m 1s) Loss: 0.0107(0.0059) Grad: 15254.4834  LR: 0.000628  \n",
      "Epoch: [3][600/2849] Elapsed 3m 50s (remain 14m 21s) Loss: 0.0001(0.0059) Grad: 558.9266  LR: 0.000620  \n",
      "Epoch: [3][700/2849] Elapsed 4m 28s (remain 13m 42s) Loss: 0.0000(0.0061) Grad: 408.5292  LR: 0.000612  \n",
      "Epoch: [3][800/2849] Elapsed 5m 5s (remain 13m 1s) Loss: 0.0052(0.0060) Grad: 26202.2305  LR: 0.000604  \n",
      "Epoch: [3][900/2849] Elapsed 5m 43s (remain 12m 22s) Loss: 0.0391(0.0060) Grad: 119658.5234  LR: 0.000596  \n",
      "Epoch: [3][1000/2849] Elapsed 6m 21s (remain 11m 43s) Loss: 0.0108(0.0059) Grad: 19103.3535  LR: 0.000589  \n",
      "Epoch: [3][1100/2849] Elapsed 6m 58s (remain 11m 3s) Loss: 0.0068(0.0059) Grad: 9899.5674  LR: 0.000581  \n",
      "Epoch: [3][1200/2849] Elapsed 7m 35s (remain 10m 25s) Loss: 0.0326(0.0060) Grad: 33994.4102  LR: 0.000573  \n",
      "Epoch: [3][1300/2849] Elapsed 8m 16s (remain 9m 50s) Loss: 0.0191(0.0059) Grad: 27371.5703  LR: 0.000565  \n",
      "Epoch: [3][1400/2849] Elapsed 8m 53s (remain 9m 11s) Loss: 0.0035(0.0060) Grad: 10468.5781  LR: 0.000557  \n",
      "Epoch: [3][1500/2849] Elapsed 9m 30s (remain 8m 32s) Loss: 0.0017(0.0062) Grad: 7565.5181  LR: 0.000550  \n",
      "Epoch: [3][1600/2849] Elapsed 10m 7s (remain 7m 53s) Loss: 0.0029(0.0062) Grad: 4104.0059  LR: 0.000542  \n",
      "Epoch: [3][1700/2849] Elapsed 10m 45s (remain 7m 15s) Loss: 0.0000(0.0062) Grad: 198.8465  LR: 0.000534  \n",
      "Epoch: [3][1800/2849] Elapsed 11m 24s (remain 6m 38s) Loss: 0.0043(0.0063) Grad: 7626.2246  LR: 0.000526  \n",
      "Epoch: [3][1900/2849] Elapsed 12m 3s (remain 6m 1s) Loss: 0.0028(0.0064) Grad: 4805.9731  LR: 0.000518  \n",
      "Epoch: [3][2000/2849] Elapsed 12m 45s (remain 5m 24s) Loss: 0.0002(0.0064) Grad: 1825.1698  LR: 0.000511  \n",
      "Epoch: [3][2100/2849] Elapsed 13m 26s (remain 4m 47s) Loss: 0.0000(0.0064) Grad: 235.6934  LR: 0.000503  \n",
      "Epoch: [3][2200/2849] Elapsed 14m 7s (remain 4m 9s) Loss: 0.0000(0.0064) Grad: 180.9128  LR: 0.000495  \n",
      "Epoch: [3][2300/2849] Elapsed 14m 46s (remain 3m 31s) Loss: 0.0002(0.0064) Grad: 1445.7882  LR: 0.000487  \n",
      "Epoch: [3][2400/2849] Elapsed 15m 26s (remain 2m 52s) Loss: 0.0016(0.0064) Grad: 4613.4409  LR: 0.000479  \n",
      "Epoch: [3][2500/2849] Elapsed 16m 7s (remain 2m 14s) Loss: 0.0038(0.0064) Grad: 18299.4199  LR: 0.000472  \n",
      "Epoch: [3][2600/2849] Elapsed 16m 45s (remain 1m 35s) Loss: 0.0230(0.0064) Grad: 26294.5684  LR: 0.000464  \n",
      "Epoch: [3][2700/2849] Elapsed 17m 25s (remain 0m 57s) Loss: 0.0051(0.0064) Grad: 12567.0439  LR: 0.000456  \n",
      "Epoch: [3][2800/2849] Elapsed 18m 5s (remain 0m 18s) Loss: 0.0003(0.0063) Grad: 2983.2607  LR: 0.000448  \n",
      "Epoch: [3][2848/2849] Elapsed 18m 25s (remain 0m 0s) Loss: 0.0021(0.0063) Grad: 8604.0127  LR: 0.000444  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 14s) Loss: 0.0003(0.0003) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0059(0.0096) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0003(0.0095) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 30s) Loss: 0.0000(0.0093) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0057(0.0112) \n",
      "EVAL: [500/726] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0354(0.0110) \n",
      "EVAL: [600/726] Elapsed 2m 6s (remain 0m 26s) Loss: 0.0014(0.0104) \n",
      "EVAL: [700/726] Elapsed 2m 27s (remain 0m 5s) Loss: 0.0013(0.0098) \n",
      "EVAL: [725/726] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0000(0.0096) \n",
      "Epoch 3 - avg_train_loss: 0.0063  avg_val_loss: 0.0096  time: 1263s\n",
      "Epoch 3 - Score: 0.8730\n",
      "Epoch: [4][0/2849] Elapsed 0m 0s (remain 25m 45s) Loss: 0.0066(0.0066) Grad: 8311.4717  LR: 0.000444  \n",
      "Epoch: [4][100/2849] Elapsed 0m 37s (remain 16m 54s) Loss: 0.0005(0.0046) Grad: 3972.2979  LR: 0.000437  \n",
      "Epoch: [4][200/2849] Elapsed 1m 15s (remain 16m 37s) Loss: 0.0486(0.0052) Grad: 36312.9922  LR: 0.000429  \n",
      "Epoch: [4][300/2849] Elapsed 1m 53s (remain 15m 56s) Loss: 0.0004(0.0055) Grad: 2029.0259  LR: 0.000421  \n",
      "Epoch: [4][400/2849] Elapsed 2m 29s (remain 15m 13s) Loss: 0.0024(0.0054) Grad: 11693.0967  LR: 0.000413  \n",
      "Epoch: [4][500/2849] Elapsed 3m 5s (remain 14m 31s) Loss: 0.0010(0.0052) Grad: 3295.2107  LR: 0.000405  \n",
      "Epoch: [4][600/2849] Elapsed 3m 42s (remain 13m 52s) Loss: 0.0043(0.0051) Grad: 7351.1953  LR: 0.000398  \n",
      "Epoch: [4][700/2849] Elapsed 4m 19s (remain 13m 15s) Loss: 0.0009(0.0051) Grad: 3939.7532  LR: 0.000390  \n",
      "Epoch: [4][800/2849] Elapsed 4m 56s (remain 12m 37s) Loss: 0.0012(0.0056) Grad: 6491.7529  LR: 0.000382  \n",
      "Epoch: [4][900/2849] Elapsed 5m 35s (remain 12m 5s) Loss: 0.0184(0.0056) Grad: 48130.6719  LR: 0.000374  \n",
      "Epoch: [4][1000/2849] Elapsed 6m 17s (remain 11m 36s) Loss: 0.0020(0.0056) Grad: 9382.4619  LR: 0.000366  \n",
      "Epoch: [4][1100/2849] Elapsed 6m 57s (remain 11m 3s) Loss: 0.0186(0.0055) Grad: 38747.7578  LR: 0.000359  \n",
      "Epoch: [4][1200/2849] Elapsed 7m 35s (remain 10m 24s) Loss: 0.0012(0.0057) Grad: 6230.5020  LR: 0.000351  \n",
      "Epoch: [4][1300/2849] Elapsed 8m 11s (remain 9m 45s) Loss: 0.0000(0.0058) Grad: 158.3910  LR: 0.000343  \n",
      "Epoch: [4][1400/2849] Elapsed 8m 48s (remain 9m 6s) Loss: 0.0001(0.0057) Grad: 542.0774  LR: 0.000335  \n",
      "Epoch: [4][1500/2849] Elapsed 9m 25s (remain 8m 27s) Loss: 0.0000(0.0058) Grad: 153.0323  LR: 0.000327  \n",
      "Epoch: [4][1600/2849] Elapsed 10m 1s (remain 7m 49s) Loss: 0.0052(0.0058) Grad: 17595.8516  LR: 0.000320  \n",
      "Epoch: [4][1700/2849] Elapsed 10m 41s (remain 7m 12s) Loss: 0.0000(0.0058) Grad: 239.5992  LR: 0.000312  \n",
      "Epoch: [4][1800/2849] Elapsed 11m 18s (remain 6m 34s) Loss: 0.0000(0.0057) Grad: 147.6932  LR: 0.000304  \n",
      "Epoch: [4][1900/2849] Elapsed 11m 55s (remain 5m 56s) Loss: 0.0011(0.0056) Grad: 7607.2861  LR: 0.000296  \n",
      "Epoch: [4][2000/2849] Elapsed 12m 32s (remain 5m 18s) Loss: 0.0005(0.0056) Grad: 4790.0142  LR: 0.000288  \n",
      "Epoch: [4][2100/2849] Elapsed 13m 9s (remain 4m 41s) Loss: 0.0000(0.0056) Grad: 181.3542  LR: 0.000281  \n",
      "Epoch: [4][2200/2849] Elapsed 13m 47s (remain 4m 3s) Loss: 0.0077(0.0055) Grad: 24331.7578  LR: 0.000273  \n",
      "Epoch: [4][2300/2849] Elapsed 14m 25s (remain 3m 26s) Loss: 0.0000(0.0055) Grad: 230.4695  LR: 0.000265  \n",
      "Epoch: [4][2400/2849] Elapsed 15m 2s (remain 2m 48s) Loss: 0.0042(0.0055) Grad: 29325.8906  LR: 0.000257  \n",
      "Epoch: [4][2500/2849] Elapsed 15m 40s (remain 2m 10s) Loss: 0.0050(0.0055) Grad: 11299.4307  LR: 0.000249  \n",
      "Epoch: [4][2600/2849] Elapsed 16m 20s (remain 1m 33s) Loss: 0.0018(0.0055) Grad: 8935.1553  LR: 0.000242  \n",
      "Epoch: [4][2700/2849] Elapsed 16m 57s (remain 0m 55s) Loss: 0.0016(0.0055) Grad: 5008.9644  LR: 0.000234  \n",
      "Epoch: [4][2800/2849] Elapsed 17m 34s (remain 0m 18s) Loss: 0.0001(0.0056) Grad: 762.0662  LR: 0.000226  \n",
      "Epoch: [4][2848/2849] Elapsed 17m 51s (remain 0m 0s) Loss: 0.0208(0.0056) Grad: 51050.0898  LR: 0.000222  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 6m 5s) Loss: 0.0005(0.0005) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0071(0.0104) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0001(0.0096) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0000(0.0095) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0027(0.0113) \n",
      "EVAL: [500/726] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0312(0.0113) \n",
      "EVAL: [600/726] Elapsed 2m 6s (remain 0m 26s) Loss: 0.0058(0.0106) \n",
      "EVAL: [700/726] Elapsed 2m 27s (remain 0m 5s) Loss: 0.0021(0.0099) \n",
      "EVAL: [725/726] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0000(0.0097) \n",
      "Epoch 4 - avg_train_loss: 0.0056  avg_val_loss: 0.0097  time: 1229s\n",
      "Epoch 4 - Score: 0.8765\n",
      "Epoch 4 - Save Best Score: 0.8765 Model\n",
      "Epoch: [5][0/2849] Elapsed 0m 0s (remain 28m 29s) Loss: 0.0006(0.0006) Grad: 2612.3208  LR: 0.000222  \n",
      "Epoch: [5][100/2849] Elapsed 0m 37s (remain 17m 1s) Loss: 0.0010(0.0035) Grad: 9034.7246  LR: 0.000214  \n",
      "Epoch: [5][200/2849] Elapsed 1m 14s (remain 16m 18s) Loss: 0.0000(0.0039) Grad: 264.9453  LR: 0.000207  \n",
      "Epoch: [5][300/2849] Elapsed 1m 51s (remain 15m 41s) Loss: 0.0000(0.0037) Grad: 150.2207  LR: 0.000199  \n",
      "Epoch: [5][400/2849] Elapsed 2m 28s (remain 15m 4s) Loss: 0.0316(0.0046) Grad: 89264.4453  LR: 0.000191  \n",
      "Epoch: [5][500/2849] Elapsed 3m 4s (remain 14m 26s) Loss: 0.0000(0.0048) Grad: 460.8323  LR: 0.000183  \n",
      "Epoch: [5][600/2849] Elapsed 3m 43s (remain 13m 54s) Loss: 0.0005(0.0049) Grad: 2072.1316  LR: 0.000175  \n",
      "Epoch: [5][700/2849] Elapsed 4m 21s (remain 13m 21s) Loss: 0.0017(0.0051) Grad: 4458.7866  LR: 0.000168  \n",
      "Epoch: [5][800/2849] Elapsed 4m 58s (remain 12m 42s) Loss: 0.0027(0.0051) Grad: 9157.2178  LR: 0.000160  \n",
      "Epoch: [5][900/2849] Elapsed 5m 35s (remain 12m 5s) Loss: 0.0000(0.0049) Grad: 172.2436  LR: 0.000152  \n",
      "Epoch: [5][1000/2849] Elapsed 6m 15s (remain 11m 33s) Loss: 0.0033(0.0048) Grad: 13274.3691  LR: 0.000144  \n",
      "Epoch: [5][1100/2849] Elapsed 6m 52s (remain 10m 55s) Loss: 0.0001(0.0049) Grad: 372.0521  LR: 0.000136  \n",
      "Epoch: [5][1200/2849] Elapsed 7m 29s (remain 10m 16s) Loss: 0.0001(0.0048) Grad: 777.2891  LR: 0.000129  \n",
      "Epoch: [5][1300/2849] Elapsed 8m 6s (remain 9m 38s) Loss: 0.0017(0.0050) Grad: 9489.4580  LR: 0.000121  \n",
      "Epoch: [5][1400/2849] Elapsed 8m 43s (remain 9m 0s) Loss: 0.0275(0.0049) Grad: 22740.4785  LR: 0.000113  \n",
      "Epoch: [5][1500/2849] Elapsed 9m 22s (remain 8m 25s) Loss: 0.0026(0.0049) Grad: 6222.7510  LR: 0.000105  \n",
      "Epoch: [5][1600/2849] Elapsed 9m 59s (remain 7m 47s) Loss: 0.0000(0.0049) Grad: 455.7580  LR: 0.000097  \n",
      "Epoch: [5][1700/2849] Elapsed 10m 36s (remain 7m 9s) Loss: 0.0119(0.0049) Grad: 11707.0547  LR: 0.000090  \n",
      "Epoch: [5][1800/2849] Elapsed 11m 13s (remain 6m 31s) Loss: 0.0000(0.0048) Grad: 199.9132  LR: 0.000082  \n",
      "Epoch: [5][1900/2849] Elapsed 11m 49s (remain 5m 54s) Loss: 0.0036(0.0047) Grad: 7354.9912  LR: 0.000074  \n",
      "Epoch: [5][2000/2849] Elapsed 12m 27s (remain 5m 16s) Loss: 0.0020(0.0048) Grad: 24697.2832  LR: 0.000066  \n",
      "Epoch: [5][2100/2849] Elapsed 13m 7s (remain 4m 40s) Loss: 0.0020(0.0049) Grad: 6490.7427  LR: 0.000058  \n",
      "Epoch: [5][2200/2849] Elapsed 13m 43s (remain 4m 2s) Loss: 0.0000(0.0048) Grad: 279.9028  LR: 0.000051  \n",
      "Epoch: [5][2300/2849] Elapsed 14m 20s (remain 3m 24s) Loss: 0.0003(0.0049) Grad: 2347.2583  LR: 0.000043  \n",
      "Epoch: [5][2400/2849] Elapsed 14m 58s (remain 2m 47s) Loss: 0.0001(0.0049) Grad: 699.3987  LR: 0.000035  \n",
      "Epoch: [5][2500/2849] Elapsed 15m 36s (remain 2m 10s) Loss: 0.0000(0.0049) Grad: 186.0048  LR: 0.000027  \n",
      "Epoch: [5][2600/2849] Elapsed 16m 17s (remain 1m 33s) Loss: 0.0136(0.0050) Grad: 13772.7119  LR: 0.000019  \n",
      "Epoch: [5][2700/2849] Elapsed 16m 54s (remain 0m 55s) Loss: 0.0010(0.0049) Grad: 7623.5869  LR: 0.000012  \n",
      "Epoch: [5][2800/2849] Elapsed 17m 31s (remain 0m 18s) Loss: 0.0023(0.0050) Grad: 9437.2275  LR: 0.000004  \n",
      "Epoch: [5][2848/2849] Elapsed 17m 49s (remain 0m 0s) Loss: 0.0031(0.0049) Grad: 6949.1152  LR: 0.000000  \n",
      "EVAL: [0/726] Elapsed 0m 0s (remain 5m 21s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/726] Elapsed 0m 21s (remain 2m 13s) Loss: 0.0063(0.0110) \n",
      "EVAL: [200/726] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0001(0.0101) \n",
      "EVAL: [300/726] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0000(0.0100) \n",
      "EVAL: [400/726] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0026(0.0119) \n",
      "EVAL: [500/726] Elapsed 1m 44s (remain 0m 47s) Loss: 0.0276(0.0118) \n",
      "EVAL: [600/726] Elapsed 2m 6s (remain 0m 26s) Loss: 0.0035(0.0110) \n",
      "EVAL: [700/726] Elapsed 2m 27s (remain 0m 5s) Loss: 0.0024(0.0103) \n",
      "EVAL: [725/726] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0000(0.0101) \n",
      "Epoch 5 - avg_train_loss: 0.0049  avg_val_loss: 0.0101  time: 1227s\n",
      "Epoch 5 - Score: 0.8793\n",
      "Epoch 5 - Save Best Score: 0.8793 Model\n",
      "========== fold: 1 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2851] Elapsed 0m 0s (remain 29m 45s) Loss: 0.4919(0.4919) Grad: inf  LR: 0.000001  \n",
      "Epoch: [1][100/2851] Elapsed 0m 37s (remain 16m 58s) Loss: 0.2018(0.4547) Grad: 23129.5410  LR: 0.000071  \n",
      "Epoch: [1][200/2851] Elapsed 1m 15s (remain 16m 35s) Loss: 0.0436(0.3081) Grad: 3771.9780  LR: 0.000141  \n",
      "Epoch: [1][300/2851] Elapsed 1m 53s (remain 16m 3s) Loss: 0.0523(0.2211) Grad: 1277.1875  LR: 0.000211  \n",
      "Epoch: [1][400/2851] Elapsed 2m 31s (remain 15m 24s) Loss: 0.0492(0.1769) Grad: 1201.2526  LR: 0.000281  \n",
      "Epoch: [1][500/2851] Elapsed 3m 8s (remain 14m 44s) Loss: 0.1176(0.1498) Grad: 4101.0474  LR: 0.000352  \n",
      "Epoch: [1][600/2851] Elapsed 3m 45s (remain 14m 4s) Loss: 0.0574(0.1312) Grad: 1742.2344  LR: 0.000422  \n",
      "Epoch: [1][700/2851] Elapsed 4m 22s (remain 13m 25s) Loss: 0.0295(0.1177) Grad: 921.9211  LR: 0.000492  \n",
      "Epoch: [1][800/2851] Elapsed 4m 59s (remain 12m 47s) Loss: 0.0088(0.1074) Grad: 2204.5312  LR: 0.000562  \n",
      "Epoch: [1][900/2851] Elapsed 5m 38s (remain 12m 12s) Loss: 0.0298(0.0981) Grad: 5273.7861  LR: 0.000632  \n",
      "Epoch: [1][1000/2851] Elapsed 6m 15s (remain 11m 34s) Loss: 0.0037(0.0902) Grad: 1022.9703  LR: 0.000702  \n",
      "Epoch: [1][1100/2851] Elapsed 6m 52s (remain 10m 55s) Loss: 0.0064(0.0836) Grad: 1760.2118  LR: 0.000773  \n",
      "Epoch: [1][1200/2851] Elapsed 7m 29s (remain 10m 17s) Loss: 0.0141(0.0778) Grad: 2545.7288  LR: 0.000843  \n",
      "Epoch: [1][1300/2851] Elapsed 8m 6s (remain 9m 39s) Loss: 0.0218(0.0729) Grad: 4644.4824  LR: 0.000913  \n",
      "Epoch: [1][1400/2851] Elapsed 8m 43s (remain 9m 2s) Loss: 0.0236(0.0685) Grad: 5506.2798  LR: 0.000983  \n",
      "Epoch: [1][1500/2851] Elapsed 9m 23s (remain 8m 27s) Loss: 0.0897(0.0649) Grad: 14207.4990  LR: 0.000994  \n",
      "Epoch: [1][1600/2851] Elapsed 10m 3s (remain 7m 50s) Loss: 0.0040(0.0616) Grad: 2039.9954  LR: 0.000986  \n",
      "Epoch: [1][1700/2851] Elapsed 10m 40s (remain 7m 12s) Loss: 0.0014(0.0585) Grad: 1361.1771  LR: 0.000978  \n",
      "Epoch: [1][1800/2851] Elapsed 11m 17s (remain 6m 34s) Loss: 0.0055(0.0561) Grad: 2047.6405  LR: 0.000971  \n",
      "Epoch: [1][1900/2851] Elapsed 11m 54s (remain 5m 56s) Loss: 0.0051(0.0537) Grad: 1028.2488  LR: 0.000963  \n",
      "Epoch: [1][2000/2851] Elapsed 12m 31s (remain 5m 19s) Loss: 0.0188(0.0517) Grad: 3146.2710  LR: 0.000955  \n",
      "Epoch: [1][2100/2851] Elapsed 13m 8s (remain 4m 41s) Loss: 0.0050(0.0496) Grad: 2870.1255  LR: 0.000947  \n",
      "Epoch: [1][2200/2851] Elapsed 13m 45s (remain 4m 3s) Loss: 0.0616(0.0478) Grad: 8651.6406  LR: 0.000940  \n",
      "Epoch: [1][2300/2851] Elapsed 14m 22s (remain 3m 26s) Loss: 0.0007(0.0461) Grad: 385.6053  LR: 0.000932  \n",
      "Epoch: [1][2400/2851] Elapsed 15m 0s (remain 2m 48s) Loss: 0.0051(0.0446) Grad: 1847.4111  LR: 0.000924  \n",
      "Epoch: [1][2500/2851] Elapsed 15m 37s (remain 2m 11s) Loss: 0.0118(0.0432) Grad: 1929.9377  LR: 0.000916  \n",
      "Epoch: [1][2600/2851] Elapsed 16m 13s (remain 1m 33s) Loss: 0.0015(0.0419) Grad: 766.5996  LR: 0.000908  \n",
      "Epoch: [1][2700/2851] Elapsed 16m 51s (remain 0m 56s) Loss: 0.0284(0.0407) Grad: 6115.6689  LR: 0.000901  \n",
      "Epoch: [1][2800/2851] Elapsed 17m 30s (remain 0m 18s) Loss: 0.0039(0.0396) Grad: 929.9656  LR: 0.000893  \n",
      "Epoch: [1][2850/2851] Elapsed 17m 49s (remain 0m 0s) Loss: 0.0043(0.0390) Grad: 729.9512  LR: 0.000889  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 34s) Loss: 0.0020(0.0020) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 14s) Loss: 0.0015(0.0075) \n",
      "EVAL: [200/724] Elapsed 0m 44s (remain 1m 54s) Loss: 0.0002(0.0092) \n",
      "EVAL: [300/724] Elapsed 1m 5s (remain 1m 31s) Loss: 0.0002(0.0087) \n",
      "EVAL: [400/724] Elapsed 1m 26s (remain 1m 9s) Loss: 0.0001(0.0090) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0208(0.0104) \n",
      "EVAL: [600/724] Elapsed 2m 9s (remain 0m 26s) Loss: 0.0008(0.0100) \n",
      "EVAL: [700/724] Elapsed 2m 30s (remain 0m 4s) Loss: 0.0001(0.0092) \n",
      "EVAL: [723/724] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0005(0.0092) \n",
      "Epoch 1 - avg_train_loss: 0.0390  avg_val_loss: 0.0092  time: 1229s\n",
      "Epoch 1 - Score: 0.8598\n",
      "Epoch 1 - Save Best Score: 0.8598 Model\n",
      "Epoch: [2][0/2851] Elapsed 0m 0s (remain 30m 51s) Loss: 0.0004(0.0004) Grad: 1926.0771  LR: 0.000889  \n",
      "Epoch: [2][100/2851] Elapsed 0m 38s (remain 17m 29s) Loss: 0.0251(0.0088) Grad: 39022.3516  LR: 0.000881  \n",
      "Epoch: [2][200/2851] Elapsed 1m 17s (remain 16m 56s) Loss: 0.0020(0.0087) Grad: 7468.7310  LR: 0.000873  \n",
      "Epoch: [2][300/2851] Elapsed 1m 53s (remain 16m 3s) Loss: 0.0027(0.0087) Grad: 10222.4551  LR: 0.000865  \n",
      "Epoch: [2][400/2851] Elapsed 2m 29s (remain 15m 16s) Loss: 0.0007(0.0087) Grad: 3869.9302  LR: 0.000858  \n",
      "Epoch: [2][500/2851] Elapsed 3m 6s (remain 14m 35s) Loss: 0.1180(0.0087) Grad: 42988.2422  LR: 0.000850  \n",
      "Epoch: [2][600/2851] Elapsed 3m 44s (remain 14m 0s) Loss: 0.0050(0.0082) Grad: 14001.8281  LR: 0.000842  \n",
      "Epoch: [2][700/2851] Elapsed 4m 22s (remain 13m 26s) Loss: 0.0001(0.0083) Grad: 901.4785  LR: 0.000834  \n",
      "Epoch: [2][800/2851] Elapsed 5m 0s (remain 12m 49s) Loss: 0.0001(0.0084) Grad: 264.0899  LR: 0.000826  \n",
      "Epoch: [2][900/2851] Elapsed 5m 37s (remain 12m 10s) Loss: 0.0005(0.0086) Grad: 1521.1733  LR: 0.000819  \n",
      "Epoch: [2][1000/2851] Elapsed 6m 14s (remain 11m 32s) Loss: 0.0024(0.0083) Grad: 9593.3262  LR: 0.000811  \n",
      "Epoch: [2][1100/2851] Elapsed 6m 51s (remain 10m 54s) Loss: 0.0044(0.0082) Grad: 11038.0928  LR: 0.000803  \n",
      "Epoch: [2][1200/2851] Elapsed 7m 29s (remain 10m 17s) Loss: 0.0084(0.0081) Grad: 18485.8359  LR: 0.000795  \n",
      "Epoch: [2][1300/2851] Elapsed 8m 7s (remain 9m 40s) Loss: 0.0020(0.0079) Grad: 4766.4399  LR: 0.000787  \n",
      "Epoch: [2][1400/2851] Elapsed 8m 45s (remain 9m 4s) Loss: 0.0094(0.0079) Grad: 18088.7480  LR: 0.000780  \n",
      "Epoch: [2][1500/2851] Elapsed 9m 22s (remain 8m 26s) Loss: 0.0014(0.0079) Grad: 4891.8115  LR: 0.000772  \n",
      "Epoch: [2][1600/2851] Elapsed 9m 59s (remain 7m 48s) Loss: 0.0006(0.0079) Grad: 1572.8691  LR: 0.000764  \n",
      "Epoch: [2][1700/2851] Elapsed 10m 38s (remain 7m 11s) Loss: 0.0002(0.0079) Grad: 1498.3137  LR: 0.000756  \n",
      "Epoch: [2][1800/2851] Elapsed 11m 16s (remain 6m 34s) Loss: 0.0106(0.0077) Grad: 8723.8457  LR: 0.000748  \n",
      "Epoch: [2][1900/2851] Elapsed 11m 53s (remain 5m 56s) Loss: 0.0008(0.0077) Grad: 6242.0103  LR: 0.000741  \n",
      "Epoch: [2][2000/2851] Elapsed 12m 30s (remain 5m 18s) Loss: 0.0022(0.0077) Grad: 5427.9473  LR: 0.000733  \n",
      "Epoch: [2][2100/2851] Elapsed 13m 8s (remain 4m 41s) Loss: 0.0168(0.0076) Grad: 32924.9531  LR: 0.000725  \n",
      "Epoch: [2][2200/2851] Elapsed 13m 47s (remain 4m 4s) Loss: 0.0184(0.0076) Grad: 57081.6641  LR: 0.000717  \n",
      "Epoch: [2][2300/2851] Elapsed 14m 24s (remain 3m 26s) Loss: 0.0002(0.0077) Grad: 2371.0132  LR: 0.000710  \n",
      "Epoch: [2][2400/2851] Elapsed 15m 1s (remain 2m 48s) Loss: 0.0095(0.0076) Grad: 24843.8145  LR: 0.000702  \n",
      "Epoch: [2][2500/2851] Elapsed 15m 39s (remain 2m 11s) Loss: 0.0027(0.0077) Grad: 4742.6230  LR: 0.000694  \n",
      "Epoch: [2][2600/2851] Elapsed 16m 17s (remain 1m 33s) Loss: 0.0049(0.0077) Grad: 8772.3027  LR: 0.000686  \n",
      "Epoch: [2][2700/2851] Elapsed 16m 58s (remain 0m 56s) Loss: 0.0128(0.0077) Grad: 84257.2266  LR: 0.000678  \n",
      "Epoch: [2][2800/2851] Elapsed 17m 38s (remain 0m 18s) Loss: 0.0034(0.0077) Grad: 10292.6328  LR: 0.000671  \n",
      "Epoch: [2][2850/2851] Elapsed 17m 57s (remain 0m 0s) Loss: 0.0010(0.0077) Grad: 8345.2100  LR: 0.000667  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 57s) Loss: 0.0014(0.0014) \n",
      "EVAL: [100/724] Elapsed 0m 22s (remain 2m 17s) Loss: 0.0016(0.0073) \n",
      "EVAL: [200/724] Elapsed 0m 44s (remain 1m 54s) Loss: 0.0000(0.0092) \n",
      "EVAL: [300/724] Elapsed 1m 5s (remain 1m 31s) Loss: 0.0001(0.0088) \n",
      "EVAL: [400/724] Elapsed 1m 26s (remain 1m 9s) Loss: 0.0000(0.0088) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0098(0.0100) \n",
      "EVAL: [600/724] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0012(0.0097) \n",
      "EVAL: [700/724] Elapsed 2m 29s (remain 0m 4s) Loss: 0.0000(0.0089) \n",
      "EVAL: [723/724] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0000(0.0088) \n",
      "Epoch 2 - avg_train_loss: 0.0077  avg_val_loss: 0.0088  time: 1236s\n",
      "Epoch 2 - Score: 0.8647\n",
      "Epoch 2 - Save Best Score: 0.8647 Model\n",
      "Epoch: [3][0/2851] Elapsed 0m 0s (remain 30m 28s) Loss: 0.0023(0.0023) Grad: 7567.2383  LR: 0.000667  \n",
      "Epoch: [3][100/2851] Elapsed 0m 37s (remain 17m 3s) Loss: 0.0001(0.0049) Grad: 596.0781  LR: 0.000659  \n",
      "Epoch: [3][200/2851] Elapsed 1m 14s (remain 16m 22s) Loss: 0.0001(0.0058) Grad: 690.0190  LR: 0.000651  \n",
      "Epoch: [3][300/2851] Elapsed 1m 51s (remain 15m 41s) Loss: 0.0009(0.0062) Grad: 11768.5293  LR: 0.000643  \n",
      "Epoch: [3][400/2851] Elapsed 2m 28s (remain 15m 5s) Loss: 0.0000(0.0060) Grad: 208.5788  LR: 0.000635  \n",
      "Epoch: [3][500/2851] Elapsed 3m 5s (remain 14m 29s) Loss: 0.0001(0.0062) Grad: 665.1020  LR: 0.000628  \n",
      "Epoch: [3][600/2851] Elapsed 3m 43s (remain 13m 57s) Loss: 0.0326(0.0065) Grad: 51112.8555  LR: 0.000620  \n",
      "Epoch: [3][700/2851] Elapsed 4m 21s (remain 13m 21s) Loss: 0.0110(0.0066) Grad: 51695.4766  LR: 0.000612  \n",
      "Epoch: [3][800/2851] Elapsed 4m 59s (remain 12m 45s) Loss: 0.0090(0.0067) Grad: 17435.5254  LR: 0.000604  \n",
      "Epoch: [3][900/2851] Elapsed 5m 36s (remain 12m 9s) Loss: 0.0135(0.0065) Grad: 34382.9688  LR: 0.000596  \n",
      "Epoch: [3][1000/2851] Elapsed 6m 15s (remain 11m 33s) Loss: 0.0004(0.0066) Grad: 947.8394  LR: 0.000589  \n",
      "Epoch: [3][1100/2851] Elapsed 6m 52s (remain 10m 55s) Loss: 0.0033(0.0065) Grad: 12956.5840  LR: 0.000581  \n",
      "Epoch: [3][1200/2851] Elapsed 7m 29s (remain 10m 16s) Loss: 0.0000(0.0067) Grad: 257.0795  LR: 0.000573  \n",
      "Epoch: [3][1300/2851] Elapsed 8m 6s (remain 9m 39s) Loss: 0.0001(0.0066) Grad: 251.2084  LR: 0.000565  \n",
      "Epoch: [3][1400/2851] Elapsed 8m 44s (remain 9m 2s) Loss: 0.0173(0.0066) Grad: 20287.8086  LR: 0.000557  \n",
      "Epoch: [3][1500/2851] Elapsed 9m 21s (remain 8m 25s) Loss: 0.0001(0.0068) Grad: 761.7894  LR: 0.000550  \n",
      "Epoch: [3][1600/2851] Elapsed 9m 58s (remain 7m 47s) Loss: 0.0107(0.0066) Grad: 21471.0410  LR: 0.000542  \n",
      "Epoch: [3][1700/2851] Elapsed 10m 35s (remain 7m 9s) Loss: 0.0000(0.0066) Grad: 317.3181  LR: 0.000534  \n",
      "Epoch: [3][1800/2851] Elapsed 11m 12s (remain 6m 32s) Loss: 0.0004(0.0066) Grad: 1332.6532  LR: 0.000526  \n",
      "Epoch: [3][1900/2851] Elapsed 11m 51s (remain 5m 55s) Loss: 0.0014(0.0066) Grad: 6469.1689  LR: 0.000518  \n",
      "Epoch: [3][2000/2851] Elapsed 12m 29s (remain 5m 18s) Loss: 0.0000(0.0065) Grad: 153.6065  LR: 0.000511  \n",
      "Epoch: [3][2100/2851] Elapsed 13m 6s (remain 4m 40s) Loss: 0.0027(0.0064) Grad: 17668.3730  LR: 0.000503  \n",
      "Epoch: [3][2200/2851] Elapsed 13m 43s (remain 4m 3s) Loss: 0.0003(0.0064) Grad: 3519.9316  LR: 0.000495  \n",
      "Epoch: [3][2300/2851] Elapsed 14m 20s (remain 3m 25s) Loss: 0.0082(0.0065) Grad: 14430.3945  LR: 0.000487  \n",
      "Epoch: [3][2400/2851] Elapsed 14m 59s (remain 2m 48s) Loss: 0.0318(0.0064) Grad: 28419.9805  LR: 0.000480  \n",
      "Epoch: [3][2500/2851] Elapsed 15m 40s (remain 2m 11s) Loss: 0.0006(0.0064) Grad: 2328.4639  LR: 0.000472  \n",
      "Epoch: [3][2600/2851] Elapsed 16m 18s (remain 1m 34s) Loss: 0.0027(0.0065) Grad: 12576.4111  LR: 0.000464  \n",
      "Epoch: [3][2700/2851] Elapsed 16m 55s (remain 0m 56s) Loss: 0.0007(0.0064) Grad: 6334.4497  LR: 0.000456  \n",
      "Epoch: [3][2800/2851] Elapsed 17m 32s (remain 0m 18s) Loss: 0.0015(0.0064) Grad: 4886.1729  LR: 0.000448  \n",
      "Epoch: [3][2850/2851] Elapsed 17m 51s (remain 0m 0s) Loss: 0.0007(0.0064) Grad: 6587.9624  LR: 0.000444  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 50s) Loss: 0.0009(0.0009) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 13s) Loss: 0.0015(0.0062) \n",
      "EVAL: [200/724] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0000(0.0086) \n",
      "EVAL: [300/724] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0002(0.0083) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0000(0.0083) \n",
      "EVAL: [500/724] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0154(0.0098) \n",
      "EVAL: [600/724] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0004(0.0095) \n",
      "EVAL: [700/724] Elapsed 2m 28s (remain 0m 4s) Loss: 0.0000(0.0086) \n",
      "EVAL: [723/724] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0000(0.0085) \n",
      "Epoch 3 - avg_train_loss: 0.0064  avg_val_loss: 0.0085  time: 1229s\n",
      "Epoch 3 - Score: 0.8840\n",
      "Epoch 3 - Save Best Score: 0.8840 Model\n",
      "Epoch: [4][0/2851] Elapsed 0m 0s (remain 29m 49s) Loss: 0.0071(0.0071) Grad: 13690.0312  LR: 0.000444  \n",
      "Epoch: [4][100/2851] Elapsed 0m 38s (remain 17m 38s) Loss: 0.0003(0.0048) Grad: 1163.5471  LR: 0.000437  \n",
      "Epoch: [4][200/2851] Elapsed 1m 17s (remain 17m 8s) Loss: 0.0001(0.0047) Grad: 667.5539  LR: 0.000429  \n",
      "Epoch: [4][300/2851] Elapsed 1m 54s (remain 16m 13s) Loss: 0.0017(0.0047) Grad: 9282.0088  LR: 0.000421  \n",
      "Epoch: [4][400/2851] Elapsed 2m 32s (remain 15m 31s) Loss: 0.0000(0.0046) Grad: 269.5249  LR: 0.000413  \n",
      "Epoch: [4][500/2851] Elapsed 3m 10s (remain 14m 51s) Loss: 0.0007(0.0046) Grad: 4899.0068  LR: 0.000405  \n",
      "Epoch: [4][600/2851] Elapsed 3m 47s (remain 14m 12s) Loss: 0.0179(0.0050) Grad: 96830.3047  LR: 0.000398  \n",
      "Epoch: [4][700/2851] Elapsed 4m 24s (remain 13m 32s) Loss: 0.0017(0.0052) Grad: 6451.5308  LR: 0.000390  \n",
      "Epoch: [4][800/2851] Elapsed 5m 1s (remain 12m 52s) Loss: 0.0011(0.0054) Grad: 4063.5520  LR: 0.000382  \n",
      "Epoch: [4][900/2851] Elapsed 5m 38s (remain 12m 13s) Loss: 0.0006(0.0057) Grad: 4589.1025  LR: 0.000374  \n",
      "Epoch: [4][1000/2851] Elapsed 6m 16s (remain 11m 34s) Loss: 0.0134(0.0058) Grad: 23685.7051  LR: 0.000366  \n",
      "Epoch: [4][1100/2851] Elapsed 6m 54s (remain 10m 58s) Loss: 0.0003(0.0057) Grad: 1466.7330  LR: 0.000359  \n",
      "Epoch: [4][1200/2851] Elapsed 7m 32s (remain 10m 21s) Loss: 0.0012(0.0058) Grad: 2874.5432  LR: 0.000351  \n",
      "Epoch: [4][1300/2851] Elapsed 8m 9s (remain 9m 42s) Loss: 0.0000(0.0057) Grad: 174.6161  LR: 0.000343  \n",
      "Epoch: [4][1400/2851] Elapsed 8m 46s (remain 9m 4s) Loss: 0.0007(0.0059) Grad: 3510.3572  LR: 0.000335  \n",
      "Epoch: [4][1500/2851] Elapsed 9m 23s (remain 8m 27s) Loss: 0.0008(0.0058) Grad: 4202.8794  LR: 0.000327  \n",
      "Epoch: [4][1600/2851] Elapsed 10m 1s (remain 7m 49s) Loss: 0.0105(0.0058) Grad: 79681.1250  LR: 0.000320  \n",
      "Epoch: [4][1700/2851] Elapsed 10m 38s (remain 7m 11s) Loss: 0.0001(0.0059) Grad: 505.3960  LR: 0.000312  \n",
      "Epoch: [4][1800/2851] Elapsed 11m 15s (remain 6m 33s) Loss: 0.0000(0.0059) Grad: 265.7665  LR: 0.000304  \n",
      "Epoch: [4][1900/2851] Elapsed 11m 53s (remain 5m 56s) Loss: 0.0014(0.0058) Grad: 6258.5527  LR: 0.000296  \n",
      "Epoch: [4][2000/2851] Elapsed 12m 30s (remain 5m 18s) Loss: 0.0159(0.0058) Grad: 24749.6543  LR: 0.000288  \n",
      "Epoch: [4][2100/2851] Elapsed 13m 7s (remain 4m 41s) Loss: 0.0311(0.0058) Grad: 178583.6875  LR: 0.000281  \n",
      "Epoch: [4][2200/2851] Elapsed 13m 43s (remain 4m 3s) Loss: 0.0164(0.0057) Grad: 28922.5430  LR: 0.000273  \n",
      "Epoch: [4][2300/2851] Elapsed 14m 21s (remain 3m 25s) Loss: 0.0017(0.0057) Grad: 6228.7324  LR: 0.000265  \n",
      "Epoch: [4][2400/2851] Elapsed 15m 0s (remain 2m 48s) Loss: 0.0035(0.0058) Grad: 8744.8574  LR: 0.000257  \n",
      "Epoch: [4][2500/2851] Elapsed 15m 37s (remain 2m 11s) Loss: 0.0001(0.0057) Grad: 807.7210  LR: 0.000249  \n",
      "Epoch: [4][2600/2851] Elapsed 16m 14s (remain 1m 33s) Loss: 0.0000(0.0057) Grad: 281.4597  LR: 0.000242  \n",
      "Epoch: [4][2700/2851] Elapsed 16m 51s (remain 0m 56s) Loss: 0.0000(0.0057) Grad: 204.0205  LR: 0.000234  \n",
      "Epoch: [4][2800/2851] Elapsed 17m 28s (remain 0m 18s) Loss: 0.0024(0.0056) Grad: 14533.9648  LR: 0.000226  \n",
      "Epoch: [4][2850/2851] Elapsed 17m 47s (remain 0m 0s) Loss: 0.0105(0.0056) Grad: 17673.7656  LR: 0.000222  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 26s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0010(0.0072) \n",
      "EVAL: [200/724] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0000(0.0091) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0001(0.0090) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 8s) Loss: 0.0000(0.0089) \n",
      "EVAL: [500/724] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0148(0.0107) \n",
      "EVAL: [600/724] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0005(0.0102) \n",
      "EVAL: [700/724] Elapsed 2m 28s (remain 0m 4s) Loss: 0.0000(0.0093) \n",
      "EVAL: [723/724] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0000(0.0092) \n",
      "Epoch 4 - avg_train_loss: 0.0056  avg_val_loss: 0.0092  time: 1225s\n",
      "Epoch 4 - Score: 0.8873\n",
      "Epoch 4 - Save Best Score: 0.8873 Model\n",
      "Epoch: [5][0/2851] Elapsed 0m 0s (remain 31m 54s) Loss: 0.0000(0.0000) Grad: 1042.0563  LR: 0.000222  \n",
      "Epoch: [5][100/2851] Elapsed 0m 38s (remain 17m 31s) Loss: 0.0304(0.0053) Grad: 101182.9844  LR: 0.000214  \n",
      "Epoch: [5][200/2851] Elapsed 1m 16s (remain 16m 42s) Loss: 0.0151(0.0050) Grad: 11964.9209  LR: 0.000207  \n",
      "Epoch: [5][300/2851] Elapsed 1m 52s (remain 15m 56s) Loss: 0.0001(0.0052) Grad: 794.5215  LR: 0.000199  \n",
      "Epoch: [5][400/2851] Elapsed 2m 29s (remain 15m 13s) Loss: 0.0001(0.0054) Grad: 864.2329  LR: 0.000191  \n",
      "Epoch: [5][500/2851] Elapsed 3m 5s (remain 14m 32s) Loss: 0.0042(0.0051) Grad: 11367.8779  LR: 0.000183  \n",
      "Epoch: [5][600/2851] Elapsed 3m 44s (remain 14m 0s) Loss: 0.0003(0.0050) Grad: 6318.6440  LR: 0.000175  \n",
      "Epoch: [5][700/2851] Elapsed 4m 23s (remain 13m 27s) Loss: 0.0087(0.0049) Grad: 17643.5879  LR: 0.000168  \n",
      "Epoch: [5][800/2851] Elapsed 5m 0s (remain 12m 48s) Loss: 0.0011(0.0048) Grad: 4186.6489  LR: 0.000160  \n",
      "Epoch: [5][900/2851] Elapsed 5m 36s (remain 12m 9s) Loss: 0.0066(0.0047) Grad: 20175.4238  LR: 0.000152  \n",
      "Epoch: [5][1000/2851] Elapsed 6m 13s (remain 11m 31s) Loss: 0.0008(0.0048) Grad: 3015.4888  LR: 0.000144  \n",
      "Epoch: [5][1100/2851] Elapsed 6m 50s (remain 10m 52s) Loss: 0.0030(0.0046) Grad: 18331.1094  LR: 0.000136  \n",
      "Epoch: [5][1200/2851] Elapsed 7m 28s (remain 10m 15s) Loss: 0.0022(0.0049) Grad: 11405.5234  LR: 0.000129  \n",
      "Epoch: [5][1300/2851] Elapsed 8m 7s (remain 9m 40s) Loss: 0.0092(0.0049) Grad: 24704.9258  LR: 0.000121  \n",
      "Epoch: [5][1400/2851] Elapsed 8m 45s (remain 9m 4s) Loss: 0.0028(0.0049) Grad: 10462.8828  LR: 0.000113  \n",
      "Epoch: [5][1500/2851] Elapsed 9m 22s (remain 8m 26s) Loss: 0.0008(0.0048) Grad: 4209.4639  LR: 0.000105  \n",
      "Epoch: [5][1600/2851] Elapsed 9m 59s (remain 7m 48s) Loss: 0.0133(0.0047) Grad: 27563.5957  LR: 0.000097  \n",
      "Epoch: [5][1700/2851] Elapsed 10m 39s (remain 7m 12s) Loss: 0.0032(0.0046) Grad: 4209.1987  LR: 0.000090  \n",
      "Epoch: [5][1800/2851] Elapsed 11m 17s (remain 6m 34s) Loss: 0.0070(0.0046) Grad: 14504.2285  LR: 0.000082  \n",
      "Epoch: [5][1900/2851] Elapsed 11m 54s (remain 5m 56s) Loss: 0.0014(0.0046) Grad: 5815.5308  LR: 0.000074  \n",
      "Epoch: [5][2000/2851] Elapsed 12m 30s (remain 5m 18s) Loss: 0.0282(0.0046) Grad: 66960.4062  LR: 0.000066  \n",
      "Epoch: [5][2100/2851] Elapsed 13m 7s (remain 4m 41s) Loss: 0.0018(0.0046) Grad: 10698.1807  LR: 0.000058  \n",
      "Epoch: [5][2200/2851] Elapsed 13m 44s (remain 4m 3s) Loss: 0.0000(0.0046) Grad: 184.5681  LR: 0.000051  \n",
      "Epoch: [5][2300/2851] Elapsed 14m 21s (remain 3m 25s) Loss: 0.0000(0.0046) Grad: 239.8802  LR: 0.000043  \n",
      "Epoch: [5][2400/2851] Elapsed 14m 58s (remain 2m 48s) Loss: 0.0001(0.0046) Grad: 441.0627  LR: 0.000035  \n",
      "Epoch: [5][2500/2851] Elapsed 15m 35s (remain 2m 10s) Loss: 0.0003(0.0047) Grad: 1841.5282  LR: 0.000027  \n",
      "Epoch: [5][2600/2851] Elapsed 16m 12s (remain 1m 33s) Loss: 0.0299(0.0048) Grad: 81162.7969  LR: 0.000019  \n",
      "Epoch: [5][2700/2851] Elapsed 16m 54s (remain 0m 56s) Loss: 0.0001(0.0048) Grad: 900.1326  LR: 0.000012  \n",
      "Epoch: [5][2800/2851] Elapsed 17m 31s (remain 0m 18s) Loss: 0.0008(0.0048) Grad: 4308.3550  LR: 0.000004  \n",
      "Epoch: [5][2850/2851] Elapsed 17m 49s (remain 0m 0s) Loss: 0.0020(0.0048) Grad: 7474.8071  LR: 0.000000  \n",
      "EVAL: [0/724] Elapsed 0m 0s (remain 5m 19s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/724] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0015(0.0071) \n",
      "EVAL: [200/724] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0000(0.0092) \n",
      "EVAL: [300/724] Elapsed 1m 4s (remain 1m 31s) Loss: 0.0001(0.0091) \n",
      "EVAL: [400/724] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0000(0.0091) \n",
      "EVAL: [500/724] Elapsed 1m 47s (remain 0m 47s) Loss: 0.0156(0.0109) \n",
      "EVAL: [600/724] Elapsed 2m 9s (remain 0m 26s) Loss: 0.0001(0.0104) \n",
      "EVAL: [700/724] Elapsed 2m 29s (remain 0m 4s) Loss: 0.0000(0.0095) \n",
      "EVAL: [723/724] Elapsed 2m 34s (remain 0m 0s) Loss: 0.0000(0.0094) \n",
      "Epoch 5 - avg_train_loss: 0.0048  avg_val_loss: 0.0094  time: 1229s\n",
      "Epoch 5 - Score: 0.8868\n",
      "========== fold: 2 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2871] Elapsed 0m 0s (remain 28m 31s) Loss: 0.6513(0.6513) Grad: inf  LR: 0.000001  \n",
      "Epoch: [1][100/2871] Elapsed 0m 37s (remain 17m 8s) Loss: 0.1545(0.3562) Grad: 17809.6953  LR: 0.000070  \n",
      "Epoch: [1][200/2871] Elapsed 1m 17s (remain 17m 4s) Loss: 0.0876(0.2445) Grad: 1758.9948  LR: 0.000140  \n",
      "Epoch: [1][300/2871] Elapsed 1m 58s (remain 16m 48s) Loss: 0.0213(0.1775) Grad: 1214.4255  LR: 0.000210  \n",
      "Epoch: [1][400/2871] Elapsed 2m 37s (remain 16m 9s) Loss: 0.0470(0.1430) Grad: 1504.0466  LR: 0.000279  \n",
      "Epoch: [1][500/2871] Elapsed 3m 14s (remain 15m 18s) Loss: 0.0334(0.1221) Grad: 862.8417  LR: 0.000349  \n",
      "Epoch: [1][600/2871] Elapsed 3m 52s (remain 14m 36s) Loss: 0.0285(0.1083) Grad: 871.8826  LR: 0.000419  \n",
      "Epoch: [1][700/2871] Elapsed 4m 29s (remain 13m 54s) Loss: 0.0463(0.0982) Grad: 1523.3510  LR: 0.000489  \n",
      "Epoch: [1][800/2871] Elapsed 5m 6s (remain 13m 12s) Loss: 0.0294(0.0901) Grad: 2336.5679  LR: 0.000558  \n",
      "Epoch: [1][900/2871] Elapsed 5m 43s (remain 12m 31s) Loss: 0.0389(0.0825) Grad: 6108.4785  LR: 0.000628  \n",
      "Epoch: [1][1000/2871] Elapsed 6m 20s (remain 11m 51s) Loss: 0.0132(0.0762) Grad: 3191.9141  LR: 0.000698  \n",
      "Epoch: [1][1100/2871] Elapsed 7m 0s (remain 11m 16s) Loss: 0.0128(0.0706) Grad: 2984.0193  LR: 0.000767  \n",
      "Epoch: [1][1200/2871] Elapsed 7m 40s (remain 10m 40s) Loss: 0.0313(0.0661) Grad: 7345.4253  LR: 0.000837  \n",
      "Epoch: [1][1300/2871] Elapsed 8m 17s (remain 10m 0s) Loss: 0.0188(0.0620) Grad: 6064.8311  LR: 0.000907  \n",
      "Epoch: [1][1400/2871] Elapsed 8m 56s (remain 9m 22s) Loss: 0.0279(0.0585) Grad: 5674.8281  LR: 0.000976  \n",
      "Epoch: [1][1500/2871] Elapsed 9m 36s (remain 8m 46s) Loss: 0.0233(0.0555) Grad: 4784.2593  LR: 0.000995  \n",
      "Epoch: [1][1600/2871] Elapsed 10m 17s (remain 8m 9s) Loss: 0.0179(0.0529) Grad: 4532.3599  LR: 0.000987  \n",
      "Epoch: [1][1700/2871] Elapsed 10m 58s (remain 7m 32s) Loss: 0.0101(0.0506) Grad: 3192.0867  LR: 0.000979  \n",
      "Epoch: [1][1800/2871] Elapsed 11m 38s (remain 6m 54s) Loss: 0.0042(0.0486) Grad: 942.6350  LR: 0.000972  \n",
      "Epoch: [1][1900/2871] Elapsed 12m 18s (remain 6m 17s) Loss: 0.0164(0.0466) Grad: 2878.4517  LR: 0.000964  \n",
      "Epoch: [1][2000/2871] Elapsed 12m 59s (remain 5m 39s) Loss: 0.0006(0.0447) Grad: 328.9692  LR: 0.000956  \n",
      "Epoch: [1][2100/2871] Elapsed 13m 40s (remain 5m 0s) Loss: 0.0091(0.0430) Grad: 2011.1376  LR: 0.000948  \n",
      "Epoch: [1][2200/2871] Elapsed 14m 20s (remain 4m 21s) Loss: 0.0453(0.0415) Grad: 5734.8999  LR: 0.000941  \n",
      "Epoch: [1][2300/2871] Elapsed 15m 1s (remain 3m 43s) Loss: 0.0238(0.0402) Grad: 1943.4825  LR: 0.000933  \n",
      "Epoch: [1][2400/2871] Elapsed 15m 39s (remain 3m 3s) Loss: 0.0148(0.0390) Grad: 3047.5261  LR: 0.000925  \n",
      "Epoch: [1][2500/2871] Elapsed 16m 19s (remain 2m 24s) Loss: 0.0046(0.0378) Grad: 1074.6155  LR: 0.000917  \n",
      "Epoch: [1][2600/2871] Elapsed 16m 58s (remain 1m 45s) Loss: 0.0130(0.0367) Grad: 2189.0586  LR: 0.000910  \n",
      "Epoch: [1][2700/2871] Elapsed 17m 38s (remain 1m 6s) Loss: 0.0014(0.0356) Grad: 701.2996  LR: 0.000902  \n",
      "Epoch: [1][2800/2871] Elapsed 18m 18s (remain 0m 27s) Loss: 0.0058(0.0346) Grad: 1833.5996  LR: 0.000894  \n",
      "Epoch: [1][2870/2871] Elapsed 18m 44s (remain 0m 0s) Loss: 0.0044(0.0340) Grad: 1436.7131  LR: 0.000889  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 5s) Loss: 0.0030(0.0030) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0138(0.0128) \n",
      "EVAL: [200/704] Elapsed 0m 42s (remain 1m 46s) Loss: 0.0001(0.0108) \n",
      "EVAL: [300/704] Elapsed 1m 3s (remain 1m 24s) Loss: 0.0011(0.0099) \n",
      "EVAL: [400/704] Elapsed 1m 24s (remain 1m 3s) Loss: 0.0116(0.0110) \n",
      "EVAL: [500/704] Elapsed 1m 45s (remain 0m 42s) Loss: 0.0316(0.0120) \n",
      "EVAL: [600/704] Elapsed 2m 7s (remain 0m 21s) Loss: 0.0004(0.0122) \n",
      "EVAL: [700/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0003(0.0115) \n",
      "EVAL: [703/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0001(0.0115) \n",
      "Epoch 1 - avg_train_loss: 0.0340  avg_val_loss: 0.0115  time: 1278s\n",
      "Epoch 1 - Score: 0.8267\n",
      "Epoch 1 - Save Best Score: 0.8267 Model\n",
      "Epoch: [2][0/2871] Elapsed 0m 0s (remain 29m 32s) Loss: 0.0135(0.0135) Grad: 10837.4502  LR: 0.000889  \n",
      "Epoch: [2][100/2871] Elapsed 0m 38s (remain 17m 28s) Loss: 0.0205(0.0100) Grad: 17627.1895  LR: 0.000881  \n",
      "Epoch: [2][200/2871] Elapsed 1m 17s (remain 17m 8s) Loss: 0.0074(0.0091) Grad: 19427.1484  LR: 0.000873  \n",
      "Epoch: [2][300/2871] Elapsed 1m 54s (remain 16m 19s) Loss: 0.0008(0.0084) Grad: 2922.4526  LR: 0.000866  \n",
      "Epoch: [2][400/2871] Elapsed 2m 31s (remain 15m 35s) Loss: 0.0079(0.0084) Grad: 10228.3535  LR: 0.000858  \n",
      "Epoch: [2][500/2871] Elapsed 3m 9s (remain 14m 54s) Loss: 0.0067(0.0079) Grad: 10780.3203  LR: 0.000850  \n",
      "Epoch: [2][600/2871] Elapsed 3m 47s (remain 14m 18s) Loss: 0.0001(0.0078) Grad: 432.9888  LR: 0.000842  \n",
      "Epoch: [2][700/2871] Elapsed 4m 24s (remain 13m 38s) Loss: 0.0003(0.0080) Grad: 1652.5023  LR: 0.000835  \n",
      "Epoch: [2][800/2871] Elapsed 5m 1s (remain 12m 58s) Loss: 0.0022(0.0079) Grad: 7377.7637  LR: 0.000827  \n",
      "Epoch: [2][900/2871] Elapsed 5m 38s (remain 12m 19s) Loss: 0.0002(0.0080) Grad: 593.1952  LR: 0.000819  \n",
      "Epoch: [2][1000/2871] Elapsed 6m 16s (remain 11m 42s) Loss: 0.0011(0.0079) Grad: 5252.9019  LR: 0.000811  \n",
      "Epoch: [2][1100/2871] Elapsed 6m 53s (remain 11m 4s) Loss: 0.0511(0.0079) Grad: 77971.2578  LR: 0.000804  \n",
      "Epoch: [2][1200/2871] Elapsed 7m 30s (remain 10m 26s) Loss: 0.0054(0.0079) Grad: 9006.6133  LR: 0.000796  \n",
      "Epoch: [2][1300/2871] Elapsed 8m 7s (remain 9m 48s) Loss: 0.0079(0.0078) Grad: 41992.0078  LR: 0.000788  \n",
      "Epoch: [2][1400/2871] Elapsed 8m 45s (remain 9m 11s) Loss: 0.0060(0.0077) Grad: 30893.0762  LR: 0.000780  \n",
      "Epoch: [2][1500/2871] Elapsed 9m 23s (remain 8m 34s) Loss: 0.0108(0.0079) Grad: 6484.6982  LR: 0.000773  \n",
      "Epoch: [2][1600/2871] Elapsed 10m 1s (remain 7m 56s) Loss: 0.0006(0.0078) Grad: 3476.1311  LR: 0.000765  \n",
      "Epoch: [2][1700/2871] Elapsed 10m 39s (remain 7m 20s) Loss: 0.0039(0.0078) Grad: 11754.6094  LR: 0.000757  \n",
      "Epoch: [2][1800/2871] Elapsed 11m 16s (remain 6m 42s) Loss: 0.0003(0.0078) Grad: 1066.3009  LR: 0.000749  \n",
      "Epoch: [2][1900/2871] Elapsed 11m 54s (remain 6m 4s) Loss: 0.0059(0.0079) Grad: 10658.1221  LR: 0.000742  \n",
      "Epoch: [2][2000/2871] Elapsed 12m 32s (remain 5m 27s) Loss: 0.0127(0.0078) Grad: 36493.7695  LR: 0.000734  \n",
      "Epoch: [2][2100/2871] Elapsed 13m 12s (remain 4m 50s) Loss: 0.0093(0.0077) Grad: 13108.6865  LR: 0.000726  \n",
      "Epoch: [2][2200/2871] Elapsed 13m 50s (remain 4m 12s) Loss: 0.0002(0.0077) Grad: 2835.5923  LR: 0.000718  \n",
      "Epoch: [2][2300/2871] Elapsed 14m 26s (remain 3m 34s) Loss: 0.0023(0.0078) Grad: 6775.5825  LR: 0.000711  \n",
      "Epoch: [2][2400/2871] Elapsed 15m 3s (remain 2m 56s) Loss: 0.0188(0.0077) Grad: 113963.4688  LR: 0.000703  \n",
      "Epoch: [2][2500/2871] Elapsed 15m 41s (remain 2m 19s) Loss: 0.0149(0.0078) Grad: 39851.2070  LR: 0.000695  \n",
      "Epoch: [2][2600/2871] Elapsed 16m 20s (remain 1m 41s) Loss: 0.0003(0.0077) Grad: 1805.4575  LR: 0.000688  \n",
      "Epoch: [2][2700/2871] Elapsed 16m 58s (remain 1m 4s) Loss: 0.0011(0.0077) Grad: 6258.6143  LR: 0.000680  \n",
      "Epoch: [2][2800/2871] Elapsed 17m 35s (remain 0m 26s) Loss: 0.0025(0.0077) Grad: 5442.3999  LR: 0.000672  \n",
      "Epoch: [2][2870/2871] Elapsed 18m 0s (remain 0m 0s) Loss: 0.0000(0.0077) Grad: 221.4962  LR: 0.000667  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 24s) Loss: 0.0012(0.0012) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0121(0.0089) \n",
      "EVAL: [200/704] Elapsed 0m 42s (remain 1m 46s) Loss: 0.0000(0.0088) \n",
      "EVAL: [300/704] Elapsed 1m 3s (remain 1m 24s) Loss: 0.0001(0.0082) \n",
      "EVAL: [400/704] Elapsed 1m 24s (remain 1m 3s) Loss: 0.0048(0.0090) \n",
      "EVAL: [500/704] Elapsed 1m 45s (remain 0m 42s) Loss: 0.0109(0.0096) \n",
      "EVAL: [600/704] Elapsed 2m 6s (remain 0m 21s) Loss: 0.0000(0.0101) \n",
      "EVAL: [700/704] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0000(0.0096) \n",
      "EVAL: [703/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0096) \n",
      "Epoch 2 - avg_train_loss: 0.0077  avg_val_loss: 0.0096  time: 1234s\n",
      "Epoch 2 - Score: 0.8595\n",
      "Epoch 2 - Save Best Score: 0.8595 Model\n",
      "Epoch: [3][0/2871] Elapsed 0m 0s (remain 29m 27s) Loss: 0.0067(0.0067) Grad: 16252.4932  LR: 0.000667  \n",
      "Epoch: [3][100/2871] Elapsed 0m 37s (remain 17m 14s) Loss: 0.0103(0.0080) Grad: 20085.1094  LR: 0.000659  \n",
      "Epoch: [3][200/2871] Elapsed 1m 15s (remain 16m 38s) Loss: 0.0032(0.0078) Grad: 5316.6118  LR: 0.000651  \n",
      "Epoch: [3][300/2871] Elapsed 1m 52s (remain 15m 56s) Loss: 0.0003(0.0071) Grad: 1383.5188  LR: 0.000643  \n",
      "Epoch: [3][400/2871] Elapsed 2m 28s (remain 15m 16s) Loss: 0.0000(0.0068) Grad: 268.6870  LR: 0.000636  \n",
      "Epoch: [3][500/2871] Elapsed 3m 5s (remain 14m 37s) Loss: 0.0436(0.0071) Grad: 53910.2500  LR: 0.000628  \n",
      "Epoch: [3][600/2871] Elapsed 3m 42s (remain 14m 1s) Loss: 0.0058(0.0069) Grad: 10035.8896  LR: 0.000620  \n",
      "Epoch: [3][700/2871] Elapsed 4m 20s (remain 13m 26s) Loss: 0.0009(0.0070) Grad: 4958.9150  LR: 0.000612  \n",
      "Epoch: [3][800/2871] Elapsed 5m 1s (remain 13m 0s) Loss: 0.0138(0.0067) Grad: 45567.9258  LR: 0.000605  \n",
      "Epoch: [3][900/2871] Elapsed 5m 39s (remain 12m 23s) Loss: 0.0225(0.0067) Grad: 58802.5391  LR: 0.000597  \n",
      "Epoch: [3][1000/2871] Elapsed 6m 16s (remain 11m 42s) Loss: 0.0003(0.0066) Grad: 1052.4121  LR: 0.000589  \n",
      "Epoch: [3][1100/2871] Elapsed 6m 52s (remain 11m 3s) Loss: 0.0014(0.0067) Grad: 8058.6851  LR: 0.000581  \n",
      "Epoch: [3][1200/2871] Elapsed 7m 30s (remain 10m 26s) Loss: 0.0012(0.0067) Grad: 5890.0547  LR: 0.000574  \n",
      "Epoch: [3][1300/2871] Elapsed 8m 8s (remain 9m 49s) Loss: 0.0443(0.0068) Grad: 32072.2324  LR: 0.000566  \n",
      "Epoch: [3][1400/2871] Elapsed 8m 45s (remain 9m 11s) Loss: 0.0003(0.0069) Grad: 2309.7500  LR: 0.000558  \n",
      "Epoch: [3][1500/2871] Elapsed 9m 22s (remain 8m 33s) Loss: 0.0042(0.0068) Grad: 8116.1284  LR: 0.000550  \n",
      "Epoch: [3][1600/2871] Elapsed 9m 59s (remain 7m 55s) Loss: 0.0067(0.0068) Grad: 11222.5967  LR: 0.000543  \n",
      "Epoch: [3][1700/2871] Elapsed 10m 37s (remain 7m 18s) Loss: 0.0001(0.0069) Grad: 541.9387  LR: 0.000535  \n",
      "Epoch: [3][1800/2871] Elapsed 11m 15s (remain 6m 41s) Loss: 0.0032(0.0069) Grad: 8340.7588  LR: 0.000527  \n",
      "Epoch: [3][1900/2871] Elapsed 11m 52s (remain 6m 3s) Loss: 0.0001(0.0068) Grad: 465.1261  LR: 0.000520  \n",
      "Epoch: [3][2000/2871] Elapsed 12m 29s (remain 5m 25s) Loss: 0.0001(0.0068) Grad: 508.2864  LR: 0.000512  \n",
      "Epoch: [3][2100/2871] Elapsed 13m 10s (remain 4m 49s) Loss: 0.0004(0.0068) Grad: 2308.3142  LR: 0.000504  \n",
      "Epoch: [3][2200/2871] Elapsed 13m 49s (remain 4m 12s) Loss: 0.0050(0.0068) Grad: 10848.3486  LR: 0.000496  \n",
      "Epoch: [3][2300/2871] Elapsed 14m 27s (remain 3m 34s) Loss: 0.0029(0.0069) Grad: 11131.4795  LR: 0.000489  \n",
      "Epoch: [3][2400/2871] Elapsed 15m 4s (remain 2m 56s) Loss: 0.0061(0.0069) Grad: 16652.9258  LR: 0.000481  \n",
      "Epoch: [3][2500/2871] Elapsed 15m 41s (remain 2m 19s) Loss: 0.0009(0.0069) Grad: 3928.6865  LR: 0.000473  \n",
      "Epoch: [3][2600/2871] Elapsed 16m 17s (remain 1m 41s) Loss: 0.0011(0.0068) Grad: 4584.9150  LR: 0.000465  \n",
      "Epoch: [3][2700/2871] Elapsed 16m 54s (remain 1m 3s) Loss: 0.0041(0.0068) Grad: 17119.5332  LR: 0.000458  \n",
      "Epoch: [3][2800/2871] Elapsed 17m 32s (remain 0m 26s) Loss: 0.0001(0.0068) Grad: 373.6613  LR: 0.000450  \n",
      "Epoch: [3][2870/2871] Elapsed 17m 58s (remain 0m 0s) Loss: 0.0082(0.0068) Grad: 17522.0469  LR: 0.000444  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 25s) Loss: 0.0008(0.0008) \n",
      "EVAL: [100/704] Elapsed 0m 22s (remain 2m 12s) Loss: 0.0120(0.0083) \n",
      "EVAL: [200/704] Elapsed 0m 43s (remain 1m 48s) Loss: 0.0000(0.0081) \n",
      "EVAL: [300/704] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0005(0.0075) \n",
      "EVAL: [400/704] Elapsed 1m 24s (remain 1m 4s) Loss: 0.0063(0.0084) \n",
      "EVAL: [500/704] Elapsed 1m 46s (remain 0m 42s) Loss: 0.0081(0.0093) \n",
      "EVAL: [600/704] Elapsed 2m 7s (remain 0m 21s) Loss: 0.0001(0.0093) \n",
      "EVAL: [700/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0088) \n",
      "EVAL: [703/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0088) \n",
      "Epoch 3 - avg_train_loss: 0.0068  avg_val_loss: 0.0088  time: 1232s\n",
      "Epoch 3 - Score: 0.8646\n",
      "Epoch 3 - Save Best Score: 0.8646 Model\n",
      "Epoch: [4][0/2871] Elapsed 0m 0s (remain 32m 3s) Loss: 0.0216(0.0216) Grad: 50195.5820  LR: 0.000444  \n",
      "Epoch: [4][100/2871] Elapsed 0m 42s (remain 19m 29s) Loss: 0.0000(0.0069) Grad: 236.5648  LR: 0.000437  \n",
      "Epoch: [4][200/2871] Elapsed 1m 20s (remain 17m 49s) Loss: 0.0042(0.0070) Grad: 8894.7012  LR: 0.000429  \n",
      "Epoch: [4][300/2871] Elapsed 1m 57s (remain 16m 40s) Loss: 0.0005(0.0064) Grad: 1656.3623  LR: 0.000421  \n",
      "Epoch: [4][400/2871] Elapsed 2m 33s (remain 15m 47s) Loss: 0.0029(0.0060) Grad: 9942.0996  LR: 0.000413  \n",
      "Epoch: [4][500/2871] Elapsed 3m 10s (remain 15m 3s) Loss: 0.0001(0.0060) Grad: 741.0226  LR: 0.000406  \n",
      "Epoch: [4][600/2871] Elapsed 3m 48s (remain 14m 22s) Loss: 0.0032(0.0059) Grad: 8860.2930  LR: 0.000398  \n",
      "Epoch: [4][700/2871] Elapsed 4m 29s (remain 13m 53s) Loss: 0.0032(0.0062) Grad: 27977.0137  LR: 0.000390  \n",
      "Epoch: [4][800/2871] Elapsed 5m 6s (remain 13m 11s) Loss: 0.0030(0.0060) Grad: 6174.9067  LR: 0.000382  \n",
      "Epoch: [4][900/2871] Elapsed 5m 43s (remain 12m 30s) Loss: 0.0000(0.0060) Grad: 170.7459  LR: 0.000375  \n",
      "Epoch: [4][1000/2871] Elapsed 6m 20s (remain 11m 50s) Loss: 0.0034(0.0061) Grad: 4074.0486  LR: 0.000367  \n",
      "Epoch: [4][1100/2871] Elapsed 6m 57s (remain 11m 11s) Loss: 0.0000(0.0060) Grad: 220.2149  LR: 0.000359  \n",
      "Epoch: [4][1200/2871] Elapsed 7m 34s (remain 10m 31s) Loss: 0.0001(0.0059) Grad: 1058.9320  LR: 0.000351  \n",
      "Epoch: [4][1300/2871] Elapsed 8m 13s (remain 9m 55s) Loss: 0.0001(0.0059) Grad: 398.5092  LR: 0.000344  \n",
      "Epoch: [4][1400/2871] Elapsed 8m 51s (remain 9m 17s) Loss: 0.0008(0.0058) Grad: 2654.0730  LR: 0.000336  \n",
      "Epoch: [4][1500/2871] Elapsed 9m 28s (remain 8m 38s) Loss: 0.0000(0.0059) Grad: 171.5939  LR: 0.000328  \n",
      "Epoch: [4][1600/2871] Elapsed 10m 5s (remain 8m 0s) Loss: 0.0056(0.0057) Grad: 22710.9746  LR: 0.000321  \n",
      "Epoch: [4][1700/2871] Elapsed 10m 43s (remain 7m 22s) Loss: 0.0002(0.0057) Grad: 1380.5404  LR: 0.000313  \n",
      "Epoch: [4][1800/2871] Elapsed 11m 22s (remain 6m 45s) Loss: 0.0001(0.0058) Grad: 380.5750  LR: 0.000305  \n",
      "Epoch: [4][1900/2871] Elapsed 12m 0s (remain 6m 7s) Loss: 0.0028(0.0058) Grad: 14204.5859  LR: 0.000297  \n",
      "Epoch: [4][2000/2871] Elapsed 12m 36s (remain 5m 28s) Loss: 0.0005(0.0057) Grad: 3177.2490  LR: 0.000290  \n",
      "Epoch: [4][2100/2871] Elapsed 13m 13s (remain 4m 50s) Loss: 0.0096(0.0057) Grad: 46950.7227  LR: 0.000282  \n",
      "Epoch: [4][2200/2871] Elapsed 13m 51s (remain 4m 13s) Loss: 0.0020(0.0057) Grad: 7120.8936  LR: 0.000274  \n",
      "Epoch: [4][2300/2871] Elapsed 14m 29s (remain 3m 35s) Loss: 0.0081(0.0056) Grad: 20663.9141  LR: 0.000266  \n",
      "Epoch: [4][2400/2871] Elapsed 15m 6s (remain 2m 57s) Loss: 0.0014(0.0057) Grad: 5855.6953  LR: 0.000259  \n",
      "Epoch: [4][2500/2871] Elapsed 15m 42s (remain 2m 19s) Loss: 0.0060(0.0057) Grad: 16441.7129  LR: 0.000251  \n",
      "Epoch: [4][2600/2871] Elapsed 16m 19s (remain 1m 41s) Loss: 0.0015(0.0057) Grad: 6067.9453  LR: 0.000243  \n",
      "Epoch: [4][2700/2871] Elapsed 16m 58s (remain 1m 4s) Loss: 0.0178(0.0057) Grad: 125642.9141  LR: 0.000235  \n",
      "Epoch: [4][2800/2871] Elapsed 17m 35s (remain 0m 26s) Loss: 0.0472(0.0057) Grad: 101388.8594  LR: 0.000228  \n",
      "Epoch: [4][2870/2871] Elapsed 18m 1s (remain 0m 0s) Loss: 0.0001(0.0057) Grad: 567.6637  LR: 0.000222  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 39s) Loss: 0.0009(0.0009) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0107(0.0083) \n",
      "EVAL: [200/704] Elapsed 0m 44s (remain 1m 50s) Loss: 0.0000(0.0084) \n",
      "EVAL: [300/704] Elapsed 1m 5s (remain 1m 27s) Loss: 0.0001(0.0079) \n",
      "EVAL: [400/704] Elapsed 1m 26s (remain 1m 5s) Loss: 0.0088(0.0088) \n",
      "EVAL: [500/704] Elapsed 1m 47s (remain 0m 43s) Loss: 0.0107(0.0097) \n",
      "EVAL: [600/704] Elapsed 2m 8s (remain 0m 22s) Loss: 0.0000(0.0099) \n",
      "EVAL: [700/704] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0094) \n",
      "EVAL: [703/704] Elapsed 2m 30s (remain 0m 0s) Loss: 0.0000(0.0094) \n",
      "Epoch 4 - avg_train_loss: 0.0057  avg_val_loss: 0.0094  time: 1237s\n",
      "Epoch 4 - Score: 0.8707\n",
      "Epoch 4 - Save Best Score: 0.8707 Model\n",
      "Epoch: [5][0/2871] Elapsed 0m 0s (remain 29m 30s) Loss: 0.0000(0.0000) Grad: 637.2665  LR: 0.000222  \n",
      "Epoch: [5][100/2871] Elapsed 0m 37s (remain 17m 9s) Loss: 0.0000(0.0041) Grad: 275.4798  LR: 0.000214  \n",
      "Epoch: [5][200/2871] Elapsed 1m 14s (remain 16m 30s) Loss: 0.0001(0.0044) Grad: 685.9692  LR: 0.000207  \n",
      "Epoch: [5][300/2871] Elapsed 1m 52s (remain 16m 1s) Loss: 0.0019(0.0043) Grad: 6100.2051  LR: 0.000199  \n",
      "Epoch: [5][400/2871] Elapsed 2m 30s (remain 15m 24s) Loss: 0.0034(0.0047) Grad: 13993.1992  LR: 0.000191  \n",
      "Epoch: [5][500/2871] Elapsed 3m 7s (remain 14m 44s) Loss: 0.0000(0.0047) Grad: 300.1738  LR: 0.000183  \n",
      "Epoch: [5][600/2871] Elapsed 3m 44s (remain 14m 7s) Loss: 0.0002(0.0047) Grad: 1663.3097  LR: 0.000176  \n",
      "Epoch: [5][700/2871] Elapsed 4m 22s (remain 13m 31s) Loss: 0.0000(0.0049) Grad: 181.4748  LR: 0.000168  \n",
      "Epoch: [5][800/2871] Elapsed 5m 0s (remain 12m 56s) Loss: 0.0002(0.0051) Grad: 4015.3416  LR: 0.000160  \n",
      "Epoch: [5][900/2871] Elapsed 5m 39s (remain 12m 22s) Loss: 0.0004(0.0050) Grad: 1558.7438  LR: 0.000152  \n",
      "Epoch: [5][1000/2871] Elapsed 6m 16s (remain 11m 43s) Loss: 0.0120(0.0053) Grad: 44952.2969  LR: 0.000145  \n",
      "Epoch: [5][1100/2871] Elapsed 6m 53s (remain 11m 4s) Loss: 0.0000(0.0053) Grad: 203.4720  LR: 0.000137  \n",
      "Epoch: [5][1200/2871] Elapsed 7m 31s (remain 10m 28s) Loss: 0.0013(0.0054) Grad: 3741.0376  LR: 0.000129  \n",
      "Epoch: [5][1300/2871] Elapsed 8m 10s (remain 9m 51s) Loss: 0.0006(0.0054) Grad: 3455.5117  LR: 0.000122  \n",
      "Epoch: [5][1400/2871] Elapsed 8m 46s (remain 9m 12s) Loss: 0.0000(0.0053) Grad: 343.2091  LR: 0.000114  \n",
      "Epoch: [5][1500/2871] Elapsed 9m 23s (remain 8m 34s) Loss: 0.0003(0.0053) Grad: 1647.4926  LR: 0.000106  \n",
      "Epoch: [5][1600/2871] Elapsed 10m 1s (remain 7m 56s) Loss: 0.0000(0.0053) Grad: 180.7442  LR: 0.000098  \n",
      "Epoch: [5][1700/2871] Elapsed 10m 38s (remain 7m 19s) Loss: 0.0005(0.0053) Grad: 3853.0217  LR: 0.000091  \n",
      "Epoch: [5][1800/2871] Elapsed 11m 19s (remain 6m 43s) Loss: 0.0005(0.0052) Grad: 3408.2971  LR: 0.000083  \n",
      "Epoch: [5][1900/2871] Elapsed 11m 56s (remain 6m 5s) Loss: 0.0008(0.0052) Grad: 7217.3423  LR: 0.000075  \n",
      "Epoch: [5][2000/2871] Elapsed 12m 33s (remain 5m 27s) Loss: 0.0151(0.0053) Grad: 60730.7227  LR: 0.000067  \n",
      "Epoch: [5][2100/2871] Elapsed 13m 10s (remain 4m 49s) Loss: 0.0074(0.0053) Grad: 23763.8398  LR: 0.000060  \n",
      "Epoch: [5][2200/2871] Elapsed 13m 48s (remain 4m 12s) Loss: 0.0067(0.0052) Grad: 12407.8730  LR: 0.000052  \n",
      "Epoch: [5][2300/2871] Elapsed 14m 27s (remain 3m 34s) Loss: 0.0000(0.0052) Grad: 176.3929  LR: 0.000044  \n",
      "Epoch: [5][2400/2871] Elapsed 15m 4s (remain 2m 57s) Loss: 0.0000(0.0051) Grad: 304.4269  LR: 0.000036  \n",
      "Epoch: [5][2500/2871] Elapsed 15m 41s (remain 2m 19s) Loss: 0.0001(0.0052) Grad: 599.7568  LR: 0.000029  \n",
      "Epoch: [5][2600/2871] Elapsed 16m 17s (remain 1m 41s) Loss: 0.0000(0.0052) Grad: 251.6271  LR: 0.000021  \n",
      "Epoch: [5][2700/2871] Elapsed 16m 54s (remain 1m 3s) Loss: 0.0000(0.0052) Grad: 534.3949  LR: 0.000013  \n",
      "Epoch: [5][2800/2871] Elapsed 17m 30s (remain 0m 26s) Loss: 0.0003(0.0051) Grad: 1566.8157  LR: 0.000005  \n",
      "Epoch: [5][2870/2871] Elapsed 17m 57s (remain 0m 0s) Loss: 0.0071(0.0051) Grad: 17856.8945  LR: 0.000000  \n",
      "EVAL: [0/704] Elapsed 0m 0s (remain 5m 20s) Loss: 0.0007(0.0007) \n",
      "EVAL: [100/704] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0085(0.0083) \n",
      "EVAL: [200/704] Elapsed 0m 42s (remain 1m 46s) Loss: 0.0000(0.0083) \n",
      "EVAL: [300/704] Elapsed 1m 3s (remain 1m 25s) Loss: 0.0002(0.0080) \n",
      "EVAL: [400/704] Elapsed 1m 24s (remain 1m 4s) Loss: 0.0078(0.0090) \n",
      "EVAL: [500/704] Elapsed 1m 45s (remain 0m 42s) Loss: 0.0107(0.0100) \n",
      "EVAL: [600/704] Elapsed 2m 7s (remain 0m 21s) Loss: 0.0000(0.0101) \n",
      "EVAL: [700/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0096) \n",
      "EVAL: [703/704] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0000(0.0096) \n",
      "Epoch 5 - avg_train_loss: 0.0051  avg_val_loss: 0.0096  time: 1231s\n",
      "Epoch 5 - Score: 0.8698\n",
      "========== fold: 3 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2877] Elapsed 0m 0s (remain 29m 10s) Loss: 0.6141(0.6141) Grad: inf  LR: 0.000001  \n",
      "Epoch: [1][100/2877] Elapsed 0m 38s (remain 17m 30s) Loss: 0.2152(0.5390) Grad: 12103.6270  LR: 0.000070  \n",
      "Epoch: [1][200/2877] Elapsed 1m 15s (remain 16m 42s) Loss: 0.0476(0.3572) Grad: 2242.3279  LR: 0.000140  \n",
      "Epoch: [1][300/2877] Elapsed 1m 51s (remain 15m 55s) Loss: 0.0622(0.2534) Grad: 927.0192  LR: 0.000209  \n",
      "Epoch: [1][400/2877] Elapsed 2m 28s (remain 15m 19s) Loss: 0.0420(0.2000) Grad: 512.3597  LR: 0.000279  \n",
      "Epoch: [1][500/2877] Elapsed 3m 6s (remain 14m 46s) Loss: 0.0391(0.1684) Grad: 563.1499  LR: 0.000348  \n",
      "Epoch: [1][600/2877] Elapsed 3m 43s (remain 14m 6s) Loss: 0.0371(0.1465) Grad: 644.6830  LR: 0.000418  \n",
      "Epoch: [1][700/2877] Elapsed 4m 19s (remain 13m 25s) Loss: 0.0401(0.1306) Grad: 756.8322  LR: 0.000487  \n",
      "Epoch: [1][800/2877] Elapsed 4m 56s (remain 12m 47s) Loss: 0.0285(0.1183) Grad: 1045.3202  LR: 0.000557  \n",
      "Epoch: [1][900/2877] Elapsed 5m 33s (remain 12m 12s) Loss: 0.0034(0.1078) Grad: 422.1658  LR: 0.000627  \n",
      "Epoch: [1][1000/2877] Elapsed 6m 13s (remain 11m 39s) Loss: 0.0104(0.0992) Grad: 1443.4856  LR: 0.000696  \n",
      "Epoch: [1][1100/2877] Elapsed 6m 51s (remain 11m 3s) Loss: 0.0482(0.0917) Grad: 2901.1887  LR: 0.000766  \n",
      "Epoch: [1][1200/2877] Elapsed 7m 27s (remain 10m 24s) Loss: 0.0154(0.0854) Grad: 1829.4064  LR: 0.000835  \n",
      "Epoch: [1][1300/2877] Elapsed 8m 4s (remain 9m 46s) Loss: 0.0076(0.0798) Grad: 896.0224  LR: 0.000905  \n",
      "Epoch: [1][1400/2877] Elapsed 8m 41s (remain 9m 9s) Loss: 0.0066(0.0750) Grad: 1116.6846  LR: 0.000974  \n",
      "Epoch: [1][1500/2877] Elapsed 9m 18s (remain 8m 32s) Loss: 0.0144(0.0709) Grad: 1417.6873  LR: 0.000995  \n",
      "Epoch: [1][1600/2877] Elapsed 9m 58s (remain 7m 56s) Loss: 0.0144(0.0674) Grad: 2312.4885  LR: 0.000987  \n",
      "Epoch: [1][1700/2877] Elapsed 10m 35s (remain 7m 19s) Loss: 0.0132(0.0639) Grad: 1480.9373  LR: 0.000980  \n",
      "Epoch: [1][1800/2877] Elapsed 11m 12s (remain 6m 41s) Loss: 0.0026(0.0610) Grad: 281.7443  LR: 0.000972  \n",
      "Epoch: [1][1900/2877] Elapsed 11m 48s (remain 6m 3s) Loss: 0.0102(0.0584) Grad: 987.3256  LR: 0.000964  \n",
      "Epoch: [1][2000/2877] Elapsed 12m 24s (remain 5m 26s) Loss: 0.0073(0.0559) Grad: 795.0854  LR: 0.000957  \n",
      "Epoch: [1][2100/2877] Elapsed 13m 1s (remain 4m 48s) Loss: 0.0025(0.0537) Grad: 300.9691  LR: 0.000949  \n",
      "Epoch: [1][2200/2877] Elapsed 13m 37s (remain 4m 11s) Loss: 0.0035(0.0516) Grad: 461.8380  LR: 0.000941  \n",
      "Epoch: [1][2300/2877] Elapsed 14m 13s (remain 3m 33s) Loss: 0.0110(0.0498) Grad: 544.0777  LR: 0.000933  \n",
      "Epoch: [1][2400/2877] Elapsed 14m 49s (remain 2m 56s) Loss: 0.0033(0.0481) Grad: 719.3980  LR: 0.000926  \n",
      "Epoch: [1][2500/2877] Elapsed 15m 26s (remain 2m 19s) Loss: 0.0034(0.0465) Grad: 563.4301  LR: 0.000918  \n",
      "Epoch: [1][2600/2877] Elapsed 16m 4s (remain 1m 42s) Loss: 0.0009(0.0450) Grad: 312.1343  LR: 0.000910  \n",
      "Epoch: [1][2700/2877] Elapsed 16m 40s (remain 1m 5s) Loss: 0.0010(0.0437) Grad: 417.8051  LR: 0.000902  \n",
      "Epoch: [1][2800/2877] Elapsed 17m 18s (remain 0m 28s) Loss: 0.0004(0.0424) Grad: 295.1047  LR: 0.000895  \n",
      "Epoch: [1][2876/2877] Elapsed 17m 46s (remain 0m 0s) Loss: 0.0185(0.0415) Grad: 2556.1509  LR: 0.000889  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 34s) Loss: 0.0032(0.0032) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0021(0.0057) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 46s) Loss: 0.0059(0.0074) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 24s) Loss: 0.0021(0.0070) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0183(0.0078) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0112(0.0079) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0079(0.0075) \n",
      "EVAL: [697/698] Elapsed 2m 28s (remain 0m 0s) Loss: 0.0003(0.0074) \n",
      "Epoch 1 - avg_train_loss: 0.0415  avg_val_loss: 0.0074  time: 1220s\n",
      "Epoch 1 - Score: 0.8437\n",
      "Epoch 1 - Save Best Score: 0.8437 Model\n",
      "Epoch: [2][0/2877] Elapsed 0m 0s (remain 30m 34s) Loss: 0.0045(0.0045) Grad: 5668.6753  LR: 0.000889  \n",
      "Epoch: [2][100/2877] Elapsed 0m 37s (remain 17m 15s) Loss: 0.0056(0.0079) Grad: 19026.7383  LR: 0.000881  \n",
      "Epoch: [2][200/2877] Elapsed 1m 15s (remain 16m 43s) Loss: 0.0041(0.0070) Grad: 12797.1553  LR: 0.000873  \n",
      "Epoch: [2][300/2877] Elapsed 1m 53s (remain 16m 15s) Loss: 0.0425(0.0067) Grad: 33014.5820  LR: 0.000866  \n",
      "Epoch: [2][400/2877] Elapsed 2m 31s (remain 15m 33s) Loss: 0.0034(0.0065) Grad: 6705.9028  LR: 0.000858  \n",
      "Epoch: [2][500/2877] Elapsed 3m 8s (remain 14m 53s) Loss: 0.0028(0.0063) Grad: 6243.5229  LR: 0.000850  \n",
      "Epoch: [2][600/2877] Elapsed 3m 47s (remain 14m 21s) Loss: 0.0044(0.0066) Grad: 15395.7539  LR: 0.000842  \n",
      "Epoch: [2][700/2877] Elapsed 4m 28s (remain 13m 53s) Loss: 0.0083(0.0068) Grad: 14857.4316  LR: 0.000835  \n",
      "Epoch: [2][800/2877] Elapsed 5m 5s (remain 13m 11s) Loss: 0.0075(0.0069) Grad: 16285.3311  LR: 0.000827  \n",
      "Epoch: [2][900/2877] Elapsed 5m 42s (remain 12m 31s) Loss: 0.0043(0.0069) Grad: 13969.7637  LR: 0.000819  \n",
      "Epoch: [2][1000/2877] Elapsed 6m 19s (remain 11m 50s) Loss: 0.0065(0.0070) Grad: 13098.2305  LR: 0.000812  \n",
      "Epoch: [2][1100/2877] Elapsed 6m 56s (remain 11m 11s) Loss: 0.0015(0.0071) Grad: 5582.9795  LR: 0.000804  \n",
      "Epoch: [2][1200/2877] Elapsed 7m 33s (remain 10m 32s) Loss: 0.0000(0.0070) Grad: 283.7778  LR: 0.000796  \n",
      "Epoch: [2][1300/2877] Elapsed 8m 10s (remain 9m 54s) Loss: 0.0087(0.0070) Grad: 15633.8223  LR: 0.000788  \n",
      "Epoch: [2][1400/2877] Elapsed 8m 50s (remain 9m 19s) Loss: 0.0349(0.0071) Grad: 63743.6484  LR: 0.000781  \n",
      "Epoch: [2][1500/2877] Elapsed 9m 29s (remain 8m 41s) Loss: 0.0020(0.0071) Grad: 10727.3877  LR: 0.000773  \n",
      "Epoch: [2][1600/2877] Elapsed 10m 6s (remain 8m 3s) Loss: 0.0011(0.0071) Grad: 3165.5181  LR: 0.000765  \n",
      "Epoch: [2][1700/2877] Elapsed 10m 43s (remain 7m 24s) Loss: 0.0002(0.0070) Grad: 621.2542  LR: 0.000757  \n",
      "Epoch: [2][1800/2877] Elapsed 11m 19s (remain 6m 46s) Loss: 0.0156(0.0071) Grad: 29055.9082  LR: 0.000750  \n",
      "Epoch: [2][1900/2877] Elapsed 11m 57s (remain 6m 8s) Loss: 0.0035(0.0071) Grad: 7973.2988  LR: 0.000742  \n",
      "Epoch: [2][2000/2877] Elapsed 12m 34s (remain 5m 30s) Loss: 0.0311(0.0073) Grad: 22851.1660  LR: 0.000734  \n",
      "Epoch: [2][2100/2877] Elapsed 13m 13s (remain 4m 53s) Loss: 0.0026(0.0073) Grad: 7121.7007  LR: 0.000727  \n",
      "Epoch: [2][2200/2877] Elapsed 13m 50s (remain 4m 14s) Loss: 0.0026(0.0072) Grad: 4695.6143  LR: 0.000719  \n",
      "Epoch: [2][2300/2877] Elapsed 14m 26s (remain 3m 37s) Loss: 0.0140(0.0072) Grad: 25885.6855  LR: 0.000711  \n",
      "Epoch: [2][2400/2877] Elapsed 15m 3s (remain 2m 59s) Loss: 0.0071(0.0072) Grad: 41026.5234  LR: 0.000703  \n",
      "Epoch: [2][2500/2877] Elapsed 15m 42s (remain 2m 21s) Loss: 0.0001(0.0072) Grad: 436.3152  LR: 0.000696  \n",
      "Epoch: [2][2600/2877] Elapsed 16m 22s (remain 1m 44s) Loss: 0.0021(0.0072) Grad: 6131.9106  LR: 0.000688  \n",
      "Epoch: [2][2700/2877] Elapsed 17m 0s (remain 1m 6s) Loss: 0.0004(0.0072) Grad: 1549.3214  LR: 0.000680  \n",
      "Epoch: [2][2800/2877] Elapsed 17m 37s (remain 0m 28s) Loss: 0.0070(0.0073) Grad: 11562.2490  LR: 0.000673  \n",
      "Epoch: [2][2876/2877] Elapsed 18m 5s (remain 0m 0s) Loss: 0.0002(0.0073) Grad: 547.8155  LR: 0.000667  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 32s) Loss: 0.0015(0.0015) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 7s) Loss: 0.0005(0.0056) \n",
      "EVAL: [200/698] Elapsed 0m 42s (remain 1m 45s) Loss: 0.0089(0.0077) \n",
      "EVAL: [300/698] Elapsed 1m 3s (remain 1m 23s) Loss: 0.0013(0.0073) \n",
      "EVAL: [400/698] Elapsed 1m 24s (remain 1m 2s) Loss: 0.0289(0.0082) \n",
      "EVAL: [500/698] Elapsed 1m 45s (remain 0m 41s) Loss: 0.0072(0.0083) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0068(0.0078) \n",
      "EVAL: [697/698] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0076) \n",
      "Epoch 2 - avg_train_loss: 0.0073  avg_val_loss: 0.0076  time: 1239s\n",
      "Epoch 2 - Score: 0.8724\n",
      "Epoch 2 - Save Best Score: 0.8724 Model\n",
      "Epoch: [3][0/2877] Elapsed 0m 0s (remain 30m 31s) Loss: 0.0004(0.0004) Grad: 1619.2590  LR: 0.000667  \n",
      "Epoch: [3][100/2877] Elapsed 0m 38s (remain 17m 44s) Loss: 0.0092(0.0043) Grad: 17318.0605  LR: 0.000659  \n",
      "Epoch: [3][200/2877] Elapsed 1m 16s (remain 17m 2s) Loss: 0.0079(0.0059) Grad: 18652.9219  LR: 0.000651  \n",
      "Epoch: [3][300/2877] Elapsed 1m 53s (remain 16m 15s) Loss: 0.0028(0.0057) Grad: 12964.9785  LR: 0.000643  \n",
      "Epoch: [3][400/2877] Elapsed 2m 32s (remain 15m 44s) Loss: 0.0085(0.0056) Grad: 13559.7041  LR: 0.000636  \n",
      "Epoch: [3][500/2877] Elapsed 3m 10s (remain 15m 3s) Loss: 0.0005(0.0057) Grad: 3323.4409  LR: 0.000628  \n",
      "Epoch: [3][600/2877] Elapsed 3m 47s (remain 14m 20s) Loss: 0.0000(0.0056) Grad: 187.3960  LR: 0.000620  \n",
      "Epoch: [3][700/2877] Elapsed 4m 24s (remain 13m 40s) Loss: 0.0117(0.0059) Grad: 89330.1484  LR: 0.000612  \n",
      "Epoch: [3][800/2877] Elapsed 5m 1s (remain 13m 0s) Loss: 0.0052(0.0060) Grad: 11545.7959  LR: 0.000605  \n",
      "Epoch: [3][900/2877] Elapsed 5m 38s (remain 12m 21s) Loss: 0.0046(0.0067) Grad: 10666.6816  LR: 0.000597  \n",
      "Epoch: [3][1000/2877] Elapsed 6m 17s (remain 11m 48s) Loss: 0.0064(0.0068) Grad: 11656.1650  LR: 0.000589  \n",
      "Epoch: [3][1100/2877] Elapsed 6m 55s (remain 11m 9s) Loss: 0.0163(0.0068) Grad: 13507.3389  LR: 0.000582  \n",
      "Epoch: [3][1200/2877] Elapsed 7m 32s (remain 10m 31s) Loss: 0.0005(0.0068) Grad: 2844.5239  LR: 0.000574  \n",
      "Epoch: [3][1300/2877] Elapsed 8m 9s (remain 9m 52s) Loss: 0.0010(0.0068) Grad: 3246.4326  LR: 0.000566  \n",
      "Epoch: [3][1400/2877] Elapsed 8m 46s (remain 9m 15s) Loss: 0.0000(0.0068) Grad: 285.5359  LR: 0.000558  \n",
      "Epoch: [3][1500/2877] Elapsed 9m 24s (remain 8m 37s) Loss: 0.0000(0.0068) Grad: 216.3030  LR: 0.000551  \n",
      "Epoch: [3][1600/2877] Elapsed 10m 1s (remain 7m 59s) Loss: 0.0021(0.0068) Grad: 5630.4746  LR: 0.000543  \n",
      "Epoch: [3][1700/2877] Elapsed 10m 38s (remain 7m 21s) Loss: 0.0112(0.0069) Grad: 47601.0898  LR: 0.000535  \n",
      "Epoch: [3][1800/2877] Elapsed 11m 15s (remain 6m 43s) Loss: 0.0055(0.0068) Grad: 12985.5615  LR: 0.000528  \n",
      "Epoch: [3][1900/2877] Elapsed 11m 52s (remain 6m 5s) Loss: 0.0114(0.0067) Grad: 19508.9141  LR: 0.000520  \n",
      "Epoch: [3][2000/2877] Elapsed 12m 30s (remain 5m 28s) Loss: 0.0138(0.0066) Grad: 12483.2666  LR: 0.000512  \n",
      "Epoch: [3][2100/2877] Elapsed 13m 7s (remain 4m 50s) Loss: 0.0000(0.0066) Grad: 221.3922  LR: 0.000504  \n",
      "Epoch: [3][2200/2877] Elapsed 13m 44s (remain 4m 13s) Loss: 0.0020(0.0066) Grad: 6469.3760  LR: 0.000497  \n",
      "Epoch: [3][2300/2877] Elapsed 14m 21s (remain 3m 35s) Loss: 0.0265(0.0066) Grad: 50211.9922  LR: 0.000489  \n",
      "Epoch: [3][2400/2877] Elapsed 14m 58s (remain 2m 58s) Loss: 0.0010(0.0066) Grad: 3479.0452  LR: 0.000481  \n",
      "Epoch: [3][2500/2877] Elapsed 15m 35s (remain 2m 20s) Loss: 0.0008(0.0065) Grad: 4651.1040  LR: 0.000473  \n",
      "Epoch: [3][2600/2877] Elapsed 16m 14s (remain 1m 43s) Loss: 0.0002(0.0065) Grad: 626.6561  LR: 0.000466  \n",
      "Epoch: [3][2700/2877] Elapsed 16m 51s (remain 1m 5s) Loss: 0.0013(0.0064) Grad: 13461.9619  LR: 0.000458  \n",
      "Epoch: [3][2800/2877] Elapsed 17m 28s (remain 0m 28s) Loss: 0.0049(0.0064) Grad: 9876.7373  LR: 0.000450  \n",
      "Epoch: [3][2876/2877] Elapsed 17m 56s (remain 0m 0s) Loss: 0.0035(0.0064) Grad: 14325.3877  LR: 0.000444  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 29s) Loss: 0.0011(0.0011) \n",
      "EVAL: [100/698] Elapsed 0m 22s (remain 2m 10s) Loss: 0.0005(0.0068) \n",
      "EVAL: [200/698] Elapsed 0m 43s (remain 1m 47s) Loss: 0.0280(0.0097) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0002(0.0095) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0302(0.0100) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 42s) Loss: 0.0086(0.0099) \n",
      "EVAL: [600/698] Elapsed 2m 8s (remain 0m 20s) Loss: 0.0034(0.0092) \n",
      "EVAL: [697/698] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0090) \n",
      "Epoch 3 - avg_train_loss: 0.0064  avg_val_loss: 0.0090  time: 1230s\n",
      "Epoch 3 - Score: 0.8825\n",
      "Epoch 3 - Save Best Score: 0.8825 Model\n",
      "Epoch: [4][0/2877] Elapsed 0m 0s (remain 29m 1s) Loss: 0.0003(0.0003) Grad: 1662.1676  LR: 0.000444  \n",
      "Epoch: [4][100/2877] Elapsed 0m 37s (remain 17m 11s) Loss: 0.0000(0.0065) Grad: 199.7053  LR: 0.000437  \n",
      "Epoch: [4][200/2877] Elapsed 1m 14s (remain 16m 28s) Loss: 0.0001(0.0050) Grad: 305.0487  LR: 0.000429  \n",
      "Epoch: [4][300/2877] Elapsed 1m 54s (remain 16m 17s) Loss: 0.0072(0.0048) Grad: 13083.7119  LR: 0.000421  \n",
      "Epoch: [4][400/2877] Elapsed 2m 34s (remain 15m 51s) Loss: 0.0068(0.0053) Grad: 13964.8652  LR: 0.000413  \n",
      "Epoch: [4][500/2877] Elapsed 3m 11s (remain 15m 7s) Loss: 0.0182(0.0055) Grad: 30982.6973  LR: 0.000406  \n",
      "Epoch: [4][600/2877] Elapsed 3m 48s (remain 14m 25s) Loss: 0.0010(0.0054) Grad: 14854.4453  LR: 0.000398  \n",
      "Epoch: [4][700/2877] Elapsed 4m 25s (remain 13m 43s) Loss: 0.0007(0.0054) Grad: 3764.2808  LR: 0.000390  \n",
      "Epoch: [4][800/2877] Elapsed 5m 2s (remain 13m 5s) Loss: 0.0059(0.0054) Grad: 12847.6787  LR: 0.000383  \n",
      "Epoch: [4][900/2877] Elapsed 5m 40s (remain 12m 26s) Loss: 0.0089(0.0055) Grad: 13637.8018  LR: 0.000375  \n",
      "Epoch: [4][1000/2877] Elapsed 6m 17s (remain 11m 46s) Loss: 0.0000(0.0056) Grad: 200.2173  LR: 0.000367  \n",
      "Epoch: [4][1100/2877] Elapsed 6m 54s (remain 11m 7s) Loss: 0.0057(0.0056) Grad: 20621.1719  LR: 0.000359  \n",
      "Epoch: [4][1200/2877] Elapsed 7m 33s (remain 10m 33s) Loss: 0.0017(0.0057) Grad: 6704.6880  LR: 0.000352  \n",
      "Epoch: [4][1300/2877] Elapsed 8m 10s (remain 9m 54s) Loss: 0.0026(0.0057) Grad: 14966.9756  LR: 0.000344  \n",
      "Epoch: [4][1400/2877] Elapsed 8m 48s (remain 9m 16s) Loss: 0.0001(0.0057) Grad: 256.4507  LR: 0.000336  \n",
      "Epoch: [4][1500/2877] Elapsed 9m 26s (remain 8m 39s) Loss: 0.0002(0.0058) Grad: 1087.1259  LR: 0.000328  \n",
      "Epoch: [4][1600/2877] Elapsed 10m 4s (remain 8m 1s) Loss: 0.0002(0.0058) Grad: 740.5978  LR: 0.000321  \n",
      "Epoch: [4][1700/2877] Elapsed 10m 41s (remain 7m 23s) Loss: 0.0000(0.0057) Grad: 268.7826  LR: 0.000313  \n",
      "Epoch: [4][1800/2877] Elapsed 11m 18s (remain 6m 45s) Loss: 0.0021(0.0056) Grad: 47348.2969  LR: 0.000305  \n",
      "Epoch: [4][1900/2877] Elapsed 11m 55s (remain 6m 7s) Loss: 0.0002(0.0056) Grad: 1280.2013  LR: 0.000298  \n",
      "Epoch: [4][2000/2877] Elapsed 12m 31s (remain 5m 28s) Loss: 0.0004(0.0056) Grad: 2241.0376  LR: 0.000290  \n",
      "Epoch: [4][2100/2877] Elapsed 13m 7s (remain 4m 51s) Loss: 0.0001(0.0056) Grad: 537.8499  LR: 0.000282  \n",
      "Epoch: [4][2200/2877] Elapsed 13m 45s (remain 4m 13s) Loss: 0.0013(0.0055) Grad: 6120.1782  LR: 0.000274  \n",
      "Epoch: [4][2300/2877] Elapsed 14m 23s (remain 3m 36s) Loss: 0.0000(0.0055) Grad: 229.8327  LR: 0.000267  \n",
      "Epoch: [4][2400/2877] Elapsed 15m 3s (remain 2m 59s) Loss: 0.0005(0.0055) Grad: 2495.9312  LR: 0.000259  \n",
      "Epoch: [4][2500/2877] Elapsed 15m 44s (remain 2m 22s) Loss: 0.0024(0.0055) Grad: 16007.3154  LR: 0.000251  \n",
      "Epoch: [4][2600/2877] Elapsed 16m 25s (remain 1m 44s) Loss: 0.0057(0.0055) Grad: 16137.7705  LR: 0.000244  \n",
      "Epoch: [4][2700/2877] Elapsed 17m 3s (remain 1m 6s) Loss: 0.0048(0.0055) Grad: 15333.8926  LR: 0.000236  \n",
      "Epoch: [4][2800/2877] Elapsed 17m 40s (remain 0m 28s) Loss: 0.0001(0.0055) Grad: 371.7281  LR: 0.000228  \n",
      "Epoch: [4][2876/2877] Elapsed 18m 9s (remain 0m 0s) Loss: 0.0004(0.0055) Grad: 2439.7244  LR: 0.000222  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 21s) Loss: 0.0007(0.0007) \n",
      "EVAL: [100/698] Elapsed 0m 21s (remain 2m 9s) Loss: 0.0006(0.0065) \n",
      "EVAL: [200/698] Elapsed 0m 43s (remain 1m 48s) Loss: 0.0395(0.0094) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0018(0.0094) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0351(0.0098) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0036(0.0095) \n",
      "EVAL: [600/698] Elapsed 2m 8s (remain 0m 20s) Loss: 0.0083(0.0088) \n",
      "EVAL: [697/698] Elapsed 2m 29s (remain 0m 0s) Loss: 0.0000(0.0086) \n",
      "Epoch 4 - avg_train_loss: 0.0055  avg_val_loss: 0.0086  time: 1243s\n",
      "Epoch 4 - Score: 0.8857\n",
      "Epoch 4 - Save Best Score: 0.8857 Model\n",
      "Epoch: [5][0/2877] Elapsed 0m 0s (remain 30m 32s) Loss: 0.0001(0.0001) Grad: 1104.1659  LR: 0.000222  \n",
      "Epoch: [5][100/2877] Elapsed 0m 40s (remain 18m 21s) Loss: 0.0037(0.0039) Grad: 22295.8418  LR: 0.000214  \n",
      "Epoch: [5][200/2877] Elapsed 1m 20s (remain 17m 50s) Loss: 0.0020(0.0044) Grad: 8567.5342  LR: 0.000207  \n",
      "Epoch: [5][300/2877] Elapsed 1m 57s (remain 16m 45s) Loss: 0.0009(0.0041) Grad: 11138.7930  LR: 0.000199  \n",
      "Epoch: [5][400/2877] Elapsed 2m 34s (remain 15m 54s) Loss: 0.0019(0.0046) Grad: 7365.3120  LR: 0.000191  \n",
      "Epoch: [5][500/2877] Elapsed 3m 11s (remain 15m 8s) Loss: 0.0005(0.0046) Grad: 3029.2092  LR: 0.000184  \n",
      "Epoch: [5][600/2877] Elapsed 3m 48s (remain 14m 25s) Loss: 0.0002(0.0045) Grad: 4009.7983  LR: 0.000176  \n",
      "Epoch: [5][700/2877] Elapsed 4m 25s (remain 13m 45s) Loss: 0.0005(0.0045) Grad: 2582.9570  LR: 0.000168  \n",
      "Epoch: [5][800/2877] Elapsed 5m 3s (remain 13m 6s) Loss: 0.0006(0.0048) Grad: 4160.4937  LR: 0.000160  \n",
      "Epoch: [5][900/2877] Elapsed 5m 40s (remain 12m 26s) Loss: 0.0018(0.0050) Grad: 6268.8608  LR: 0.000153  \n",
      "Epoch: [5][1000/2877] Elapsed 6m 17s (remain 11m 47s) Loss: 0.0003(0.0051) Grad: 1162.2910  LR: 0.000145  \n",
      "Epoch: [5][1100/2877] Elapsed 6m 54s (remain 11m 8s) Loss: 0.0000(0.0050) Grad: 200.8891  LR: 0.000137  \n",
      "Epoch: [5][1200/2877] Elapsed 7m 31s (remain 10m 30s) Loss: 0.0080(0.0051) Grad: 34791.0664  LR: 0.000129  \n",
      "Epoch: [5][1300/2877] Elapsed 8m 9s (remain 9m 52s) Loss: 0.0004(0.0051) Grad: 2418.2786  LR: 0.000122  \n",
      "Epoch: [5][1400/2877] Elapsed 8m 46s (remain 9m 14s) Loss: 0.0086(0.0052) Grad: 10813.2275  LR: 0.000114  \n",
      "Epoch: [5][1500/2877] Elapsed 9m 23s (remain 8m 36s) Loss: 0.0001(0.0051) Grad: 779.1766  LR: 0.000106  \n",
      "Epoch: [5][1600/2877] Elapsed 10m 0s (remain 7m 58s) Loss: 0.0000(0.0050) Grad: 316.4740  LR: 0.000099  \n",
      "Epoch: [5][1700/2877] Elapsed 10m 38s (remain 7m 21s) Loss: 0.0006(0.0049) Grad: 1779.7075  LR: 0.000091  \n",
      "Epoch: [5][1800/2877] Elapsed 11m 15s (remain 6m 43s) Loss: 0.0045(0.0050) Grad: 6918.9111  LR: 0.000083  \n",
      "Epoch: [5][1900/2877] Elapsed 11m 53s (remain 6m 6s) Loss: 0.0010(0.0049) Grad: 5255.1436  LR: 0.000075  \n",
      "Epoch: [5][2000/2877] Elapsed 12m 30s (remain 5m 28s) Loss: 0.0034(0.0049) Grad: 13142.4912  LR: 0.000068  \n",
      "Epoch: [5][2100/2877] Elapsed 13m 7s (remain 4m 50s) Loss: 0.0001(0.0049) Grad: 836.6602  LR: 0.000060  \n",
      "Epoch: [5][2200/2877] Elapsed 13m 43s (remain 4m 13s) Loss: 0.0002(0.0049) Grad: 7167.3701  LR: 0.000052  \n",
      "Epoch: [5][2300/2877] Elapsed 14m 21s (remain 3m 35s) Loss: 0.0001(0.0049) Grad: 726.8089  LR: 0.000044  \n",
      "Epoch: [5][2400/2877] Elapsed 15m 1s (remain 2m 58s) Loss: 0.0002(0.0049) Grad: 1024.0338  LR: 0.000037  \n",
      "Epoch: [5][2500/2877] Elapsed 15m 38s (remain 2m 21s) Loss: 0.0004(0.0049) Grad: 2061.9780  LR: 0.000029  \n",
      "Epoch: [5][2600/2877] Elapsed 16m 15s (remain 1m 43s) Loss: 0.0000(0.0049) Grad: 273.1186  LR: 0.000021  \n",
      "Epoch: [5][2700/2877] Elapsed 16m 52s (remain 1m 5s) Loss: 0.0026(0.0049) Grad: 40847.0273  LR: 0.000014  \n",
      "Epoch: [5][2800/2877] Elapsed 17m 30s (remain 0m 28s) Loss: 0.0000(0.0049) Grad: 207.7024  LR: 0.000006  \n",
      "Epoch: [5][2876/2877] Elapsed 17m 59s (remain 0m 0s) Loss: 0.0063(0.0049) Grad: 12253.6973  LR: 0.000000  \n",
      "EVAL: [0/698] Elapsed 0m 0s (remain 5m 51s) Loss: 0.0004(0.0004) \n",
      "EVAL: [100/698] Elapsed 0m 22s (remain 2m 10s) Loss: 0.0002(0.0069) \n",
      "EVAL: [200/698] Elapsed 0m 43s (remain 1m 47s) Loss: 0.0361(0.0099) \n",
      "EVAL: [300/698] Elapsed 1m 4s (remain 1m 25s) Loss: 0.0012(0.0097) \n",
      "EVAL: [400/698] Elapsed 1m 25s (remain 1m 3s) Loss: 0.0307(0.0102) \n",
      "EVAL: [500/698] Elapsed 1m 46s (remain 0m 41s) Loss: 0.0037(0.0099) \n",
      "EVAL: [600/698] Elapsed 2m 7s (remain 0m 20s) Loss: 0.0084(0.0092) \n",
      "EVAL: [697/698] Elapsed 2m 27s (remain 0m 0s) Loss: 0.0000(0.0091) \n",
      "Epoch 5 - avg_train_loss: 0.0049  avg_val_loss: 0.0091  time: 1232s\n",
      "Epoch 5 - Score: 0.8843\n",
      "========== fold: 4 training ==========\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n",
      "Epoch: [1][0/2850] Elapsed 0m 0s (remain 29m 34s) Loss: 0.4362(0.4362) Grad: inf  LR: 0.000001  \n",
      "Epoch: [1][100/2850] Elapsed 0m 37s (remain 17m 5s) Loss: 0.4766(0.5814) Grad: 28610.1875  LR: 0.000071  \n",
      "Epoch: [1][200/2850] Elapsed 1m 15s (remain 16m 30s) Loss: 0.0481(0.3843) Grad: 2925.8635  LR: 0.000141  \n",
      "Epoch: [1][300/2850] Elapsed 1m 51s (remain 15m 44s) Loss: 0.0208(0.2716) Grad: 418.7640  LR: 0.000211  \n",
      "Epoch: [1][400/2850] Elapsed 2m 27s (remain 15m 2s) Loss: 0.0782(0.2153) Grad: 975.1729  LR: 0.000281  \n",
      "Epoch: [1][500/2850] Elapsed 3m 3s (remain 14m 22s) Loss: 0.0403(0.1800) Grad: 547.1851  LR: 0.000352  \n",
      "Epoch: [1][600/2850] Elapsed 3m 40s (remain 13m 43s) Loss: 0.0250(0.1565) Grad: 858.2490  LR: 0.000422  \n",
      "Epoch: [1][700/2850] Elapsed 4m 16s (remain 13m 7s) Loss: 0.0225(0.1392) Grad: 569.4272  LR: 0.000492  \n",
      "Epoch: [1][800/2850] Elapsed 4m 53s (remain 12m 32s) Loss: 0.0260(0.1258) Grad: 1173.0405  LR: 0.000562  \n",
      "Epoch: [1][900/2850] Elapsed 5m 30s (remain 11m 55s) Loss: 0.0180(0.1143) Grad: 2074.5623  LR: 0.000632  \n",
      "Epoch: [1][1000/2850] Elapsed 6m 7s (remain 11m 19s) Loss: 0.0172(0.1043) Grad: 1961.2106  LR: 0.000702  \n",
      "Epoch: [1][1100/2850] Elapsed 6m 45s (remain 10m 44s) Loss: 0.0055(0.0962) Grad: 1166.1367  LR: 0.000773  \n",
      "Epoch: [1][1200/2850] Elapsed 7m 22s (remain 10m 7s) Loss: 0.0029(0.0894) Grad: 535.7979  LR: 0.000843  \n",
      "Epoch: [1][1300/2850] Elapsed 7m 59s (remain 9m 30s) Loss: 0.0103(0.0836) Grad: 1822.8684  LR: 0.000913  \n",
      "Epoch: [1][1400/2850] Elapsed 8m 35s (remain 8m 53s) Loss: 0.0026(0.0787) Grad: 860.3726  LR: 0.000983  \n",
      "Epoch: [1][1500/2850] Elapsed 9m 12s (remain 8m 16s) Loss: 0.0145(0.0743) Grad: 7294.8047  LR: 0.000994  \n",
      "Epoch: [1][1600/2850] Elapsed 9m 51s (remain 7m 41s) Loss: 0.0061(0.0702) Grad: 617.5401  LR: 0.000986  \n",
      "Epoch: [1][1700/2850] Elapsed 10m 27s (remain 7m 4s) Loss: 0.0108(0.0667) Grad: 1096.1353  LR: 0.000978  \n",
      "Epoch: [1][1800/2850] Elapsed 11m 4s (remain 6m 26s) Loss: 0.0131(0.0637) Grad: 1277.6300  LR: 0.000971  \n",
      "Epoch: [1][1900/2850] Elapsed 11m 40s (remain 5m 49s) Loss: 0.0006(0.0608) Grad: 335.5697  LR: 0.000963  \n",
      "Epoch: [1][2000/2850] Elapsed 12m 18s (remain 5m 13s) Loss: 0.0090(0.0582) Grad: 1374.3920  LR: 0.000955  \n",
      "Epoch: [1][2100/2850] Elapsed 12m 57s (remain 4m 37s) Loss: 0.0013(0.0558) Grad: 339.7748  LR: 0.000947  \n",
      "Epoch: [1][2200/2850] Elapsed 13m 37s (remain 4m 1s) Loss: 0.0012(0.0539) Grad: 243.0654  LR: 0.000939  \n",
      "Epoch: [1][2300/2850] Elapsed 14m 14s (remain 3m 23s) Loss: 0.0028(0.0520) Grad: 566.9084  LR: 0.000932  \n",
      "Epoch: [1][2400/2850] Elapsed 14m 51s (remain 2m 46s) Loss: 0.0018(0.0501) Grad: 379.6953  LR: 0.000924  \n",
      "Epoch: [1][2500/2850] Elapsed 15m 29s (remain 2m 9s) Loss: 0.0014(0.0485) Grad: 268.0405  LR: 0.000916  \n",
      "Epoch: [1][2600/2850] Elapsed 16m 8s (remain 1m 32s) Loss: 0.0081(0.0470) Grad: 776.2825  LR: 0.000908  \n",
      "Epoch: [1][2700/2850] Elapsed 16m 44s (remain 0m 55s) Loss: 0.0023(0.0455) Grad: 503.9472  LR: 0.000901  \n",
      "Epoch: [1][2800/2850] Elapsed 17m 20s (remain 0m 18s) Loss: 0.0175(0.0442) Grad: 5183.8301  LR: 0.000893  \n",
      "Epoch: [1][2849/2850] Elapsed 17m 38s (remain 0m 0s) Loss: 0.0046(0.0437) Grad: 1069.1622  LR: 0.000889  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 50s) Loss: 0.0273(0.0273) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0008(0.0092) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 52s) Loss: 0.0176(0.0107) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0038(0.0092) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 8s) Loss: 0.1310(0.0103) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0151(0.0104) \n",
      "EVAL: [600/725] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0037(0.0099) \n",
      "EVAL: [700/725] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0010(0.0091) \n",
      "EVAL: [724/725] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0141(0.0089) \n",
      "Epoch 1 - avg_train_loss: 0.0437  avg_val_loss: 0.0089  time: 1217s\n",
      "Epoch 1 - Score: 0.8454\n",
      "Epoch 1 - Save Best Score: 0.8454 Model\n",
      "Epoch: [2][0/2850] Elapsed 0m 0s (remain 31m 53s) Loss: 0.0010(0.0010) Grad: 2704.5811  LR: 0.000889  \n",
      "Epoch: [2][100/2850] Elapsed 0m 37s (remain 17m 7s) Loss: 0.0014(0.0061) Grad: 5454.1738  LR: 0.000881  \n",
      "Epoch: [2][200/2850] Elapsed 1m 14s (remain 16m 26s) Loss: 0.0102(0.0068) Grad: 18715.6660  LR: 0.000873  \n",
      "Epoch: [2][300/2850] Elapsed 1m 51s (remain 15m 41s) Loss: 0.0361(0.0078) Grad: 31207.4004  LR: 0.000865  \n",
      "Epoch: [2][400/2850] Elapsed 2m 28s (remain 15m 5s) Loss: 0.0045(0.0072) Grad: 8911.1836  LR: 0.000858  \n",
      "Epoch: [2][500/2850] Elapsed 3m 5s (remain 14m 31s) Loss: 0.0057(0.0074) Grad: 12410.2266  LR: 0.000850  \n",
      "Epoch: [2][600/2850] Elapsed 3m 44s (remain 14m 0s) Loss: 0.0154(0.0070) Grad: 27926.7148  LR: 0.000842  \n",
      "Epoch: [2][700/2850] Elapsed 4m 21s (remain 13m 21s) Loss: 0.0432(0.0073) Grad: 97037.2734  LR: 0.000834  \n",
      "Epoch: [2][800/2850] Elapsed 4m 59s (remain 12m 45s) Loss: 0.0067(0.0074) Grad: 17677.7734  LR: 0.000826  \n",
      "Epoch: [2][900/2850] Elapsed 5m 37s (remain 12m 9s) Loss: 0.0008(0.0074) Grad: 3839.8860  LR: 0.000819  \n",
      "Epoch: [2][1000/2850] Elapsed 6m 14s (remain 11m 31s) Loss: 0.0010(0.0075) Grad: 6036.9414  LR: 0.000811  \n",
      "Epoch: [2][1100/2850] Elapsed 6m 51s (remain 10m 53s) Loss: 0.0007(0.0075) Grad: 2074.8279  LR: 0.000803  \n",
      "Epoch: [2][1200/2850] Elapsed 7m 29s (remain 10m 17s) Loss: 0.0000(0.0076) Grad: 199.3183  LR: 0.000795  \n",
      "Epoch: [2][1300/2850] Elapsed 8m 7s (remain 9m 39s) Loss: 0.0146(0.0074) Grad: 23460.0664  LR: 0.000787  \n",
      "Epoch: [2][1400/2850] Elapsed 8m 44s (remain 9m 2s) Loss: 0.0000(0.0074) Grad: 162.3426  LR: 0.000780  \n",
      "Epoch: [2][1500/2850] Elapsed 9m 21s (remain 8m 24s) Loss: 0.0000(0.0074) Grad: 281.9884  LR: 0.000772  \n",
      "Epoch: [2][1600/2850] Elapsed 9m 59s (remain 7m 48s) Loss: 0.0018(0.0074) Grad: 9871.7324  LR: 0.000764  \n",
      "Epoch: [2][1700/2850] Elapsed 10m 36s (remain 7m 10s) Loss: 0.0076(0.0074) Grad: 11992.2227  LR: 0.000756  \n",
      "Epoch: [2][1800/2850] Elapsed 11m 13s (remain 6m 32s) Loss: 0.0035(0.0074) Grad: 11096.9766  LR: 0.000748  \n",
      "Epoch: [2][1900/2850] Elapsed 11m 51s (remain 5m 55s) Loss: 0.0011(0.0074) Grad: 3241.9226  LR: 0.000741  \n",
      "Epoch: [2][2000/2850] Elapsed 12m 32s (remain 5m 19s) Loss: 0.0000(0.0074) Grad: 219.0627  LR: 0.000733  \n",
      "Epoch: [2][2100/2850] Elapsed 13m 9s (remain 4m 41s) Loss: 0.0008(0.0073) Grad: 3062.9790  LR: 0.000725  \n",
      "Epoch: [2][2200/2850] Elapsed 13m 47s (remain 4m 3s) Loss: 0.0007(0.0073) Grad: 1245.5299  LR: 0.000717  \n",
      "Epoch: [2][2300/2850] Elapsed 14m 24s (remain 3m 26s) Loss: 0.0089(0.0073) Grad: 19651.6602  LR: 0.000709  \n",
      "Epoch: [2][2400/2850] Elapsed 15m 1s (remain 2m 48s) Loss: 0.0002(0.0073) Grad: 948.7125  LR: 0.000702  \n",
      "Epoch: [2][2500/2850] Elapsed 15m 38s (remain 2m 10s) Loss: 0.0000(0.0073) Grad: 274.3640  LR: 0.000694  \n",
      "Epoch: [2][2600/2850] Elapsed 16m 14s (remain 1m 33s) Loss: 0.0148(0.0074) Grad: 34476.0625  LR: 0.000686  \n",
      "Epoch: [2][2700/2850] Elapsed 16m 52s (remain 0m 55s) Loss: 0.0006(0.0074) Grad: 4613.3281  LR: 0.000678  \n",
      "Epoch: [2][2800/2850] Elapsed 17m 30s (remain 0m 18s) Loss: 0.0041(0.0073) Grad: 7752.0391  LR: 0.000670  \n",
      "Epoch: [2][2849/2850] Elapsed 17m 48s (remain 0m 0s) Loss: 0.0007(0.0073) Grad: 2114.2036  LR: 0.000667  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 24s) Loss: 0.0195(0.0195) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 11s) Loss: 0.0006(0.0085) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 51s) Loss: 0.0182(0.0105) \n",
      "EVAL: [300/725] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0008(0.0091) \n",
      "EVAL: [400/725] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0708(0.0097) \n",
      "EVAL: [500/725] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0176(0.0096) \n",
      "EVAL: [600/725] Elapsed 2m 6s (remain 0m 26s) Loss: 0.0037(0.0095) \n",
      "EVAL: [700/725] Elapsed 2m 27s (remain 0m 5s) Loss: 0.0002(0.0087) \n",
      "EVAL: [724/725] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0214(0.0085) \n",
      "Epoch 2 - avg_train_loss: 0.0073  avg_val_loss: 0.0085  time: 1226s\n",
      "Epoch 2 - Score: 0.8579\n",
      "Epoch 2 - Save Best Score: 0.8579 Model\n",
      "Epoch: [3][0/2850] Elapsed 0m 0s (remain 28m 56s) Loss: 0.0010(0.0010) Grad: 11478.8301  LR: 0.000667  \n",
      "Epoch: [3][100/2850] Elapsed 0m 38s (remain 17m 38s) Loss: 0.0001(0.0075) Grad: 653.1523  LR: 0.000659  \n",
      "Epoch: [3][200/2850] Elapsed 1m 16s (remain 16m 53s) Loss: 0.0010(0.0071) Grad: 3223.9631  LR: 0.000651  \n",
      "Epoch: [3][300/2850] Elapsed 1m 54s (remain 16m 10s) Loss: 0.0000(0.0065) Grad: 211.9811  LR: 0.000643  \n",
      "Epoch: [3][400/2850] Elapsed 2m 31s (remain 15m 27s) Loss: 0.0129(0.0065) Grad: 11910.0518  LR: 0.000635  \n",
      "Epoch: [3][500/2850] Elapsed 3m 9s (remain 14m 46s) Loss: 0.0006(0.0062) Grad: 2628.2908  LR: 0.000628  \n",
      "Epoch: [3][600/2850] Elapsed 3m 46s (remain 14m 6s) Loss: 0.0012(0.0064) Grad: 13947.9268  LR: 0.000620  \n",
      "Epoch: [3][700/2850] Elapsed 4m 23s (remain 13m 28s) Loss: 0.0004(0.0059) Grad: 2945.0532  LR: 0.000612  \n",
      "Epoch: [3][800/2850] Elapsed 5m 1s (remain 12m 51s) Loss: 0.0042(0.0060) Grad: 14330.7861  LR: 0.000604  \n",
      "Epoch: [3][900/2850] Elapsed 5m 40s (remain 12m 16s) Loss: 0.0699(0.0061) Grad: 90292.4219  LR: 0.000596  \n",
      "Epoch: [3][1000/2850] Elapsed 6m 17s (remain 11m 37s) Loss: 0.0059(0.0062) Grad: 13486.1211  LR: 0.000589  \n",
      "Epoch: [3][1100/2850] Elapsed 6m 53s (remain 10m 57s) Loss: 0.0023(0.0061) Grad: 8083.2490  LR: 0.000581  \n",
      "Epoch: [3][1200/2850] Elapsed 7m 30s (remain 10m 18s) Loss: 0.0004(0.0062) Grad: 1197.7340  LR: 0.000573  \n",
      "Epoch: [3][1300/2850] Elapsed 8m 8s (remain 9m 41s) Loss: 0.0006(0.0062) Grad: 16673.4531  LR: 0.000565  \n",
      "Epoch: [3][1400/2850] Elapsed 8m 50s (remain 9m 8s) Loss: 0.0000(0.0062) Grad: 192.0384  LR: 0.000557  \n",
      "Epoch: [3][1500/2850] Elapsed 9m 28s (remain 8m 30s) Loss: 0.0000(0.0062) Grad: 209.2399  LR: 0.000550  \n",
      "Epoch: [3][1600/2850] Elapsed 10m 5s (remain 7m 52s) Loss: 0.0024(0.0062) Grad: 21668.1680  LR: 0.000542  \n",
      "Epoch: [3][1700/2850] Elapsed 10m 41s (remain 7m 13s) Loss: 0.0011(0.0062) Grad: 5317.0825  LR: 0.000534  \n",
      "Epoch: [3][1800/2850] Elapsed 11m 18s (remain 6m 35s) Loss: 0.0000(0.0061) Grad: 238.7650  LR: 0.000526  \n",
      "Epoch: [3][1900/2850] Elapsed 11m 56s (remain 5m 57s) Loss: 0.0000(0.0062) Grad: 238.3957  LR: 0.000518  \n",
      "Epoch: [3][2000/2850] Elapsed 12m 32s (remain 5m 19s) Loss: 0.0297(0.0062) Grad: 65300.4180  LR: 0.000511  \n",
      "Epoch: [3][2100/2850] Elapsed 13m 9s (remain 4m 41s) Loss: 0.0019(0.0062) Grad: 5509.3555  LR: 0.000503  \n",
      "Epoch: [3][2200/2850] Elapsed 13m 47s (remain 4m 3s) Loss: 0.0058(0.0063) Grad: 12215.8799  LR: 0.000495  \n",
      "Epoch: [3][2300/2850] Elapsed 14m 24s (remain 3m 26s) Loss: 0.0082(0.0063) Grad: 11221.0762  LR: 0.000487  \n",
      "Epoch: [3][2400/2850] Elapsed 15m 1s (remain 2m 48s) Loss: 0.0277(0.0063) Grad: 29189.6758  LR: 0.000479  \n",
      "Epoch: [3][2500/2850] Elapsed 15m 39s (remain 2m 11s) Loss: 0.0008(0.0063) Grad: 1916.7802  LR: 0.000472  \n",
      "Epoch: [3][2600/2850] Elapsed 16m 16s (remain 1m 33s) Loss: 0.0007(0.0062) Grad: 2177.8450  LR: 0.000464  \n",
      "Epoch: [3][2700/2850] Elapsed 16m 53s (remain 0m 55s) Loss: 0.0017(0.0062) Grad: 5199.0142  LR: 0.000456  \n",
      "Epoch: [3][2800/2850] Elapsed 17m 31s (remain 0m 18s) Loss: 0.0001(0.0062) Grad: 344.7625  LR: 0.000448  \n",
      "Epoch: [3][2849/2850] Elapsed 17m 49s (remain 0m 0s) Loss: 0.0034(0.0061) Grad: 11779.8984  LR: 0.000444  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 27s) Loss: 0.0067(0.0067) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0012(0.0084) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0132(0.0114) \n",
      "EVAL: [300/725] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0011(0.0097) \n",
      "EVAL: [400/725] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0770(0.0107) \n",
      "EVAL: [500/725] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0222(0.0107) \n",
      "EVAL: [600/725] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0136(0.0104) \n",
      "EVAL: [700/725] Elapsed 2m 27s (remain 0m 5s) Loss: 0.0000(0.0096) \n",
      "EVAL: [724/725] Elapsed 2m 32s (remain 0m 0s) Loss: 0.0203(0.0094) \n",
      "Epoch 3 - avg_train_loss: 0.0061  avg_val_loss: 0.0094  time: 1227s\n",
      "Epoch 3 - Score: 0.8742\n",
      "Epoch 3 - Save Best Score: 0.8742 Model\n",
      "Epoch: [4][0/2850] Elapsed 0m 0s (remain 30m 32s) Loss: 0.0004(0.0004) Grad: 2149.6692  LR: 0.000444  \n",
      "Epoch: [4][100/2850] Elapsed 0m 38s (remain 17m 26s) Loss: 0.0002(0.0053) Grad: 1058.4517  LR: 0.000437  \n",
      "Epoch: [4][200/2850] Elapsed 1m 16s (remain 16m 45s) Loss: 0.0125(0.0050) Grad: 29819.5840  LR: 0.000429  \n",
      "Epoch: [4][300/2850] Elapsed 1m 53s (remain 16m 5s) Loss: 0.0003(0.0053) Grad: 2001.8660  LR: 0.000421  \n",
      "Epoch: [4][400/2850] Elapsed 2m 32s (remain 15m 30s) Loss: 0.0002(0.0056) Grad: 1223.2744  LR: 0.000413  \n",
      "Epoch: [4][500/2850] Elapsed 3m 9s (remain 14m 47s) Loss: 0.0084(0.0055) Grad: 9147.2002  LR: 0.000405  \n",
      "Epoch: [4][600/2850] Elapsed 3m 46s (remain 14m 6s) Loss: 0.0013(0.0053) Grad: 5239.5308  LR: 0.000398  \n",
      "Epoch: [4][700/2850] Elapsed 4m 24s (remain 13m 30s) Loss: 0.0026(0.0050) Grad: 5043.0508  LR: 0.000390  \n",
      "Epoch: [4][800/2850] Elapsed 5m 3s (remain 12m 57s) Loss: 0.0011(0.0051) Grad: 8185.3062  LR: 0.000382  \n",
      "Epoch: [4][900/2850] Elapsed 5m 41s (remain 12m 17s) Loss: 0.0023(0.0051) Grad: 9747.4307  LR: 0.000374  \n",
      "Epoch: [4][1000/2850] Elapsed 6m 18s (remain 11m 38s) Loss: 0.0084(0.0051) Grad: 19541.3867  LR: 0.000366  \n",
      "Epoch: [4][1100/2850] Elapsed 6m 54s (remain 10m 58s) Loss: 0.0115(0.0052) Grad: 43907.2500  LR: 0.000359  \n",
      "Epoch: [4][1200/2850] Elapsed 7m 31s (remain 10m 20s) Loss: 0.0157(0.0052) Grad: 22765.9336  LR: 0.000351  \n",
      "Epoch: [4][1300/2850] Elapsed 8m 9s (remain 9m 42s) Loss: 0.0008(0.0051) Grad: 4898.2783  LR: 0.000343  \n",
      "Epoch: [4][1400/2850] Elapsed 8m 47s (remain 9m 5s) Loss: 0.0043(0.0052) Grad: 14679.5381  LR: 0.000335  \n",
      "Epoch: [4][1500/2850] Elapsed 9m 25s (remain 8m 27s) Loss: 0.0003(0.0052) Grad: 1630.3804  LR: 0.000327  \n",
      "Epoch: [4][1600/2850] Elapsed 10m 3s (remain 7m 50s) Loss: 0.0003(0.0053) Grad: 1164.8088  LR: 0.000320  \n",
      "Epoch: [4][1700/2850] Elapsed 10m 40s (remain 7m 12s) Loss: 0.0014(0.0052) Grad: 39891.9258  LR: 0.000312  \n",
      "Epoch: [4][1800/2850] Elapsed 11m 17s (remain 6m 34s) Loss: 0.0010(0.0053) Grad: 7015.3491  LR: 0.000304  \n",
      "Epoch: [4][1900/2850] Elapsed 11m 54s (remain 5m 56s) Loss: 0.0080(0.0052) Grad: 21073.3301  LR: 0.000296  \n",
      "Epoch: [4][2000/2850] Elapsed 12m 31s (remain 5m 18s) Loss: 0.0014(0.0054) Grad: 5316.7515  LR: 0.000288  \n",
      "Epoch: [4][2100/2850] Elapsed 13m 8s (remain 4m 41s) Loss: 0.0003(0.0053) Grad: 1742.3619  LR: 0.000281  \n",
      "Epoch: [4][2200/2850] Elapsed 13m 46s (remain 4m 3s) Loss: 0.0078(0.0054) Grad: 17716.9551  LR: 0.000273  \n",
      "Epoch: [4][2300/2850] Elapsed 14m 23s (remain 3m 26s) Loss: 0.0078(0.0053) Grad: 23587.5469  LR: 0.000265  \n",
      "Epoch: [4][2400/2850] Elapsed 15m 0s (remain 2m 48s) Loss: 0.0028(0.0052) Grad: 11409.9336  LR: 0.000257  \n",
      "Epoch: [4][2500/2850] Elapsed 15m 36s (remain 2m 10s) Loss: 0.0243(0.0052) Grad: 35603.4961  LR: 0.000249  \n",
      "Epoch: [4][2600/2850] Elapsed 16m 13s (remain 1m 33s) Loss: 0.0004(0.0053) Grad: 3961.5476  LR: 0.000242  \n",
      "Epoch: [4][2700/2850] Elapsed 16m 50s (remain 0m 55s) Loss: 0.0000(0.0053) Grad: 190.0773  LR: 0.000234  \n",
      "Epoch: [4][2800/2850] Elapsed 17m 29s (remain 0m 18s) Loss: 0.0003(0.0053) Grad: 961.4707  LR: 0.000226  \n",
      "Epoch: [4][2849/2850] Elapsed 17m 47s (remain 0m 0s) Loss: 0.0000(0.0053) Grad: 1003.7411  LR: 0.000222  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 11s) Loss: 0.0179(0.0179) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 12s) Loss: 0.0013(0.0079) \n",
      "EVAL: [200/725] Elapsed 0m 42s (remain 1m 50s) Loss: 0.0185(0.0113) \n",
      "EVAL: [300/725] Elapsed 1m 3s (remain 1m 29s) Loss: 0.0066(0.0098) \n",
      "EVAL: [400/725] Elapsed 1m 24s (remain 1m 8s) Loss: 0.0450(0.0104) \n",
      "EVAL: [500/725] Elapsed 1m 45s (remain 0m 47s) Loss: 0.0179(0.0104) \n",
      "EVAL: [600/725] Elapsed 2m 7s (remain 0m 26s) Loss: 0.0126(0.0101) \n",
      "EVAL: [700/725] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0000(0.0093) \n",
      "EVAL: [724/725] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0248(0.0091) \n",
      "Epoch 4 - avg_train_loss: 0.0053  avg_val_loss: 0.0091  time: 1226s\n",
      "Epoch 4 - Score: 0.8776\n",
      "Epoch 4 - Save Best Score: 0.8776 Model\n",
      "Epoch: [5][0/2850] Elapsed 0m 0s (remain 30m 46s) Loss: 0.0007(0.0007) Grad: 3805.8899  LR: 0.000222  \n",
      "Epoch: [5][100/2850] Elapsed 0m 37s (remain 17m 4s) Loss: 0.0000(0.0044) Grad: 193.1259  LR: 0.000214  \n",
      "Epoch: [5][200/2850] Elapsed 1m 14s (remain 16m 21s) Loss: 0.0014(0.0048) Grad: 7305.1211  LR: 0.000207  \n",
      "Epoch: [5][300/2850] Elapsed 1m 54s (remain 16m 6s) Loss: 0.0133(0.0053) Grad: 12582.1299  LR: 0.000199  \n",
      "Epoch: [5][400/2850] Elapsed 2m 32s (remain 15m 30s) Loss: 0.0023(0.0050) Grad: 8880.3721  LR: 0.000191  \n",
      "Epoch: [5][500/2850] Elapsed 3m 12s (remain 15m 1s) Loss: 0.0024(0.0050) Grad: 11733.7529  LR: 0.000183  \n",
      "Epoch: [5][600/2850] Elapsed 3m 51s (remain 14m 26s) Loss: 0.0043(0.0050) Grad: 16279.6055  LR: 0.000175  \n",
      "Epoch: [5][700/2850] Elapsed 4m 29s (remain 13m 44s) Loss: 0.0011(0.0049) Grad: 5185.8564  LR: 0.000168  \n",
      "Epoch: [5][800/2850] Elapsed 5m 5s (remain 13m 1s) Loss: 0.0000(0.0047) Grad: 108.2856  LR: 0.000160  \n",
      "Epoch: [5][900/2850] Elapsed 5m 42s (remain 12m 20s) Loss: 0.0000(0.0047) Grad: 205.4740  LR: 0.000152  \n",
      "Epoch: [5][1000/2850] Elapsed 6m 18s (remain 11m 39s) Loss: 0.0003(0.0047) Grad: 1069.5830  LR: 0.000144  \n",
      "Epoch: [5][1100/2850] Elapsed 6m 55s (remain 10m 59s) Loss: 0.0079(0.0048) Grad: 85814.9766  LR: 0.000136  \n",
      "Epoch: [5][1200/2850] Elapsed 7m 32s (remain 10m 21s) Loss: 0.0000(0.0049) Grad: 214.5598  LR: 0.000129  \n",
      "Epoch: [5][1300/2850] Elapsed 8m 10s (remain 9m 43s) Loss: 0.0001(0.0048) Grad: 1329.1082  LR: 0.000121  \n",
      "Epoch: [5][1400/2850] Elapsed 8m 47s (remain 9m 5s) Loss: 0.0013(0.0047) Grad: 7678.8804  LR: 0.000113  \n",
      "Epoch: [5][1500/2850] Elapsed 9m 25s (remain 8m 28s) Loss: 0.0001(0.0048) Grad: 692.2228  LR: 0.000105  \n",
      "Epoch: [5][1600/2850] Elapsed 10m 4s (remain 7m 51s) Loss: 0.0005(0.0047) Grad: 5456.8418  LR: 0.000097  \n",
      "Epoch: [5][1700/2850] Elapsed 10m 41s (remain 7m 13s) Loss: 0.0000(0.0047) Grad: 158.2330  LR: 0.000090  \n",
      "Epoch: [5][1800/2850] Elapsed 11m 18s (remain 6m 35s) Loss: 0.0210(0.0047) Grad: 81106.7188  LR: 0.000082  \n",
      "Epoch: [5][1900/2850] Elapsed 11m 55s (remain 5m 57s) Loss: 0.0001(0.0047) Grad: 823.9909  LR: 0.000074  \n",
      "Epoch: [5][2000/2850] Elapsed 12m 31s (remain 5m 18s) Loss: 0.0794(0.0048) Grad: 57797.4648  LR: 0.000066  \n",
      "Epoch: [5][2100/2850] Elapsed 13m 8s (remain 4m 41s) Loss: 0.0060(0.0049) Grad: 12600.9668  LR: 0.000058  \n",
      "Epoch: [5][2200/2850] Elapsed 13m 45s (remain 4m 3s) Loss: 0.0000(0.0048) Grad: 272.1570  LR: 0.000051  \n",
      "Epoch: [5][2300/2850] Elapsed 14m 23s (remain 3m 25s) Loss: 0.0002(0.0048) Grad: 1914.4885  LR: 0.000043  \n",
      "Epoch: [5][2400/2850] Elapsed 15m 1s (remain 2m 48s) Loss: 0.0006(0.0048) Grad: 2986.9216  LR: 0.000035  \n",
      "Epoch: [5][2500/2850] Elapsed 15m 42s (remain 2m 11s) Loss: 0.0000(0.0049) Grad: 163.4254  LR: 0.000027  \n",
      "Epoch: [5][2600/2850] Elapsed 16m 21s (remain 1m 33s) Loss: 0.0016(0.0049) Grad: 7241.4136  LR: 0.000019  \n",
      "Epoch: [5][2700/2850] Elapsed 16m 58s (remain 0m 56s) Loss: 0.0001(0.0049) Grad: 1538.1581  LR: 0.000012  \n",
      "Epoch: [5][2800/2850] Elapsed 17m 34s (remain 0m 18s) Loss: 0.0001(0.0049) Grad: 773.1603  LR: 0.000004  \n",
      "Epoch: [5][2849/2850] Elapsed 17m 53s (remain 0m 0s) Loss: 0.0001(0.0049) Grad: 1167.1418  LR: 0.000000  \n",
      "EVAL: [0/725] Elapsed 0m 0s (remain 5m 53s) Loss: 0.0267(0.0267) \n",
      "EVAL: [100/725] Elapsed 0m 21s (remain 2m 13s) Loss: 0.0017(0.0093) \n",
      "EVAL: [200/725] Elapsed 0m 43s (remain 1m 52s) Loss: 0.0116(0.0132) \n",
      "EVAL: [300/725] Elapsed 1m 4s (remain 1m 30s) Loss: 0.0122(0.0112) \n",
      "EVAL: [400/725] Elapsed 1m 25s (remain 1m 9s) Loss: 0.0425(0.0118) \n",
      "EVAL: [500/725] Elapsed 1m 46s (remain 0m 47s) Loss: 0.0208(0.0117) \n",
      "EVAL: [600/725] Elapsed 2m 8s (remain 0m 26s) Loss: 0.0133(0.0113) \n",
      "EVAL: [700/725] Elapsed 2m 28s (remain 0m 5s) Loss: 0.0000(0.0104) \n",
      "EVAL: [724/725] Elapsed 2m 33s (remain 0m 0s) Loss: 0.0232(0.0102) \n",
      "Epoch 5 - avg_train_loss: 0.0049  avg_val_loss: 0.0102  time: 1232s\n",
      "Epoch 5 - Score: 0.8792\n",
      "Epoch 5 - Save Best Score: 0.8792 Model\n",
      "Best thres: 0.5, Score: 0.8804\n",
      "Best thres: 0.49687499999999996, Score: 0.8805\n",
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c8d06b60c24d7e86d69c0531ea4a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b670ce4b864ba0a6394b35b62fa9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134867348742449a866a1b6ebf0d3caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66933dc02fd4755a8f0fc60f4c32314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight from ../output/nbme-score-clinical-patient-notes/nbme-exp022/checkpoint-130170/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b57f44a95445d9bc5b56ad72d618bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp023.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.572862,
   "end_time": "2022-02-27T11:39:50.972497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T11:29:09.399635",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00419a15e9834e98b8a3459b62d01f8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "008f77fefdba425ab2c755f515693e6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05fdce5a55c1483a937d07a50bd9465e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b48bd338cc94fe396aa1b736b9a2507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f856d468c8a4c4c9c83b5b263745508": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1193874a74974cc59982c8d5e3ced585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8e243ea82e59492fb5b845e51a56347a",
       "IPY_MODEL_55ac42bee2ce4f00841b8bd49a7c552d",
       "IPY_MODEL_2281dd4891c640a0b31c23976223f2ba"
      ],
      "layout": "IPY_MODEL_84ea1506dcad4e01ad1cc35b76c0339a"
     }
    },
    "160e78a145894001b2a1295627d80df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_605151b49d7641a28ebd0ca083770c69",
       "IPY_MODEL_8f8c8632070c4fa0a3182521f41e9c40",
       "IPY_MODEL_dfb4641da88e47d3bafabbaa56bc6916"
      ],
      "layout": "IPY_MODEL_008f77fefdba425ab2c755f515693e6f"
     }
    },
    "19783f5141cb47f8aaa057fb01dda913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c55e9e0223548fbbbe29b3e11e59d50",
      "placeholder": "​",
      "style": "IPY_MODEL_1faca6dc4b0e43988d2f81cd209297be",
      "value": " 143/143 [00:00&lt;00:00, 3251.56it/s]"
     }
    },
    "1ad701d95f084c98bd1bf0e9d7d498a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e0d277fe44242e19e3bec17a1cb7280": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1faca6dc4b0e43988d2f81cd209297be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "219090e2dd934c1296f12660ea69b161": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05fdce5a55c1483a937d07a50bd9465e",
      "placeholder": "​",
      "style": "IPY_MODEL_00419a15e9834e98b8a3459b62d01f8b",
      "value": " 2/2 [00:00&lt;00:00,  1.25it/s]"
     }
    },
    "2281dd4891c640a0b31c23976223f2ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b311e42f1294339a07248b31db0c26c",
      "placeholder": "​",
      "style": "IPY_MODEL_ab8e5c4cef00426fa0cf2fc25c51381a",
      "value": " 2/2 [00:00&lt;00:00,  1.31it/s]"
     }
    },
    "26b1a86ee1ff4ce2862c13d47be2b2d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b311e42f1294339a07248b31db0c26c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c55e9e0223548fbbbe29b3e11e59d50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ddd9fc857b549a4ba446dd64a1dd1d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "331b7288a5024ce3a5036af53eb75cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b50983bfae8445fa305d1edadd651af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b09413b459c8406882a16db62e8df9c0",
      "placeholder": "​",
      "style": "IPY_MODEL_8478e8bf8b6146b48e717b84c021e7ab",
      "value": "100%"
     }
    },
    "3ca14e3fd6b84312b0af50a89d5ac7c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fb5b968d9ab4e88964b6b126c6023d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "410c3733ee43430eb55278748d07bc45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44650208feba4c118904c7efc9887532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "490bfe688fe1419996b69f7de1cfee23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5068fb514bf143ba812fe202c3e7a83d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5292a911912d43c2b80919e486b99de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8234c7d9369644dea7e5c7e8fe436771",
      "placeholder": "​",
      "style": "IPY_MODEL_3ca14e3fd6b84312b0af50a89d5ac7c1",
      "value": "100%"
     }
    },
    "537dee640701470c8fc3cc29e7940bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "548835fe547d4114bfd39e5fac680635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5536b7aaba7c41f28197e318b362ec75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b50983bfae8445fa305d1edadd651af",
       "IPY_MODEL_cdbf6aefee644006826f76e2f6722b07",
       "IPY_MODEL_7c62f6a2b08c41a8bc3ecf2efa58c325"
      ],
      "layout": "IPY_MODEL_5ecd28892bb84432935145e27ac71de7"
     }
    },
    "55ac42bee2ce4f00841b8bd49a7c552d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e0d277fe44242e19e3bec17a1cb7280",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5068fb514bf143ba812fe202c3e7a83d",
      "value": 2
     }
    },
    "5a3f361a320f480aa8a4115366073d32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ecd28892bb84432935145e27ac71de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "605151b49d7641a28ebd0ca083770c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dc964a8934744608f92a6af0f0f923f",
      "placeholder": "​",
      "style": "IPY_MODEL_537dee640701470c8fc3cc29e7940bee",
      "value": "100%"
     }
    },
    "63aa4d26409d437fa76e5a156bb04791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65d16c05424c4df0b79b5786be8bd5d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661a9a315f8646a49162891ae47c69e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74fa3a6b51ad46958e58de5580cf5333",
       "IPY_MODEL_810a830f3b6743b9b074867dd8e4e179",
       "IPY_MODEL_7316ae87cfb849898eb022e100730ba2"
      ],
      "layout": "IPY_MODEL_ef004a834af944abbd512fa3218642a1"
     }
    },
    "6919ba0239084b04988e1de02316c76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d74dcf5002c4752af12a65c3aca2113": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc964a8934744608f92a6af0f0f923f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a8b4ea52534d4e9feab6c6fdd72a77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7316ae87cfb849898eb022e100730ba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ddd9fc857b549a4ba446dd64a1dd1d4",
      "placeholder": "​",
      "style": "IPY_MODEL_0b48bd338cc94fe396aa1b736b9a2507",
      "value": " 42146/42146 [00:22&lt;00:00, 1885.59it/s]"
     }
    },
    "74fa3a6b51ad46958e58de5580cf5333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d891639f26644e8a05d7fe38d178245",
      "placeholder": "​",
      "style": "IPY_MODEL_c7cb034c107247cba318475c9952b4ac",
      "value": "100%"
     }
    },
    "789324d1692d4f478d5b95491b03fc22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c62f6a2b08c41a8bc3ecf2efa58c325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e48e5c946462499ab018748ccf80c5b5",
      "placeholder": "​",
      "style": "IPY_MODEL_63aa4d26409d437fa76e5a156bb04791",
      "value": " 2/2 [00:01&lt;00:00,  1.16it/s]"
     }
    },
    "7d891639f26644e8a05d7fe38d178245": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e210db5a5fe41f696351dc87d525ee4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ed0ca5ee62d45d89050f3caf3d528c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "810a830f3b6743b9b074867dd8e4e179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ed0ca5ee62d45d89050f3caf3d528c9",
      "max": 42146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8a7a19edb074139baefe21f1901d4f4",
      "value": 42146
     }
    },
    "8234c7d9369644dea7e5c7e8fe436771": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8478e8bf8b6146b48e717b84c021e7ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84ea1506dcad4e01ad1cc35b76c0339a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e243ea82e59492fb5b845e51a56347a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_548835fe547d4114bfd39e5fac680635",
      "placeholder": "​",
      "style": "IPY_MODEL_6919ba0239084b04988e1de02316c76e",
      "value": "100%"
     }
    },
    "8f8c8632070c4fa0a3182521f41e9c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d76610cad4f645f187b26f1b82733569",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_925a3ae98bd6488eb7cffdec89d768da",
      "value": 2
     }
    },
    "925a3ae98bd6488eb7cffdec89d768da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "953c495e9f64430cbdd9184bb0bd35cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9815ec90f12a4696a85db6dc629ec62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e210db5a5fe41f696351dc87d525ee4",
      "placeholder": "​",
      "style": "IPY_MODEL_953c495e9f64430cbdd9184bb0bd35cb",
      "value": "100%"
     }
    },
    "9e66574c8c0343ffb0477891bfe5e892": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_331b7288a5024ce3a5036af53eb75cec",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1cd0285cfe34f188e9c779617d48448",
      "value": 2
     }
    },
    "ab8e5c4cef00426fa0cf2fc25c51381a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b09413b459c8406882a16db62e8df9c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28fa99d1b1b4e4da668bcc50373e4cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8554928c5f141de8dfb94c04c2dda03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bec237aed5184115b697ea257f7b0c9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_789324d1692d4f478d5b95491b03fc22",
      "placeholder": "​",
      "style": "IPY_MODEL_490bfe688fe1419996b69f7de1cfee23",
      "value": " 2/2 [00:00&lt;00:00,  1.38it/s]"
     }
    },
    "c7cb034c107247cba318475c9952b4ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8a7a19edb074139baefe21f1901d4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cdbf6aefee644006826f76e2f6722b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65d16c05424c4df0b79b5786be8bd5d1",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72a8b4ea52534d4e9feab6c6fdd72a77",
      "value": 2
     }
    },
    "ce26114873ed4c96b5ea391a41b18f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f856d468c8a4c4c9c83b5b263745508",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a3f361a320f480aa8a4115366073d32",
      "value": 2
     }
    },
    "d1cd0285cfe34f188e9c779617d48448": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d240d13622c14726a5639d44ef2421ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44650208feba4c118904c7efc9887532",
      "placeholder": "​",
      "style": "IPY_MODEL_e7be4ec44f2a4183b295f486e250b414",
      "value": "100%"
     }
    },
    "d76610cad4f645f187b26f1b82733569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfb4641da88e47d3bafabbaa56bc6916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8554928c5f141de8dfb94c04c2dda03",
      "placeholder": "​",
      "style": "IPY_MODEL_b28fa99d1b1b4e4da668bcc50373e4cc",
      "value": " 2/2 [00:01&lt;00:00,  1.11it/s]"
     }
    },
    "e032f2bf0bb241c2911087a6efe1ce0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d74dcf5002c4752af12a65c3aca2113",
      "max": 143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ad701d95f084c98bd1bf0e9d7d498a9",
      "value": 143
     }
    },
    "e48e5c946462499ab018748ccf80c5b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7be4ec44f2a4183b295f486e250b414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef004a834af944abbd512fa3218642a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f319feca977544738ff2400ab23a9276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9815ec90f12a4696a85db6dc629ec62a",
       "IPY_MODEL_e032f2bf0bb241c2911087a6efe1ce0b",
       "IPY_MODEL_19783f5141cb47f8aaa057fb01dda913"
      ],
      "layout": "IPY_MODEL_26b1a86ee1ff4ce2862c13d47be2b2d6"
     }
    },
    "f39640d290374992aa246753125a91de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5292a911912d43c2b80919e486b99de9",
       "IPY_MODEL_ce26114873ed4c96b5ea391a41b18f68",
       "IPY_MODEL_bec237aed5184115b697ea257f7b0c9b"
      ],
      "layout": "IPY_MODEL_410c3733ee43430eb55278748d07bc45"
     }
    },
    "fc3c6209df394eefa2df9ce8dbb56830": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d240d13622c14726a5639d44ef2421ec",
       "IPY_MODEL_9e66574c8c0343ffb0477891bfe5e892",
       "IPY_MODEL_219090e2dd934c1296f12660ea69b161"
      ],
      "layout": "IPY_MODEL_3fb5b968d9ab4e88964b6b126c6023d9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
