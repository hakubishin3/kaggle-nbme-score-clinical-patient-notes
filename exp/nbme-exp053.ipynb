{"cells":[{"cell_type":"markdown","id":"brave-teach","metadata":{"id":"brave-teach"},"source":["## References"]},{"cell_type":"markdown","id":"orange-toilet","metadata":{"id":"orange-toilet"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"serious-sending","metadata":{"id":"serious-sending"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"august-providence","metadata":{"id":"august-providence","executionInfo":{"status":"ok","timestamp":1647655929651,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp053\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"cathedral-horror","metadata":{"id":"cathedral-horror","executionInfo":{"status":"ok","timestamp":1647655929652,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    mixout=0.5\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=2\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=4\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"armed-norfolk","metadata":{"id":"armed-norfolk","executionInfo":{"status":"ok","timestamp":1647655929652,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"atlantic-warrant","metadata":{"id":"atlantic-warrant"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"federal-marsh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"federal-marsh","outputId":"2220d342-f823-41a2-f52d-065f8368fbd3","executionInfo":{"status":"ok","timestamp":1647655965224,"user_tz":-540,"elapsed":35581,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Mounted at /content/drive\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 15.0 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 53.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 62.2 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 58.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"recent-harrison","metadata":{"id":"recent-harrison","executionInfo":{"status":"ok","timestamp":1647655977139,"user_tz":-540,"elapsed":11922,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"technical-story","metadata":{"id":"technical-story"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"understanding-trial","metadata":{"id":"understanding-trial","executionInfo":{"status":"ok","timestamp":1647655977139,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"pursuant-lover","metadata":{"id":"pursuant-lover","executionInfo":{"status":"ok","timestamp":1647655977140,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"matched-hollow","metadata":{"id":"matched-hollow","executionInfo":{"status":"ok","timestamp":1647655977140,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"weighted-screw","metadata":{"id":"weighted-screw","executionInfo":{"status":"ok","timestamp":1647655977140,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"following-passport","metadata":{"id":"following-passport"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"absent-performance","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"absent-performance","outputId":"2c0995a3-fe55-473c-b132-070418a383b9","executionInfo":{"status":"ok","timestamp":1647655980321,"user_tz":-540,"elapsed":3186,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"automated-proportion","metadata":{"id":"automated-proportion","executionInfo":{"status":"ok","timestamp":1647655980322,"user_tz":-540,"elapsed":12,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"preceding-january","metadata":{"id":"preceding-january"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"monetary-camera","metadata":{"id":"monetary-camera","executionInfo":{"status":"ok","timestamp":1647655980322,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"fitted-current","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fitted-current","outputId":"adcc3caa-ccd1-4b81-d4cf-ea397c317154","executionInfo":{"status":"ok","timestamp":1647655980323,"user_tz":-540,"elapsed":12,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"australian-vehicle","metadata":{"id":"australian-vehicle","executionInfo":{"status":"ok","timestamp":1647655980323,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"devoted-peter","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"devoted-peter","outputId":"986f8870-f05a-4734-c99a-6716c3479051","executionInfo":{"status":"ok","timestamp":1647655980323,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"incorrect-honey","metadata":{"id":"incorrect-honey"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"adjacent-antibody","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"adjacent-antibody","outputId":"cf15810d-9640-46a2-bea4-5cd732534e9f","executionInfo":{"status":"ok","timestamp":1647655980763,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"breathing-state","metadata":{"id":"breathing-state"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"former-beast","metadata":{"id":"former-beast","executionInfo":{"status":"ok","timestamp":1647655987642,"user_tz":-540,"elapsed":6884,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["4aca5d978e3c46688e387544beef1053","2d5619270759476a9bc67ab5b183a426","e8b52938d8be46da95bda58aab91bba4","e909b587736b4caeb7c301da82330fea","d547223a923e4e11aa0991781093b521","4a4904aa488a4957b438d895dfc933ab","b168424a48e34782bca6a643bfad71bc","76dc0df93e81433abd69458483cc0748","b183101caec445608ab717a8557d0f29","cdf7790f04cf4e6098f64153a9690037","9597d005eded42f2a2f64dc858e0f32a","b58db1e8f7b44dbb89c57c5c0c4a250d","74982d2d13d24681940a72a548ff2e8e","84c5457394a94f409b08ffab3cbf65a6","992bedc3ce57440b8d7dcf23779785c1","18a35825cfa846489e6ae28842beb89a","3cd6503c9ecc4e37a1569df8e4c4a5c6","97b355011f484349b5475780a17feba3","cae1e3b79e404f91853a84449aedb67d","9c642c92e18c458999fe79f47a6838e5","ebcebcd05b334d18bc71ef44f1fc8fb8","c23b7159af9e4ea09c81d1409f4ba270","7f9c845d3c394fb38ca91e2dcf5a760a","15a4c7bd65c344d7bc871dc479b98747","65ea4d9fe40a414fa21cf0391ff4115c","2497f4bc4f4242d39b86ac02eab0bb77","80e1024cc4d54775bb38f584e225c793","76c0be9bbdb642f1a61ff4b511dbd253","4426b7981a314bcf93a35a064495c53c","381ed600b47b445b89fda19cd9fc3eb0","c1548830b4af4c81a999b5ce5c503258","1227fbe6c8ec4b458f1df2f3dfc63ad2","cb4cebe78958440886212d21accd8b31","be385109cd324c81aceef334e024bd8d","5a7801a1b65b42f8bcac09f4757ae90d","1ef55881ffec4b1ead8a5c4e1a8849d4","c01fb4f4c57a4d248b1ba84a05339632","3235ac11228348578980f45ffca02e6c","25aa1da131fc4f379cb65e4f55a1688c","e113d7f11eb0423bbf80d6ae48be773c","753873935e034b62989c8bc0cf1260bf","6429e386ee40478fab61eb81cfabdb8e","489b2fb487564b7080fdf08ebd0c82f7","81ce4244f06649f7a852bbbcb8e6de03"]},"outputId":"228ce2be-1ee3-4979-ccc1-610da0c69da2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aca5d978e3c46688e387544beef1053"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b58db1e8f7b44dbb89c57c5c0c4a250d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f9c845d3c394fb38ca91e2dcf5a760a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be385109cd324c81aceef334e024bd8d"}},"metadata":{}}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","source":["tmp = 'dad with recent heart attack'\n","encode = tokenizer(tmp, return_offsets_mapping=True)\n","for (start,end) in encode['offset_mapping']:\n","    print(f\"'{tmp[start:end]}', {start}, {end}\")\n","\n","print(\"ans\")\n","print(\"\"\"\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDMSkwTNgOOh","executionInfo":{"status":"ok","timestamp":1647655987642,"user_tz":-540,"elapsed":22,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"ed859738-28b6-4112-c292-3d305424e293"},"id":"TDMSkwTNgOOh","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","ans\n","\n","'', 0, 0\n","'dad', 0, 3\n","' with', 3, 8\n","' recent', 8, 15\n","' heart', 15, 21\n","' attack', 21, 28\n","'', 0, 0\n","\n"]}]},{"cell_type":"markdown","id":"employed-foster","metadata":{"id":"employed-foster"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":19,"id":"biblical-mailing","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["036556b017254d49aa75e97a3e2774cb","4f890ffcde5443fda80abad9e04c7390","a34b431d76df417f9c273e20e209c7ae","1c1c93674fbe488e85a6e1285cb921d6","45662e8179d640e99502be120e83ad52","f0165fa7d9b244989c860cfceac115a3","15a9abda553f4eedbbdd3a7c1d40b646","fefd2580da384494b9138a43f1ae71e6","eafe217d4c694369801bfcff980b781c","8bec9c8127e7485e9feeb4aa567b23c2","61e416cb3c214523ac93a964f27341f2"]},"id":"biblical-mailing","outputId":"6c10efa2-c231-47ba-a325-8b111e232f57","executionInfo":{"status":"ok","timestamp":1647656019304,"user_tz":-540,"elapsed":31679,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036556b017254d49aa75e97a3e2774cb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":20,"id":"renewable-mercury","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["7e72afb327ad46faa73cbda5f7f987b5","cfc5af9d10974e76a043cc5d35067cc6","68ced3c976c04c15a5dd0b6d628bfe05","50b879d10f71417e9ec05866338a9602","65aca0413919449e9d38a3d57d3397eb","825a952ce8f749aa877d2cacecf2a130","a10baceb9abf47c9b5b264bb13e6ed10","82c69d96982045feace697e62b08e385","7ee36b8126054460ae47b42a2b78c120","a646899ba37f4cf0b9df27fe0cf5b081","f613bbc4eaff4dc9922fb47cc1f7fd03"]},"id":"renewable-mercury","outputId":"155a5748-c0f7-444d-ef34-04e4d41c771b","executionInfo":{"status":"ok","timestamp":1647656019696,"user_tz":-540,"elapsed":18,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e72afb327ad46faa73cbda5f7f987b5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":21,"id":"latin-burlington","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"latin-burlington","outputId":"1b80987e-25ea-4b95-d662-ce613daf6822","executionInfo":{"status":"ok","timestamp":1647656019697,"user_tz":-540,"elapsed":15,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":22,"id":"minor-stock","metadata":{"id":"minor-stock","executionInfo":{"status":"ok","timestamp":1647656019698,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":23,"id":"decimal-schema","metadata":{"id":"decimal-schema","executionInfo":{"status":"ok","timestamp":1647656019699,"user_tz":-540,"elapsed":12,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"exceptional-vertical","metadata":{"id":"exceptional-vertical"},"source":["## Model"]},{"cell_type":"code","execution_count":24,"id":"dynamic-fifteen","metadata":{"id":"dynamic-fifteen","executionInfo":{"status":"ok","timestamp":1647656019702,"user_tz":-540,"elapsed":14,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            #path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size * 4, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"hidden_states\"]\n","        h = torch.cat([h[-1*i][:, :] for i in range(1, 4 + 1)], dim=2)  # concatenate\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"driving-commercial","metadata":{"id":"driving-commercial"},"source":["## Training"]},{"cell_type":"code","source":["import math\n","from torch.autograd.function import InplaceFunction\n","from torch.nn import Parameter\n","import torch.nn.init as init\n","\n","class Mixout(InplaceFunction):\n","    @staticmethod\n","    def _make_noise(input):\n","        return input.new().resize_as_(input)\n","\n","    @classmethod\n","    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n","        if p < 0 or p > 1:\n","            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\" \" but got {}\".format(p))\n","        if target is not None and input.size() != target.size():\n","            raise ValueError(\n","                \"A target tensor size must match with a input tensor size {},\"\n","                \" but got {}\".format(input.size(), target.size())\n","            )\n","        ctx.p = p\n","        ctx.training = training\n","\n","        if ctx.p == 0 or not ctx.training:\n","            return input\n","\n","        if target is None:\n","            target = cls._make_noise(input)\n","            target.fill_(0)\n","        target = target.to(input.device)\n","\n","        if inplace:\n","            ctx.mark_dirty(input)\n","            output = input\n","        else:\n","            output = input.clone()\n","\n","        ctx.noise = cls._make_noise(input)\n","        if len(ctx.noise.size()) == 1:\n","            ctx.noise.bernoulli_(1 - ctx.p)\n","        else:\n","            ctx.noise[0].bernoulli_(1 - ctx.p)\n","            ctx.noise = ctx.noise[0].repeat(input.size()[0], 1)\n","        ctx.noise.expand_as(input)\n","\n","        if ctx.p == 1:\n","            output = target\n","        else:\n","            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        if ctx.p > 0 and ctx.training:\n","            return grad_output * ctx.noise, None, None, None, None\n","        else:\n","            return grad_output, None, None, None, None\n","\n","\n","def mixout(input, target=None, p=0.0, training=False, inplace=False):\n","    return Mixout.apply(input, target, p, training, inplace)\n","\n","\n","class MixLinear(torch.nn.Module):\n","    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n","    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n","        super(MixLinear, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = Parameter(torch.Tensor(out_features, in_features))\n","        if bias:\n","            self.bias = Parameter(torch.Tensor(out_features))\n","        else:\n","            self.register_parameter(\"bias\", None)\n","        self.reset_parameters()\n","        self.target = target\n","        self.p = p\n","\n","    def reset_parameters(self):\n","        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","        if self.bias is not None:\n","            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n","            bound = 1 / math.sqrt(fan_in)\n","            init.uniform_(self.bias, -bound, bound)\n","\n","    def forward(self, input):\n","        return F.linear(input, mixout(self.weight, self.target, self.p, self.training), self.bias)\n","\n","    def extra_repr(self):\n","        type = \"drop\" if self.target is None else \"mix\"\n","        return \"{}={}, in_features={}, out_features={}, bias={}\".format(\n","            type + \"out\", self.p, self.in_features, self.out_features, self.bias is not None\n","        )\n","\n","\n","def replace_mixout(model):\n","    for sup_module in model.modules():\n","        for name, module in sup_module.named_children():\n","            if isinstance(module, nn.Dropout):\n","                module.p = 0.0\n","            if isinstance(module, nn.Linear):\n","                target_state_dict = module.state_dict()\n","                bias = True if module.bias is not None else False\n","                new_module = MixLinear(\n","                    module.in_features, module.out_features, bias, target_state_dict[\"weight\"], CFG.mixout\n","                )\n","                new_module.load_state_dict(target_state_dict)\n","                setattr(sup_module, name, new_module)\n","    return model"],"metadata":{"id":"GqZSJBMF6B1n","executionInfo":{"status":"ok","timestamp":1647656019704,"user_tz":-540,"elapsed":16,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"GqZSJBMF6B1n","execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":26,"id":"cathedral-component","metadata":{"id":"cathedral-component","executionInfo":{"status":"ok","timestamp":1647656020028,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":27,"id":"expired-wilson","metadata":{"id":"expired-wilson","executionInfo":{"status":"ok","timestamp":1647656020029,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","\n","        pos_nums = (labels == 1).sum(axis=1)\n","        pos_nums = torch.tensor([[pos_num] * CFG.max_len for pos_num in pos_nums]).view(-1, 1).to(device)\n","        pos_nums = torch.masked_select(pos_nums, labels.view(-1, 1) != -1)\n","        weight = []\n","        for pos_num in pos_nums:\n","            if pos_num == 0:\n","                weight.append(3.0)\n","            else:\n","                weight.append(1.0)\n","        weight = torch.tensor(weight).to(device)\n","        loss = loss * weight\n","\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":28,"id":"chinese-sympathy","metadata":{"id":"chinese-sympathy","executionInfo":{"status":"ok","timestamp":1647656020029,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":29,"id":"healthy-sleep","metadata":{"id":"healthy-sleep","executionInfo":{"status":"ok","timestamp":1647656020030,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    model = replace_mixout(model)  # mixout\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"balanced-novel","metadata":{"id":"balanced-novel"},"source":["## Main"]},{"cell_type":"code","execution_count":30,"id":"sound-silly","metadata":{"id":"sound-silly","executionInfo":{"status":"ok","timestamp":1647656020030,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"id":"reduced-indication","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["804b2a4e2fe74220ae7a562e4fe9b947","e08f2f5bc05b46bc9c23b1a4d496abf0","05e6e8cb9f4f4ba69fc11028cda5de85","f393cd5358a14875a767f405eb43d6be","5a36f1c0e4eb4c9e85a6d355dfdcd17d","ad45ffb3a76c4550844434522e46bc66","142a5671af8c49db897ef5e57132e64d","4319e7e14e49472d9873e27b8f8226cc","7a6949f16c2f4569a2ed8d6cf83f2300","f5a6a722e2c043c395ddd42e5af0eced","7d5cc694c6ef42889fad9710c3017d5e","1d4457fc2ced403f8fdc30f7b5e73fdd","9fe3ad97584845e39369defc144a5b1a","bbe93a19ef544577b0c8d4658a6ba955","17da435db97c4130a89ce857fd5f778c","4709f234dbd04f1c9e08dcd879911add","acb74eb656a34697a0c11bf00c90aa21","4fd88d5a168349eca4787bed39dd6a57","5bde81a206e5419a96b43aa607ff2dd6","a42c8a8fdce046599c033efd837bb818","cf2eb96f21564ecf9e21a0f97c1a38d3","696dec4ab83643c7a260b4764824ede6","c2e3517d51e24e3685b40409991c23b6","1a72551ae1b1420b8d7d513eca28a8cc","97a23b511d054da49580bff31acde80e","2cb4420ec1d2453e90d01d27d293c8a4","2fc8483ae852488991aae56f7425c16c","897c741c93fc41f2b0d3d3c87c9cc566","afce95bc76ef4434a7067dced39b6920","3519d15501644f0c88ba2878a6b07e43","258c2c4c47084b2b92600a3d44bbad4b","78978057682041c39051b47f9fcae909","e1e517a805b24165a31d218535327f33"]},"id":"reduced-indication","outputId":"5e81479f-5ed4-4c61-a318-1779f180f0a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 130m 44s) Loss: 0.4338(0.4338) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 3s (remain 55m 25s) Loss: 0.2058(0.3625) Grad: 8477.0225  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 4s (remain 53m 24s) Loss: 0.3357(0.3317) Grad: 15142.5469  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 6s (remain 52m 14s) Loss: 0.1958(0.2921) Grad: 7277.0957  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 7s (remain 51m 6s) Loss: 0.0673(0.2447) Grad: 3672.7019  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 9s (remain 49m 58s) Loss: 0.0047(0.2019) Grad: 139.2807  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 10s (remain 48m 51s) Loss: 0.0367(0.1718) Grad: 403.8513  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 11s (remain 47m 47s) Loss: 0.0336(0.1502) Grad: 394.2928  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 12s (remain 46m 45s) Loss: 0.0488(0.1339) Grad: 649.1876  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 14s (remain 45m 43s) Loss: 0.0254(0.1211) Grad: 309.4258  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 15s (remain 44m 40s) Loss: 0.0326(0.1106) Grad: 321.2181  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 16s (remain 43m 37s) Loss: 0.0017(0.1017) Grad: 152.9456  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 17s (remain 42m 35s) Loss: 0.0205(0.0940) Grad: 1063.6241  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 18s (remain 41m 32s) Loss: 0.0020(0.0874) Grad: 100.2375  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 19s (remain 40m 30s) Loss: 0.0047(0.0819) Grad: 309.9593  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 20s (remain 39m 28s) Loss: 0.0030(0.0769) Grad: 180.7242  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 21s (remain 38m 26s) Loss: 0.0029(0.0726) Grad: 168.4600  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 22s (remain 37m 24s) Loss: 0.0038(0.0687) Grad: 394.8722  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 23s (remain 36m 22s) Loss: 0.0039(0.0653) Grad: 187.7923  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 24s (remain 35m 20s) Loss: 0.0121(0.0621) Grad: 1824.8949  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 25s (remain 34m 18s) Loss: 0.0140(0.0593) Grad: 692.1661  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 26s (remain 33m 17s) Loss: 0.0000(0.0567) Grad: 12.7550  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 27s (remain 32m 15s) Loss: 0.0012(0.0544) Grad: 100.7968  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 23m 28s (remain 31m 13s) Loss: 0.0076(0.0523) Grad: 403.7228  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 24m 29s (remain 30m 12s) Loss: 0.0038(0.0503) Grad: 202.9684  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 25m 30s (remain 29m 10s) Loss: 0.0015(0.0485) Grad: 66.5953  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 26m 31s (remain 28m 9s) Loss: 0.0056(0.0468) Grad: 466.8956  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 27m 32s (remain 27m 8s) Loss: 0.0006(0.0453) Grad: 34.7282  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 28m 33s (remain 26m 6s) Loss: 0.0008(0.0439) Grad: 67.6317  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 29m 34s (remain 25m 5s) Loss: 0.0074(0.0425) Grad: 392.0518  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 30m 36s (remain 24m 4s) Loss: 0.0026(0.0413) Grad: 197.5072  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 31m 37s (remain 23m 3s) Loss: 0.0026(0.0401) Grad: 174.2026  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 32m 38s (remain 22m 2s) Loss: 0.0007(0.0389) Grad: 57.0742  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 33m 39s (remain 21m 0s) Loss: 0.0008(0.0379) Grad: 72.7678  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 34m 40s (remain 19m 59s) Loss: 0.0001(0.0369) Grad: 6.5092  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 35m 41s (remain 18m 58s) Loss: 0.0037(0.0360) Grad: 142.5474  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 36m 42s (remain 17m 57s) Loss: 0.0100(0.0351) Grad: 392.6443  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 37m 43s (remain 16m 55s) Loss: 0.0026(0.0343) Grad: 85.1540  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 38m 44s (remain 15m 54s) Loss: 0.0063(0.0335) Grad: 316.4048  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 39m 45s (remain 14m 53s) Loss: 0.0000(0.0327) Grad: 11.8640  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 40m 46s (remain 13m 52s) Loss: 0.0005(0.0320) Grad: 53.9643  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 41m 47s (remain 12m 51s) Loss: 0.0007(0.0314) Grad: 55.5050  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 42m 48s (remain 11m 49s) Loss: 0.0011(0.0307) Grad: 53.6297  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 43m 49s (remain 10m 48s) Loss: 0.0027(0.0301) Grad: 176.8545  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 44m 50s (remain 9m 47s) Loss: 0.0036(0.0294) Grad: 123.1143  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 45m 51s (remain 8m 46s) Loss: 0.0029(0.0289) Grad: 169.2156  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 46m 52s (remain 7m 45s) Loss: 0.0021(0.0283) Grad: 120.1664  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 47m 53s (remain 6m 44s) Loss: 0.0040(0.0278) Grad: 296.6873  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 48m 54s (remain 5m 42s) Loss: 0.0032(0.0273) Grad: 342.4288  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 49m 55s (remain 4m 41s) Loss: 0.0004(0.0268) Grad: 33.3473  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 50m 56s (remain 3m 40s) Loss: 0.0002(0.0263) Grad: 17.6673  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 51m 58s (remain 2m 39s) Loss: 0.0235(0.0259) Grad: 840.1592  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 52m 59s (remain 1m 38s) Loss: 0.0001(0.0255) Grad: 11.6148  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 54m 1s (remain 0m 37s) Loss: 0.0039(0.0251) Grad: 194.2437  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 54m 38s (remain 0m 0s) Loss: 0.0077(0.0248) Grad: 344.7626  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 39s) Loss: 0.0003(0.0003) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0008(0.0029) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0006(0.0030) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0137(0.0029) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 47s) Loss: 0.0035(0.0031) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0002(0.0032) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0027(0.0031) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0042(0.0029) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0028(0.0029) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0099(0.0030) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0011(0.0033) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0004(0.0037) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0040(0.0037) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0003(0.0037) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0004(0.0037) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0004(0.0037) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0001(0.0036) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0021(0.0036) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0014(0.0035) \n","Epoch 1 - avg_train_loss: 0.0248  avg_val_loss: 0.0035  time: 3503s\n","Epoch 1 - Score: 0.8393\n","Epoch 1 - Save Best Score: 0.8393 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 91m 21s) Loss: 0.0004(0.0004) Grad: 818.6172  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 6s (remain 57m 29s) Loss: 0.0015(0.0032) Grad: 2715.1438  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 7s (remain 54m 42s) Loss: 0.0000(0.0029) Grad: 37.9444  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 9s (remain 53m 2s) Loss: 0.0038(0.0031) Grad: 15540.6670  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 10s (remain 51m 43s) Loss: 0.0009(0.0030) Grad: 2768.4126  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 12s (remain 50m 30s) Loss: 0.0000(0.0029) Grad: 14.5530  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 13s (remain 49m 21s) Loss: 0.0009(0.0030) Grad: 1961.8777  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 15s (remain 48m 13s) Loss: 0.0161(0.0029) Grad: 39434.1094  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 16s (remain 47m 7s) Loss: 0.0028(0.0029) Grad: 18952.4355  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 18s (remain 46m 3s) Loss: 0.0130(0.0030) Grad: 30940.0332  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 19s (remain 45m 0s) Loss: 0.0000(0.0030) Grad: 145.8502  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 21s (remain 43m 56s) Loss: 0.0011(0.0030) Grad: 4431.4609  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 22s (remain 42m 52s) Loss: 0.0011(0.0031) Grad: 2596.1648  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 23s (remain 41m 48s) Loss: 0.0012(0.0031) Grad: 3850.2131  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 25s (remain 40m 45s) Loss: 0.0065(0.0032) Grad: 15379.9746  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 26s (remain 39m 42s) Loss: 0.0030(0.0031) Grad: 8700.7002  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 27s (remain 38m 40s) Loss: 0.0000(0.0031) Grad: 93.8697  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 29s (remain 37m 38s) Loss: 0.0007(0.0031) Grad: 4351.4927  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 30s (remain 36m 35s) Loss: 0.0000(0.0031) Grad: 99.8303  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 31s (remain 35m 33s) Loss: 0.0117(0.0032) Grad: 24990.4355  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 33s (remain 34m 31s) Loss: 0.0000(0.0032) Grad: 77.5525  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 21m 34s (remain 33m 29s) Loss: 0.0075(0.0031) Grad: 9693.0664  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 22m 35s (remain 32m 27s) Loss: 0.0000(0.0031) Grad: 11.0490  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 23m 36s (remain 31m 24s) Loss: 0.0066(0.0031) Grad: 39680.4727  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 24m 38s (remain 30m 22s) Loss: 0.0208(0.0031) Grad: 20490.5137  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 25m 39s (remain 29m 20s) Loss: 0.0000(0.0031) Grad: 19.2368  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 26m 40s (remain 28m 18s) Loss: 0.0024(0.0031) Grad: 5338.6084  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 27m 41s (remain 27m 16s) Loss: 0.0001(0.0031) Grad: 259.4290  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 28m 42s (remain 26m 14s) Loss: 0.0134(0.0031) Grad: 13423.9785  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 29m 43s (remain 25m 12s) Loss: 0.0032(0.0031) Grad: 11771.8916  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 30m 44s (remain 24m 11s) Loss: 0.0038(0.0031) Grad: 8156.4517  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 31m 45s (remain 23m 9s) Loss: 0.0000(0.0031) Grad: 138.8783  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 32m 46s (remain 22m 7s) Loss: 0.0000(0.0031) Grad: 24.7962  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 33m 47s (remain 21m 5s) Loss: 0.0014(0.0031) Grad: 4365.7388  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 34m 48s (remain 20m 4s) Loss: 0.0000(0.0031) Grad: 208.2502  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 35m 49s (remain 19m 2s) Loss: 0.0000(0.0031) Grad: 9.9427  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 36m 50s (remain 18m 1s) Loss: 0.0000(0.0031) Grad: 125.2692  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 37m 52s (remain 16m 59s) Loss: 0.0030(0.0031) Grad: 4756.9902  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 38m 53s (remain 15m 58s) Loss: 0.0001(0.0031) Grad: 995.8201  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 39m 55s (remain 14m 56s) Loss: 0.0020(0.0031) Grad: 10343.7471  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 40m 56s (remain 13m 55s) Loss: 0.0001(0.0031) Grad: 308.8082  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 41m 57s (remain 12m 54s) Loss: 0.0000(0.0031) Grad: 18.4575  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 42m 58s (remain 11m 52s) Loss: 0.0000(0.0031) Grad: 23.5019  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 44m 0s (remain 10m 51s) Loss: 0.0002(0.0031) Grad: 1336.0203  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 45m 1s (remain 9m 49s) Loss: 0.0005(0.0031) Grad: 22233.3262  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 46m 3s (remain 8m 48s) Loss: 0.0000(0.0032) Grad: 19.4479  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 47m 5s (remain 7m 47s) Loss: 0.0001(0.0032) Grad: 509.2657  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 48m 6s (remain 6m 45s) Loss: 0.0117(0.0031) Grad: 65826.7422  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 49m 7s (remain 5m 44s) Loss: 0.0087(0.0031) Grad: 33363.4609  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 50m 9s (remain 4m 43s) Loss: 0.0013(0.0031) Grad: 5412.8335  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 51m 11s (remain 3m 41s) Loss: 0.0098(0.0031) Grad: 20518.1992  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 52m 13s (remain 2m 40s) Loss: 0.0136(0.0031) Grad: 20150.4590  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 53m 15s (remain 1m 38s) Loss: 0.0023(0.0031) Grad: 9429.8369  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 54m 17s (remain 0m 37s) Loss: 0.0000(0.0031) Grad: 4.3636  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 54m 54s (remain 0m 0s) Loss: 0.0001(0.0031) Grad: 1028.6045  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 45s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0000(0.0034) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0000(0.0039) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0109(0.0036) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0046(0.0039) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0039) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0023(0.0038) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0022(0.0035) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0020(0.0034) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0220(0.0035) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0001(0.0041) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0048) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0004(0.0047) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0000(0.0047) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0001(0.0046) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0001(0.0046) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0045) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0006(0.0044) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0000(0.0043) \n","Epoch 2 - avg_train_loss: 0.0031  avg_val_loss: 0.0043  time: 3514s\n","Epoch 2 - Score: 0.8664\n","Epoch 2 - Save Best Score: 0.8664 Model\n","Epoch: [3][0/5362] Elapsed 0m 1s (remain 90m 30s) Loss: 0.0000(0.0000) Grad: 997.2810  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 6s (remain 57m 30s) Loss: 0.0037(0.0019) Grad: 27948.5371  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 8s (remain 54m 50s) Loss: 0.0002(0.0021) Grad: 1315.9186  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 9s (remain 53m 5s) Loss: 0.0052(0.0024) Grad: 9681.7588  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 10s (remain 51m 42s) Loss: 0.0014(0.0023) Grad: 5343.7065  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 12s (remain 50m 27s) Loss: 0.0000(0.0023) Grad: 22.6820  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 13s (remain 49m 17s) Loss: 0.0012(0.0024) Grad: 1936.9904  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 14s (remain 48m 8s) Loss: 0.0001(0.0024) Grad: 1064.7698  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 15s (remain 47m 1s) Loss: 0.0005(0.0028) Grad: 1821.7058  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 16s (remain 45m 57s) Loss: 0.0007(0.0028) Grad: 2792.1003  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 18s (remain 44m 52s) Loss: 0.0004(0.0029) Grad: 1363.6266  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 19s (remain 43m 48s) Loss: 0.0080(0.0028) Grad: 50318.6289  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 20s (remain 42m 44s) Loss: 0.0001(0.0028) Grad: 204.9990  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 21s (remain 41m 42s) Loss: 0.0258(0.0029) Grad: 19968.6641  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 22s (remain 40m 39s) Loss: 0.0008(0.0028) Grad: 2516.0503  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 23s (remain 39m 36s) Loss: 0.0134(0.0028) Grad: 24245.6113  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 25s (remain 38m 34s) Loss: 0.0022(0.0028) Grad: 2744.4236  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 17m 26s (remain 37m 32s) Loss: 0.0124(0.0029) Grad: 26140.9746  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 18m 27s (remain 36m 30s) Loss: 0.0009(0.0030) Grad: 5631.0059  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 19m 28s (remain 35m 28s) Loss: 0.0000(0.0029) Grad: 55.9707  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 20m 29s (remain 34m 25s) Loss: 0.0125(0.0029) Grad: 23137.9297  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 21m 31s (remain 33m 23s) Loss: 0.0000(0.0029) Grad: 203.7530  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 22m 32s (remain 32m 21s) Loss: 0.0000(0.0029) Grad: 3.4536  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 23m 33s (remain 31m 20s) Loss: 0.0298(0.0029) Grad: 135369.0156  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 24m 34s (remain 30m 18s) Loss: 0.0060(0.0029) Grad: 7832.2651  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 25m 35s (remain 29m 16s) Loss: 0.0000(0.0028) Grad: 44.9685  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 26m 36s (remain 28m 14s) Loss: 0.0001(0.0028) Grad: 222.0514  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 27m 37s (remain 27m 13s) Loss: 0.0000(0.0028) Grad: 232.0306  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 28m 39s (remain 26m 11s) Loss: 0.0002(0.0028) Grad: 770.8334  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 29m 40s (remain 25m 10s) Loss: 0.0012(0.0029) Grad: 4098.2163  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 30m 41s (remain 24m 8s) Loss: 0.0000(0.0028) Grad: 73.6296  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 31m 42s (remain 23m 7s) Loss: 0.0000(0.0028) Grad: 50.6754  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 32m 43s (remain 22m 5s) Loss: 0.0077(0.0028) Grad: 12163.6758  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 33m 45s (remain 21m 4s) Loss: 0.0066(0.0028) Grad: 8924.0664  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 34m 46s (remain 20m 2s) Loss: 0.0134(0.0029) Grad: 32453.4336  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 35m 47s (remain 19m 1s) Loss: 0.0000(0.0029) Grad: 45.0249  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 36m 49s (remain 18m 0s) Loss: 0.0080(0.0029) Grad: 14653.3555  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 37m 50s (remain 16m 58s) Loss: 0.0009(0.0029) Grad: 5119.8433  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 38m 51s (remain 15m 57s) Loss: 0.0050(0.0028) Grad: 11102.4609  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 39m 52s (remain 14m 56s) Loss: 0.0000(0.0028) Grad: 10.1541  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 40m 54s (remain 13m 54s) Loss: 0.0000(0.0028) Grad: 37.8640  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 41m 55s (remain 12m 53s) Loss: 0.0011(0.0028) Grad: 9988.0713  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 42m 56s (remain 11m 52s) Loss: 0.0002(0.0028) Grad: 849.4724  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 43m 57s (remain 10m 50s) Loss: 0.0000(0.0028) Grad: 11.0063  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 44m 58s (remain 9m 49s) Loss: 0.0000(0.0028) Grad: 46.8428  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 46m 0s (remain 8m 47s) Loss: 0.0000(0.0028) Grad: 15.7578  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 47m 1s (remain 7m 46s) Loss: 0.0000(0.0029) Grad: 28.8377  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 48m 2s (remain 6m 45s) Loss: 0.0000(0.0028) Grad: 132.1472  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 49m 3s (remain 5m 43s) Loss: 0.0032(0.0028) Grad: 11493.2822  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 50m 4s (remain 4m 42s) Loss: 0.0000(0.0028) Grad: 19.9738  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 51m 6s (remain 3m 41s) Loss: 0.0000(0.0028) Grad: 6.6349  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 52m 7s (remain 2m 40s) Loss: 0.0030(0.0028) Grad: 28628.3008  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 53m 8s (remain 1m 38s) Loss: 0.0045(0.0028) Grad: 18349.1445  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 54m 9s (remain 0m 37s) Loss: 0.0000(0.0028) Grad: 151.4220  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 54m 47s (remain 0m 0s) Loss: 0.0000(0.0028) Grad: 518.3296  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 35s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0000(0.0039) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0000(0.0040) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 57s) Loss: 0.0238(0.0039) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0049(0.0042) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0000(0.0042) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 22s) Loss: 0.0023(0.0039) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 10s) Loss: 0.0038(0.0036) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 58s) Loss: 0.0029(0.0035) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 46s) Loss: 0.0003(0.0036) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0000(0.0042) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0049) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0002(0.0048) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0000(0.0049) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0048) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0048) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0046) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0028(0.0045) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0000(0.0045) \n","Epoch 3 - avg_train_loss: 0.0028  avg_val_loss: 0.0045  time: 3509s\n","Epoch 3 - Score: 0.8721\n","Epoch 3 - Save Best Score: 0.8721 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 83m 4s) Loss: 0.0000(0.0000) Grad: 535.6937  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 5s (remain 57m 14s) Loss: 0.0200(0.0036) Grad: 14535.5771  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 7s (remain 54m 21s) Loss: 0.0000(0.0025) Grad: 85.2440  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 8s (remain 52m 41s) Loss: 0.0000(0.0028) Grad: 46.2699  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 9s (remain 51m 23s) Loss: 0.0005(0.0024) Grad: 3037.8755  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 10s (remain 50m 11s) Loss: 0.0003(0.0023) Grad: 1508.6174  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 11s (remain 49m 3s) Loss: 0.0010(0.0023) Grad: 5368.7275  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 12s (remain 47m 57s) Loss: 0.0000(0.0022) Grad: 36.4594  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 14s (remain 46m 53s) Loss: 0.0001(0.0022) Grad: 697.6497  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 15s (remain 45m 49s) Loss: 0.0000(0.0021) Grad: 41.8638  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 16s (remain 44m 45s) Loss: 0.0132(0.0022) Grad: 11968.5898  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 17s (remain 43m 41s) Loss: 0.0000(0.0021) Grad: 116.3722  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 18s (remain 42m 38s) Loss: 0.0174(0.0022) Grad: 17604.1172  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 19s (remain 41m 35s) Loss: 0.0000(0.0022) Grad: 32.1023  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 21s (remain 40m 34s) Loss: 0.0171(0.0022) Grad: 19287.7520  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 22s (remain 39m 33s) Loss: 0.0019(0.0023) Grad: 5517.5493  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 23s (remain 38m 30s) Loss: 0.0000(0.0022) Grad: 86.1195  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 24s (remain 37m 28s) Loss: 0.0000(0.0022) Grad: 11.3625  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 25s (remain 36m 26s) Loss: 0.0013(0.0023) Grad: 7087.9609  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 26s (remain 35m 24s) Loss: 0.0000(0.0022) Grad: 9.1269  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 27s (remain 34m 22s) Loss: 0.0006(0.0022) Grad: 3174.0586  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 21m 28s (remain 33m 20s) Loss: 0.0014(0.0022) Grad: 7984.2690  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 22m 29s (remain 32m 18s) Loss: 0.0001(0.0022) Grad: 1094.4395  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 23m 30s (remain 31m 16s) Loss: 0.0001(0.0023) Grad: 447.3760  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 24m 31s (remain 30m 15s) Loss: 0.0084(0.0022) Grad: 8229.0693  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 25m 33s (remain 29m 13s) Loss: 0.0000(0.0023) Grad: 518.6838  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 26m 34s (remain 28m 12s) Loss: 0.0009(0.0023) Grad: 8904.4531  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 27m 36s (remain 27m 11s) Loss: 0.0000(0.0023) Grad: 46.1441  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 28m 36s (remain 26m 9s) Loss: 0.0001(0.0023) Grad: 308.6466  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 29m 37s (remain 25m 7s) Loss: 0.0000(0.0023) Grad: 4.9267  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 30m 38s (remain 24m 6s) Loss: 0.0000(0.0024) Grad: 177.5686  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 31m 39s (remain 23m 4s) Loss: 0.0000(0.0024) Grad: 6.3163  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 32m 40s (remain 22m 3s) Loss: 0.0000(0.0024) Grad: 30.3781  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 33m 40s (remain 21m 1s) Loss: 0.0005(0.0024) Grad: 5160.1523  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 34m 42s (remain 20m 0s) Loss: 0.0002(0.0024) Grad: 876.0420  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 35m 43s (remain 18m 59s) Loss: 0.0008(0.0024) Grad: 4266.5903  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 36m 45s (remain 17m 58s) Loss: 0.0011(0.0024) Grad: 3866.7229  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 37m 46s (remain 16m 57s) Loss: 0.0049(0.0024) Grad: 16452.6562  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 38m 47s (remain 15m 56s) Loss: 0.0006(0.0024) Grad: 6080.4673  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 39m 49s (remain 14m 54s) Loss: 0.0001(0.0024) Grad: 1379.3541  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 40m 50s (remain 13m 53s) Loss: 0.0002(0.0024) Grad: 1026.4010  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 41m 52s (remain 12m 52s) Loss: 0.0000(0.0024) Grad: 56.8905  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 42m 53s (remain 11m 51s) Loss: 0.0000(0.0024) Grad: 47.6527  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 43m 55s (remain 10m 50s) Loss: 0.0034(0.0024) Grad: 12467.9375  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 44m 57s (remain 9m 48s) Loss: 0.0003(0.0024) Grad: 1410.4023  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 45m 58s (remain 8m 47s) Loss: 0.0000(0.0024) Grad: 47.8256  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 47m 0s (remain 7m 46s) Loss: 0.0000(0.0024) Grad: 151.9154  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 48m 2s (remain 6m 45s) Loss: 0.0024(0.0024) Grad: 14365.3594  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 49m 3s (remain 5m 43s) Loss: 0.0044(0.0025) Grad: 6790.6807  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 50m 5s (remain 4m 42s) Loss: 0.0000(0.0024) Grad: 35.3085  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 51m 7s (remain 3m 41s) Loss: 0.0000(0.0024) Grad: 175.2462  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 52m 8s (remain 2m 40s) Loss: 0.0008(0.0024) Grad: 6832.7974  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 53m 9s (remain 1m 38s) Loss: 0.0011(0.0025) Grad: 2712.7383  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 54m 11s (remain 0m 37s) Loss: 0.0001(0.0025) Grad: 788.5587  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 54m 48s (remain 0m 0s) Loss: 0.0000(0.0025) Grad: 15.6723  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 21s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0000(0.0042) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0000(0.0042) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 57s) Loss: 0.0176(0.0039) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0051(0.0042) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0000(0.0042) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0022(0.0040) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0016(0.0037) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 58s) Loss: 0.0027(0.0036) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 46s) Loss: 0.0001(0.0037) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0000(0.0042) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0052) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0001(0.0051) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0000(0.0052) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0051) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0051) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0049) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0023(0.0048) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0000(0.0047) \n","Epoch 4 - avg_train_loss: 0.0025  avg_val_loss: 0.0047  time: 3507s\n","Epoch 4 - Score: 0.8798\n","Epoch 4 - Save Best Score: 0.8798 Model\n","Epoch: [5][0/5362] Elapsed 0m 1s (remain 90m 32s) Loss: 0.0046(0.0046) Grad: 43223.3164  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 5s (remain 57m 5s) Loss: 0.0060(0.0018) Grad: 21419.1367  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 6s (remain 54m 13s) Loss: 0.0001(0.0023) Grad: 397.0011  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 8s (remain 52m 44s) Loss: 0.0028(0.0021) Grad: 8311.5469  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 9s (remain 51m 28s) Loss: 0.0000(0.0024) Grad: 44.8713  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 11s (remain 50m 18s) Loss: 0.0000(0.0023) Grad: 7.3570  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 12s (remain 49m 13s) Loss: 0.0005(0.0021) Grad: 2617.0298  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 14s (remain 48m 9s) Loss: 0.0000(0.0021) Grad: 88.0413  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 16s (remain 47m 6s) Loss: 0.0036(0.0020) Grad: 7997.9385  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 18s (remain 46m 3s) Loss: 0.0247(0.0022) Grad: 43179.9844  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 19s (remain 44m 59s) Loss: 0.0006(0.0024) Grad: 3373.7534  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 21s (remain 43m 56s) Loss: 0.0001(0.0023) Grad: 860.6318  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 22s (remain 42m 53s) Loss: 0.0000(0.0023) Grad: 16.7575  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 24s (remain 41m 50s) Loss: 0.0000(0.0022) Grad: 20.0215  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 25s (remain 40m 47s) Loss: 0.0041(0.0022) Grad: 21345.7422  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 27s (remain 39m 45s) Loss: 0.0000(0.0022) Grad: 7.0284  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 29s (remain 38m 43s) Loss: 0.0017(0.0022) Grad: 10964.3447  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 30s (remain 37m 41s) Loss: 0.0000(0.0022) Grad: 129.3650  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 32s (remain 36m 38s) Loss: 0.0000(0.0022) Grad: 6.8765  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 33s (remain 35m 37s) Loss: 0.0311(0.0021) Grad: 164651.6719  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 35s (remain 34m 34s) Loss: 0.0006(0.0022) Grad: 4624.2939  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 37s (remain 33m 33s) Loss: 0.0007(0.0022) Grad: 5146.6118  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 38s (remain 32m 31s) Loss: 0.0000(0.0022) Grad: 128.0883  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 40s (remain 31m 29s) Loss: 0.0000(0.0022) Grad: 48.1730  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 41s (remain 30m 27s) Loss: 0.0004(0.0022) Grad: 2764.9312  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 43s (remain 29m 25s) Loss: 0.0000(0.0022) Grad: 2.6796  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 44s (remain 28m 23s) Loss: 0.0032(0.0022) Grad: 10925.9551  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 27m 46s (remain 27m 21s) Loss: 0.0001(0.0022) Grad: 1257.7057  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 28m 47s (remain 26m 19s) Loss: 0.0000(0.0022) Grad: 54.0750  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 29m 49s (remain 25m 17s) Loss: 0.0103(0.0022) Grad: 9171.6650  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 30m 50s (remain 24m 15s) Loss: 0.0000(0.0022) Grad: 126.9665  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 31m 52s (remain 23m 14s) Loss: 0.0000(0.0021) Grad: 5.3658  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 32m 53s (remain 22m 12s) Loss: 0.0000(0.0021) Grad: 41.3279  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 33m 55s (remain 21m 10s) Loss: 0.0000(0.0021) Grad: 3.4649  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 34m 56s (remain 20m 9s) Loss: 0.0000(0.0021) Grad: 321.9025  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 35m 58s (remain 19m 7s) Loss: 0.0000(0.0021) Grad: 16.6023  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 37m 0s (remain 18m 5s) Loss: 0.0000(0.0021) Grad: 2.8077  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 38m 2s (remain 17m 4s) Loss: 0.0002(0.0021) Grad: 753.7670  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 39m 4s (remain 16m 2s) Loss: 0.0123(0.0021) Grad: 15163.3359  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 40m 6s (remain 15m 1s) Loss: 0.0000(0.0021) Grad: 11.0823  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 41m 8s (remain 13m 59s) Loss: 0.0000(0.0021) Grad: 4.4841  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 42m 9s (remain 12m 57s) Loss: 0.0001(0.0021) Grad: 1152.1598  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 43m 11s (remain 11m 56s) Loss: 0.0080(0.0021) Grad: 32268.6836  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 44m 13s (remain 10m 54s) Loss: 0.0220(0.0021) Grad: 29016.0195  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 45m 15s (remain 9m 52s) Loss: 0.0000(0.0021) Grad: 2.5869  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 46m 17s (remain 8m 51s) Loss: 0.0151(0.0021) Grad: 21360.5586  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 47m 19s (remain 7m 49s) Loss: 0.0000(0.0021) Grad: 640.6002  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 48m 21s (remain 6m 47s) Loss: 0.0000(0.0021) Grad: 20.6591  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 49m 23s (remain 5m 46s) Loss: 0.0055(0.0021) Grad: 15385.0684  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 50m 25s (remain 4m 44s) Loss: 0.0000(0.0021) Grad: 89.5884  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 51m 27s (remain 3m 42s) Loss: 0.0000(0.0021) Grad: 206.4811  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 52m 29s (remain 2m 41s) Loss: 0.0000(0.0021) Grad: 3.6265  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 53m 31s (remain 1m 39s) Loss: 0.0000(0.0021) Grad: 9.3558  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 54m 32s (remain 0m 37s) Loss: 0.0000(0.0021) Grad: 41.7810  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 55m 10s (remain 0m 0s) Loss: 0.0001(0.0021) Grad: 440.3939  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 19s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 27s) Loss: 0.0000(0.0040) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0000(0.0040) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0178(0.0037) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 47s) Loss: 0.0051(0.0041) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0042) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0025(0.0040) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0029(0.0037) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0018(0.0036) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0002(0.0037) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0000(0.0042) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0000(0.0052) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0006(0.0051) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0000(0.0052) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0000(0.0051) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0000(0.0050) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0000(0.0049) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0018(0.0048) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0000(0.0047) \n","Epoch 5 - avg_train_loss: 0.0021  avg_val_loss: 0.0047  time: 3530s\n","Epoch 5 - Score: 0.8807\n","Epoch 5 - Save Best Score: 0.8807 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 111m 2s) Loss: 0.5674(0.5674) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 4s (remain 56m 3s) Loss: 0.1864(0.3282) Grad: 24175.2266  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 6s (remain 54m 12s) Loss: 0.3142(0.3006) Grad: 53088.5195  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 8s (remain 52m 54s) Loss: 0.3224(0.2724) Grad: 26908.8008  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 10s (remain 51m 42s) Loss: 0.0568(0.2364) Grad: 4217.9243  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 12s (remain 50m 35s) Loss: 0.0247(0.1994) Grad: 726.2867  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 14s (remain 49m 28s) Loss: 0.0259(0.1697) Grad: 773.4180  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 16s (remain 48m 24s) Loss: 0.0055(0.1483) Grad: 615.2310  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 18s (remain 47m 20s) Loss: 0.0042(0.1321) Grad: 524.4401  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 20s (remain 46m 16s) Loss: 0.0136(0.1194) Grad: 397.4151  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 22s (remain 45m 13s) Loss: 0.0356(0.1092) Grad: 936.1906  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 24s (remain 44m 10s) Loss: 0.0068(0.1005) Grad: 303.1999  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 26s (remain 43m 7s) Loss: 0.0215(0.0930) Grad: 1750.2611  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 28s (remain 42m 4s) Loss: 0.0086(0.0866) Grad: 1463.3154  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 30s (remain 41m 2s) Loss: 0.0039(0.0809) Grad: 259.7860  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 32s (remain 39m 58s) Loss: 0.0030(0.0761) Grad: 180.5629  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 34s (remain 38m 56s) Loss: 0.0078(0.0719) Grad: 971.5400  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 36s (remain 37m 54s) Loss: 0.0026(0.0682) Grad: 234.6800  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 38s (remain 36m 51s) Loss: 0.0354(0.0647) Grad: 3622.3369  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 40s (remain 35m 49s) Loss: 0.0033(0.0617) Grad: 516.5176  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 42s (remain 34m 46s) Loss: 0.0022(0.0589) Grad: 293.0146  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 44s (remain 33m 44s) Loss: 0.0064(0.0564) Grad: 563.3710  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 46s (remain 32m 41s) Loss: 0.0028(0.0541) Grad: 593.2542  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 23m 47s (remain 31m 39s) Loss: 0.0087(0.0520) Grad: 1005.3129  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 24m 49s (remain 30m 36s) Loss: 0.0093(0.0500) Grad: 1303.2904  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 25m 51s (remain 29m 34s) Loss: 0.0063(0.0482) Grad: 1152.7979  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 26m 52s (remain 28m 32s) Loss: 0.0061(0.0465) Grad: 769.3432  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 27m 55s (remain 27m 30s) Loss: 0.0005(0.0450) Grad: 107.3269  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 28m 57s (remain 26m 28s) Loss: 0.0037(0.0435) Grad: 417.4179  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 29m 58s (remain 25m 25s) Loss: 0.0003(0.0422) Grad: 56.1865  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 31m 0s (remain 24m 23s) Loss: 0.0132(0.0409) Grad: 2363.0425  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 32m 1s (remain 23m 21s) Loss: 0.0072(0.0397) Grad: 907.6332  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 33m 3s (remain 22m 19s) Loss: 0.0003(0.0386) Grad: 77.4651  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 34m 4s (remain 21m 16s) Loss: 0.0001(0.0376) Grad: 31.8363  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 35m 6s (remain 20m 14s) Loss: 0.0004(0.0366) Grad: 64.6172  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 36m 7s (remain 19m 12s) Loss: 0.0026(0.0357) Grad: 428.3192  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 37m 9s (remain 18m 10s) Loss: 0.0019(0.0348) Grad: 368.8462  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 38m 10s (remain 17m 8s) Loss: 0.0006(0.0340) Grad: 91.6799  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 39m 12s (remain 16m 6s) Loss: 0.0016(0.0332) Grad: 147.9919  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 40m 13s (remain 15m 4s) Loss: 0.0198(0.0325) Grad: 3042.2437  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 41m 15s (remain 14m 1s) Loss: 0.0025(0.0318) Grad: 255.2684  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 42m 16s (remain 13m 0s) Loss: 0.0004(0.0311) Grad: 413.7857  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 43m 18s (remain 11m 58s) Loss: 0.0047(0.0304) Grad: 746.4962  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 44m 19s (remain 10m 56s) Loss: 0.0123(0.0298) Grad: 1532.4017  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 45m 21s (remain 9m 54s) Loss: 0.0005(0.0292) Grad: 118.8868  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 46m 22s (remain 8m 52s) Loss: 0.0052(0.0287) Grad: 770.8002  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 47m 24s (remain 7m 50s) Loss: 0.0003(0.0281) Grad: 50.5460  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 48m 25s (remain 6m 48s) Loss: 0.0003(0.0276) Grad: 128.1659  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 49m 26s (remain 5m 46s) Loss: 0.0004(0.0271) Grad: 81.8048  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 50m 28s (remain 4m 44s) Loss: 0.0001(0.0266) Grad: 16.1165  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 51m 29s (remain 3m 43s) Loss: 0.0055(0.0262) Grad: 625.5585  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 52m 31s (remain 2m 41s) Loss: 0.0137(0.0257) Grad: 2204.9978  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 53m 32s (remain 1m 39s) Loss: 0.0022(0.0253) Grad: 198.5440  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 54m 34s (remain 0m 37s) Loss: 0.0004(0.0249) Grad: 89.6524  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 55m 12s (remain 0m 0s) Loss: 0.0097(0.0246) Grad: 1350.2267  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 54s) Loss: 0.0008(0.0008) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0026(0.0024) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0026(0.0026) \n","EVAL: [300/1788] Elapsed 0m 35s (remain 2m 57s) Loss: 0.0009(0.0029) \n","EVAL: [400/1788] Elapsed 0m 47s (remain 2m 45s) Loss: 0.0070(0.0041) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0002(0.0044) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0061(0.0042) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0032(0.0041) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0003(0.0040) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0636(0.0040) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0032(0.0041) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 21s) Loss: 0.0009(0.0043) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0034(0.0042) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0023(0.0042) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0042) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0001(0.0041) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0042(0.0040) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0000(0.0038) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0078(0.0037) \n","Epoch 1 - avg_train_loss: 0.0246  avg_val_loss: 0.0037  time: 3531s\n","Epoch 1 - Score: 0.8521\n","Epoch 1 - Save Best Score: 0.8521 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 101m 42s) Loss: 0.0008(0.0008) Grad: 1958.3276  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 6s (remain 57m 48s) Loss: 0.0001(0.0024) Grad: 154.0804  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 8s (remain 54m 50s) Loss: 0.0000(0.0021) Grad: 7.1045  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 9s (remain 53m 11s) Loss: 0.0084(0.0022) Grad: 12480.6709  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 11s (remain 51m 50s) Loss: 0.0155(0.0026) Grad: 10700.3955  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 12s (remain 50m 35s) Loss: 0.0010(0.0027) Grad: 2912.3970  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 14s (remain 49m 26s) Loss: 0.0046(0.0027) Grad: 6654.7534  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 16s (remain 48m 24s) Loss: 0.0063(0.0029) Grad: 18004.8398  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 17s (remain 47m 15s) Loss: 0.0000(0.0029) Grad: 56.9035  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 19s (remain 46m 9s) Loss: 0.0000(0.0030) Grad: 35.3071  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 20s (remain 45m 4s) Loss: 0.0138(0.0030) Grad: 15570.7695  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 22s (remain 44m 2s) Loss: 0.0003(0.0029) Grad: 1082.0204  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 24s (remain 43m 0s) Loss: 0.0001(0.0029) Grad: 461.3437  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 26s (remain 41m 56s) Loss: 0.0001(0.0030) Grad: 172.7769  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 27s (remain 40m 53s) Loss: 0.0065(0.0030) Grad: 10409.4434  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 29s (remain 39m 51s) Loss: 0.0025(0.0030) Grad: 3708.9414  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 31s (remain 38m 49s) Loss: 0.0002(0.0030) Grad: 720.5676  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 32s (remain 37m 46s) Loss: 0.0004(0.0029) Grad: 2150.8474  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 34s (remain 36m 43s) Loss: 0.0106(0.0030) Grad: 41851.1680  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 36s (remain 35m 41s) Loss: 0.0019(0.0030) Grad: 11947.0752  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 37s (remain 34m 39s) Loss: 0.0000(0.0030) Grad: 189.5533  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 21m 39s (remain 33m 37s) Loss: 0.0034(0.0030) Grad: 18241.4043  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 22m 41s (remain 32m 35s) Loss: 0.0038(0.0030) Grad: 11266.8359  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 23m 42s (remain 31m 32s) Loss: 0.0005(0.0031) Grad: 1361.1810  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 24m 44s (remain 30m 30s) Loss: 0.0001(0.0031) Grad: 483.5034  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 25m 46s (remain 29m 29s) Loss: 0.0000(0.0030) Grad: 11.8925  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 26m 48s (remain 28m 26s) Loss: 0.0094(0.0030) Grad: 17807.1738  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 27m 49s (remain 27m 24s) Loss: 0.0046(0.0031) Grad: 18574.4023  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 28m 51s (remain 26m 22s) Loss: 0.0000(0.0031) Grad: 87.8695  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 29m 52s (remain 25m 20s) Loss: 0.0026(0.0031) Grad: 21664.0156  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 30m 54s (remain 24m 18s) Loss: 0.0127(0.0031) Grad: 20142.7598  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 31m 55s (remain 23m 16s) Loss: 0.0025(0.0031) Grad: 5008.8315  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 32m 57s (remain 22m 15s) Loss: 0.0071(0.0031) Grad: 6395.3428  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 33m 59s (remain 21m 13s) Loss: 0.0008(0.0031) Grad: 3513.0229  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 35m 1s (remain 20m 11s) Loss: 0.0002(0.0031) Grad: 3034.3916  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 36m 3s (remain 19m 9s) Loss: 0.0211(0.0032) Grad: 151722.1875  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 37m 5s (remain 18m 8s) Loss: 0.0012(0.0032) Grad: 8731.4795  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 38m 7s (remain 17m 6s) Loss: 0.0014(0.0032) Grad: 5428.8818  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 39m 9s (remain 16m 4s) Loss: 0.0002(0.0032) Grad: 1559.9606  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 40m 11s (remain 15m 3s) Loss: 0.0010(0.0031) Grad: 9342.8896  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 41m 13s (remain 14m 1s) Loss: 0.0000(0.0031) Grad: 46.6572  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 42m 16s (remain 12m 59s) Loss: 0.0007(0.0031) Grad: 1858.8456  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 43m 17s (remain 11m 57s) Loss: 0.0010(0.0031) Grad: 4063.3665  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 44m 19s (remain 10m 56s) Loss: 0.0007(0.0031) Grad: 8396.9561  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 45m 22s (remain 9m 54s) Loss: 0.0000(0.0032) Grad: 64.3535  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 46m 24s (remain 8m 52s) Loss: 0.0000(0.0032) Grad: 71.9482  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 47m 26s (remain 7m 50s) Loss: 0.0003(0.0032) Grad: 1965.8442  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 48m 28s (remain 6m 48s) Loss: 0.0150(0.0032) Grad: 60898.0898  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 49m 29s (remain 5m 47s) Loss: 0.0091(0.0032) Grad: 39955.0000  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 50m 31s (remain 4m 45s) Loss: 0.0008(0.0032) Grad: 6189.7056  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 51m 33s (remain 3m 43s) Loss: 0.0000(0.0032) Grad: 298.4796  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 52m 34s (remain 2m 41s) Loss: 0.0160(0.0032) Grad: 32590.1719  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 53m 36s (remain 1m 39s) Loss: 0.0000(0.0032) Grad: 147.2973  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 54m 38s (remain 0m 37s) Loss: 0.0003(0.0032) Grad: 2253.7615  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 55m 15s (remain 0m 0s) Loss: 0.0160(0.0032) Grad: 29595.7988  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 22s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0014(0.0030) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0057(0.0033) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0001(0.0035) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0106(0.0054) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 34s) Loss: 0.0000(0.0058) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 22s) Loss: 0.0109(0.0056) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0030(0.0054) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0051) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0825(0.0051) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0008(0.0054) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0002(0.0056) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0037(0.0055) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0002(0.0054) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0053) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0052) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0006(0.0050) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0000(0.0049) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0199(0.0047) \n","Epoch 2 - avg_train_loss: 0.0032  avg_val_loss: 0.0047  time: 3538s\n","Epoch 2 - Score: 0.8668\n","Epoch 2 - Save Best Score: 0.8668 Model\n","Epoch: [3][0/5362] Elapsed 0m 0s (remain 87m 51s) Loss: 0.0000(0.0000) Grad: 996.8710  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 7s (remain 58m 15s) Loss: 0.0004(0.0027) Grad: 1993.1144  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 9s (remain 55m 12s) Loss: 0.0000(0.0031) Grad: 69.0702  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 10s (remain 53m 30s) Loss: 0.0000(0.0028) Grad: 29.6255  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 12s (remain 52m 9s) Loss: 0.0000(0.0029) Grad: 29.0157  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 15s (remain 50m 58s) Loss: 0.0000(0.0029) Grad: 138.5954  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 17s (remain 49m 53s) Loss: 0.0040(0.0028) Grad: 8097.6191  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 20s (remain 48m 45s) Loss: 0.0010(0.0029) Grad: 3764.4243  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 22s (remain 47m 39s) Loss: 0.0033(0.0029) Grad: 6886.3574  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 24s (remain 46m 32s) Loss: 0.0110(0.0029) Grad: 31450.5098  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 26s (remain 45m 27s) Loss: 0.0125(0.0030) Grad: 27547.5195  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 27s (remain 44m 21s) Loss: 0.0001(0.0028) Grad: 780.1652  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 29s (remain 43m 17s) Loss: 0.0001(0.0028) Grad: 708.3901  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 31s (remain 42m 12s) Loss: 0.0074(0.0028) Grad: 15904.3516  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 33s (remain 41m 8s) Loss: 0.0002(0.0028) Grad: 487.9916  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 34s (remain 40m 4s) Loss: 0.0000(0.0028) Grad: 2.9966  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 36s (remain 39m 1s) Loss: 0.0001(0.0028) Grad: 461.3398  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 17m 38s (remain 37m 57s) Loss: 0.0023(0.0028) Grad: 5803.3521  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 18m 40s (remain 36m 54s) Loss: 0.0000(0.0028) Grad: 8.0512  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 19m 42s (remain 35m 53s) Loss: 0.0033(0.0028) Grad: 22983.8516  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 20m 45s (remain 34m 52s) Loss: 0.0014(0.0028) Grad: 5267.8496  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 21m 48s (remain 33m 50s) Loss: 0.0001(0.0028) Grad: 278.5020  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 22m 51s (remain 32m 49s) Loss: 0.0015(0.0028) Grad: 5422.4873  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 23m 53s (remain 31m 47s) Loss: 0.0039(0.0028) Grad: 11280.9502  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 24m 55s (remain 30m 44s) Loss: 0.0008(0.0028) Grad: 9627.5439  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 25m 57s (remain 29m 41s) Loss: 0.0000(0.0028) Grad: 70.9149  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 27m 0s (remain 28m 40s) Loss: 0.0000(0.0028) Grad: 452.3825  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 28m 2s (remain 27m 37s) Loss: 0.0000(0.0028) Grad: 96.9288  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 29m 4s (remain 26m 34s) Loss: 0.0001(0.0028) Grad: 1184.5033  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 30m 6s (remain 25m 32s) Loss: 0.0011(0.0028) Grad: 4669.4595  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 31m 7s (remain 24m 29s) Loss: 0.0000(0.0027) Grad: 190.5668  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 32m 9s (remain 23m 26s) Loss: 0.0000(0.0027) Grad: 5.2946  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 33m 11s (remain 22m 24s) Loss: 0.0142(0.0027) Grad: 19897.3359  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 34m 13s (remain 21m 22s) Loss: 0.0000(0.0027) Grad: 32.1124  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 35m 15s (remain 20m 20s) Loss: 0.0001(0.0027) Grad: 308.0610  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 36m 17s (remain 19m 17s) Loss: 0.0001(0.0027) Grad: 1995.6277  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 37m 19s (remain 18m 15s) Loss: 0.0005(0.0027) Grad: 1557.9563  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 38m 21s (remain 17m 12s) Loss: 0.0035(0.0027) Grad: 5720.4600  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 39m 23s (remain 16m 10s) Loss: 0.0000(0.0027) Grad: 13.7286  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 40m 25s (remain 15m 8s) Loss: 0.0001(0.0027) Grad: 341.0069  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 41m 27s (remain 14m 6s) Loss: 0.0043(0.0028) Grad: 5562.6226  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 42m 30s (remain 13m 4s) Loss: 0.0052(0.0028) Grad: 4207.0356  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 43m 32s (remain 12m 1s) Loss: 0.0037(0.0028) Grad: 5449.5181  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 44m 34s (remain 10m 59s) Loss: 0.0014(0.0028) Grad: 5701.6025  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 45m 36s (remain 9m 57s) Loss: 0.0013(0.0028) Grad: 4965.5854  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 46m 38s (remain 8m 55s) Loss: 0.0035(0.0028) Grad: 5705.5938  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 47m 40s (remain 7m 53s) Loss: 0.0000(0.0028) Grad: 32.3927  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 48m 41s (remain 6m 50s) Loss: 0.0000(0.0028) Grad: 11.6657  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 49m 43s (remain 5m 48s) Loss: 0.0101(0.0028) Grad: 26855.2773  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 50m 45s (remain 4m 46s) Loss: 0.0002(0.0028) Grad: 1683.1144  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 51m 46s (remain 3m 44s) Loss: 0.0000(0.0028) Grad: 20.8350  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 52m 48s (remain 2m 42s) Loss: 0.0053(0.0028) Grad: 19699.5723  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 53m 50s (remain 1m 39s) Loss: 0.0000(0.0028) Grad: 38.5575  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 54m 52s (remain 0m 37s) Loss: 0.0000(0.0027) Grad: 19.1227  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 55m 29s (remain 0m 0s) Loss: 0.0003(0.0027) Grad: 1167.2925  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 36s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0004(0.0031) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0011(0.0030) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0001(0.0033) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0137(0.0051) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 34s) Loss: 0.0000(0.0056) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0118(0.0053) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0041(0.0052) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0050) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0731(0.0050) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 33s) Loss: 0.0007(0.0053) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0004(0.0056) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0111(0.0055) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0003(0.0054) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0052) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0051) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0007(0.0050) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0000(0.0048) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0251(0.0047) \n","Epoch 3 - avg_train_loss: 0.0027  avg_val_loss: 0.0047  time: 3549s\n","Epoch 3 - Score: 0.8732\n","Epoch 3 - Save Best Score: 0.8732 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 86m 57s) Loss: 0.0000(0.0000) Grad: 1000.2356  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 6s (remain 57m 49s) Loss: 0.0000(0.0016) Grad: 131.1207  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 8s (remain 54m 51s) Loss: 0.0000(0.0021) Grad: 176.3581  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 9s (remain 53m 12s) Loss: 0.0048(0.0020) Grad: 8144.4263  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 11s (remain 51m 52s) Loss: 0.0000(0.0019) Grad: 27.5218  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 13s (remain 50m 37s) Loss: 0.0000(0.0019) Grad: 71.7911  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 14s (remain 49m 28s) Loss: 0.0002(0.0019) Grad: 1168.1464  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 16s (remain 48m 20s) Loss: 0.0025(0.0018) Grad: 7454.5601  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 17s (remain 47m 12s) Loss: 0.0000(0.0019) Grad: 123.3275  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 19s (remain 46m 7s) Loss: 0.0020(0.0019) Grad: 5570.7603  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 20s (remain 45m 2s) Loss: 0.0057(0.0020) Grad: 9735.0352  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 21s (remain 43m 58s) Loss: 0.0005(0.0020) Grad: 11636.0059  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 23s (remain 42m 54s) Loss: 0.0000(0.0020) Grad: 191.5784  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 24s (remain 41m 51s) Loss: 0.0005(0.0020) Grad: 2379.0730  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 26s (remain 40m 49s) Loss: 0.0000(0.0020) Grad: 188.7964  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 27s (remain 39m 46s) Loss: 0.0000(0.0021) Grad: 21.6235  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 29s (remain 38m 43s) Loss: 0.0001(0.0021) Grad: 334.6466  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 30s (remain 37m 40s) Loss: 0.0006(0.0021) Grad: 3021.5166  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 32s (remain 36m 39s) Loss: 0.0000(0.0021) Grad: 101.3672  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 34s (remain 35m 38s) Loss: 0.0000(0.0022) Grad: 27.8073  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 35s (remain 34m 35s) Loss: 0.0000(0.0022) Grad: 412.6408  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 21m 37s (remain 33m 33s) Loss: 0.0000(0.0022) Grad: 110.9551  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 22m 39s (remain 32m 32s) Loss: 0.0000(0.0022) Grad: 13.9283  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 23m 40s (remain 31m 29s) Loss: 0.0001(0.0022) Grad: 928.1200  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 24m 42s (remain 30m 27s) Loss: 0.0038(0.0022) Grad: 3896.6477  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 25m 43s (remain 29m 25s) Loss: 0.0018(0.0022) Grad: 11618.1055  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 26m 45s (remain 28m 23s) Loss: 0.0000(0.0023) Grad: 58.8816  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 27m 46s (remain 27m 22s) Loss: 0.0001(0.0022) Grad: 265.3851  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 28m 48s (remain 26m 20s) Loss: 0.0000(0.0023) Grad: 12.4555  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 29m 49s (remain 25m 18s) Loss: 0.0102(0.0023) Grad: 72639.9688  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 30m 51s (remain 24m 16s) Loss: 0.0009(0.0023) Grad: 4157.8887  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 31m 53s (remain 23m 15s) Loss: 0.0000(0.0023) Grad: 5.2064  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 32m 54s (remain 22m 13s) Loss: 0.0000(0.0023) Grad: 19.5051  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 33m 56s (remain 21m 11s) Loss: 0.0025(0.0023) Grad: 15484.6104  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 34m 58s (remain 20m 9s) Loss: 0.0000(0.0023) Grad: 4.7054  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 36m 0s (remain 19m 8s) Loss: 0.0008(0.0023) Grad: 3311.5310  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 37m 1s (remain 18m 6s) Loss: 0.0000(0.0023) Grad: 167.3976  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 38m 3s (remain 17m 4s) Loss: 0.0000(0.0023) Grad: 16.0558  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 39m 5s (remain 16m 3s) Loss: 0.0001(0.0023) Grad: 1704.1782  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 40m 7s (remain 15m 1s) Loss: 0.0000(0.0024) Grad: 98.4616  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 41m 9s (remain 14m 0s) Loss: 0.0000(0.0024) Grad: 187.4734  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 42m 11s (remain 12m 58s) Loss: 0.0007(0.0023) Grad: 6104.2407  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 43m 13s (remain 11m 56s) Loss: 0.0007(0.0023) Grad: 2322.9954  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 44m 14s (remain 10m 54s) Loss: 0.0001(0.0023) Grad: 646.8205  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 45m 16s (remain 9m 53s) Loss: 0.0005(0.0023) Grad: 4974.1265  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 46m 18s (remain 8m 51s) Loss: 0.0000(0.0023) Grad: 11.7234  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 47m 20s (remain 7m 49s) Loss: 0.0000(0.0023) Grad: 44.4108  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 48m 22s (remain 6m 48s) Loss: 0.0062(0.0023) Grad: 13214.7988  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 49m 24s (remain 5m 46s) Loss: 0.0098(0.0023) Grad: 65172.8125  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 50m 26s (remain 4m 44s) Loss: 0.0066(0.0023) Grad: 28468.4102  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 51m 28s (remain 3m 42s) Loss: 0.0000(0.0023) Grad: 20.7002  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 52m 30s (remain 2m 41s) Loss: 0.0000(0.0023) Grad: 40.0310  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 53m 32s (remain 1m 39s) Loss: 0.0001(0.0024) Grad: 466.9670  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 54m 34s (remain 0m 37s) Loss: 0.0004(0.0023) Grad: 5031.0850  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 55m 11s (remain 0m 0s) Loss: 0.0000(0.0023) Grad: 965.0602  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 43s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0002(0.0033) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0006(0.0032) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 57s) Loss: 0.0001(0.0035) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0154(0.0053) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0000(0.0059) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 22s) Loss: 0.0136(0.0055) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0043(0.0054) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0051) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0761(0.0051) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0011(0.0056) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0059) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0136(0.0057) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0003(0.0055) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0054) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0053) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0006(0.0051) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0000(0.0050) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0248(0.0048) \n","Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0048  time: 3531s\n","Epoch 4 - Score: 0.8780\n","Epoch 4 - Save Best Score: 0.8780 Model\n","Epoch: [5][0/5362] Elapsed 0m 0s (remain 86m 3s) Loss: 0.0000(0.0000) Grad: 967.5441  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 6s (remain 58m 8s) Loss: 0.0000(0.0024) Grad: 14.8950  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 9s (remain 55m 17s) Loss: 0.0000(0.0025) Grad: 10.2034  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 11s (remain 53m 39s) Loss: 0.0000(0.0021) Grad: 13.0167  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 13s (remain 52m 18s) Loss: 0.0000(0.0020) Grad: 3.7978  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 15s (remain 51m 3s) Loss: 0.0407(0.0022) Grad: 40759.8984  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 17s (remain 49m 53s) Loss: 0.0043(0.0021) Grad: 9269.2090  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 19s (remain 48m 44s) Loss: 0.0006(0.0020) Grad: 17718.6230  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 21s (remain 47m 38s) Loss: 0.0007(0.0020) Grad: 3027.5684  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 23s (remain 46m 32s) Loss: 0.0000(0.0019) Grad: 8.2258  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 25s (remain 45m 26s) Loss: 0.0155(0.0019) Grad: 30409.2578  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 27s (remain 44m 22s) Loss: 0.0000(0.0019) Grad: 11.2530  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 30s (remain 43m 18s) Loss: 0.0000(0.0019) Grad: 55.5628  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 31s (remain 42m 14s) Loss: 0.0045(0.0019) Grad: 3973.5044  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 33s (remain 41m 10s) Loss: 0.0001(0.0018) Grad: 629.6924  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 35s (remain 40m 7s) Loss: 0.0001(0.0019) Grad: 560.9402  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 37s (remain 39m 3s) Loss: 0.0016(0.0019) Grad: 8945.4531  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 39s (remain 38m 0s) Loss: 0.0000(0.0020) Grad: 122.3081  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 41s (remain 36m 57s) Loss: 0.0092(0.0020) Grad: 20702.2363  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 43s (remain 35m 54s) Loss: 0.0000(0.0020) Grad: 11.5830  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 45s (remain 34m 51s) Loss: 0.0109(0.0020) Grad: 9451.1309  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 47s (remain 33m 49s) Loss: 0.0000(0.0019) Grad: 10.7036  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 49s (remain 32m 46s) Loss: 0.0000(0.0019) Grad: 2.4536  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 51s (remain 31m 44s) Loss: 0.0002(0.0020) Grad: 1331.8896  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 53s (remain 30m 41s) Loss: 0.0000(0.0020) Grad: 1.9049  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 55s (remain 29m 39s) Loss: 0.0006(0.0020) Grad: 4432.9868  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 57s (remain 28m 36s) Loss: 0.0025(0.0021) Grad: 3180.0710  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 27m 58s (remain 27m 33s) Loss: 0.0000(0.0020) Grad: 45.1131  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 29m 0s (remain 26m 31s) Loss: 0.0005(0.0020) Grad: 2619.2563  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 30m 2s (remain 25m 29s) Loss: 0.0001(0.0020) Grad: 790.8170  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 31m 4s (remain 24m 27s) Loss: 0.0002(0.0021) Grad: 971.7550  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 32m 6s (remain 23m 24s) Loss: 0.0049(0.0020) Grad: 11926.8193  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 33m 8s (remain 22m 22s) Loss: 0.0000(0.0020) Grad: 18.2741  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 34m 10s (remain 21m 20s) Loss: 0.0000(0.0020) Grad: 4.1767  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 35m 12s (remain 20m 17s) Loss: 0.0000(0.0021) Grad: 125.5875  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 36m 13s (remain 19m 15s) Loss: 0.0000(0.0021) Grad: 10.5752  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 37m 15s (remain 18m 13s) Loss: 0.0010(0.0021) Grad: 4504.3740  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 38m 17s (remain 17m 11s) Loss: 0.0000(0.0020) Grad: 5.8154  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 39m 19s (remain 16m 8s) Loss: 0.0010(0.0021) Grad: 3481.9900  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 40m 21s (remain 15m 6s) Loss: 0.0014(0.0021) Grad: 2882.0403  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 41m 23s (remain 14m 4s) Loss: 0.0000(0.0021) Grad: 121.5439  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 42m 24s (remain 13m 2s) Loss: 0.0001(0.0021) Grad: 404.7327  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 43m 26s (remain 12m 0s) Loss: 0.0055(0.0021) Grad: 80517.5859  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 44m 28s (remain 10m 58s) Loss: 0.0000(0.0021) Grad: 23.0754  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 45m 30s (remain 9m 56s) Loss: 0.0012(0.0021) Grad: 18100.1504  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 46m 32s (remain 8m 54s) Loss: 0.0128(0.0021) Grad: 13529.3184  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 47m 34s (remain 7m 52s) Loss: 0.0001(0.0021) Grad: 384.8100  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 48m 36s (remain 6m 50s) Loss: 0.0000(0.0021) Grad: 32.5263  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 49m 38s (remain 5m 48s) Loss: 0.0000(0.0021) Grad: 28.3613  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 50m 40s (remain 4m 45s) Loss: 0.0018(0.0021) Grad: 25228.3828  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 51m 41s (remain 3m 43s) Loss: 0.0002(0.0021) Grad: 1827.0016  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 52m 43s (remain 2m 41s) Loss: 0.0007(0.0021) Grad: 5385.8984  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 53m 45s (remain 1m 39s) Loss: 0.0015(0.0021) Grad: 9849.2090  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 54m 47s (remain 0m 37s) Loss: 0.0000(0.0021) Grad: 28.0236  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 55m 25s (remain 0m 0s) Loss: 0.0006(0.0021) Grad: 8610.6592  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 33s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0003(0.0039) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0004(0.0035) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0000(0.0036) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0151(0.0054) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 34s) Loss: 0.0000(0.0060) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 22s) Loss: 0.0151(0.0056) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 9s) Loss: 0.0043(0.0055) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 57s) Loss: 0.0000(0.0052) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 45s) Loss: 0.0643(0.0052) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0011(0.0057) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0004(0.0060) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0116(0.0058) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0002(0.0057) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0000(0.0055) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0054) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0005(0.0053) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0000(0.0051) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0266(0.0049) \n","Epoch 5 - avg_train_loss: 0.0021  avg_val_loss: 0.0049  time: 3545s\n","Epoch 5 - Score: 0.8777\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 101m 7s) Loss: 0.2624(0.2624) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 3s (remain 54m 55s) Loss: 0.1710(0.2789) Grad: 10774.3750  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 5s (remain 53m 36s) Loss: 0.2696(0.2690) Grad: 7653.6787  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 7s (remain 52m 29s) Loss: 0.0725(0.2341) Grad: 2631.4282  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 9s (remain 51m 26s) Loss: 0.0517(0.1930) Grad: 1241.0089  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 11s (remain 50m 22s) Loss: 0.0266(0.1592) Grad: 264.9115  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 13s (remain 49m 20s) Loss: 0.0074(0.1363) Grad: 163.2415  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 15s (remain 48m 17s) Loss: 0.0173(0.1198) Grad: 177.1005  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 18s (remain 47m 16s) Loss: 0.0256(0.1072) Grad: 341.5981  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 20s (remain 46m 13s) Loss: 0.0337(0.0973) Grad: 430.7700  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 22s (remain 45m 11s) Loss: 0.0061(0.0893) Grad: 189.1773  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 24s (remain 44m 9s) Loss: 0.0082(0.0827) Grad: 114.6288  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 26s (remain 43m 6s) Loss: 0.0066(0.0768) Grad: 172.3965  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 28s (remain 42m 3s) Loss: 0.0029(0.0716) Grad: 194.0889  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 30s (remain 41m 1s) Loss: 0.0033(0.0672) Grad: 200.1416  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 32s (remain 39m 58s) Loss: 0.0080(0.0633) Grad: 335.8320  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 34s (remain 38m 55s) Loss: 0.0031(0.0598) Grad: 351.1342  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 35s (remain 37m 52s) Loss: 0.0168(0.0566) Grad: 1262.2155  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 37s (remain 36m 49s) Loss: 0.0011(0.0538) Grad: 72.2572  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 38s (remain 35m 46s) Loss: 0.0036(0.0513) Grad: 273.1503  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 40s (remain 34m 43s) Loss: 0.0018(0.0490) Grad: 213.0677  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 41s (remain 33m 40s) Loss: 0.0045(0.0469) Grad: 591.4200  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 43s (remain 32m 38s) Loss: 0.0008(0.0450) Grad: 47.7107  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 23m 44s (remain 31m 35s) Loss: 0.0013(0.0433) Grad: 152.0948  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 24m 45s (remain 30m 32s) Loss: 0.0007(0.0417) Grad: 53.5737  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 25m 47s (remain 29m 29s) Loss: 0.0102(0.0403) Grad: 652.3644  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 26m 48s (remain 28m 27s) Loss: 0.0068(0.0389) Grad: 366.8253  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 27m 50s (remain 27m 25s) Loss: 0.0072(0.0377) Grad: 244.7582  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 28m 51s (remain 26m 23s) Loss: 0.0023(0.0365) Grad: 155.9599  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 29m 53s (remain 25m 21s) Loss: 0.0163(0.0354) Grad: 658.2961  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 30m 55s (remain 24m 19s) Loss: 0.0007(0.0344) Grad: 246.6994  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 31m 56s (remain 23m 17s) Loss: 0.0004(0.0335) Grad: 37.2300  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 32m 58s (remain 22m 15s) Loss: 0.0073(0.0325) Grad: 216.8431  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 34m 0s (remain 21m 14s) Loss: 0.0054(0.0317) Grad: 488.3252  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 35m 2s (remain 20m 12s) Loss: 0.0006(0.0309) Grad: 42.7725  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 36m 3s (remain 19m 10s) Loss: 0.0093(0.0301) Grad: 226.9748  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 37m 5s (remain 18m 8s) Loss: 0.0002(0.0294) Grad: 20.3406  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 38m 6s (remain 17m 6s) Loss: 0.0005(0.0287) Grad: 43.9341  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 39m 8s (remain 16m 4s) Loss: 0.0033(0.0280) Grad: 144.4802  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 40m 9s (remain 15m 2s) Loss: 0.0002(0.0275) Grad: 21.4333  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 41m 11s (remain 14m 0s) Loss: 0.0028(0.0269) Grad: 240.2433  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 42m 12s (remain 12m 58s) Loss: 0.0074(0.0264) Grad: 331.3254  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 43m 14s (remain 11m 56s) Loss: 0.0097(0.0258) Grad: 323.1671  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 44m 15s (remain 10m 55s) Loss: 0.0045(0.0253) Grad: 242.9621  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 45m 17s (remain 9m 53s) Loss: 0.0003(0.0248) Grad: 24.6342  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 46m 19s (remain 8m 51s) Loss: 0.0164(0.0244) Grad: 1463.5433  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 47m 21s (remain 7m 49s) Loss: 0.0000(0.0239) Grad: 0.7832  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 48m 22s (remain 6m 48s) Loss: 0.0005(0.0235) Grad: 28.9692  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 49m 24s (remain 5m 46s) Loss: 0.0035(0.0230) Grad: 377.0552  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 50m 25s (remain 4m 44s) Loss: 0.0014(0.0226) Grad: 129.1008  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 51m 27s (remain 3m 42s) Loss: 0.0003(0.0223) Grad: 41.6463  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 52m 28s (remain 2m 41s) Loss: 0.0031(0.0219) Grad: 180.9678  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 53m 30s (remain 1m 39s) Loss: 0.0005(0.0216) Grad: 41.3598  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 54m 31s (remain 0m 37s) Loss: 0.0286(0.0212) Grad: 751.6005  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 55m 9s (remain 0m 0s) Loss: 0.0000(0.0210) Grad: 18.9242  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 13m 57s) Loss: 0.0008(0.0008) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0003(0.0029) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0032(0.0032) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0054(0.0030) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0000(0.0030) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0159(0.0033) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 22s) Loss: 0.0033(0.0033) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 10s) Loss: 0.0040(0.0032) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 58s) Loss: 0.0001(0.0030) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 46s) Loss: 0.0031(0.0032) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0148(0.0034) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0004(0.0036) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0025(0.0036) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0021(0.0036) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0223(0.0036) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0173(0.0036) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0035) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0005(0.0034) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0007(0.0033) \n","Epoch 1 - avg_train_loss: 0.0210  avg_val_loss: 0.0033  time: 3529s\n","Epoch 1 - Score: 0.8558\n","Epoch 1 - Save Best Score: 0.8558 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 97m 4s) Loss: 0.0256(0.0256) Grad: 24513.2969  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 7s (remain 58m 14s) Loss: 0.0011(0.0033) Grad: 1516.2354  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 8s (remain 54m 59s) Loss: 0.0001(0.0032) Grad: 358.3332  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 10s (remain 53m 16s) Loss: 0.0057(0.0031) Grad: 11452.3672  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 11s (remain 51m 53s) Loss: 0.0001(0.0032) Grad: 947.1505  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 13s (remain 50m 40s) Loss: 0.0001(0.0036) Grad: 918.1805  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 15s (remain 49m 31s) Loss: 0.0000(0.0036) Grad: 107.9417  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 17s (remain 48m 27s) Loss: 0.0013(0.0035) Grad: 4583.3525  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 19s (remain 47m 24s) Loss: 0.0031(0.0034) Grad: 11422.1680  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 22s (remain 46m 25s) Loss: 0.0000(0.0034) Grad: 167.8048  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 25s (remain 45m 25s) Loss: 0.0002(0.0033) Grad: 514.3973  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 28s (remain 44m 23s) Loss: 0.0047(0.0033) Grad: 24513.5742  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 31s (remain 43m 22s) Loss: 0.0000(0.0034) Grad: 14.7801  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 33s (remain 42m 20s) Loss: 0.0002(0.0033) Grad: 923.7281  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 36s (remain 41m 19s) Loss: 0.0023(0.0034) Grad: 5530.5557  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 39s (remain 40m 17s) Loss: 0.0000(0.0034) Grad: 49.9526  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 42s (remain 39m 15s) Loss: 0.0001(0.0033) Grad: 1038.2648  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 45s (remain 38m 12s) Loss: 0.0040(0.0033) Grad: 4451.5635  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 47s (remain 37m 10s) Loss: 0.0000(0.0032) Grad: 156.0935  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 50s (remain 36m 7s) Loss: 0.0000(0.0032) Grad: 174.2094  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 53s (remain 35m 5s) Loss: 0.0000(0.0032) Grad: 197.6913  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 21m 56s (remain 34m 3s) Loss: 0.0000(0.0032) Grad: 232.8049  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 23m 0s (remain 33m 2s) Loss: 0.0044(0.0032) Grad: 15916.0371  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 24m 3s (remain 32m 0s) Loss: 0.0005(0.0032) Grad: 1229.3468  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 25m 6s (remain 30m 58s) Loss: 0.0000(0.0032) Grad: 31.5368  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 26m 9s (remain 29m 55s) Loss: 0.0075(0.0032) Grad: 15361.5098  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 27m 12s (remain 28m 52s) Loss: 0.0000(0.0032) Grad: 80.0537  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 28m 15s (remain 27m 50s) Loss: 0.0000(0.0032) Grad: 78.8406  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 29m 17s (remain 26m 47s) Loss: 0.0000(0.0031) Grad: 9.5807  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 30m 20s (remain 25m 44s) Loss: 0.0000(0.0032) Grad: 162.1016  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 31m 23s (remain 24m 41s) Loss: 0.0000(0.0032) Grad: 19.6404  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 32m 26s (remain 23m 38s) Loss: 0.0058(0.0032) Grad: 38333.6797  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 33m 28s (remain 22m 36s) Loss: 0.0093(0.0032) Grad: 18345.0391  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 34m 31s (remain 21m 33s) Loss: 0.0067(0.0032) Grad: 17876.2090  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 35m 34s (remain 20m 30s) Loss: 0.0000(0.0032) Grad: 201.7229  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 36m 36s (remain 19m 27s) Loss: 0.0013(0.0031) Grad: 4753.0283  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 37m 39s (remain 18m 25s) Loss: 0.0002(0.0032) Grad: 2096.9934  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 38m 42s (remain 17m 22s) Loss: 0.0020(0.0032) Grad: 7125.6460  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 39m 44s (remain 16m 19s) Loss: 0.0021(0.0032) Grad: 3306.5120  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 40m 47s (remain 15m 16s) Loss: 0.0385(0.0032) Grad: 26726.7051  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 41m 50s (remain 14m 13s) Loss: 0.0030(0.0032) Grad: 7954.8276  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 42m 53s (remain 13m 11s) Loss: 0.0004(0.0032) Grad: 1198.7905  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 43m 55s (remain 12m 8s) Loss: 0.0009(0.0032) Grad: 2955.2114  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 44m 58s (remain 11m 5s) Loss: 0.0058(0.0032) Grad: 14621.0244  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 46m 1s (remain 10m 3s) Loss: 0.0004(0.0032) Grad: 2177.1196  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 47m 4s (remain 9m 0s) Loss: 0.0000(0.0032) Grad: 182.5498  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 48m 7s (remain 7m 57s) Loss: 0.0000(0.0032) Grad: 6.0191  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 49m 10s (remain 6m 54s) Loss: 0.0079(0.0031) Grad: 27033.2676  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 50m 13s (remain 5m 52s) Loss: 0.0000(0.0031) Grad: 75.5301  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 51m 16s (remain 4m 49s) Loss: 0.0004(0.0031) Grad: 4743.1235  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 52m 20s (remain 3m 46s) Loss: 0.0079(0.0031) Grad: 9340.6328  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 53m 23s (remain 2m 43s) Loss: 0.0016(0.0031) Grad: 4271.7783  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 54m 26s (remain 1m 41s) Loss: 0.0020(0.0031) Grad: 13953.9600  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 55m 30s (remain 0m 38s) Loss: 0.0004(0.0031) Grad: 8829.6123  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 56m 8s (remain 0m 0s) Loss: 0.0001(0.0031) Grad: 1143.9556  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 54s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 27s) Loss: 0.0001(0.0040) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 12s) Loss: 0.0073(0.0040) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0070(0.0037) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 47s) Loss: 0.0000(0.0037) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0242(0.0042) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0008(0.0041) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0034(0.0040) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0000(0.0037) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0034(0.0039) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 35s) Loss: 0.0021(0.0040) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0000(0.0042) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0007(0.0042) \n","EVAL: [1300/1788] Elapsed 2m 37s (remain 0m 58s) Loss: 0.0003(0.0042) \n","EVAL: [1400/1788] Elapsed 2m 49s (remain 0m 46s) Loss: 0.0217(0.0042) \n","EVAL: [1500/1788] Elapsed 3m 1s (remain 0m 34s) Loss: 0.0223(0.0041) \n","EVAL: [1600/1788] Elapsed 3m 13s (remain 0m 22s) Loss: 0.0000(0.0039) \n","EVAL: [1700/1788] Elapsed 3m 25s (remain 0m 10s) Loss: 0.0002(0.0038) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0001(0.0038) \n","Epoch 2 - avg_train_loss: 0.0031  avg_val_loss: 0.0038  time: 3590s\n","Epoch 2 - Score: 0.8813\n","Epoch 2 - Save Best Score: 0.8813 Model\n","Epoch: [3][0/5362] Elapsed 0m 1s (remain 92m 10s) Loss: 0.0005(0.0005) Grad: 4174.7451  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 8s (remain 59m 53s) Loss: 0.0013(0.0022) Grad: 3101.0886  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 12s (remain 56m 41s) Loss: 0.0000(0.0026) Grad: 74.7924  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 15s (remain 54m 52s) Loss: 0.0002(0.0027) Grad: 540.6954  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 19s (remain 53m 26s) Loss: 0.0008(0.0029) Grad: 2422.5134  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 22s (remain 52m 8s) Loss: 0.0000(0.0027) Grad: 33.0536  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 26s (remain 50m 58s) Loss: 0.0056(0.0028) Grad: 12404.2822  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 29s (remain 49m 48s) Loss: 0.0000(0.0027) Grad: 2.8994  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 32s (remain 48m 39s) Loss: 0.0000(0.0027) Grad: 128.3780  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 36s (remain 47m 32s) Loss: 0.0006(0.0028) Grad: 4708.9087  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 39s (remain 46m 25s) Loss: 0.0085(0.0029) Grad: 18301.2793  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 42s (remain 45m 19s) Loss: 0.0004(0.0028) Grad: 2260.4980  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 45s (remain 44m 13s) Loss: 0.0000(0.0029) Grad: 12.1270  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 48s (remain 43m 7s) Loss: 0.0005(0.0029) Grad: 1287.8247  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 51s (remain 42m 1s) Loss: 0.0013(0.0029) Grad: 3494.0708  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 54s (remain 40m 56s) Loss: 0.0000(0.0028) Grad: 75.5494  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 58s (remain 39m 51s) Loss: 0.0053(0.0028) Grad: 12748.9307  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 18m 1s (remain 38m 47s) Loss: 0.0004(0.0028) Grad: 1681.5645  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 19m 3s (remain 37m 40s) Loss: 0.0000(0.0028) Grad: 10.7886  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 20m 5s (remain 36m 34s) Loss: 0.0003(0.0028) Grad: 1454.4795  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 21m 7s (remain 35m 28s) Loss: 0.0001(0.0028) Grad: 596.0287  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 22m 10s (remain 34m 24s) Loss: 0.0065(0.0028) Grad: 12058.6045  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 23m 12s (remain 33m 19s) Loss: 0.0000(0.0028) Grad: 10.8625  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 24m 14s (remain 32m 15s) Loss: 0.0053(0.0027) Grad: 32432.7773  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 25m 16s (remain 31m 10s) Loss: 0.0000(0.0028) Grad: 76.5173  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 26m 18s (remain 30m 5s) Loss: 0.0002(0.0027) Grad: 934.6788  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 27m 20s (remain 29m 1s) Loss: 0.0008(0.0027) Grad: 3691.9297  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 28m 21s (remain 27m 56s) Loss: 0.0003(0.0027) Grad: 3002.4739  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 29m 23s (remain 26m 52s) Loss: 0.0058(0.0027) Grad: 17450.4629  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 30m 25s (remain 25m 48s) Loss: 0.0000(0.0027) Grad: 375.2428  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 31m 27s (remain 24m 44s) Loss: 0.0062(0.0027) Grad: 26423.1406  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 32m 28s (remain 23m 40s) Loss: 0.0034(0.0027) Grad: 6651.1992  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 33m 30s (remain 22m 37s) Loss: 0.0000(0.0027) Grad: 25.5353  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 34m 31s (remain 21m 33s) Loss: 0.0032(0.0027) Grad: 14557.4170  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 35m 33s (remain 20m 29s) Loss: 0.0190(0.0027) Grad: 85088.3672  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 36m 34s (remain 19m 26s) Loss: 0.0001(0.0027) Grad: 675.8517  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 37m 36s (remain 18m 23s) Loss: 0.0002(0.0028) Grad: 1431.4354  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 38m 37s (remain 17m 20s) Loss: 0.0033(0.0028) Grad: 5120.1104  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 39m 39s (remain 16m 17s) Loss: 0.0005(0.0028) Grad: 1716.9657  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 40m 41s (remain 15m 14s) Loss: 0.0063(0.0028) Grad: 29403.1113  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 41m 42s (remain 14m 11s) Loss: 0.0000(0.0028) Grad: 3.8358  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 42m 44s (remain 13m 8s) Loss: 0.0011(0.0028) Grad: 4805.0225  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 43m 45s (remain 12m 5s) Loss: 0.0064(0.0028) Grad: 97914.6797  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 44m 47s (remain 11m 2s) Loss: 0.0066(0.0028) Grad: 11848.7842  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 45m 48s (remain 10m 0s) Loss: 0.0000(0.0027) Grad: 83.6281  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 46m 49s (remain 8m 57s) Loss: 0.0000(0.0027) Grad: 5.1325  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 47m 51s (remain 7m 54s) Loss: 0.0001(0.0027) Grad: 908.4022  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 48m 52s (remain 6m 52s) Loss: 0.0066(0.0027) Grad: 17452.6582  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 49m 54s (remain 5m 49s) Loss: 0.0000(0.0028) Grad: 28.7590  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 50m 55s (remain 4m 47s) Loss: 0.0000(0.0027) Grad: 9.9647  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 51m 57s (remain 3m 45s) Loss: 0.0130(0.0027) Grad: 33774.9648  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 52m 58s (remain 2m 42s) Loss: 0.0000(0.0027) Grad: 8.8932  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 54m 0s (remain 1m 40s) Loss: 0.0008(0.0027) Grad: 4478.5654  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 55m 1s (remain 0m 37s) Loss: 0.0017(0.0027) Grad: 8025.3140  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 55m 38s (remain 0m 0s) Loss: 0.0017(0.0027) Grad: 3097.9856  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 16s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0000(0.0035) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0041(0.0038) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0054(0.0036) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0000(0.0035) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 33s) Loss: 0.0261(0.0039) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 21s) Loss: 0.0006(0.0039) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 10s) Loss: 0.0041(0.0038) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 58s) Loss: 0.0000(0.0036) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 46s) Loss: 0.0040(0.0037) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0016(0.0039) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0041) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0000(0.0041) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0007(0.0041) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0311(0.0041) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0322(0.0040) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0039) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0003(0.0038) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0002(0.0037) \n","Epoch 3 - avg_train_loss: 0.0027  avg_val_loss: 0.0037  time: 3558s\n","Epoch 3 - Score: 0.8839\n","Epoch 3 - Save Best Score: 0.8839 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 87m 51s) Loss: 0.0136(0.0136) Grad: 14244.2266  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 6s (remain 57m 50s) Loss: 0.0000(0.0013) Grad: 173.2952  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 8s (remain 54m 51s) Loss: 0.0000(0.0017) Grad: 13.9397  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 9s (remain 53m 13s) Loss: 0.0012(0.0023) Grad: 6651.0518  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 11s (remain 51m 52s) Loss: 0.0000(0.0021) Grad: 73.5277  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 13s (remain 50m 41s) Loss: 0.0065(0.0020) Grad: 18799.0684  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 15s (remain 49m 34s) Loss: 0.0038(0.0021) Grad: 6220.8271  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 17s (remain 48m 26s) Loss: 0.0082(0.0021) Grad: 34153.0391  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 18s (remain 47m 19s) Loss: 0.0007(0.0022) Grad: 3889.1387  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 20s (remain 46m 14s) Loss: 0.0000(0.0023) Grad: 21.1961  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 21s (remain 45m 8s) Loss: 0.0035(0.0023) Grad: 18224.1387  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 23s (remain 44m 4s) Loss: 0.0000(0.0023) Grad: 56.5698  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 25s (remain 43m 1s) Loss: 0.0000(0.0023) Grad: 4.5336  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 26s (remain 41m 58s) Loss: 0.0001(0.0023) Grad: 829.5359  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 29s (remain 40m 57s) Loss: 0.0027(0.0023) Grad: 3986.5017  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 31s (remain 39m 55s) Loss: 0.0000(0.0024) Grad: 279.0708  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 32s (remain 38m 51s) Loss: 0.0000(0.0023) Grad: 12.1985  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 34s (remain 37m 49s) Loss: 0.0000(0.0023) Grad: 143.0965  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 36s (remain 36m 46s) Loss: 0.0000(0.0023) Grad: 2.2977  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 37s (remain 35m 44s) Loss: 0.0120(0.0022) Grad: 8372.0596  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 39s (remain 34m 41s) Loss: 0.0000(0.0023) Grad: 134.9223  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 21m 40s (remain 33m 39s) Loss: 0.0000(0.0022) Grad: 2.7643  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 22m 42s (remain 32m 36s) Loss: 0.0004(0.0022) Grad: 3322.0481  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 23m 44s (remain 31m 34s) Loss: 0.0069(0.0023) Grad: 18115.4863  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 24m 45s (remain 30m 32s) Loss: 0.0000(0.0023) Grad: 78.4163  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 25m 47s (remain 29m 30s) Loss: 0.0000(0.0023) Grad: 4.0176  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 26m 48s (remain 28m 27s) Loss: 0.0017(0.0023) Grad: 3955.5955  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 27m 50s (remain 27m 25s) Loss: 0.0000(0.0023) Grad: 149.1686  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 28m 51s (remain 26m 23s) Loss: 0.0010(0.0023) Grad: 4449.3843  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 29m 53s (remain 25m 21s) Loss: 0.0059(0.0023) Grad: 21960.3105  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 30m 54s (remain 24m 19s) Loss: 0.0000(0.0023) Grad: 3.2471  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 31m 56s (remain 23m 17s) Loss: 0.0000(0.0024) Grad: 26.2911  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 32m 58s (remain 22m 15s) Loss: 0.0029(0.0024) Grad: 4208.0161  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 34m 0s (remain 21m 13s) Loss: 0.0288(0.0025) Grad: 40351.0938  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 35m 1s (remain 20m 11s) Loss: 0.0000(0.0024) Grad: 7.2488  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 36m 3s (remain 19m 10s) Loss: 0.0000(0.0024) Grad: 5.8618  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 37m 5s (remain 18m 8s) Loss: 0.0001(0.0024) Grad: 542.1293  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 38m 7s (remain 17m 6s) Loss: 0.0179(0.0024) Grad: 21206.0332  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 39m 9s (remain 16m 4s) Loss: 0.0000(0.0024) Grad: 6.7663  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 40m 11s (remain 15m 3s) Loss: 0.0091(0.0025) Grad: 11696.9326  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 41m 12s (remain 14m 1s) Loss: 0.0047(0.0024) Grad: 5602.3896  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 42m 14s (remain 12m 59s) Loss: 0.0002(0.0024) Grad: 901.2586  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 43m 16s (remain 11m 57s) Loss: 0.0005(0.0024) Grad: 1188.9084  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 44m 18s (remain 10m 55s) Loss: 0.0049(0.0024) Grad: 9062.4570  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 45m 20s (remain 9m 54s) Loss: 0.0029(0.0024) Grad: 6418.6284  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 46m 21s (remain 8m 52s) Loss: 0.0012(0.0024) Grad: 5244.3477  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 47m 23s (remain 7m 50s) Loss: 0.0000(0.0025) Grad: 90.2059  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 48m 25s (remain 6m 48s) Loss: 0.0000(0.0025) Grad: 87.5257  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 49m 26s (remain 5m 46s) Loss: 0.0000(0.0025) Grad: 84.8917  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 50m 28s (remain 4m 44s) Loss: 0.0032(0.0025) Grad: 9587.0146  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 51m 30s (remain 3m 43s) Loss: 0.0086(0.0025) Grad: 11372.2090  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 52m 31s (remain 2m 41s) Loss: 0.0000(0.0025) Grad: 85.1120  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 53m 34s (remain 1m 39s) Loss: 0.0003(0.0025) Grad: 4434.4346  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 54m 36s (remain 0m 37s) Loss: 0.0013(0.0025) Grad: 5033.4565  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 55m 14s (remain 0m 0s) Loss: 0.0001(0.0024) Grad: 1281.1260  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 39s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0000(0.0040) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 10s) Loss: 0.0080(0.0043) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0038(0.0040) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0000(0.0039) \n","EVAL: [500/1788] Elapsed 0m 59s (remain 2m 34s) Loss: 0.0293(0.0044) \n","EVAL: [600/1788] Elapsed 1m 11s (remain 2m 22s) Loss: 0.0004(0.0044) \n","EVAL: [700/1788] Elapsed 1m 23s (remain 2m 10s) Loss: 0.0034(0.0043) \n","EVAL: [800/1788] Elapsed 1m 35s (remain 1m 58s) Loss: 0.0000(0.0040) \n","EVAL: [900/1788] Elapsed 1m 47s (remain 1m 46s) Loss: 0.0070(0.0041) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0013(0.0043) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0045) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0000(0.0046) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0001(0.0045) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0277(0.0045) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0193(0.0044) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0043) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0004(0.0042) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0000(0.0041) \n","Epoch 4 - avg_train_loss: 0.0024  avg_val_loss: 0.0041  time: 3533s\n","Epoch 4 - Score: 0.8836\n","Epoch: [5][0/5362] Elapsed 0m 0s (remain 88m 5s) Loss: 0.0005(0.0005) Grad: 9678.6465  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 2s (remain 54m 21s) Loss: 0.0004(0.0019) Grad: 2775.5654  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 4s (remain 53m 11s) Loss: 0.0078(0.0025) Grad: 13838.5781  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 6s (remain 52m 9s) Loss: 0.0000(0.0028) Grad: 319.0753  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 8s (remain 51m 8s) Loss: 0.0038(0.0026) Grad: 32397.5449  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 10s (remain 50m 8s) Loss: 0.0000(0.0025) Grad: 30.1008  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 11s (remain 49m 4s) Loss: 0.0000(0.0023) Grad: 42.1478  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 13s (remain 48m 2s) Loss: 0.0011(0.0022) Grad: 9651.5664  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 15s (remain 47m 0s) Loss: 0.0000(0.0022) Grad: 1.6324  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 17s (remain 45m 59s) Loss: 0.0000(0.0020) Grad: 20.8134  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 19s (remain 44m 57s) Loss: 0.0000(0.0020) Grad: 97.6244  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 20s (remain 43m 55s) Loss: 0.0002(0.0019) Grad: 5748.4062  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 22s (remain 42m 52s) Loss: 0.0002(0.0019) Grad: 953.1497  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 24s (remain 41m 50s) Loss: 0.0008(0.0019) Grad: 2592.8164  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 26s (remain 40m 48s) Loss: 0.0048(0.0020) Grad: 16709.3535  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 27s (remain 39m 45s) Loss: 0.0000(0.0020) Grad: 3.1259  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 29s (remain 38m 43s) Loss: 0.0000(0.0020) Grad: 2.3595  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 30s (remain 37m 41s) Loss: 0.0000(0.0021) Grad: 57.2034  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 32s (remain 36m 39s) Loss: 0.0001(0.0021) Grad: 1818.9343  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 33s (remain 35m 37s) Loss: 0.0021(0.0021) Grad: 10727.3154  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 35s (remain 34m 35s) Loss: 0.0000(0.0021) Grad: 28.5239  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 36s (remain 33m 33s) Loss: 0.0000(0.0021) Grad: 2.4055  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 37s (remain 32m 29s) Loss: 0.0026(0.0021) Grad: 5681.8105  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 38s (remain 31m 27s) Loss: 0.0018(0.0021) Grad: 4321.7563  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 39s (remain 30m 24s) Loss: 0.0038(0.0021) Grad: 6692.9438  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 40s (remain 29m 21s) Loss: 0.0000(0.0021) Grad: 80.2873  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 40s (remain 28m 19s) Loss: 0.0000(0.0021) Grad: 17.8644  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 27m 41s (remain 27m 17s) Loss: 0.0000(0.0021) Grad: 141.5436  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 28m 42s (remain 26m 14s) Loss: 0.0000(0.0021) Grad: 8.8857  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 29m 43s (remain 25m 13s) Loss: 0.0000(0.0021) Grad: 13.4699  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 30m 45s (remain 24m 11s) Loss: 0.0000(0.0021) Grad: 8.2865  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 31m 46s (remain 23m 9s) Loss: 0.0000(0.0021) Grad: 5.3748  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 32m 46s (remain 22m 7s) Loss: 0.0168(0.0021) Grad: 37322.5391  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 33m 47s (remain 21m 6s) Loss: 0.0000(0.0020) Grad: 9.5509  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 34m 48s (remain 20m 4s) Loss: 0.0014(0.0020) Grad: 5536.5532  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 35m 49s (remain 19m 2s) Loss: 0.0000(0.0021) Grad: 60.3982  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 36m 50s (remain 18m 0s) Loss: 0.0000(0.0020) Grad: 17.9689  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 37m 51s (remain 16m 59s) Loss: 0.0248(0.0021) Grad: 36238.2109  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 38m 53s (remain 15m 58s) Loss: 0.0000(0.0021) Grad: 14.2918  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 39m 54s (remain 14m 56s) Loss: 0.0001(0.0021) Grad: 343.1010  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 40m 55s (remain 13m 55s) Loss: 0.0000(0.0021) Grad: 30.4170  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 41m 56s (remain 12m 53s) Loss: 0.0000(0.0020) Grad: 20.8201  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 42m 58s (remain 11m 52s) Loss: 0.0000(0.0020) Grad: 54.7216  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 44m 0s (remain 10m 51s) Loss: 0.0000(0.0021) Grad: 31.7021  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 45m 2s (remain 9m 50s) Loss: 0.0014(0.0021) Grad: 16306.1182  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 46m 4s (remain 8m 48s) Loss: 0.0006(0.0021) Grad: 4770.9404  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 47m 5s (remain 7m 47s) Loss: 0.0046(0.0021) Grad: 4397.1875  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 48m 7s (remain 6m 46s) Loss: 0.0000(0.0021) Grad: 170.7190  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 49m 9s (remain 5m 44s) Loss: 0.0000(0.0021) Grad: 97.9228  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 50m 11s (remain 4m 43s) Loss: 0.0010(0.0021) Grad: 3295.9856  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 51m 12s (remain 3m 41s) Loss: 0.0000(0.0021) Grad: 5.3268  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 52m 14s (remain 2m 40s) Loss: 0.0000(0.0021) Grad: 27.0172  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 53m 16s (remain 1m 38s) Loss: 0.0000(0.0021) Grad: 2.1629  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 54m 18s (remain 0m 37s) Loss: 0.0005(0.0021) Grad: 3435.6016  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 54m 55s (remain 0m 0s) Loss: 0.0000(0.0021) Grad: 220.0365  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 28s) Loss: 0.0000(0.0000) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0000(0.0044) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0056(0.0047) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 58s) Loss: 0.0057(0.0044) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0000(0.0043) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0300(0.0048) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0003(0.0047) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0040(0.0046) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0000(0.0043) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0051(0.0044) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0013(0.0046) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0000(0.0049) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0000(0.0049) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0002(0.0048) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0354(0.0048) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0227(0.0047) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0000(0.0045) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0003(0.0044) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0000(0.0043) \n","Epoch 5 - avg_train_loss: 0.0021  avg_val_loss: 0.0043  time: 3516s\n","Epoch 5 - Score: 0.8880\n","Epoch 5 - Save Best Score: 0.8880 Model\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/5362] Elapsed 0m 1s (remain 115m 6s) Loss: 0.1720(0.1720) Grad: nan  LR: 0.000000  \n","Epoch: [1][100/5362] Elapsed 1m 3s (remain 55m 25s) Loss: 0.3142(0.2685) Grad: 43392.1211  LR: 0.000001  \n","Epoch: [1][200/5362] Elapsed 2m 5s (remain 53m 43s) Loss: 0.2207(0.2480) Grad: 38418.2305  LR: 0.000001  \n","Epoch: [1][300/5362] Elapsed 3m 7s (remain 52m 32s) Loss: 0.1352(0.2189) Grad: 24589.8379  LR: 0.000002  \n","Epoch: [1][400/5362] Elapsed 4m 9s (remain 51m 22s) Loss: 0.1428(0.1880) Grad: 29111.7207  LR: 0.000003  \n","Epoch: [1][500/5362] Elapsed 5m 10s (remain 50m 16s) Loss: 0.0300(0.1585) Grad: 1067.3647  LR: 0.000004  \n","Epoch: [1][600/5362] Elapsed 6m 12s (remain 49m 13s) Loss: 0.0144(0.1358) Grad: 707.1976  LR: 0.000004  \n","Epoch: [1][700/5362] Elapsed 7m 14s (remain 48m 8s) Loss: 0.0369(0.1197) Grad: 1532.1393  LR: 0.000005  \n","Epoch: [1][800/5362] Elapsed 8m 15s (remain 47m 3s) Loss: 0.0102(0.1073) Grad: 821.2446  LR: 0.000006  \n","Epoch: [1][900/5362] Elapsed 9m 17s (remain 45m 58s) Loss: 0.0395(0.0975) Grad: 1861.0814  LR: 0.000007  \n","Epoch: [1][1000/5362] Elapsed 10m 18s (remain 44m 56s) Loss: 0.0027(0.0893) Grad: 837.1230  LR: 0.000007  \n","Epoch: [1][1100/5362] Elapsed 11m 20s (remain 43m 54s) Loss: 0.0084(0.0827) Grad: 836.2961  LR: 0.000008  \n","Epoch: [1][1200/5362] Elapsed 12m 22s (remain 42m 53s) Loss: 0.0045(0.0771) Grad: 480.9791  LR: 0.000009  \n","Epoch: [1][1300/5362] Elapsed 13m 24s (remain 41m 52s) Loss: 0.0424(0.0721) Grad: 2654.2688  LR: 0.000010  \n","Epoch: [1][1400/5362] Elapsed 14m 27s (remain 40m 51s) Loss: 0.0073(0.0677) Grad: 2102.6597  LR: 0.000010  \n","Epoch: [1][1500/5362] Elapsed 15m 29s (remain 39m 50s) Loss: 0.0043(0.0637) Grad: 462.5998  LR: 0.000011  \n","Epoch: [1][1600/5362] Elapsed 16m 31s (remain 38m 48s) Loss: 0.0097(0.0603) Grad: 1737.4877  LR: 0.000012  \n","Epoch: [1][1700/5362] Elapsed 17m 33s (remain 37m 46s) Loss: 0.0251(0.0573) Grad: 3634.2524  LR: 0.000013  \n","Epoch: [1][1800/5362] Elapsed 18m 35s (remain 36m 45s) Loss: 0.0037(0.0546) Grad: 3817.6990  LR: 0.000013  \n","Epoch: [1][1900/5362] Elapsed 19m 37s (remain 35m 43s) Loss: 0.0172(0.0522) Grad: 2676.9893  LR: 0.000014  \n","Epoch: [1][2000/5362] Elapsed 20m 39s (remain 34m 41s) Loss: 0.0090(0.0499) Grad: 4680.4653  LR: 0.000015  \n","Epoch: [1][2100/5362] Elapsed 21m 41s (remain 33m 39s) Loss: 0.0043(0.0478) Grad: 1132.8942  LR: 0.000016  \n","Epoch: [1][2200/5362] Elapsed 22m 43s (remain 32m 37s) Loss: 0.0002(0.0459) Grad: 89.0766  LR: 0.000016  \n","Epoch: [1][2300/5362] Elapsed 23m 44s (remain 31m 35s) Loss: 0.0164(0.0442) Grad: 4154.9077  LR: 0.000017  \n","Epoch: [1][2400/5362] Elapsed 24m 46s (remain 30m 33s) Loss: 0.0036(0.0426) Grad: 2426.0703  LR: 0.000018  \n","Epoch: [1][2500/5362] Elapsed 25m 48s (remain 29m 31s) Loss: 0.0031(0.0412) Grad: 1457.1239  LR: 0.000019  \n","Epoch: [1][2600/5362] Elapsed 26m 50s (remain 28m 29s) Loss: 0.0568(0.0399) Grad: 10671.6465  LR: 0.000019  \n","Epoch: [1][2700/5362] Elapsed 27m 53s (remain 27m 28s) Loss: 0.0001(0.0387) Grad: 50.6562  LR: 0.000020  \n","Epoch: [1][2800/5362] Elapsed 28m 55s (remain 26m 26s) Loss: 0.0029(0.0374) Grad: 875.2768  LR: 0.000020  \n","Epoch: [1][2900/5362] Elapsed 29m 57s (remain 25m 24s) Loss: 0.0048(0.0364) Grad: 953.2858  LR: 0.000020  \n","Epoch: [1][3000/5362] Elapsed 30m 59s (remain 24m 23s) Loss: 0.0005(0.0354) Grad: 159.0751  LR: 0.000020  \n","Epoch: [1][3100/5362] Elapsed 32m 1s (remain 23m 21s) Loss: 0.0001(0.0344) Grad: 89.3093  LR: 0.000020  \n","Epoch: [1][3200/5362] Elapsed 33m 4s (remain 22m 19s) Loss: 0.0030(0.0335) Grad: 439.3004  LR: 0.000020  \n","Epoch: [1][3300/5362] Elapsed 34m 6s (remain 21m 17s) Loss: 0.0042(0.0326) Grad: 781.0702  LR: 0.000019  \n","Epoch: [1][3400/5362] Elapsed 35m 8s (remain 20m 15s) Loss: 0.0005(0.0318) Grad: 197.3724  LR: 0.000019  \n","Epoch: [1][3500/5362] Elapsed 36m 10s (remain 19m 13s) Loss: 0.0001(0.0310) Grad: 130.8044  LR: 0.000019  \n","Epoch: [1][3600/5362] Elapsed 37m 12s (remain 18m 11s) Loss: 0.0057(0.0302) Grad: 1166.9165  LR: 0.000019  \n","Epoch: [1][3700/5362] Elapsed 38m 14s (remain 17m 9s) Loss: 0.0009(0.0295) Grad: 306.1753  LR: 0.000019  \n","Epoch: [1][3800/5362] Elapsed 39m 16s (remain 16m 7s) Loss: 0.0043(0.0289) Grad: 652.6793  LR: 0.000019  \n","Epoch: [1][3900/5362] Elapsed 40m 18s (remain 15m 5s) Loss: 0.0001(0.0283) Grad: 74.3456  LR: 0.000019  \n","Epoch: [1][4000/5362] Elapsed 41m 19s (remain 14m 3s) Loss: 0.0005(0.0277) Grad: 231.5859  LR: 0.000019  \n","Epoch: [1][4100/5362] Elapsed 42m 21s (remain 13m 1s) Loss: 0.0244(0.0271) Grad: 3538.8057  LR: 0.000019  \n","Epoch: [1][4200/5362] Elapsed 43m 23s (remain 11m 59s) Loss: 0.0010(0.0266) Grad: 356.6818  LR: 0.000019  \n","Epoch: [1][4300/5362] Elapsed 44m 25s (remain 10m 57s) Loss: 0.0104(0.0261) Grad: 2282.4045  LR: 0.000019  \n","Epoch: [1][4400/5362] Elapsed 45m 27s (remain 9m 55s) Loss: 0.0005(0.0256) Grad: 255.5633  LR: 0.000019  \n","Epoch: [1][4500/5362] Elapsed 46m 29s (remain 8m 53s) Loss: 0.0019(0.0251) Grad: 772.9269  LR: 0.000018  \n","Epoch: [1][4600/5362] Elapsed 47m 31s (remain 7m 51s) Loss: 0.0001(0.0246) Grad: 50.7416  LR: 0.000018  \n","Epoch: [1][4700/5362] Elapsed 48m 33s (remain 6m 49s) Loss: 0.0013(0.0242) Grad: 359.0388  LR: 0.000018  \n","Epoch: [1][4800/5362] Elapsed 49m 35s (remain 5m 47s) Loss: 0.0004(0.0238) Grad: 113.8089  LR: 0.000018  \n","Epoch: [1][4900/5362] Elapsed 50m 38s (remain 4m 45s) Loss: 0.0026(0.0234) Grad: 2258.8311  LR: 0.000018  \n","Epoch: [1][5000/5362] Elapsed 51m 40s (remain 3m 43s) Loss: 0.0000(0.0230) Grad: 14.4497  LR: 0.000018  \n","Epoch: [1][5100/5362] Elapsed 52m 41s (remain 2m 41s) Loss: 0.0138(0.0227) Grad: 2394.3289  LR: 0.000018  \n","Epoch: [1][5200/5362] Elapsed 53m 44s (remain 1m 39s) Loss: 0.0010(0.0223) Grad: 241.1824  LR: 0.000018  \n","Epoch: [1][5300/5362] Elapsed 54m 46s (remain 0m 37s) Loss: 0.0077(0.0220) Grad: 587.7499  LR: 0.000018  \n","Epoch: [1][5361/5362] Elapsed 55m 23s (remain 0m 0s) Loss: 0.0057(0.0218) Grad: 1249.6854  LR: 0.000018  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 14m 41s) Loss: 0.0008(0.0008) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 27s) Loss: 0.0005(0.0026) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 12s) Loss: 0.0002(0.0026) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 3m 1s) Loss: 0.0077(0.0029) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 48s) Loss: 0.0001(0.0032) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 36s) Loss: 0.0001(0.0034) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 24s) Loss: 0.0000(0.0033) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0015(0.0031) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 59s) Loss: 0.0041(0.0030) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 47s) Loss: 0.0006(0.0034) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 35s) Loss: 0.0052(0.0037) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0011(0.0039) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0066(0.0039) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0004(0.0039) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0047(0.0039) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0001(0.0039) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0013(0.0038) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0018(0.0037) \n","EVAL: [1787/1788] Elapsed 3m 35s (remain 0m 0s) Loss: 0.0002(0.0036) \n","Epoch 1 - avg_train_loss: 0.0218  avg_val_loss: 0.0036  time: 3545s\n","Epoch 1 - Score: 0.8468\n","Epoch 1 - Save Best Score: 0.8468 Model\n","Epoch: [2][0/5362] Elapsed 0m 1s (remain 98m 18s) Loss: 0.0061(0.0061) Grad: 9539.7119  LR: 0.000018  \n","Epoch: [2][100/5362] Elapsed 1m 7s (remain 58m 31s) Loss: 0.0000(0.0034) Grad: 135.9749  LR: 0.000018  \n","Epoch: [2][200/5362] Elapsed 2m 9s (remain 55m 32s) Loss: 0.0301(0.0048) Grad: 29115.6836  LR: 0.000018  \n","Epoch: [2][300/5362] Elapsed 3m 12s (remain 53m 53s) Loss: 0.0111(0.0040) Grad: 17679.7051  LR: 0.000018  \n","Epoch: [2][400/5362] Elapsed 4m 14s (remain 52m 31s) Loss: 0.0073(0.0043) Grad: 13803.8809  LR: 0.000017  \n","Epoch: [2][500/5362] Elapsed 5m 17s (remain 51m 20s) Loss: 0.0000(0.0041) Grad: 118.9163  LR: 0.000017  \n","Epoch: [2][600/5362] Elapsed 6m 20s (remain 50m 12s) Loss: 0.0000(0.0041) Grad: 43.1529  LR: 0.000017  \n","Epoch: [2][700/5362] Elapsed 7m 22s (remain 49m 2s) Loss: 0.0000(0.0040) Grad: 34.2974  LR: 0.000017  \n","Epoch: [2][800/5362] Elapsed 8m 25s (remain 47m 55s) Loss: 0.0000(0.0039) Grad: 9.0535  LR: 0.000017  \n","Epoch: [2][900/5362] Elapsed 9m 27s (remain 46m 47s) Loss: 0.0000(0.0038) Grad: 15.8212  LR: 0.000017  \n","Epoch: [2][1000/5362] Elapsed 10m 29s (remain 45m 40s) Loss: 0.0001(0.0037) Grad: 226.6652  LR: 0.000017  \n","Epoch: [2][1100/5362] Elapsed 11m 31s (remain 44m 34s) Loss: 0.0000(0.0037) Grad: 544.7987  LR: 0.000017  \n","Epoch: [2][1200/5362] Elapsed 12m 32s (remain 43m 28s) Loss: 0.0001(0.0036) Grad: 568.2178  LR: 0.000017  \n","Epoch: [2][1300/5362] Elapsed 13m 34s (remain 42m 23s) Loss: 0.0000(0.0036) Grad: 133.1825  LR: 0.000017  \n","Epoch: [2][1400/5362] Elapsed 14m 36s (remain 41m 18s) Loss: 0.0014(0.0036) Grad: 4549.6738  LR: 0.000017  \n","Epoch: [2][1500/5362] Elapsed 15m 38s (remain 40m 14s) Loss: 0.0000(0.0037) Grad: 50.5290  LR: 0.000017  \n","Epoch: [2][1600/5362] Elapsed 16m 40s (remain 39m 11s) Loss: 0.0001(0.0037) Grad: 565.5889  LR: 0.000016  \n","Epoch: [2][1700/5362] Elapsed 17m 43s (remain 38m 8s) Loss: 0.0016(0.0037) Grad: 4620.1846  LR: 0.000016  \n","Epoch: [2][1800/5362] Elapsed 18m 45s (remain 37m 4s) Loss: 0.0022(0.0037) Grad: 3802.7607  LR: 0.000016  \n","Epoch: [2][1900/5362] Elapsed 19m 47s (remain 36m 1s) Loss: 0.0095(0.0036) Grad: 12906.8555  LR: 0.000016  \n","Epoch: [2][2000/5362] Elapsed 20m 49s (remain 34m 58s) Loss: 0.0193(0.0037) Grad: 43625.6562  LR: 0.000016  \n","Epoch: [2][2100/5362] Elapsed 21m 51s (remain 33m 54s) Loss: 0.0005(0.0037) Grad: 2819.6770  LR: 0.000016  \n","Epoch: [2][2200/5362] Elapsed 22m 53s (remain 32m 52s) Loss: 0.0102(0.0037) Grad: 23339.8086  LR: 0.000016  \n","Epoch: [2][2300/5362] Elapsed 23m 55s (remain 31m 49s) Loss: 0.0040(0.0037) Grad: 15371.9561  LR: 0.000016  \n","Epoch: [2][2400/5362] Elapsed 24m 57s (remain 30m 46s) Loss: 0.0000(0.0037) Grad: 124.8022  LR: 0.000016  \n","Epoch: [2][2500/5362] Elapsed 25m 59s (remain 29m 43s) Loss: 0.0032(0.0036) Grad: 30756.3438  LR: 0.000016  \n","Epoch: [2][2600/5362] Elapsed 27m 1s (remain 28m 41s) Loss: 0.0000(0.0036) Grad: 362.3878  LR: 0.000016  \n","Epoch: [2][2700/5362] Elapsed 28m 3s (remain 27m 38s) Loss: 0.0004(0.0036) Grad: 1965.2347  LR: 0.000016  \n","Epoch: [2][2800/5362] Elapsed 29m 5s (remain 26m 36s) Loss: 0.0114(0.0036) Grad: 15908.1299  LR: 0.000015  \n","Epoch: [2][2900/5362] Elapsed 30m 7s (remain 25m 33s) Loss: 0.0012(0.0036) Grad: 3163.7307  LR: 0.000015  \n","Epoch: [2][3000/5362] Elapsed 31m 9s (remain 24m 31s) Loss: 0.0005(0.0036) Grad: 2003.8878  LR: 0.000015  \n","Epoch: [2][3100/5362] Elapsed 32m 11s (remain 23m 28s) Loss: 0.0018(0.0037) Grad: 3674.8889  LR: 0.000015  \n","Epoch: [2][3200/5362] Elapsed 33m 13s (remain 22m 25s) Loss: 0.0020(0.0036) Grad: 4750.7896  LR: 0.000015  \n","Epoch: [2][3300/5362] Elapsed 34m 15s (remain 21m 23s) Loss: 0.0000(0.0037) Grad: 9.1066  LR: 0.000015  \n","Epoch: [2][3400/5362] Elapsed 35m 17s (remain 20m 20s) Loss: 0.0049(0.0037) Grad: 6696.4326  LR: 0.000015  \n","Epoch: [2][3500/5362] Elapsed 36m 18s (remain 19m 18s) Loss: 0.0063(0.0037) Grad: 12113.2168  LR: 0.000015  \n","Epoch: [2][3600/5362] Elapsed 37m 20s (remain 18m 15s) Loss: 0.0002(0.0036) Grad: 731.8072  LR: 0.000015  \n","Epoch: [2][3700/5362] Elapsed 38m 22s (remain 17m 13s) Loss: 0.0000(0.0036) Grad: 20.6398  LR: 0.000015  \n","Epoch: [2][3800/5362] Elapsed 39m 23s (remain 16m 10s) Loss: 0.0000(0.0036) Grad: 75.2245  LR: 0.000015  \n","Epoch: [2][3900/5362] Elapsed 40m 25s (remain 15m 8s) Loss: 0.0042(0.0036) Grad: 24753.2148  LR: 0.000015  \n","Epoch: [2][4000/5362] Elapsed 41m 26s (remain 14m 5s) Loss: 0.0017(0.0037) Grad: 12834.7334  LR: 0.000014  \n","Epoch: [2][4100/5362] Elapsed 42m 28s (remain 13m 3s) Loss: 0.0015(0.0037) Grad: 7528.1074  LR: 0.000014  \n","Epoch: [2][4200/5362] Elapsed 43m 30s (remain 12m 1s) Loss: 0.0063(0.0036) Grad: 14294.5293  LR: 0.000014  \n","Epoch: [2][4300/5362] Elapsed 44m 31s (remain 10m 59s) Loss: 0.0084(0.0036) Grad: 14304.9141  LR: 0.000014  \n","Epoch: [2][4400/5362] Elapsed 45m 33s (remain 9m 56s) Loss: 0.0024(0.0036) Grad: 7788.3633  LR: 0.000014  \n","Epoch: [2][4500/5362] Elapsed 46m 34s (remain 8m 54s) Loss: 0.0108(0.0036) Grad: 13952.9717  LR: 0.000014  \n","Epoch: [2][4600/5362] Elapsed 47m 35s (remain 7m 52s) Loss: 0.0001(0.0036) Grad: 394.7480  LR: 0.000014  \n","Epoch: [2][4700/5362] Elapsed 48m 37s (remain 6m 50s) Loss: 0.0002(0.0036) Grad: 1145.7787  LR: 0.000014  \n","Epoch: [2][4800/5362] Elapsed 49m 39s (remain 5m 48s) Loss: 0.0011(0.0036) Grad: 2895.4250  LR: 0.000014  \n","Epoch: [2][4900/5362] Elapsed 50m 40s (remain 4m 46s) Loss: 0.0003(0.0036) Grad: 2286.9023  LR: 0.000014  \n","Epoch: [2][5000/5362] Elapsed 51m 42s (remain 3m 43s) Loss: 0.0001(0.0036) Grad: 2030.5487  LR: 0.000014  \n","Epoch: [2][5100/5362] Elapsed 52m 43s (remain 2m 41s) Loss: 0.0113(0.0036) Grad: 24537.3984  LR: 0.000014  \n","Epoch: [2][5200/5362] Elapsed 53m 45s (remain 1m 39s) Loss: 0.0001(0.0036) Grad: 821.0580  LR: 0.000013  \n","Epoch: [2][5300/5362] Elapsed 54m 47s (remain 0m 37s) Loss: 0.0001(0.0036) Grad: 229.5780  LR: 0.000013  \n","Epoch: [2][5361/5362] Elapsed 55m 24s (remain 0m 0s) Loss: 0.0046(0.0036) Grad: 10438.0049  LR: 0.000013  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 51s) Loss: 0.0009(0.0009) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 26s) Loss: 0.0016(0.0037) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0006(0.0034) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0040(0.0033) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 47s) Loss: 0.0000(0.0034) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0036) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0000(0.0035) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0016(0.0034) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0060(0.0033) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0006(0.0035) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0026(0.0038) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0006(0.0040) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0100(0.0041) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0002(0.0041) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0020(0.0040) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0000(0.0040) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0022(0.0039) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0008(0.0039) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0000(0.0038) \n","Epoch 2 - avg_train_loss: 0.0036  avg_val_loss: 0.0038  time: 3545s\n","Epoch 2 - Score: 0.8739\n","Epoch 2 - Save Best Score: 0.8739 Model\n","Epoch: [3][0/5362] Elapsed 0m 1s (remain 94m 57s) Loss: 0.0000(0.0000) Grad: 998.3605  LR: 0.000013  \n","Epoch: [3][100/5362] Elapsed 1m 6s (remain 58m 5s) Loss: 0.0003(0.0031) Grad: 2256.1626  LR: 0.000013  \n","Epoch: [3][200/5362] Elapsed 2m 8s (remain 55m 2s) Loss: 0.0005(0.0026) Grad: 2086.5017  LR: 0.000013  \n","Epoch: [3][300/5362] Elapsed 3m 10s (remain 53m 19s) Loss: 0.0002(0.0028) Grad: 1271.6477  LR: 0.000013  \n","Epoch: [3][400/5362] Elapsed 4m 11s (remain 51m 56s) Loss: 0.0000(0.0032) Grad: 153.6612  LR: 0.000013  \n","Epoch: [3][500/5362] Elapsed 5m 13s (remain 50m 42s) Loss: 0.0100(0.0035) Grad: 24747.3867  LR: 0.000013  \n","Epoch: [3][600/5362] Elapsed 6m 15s (remain 49m 32s) Loss: 0.0004(0.0033) Grad: 1431.9152  LR: 0.000013  \n","Epoch: [3][700/5362] Elapsed 7m 17s (remain 48m 26s) Loss: 0.0000(0.0032) Grad: 232.0404  LR: 0.000013  \n","Epoch: [3][800/5362] Elapsed 8m 18s (remain 47m 19s) Loss: 0.0010(0.0030) Grad: 7449.2646  LR: 0.000013  \n","Epoch: [3][900/5362] Elapsed 9m 20s (remain 46m 14s) Loss: 0.0002(0.0031) Grad: 1556.5736  LR: 0.000013  \n","Epoch: [3][1000/5362] Elapsed 10m 21s (remain 45m 9s) Loss: 0.0028(0.0031) Grad: 10991.9863  LR: 0.000013  \n","Epoch: [3][1100/5362] Elapsed 11m 23s (remain 44m 5s) Loss: 0.0001(0.0030) Grad: 484.7567  LR: 0.000012  \n","Epoch: [3][1200/5362] Elapsed 12m 25s (remain 43m 1s) Loss: 0.0000(0.0029) Grad: 28.2715  LR: 0.000012  \n","Epoch: [3][1300/5362] Elapsed 13m 26s (remain 41m 58s) Loss: 0.0000(0.0031) Grad: 131.6193  LR: 0.000012  \n","Epoch: [3][1400/5362] Elapsed 14m 28s (remain 40m 55s) Loss: 0.0000(0.0029) Grad: 147.7020  LR: 0.000012  \n","Epoch: [3][1500/5362] Elapsed 15m 30s (remain 39m 52s) Loss: 0.0000(0.0030) Grad: 10.2840  LR: 0.000012  \n","Epoch: [3][1600/5362] Elapsed 16m 31s (remain 38m 50s) Loss: 0.0000(0.0030) Grad: 3.1137  LR: 0.000012  \n","Epoch: [3][1700/5362] Elapsed 17m 33s (remain 37m 47s) Loss: 0.0001(0.0030) Grad: 1065.5157  LR: 0.000012  \n","Epoch: [3][1800/5362] Elapsed 18m 35s (remain 36m 44s) Loss: 0.0000(0.0030) Grad: 17.5378  LR: 0.000012  \n","Epoch: [3][1900/5362] Elapsed 19m 36s (remain 35m 42s) Loss: 0.0096(0.0030) Grad: 16974.8340  LR: 0.000012  \n","Epoch: [3][2000/5362] Elapsed 20m 38s (remain 34m 40s) Loss: 0.0138(0.0030) Grad: 28521.1562  LR: 0.000012  \n","Epoch: [3][2100/5362] Elapsed 21m 40s (remain 33m 37s) Loss: 0.0005(0.0030) Grad: 3060.5039  LR: 0.000012  \n","Epoch: [3][2200/5362] Elapsed 22m 41s (remain 32m 35s) Loss: 0.0014(0.0031) Grad: 3380.0715  LR: 0.000012  \n","Epoch: [3][2300/5362] Elapsed 23m 43s (remain 31m 33s) Loss: 0.0000(0.0031) Grad: 18.4656  LR: 0.000011  \n","Epoch: [3][2400/5362] Elapsed 24m 45s (remain 30m 31s) Loss: 0.0113(0.0031) Grad: 9887.5791  LR: 0.000011  \n","Epoch: [3][2500/5362] Elapsed 25m 47s (remain 29m 30s) Loss: 0.0000(0.0031) Grad: 15.8932  LR: 0.000011  \n","Epoch: [3][2600/5362] Elapsed 26m 49s (remain 28m 28s) Loss: 0.0005(0.0031) Grad: 13484.4053  LR: 0.000011  \n","Epoch: [3][2700/5362] Elapsed 27m 51s (remain 27m 26s) Loss: 0.0000(0.0031) Grad: 54.4815  LR: 0.000011  \n","Epoch: [3][2800/5362] Elapsed 28m 53s (remain 26m 24s) Loss: 0.0036(0.0031) Grad: 7830.7998  LR: 0.000011  \n","Epoch: [3][2900/5362] Elapsed 29m 54s (remain 25m 22s) Loss: 0.0004(0.0031) Grad: 3984.1479  LR: 0.000011  \n","Epoch: [3][3000/5362] Elapsed 30m 56s (remain 24m 20s) Loss: 0.0000(0.0031) Grad: 23.8979  LR: 0.000011  \n","Epoch: [3][3100/5362] Elapsed 31m 58s (remain 23m 18s) Loss: 0.0000(0.0031) Grad: 376.4560  LR: 0.000011  \n","Epoch: [3][3200/5362] Elapsed 32m 59s (remain 22m 16s) Loss: 0.0000(0.0030) Grad: 220.8687  LR: 0.000011  \n","Epoch: [3][3300/5362] Elapsed 34m 1s (remain 21m 14s) Loss: 0.0041(0.0030) Grad: 14859.1963  LR: 0.000011  \n","Epoch: [3][3400/5362] Elapsed 35m 2s (remain 20m 12s) Loss: 0.0052(0.0030) Grad: 13550.3291  LR: 0.000011  \n","Epoch: [3][3500/5362] Elapsed 36m 4s (remain 19m 10s) Loss: 0.0000(0.0030) Grad: 37.3741  LR: 0.000010  \n","Epoch: [3][3600/5362] Elapsed 37m 6s (remain 18m 8s) Loss: 0.0003(0.0030) Grad: 1079.6311  LR: 0.000010  \n","Epoch: [3][3700/5362] Elapsed 38m 7s (remain 17m 6s) Loss: 0.0009(0.0030) Grad: 2170.2222  LR: 0.000010  \n","Epoch: [3][3800/5362] Elapsed 39m 9s (remain 16m 4s) Loss: 0.0088(0.0030) Grad: 8153.9155  LR: 0.000010  \n","Epoch: [3][3900/5362] Elapsed 40m 10s (remain 15m 2s) Loss: 0.0000(0.0030) Grad: 10.3748  LR: 0.000010  \n","Epoch: [3][4000/5362] Elapsed 41m 11s (remain 14m 0s) Loss: 0.0000(0.0030) Grad: 5.3830  LR: 0.000010  \n","Epoch: [3][4100/5362] Elapsed 42m 12s (remain 12m 58s) Loss: 0.0002(0.0030) Grad: 1342.2478  LR: 0.000010  \n","Epoch: [3][4200/5362] Elapsed 43m 14s (remain 11m 56s) Loss: 0.0000(0.0030) Grad: 126.0302  LR: 0.000010  \n","Epoch: [3][4300/5362] Elapsed 44m 15s (remain 10m 55s) Loss: 0.0000(0.0030) Grad: 164.4745  LR: 0.000010  \n","Epoch: [3][4400/5362] Elapsed 45m 17s (remain 9m 53s) Loss: 0.0000(0.0030) Grad: 3.3995  LR: 0.000010  \n","Epoch: [3][4500/5362] Elapsed 46m 19s (remain 8m 51s) Loss: 0.0019(0.0030) Grad: 8433.7471  LR: 0.000010  \n","Epoch: [3][4600/5362] Elapsed 47m 20s (remain 7m 49s) Loss: 0.0293(0.0030) Grad: 28815.9902  LR: 0.000010  \n","Epoch: [3][4700/5362] Elapsed 48m 22s (remain 6m 48s) Loss: 0.0000(0.0031) Grad: 218.8194  LR: 0.000009  \n","Epoch: [3][4800/5362] Elapsed 49m 23s (remain 5m 46s) Loss: 0.0000(0.0031) Grad: 165.5731  LR: 0.000009  \n","Epoch: [3][4900/5362] Elapsed 50m 25s (remain 4m 44s) Loss: 0.0000(0.0031) Grad: 70.6699  LR: 0.000009  \n","Epoch: [3][5000/5362] Elapsed 51m 26s (remain 3m 42s) Loss: 0.0003(0.0031) Grad: 1512.5734  LR: 0.000009  \n","Epoch: [3][5100/5362] Elapsed 52m 28s (remain 2m 41s) Loss: 0.0001(0.0031) Grad: 542.3859  LR: 0.000009  \n","Epoch: [3][5200/5362] Elapsed 53m 29s (remain 1m 39s) Loss: 0.0000(0.0030) Grad: 87.3577  LR: 0.000009  \n","Epoch: [3][5300/5362] Elapsed 54m 31s (remain 0m 37s) Loss: 0.0000(0.0031) Grad: 13.4235  LR: 0.000009  \n","Epoch: [3][5361/5362] Elapsed 55m 9s (remain 0m 0s) Loss: 0.0776(0.0031) Grad: 35341.6133  LR: 0.000009  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 35s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0074(0.0034) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0003(0.0036) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0022(0.0033) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0001(0.0035) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0001(0.0039) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0000(0.0038) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0005(0.0037) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0056(0.0035) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0001(0.0037) \n","EVAL: [1000/1788] Elapsed 1m 59s (remain 1m 34s) Loss: 0.0049(0.0039) \n","EVAL: [1100/1788] Elapsed 2m 11s (remain 1m 22s) Loss: 0.0007(0.0041) \n","EVAL: [1200/1788] Elapsed 2m 23s (remain 1m 10s) Loss: 0.0123(0.0042) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0000(0.0043) \n","EVAL: [1400/1788] Elapsed 2m 47s (remain 0m 46s) Loss: 0.0018(0.0042) \n","EVAL: [1500/1788] Elapsed 2m 59s (remain 0m 34s) Loss: 0.0000(0.0041) \n","EVAL: [1600/1788] Elapsed 3m 11s (remain 0m 22s) Loss: 0.0024(0.0041) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0003(0.0041) \n","EVAL: [1787/1788] Elapsed 3m 33s (remain 0m 0s) Loss: 0.0000(0.0040) \n","Epoch 3 - avg_train_loss: 0.0031  avg_val_loss: 0.0040  time: 3528s\n","Epoch 3 - Score: 0.8804\n","Epoch 3 - Save Best Score: 0.8804 Model\n","Epoch: [4][0/5362] Elapsed 0m 0s (remain 87m 29s) Loss: 0.0000(0.0000) Grad: 994.8622  LR: 0.000009  \n","Epoch: [4][100/5362] Elapsed 1m 6s (remain 58m 1s) Loss: 0.0345(0.0025) Grad: 84583.4766  LR: 0.000009  \n","Epoch: [4][200/5362] Elapsed 2m 8s (remain 55m 1s) Loss: 0.0000(0.0032) Grad: 129.9525  LR: 0.000009  \n","Epoch: [4][300/5362] Elapsed 3m 10s (remain 53m 18s) Loss: 0.0000(0.0028) Grad: 71.9702  LR: 0.000009  \n","Epoch: [4][400/5362] Elapsed 4m 11s (remain 51m 56s) Loss: 0.0099(0.0030) Grad: 51542.4727  LR: 0.000009  \n","Epoch: [4][500/5362] Elapsed 5m 13s (remain 50m 43s) Loss: 0.0005(0.0028) Grad: 2084.9509  LR: 0.000008  \n","Epoch: [4][600/5362] Elapsed 6m 15s (remain 49m 34s) Loss: 0.0072(0.0027) Grad: 12953.6963  LR: 0.000008  \n","Epoch: [4][700/5362] Elapsed 7m 17s (remain 48m 29s) Loss: 0.0001(0.0027) Grad: 1725.0695  LR: 0.000008  \n","Epoch: [4][800/5362] Elapsed 8m 19s (remain 47m 22s) Loss: 0.0001(0.0026) Grad: 764.3666  LR: 0.000008  \n","Epoch: [4][900/5362] Elapsed 9m 20s (remain 46m 17s) Loss: 0.0000(0.0026) Grad: 6.8967  LR: 0.000008  \n","Epoch: [4][1000/5362] Elapsed 10m 22s (remain 45m 12s) Loss: 0.0000(0.0026) Grad: 5.6989  LR: 0.000008  \n","Epoch: [4][1100/5362] Elapsed 11m 24s (remain 44m 8s) Loss: 0.0030(0.0027) Grad: 4701.2183  LR: 0.000008  \n","Epoch: [4][1200/5362] Elapsed 12m 26s (remain 43m 4s) Loss: 0.0013(0.0027) Grad: 7991.9004  LR: 0.000008  \n","Epoch: [4][1300/5362] Elapsed 13m 28s (remain 42m 2s) Loss: 0.0003(0.0026) Grad: 1034.7289  LR: 0.000008  \n","Epoch: [4][1400/5362] Elapsed 14m 30s (remain 41m 0s) Loss: 0.0021(0.0027) Grad: 7471.3179  LR: 0.000008  \n","Epoch: [4][1500/5362] Elapsed 15m 32s (remain 39m 58s) Loss: 0.0000(0.0026) Grad: 298.2059  LR: 0.000008  \n","Epoch: [4][1600/5362] Elapsed 16m 34s (remain 38m 57s) Loss: 0.0003(0.0026) Grad: 3011.0325  LR: 0.000008  \n","Epoch: [4][1700/5362] Elapsed 17m 36s (remain 37m 54s) Loss: 0.0000(0.0026) Grad: 25.4475  LR: 0.000007  \n","Epoch: [4][1800/5362] Elapsed 18m 38s (remain 36m 51s) Loss: 0.0003(0.0025) Grad: 2714.0513  LR: 0.000007  \n","Epoch: [4][1900/5362] Elapsed 19m 40s (remain 35m 48s) Loss: 0.0014(0.0026) Grad: 7065.4199  LR: 0.000007  \n","Epoch: [4][2000/5362] Elapsed 20m 41s (remain 34m 45s) Loss: 0.0000(0.0026) Grad: 67.2829  LR: 0.000007  \n","Epoch: [4][2100/5362] Elapsed 21m 43s (remain 33m 43s) Loss: 0.0000(0.0027) Grad: 230.4988  LR: 0.000007  \n","Epoch: [4][2200/5362] Elapsed 22m 45s (remain 32m 40s) Loss: 0.0000(0.0027) Grad: 8.8836  LR: 0.000007  \n","Epoch: [4][2300/5362] Elapsed 23m 46s (remain 31m 38s) Loss: 0.0034(0.0027) Grad: 23788.1270  LR: 0.000007  \n","Epoch: [4][2400/5362] Elapsed 24m 48s (remain 30m 35s) Loss: 0.0026(0.0027) Grad: 11818.6670  LR: 0.000007  \n","Epoch: [4][2500/5362] Elapsed 25m 50s (remain 29m 33s) Loss: 0.0000(0.0027) Grad: 29.3736  LR: 0.000007  \n","Epoch: [4][2600/5362] Elapsed 26m 52s (remain 28m 31s) Loss: 0.0000(0.0027) Grad: 10.4447  LR: 0.000007  \n","Epoch: [4][2700/5362] Elapsed 27m 54s (remain 27m 29s) Loss: 0.0000(0.0027) Grad: 12.0609  LR: 0.000007  \n","Epoch: [4][2800/5362] Elapsed 28m 56s (remain 26m 27s) Loss: 0.0000(0.0027) Grad: 69.2766  LR: 0.000007  \n","Epoch: [4][2900/5362] Elapsed 29m 58s (remain 25m 25s) Loss: 0.0034(0.0027) Grad: 11586.9570  LR: 0.000006  \n","Epoch: [4][3000/5362] Elapsed 30m 59s (remain 24m 23s) Loss: 0.0005(0.0027) Grad: 1955.4277  LR: 0.000006  \n","Epoch: [4][3100/5362] Elapsed 32m 1s (remain 23m 21s) Loss: 0.0002(0.0027) Grad: 676.1211  LR: 0.000006  \n","Epoch: [4][3200/5362] Elapsed 33m 3s (remain 22m 19s) Loss: 0.0000(0.0027) Grad: 8.2460  LR: 0.000006  \n","Epoch: [4][3300/5362] Elapsed 34m 5s (remain 21m 17s) Loss: 0.0000(0.0027) Grad: 63.4449  LR: 0.000006  \n","Epoch: [4][3400/5362] Elapsed 35m 6s (remain 20m 14s) Loss: 0.0001(0.0026) Grad: 816.9764  LR: 0.000006  \n","Epoch: [4][3500/5362] Elapsed 36m 8s (remain 19m 12s) Loss: 0.0000(0.0026) Grad: 107.4259  LR: 0.000006  \n","Epoch: [4][3600/5362] Elapsed 37m 10s (remain 18m 10s) Loss: 0.0001(0.0026) Grad: 585.4985  LR: 0.000006  \n","Epoch: [4][3700/5362] Elapsed 38m 12s (remain 17m 8s) Loss: 0.0000(0.0026) Grad: 8.0767  LR: 0.000006  \n","Epoch: [4][3800/5362] Elapsed 39m 13s (remain 16m 6s) Loss: 0.0339(0.0027) Grad: 77532.1484  LR: 0.000006  \n","Epoch: [4][3900/5362] Elapsed 40m 15s (remain 15m 4s) Loss: 0.0000(0.0027) Grad: 15.0424  LR: 0.000006  \n","Epoch: [4][4000/5362] Elapsed 41m 16s (remain 14m 2s) Loss: 0.0000(0.0027) Grad: 9.6516  LR: 0.000006  \n","Epoch: [4][4100/5362] Elapsed 42m 18s (remain 13m 0s) Loss: 0.0000(0.0027) Grad: 55.3166  LR: 0.000005  \n","Epoch: [4][4200/5362] Elapsed 43m 19s (remain 11m 58s) Loss: 0.0035(0.0027) Grad: 32026.8711  LR: 0.000005  \n","Epoch: [4][4300/5362] Elapsed 44m 21s (remain 10m 56s) Loss: 0.0003(0.0027) Grad: 2326.1208  LR: 0.000005  \n","Epoch: [4][4400/5362] Elapsed 45m 23s (remain 9m 54s) Loss: 0.0000(0.0027) Grad: 52.3606  LR: 0.000005  \n","Epoch: [4][4500/5362] Elapsed 46m 25s (remain 8m 52s) Loss: 0.0000(0.0027) Grad: 180.7474  LR: 0.000005  \n","Epoch: [4][4600/5362] Elapsed 47m 27s (remain 7m 50s) Loss: 0.0000(0.0027) Grad: 6.7426  LR: 0.000005  \n","Epoch: [4][4700/5362] Elapsed 48m 29s (remain 6m 49s) Loss: 0.0000(0.0027) Grad: 71.1559  LR: 0.000005  \n","Epoch: [4][4800/5362] Elapsed 49m 30s (remain 5m 47s) Loss: 0.0000(0.0027) Grad: 159.2503  LR: 0.000005  \n","Epoch: [4][4900/5362] Elapsed 50m 32s (remain 4m 45s) Loss: 0.0000(0.0027) Grad: 35.5128  LR: 0.000005  \n","Epoch: [4][5000/5362] Elapsed 51m 34s (remain 3m 43s) Loss: 0.0000(0.0027) Grad: 6.6527  LR: 0.000005  \n","Epoch: [4][5100/5362] Elapsed 52m 36s (remain 2m 41s) Loss: 0.0027(0.0027) Grad: 7508.1743  LR: 0.000005  \n","Epoch: [4][5200/5362] Elapsed 53m 38s (remain 1m 39s) Loss: 0.0040(0.0027) Grad: 6226.9453  LR: 0.000005  \n","Epoch: [4][5300/5362] Elapsed 54m 40s (remain 0m 37s) Loss: 0.0001(0.0027) Grad: 575.3726  LR: 0.000004  \n","Epoch: [4][5361/5362] Elapsed 55m 18s (remain 0m 0s) Loss: 0.0148(0.0027) Grad: 32800.9258  LR: 0.000004  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 36s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0040(0.0033) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0003(0.0034) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0087(0.0032) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 46s) Loss: 0.0000(0.0033) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 34s) Loss: 0.0000(0.0035) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 22s) Loss: 0.0000(0.0034) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 10s) Loss: 0.0002(0.0034) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0091(0.0032) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0001(0.0035) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0088(0.0038) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0012(0.0040) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0116(0.0041) \n","EVAL: [1300/1788] Elapsed 2m 35s (remain 0m 58s) Loss: 0.0000(0.0042) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0021(0.0041) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0000(0.0041) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0016(0.0041) \n","EVAL: [1700/1788] Elapsed 3m 23s (remain 0m 10s) Loss: 0.0004(0.0041) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0000(0.0040) \n","Epoch 4 - avg_train_loss: 0.0027  avg_val_loss: 0.0040  time: 3538s\n","Epoch 4 - Score: 0.8822\n","Epoch 4 - Save Best Score: 0.8822 Model\n","Epoch: [5][0/5362] Elapsed 0m 1s (remain 92m 10s) Loss: 0.0000(0.0000) Grad: 996.0214  LR: 0.000004  \n","Epoch: [5][100/5362] Elapsed 1m 7s (remain 58m 40s) Loss: 0.0001(0.0018) Grad: 2422.0420  LR: 0.000004  \n","Epoch: [5][200/5362] Elapsed 2m 9s (remain 55m 24s) Loss: 0.0000(0.0024) Grad: 9.8302  LR: 0.000004  \n","Epoch: [5][300/5362] Elapsed 3m 11s (remain 53m 38s) Loss: 0.0016(0.0025) Grad: 7988.5151  LR: 0.000004  \n","Epoch: [5][400/5362] Elapsed 4m 13s (remain 52m 15s) Loss: 0.0000(0.0024) Grad: 248.8190  LR: 0.000004  \n","Epoch: [5][500/5362] Elapsed 5m 15s (remain 51m 0s) Loss: 0.0000(0.0025) Grad: 40.7684  LR: 0.000004  \n","Epoch: [5][600/5362] Elapsed 6m 17s (remain 49m 52s) Loss: 0.0000(0.0024) Grad: 24.4116  LR: 0.000004  \n","Epoch: [5][700/5362] Elapsed 7m 19s (remain 48m 43s) Loss: 0.0001(0.0023) Grad: 842.2139  LR: 0.000004  \n","Epoch: [5][800/5362] Elapsed 8m 21s (remain 47m 37s) Loss: 0.0000(0.0024) Grad: 42.3503  LR: 0.000004  \n","Epoch: [5][900/5362] Elapsed 9m 23s (remain 46m 31s) Loss: 0.0000(0.0023) Grad: 114.4802  LR: 0.000004  \n","Epoch: [5][1000/5362] Elapsed 10m 25s (remain 45m 24s) Loss: 0.0000(0.0023) Grad: 13.3590  LR: 0.000004  \n","Epoch: [5][1100/5362] Elapsed 11m 27s (remain 44m 19s) Loss: 0.0018(0.0022) Grad: 5819.7988  LR: 0.000004  \n","Epoch: [5][1200/5362] Elapsed 12m 28s (remain 43m 14s) Loss: 0.0000(0.0023) Grad: 186.3933  LR: 0.000003  \n","Epoch: [5][1300/5362] Elapsed 13m 30s (remain 42m 9s) Loss: 0.0000(0.0025) Grad: 2.3405  LR: 0.000003  \n","Epoch: [5][1400/5362] Elapsed 14m 31s (remain 41m 5s) Loss: 0.0000(0.0025) Grad: 59.4978  LR: 0.000003  \n","Epoch: [5][1500/5362] Elapsed 15m 33s (remain 40m 1s) Loss: 0.0000(0.0026) Grad: 3.3265  LR: 0.000003  \n","Epoch: [5][1600/5362] Elapsed 16m 35s (remain 38m 58s) Loss: 0.0023(0.0026) Grad: 3954.6187  LR: 0.000003  \n","Epoch: [5][1700/5362] Elapsed 17m 37s (remain 37m 55s) Loss: 0.0000(0.0025) Grad: 18.0967  LR: 0.000003  \n","Epoch: [5][1800/5362] Elapsed 18m 39s (remain 36m 52s) Loss: 0.0010(0.0025) Grad: 7537.3608  LR: 0.000003  \n","Epoch: [5][1900/5362] Elapsed 19m 41s (remain 35m 50s) Loss: 0.0000(0.0025) Grad: 19.0573  LR: 0.000003  \n","Epoch: [5][2000/5362] Elapsed 20m 43s (remain 34m 48s) Loss: 0.0028(0.0025) Grad: 23280.3242  LR: 0.000003  \n","Epoch: [5][2100/5362] Elapsed 21m 45s (remain 33m 46s) Loss: 0.0001(0.0025) Grad: 434.2740  LR: 0.000003  \n","Epoch: [5][2200/5362] Elapsed 22m 47s (remain 32m 43s) Loss: 0.0000(0.0024) Grad: 110.5116  LR: 0.000003  \n","Epoch: [5][2300/5362] Elapsed 23m 49s (remain 31m 41s) Loss: 0.0000(0.0024) Grad: 394.5844  LR: 0.000003  \n","Epoch: [5][2400/5362] Elapsed 24m 51s (remain 30m 39s) Loss: 0.0000(0.0024) Grad: 2.8800  LR: 0.000002  \n","Epoch: [5][2500/5362] Elapsed 25m 53s (remain 29m 37s) Loss: 0.0000(0.0024) Grad: 50.0987  LR: 0.000002  \n","Epoch: [5][2600/5362] Elapsed 26m 55s (remain 28m 34s) Loss: 0.0017(0.0024) Grad: 10242.1191  LR: 0.000002  \n","Epoch: [5][2700/5362] Elapsed 27m 57s (remain 27m 32s) Loss: 0.0024(0.0023) Grad: 14538.4453  LR: 0.000002  \n","Epoch: [5][2800/5362] Elapsed 28m 59s (remain 26m 30s) Loss: 0.0003(0.0023) Grad: 2609.7632  LR: 0.000002  \n","Epoch: [5][2900/5362] Elapsed 30m 0s (remain 25m 27s) Loss: 0.0002(0.0024) Grad: 824.9897  LR: 0.000002  \n","Epoch: [5][3000/5362] Elapsed 31m 1s (remain 24m 24s) Loss: 0.0000(0.0024) Grad: 14.7545  LR: 0.000002  \n","Epoch: [5][3100/5362] Elapsed 32m 2s (remain 23m 21s) Loss: 0.0000(0.0024) Grad: 2.8172  LR: 0.000002  \n","Epoch: [5][3200/5362] Elapsed 33m 3s (remain 22m 19s) Loss: 0.0000(0.0024) Grad: 55.5177  LR: 0.000002  \n","Epoch: [5][3300/5362] Elapsed 34m 4s (remain 21m 16s) Loss: 0.0160(0.0024) Grad: 54501.1094  LR: 0.000002  \n","Epoch: [5][3400/5362] Elapsed 35m 6s (remain 20m 14s) Loss: 0.0000(0.0024) Grad: 15.6271  LR: 0.000002  \n","Epoch: [5][3500/5362] Elapsed 36m 7s (remain 19m 12s) Loss: 0.0002(0.0024) Grad: 3052.5420  LR: 0.000002  \n","Epoch: [5][3600/5362] Elapsed 37m 10s (remain 18m 10s) Loss: 0.0006(0.0024) Grad: 10720.4814  LR: 0.000001  \n","Epoch: [5][3700/5362] Elapsed 38m 12s (remain 17m 8s) Loss: 0.0002(0.0024) Grad: 1481.2695  LR: 0.000001  \n","Epoch: [5][3800/5362] Elapsed 39m 14s (remain 16m 6s) Loss: 0.0000(0.0024) Grad: 64.4255  LR: 0.000001  \n","Epoch: [5][3900/5362] Elapsed 40m 16s (remain 15m 4s) Loss: 0.0018(0.0024) Grad: 7619.0200  LR: 0.000001  \n","Epoch: [5][4000/5362] Elapsed 41m 18s (remain 14m 2s) Loss: 0.0001(0.0024) Grad: 304.9872  LR: 0.000001  \n","Epoch: [5][4100/5362] Elapsed 42m 20s (remain 13m 1s) Loss: 0.0000(0.0024) Grad: 91.0661  LR: 0.000001  \n","Epoch: [5][4200/5362] Elapsed 43m 22s (remain 11m 59s) Loss: 0.0013(0.0024) Grad: 9668.8428  LR: 0.000001  \n","Epoch: [5][4300/5362] Elapsed 44m 24s (remain 10m 57s) Loss: 0.0005(0.0024) Grad: 4340.7734  LR: 0.000001  \n","Epoch: [5][4400/5362] Elapsed 45m 25s (remain 9m 55s) Loss: 0.0000(0.0024) Grad: 4.9004  LR: 0.000001  \n","Epoch: [5][4500/5362] Elapsed 46m 27s (remain 8m 53s) Loss: 0.0000(0.0024) Grad: 32.6913  LR: 0.000001  \n","Epoch: [5][4600/5362] Elapsed 47m 29s (remain 7m 51s) Loss: 0.0032(0.0024) Grad: 12237.3936  LR: 0.000001  \n","Epoch: [5][4700/5362] Elapsed 48m 31s (remain 6m 49s) Loss: 0.0000(0.0024) Grad: 5.4855  LR: 0.000001  \n","Epoch: [5][4800/5362] Elapsed 49m 33s (remain 5m 47s) Loss: 0.0016(0.0024) Grad: 5895.0312  LR: 0.000000  \n","Epoch: [5][4900/5362] Elapsed 50m 35s (remain 4m 45s) Loss: 0.0000(0.0024) Grad: 40.6890  LR: 0.000000  \n","Epoch: [5][5000/5362] Elapsed 51m 37s (remain 3m 43s) Loss: 0.0000(0.0024) Grad: 14.7542  LR: 0.000000  \n","Epoch: [5][5100/5362] Elapsed 52m 39s (remain 2m 41s) Loss: 0.0006(0.0023) Grad: 30797.3574  LR: 0.000000  \n","Epoch: [5][5200/5362] Elapsed 53m 41s (remain 1m 39s) Loss: 0.0000(0.0024) Grad: 94.4561  LR: 0.000000  \n","Epoch: [5][5300/5362] Elapsed 54m 43s (remain 0m 37s) Loss: 0.0000(0.0024) Grad: 35.9698  LR: 0.000000  \n","Epoch: [5][5361/5362] Elapsed 55m 21s (remain 0m 0s) Loss: 0.0000(0.0024) Grad: 145.2547  LR: 0.000000  \n","EVAL: [0/1788] Elapsed 0m 0s (remain 12m 45s) Loss: 0.0001(0.0001) \n","EVAL: [100/1788] Elapsed 0m 12s (remain 3m 25s) Loss: 0.0009(0.0033) \n","EVAL: [200/1788] Elapsed 0m 24s (remain 3m 11s) Loss: 0.0001(0.0036) \n","EVAL: [300/1788] Elapsed 0m 36s (remain 2m 59s) Loss: 0.0050(0.0034) \n","EVAL: [400/1788] Elapsed 0m 48s (remain 2m 47s) Loss: 0.0000(0.0035) \n","EVAL: [500/1788] Elapsed 1m 0s (remain 2m 35s) Loss: 0.0000(0.0037) \n","EVAL: [600/1788] Elapsed 1m 12s (remain 2m 23s) Loss: 0.0000(0.0037) \n","EVAL: [700/1788] Elapsed 1m 24s (remain 2m 11s) Loss: 0.0001(0.0037) \n","EVAL: [800/1788] Elapsed 1m 36s (remain 1m 58s) Loss: 0.0024(0.0035) \n","EVAL: [900/1788] Elapsed 1m 48s (remain 1m 46s) Loss: 0.0001(0.0037) \n","EVAL: [1000/1788] Elapsed 2m 0s (remain 1m 34s) Loss: 0.0075(0.0040) \n","EVAL: [1100/1788] Elapsed 2m 12s (remain 1m 22s) Loss: 0.0012(0.0043) \n","EVAL: [1200/1788] Elapsed 2m 24s (remain 1m 10s) Loss: 0.0129(0.0044) \n","EVAL: [1300/1788] Elapsed 2m 36s (remain 0m 58s) Loss: 0.0000(0.0044) \n","EVAL: [1400/1788] Elapsed 2m 48s (remain 0m 46s) Loss: 0.0020(0.0043) \n","EVAL: [1500/1788] Elapsed 3m 0s (remain 0m 34s) Loss: 0.0000(0.0043) \n","EVAL: [1600/1788] Elapsed 3m 12s (remain 0m 22s) Loss: 0.0016(0.0043) \n","EVAL: [1700/1788] Elapsed 3m 24s (remain 0m 10s) Loss: 0.0002(0.0043) \n","EVAL: [1787/1788] Elapsed 3m 34s (remain 0m 0s) Loss: 0.0000(0.0042) \n","Epoch 5 - avg_train_loss: 0.0024  avg_val_loss: 0.0042  time: 3542s\n","Epoch 5 - Score: 0.8841\n","Epoch 5 - Save Best Score: 0.8841 Model\n","Best thres: 0.5, Score: 0.8827\n","Best thres: 0.5140625, Score: 0.8828\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"804b2a4e2fe74220ae7a562e4fe9b947"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d4457fc2ced403f8fdc30f7b5e73fdd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e3517d51e24e3685b40409991c23b6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp053.ipynb","provenance":[{"file_id":"17kVbQ-XIfEPDlRkluS06AyK24t4Z-nRb","timestamp":1647655900788},{"file_id":"17d5VktGiKlzZFZ4DX0Xh1M3Yr83oZpnY","timestamp":1647654875373}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4aca5d978e3c46688e387544beef1053":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d5619270759476a9bc67ab5b183a426","IPY_MODEL_e8b52938d8be46da95bda58aab91bba4","IPY_MODEL_e909b587736b4caeb7c301da82330fea"],"layout":"IPY_MODEL_d547223a923e4e11aa0991781093b521"}},"2d5619270759476a9bc67ab5b183a426":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a4904aa488a4957b438d895dfc933ab","placeholder":"​","style":"IPY_MODEL_b168424a48e34782bca6a643bfad71bc","value":"Downloading: 100%"}},"e8b52938d8be46da95bda58aab91bba4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76dc0df93e81433abd69458483cc0748","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b183101caec445608ab717a8557d0f29","value":52}},"e909b587736b4caeb7c301da82330fea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdf7790f04cf4e6098f64153a9690037","placeholder":"​","style":"IPY_MODEL_9597d005eded42f2a2f64dc858e0f32a","value":" 52.0/52.0 [00:00&lt;00:00, 1.29kB/s]"}},"d547223a923e4e11aa0991781093b521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a4904aa488a4957b438d895dfc933ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b168424a48e34782bca6a643bfad71bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76dc0df93e81433abd69458483cc0748":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b183101caec445608ab717a8557d0f29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdf7790f04cf4e6098f64153a9690037":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9597d005eded42f2a2f64dc858e0f32a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b58db1e8f7b44dbb89c57c5c0c4a250d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74982d2d13d24681940a72a548ff2e8e","IPY_MODEL_84c5457394a94f409b08ffab3cbf65a6","IPY_MODEL_992bedc3ce57440b8d7dcf23779785c1"],"layout":"IPY_MODEL_18a35825cfa846489e6ae28842beb89a"}},"74982d2d13d24681940a72a548ff2e8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cd6503c9ecc4e37a1569df8e4c4a5c6","placeholder":"​","style":"IPY_MODEL_97b355011f484349b5475780a17feba3","value":"Downloading: 100%"}},"84c5457394a94f409b08ffab3cbf65a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae1e3b79e404f91853a84449aedb67d","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c642c92e18c458999fe79f47a6838e5","value":475}},"992bedc3ce57440b8d7dcf23779785c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebcebcd05b334d18bc71ef44f1fc8fb8","placeholder":"​","style":"IPY_MODEL_c23b7159af9e4ea09c81d1409f4ba270","value":" 475/475 [00:00&lt;00:00, 5.56kB/s]"}},"18a35825cfa846489e6ae28842beb89a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cd6503c9ecc4e37a1569df8e4c4a5c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97b355011f484349b5475780a17feba3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae1e3b79e404f91853a84449aedb67d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c642c92e18c458999fe79f47a6838e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebcebcd05b334d18bc71ef44f1fc8fb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c23b7159af9e4ea09c81d1409f4ba270":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f9c845d3c394fb38ca91e2dcf5a760a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15a4c7bd65c344d7bc871dc479b98747","IPY_MODEL_65ea4d9fe40a414fa21cf0391ff4115c","IPY_MODEL_2497f4bc4f4242d39b86ac02eab0bb77"],"layout":"IPY_MODEL_80e1024cc4d54775bb38f584e225c793"}},"15a4c7bd65c344d7bc871dc479b98747":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76c0be9bbdb642f1a61ff4b511dbd253","placeholder":"​","style":"IPY_MODEL_4426b7981a314bcf93a35a064495c53c","value":"Downloading: 100%"}},"65ea4d9fe40a414fa21cf0391ff4115c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_381ed600b47b445b89fda19cd9fc3eb0","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1548830b4af4c81a999b5ce5c503258","value":898825}},"2497f4bc4f4242d39b86ac02eab0bb77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1227fbe6c8ec4b458f1df2f3dfc63ad2","placeholder":"​","style":"IPY_MODEL_cb4cebe78958440886212d21accd8b31","value":" 878k/878k [00:00&lt;00:00, 2.24MB/s]"}},"80e1024cc4d54775bb38f584e225c793":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76c0be9bbdb642f1a61ff4b511dbd253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4426b7981a314bcf93a35a064495c53c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"381ed600b47b445b89fda19cd9fc3eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1548830b4af4c81a999b5ce5c503258":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1227fbe6c8ec4b458f1df2f3dfc63ad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb4cebe78958440886212d21accd8b31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be385109cd324c81aceef334e024bd8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a7801a1b65b42f8bcac09f4757ae90d","IPY_MODEL_1ef55881ffec4b1ead8a5c4e1a8849d4","IPY_MODEL_c01fb4f4c57a4d248b1ba84a05339632"],"layout":"IPY_MODEL_3235ac11228348578980f45ffca02e6c"}},"5a7801a1b65b42f8bcac09f4757ae90d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25aa1da131fc4f379cb65e4f55a1688c","placeholder":"​","style":"IPY_MODEL_e113d7f11eb0423bbf80d6ae48be773c","value":"Downloading: 100%"}},"1ef55881ffec4b1ead8a5c4e1a8849d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_753873935e034b62989c8bc0cf1260bf","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6429e386ee40478fab61eb81cfabdb8e","value":456318}},"c01fb4f4c57a4d248b1ba84a05339632":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_489b2fb487564b7080fdf08ebd0c82f7","placeholder":"​","style":"IPY_MODEL_81ce4244f06649f7a852bbbcb8e6de03","value":" 446k/446k [00:00&lt;00:00, 609kB/s]"}},"3235ac11228348578980f45ffca02e6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25aa1da131fc4f379cb65e4f55a1688c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e113d7f11eb0423bbf80d6ae48be773c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"753873935e034b62989c8bc0cf1260bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6429e386ee40478fab61eb81cfabdb8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"489b2fb487564b7080fdf08ebd0c82f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ce4244f06649f7a852bbbcb8e6de03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"036556b017254d49aa75e97a3e2774cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f890ffcde5443fda80abad9e04c7390","IPY_MODEL_a34b431d76df417f9c273e20e209c7ae","IPY_MODEL_1c1c93674fbe488e85a6e1285cb921d6"],"layout":"IPY_MODEL_45662e8179d640e99502be120e83ad52"}},"4f890ffcde5443fda80abad9e04c7390":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0165fa7d9b244989c860cfceac115a3","placeholder":"​","style":"IPY_MODEL_15a9abda553f4eedbbdd3a7c1d40b646","value":"100%"}},"a34b431d76df417f9c273e20e209c7ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fefd2580da384494b9138a43f1ae71e6","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eafe217d4c694369801bfcff980b781c","value":42146}},"1c1c93674fbe488e85a6e1285cb921d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bec9c8127e7485e9feeb4aa567b23c2","placeholder":"​","style":"IPY_MODEL_61e416cb3c214523ac93a964f27341f2","value":" 42146/42146 [00:31&lt;00:00, 2103.87it/s]"}},"45662e8179d640e99502be120e83ad52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0165fa7d9b244989c860cfceac115a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15a9abda553f4eedbbdd3a7c1d40b646":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fefd2580da384494b9138a43f1ae71e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eafe217d4c694369801bfcff980b781c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bec9c8127e7485e9feeb4aa567b23c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61e416cb3c214523ac93a964f27341f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e72afb327ad46faa73cbda5f7f987b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfc5af9d10974e76a043cc5d35067cc6","IPY_MODEL_68ced3c976c04c15a5dd0b6d628bfe05","IPY_MODEL_50b879d10f71417e9ec05866338a9602"],"layout":"IPY_MODEL_65aca0413919449e9d38a3d57d3397eb"}},"cfc5af9d10974e76a043cc5d35067cc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_825a952ce8f749aa877d2cacecf2a130","placeholder":"​","style":"IPY_MODEL_a10baceb9abf47c9b5b264bb13e6ed10","value":"100%"}},"68ced3c976c04c15a5dd0b6d628bfe05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82c69d96982045feace697e62b08e385","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ee36b8126054460ae47b42a2b78c120","value":143}},"50b879d10f71417e9ec05866338a9602":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a646899ba37f4cf0b9df27fe0cf5b081","placeholder":"​","style":"IPY_MODEL_f613bbc4eaff4dc9922fb47cc1f7fd03","value":" 143/143 [00:00&lt;00:00, 2363.76it/s]"}},"65aca0413919449e9d38a3d57d3397eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"825a952ce8f749aa877d2cacecf2a130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a10baceb9abf47c9b5b264bb13e6ed10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82c69d96982045feace697e62b08e385":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee36b8126054460ae47b42a2b78c120":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a646899ba37f4cf0b9df27fe0cf5b081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f613bbc4eaff4dc9922fb47cc1f7fd03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"804b2a4e2fe74220ae7a562e4fe9b947":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e08f2f5bc05b46bc9c23b1a4d496abf0","IPY_MODEL_05e6e8cb9f4f4ba69fc11028cda5de85","IPY_MODEL_f393cd5358a14875a767f405eb43d6be"],"layout":"IPY_MODEL_5a36f1c0e4eb4c9e85a6d355dfdcd17d"}},"e08f2f5bc05b46bc9c23b1a4d496abf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad45ffb3a76c4550844434522e46bc66","placeholder":"​","style":"IPY_MODEL_142a5671af8c49db897ef5e57132e64d","value":"Downloading: 100%"}},"05e6e8cb9f4f4ba69fc11028cda5de85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4319e7e14e49472d9873e27b8f8226cc","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a6949f16c2f4569a2ed8d6cf83f2300","value":1627284589}},"f393cd5358a14875a767f405eb43d6be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5a6a722e2c043c395ddd42e5af0eced","placeholder":"​","style":"IPY_MODEL_7d5cc694c6ef42889fad9710c3017d5e","value":" 1.52G/1.52G [00:32&lt;00:00, 50.2MB/s]"}},"5a36f1c0e4eb4c9e85a6d355dfdcd17d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad45ffb3a76c4550844434522e46bc66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142a5671af8c49db897ef5e57132e64d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4319e7e14e49472d9873e27b8f8226cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a6949f16c2f4569a2ed8d6cf83f2300":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5a6a722e2c043c395ddd42e5af0eced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d5cc694c6ef42889fad9710c3017d5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d4457fc2ced403f8fdc30f7b5e73fdd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fe3ad97584845e39369defc144a5b1a","IPY_MODEL_bbe93a19ef544577b0c8d4658a6ba955","IPY_MODEL_17da435db97c4130a89ce857fd5f778c"],"layout":"IPY_MODEL_4709f234dbd04f1c9e08dcd879911add"}},"9fe3ad97584845e39369defc144a5b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acb74eb656a34697a0c11bf00c90aa21","placeholder":"​","style":"IPY_MODEL_4fd88d5a168349eca4787bed39dd6a57","value":"100%"}},"bbe93a19ef544577b0c8d4658a6ba955":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bde81a206e5419a96b43aa607ff2dd6","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a42c8a8fdce046599c033efd837bb818","value":3}},"17da435db97c4130a89ce857fd5f778c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf2eb96f21564ecf9e21a0f97c1a38d3","placeholder":"​","style":"IPY_MODEL_696dec4ab83643c7a260b4764824ede6","value":" 3/3 [00:01&lt;00:00,  1.71it/s]"}},"4709f234dbd04f1c9e08dcd879911add":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acb74eb656a34697a0c11bf00c90aa21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fd88d5a168349eca4787bed39dd6a57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bde81a206e5419a96b43aa607ff2dd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a42c8a8fdce046599c033efd837bb818":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf2eb96f21564ecf9e21a0f97c1a38d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"696dec4ab83643c7a260b4764824ede6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2e3517d51e24e3685b40409991c23b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a72551ae1b1420b8d7d513eca28a8cc","IPY_MODEL_97a23b511d054da49580bff31acde80e","IPY_MODEL_2cb4420ec1d2453e90d01d27d293c8a4"],"layout":"IPY_MODEL_2fc8483ae852488991aae56f7425c16c"}},"1a72551ae1b1420b8d7d513eca28a8cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_897c741c93fc41f2b0d3d3c87c9cc566","placeholder":"​","style":"IPY_MODEL_afce95bc76ef4434a7067dced39b6920","value":"100%"}},"97a23b511d054da49580bff31acde80e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3519d15501644f0c88ba2878a6b07e43","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_258c2c4c47084b2b92600a3d44bbad4b","value":3}},"2cb4420ec1d2453e90d01d27d293c8a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78978057682041c39051b47f9fcae909","placeholder":"​","style":"IPY_MODEL_e1e517a805b24165a31d218535327f33","value":" 3/3 [00:02&lt;00:00,  1.48it/s]"}},"2fc8483ae852488991aae56f7425c16c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"897c741c93fc41f2b0d3d3c87c9cc566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afce95bc76ef4434a7067dced39b6920":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3519d15501644f0c88ba2878a6b07e43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"258c2c4c47084b2b92600a3d44bbad4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78978057682041c39051b47f9fcae909":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e517a805b24165a31d218535327f33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}