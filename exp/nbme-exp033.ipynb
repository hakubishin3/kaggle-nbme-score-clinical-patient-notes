{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "great-glasgow",
   "metadata": {
    "id": "incredible-principle"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-pearl",
   "metadata": {
    "id": "simplified-tract"
   },
   "source": [
    "- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n",
    "- https://www.kaggle.com/abebe9849/nbmeexp019?select=itpt.py\n",
    "- https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-itpt\n",
    "- https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-satisfaction",
   "metadata": {
    "id": "boolean-shame"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-lemon",
   "metadata": {
    "id": "needed-consistency"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"nbme-exp033\"\n",
    "ENV = \"local\"\n",
    "DEBUG_MODE = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expressed-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 12 00:11:45 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 40%   29C    P8     8W / 280W |     15MiB / 24219MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bulgarian-timber",
   "metadata": {
    "id": "operational-trader"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env=ENV\n",
    "    exp_name=EXP_NAME\n",
    "    debug=DEBUG_MODE\n",
    "    submission=SUBMISSION_MODE\n",
    "    apex=True\n",
    "    input_dir=None\n",
    "    output_dir=None\n",
    "    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n",
    "    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n",
    "    competition_name=\"nbme-score-clinical-patient-notes\"\n",
    "    id_col=\"id\"\n",
    "    target_col=\"location\"\n",
    "    pretrained_model_name=\"roberta-large\"\n",
    "    tokenizer=None\n",
    "    max_len=None\n",
    "    output_dim=1\n",
    "    dropout=0.2\n",
    "    num_workers=4\n",
    "    batch_size=8\n",
    "    lr=2e-5\n",
    "    betas=(0.9, 0.98)\n",
    "    weight_decay=0.1\n",
    "    num_warmup_steps_rate=0.1\n",
    "    batch_scheduler=True\n",
    "    epochs=5\n",
    "    n_fold=5\n",
    "    train_fold=[0, 1, 2, 3, 4]\n",
    "    seed=71\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "utility-allocation",
   "metadata": {
    "id": "g6Cc8fDp2Nle"
   },
   "outputs": [],
   "source": [
    "class CFG_For_MLM:\n",
    "    epochs = 15 # adjust\n",
    "    learning_rate = 5e-05\n",
    "    train_batch_size = 8\n",
    "    gradient_accum_steps = 4\n",
    "    eval_batch_size = 16\n",
    "    eval_steps = 8678\n",
    "    block_size = 466 # tokenizerのmax_length\n",
    "    mlm_prob = 0.15\n",
    "    fp16 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "velvet-tucson",
   "metadata": {
    "id": "seasonal-consistency"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]\n",
    "\n",
    "if CFG.submission:\n",
    "    CFG.train = False\n",
    "    CFG.inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-indian",
   "metadata": {
    "id": "billion-composite"
   },
   "source": [
    "## Directory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charitable-holiday",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4861,
     "status": "ok",
     "timestamp": 1645861057787,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "desperate-collect",
    "outputId": "5fe1bfad-5d36-4201-a4a2-f84d8a7d809d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(CFG.env)\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    # install packages\n",
    "    !pip install -q sentencepiece==0.1.96\n",
    "    !pip install -q transformers==4.16.2\n",
    "\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-universe",
   "metadata": {
    "id": "acute-pregnancy"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import BartModel,BertModel,BertTokenizer\n",
    "from transformers import DebertaModel,DebertaTokenizer\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "divine-vietnam",
   "metadata": {
    "id": "IW4rCfxa1wyC"
   },
   "outputs": [],
   "source": [
    "from transformers import (AutoModel, \n",
    "                          AutoModelForMaskedLM,\n",
    "                          AutoTokenizer,\n",
    "                          AutoConfig,\n",
    "                          AdamW,\n",
    "                          LineByLineTextDataset,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          Trainer,\n",
    "                          TrainingArguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-slave",
   "metadata": {
    "id": "generous-raleigh"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tutorial-rocket",
   "metadata": {
    "id": "mmZHVaPkh0Qc"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "different-jungle",
   "metadata": {
    "id": "IydDnpFyh4PX"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-livestock",
   "metadata": {
    "id": "formed-handbook"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compatible-plymouth",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1645861061670,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "vanilla-register",
    "outputId": "21d382a3-c203-4855-f7fd-e0f08cfaf2f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14300, 6), (143, 3), (42146, 3), (5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.input_dir / \"train.csv\")\n",
    "features = pd.read_csv(CFG.input_dir / \"features.csv\")\n",
    "patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n",
    "test = pd.read_csv(CFG.input_dir / \"test.csv\")\n",
    "\n",
    "train.shape, features.shape, patient_notes.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vocational-comment",
   "metadata": {
    "id": "approximate-transmission"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-graph",
   "metadata": {
    "id": "civic-advisory"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atomic-remainder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1645861062051,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "dPHRME1x0a6j",
    "outputId": "a33b6872-352f-4fd9-fe39-de92cdf40a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42146\n"
     ]
    }
   ],
   "source": [
    "pretrain_texts = patient_notes[\"pn_history\"].unique()\n",
    "print(len(pretrain_texts))\n",
    "\n",
    "\n",
    "with open(CFG.output_dir / \"text.txt\", \"w\") as f:\n",
    "    texts  = \"\\n\".join(pretrain_texts.tolist())\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-guarantee",
   "metadata": {
    "id": "senior-wichita"
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excess-cameroon",
   "metadata": {
    "id": "thrown-theology"
   },
   "outputs": [],
   "source": [
    "if CFG.submission:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\", trim_offsets=False)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name, trim_offsets=False)\n",
    "    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "remarkable-attendance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'', 0, 0\n",
      "'dad', 0, 3\n",
      "' with', 3, 8\n",
      "' recent', 8, 15\n",
      "' heart', 15, 21\n",
      "' attack', 21, 28\n",
      "'', 0, 0\n",
      "ans\n",
      "\n",
      "'', 0, 0\n",
      "'dad', 0, 3\n",
      "' with', 3, 8\n",
      "' recent', 8, 15\n",
      "' heart', 15, 21\n",
      "' attack', 21, 28\n",
      "'', 0, 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = 'dad with recent heart attack'\n",
    "encode = tokenizer(tmp, return_offsets_mapping=True)\n",
    "for (start,end) in encode['offset_mapping']:\n",
    "    print(f\"'{tmp[start:end]}', {start}, {end}\")\n",
    "\n",
    "print(\"ans\")\n",
    "print(\"\"\"\n",
    "'', 0, 0\n",
    "'dad', 0, 3\n",
    "' with', 3, 8\n",
    "' recent', 8, 15\n",
    "' heart', 15, 21\n",
    "' attack', 21, 28\n",
    "'', 0, 0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-cooper",
   "metadata": {
    "id": "ZbXou2dp152b"
   },
   "source": [
    "## Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "widespread-sucking",
   "metadata": {
    "id": "a-o-wrnz1n-a"
   },
   "outputs": [],
   "source": [
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer=CFG.tokenizer,\n",
    "    file_path=CFG.output_dir / \"text.txt\",\n",
    "    block_size=CFG_For_MLM.block_size)\n",
    "\n",
    "valid_dataset = LineByLineTextDataset(\n",
    "    tokenizer=CFG.tokenizer,\n",
    "    file_path=CFG.output_dir / \"text.txt\",\n",
    "    block_size=CFG_For_MLM.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "appropriate-mining",
   "metadata": {
    "id": "o-XhXXOx2z4d"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=CFG.tokenizer, \n",
    "    mlm=True, \n",
    "    mlm_probability=CFG_For_MLM.mlm_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-wellington",
   "metadata": {
    "id": "JaGyEd0r3i0W"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "completed-tracker",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1889,
     "status": "ok",
     "timestamp": 1645861087570,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "l6v9UUtX3h8m",
    "outputId": "fe951334-cb48-4681-eed2-c065e2691367"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(CFG.pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-password",
   "metadata": {
    "id": "seventh-configuration"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "guilty-faith",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5222,
     "status": "ok",
     "timestamp": 1645861092785,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "rocky-lexington",
    "outputId": "226f954d-8f15-43d4-dcc2-a96035789085"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=CFG.output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=CFG_For_MLM.epochs,\n",
    "    per_device_train_batch_size=CFG_For_MLM.train_batch_size,\n",
    "    per_device_eval_batch_size=CFG_For_MLM.eval_batch_size,\n",
    "    learning_rate=CFG_For_MLM.learning_rate,\n",
    "    gradient_accumulation_steps=CFG_For_MLM.gradient_accum_steps,\n",
    "    fp16=CFG_For_MLM.fp16,\n",
    "    eval_steps=CFG_For_MLM.eval_steps,\n",
    "    save_steps=CFG_For_MLM.eval_steps,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    "    prediction_loss_only=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unexpected-ceiling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 24631372,
     "status": "ok",
     "timestamp": 1645913902114,
     "user": {
      "displayName": "Shuhei Goda",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08246931244224045522"
     },
     "user_tz": -540
    },
    "id": "LmU2Kx_p3qGh",
    "outputId": "00f1762a-aab6-42f5-c255-aa13468f0daa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 277742\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 130185\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130185' max='130185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130185/130185 29:44:07, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8678</td>\n",
       "      <td>1.075000</td>\n",
       "      <td>0.991411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17356</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.916570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26034</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.872384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34712</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.822928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43390</td>\n",
       "      <td>0.852300</td>\n",
       "      <td>0.790142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52068</td>\n",
       "      <td>0.831200</td>\n",
       "      <td>0.769994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60746</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.743874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69424</td>\n",
       "      <td>0.773700</td>\n",
       "      <td>0.725133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78102</td>\n",
       "      <td>0.734700</td>\n",
       "      <td>0.699365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86780</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.687088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95458</td>\n",
       "      <td>0.702100</td>\n",
       "      <td>0.667751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104136</td>\n",
       "      <td>0.705800</td>\n",
       "      <td>0.647903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112814</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>0.635083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121492</td>\n",
       "      <td>0.657800</td>\n",
       "      <td>0.621203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130170</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>0.616843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-8678\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-8678/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-8678/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-121492] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-17356\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-17356/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-17356/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-26034\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-26034/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-26034/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-8678] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-34712\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-34712/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-34712/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-17356] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-43390\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-43390/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-43390/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-26034] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-52068\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-52068/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-52068/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-34712] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-60746\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-60746/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-60746/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-43390] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-69424\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-69424/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-69424/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-52068] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-78102\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-78102/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-78102/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-60746] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-86780\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-86780/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-86780/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-69424] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-95458\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-95458/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-95458/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-78102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-104136\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-104136/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-104136/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-86780] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-112814\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-112814/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-112814/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-95458] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-121492\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-121492/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-121492/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-104136] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 277742\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170/pytorch_model.bin\n",
      "Deleting older checkpoint [../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-112814] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../output/nbme-score-clinical-patient-notes/nbme-exp033/checkpoint-130170 (score: 0.6168426275253296).\n",
      "Saving model checkpoint to ../output/nbme-score-clinical-patient-notes/nbme-exp033\n",
      "Configuration saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/config.json\n",
      "Model weights saved in ../output/nbme-score-clinical-patient-notes/nbme-exp033/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(CFG.output_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "nbme-exp004.ipynb",
   "provenance": [
    {
     "file_id": "1k6U1erE6sYu9U7bfGdYhvEovwiTN0ehD",
     "timestamp": 1645625636482
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
