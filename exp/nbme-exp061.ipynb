{"cells":[{"cell_type":"markdown","id":"colored-security","metadata":{"id":"colored-security"},"source":["## References"]},{"cell_type":"markdown","id":"educational-operator","metadata":{"id":"educational-operator"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"incorrect-greek","metadata":{"id":"incorrect-greek"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"alive-granny","metadata":{"id":"alive-granny","executionInfo":{"status":"ok","timestamp":1647961603695,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp061\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"heavy-prophet","metadata":{"id":"heavy-prophet","executionInfo":{"status":"ok","timestamp":1647961603695,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"vocational-coating","metadata":{"id":"vocational-coating","executionInfo":{"status":"ok","timestamp":1647961603696,"user_tz":-540,"elapsed":4,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"private-moderator","metadata":{"id":"private-moderator"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"married-tokyo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"married-tokyo","outputId":"22aa364a-2eae-4e86-8c51-c3102b7e3a2c","executionInfo":{"status":"ok","timestamp":1647961610200,"user_tz":-540,"elapsed":6508,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.49)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"blank-pierre","metadata":{"id":"blank-pierre","executionInfo":{"status":"ok","timestamp":1647961619464,"user_tz":-540,"elapsed":9268,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"sound-still","metadata":{"id":"sound-still"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"surprised-commercial","metadata":{"id":"surprised-commercial","executionInfo":{"status":"ok","timestamp":1647961619465,"user_tz":-540,"elapsed":22,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"interstate-accident","metadata":{"id":"interstate-accident","executionInfo":{"status":"ok","timestamp":1647961619465,"user_tz":-540,"elapsed":20,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"coated-pioneer","metadata":{"id":"coated-pioneer","executionInfo":{"status":"ok","timestamp":1647961619465,"user_tz":-540,"elapsed":20,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"nervous-delaware","metadata":{"id":"nervous-delaware","executionInfo":{"status":"ok","timestamp":1647961619466,"user_tz":-540,"elapsed":21,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"functioning-destruction","metadata":{"id":"functioning-destruction"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"global-monte","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"global-monte","outputId":"71dc99d6-0060-40e1-f3d4-a2cc6626001a","executionInfo":{"status":"ok","timestamp":1647961620530,"user_tz":-540,"elapsed":1084,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"independent-airfare","metadata":{"id":"independent-airfare","executionInfo":{"status":"ok","timestamp":1647961620530,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"silent-locator","metadata":{"id":"silent-locator"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"unusual-fifty","metadata":{"id":"unusual-fifty","executionInfo":{"status":"ok","timestamp":1647961620531,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","execution_count":13,"id":"decreased-mustang","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"decreased-mustang","outputId":"896b2374-548a-4528-9f91-f00cf14f493a","executionInfo":{"status":"ok","timestamp":1647961620531,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":13}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":14,"id":"boolean-trade","metadata":{"id":"boolean-trade","executionInfo":{"status":"ok","timestamp":1647961620994,"user_tz":-540,"elapsed":467,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":15,"id":"accomplished-dakota","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"id":"accomplished-dakota","outputId":"dd5df366-cc13-434d-e72b-7374001e846d","executionInfo":{"status":"ok","timestamp":1647961620995,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"funded-elizabeth","metadata":{"id":"funded-elizabeth"},"source":["## CV split"]},{"cell_type":"code","execution_count":16,"id":"unexpected-columbia","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"unexpected-columbia","outputId":"12442535-4b3e-4a6e-a2ed-d239b54b450f","executionInfo":{"status":"ok","timestamp":1647961620995,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"critical-archive","metadata":{"id":"critical-archive"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":17,"id":"broken-generator","metadata":{"id":"broken-generator","executionInfo":{"status":"ok","timestamp":1647961625261,"user_tz":-540,"elapsed":4272,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","id":"compatible-lincoln","metadata":{"id":"compatible-lincoln"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":18,"id":"fluid-nancy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e49e7d913b014b799bb6c430ea437050","846aed472ec1445c9821d997a160761b","fe8a514f09f849d9a1202b114b81ca67","afa41d99c01742fbb5a36f78d483688a","83339685e60f4e269a7ce90195b0b835","709941fbb4854281b034afe2a110eedf","f2c5fd44170943ed9728b67b4b141b58","42f270b69e8f4f7d9335b4d6812a231e","aa686274513846b0b5327f74cce07feb","2f17f251ed64466795062c4c7aecd197","91bf0d41ddd749c4897cb9dae7142f9e"]},"id":"fluid-nancy","outputId":"f65c1596-a5ad-47d0-931e-8f98fafa511b","executionInfo":{"status":"ok","timestamp":1647961662638,"user_tz":-540,"elapsed":37383,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e49e7d913b014b799bb6c430ea437050"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 433\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":19,"id":"posted-humidity","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["8e366494600f4459926de98f519c3c2d","d6c5f982485147bdbb7a34bb579a556e","adf4fd58487d46feb0075cbea4126202","863ceb6b39164f3489f65608cffdc2c9","dba83b2fb2344eeba1869222129ec79d","4866556d6b78497eb91bd528dd47ac08","0ddc3908eaae406dae32f3e27b2d16cb","eae395eeef8640c68388946f1e6542ed","5efcdb440400444a9da477697ba71e89","96a28a87bf5d43339130946a25bfd0a8","75881f5d7f3f4022a805ce931dbb4535"]},"id":"posted-humidity","outputId":"40fbcad3-e655-4de2-8f21-e6aa490841e4","executionInfo":{"status":"ok","timestamp":1647961662639,"user_tz":-540,"elapsed":30,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e366494600f4459926de98f519c3c2d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":20,"id":"resistant-amount","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"resistant-amount","outputId":"c08c9f17-34bc-48d0-be3b-9a8359734728","executionInfo":{"status":"ok","timestamp":1647961662639,"user_tz":-540,"elapsed":27,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 466\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":21,"id":"august-equity","metadata":{"id":"august-equity","executionInfo":{"status":"ok","timestamp":1647961662640,"user_tz":-540,"elapsed":26,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":22,"id":"weird-interaction","metadata":{"id":"weird-interaction","executionInfo":{"status":"ok","timestamp":1647961662640,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"upper-mobility","metadata":{"id":"upper-mobility"},"source":["## Model"]},{"cell_type":"code","execution_count":23,"id":"spanish-destruction","metadata":{"id":"spanish-destruction","executionInfo":{"status":"ok","timestamp":1647961662640,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"chronic-bullet","metadata":{"id":"chronic-bullet"},"source":["## Training"]},{"cell_type":"code","source":["def dice_loss(y_pred, y_true):\n","    y_pred = y_pred.sigmoid()\n","    intersect = (y_true * y_pred).sum(axis=1)\n","    return 1 - (intersect / (intersect + y_true.sum(axis=1) + y_pred.sum(axis=1)))"],"metadata":{"id":"J7qgt4asI-EI","executionInfo":{"status":"ok","timestamp":1647961662640,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"J7qgt4asI-EI","execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"id":"biological-hunger","metadata":{"id":"biological-hunger","executionInfo":{"status":"ok","timestamp":1647961662641,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        loss_dice = dice_loss(output.view(-1, 1), labels.view(-1, 1))\n","        loss_dice = torch.masked_select(loss_dice, labels.view(-1, 1) != -1)\n","        loss_dice = loss_dice.mean()\n","\n","        loss = (loss + loss_dice) * 0.5\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":26,"id":"satisfied-sterling","metadata":{"id":"satisfied-sterling","executionInfo":{"status":"ok","timestamp":1647961662641,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        loss_dice = dice_loss(output.view(-1, 1), labels.view(-1, 1))\n","        loss_dice = torch.masked_select(loss_dice, labels.view(-1, 1) != -1)\n","        loss_dice = loss_dice.mean()\n","\n","        loss = (loss + loss_dice) * 0.5\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":27,"id":"incorporate-viking","metadata":{"id":"incorporate-viking","executionInfo":{"status":"ok","timestamp":1647961662641,"user_tz":-540,"elapsed":25,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":28,"id":"dental-sunset","metadata":{"id":"dental-sunset","executionInfo":{"status":"ok","timestamp":1647961662641,"user_tz":-540,"elapsed":24,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"brazilian-graphics","metadata":{"id":"brazilian-graphics"},"source":["## Main"]},{"cell_type":"code","execution_count":29,"id":"connected-protein","metadata":{"id":"connected-protein","executionInfo":{"status":"ok","timestamp":1647961662641,"user_tz":-540,"elapsed":23,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"id":"serious-bunny","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["83bcf8b640694ea98c0bcee9ba680288","8d9b9dcf828c48a891a0bb1a6f652b85","e83126322c654456a94546c66bcf2c3e","50dfd5f5e1924076a8de2c3d658fee58","bf0b99955aff4e4fa68aad7c70a8bc81","6432c1ee66384b8696107f34252cbe4f","73e22e85ec224fdc9b5d1944a72ad7ed","9a237130fbe84224898ffb125cb33cd5","320ccd4613af4a76bc78a188b9c53ede","b7ca9bb9646945cb9d89c26d68411f3b","dc1d1243e80c45ada8e44f1b121a8a97","32596053994d44e3b4a5b56588d897dc","a157fcb7ccbc47b5b44676f35eb51669","1f5ff5dd342147c082768bea17a10526","77b212337d5941bc818d630abd5327cf","9e33ec7100024de8b87f74b338d7d094","7e7929d944b04bf398541bf24a731551","5d4d987dd6584503ae42baacc89bd753","573e0247d8fc47af822c4a34f5abbf93","318de2fac1e64a48aacd8f2d6179c0ce","ca217057537a45cfa33e80c77489cf34","ed186079846345abbed836f8751756f6","566b48c1e53d43b3a80f300aa1794515","d2478baed65e426ca05e48663044a717","8015c034288d4794a440dbd98d46a211","89fb272a365e4e7287b60446d9984588","952a68a0529b46e6af881624f7cf3b79","884de52bbf8e42a59b702d98276e9a42","667ee42d99d148ab8c1046634cf69b76","682ab3900b2b43a6a56291216d6c6ef4","aeb2010d7a354f5699c7e22c83711c2a","128e0e6efbbc4f1f9586aa8e12770456","bd1e55a98c574326bbe26129be00c973"]},"id":"serious-bunny","outputId":"6789f0ec-72d0-446c-fdba-59f21d50546b"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 52m 21s) Loss: 0.3482(0.3482) Grad: 86136.5703  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 28s (remain 16m 7s) Loss: 0.3074(0.3424) Grad: 41356.6758  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 55s (remain 15m 27s) Loss: 0.2027(0.3017) Grad: 25756.2852  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 23s (remain 15m 11s) Loss: 0.1180(0.2579) Grad: 4266.0591  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 50s (remain 14m 38s) Loss: 0.1351(0.2293) Grad: 2637.9111  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 18s (remain 14m 9s) Loss: 0.1432(0.2120) Grad: 2692.2825  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 45s (remain 13m 39s) Loss: 0.1306(0.1999) Grad: 2203.3037  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 12s (remain 13m 10s) Loss: 0.1292(0.1909) Grad: 4772.4448  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 39s (remain 12m 41s) Loss: 0.1316(0.1834) Grad: 19100.3262  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 7s (remain 12m 13s) Loss: 0.1336(0.1775) Grad: 2009.1263  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 34s (remain 11m 45s) Loss: 0.1354(0.1724) Grad: 14629.4639  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 1s (remain 11m 17s) Loss: 0.1259(0.1682) Grad: 1506.8032  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 28s (remain 10m 49s) Loss: 0.1170(0.1644) Grad: 3469.1011  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 55s (remain 10m 21s) Loss: 0.1530(0.1613) Grad: 17804.5234  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 22s (remain 9m 54s) Loss: 0.1306(0.1585) Grad: 16279.6348  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 50s (remain 9m 26s) Loss: 0.1180(0.1563) Grad: 8048.6753  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.1162(0.1542) Grad: 22866.7617  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 44s (remain 8m 31s) Loss: 0.1301(0.1523) Grad: 4069.0903  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 11s (remain 8m 4s) Loss: 0.1288(0.1507) Grad: 11042.6514  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 38s (remain 7m 36s) Loss: 0.1165(0.1492) Grad: 4526.8911  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 5s (remain 7m 9s) Loss: 0.1083(0.1478) Grad: 1036.2036  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 33s (remain 6m 42s) Loss: 0.1356(0.1464) Grad: 2909.3594  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 0s (remain 6m 14s) Loss: 0.1027(0.1452) Grad: 1298.1168  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 27s (remain 5m 47s) Loss: 0.1179(0.1443) Grad: 4290.8345  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 54s (remain 5m 20s) Loss: 0.1060(0.1434) Grad: 1040.2375  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 21s (remain 4m 52s) Loss: 0.1246(0.1426) Grad: 232.1351  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 48s (remain 4m 25s) Loss: 0.1181(0.1418) Grad: 103.1877  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 16s (remain 3m 58s) Loss: 0.1123(0.1410) Grad: 4365.7778  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 43s (remain 3m 30s) Loss: 0.1119(0.1403) Grad: 2149.8242  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 10s (remain 3m 3s) Loss: 0.1396(0.1396) Grad: 6193.6006  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 37s (remain 2m 36s) Loss: 0.1276(0.1390) Grad: 1262.4421  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 4s (remain 2m 9s) Loss: 0.1305(0.1383) Grad: 4689.0278  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 31s (remain 1m 41s) Loss: 0.1266(0.1376) Grad: 9037.6357  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 14m 59s (remain 1m 14s) Loss: 0.1143(0.1370) Grad: 1874.1731  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 26s (remain 0m 47s) Loss: 0.1247(0.1365) Grad: 2241.5515  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 53s (remain 0m 20s) Loss: 0.1238(0.1360) Grad: 162.4106  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 13s (remain 0m 0s) Loss: 0.1219(0.1357) Grad: 6449.2925  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 27s) Loss: 0.1471(0.1471) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1133(0.1213) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.2228(0.1218) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1314(0.1239) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.1033(0.1241) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1300(0.1225) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1366(0.1220) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1574(0.1219) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1237(0.1220) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1146(0.1221) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.1196(0.1226) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1187(0.1211) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0907(0.1205) \n","Epoch 1 - avg_train_loss: 0.1357  avg_val_loss: 0.1205  time: 1151s\n","Epoch 1 - Score: 0.8428\n","Epoch 1 - Save Best Score: 0.8428 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 37m 49s) Loss: 0.1405(0.1405) Grad: 6229.3462  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 29s (remain 16m 52s) Loss: 0.1530(0.1192) Grad: 6281.6255  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 57s (remain 15m 59s) Loss: 0.1178(0.1192) Grad: 440.8941  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 24s (remain 15m 17s) Loss: 0.1287(0.1189) Grad: 6554.8232  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 51s (remain 14m 43s) Loss: 0.1212(0.1188) Grad: 8335.1572  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 18s (remain 14m 11s) Loss: 0.1213(0.1190) Grad: 13995.9482  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 45s (remain 13m 41s) Loss: 0.0985(0.1191) Grad: 9888.8438  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 13s (remain 13m 12s) Loss: 0.1296(0.1192) Grad: 3734.7817  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 40s (remain 12m 43s) Loss: 0.1371(0.1193) Grad: 6317.2363  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 7s (remain 12m 15s) Loss: 0.1154(0.1193) Grad: 12440.0762  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 35s (remain 11m 47s) Loss: 0.1247(0.1193) Grad: 316.3436  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 2s (remain 11m 19s) Loss: 0.1298(0.1193) Grad: 27888.1348  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 29s (remain 10m 51s) Loss: 0.1179(0.1194) Grad: 6329.7485  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 56s (remain 10m 23s) Loss: 0.1287(0.1194) Grad: 798.8884  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 23s (remain 9m 55s) Loss: 0.1065(0.1194) Grad: 64.3965  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 51s (remain 9m 28s) Loss: 0.1233(0.1194) Grad: 2775.4377  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 18s (remain 9m 0s) Loss: 0.1131(0.1192) Grad: 3218.6917  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 45s (remain 8m 32s) Loss: 0.1077(0.1193) Grad: 10618.4844  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 12s (remain 8m 5s) Loss: 0.1145(0.1193) Grad: 495.7059  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.1166(0.1194) Grad: 6298.5664  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 7s (remain 7m 10s) Loss: 0.1249(0.1194) Grad: 10832.2773  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 34s (remain 6m 42s) Loss: 0.1224(0.1194) Grad: 6164.3452  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 1s (remain 6m 15s) Loss: 0.1142(0.1195) Grad: 19730.4941  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 28s (remain 5m 48s) Loss: 0.1390(0.1194) Grad: 3618.0183  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 56s (remain 5m 20s) Loss: 0.1165(0.1193) Grad: 7721.5352  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 23s (remain 4m 53s) Loss: 0.1114(0.1193) Grad: 10627.1250  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 50s (remain 4m 26s) Loss: 0.1094(0.1193) Grad: 4573.1401  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 17s (remain 3m 58s) Loss: 0.1202(0.1194) Grad: 5156.4658  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 44s (remain 3m 31s) Loss: 0.1123(0.1194) Grad: 328.1870  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.1130(0.1194) Grad: 12190.5840  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 39s (remain 2m 36s) Loss: 0.1207(0.1194) Grad: 1400.1266  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 6s (remain 2m 9s) Loss: 0.1239(0.1194) Grad: 33263.7930  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 33s (remain 1m 42s) Loss: 0.1184(0.1194) Grad: 116.6926  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 0s (remain 1m 14s) Loss: 0.1108(0.1194) Grad: 4338.9316  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 27s (remain 0m 47s) Loss: 0.1097(0.1193) Grad: 16.7777  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 54s (remain 0m 20s) Loss: 0.1424(0.1193) Grad: 934.5377  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 15s (remain 0m 0s) Loss: 0.1049(0.1192) Grad: 7200.7373  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 9s) Loss: 0.1466(0.1466) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.1087(0.1205) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.2092(0.1207) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1330(0.1227) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1038(0.1229) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1240(0.1214) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1326(0.1209) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1518(0.1208) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1225(0.1209) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1172(0.1211) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1195(0.1217) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1190(0.1202) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0905(0.1196) \n","Epoch 2 - avg_train_loss: 0.1192  avg_val_loss: 0.1196  time: 1151s\n","Epoch 2 - Score: 0.8736\n","Epoch 2 - Save Best Score: 0.8736 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 36m 43s) Loss: 0.1199(0.1199) Grad: 2872.4246  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 28s (remain 16m 29s) Loss: 0.1188(0.1184) Grad: 134.5276  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 56s (remain 15m 47s) Loss: 0.1196(0.1182) Grad: 2794.9890  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 23s (remain 15m 8s) Loss: 0.1193(0.1182) Grad: 10867.6895  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 50s (remain 14m 36s) Loss: 0.1176(0.1182) Grad: 21606.2871  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 17s (remain 14m 5s) Loss: 0.1235(0.1184) Grad: 75.1585  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 44s (remain 13m 36s) Loss: 0.1613(0.1183) Grad: 59472.0352  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 12s (remain 13m 7s) Loss: 0.1174(0.1184) Grad: 2853.6140  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 39s (remain 12m 39s) Loss: 0.1166(0.1184) Grad: 364.6188  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 6s (remain 12m 10s) Loss: 0.0939(0.1187) Grad: 175.8489  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 33s (remain 11m 43s) Loss: 0.1081(0.1187) Grad: 225.8252  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 0s (remain 11m 15s) Loss: 0.1313(0.1184) Grad: 92.2834  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 27s (remain 10m 47s) Loss: 0.1298(0.1184) Grad: 7080.5713  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 55s (remain 10m 20s) Loss: 0.0989(0.1185) Grad: 47.7798  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 22s (remain 9m 53s) Loss: 0.1149(0.1185) Grad: 13114.6748  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 49s (remain 9m 25s) Loss: 0.1246(0.1186) Grad: 41.7650  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 16s (remain 8m 58s) Loss: 0.1215(0.1185) Grad: 8666.8291  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 43s (remain 8m 30s) Loss: 0.1123(0.1186) Grad: 814.9083  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 10s (remain 8m 3s) Loss: 0.1264(0.1187) Grad: 22710.1719  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 38s (remain 7m 36s) Loss: 0.1423(0.1187) Grad: 19761.6152  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 5s (remain 7m 8s) Loss: 0.1365(0.1187) Grad: 24521.5352  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 32s (remain 6m 41s) Loss: 0.1485(0.1187) Grad: 132681.4375  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 9m 59s (remain 6m 14s) Loss: 0.1150(0.1187) Grad: 28028.3379  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 26s (remain 5m 46s) Loss: 0.0952(0.1186) Grad: 8013.6465  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 53s (remain 5m 19s) Loss: 0.1147(0.1187) Grad: 4515.5068  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 20s (remain 4m 52s) Loss: 0.1156(0.1186) Grad: 10.3093  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 47s (remain 4m 25s) Loss: 0.1043(0.1185) Grad: 144.9010  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 15s (remain 3m 57s) Loss: 0.1453(0.1185) Grad: 5592.5664  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.1275(0.1185) Grad: 3671.1509  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 9s (remain 3m 3s) Loss: 0.1260(0.1185) Grad: 3440.9312  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 36s (remain 2m 36s) Loss: 0.0905(0.1185) Grad: 79.1896  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.1169(0.1185) Grad: 596.6295  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 30s (remain 1m 41s) Loss: 0.1130(0.1184) Grad: 2650.4272  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 14m 57s (remain 1m 14s) Loss: 0.1273(0.1185) Grad: 11.6305  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 24s (remain 0m 47s) Loss: 0.1175(0.1185) Grad: 531.8336  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 52s (remain 0m 20s) Loss: 0.1186(0.1185) Grad: 134.6543  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 12s (remain 0m 0s) Loss: 0.1085(0.1185) Grad: 1238.4785  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 5s) Loss: 0.1466(0.1466) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.1067(0.1206) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.2102(0.1208) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1323(0.1228) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.1035(0.1230) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1235(0.1215) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1306(0.1209) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1498(0.1208) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1227(0.1209) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1133(0.1211) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1195(0.1216) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1182(0.1202) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0905(0.1196) \n","Epoch 3 - avg_train_loss: 0.1185  avg_val_loss: 0.1196  time: 1152s\n","Epoch 3 - Score: 0.8808\n","Epoch 3 - Save Best Score: 0.8808 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 35m 6s) Loss: 0.1450(0.1450) Grad: 3447.0371  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 28s (remain 16m 25s) Loss: 0.1037(0.1184) Grad: 6231.8286  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 56s (remain 15m 50s) Loss: 0.1222(0.1183) Grad: 1763.1456  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 24s (remain 15m 14s) Loss: 0.1106(0.1181) Grad: 18.6444  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 51s (remain 14m 40s) Loss: 0.1267(0.1183) Grad: 15369.0508  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 18s (remain 14m 8s) Loss: 0.1086(0.1184) Grad: 13247.0850  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 45s (remain 13m 38s) Loss: 0.1251(0.1185) Grad: 214.5233  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 12s (remain 13m 9s) Loss: 0.1255(0.1182) Grad: 6254.1377  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 39s (remain 12m 40s) Loss: 0.1126(0.1178) Grad: 23.4476  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 6s (remain 12m 12s) Loss: 0.1557(0.1178) Grad: 13.3400  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 33s (remain 11m 44s) Loss: 0.1219(0.1179) Grad: 95.3320  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 1s (remain 11m 16s) Loss: 0.1238(0.1179) Grad: 19.5004  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 28s (remain 10m 48s) Loss: 0.1253(0.1177) Grad: 82.9392  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 55s (remain 10m 20s) Loss: 0.1185(0.1178) Grad: 2149.4231  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 22s (remain 9m 53s) Loss: 0.1115(0.1178) Grad: 4384.6484  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 49s (remain 9m 26s) Loss: 0.1039(0.1178) Grad: 725.8370  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 16s (remain 8m 58s) Loss: 0.1520(0.1178) Grad: 500.8813  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 44s (remain 8m 31s) Loss: 0.1119(0.1179) Grad: 6.2067  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 11s (remain 8m 3s) Loss: 0.1134(0.1177) Grad: 48.1055  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 38s (remain 7m 36s) Loss: 0.1170(0.1177) Grad: 6321.9194  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 5s (remain 7m 9s) Loss: 0.1230(0.1177) Grad: 9683.4707  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 32s (remain 6m 41s) Loss: 0.1242(0.1177) Grad: 3450.4592  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 9m 59s (remain 6m 14s) Loss: 0.1305(0.1178) Grad: 7655.5254  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 26s (remain 5m 47s) Loss: 0.1149(0.1179) Grad: 6627.9282  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 54s (remain 5m 19s) Loss: 0.1209(0.1179) Grad: 17.6655  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 21s (remain 4m 52s) Loss: 0.1085(0.1178) Grad: 2501.8025  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 48s (remain 4m 25s) Loss: 0.0957(0.1179) Grad: 29.6347  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 15s (remain 3m 57s) Loss: 0.1222(0.1179) Grad: 11668.0400  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.1185(0.1179) Grad: 3534.4055  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 9s (remain 3m 3s) Loss: 0.1071(0.1179) Grad: 5570.1050  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 36s (remain 2m 36s) Loss: 0.1090(0.1179) Grad: 23.4981  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.0988(0.1180) Grad: 2190.8650  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 30s (remain 1m 41s) Loss: 0.1032(0.1179) Grad: 15.0666  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 14m 58s (remain 1m 14s) Loss: 0.1081(0.1180) Grad: 10.3398  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 25s (remain 0m 47s) Loss: 0.1160(0.1179) Grad: 1073.6056  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 52s (remain 0m 20s) Loss: 0.1260(0.1180) Grad: 102.6544  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 12s (remain 0m 0s) Loss: 0.1127(0.1180) Grad: 890.4129  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 4s) Loss: 0.1465(0.1465) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.1113(0.1211) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.2118(0.1215) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1323(0.1235) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1041(0.1237) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1238(0.1221) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1290(0.1216) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1589(0.1217) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1228(0.1219) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1136(0.1220) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1195(0.1226) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1188(0.1211) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0905(0.1205) \n","Epoch 4 - avg_train_loss: 0.1180  avg_val_loss: 0.1205  time: 1151s\n","Epoch 4 - Score: 0.8789\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 32m 44s) Loss: 0.1187(0.1187) Grad: 893.4834  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 27s (remain 15m 52s) Loss: 0.1184(0.1145) Grad: 35.0896  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 54s (remain 15m 20s) Loss: 0.1305(0.1166) Grad: 9.0368  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 21s (remain 14m 51s) Loss: 0.1288(0.1171) Grad: 5.0202  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.1112(0.1174) Grad: 20.2987  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 16s (remain 13m 55s) Loss: 0.1145(0.1176) Grad: 236.1816  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.1339(0.1178) Grad: 4810.3896  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 10s (remain 13m 1s) Loss: 0.1201(0.1179) Grad: 2.7703  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 37s (remain 12m 34s) Loss: 0.1033(0.1179) Grad: 5210.0439  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.1252(0.1178) Grad: 6.0769  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 31s (remain 11m 39s) Loss: 0.1718(0.1179) Grad: 29528.6035  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 59s (remain 11m 12s) Loss: 0.1331(0.1178) Grad: 18234.2559  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 26s (remain 10m 44s) Loss: 0.1418(0.1178) Grad: 1.4706  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.1336(0.1178) Grad: 7877.9629  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.1056(0.1177) Grad: 548.1885  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.0993(0.1177) Grad: 1209.2936  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 14s (remain 8m 55s) Loss: 0.1124(0.1177) Grad: 91.7854  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 41s (remain 8m 28s) Loss: 0.1295(0.1178) Grad: 1.9778  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 8s (remain 8m 1s) Loss: 0.1211(0.1178) Grad: 3597.0010  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 35s (remain 7m 34s) Loss: 0.1159(0.1178) Grad: 5.6074  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.1168(0.1178) Grad: 88.7581  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.1085(0.1178) Grad: 18726.1367  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 9m 57s (remain 6m 12s) Loss: 0.1096(0.1177) Grad: 6072.7627  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.1289(0.1178) Grad: 28.9578  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.1135(0.1178) Grad: 85.8789  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.1328(0.1178) Grad: 11.8736  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 45s (remain 4m 24s) Loss: 0.1156(0.1177) Grad: 613.1118  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 12s (remain 3m 57s) Loss: 0.1232(0.1177) Grad: 274.0738  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.1268(0.1176) Grad: 5115.1646  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.1197(0.1177) Grad: 18122.8379  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.1119(0.1177) Grad: 15.2579  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.1106(0.1176) Grad: 4065.1909  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.1157(0.1176) Grad: 1551.2799  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 14m 55s (remain 1m 14s) Loss: 0.0975(0.1176) Grad: 32.0158  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 22s (remain 0m 47s) Loss: 0.1222(0.1176) Grad: 4757.2202  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 49s (remain 0m 20s) Loss: 0.1316(0.1176) Grad: 74.8400  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.1295(0.1176) Grad: 3333.1392  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 18s) Loss: 0.1465(0.1465) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1077(0.1211) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.2110(0.1216) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1311(0.1236) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1045(0.1238) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1238(0.1222) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1305(0.1216) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1572(0.1217) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1232(0.1219) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1137(0.1220) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1195(0.1226) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1184(0.1211) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0905(0.1205) \n","Epoch 5 - avg_train_loss: 0.1176  avg_val_loss: 0.1205  time: 1146s\n","Epoch 5 - Score: 0.8783\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 38m 15s) Loss: 0.3620(0.3620) Grad: 91214.2891  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 27s (remain 15m 53s) Loss: 0.3198(0.3520) Grad: 10869.2393  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 54s (remain 15m 21s) Loss: 0.1971(0.2997) Grad: 4182.0464  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 22s (remain 14m 52s) Loss: 0.1301(0.2506) Grad: 570.0640  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 49s (remain 14m 23s) Loss: 0.1284(0.2237) Grad: 770.1989  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 16s (remain 13m 56s) Loss: 0.1197(0.2071) Grad: 433.3575  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 43s (remain 13m 28s) Loss: 0.1283(0.1956) Grad: 1365.0372  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 10s (remain 13m 1s) Loss: 0.1251(0.1866) Grad: 2268.3328  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 37s (remain 12m 33s) Loss: 0.1785(0.1793) Grad: 7739.3320  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 4s (remain 12m 6s) Loss: 0.1545(0.1737) Grad: 3868.1606  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 31s (remain 11m 39s) Loss: 0.1109(0.1688) Grad: 626.9909  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 59s (remain 11m 12s) Loss: 0.1264(0.1649) Grad: 1867.0320  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 26s (remain 10m 44s) Loss: 0.1291(0.1612) Grad: 1405.6506  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 53s (remain 10m 17s) Loss: 0.1214(0.1583) Grad: 274.2459  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 20s (remain 9m 50s) Loss: 0.1159(0.1558) Grad: 635.3301  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 47s (remain 9m 23s) Loss: 0.1230(0.1535) Grad: 124.1995  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 14s (remain 8m 56s) Loss: 0.1117(0.1514) Grad: 401.3987  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.1094(0.1496) Grad: 273.1329  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 9s (remain 8m 1s) Loss: 0.1213(0.1480) Grad: 1172.0972  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 36s (remain 7m 34s) Loss: 0.1158(0.1466) Grad: 166.1563  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 3s (remain 7m 7s) Loss: 0.1242(0.1454) Grad: 265.1827  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 30s (remain 6m 40s) Loss: 0.1275(0.1441) Grad: 812.6424  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 9m 57s (remain 6m 13s) Loss: 0.1177(0.1431) Grad: 286.1734  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 24s (remain 5m 45s) Loss: 0.1179(0.1421) Grad: 256.7554  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 51s (remain 5m 18s) Loss: 0.1178(0.1413) Grad: 329.7901  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 18s (remain 4m 51s) Loss: 0.1195(0.1406) Grad: 684.7102  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 46s (remain 4m 24s) Loss: 0.1282(0.1398) Grad: 19.5054  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 13s (remain 3m 57s) Loss: 0.1227(0.1391) Grad: 1261.7152  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 40s (remain 3m 30s) Loss: 0.1117(0.1385) Grad: 493.2630  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 7s (remain 3m 2s) Loss: 0.1102(0.1378) Grad: 1104.9032  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 34s (remain 2m 35s) Loss: 0.0995(0.1372) Grad: 181.3729  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 1s (remain 2m 8s) Loss: 0.1168(0.1367) Grad: 10.5380  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 28s (remain 1m 41s) Loss: 0.1179(0.1361) Grad: 514.5276  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 14m 56s (remain 1m 14s) Loss: 0.1202(0.1356) Grad: 130.7354  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 23s (remain 0m 47s) Loss: 0.1294(0.1352) Grad: 245.4519  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 50s (remain 0m 20s) Loss: 0.1174(0.1348) Grad: 105.7583  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 10s (remain 0m 0s) Loss: 0.1133(0.1345) Grad: 5.2976  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 51s) Loss: 0.1091(0.1091) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1127(0.1178) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1053(0.1161) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0990(0.1210) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1708(0.1193) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1241(0.1168) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1837(0.1177) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1229(0.1190) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1224(0.1194) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1028(0.1199) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1183(0.1204) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1211(0.1198) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1095(0.1188) \n","Epoch 1 - avg_train_loss: 0.1345  avg_val_loss: 0.1188  time: 1147s\n","Epoch 1 - Score: 0.8613\n","Epoch 1 - Save Best Score: 0.8613 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 38m 36s) Loss: 0.1347(0.1347) Grad: 22840.7305  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 28s (remain 16m 31s) Loss: 0.1240(0.1239) Grad: 7659.6138  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 56s (remain 15m 49s) Loss: 0.1466(0.1217) Grad: 4966.4141  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 23s (remain 15m 12s) Loss: 0.1027(0.1207) Grad: 262.7341  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 51s (remain 14m 39s) Loss: 0.1215(0.1205) Grad: 631.4279  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 18s (remain 14m 8s) Loss: 0.1029(0.1203) Grad: 12223.9609  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 45s (remain 13m 38s) Loss: 0.1259(0.1204) Grad: 242.7424  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 12s (remain 13m 9s) Loss: 0.1155(0.1202) Grad: 57.9049  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 39s (remain 12m 40s) Loss: 0.1269(0.1200) Grad: 5184.1865  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 6s (remain 12m 12s) Loss: 0.1102(0.1199) Grad: 3696.2466  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 34s (remain 11m 44s) Loss: 0.1064(0.1199) Grad: 6307.7192  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 1s (remain 11m 16s) Loss: 0.1029(0.1198) Grad: 4487.6890  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 28s (remain 10m 48s) Loss: 0.1046(0.1197) Grad: 238.9039  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 55s (remain 10m 21s) Loss: 0.1191(0.1196) Grad: 178.9281  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 22s (remain 9m 53s) Loss: 0.1170(0.1195) Grad: 41.9697  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 49s (remain 9m 26s) Loss: 0.0974(0.1195) Grad: 189.1721  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 16s (remain 8m 58s) Loss: 0.0869(0.1195) Grad: 594.7766  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 44s (remain 8m 31s) Loss: 0.1171(0.1194) Grad: 4532.4053  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 11s (remain 8m 3s) Loss: 0.0908(0.1194) Grad: 60.3151  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 38s (remain 7m 36s) Loss: 0.1216(0.1194) Grad: 11505.1221  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 5s (remain 7m 9s) Loss: 0.1321(0.1195) Grad: 27947.4570  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 32s (remain 6m 41s) Loss: 0.1258(0.1195) Grad: 19.7841  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 9m 59s (remain 6m 14s) Loss: 0.1035(0.1194) Grad: 12170.1572  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 27s (remain 5m 47s) Loss: 0.1326(0.1195) Grad: 37.8551  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 54s (remain 5m 19s) Loss: 0.1056(0.1196) Grad: 10882.8359  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 21s (remain 4m 52s) Loss: 0.1381(0.1196) Grad: 357.6375  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 48s (remain 4m 25s) Loss: 0.1125(0.1196) Grad: 8307.4434  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 15s (remain 3m 58s) Loss: 0.1227(0.1195) Grad: 1657.5610  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.1029(0.1195) Grad: 90.5512  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 10s (remain 3m 3s) Loss: 0.1375(0.1196) Grad: 17924.6602  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 37s (remain 2m 36s) Loss: 0.1187(0.1196) Grad: 1820.4999  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 4s (remain 2m 9s) Loss: 0.0946(0.1195) Grad: 1452.1772  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 31s (remain 1m 41s) Loss: 0.1328(0.1194) Grad: 2896.6438  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 14m 58s (remain 1m 14s) Loss: 0.1231(0.1194) Grad: 519.4269  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 25s (remain 0m 47s) Loss: 0.1220(0.1194) Grad: 10265.0967  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 53s (remain 0m 20s) Loss: 0.1255(0.1195) Grad: 14953.5049  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 13s (remain 0m 0s) Loss: 0.1174(0.1194) Grad: 90.7555  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 33s) Loss: 0.1089(0.1089) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1127(0.1180) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1056(0.1157) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0994(0.1203) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1708(0.1186) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1250(0.1160) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1697(0.1169) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1175(0.1181) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1277(0.1185) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1041(0.1189) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1183(0.1194) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1210(0.1189) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1092(0.1179) \n","Epoch 2 - avg_train_loss: 0.1194  avg_val_loss: 0.1179  time: 1158s\n","Epoch 2 - Score: 0.8733\n","Epoch 2 - Save Best Score: 0.8733 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 33m 11s) Loss: 0.1366(0.1366) Grad: 93.8664  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 28s (remain 16m 33s) Loss: 0.1270(0.1182) Grad: 7693.1558  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 56s (remain 15m 49s) Loss: 0.1193(0.1182) Grad: 19.7532  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 23s (remain 15m 10s) Loss: 0.1017(0.1189) Grad: 839.7360  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 51s (remain 14m 39s) Loss: 0.1096(0.1184) Grad: 73.9678  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 18s (remain 14m 9s) Loss: 0.1196(0.1185) Grad: 6924.4375  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 45s (remain 13m 40s) Loss: 0.1470(0.1186) Grad: 21.5675  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 13s (remain 13m 12s) Loss: 0.1149(0.1187) Grad: 3080.0371  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 40s (remain 12m 43s) Loss: 0.1227(0.1184) Grad: 2282.1482  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 7s (remain 12m 14s) Loss: 0.1280(0.1185) Grad: 17.1969  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 34s (remain 11m 46s) Loss: 0.1136(0.1185) Grad: 143.0609  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 1s (remain 11m 18s) Loss: 0.1235(0.1187) Grad: 3550.9685  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 29s (remain 10m 50s) Loss: 0.1020(0.1188) Grad: 8714.1367  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 56s (remain 10m 22s) Loss: 0.1098(0.1187) Grad: 67.2236  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 23s (remain 9m 54s) Loss: 0.1094(0.1186) Grad: 4428.2900  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 50s (remain 9m 27s) Loss: 0.1472(0.1185) Grad: 10452.0400  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.1086(0.1184) Grad: 750.5466  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 44s (remain 8m 31s) Loss: 0.1121(0.1184) Grad: 35.9729  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 11s (remain 8m 4s) Loss: 0.1052(0.1184) Grad: 2444.7834  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 38s (remain 7m 36s) Loss: 0.1127(0.1184) Grad: 182.0466  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 6s (remain 7m 9s) Loss: 0.1313(0.1185) Grad: 18.4279  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 33s (remain 6m 42s) Loss: 0.1248(0.1186) Grad: 7030.9614  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 0s (remain 6m 14s) Loss: 0.1214(0.1186) Grad: 279.0847  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 27s (remain 5m 47s) Loss: 0.1207(0.1187) Grad: 734.8058  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 54s (remain 5m 20s) Loss: 0.1183(0.1186) Grad: 1282.6615  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 21s (remain 4m 52s) Loss: 0.1242(0.1186) Grad: 3612.8416  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 48s (remain 4m 25s) Loss: 0.1472(0.1186) Grad: 274.7843  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 15s (remain 3m 58s) Loss: 0.1148(0.1186) Grad: 8962.7275  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 43s (remain 3m 30s) Loss: 0.1066(0.1187) Grad: 1517.2045  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 10s (remain 3m 3s) Loss: 0.1161(0.1187) Grad: 13029.0146  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 37s (remain 2m 36s) Loss: 0.1056(0.1187) Grad: 246.1894  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 4s (remain 2m 9s) Loss: 0.1100(0.1188) Grad: 9187.5811  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 31s (remain 1m 41s) Loss: 0.1030(0.1188) Grad: 616.1720  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 14m 58s (remain 1m 14s) Loss: 0.1087(0.1188) Grad: 15.2399  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 26s (remain 0m 47s) Loss: 0.1160(0.1188) Grad: 2009.1842  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 53s (remain 0m 20s) Loss: 0.1233(0.1188) Grad: 725.8520  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 13s (remain 0m 0s) Loss: 0.1262(0.1188) Grad: 9598.0215  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 26s) Loss: 0.1089(0.1089) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.1127(0.1180) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1052(0.1161) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0991(0.1208) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1693(0.1189) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1274(0.1163) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1782(0.1171) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1209(0.1183) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1299(0.1187) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1032(0.1190) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1183(0.1196) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1222(0.1191) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1092(0.1182) \n","Epoch 3 - avg_train_loss: 0.1188  avg_val_loss: 0.1182  time: 1157s\n","Epoch 3 - Score: 0.8817\n","Epoch 3 - Save Best Score: 0.8817 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 34m 37s) Loss: 0.1191(0.1191) Grad: 1005.8303  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 28s (remain 16m 33s) Loss: 0.1067(0.1184) Grad: 5.2812  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 56s (remain 15m 48s) Loss: 0.1237(0.1179) Grad: 883.6345  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 23s (remain 15m 9s) Loss: 0.1255(0.1187) Grad: 15531.4238  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 50s (remain 14m 36s) Loss: 0.1262(0.1189) Grad: 32.5258  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 17s (remain 14m 5s) Loss: 0.1305(0.1185) Grad: 6125.4834  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 44s (remain 13m 36s) Loss: 0.1039(0.1183) Grad: 3.4441  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 12s (remain 13m 7s) Loss: 0.1033(0.1184) Grad: 351.9872  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 39s (remain 12m 38s) Loss: 0.1159(0.1183) Grad: 19.8087  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 6s (remain 12m 10s) Loss: 0.1177(0.1182) Grad: 85.6504  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 33s (remain 11m 42s) Loss: 0.1167(0.1181) Grad: 34.4147  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 0s (remain 11m 15s) Loss: 0.1069(0.1182) Grad: 290.8936  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 27s (remain 10m 47s) Loss: 0.1252(0.1182) Grad: 14187.7148  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 54s (remain 10m 20s) Loss: 0.1260(0.1183) Grad: 36.5597  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 22s (remain 9m 52s) Loss: 0.1280(0.1183) Grad: 1637.4625  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 49s (remain 9m 25s) Loss: 0.0980(0.1183) Grad: 422.5891  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 16s (remain 8m 57s) Loss: 0.1245(0.1183) Grad: 3610.7727  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 43s (remain 8m 30s) Loss: 0.1526(0.1184) Grad: 7026.3901  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 10s (remain 8m 3s) Loss: 0.1240(0.1184) Grad: 37.5692  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 37s (remain 7m 35s) Loss: 0.1168(0.1184) Grad: 3.2707  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 4s (remain 7m 8s) Loss: 0.1310(0.1184) Grad: 12401.7666  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 32s (remain 6m 41s) Loss: 0.1515(0.1183) Grad: 7760.0063  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 9m 59s (remain 6m 14s) Loss: 0.1092(0.1183) Grad: 8004.4614  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 26s (remain 5m 46s) Loss: 0.1189(0.1183) Grad: 9909.3936  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 53s (remain 5m 19s) Loss: 0.1277(0.1183) Grad: 31.1318  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 20s (remain 4m 52s) Loss: 0.1036(0.1182) Grad: 114.9129  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 47s (remain 4m 25s) Loss: 0.1127(0.1182) Grad: 877.2416  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 14s (remain 3m 57s) Loss: 0.1188(0.1182) Grad: 12215.3506  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.1121(0.1183) Grad: 1275.9004  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 9s (remain 3m 3s) Loss: 0.1018(0.1183) Grad: 5.1906  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 36s (remain 2m 36s) Loss: 0.1152(0.1183) Grad: 70.7880  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.1182(0.1183) Grad: 6524.7661  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 30s (remain 1m 41s) Loss: 0.1247(0.1184) Grad: 3926.4077  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 14m 57s (remain 1m 14s) Loss: 0.1202(0.1184) Grad: 12995.7324  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 24s (remain 0m 47s) Loss: 0.1420(0.1184) Grad: 8394.8613  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 52s (remain 0m 20s) Loss: 0.1282(0.1184) Grad: 25721.6641  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 12s (remain 0m 0s) Loss: 0.1020(0.1184) Grad: 7083.9717  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 20s) Loss: 0.1089(0.1089) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.1127(0.1187) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1051(0.1166) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0987(0.1216) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1722(0.1198) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1278(0.1171) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1770(0.1179) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1272(0.1193) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1247(0.1197) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1035(0.1199) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1183(0.1205) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1218(0.1199) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1104(0.1189) \n","Epoch 4 - avg_train_loss: 0.1184  avg_val_loss: 0.1189  time: 1148s\n","Epoch 4 - Score: 0.8794\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 31m 59s) Loss: 0.1137(0.1137) Grad: 1001.2108  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 27s (remain 16m 0s) Loss: 0.1429(0.1181) Grad: 5.0001  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 55s (remain 15m 24s) Loss: 0.1255(0.1176) Grad: 1086.9937  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 22s (remain 14m 54s) Loss: 0.1294(0.1177) Grad: 12531.0137  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 49s (remain 14m 26s) Loss: 0.1066(0.1181) Grad: 355.5278  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 16s (remain 13m 58s) Loss: 0.1293(0.1182) Grad: 18159.3711  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 43s (remain 13m 31s) Loss: 0.1402(0.1183) Grad: 9845.6074  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 11s (remain 13m 3s) Loss: 0.1109(0.1183) Grad: 11.0857  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 38s (remain 12m 35s) Loss: 0.0943(0.1181) Grad: 21168.4883  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 5s (remain 12m 8s) Loss: 0.1330(0.1183) Grad: 60419.5508  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 32s (remain 11m 40s) Loss: 0.1526(0.1185) Grad: 23090.7207  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 59s (remain 11m 13s) Loss: 0.1099(0.1185) Grad: 155.0314  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 26s (remain 10m 46s) Loss: 0.1028(0.1186) Grad: 2932.1921  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 54s (remain 10m 18s) Loss: 0.1141(0.1185) Grad: 2.4770  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 21s (remain 9m 51s) Loss: 0.1147(0.1183) Grad: 1533.8455  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.1073(0.1184) Grad: 3879.7859  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 15s (remain 8m 57s) Loss: 0.1414(0.1184) Grad: 21.6291  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 43s (remain 8m 30s) Loss: 0.0921(0.1184) Grad: 27.8919  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 10s (remain 8m 2s) Loss: 0.0964(0.1183) Grad: 383.9690  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 37s (remain 7m 35s) Loss: 0.1190(0.1182) Grad: 9.0863  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 4s (remain 7m 8s) Loss: 0.1203(0.1183) Grad: 234.7282  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 31s (remain 6m 41s) Loss: 0.1125(0.1182) Grad: 5644.6143  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 9m 58s (remain 6m 13s) Loss: 0.0974(0.1182) Grad: 30.4670  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 26s (remain 5m 46s) Loss: 0.1739(0.1183) Grad: 14252.9717  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 53s (remain 5m 19s) Loss: 0.1224(0.1182) Grad: 2851.2102  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 20s (remain 4m 52s) Loss: 0.1277(0.1182) Grad: 5628.5435  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 47s (remain 4m 24s) Loss: 0.1280(0.1182) Grad: 5263.3633  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 14s (remain 3m 57s) Loss: 0.1180(0.1182) Grad: 22.3955  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.1053(0.1182) Grad: 25.2247  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 9s (remain 3m 3s) Loss: 0.1169(0.1181) Grad: 436.5015  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 36s (remain 2m 36s) Loss: 0.1160(0.1181) Grad: 13571.9668  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.1143(0.1181) Grad: 20.5949  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 30s (remain 1m 41s) Loss: 0.1263(0.1181) Grad: 135.2638  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 14m 57s (remain 1m 14s) Loss: 0.1324(0.1181) Grad: 118.1621  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 24s (remain 0m 47s) Loss: 0.1275(0.1181) Grad: 12921.6045  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 52s (remain 0m 20s) Loss: 0.1264(0.1181) Grad: 886.5272  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 12s (remain 0m 0s) Loss: 0.1093(0.1181) Grad: 37.1206  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 12s) Loss: 0.1089(0.1089) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.1127(0.1189) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 22s) Loss: 0.1051(0.1168) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.0987(0.1218) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1729(0.1200) \n","EVAL: [500/1192] Elapsed 1m 11s (remain 1m 39s) Loss: 0.1285(0.1173) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1770(0.1180) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1255(0.1194) \n","EVAL: [800/1192] Elapsed 1m 54s (remain 0m 56s) Loss: 0.1255(0.1199) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1032(0.1201) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1183(0.1207) \n","EVAL: [1100/1192] Elapsed 2m 37s (remain 0m 13s) Loss: 0.1229(0.1201) \n","EVAL: [1191/1192] Elapsed 2m 50s (remain 0m 0s) Loss: 0.1105(0.1191) \n","Epoch 5 - avg_train_loss: 0.1181  avg_val_loss: 0.1191  time: 1148s\n","Epoch 5 - Score: 0.8801\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 39m 59s) Loss: 0.3399(0.3399) Grad: 85425.0469  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 27s (remain 15m 58s) Loss: 0.2927(0.3304) Grad: 19912.2246  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 55s (remain 15m 24s) Loss: 0.1856(0.2852) Grad: 9836.2998  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 22s (remain 14m 54s) Loss: 0.1467(0.2442) Grad: 1010.4310  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 49s (remain 14m 26s) Loss: 0.1644(0.2181) Grad: 2944.1833  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 16s (remain 13m 58s) Loss: 0.1268(0.2022) Grad: 1991.1522  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 43s (remain 13m 30s) Loss: 0.1274(0.1914) Grad: 1392.5862  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 10s (remain 13m 2s) Loss: 0.1105(0.1828) Grad: 722.5010  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 38s (remain 12m 35s) Loss: 0.1361(0.1759) Grad: 3535.9377  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 5s (remain 12m 7s) Loss: 0.0844(0.1702) Grad: 1897.0745  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 32s (remain 11m 40s) Loss: 0.1201(0.1657) Grad: 3031.4670  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 59s (remain 11m 13s) Loss: 0.1092(0.1618) Grad: 1688.4293  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 26s (remain 10m 45s) Loss: 0.1236(0.1584) Grad: 1222.2493  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 54s (remain 10m 18s) Loss: 0.1164(0.1557) Grad: 1019.4095  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 21s (remain 9m 51s) Loss: 0.1311(0.1532) Grad: 4955.6177  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.1136(0.1512) Grad: 356.6041  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 15s (remain 8m 57s) Loss: 0.1005(0.1494) Grad: 1886.4924  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 42s (remain 8m 29s) Loss: 0.1166(0.1477) Grad: 5283.6646  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 10s (remain 8m 2s) Loss: 0.1529(0.1463) Grad: 5534.0728  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 37s (remain 7m 35s) Loss: 0.1166(0.1450) Grad: 3282.6514  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 4s (remain 7m 8s) Loss: 0.1090(0.1437) Grad: 1959.7964  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 31s (remain 6m 40s) Loss: 0.1414(0.1427) Grad: 3188.7324  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 9m 58s (remain 6m 13s) Loss: 0.1189(0.1417) Grad: 2693.5918  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 25s (remain 5m 46s) Loss: 0.1237(0.1408) Grad: 71.2122  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 53s (remain 5m 19s) Loss: 0.1084(0.1400) Grad: 706.7440  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 20s (remain 4m 52s) Loss: 0.1226(0.1392) Grad: 3655.9824  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 47s (remain 4m 24s) Loss: 0.1242(0.1384) Grad: 190.9049  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 14s (remain 3m 57s) Loss: 0.1357(0.1378) Grad: 10608.9287  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 41s (remain 3m 30s) Loss: 0.1234(0.1371) Grad: 237.2094  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 8s (remain 3m 3s) Loss: 0.1141(0.1365) Grad: 868.4258  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 36s (remain 2m 36s) Loss: 0.1229(0.1360) Grad: 1913.6123  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.1219(0.1356) Grad: 2874.1748  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 30s (remain 1m 41s) Loss: 0.1121(0.1351) Grad: 49.9270  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 14m 57s (remain 1m 14s) Loss: 0.1165(0.1347) Grad: 638.1802  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 24s (remain 0m 47s) Loss: 0.0896(0.1342) Grad: 5409.8794  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 51s (remain 0m 20s) Loss: 0.1282(0.1338) Grad: 765.6851  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 11s (remain 0m 0s) Loss: 0.1096(0.1335) Grad: 894.3774  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 21s) Loss: 0.1124(0.1124) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0913(0.1235) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1094(0.1221) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1223(0.1216) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1379(0.1222) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1272(0.1229) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1459(0.1222) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1245(0.1228) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0977(0.1218) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1323(0.1221) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1301(0.1227) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1391(0.1221) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1107(0.1210) \n","Epoch 1 - avg_train_loss: 0.1335  avg_val_loss: 0.1210  time: 1149s\n","Epoch 1 - Score: 0.8517\n","Epoch 1 - Save Best Score: 0.8517 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 37m 24s) Loss: 0.1235(0.1235) Grad: 1270.4910  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 29s (remain 16m 44s) Loss: 0.1172(0.1196) Grad: 4057.5737  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 57s (remain 15m 58s) Loss: 0.1202(0.1184) Grad: 2237.5691  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 24s (remain 15m 17s) Loss: 0.1140(0.1191) Grad: 6231.0649  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 51s (remain 14m 44s) Loss: 0.1058(0.1190) Grad: 2574.6948  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 18s (remain 14m 12s) Loss: 0.1212(0.1188) Grad: 1824.7817  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 46s (remain 13m 42s) Loss: 0.1106(0.1183) Grad: 23.7404  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 13s (remain 13m 12s) Loss: 0.1071(0.1183) Grad: 936.2186  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 40s (remain 12m 43s) Loss: 0.1418(0.1184) Grad: 39608.0156  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 7s (remain 12m 15s) Loss: 0.1184(0.1186) Grad: 452.8238  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 34s (remain 11m 47s) Loss: 0.1234(0.1186) Grad: 1654.7990  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 2s (remain 11m 19s) Loss: 0.1268(0.1186) Grad: 2116.0237  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 29s (remain 10m 51s) Loss: 0.1131(0.1186) Grad: 5617.9028  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 56s (remain 10m 23s) Loss: 0.1053(0.1186) Grad: 70.8277  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 23s (remain 9m 55s) Loss: 0.1357(0.1186) Grad: 13608.4912  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 50s (remain 9m 27s) Loss: 0.1097(0.1185) Grad: 2301.8157  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 18s (remain 9m 0s) Loss: 0.1282(0.1185) Grad: 2356.8669  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 45s (remain 8m 32s) Loss: 0.1166(0.1184) Grad: 3416.7168  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 12s (remain 8m 5s) Loss: 0.1071(0.1185) Grad: 85.3064  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.1179(0.1186) Grad: 420.5418  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 7s (remain 7m 10s) Loss: 0.1295(0.1187) Grad: 214.6502  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 34s (remain 6m 42s) Loss: 0.1180(0.1187) Grad: 8836.1035  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 1s (remain 6m 15s) Loss: 0.1073(0.1186) Grad: 1383.1528  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 28s (remain 5m 48s) Loss: 0.1270(0.1187) Grad: 2279.8438  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 55s (remain 5m 20s) Loss: 0.1199(0.1187) Grad: 13693.9932  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 23s (remain 4m 53s) Loss: 0.1392(0.1187) Grad: 38866.1641  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 50s (remain 4m 25s) Loss: 0.0963(0.1187) Grad: 1253.2180  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 17s (remain 3m 58s) Loss: 0.1352(0.1187) Grad: 26656.9609  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 44s (remain 3m 31s) Loss: 0.1210(0.1187) Grad: 1266.7306  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.1195(0.1187) Grad: 23284.2754  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 38s (remain 2m 36s) Loss: 0.1113(0.1188) Grad: 4169.5186  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 6s (remain 2m 9s) Loss: 0.1292(0.1188) Grad: 6176.3022  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 33s (remain 1m 42s) Loss: 0.1187(0.1187) Grad: 546.4164  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 0s (remain 1m 14s) Loss: 0.1128(0.1187) Grad: 1275.7263  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 27s (remain 0m 47s) Loss: 0.1251(0.1186) Grad: 10679.1338  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 55s (remain 0m 20s) Loss: 0.1028(0.1187) Grad: 5746.9492  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 15s (remain 0m 0s) Loss: 0.1142(0.1187) Grad: 116.2628  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 27s) Loss: 0.1124(0.1124) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0962(0.1235) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1095(0.1219) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1253(0.1214) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1361(0.1218) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1269(0.1224) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1442(0.1216) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1243(0.1221) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0976(0.1212) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1335(0.1214) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1273(0.1219) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1401(0.1214) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1106(0.1204) \n","Epoch 2 - avg_train_loss: 0.1187  avg_val_loss: 0.1204  time: 1162s\n","Epoch 2 - Score: 0.8794\n","Epoch 2 - Save Best Score: 0.8794 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 35m 16s) Loss: 0.0997(0.0997) Grad: 518.4640  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 29s (remain 16m 43s) Loss: 0.1297(0.1173) Grad: 5145.6133  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 57s (remain 15m 58s) Loss: 0.1300(0.1171) Grad: 21632.3945  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 24s (remain 15m 16s) Loss: 0.1311(0.1174) Grad: 4639.6270  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 51s (remain 14m 42s) Loss: 0.0956(0.1171) Grad: 320.5297  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 18s (remain 14m 10s) Loss: 0.1291(0.1173) Grad: 12420.1475  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 45s (remain 13m 40s) Loss: 0.1140(0.1174) Grad: 92.7709  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 12s (remain 13m 11s) Loss: 0.1245(0.1172) Grad: 8733.7354  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 40s (remain 12m 43s) Loss: 0.1257(0.1174) Grad: 32.1610  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 7s (remain 12m 14s) Loss: 0.1196(0.1174) Grad: 1028.4137  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 34s (remain 11m 46s) Loss: 0.1147(0.1175) Grad: 59.5439  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 1s (remain 11m 18s) Loss: 0.1086(0.1176) Grad: 768.7719  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 29s (remain 10m 50s) Loss: 0.1128(0.1176) Grad: 37.9903  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 56s (remain 10m 22s) Loss: 0.0933(0.1177) Grad: 1536.8694  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 23s (remain 9m 55s) Loss: 0.1221(0.1178) Grad: 3985.3777  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 50s (remain 9m 27s) Loss: 0.1115(0.1178) Grad: 2637.3594  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.1058(0.1178) Grad: 8106.8862  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 44s (remain 8m 32s) Loss: 0.1210(0.1178) Grad: 20805.1152  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 12s (remain 8m 4s) Loss: 0.1042(0.1177) Grad: 241.9296  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.1286(0.1177) Grad: 6227.6504  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 6s (remain 7m 9s) Loss: 0.1288(0.1178) Grad: 174.2335  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 33s (remain 6m 42s) Loss: 0.1361(0.1178) Grad: 7635.8594  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 0s (remain 6m 15s) Loss: 0.1336(0.1179) Grad: 26717.1992  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 27s (remain 5m 47s) Loss: 0.0938(0.1179) Grad: 3622.4556  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 55s (remain 5m 20s) Loss: 0.1119(0.1179) Grad: 542.4964  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 22s (remain 4m 52s) Loss: 0.1275(0.1179) Grad: 26469.4414  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 49s (remain 4m 25s) Loss: 0.1172(0.1179) Grad: 2082.8677  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 16s (remain 3m 58s) Loss: 0.1138(0.1179) Grad: 130.8997  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 43s (remain 3m 31s) Loss: 0.1026(0.1179) Grad: 11389.3760  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.1106(0.1179) Grad: 2481.3894  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 38s (remain 2m 36s) Loss: 0.0957(0.1179) Grad: 5.3346  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 5s (remain 2m 9s) Loss: 0.1232(0.1179) Grad: 3643.0598  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 32s (remain 1m 41s) Loss: 0.1333(0.1179) Grad: 15992.3418  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 14m 59s (remain 1m 14s) Loss: 0.1208(0.1179) Grad: 94.2125  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 26s (remain 0m 47s) Loss: 0.1251(0.1179) Grad: 326.7601  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 54s (remain 0m 20s) Loss: 0.1054(0.1180) Grad: 4012.4087  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 14s (remain 0m 0s) Loss: 0.1191(0.1180) Grad: 1673.0889  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 13s) Loss: 0.1124(0.1124) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.0979(0.1237) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1098(0.1222) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1163(0.1217) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1361(0.1222) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1279(0.1227) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1432(0.1218) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1244(0.1223) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0976(0.1214) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1352(0.1216) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1290(0.1222) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1461(0.1216) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1106(0.1206) \n","Epoch 3 - avg_train_loss: 0.1180  avg_val_loss: 0.1206  time: 1154s\n","Epoch 3 - Score: 0.8851\n","Epoch 3 - Save Best Score: 0.8851 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 34m 49s) Loss: 0.1274(0.1274) Grad: 15019.1230  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 29s (remain 16m 56s) Loss: 0.1143(0.1201) Grad: 1340.0759  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 57s (remain 16m 2s) Loss: 0.1312(0.1182) Grad: 6351.1104  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 24s (remain 15m 19s) Loss: 0.1150(0.1176) Grad: 335.8694  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 51s (remain 14m 44s) Loss: 0.1244(0.1171) Grad: 18093.6875  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 18s (remain 14m 12s) Loss: 0.1246(0.1175) Grad: 26583.6777  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 46s (remain 13m 41s) Loss: 0.1106(0.1174) Grad: 8707.2607  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 13s (remain 13m 12s) Loss: 0.1094(0.1176) Grad: 4734.6963  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 40s (remain 12m 43s) Loss: 0.1145(0.1178) Grad: 3409.6663  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 7s (remain 12m 14s) Loss: 0.1164(0.1179) Grad: 14.5348  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 34s (remain 11m 46s) Loss: 0.1125(0.1178) Grad: 108.7390  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 1s (remain 11m 18s) Loss: 0.1164(0.1178) Grad: 1621.6635  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 28s (remain 10m 50s) Loss: 0.1235(0.1179) Grad: 19778.2070  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 56s (remain 10m 22s) Loss: 0.1032(0.1178) Grad: 1161.7518  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 23s (remain 9m 55s) Loss: 0.0956(0.1177) Grad: 1000.9614  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 50s (remain 9m 27s) Loss: 0.1335(0.1176) Grad: 14067.4980  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.1157(0.1175) Grad: 771.3766  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 44s (remain 8m 32s) Loss: 0.1229(0.1176) Grad: 2.1985  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 12s (remain 8m 4s) Loss: 0.1135(0.1176) Grad: 19523.9824  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.1200(0.1176) Grad: 5017.3447  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 6s (remain 7m 9s) Loss: 0.1067(0.1176) Grad: 2789.9905  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 33s (remain 6m 42s) Loss: 0.1152(0.1177) Grad: 131.2405  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 10m 0s (remain 6m 15s) Loss: 0.1182(0.1177) Grad: 1926.1835  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 27s (remain 5m 47s) Loss: 0.1242(0.1177) Grad: 2540.9502  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 55s (remain 5m 20s) Loss: 0.1262(0.1177) Grad: 255.5990  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 22s (remain 4m 52s) Loss: 0.1124(0.1176) Grad: 125.5864  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 49s (remain 4m 25s) Loss: 0.1223(0.1176) Grad: 10.9022  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 17s (remain 3m 58s) Loss: 0.1167(0.1176) Grad: 124.9679  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 44s (remain 3m 31s) Loss: 0.1192(0.1175) Grad: 27463.6074  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.1083(0.1175) Grad: 4141.7725  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 39s (remain 2m 36s) Loss: 0.1171(0.1176) Grad: 4175.1221  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 6s (remain 2m 9s) Loss: 0.1325(0.1176) Grad: 6488.5942  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 33s (remain 1m 42s) Loss: 0.1225(0.1176) Grad: 164.6370  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 15m 0s (remain 1m 14s) Loss: 0.1242(0.1176) Grad: 31653.5996  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 27s (remain 0m 47s) Loss: 0.1100(0.1176) Grad: 8046.7266  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 55s (remain 0m 20s) Loss: 0.1139(0.1176) Grad: 21696.4961  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 15s (remain 0m 0s) Loss: 0.1231(0.1175) Grad: 68858.3047  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 57s) Loss: 0.1124(0.1124) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1009(0.1241) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1119(0.1228) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1213(0.1222) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1359(0.1226) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1269(0.1231) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1445(0.1222) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1241(0.1228) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0976(0.1219) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1322(0.1222) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1273(0.1227) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1516(0.1221) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1105(0.1211) \n","Epoch 4 - avg_train_loss: 0.1175  avg_val_loss: 0.1211  time: 1156s\n","Epoch 4 - Score: 0.8848\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 33m 42s) Loss: 0.1307(0.1307) Grad: 7161.1201  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 27s (remain 15m 55s) Loss: 0.1230(0.1183) Grad: 3090.8022  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 54s (remain 15m 22s) Loss: 0.1262(0.1179) Grad: 1854.1937  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 22s (remain 14m 55s) Loss: 0.1086(0.1177) Grad: 8213.3213  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 49s (remain 14m 26s) Loss: 0.1165(0.1168) Grad: 59.7101  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 16s (remain 13m 59s) Loss: 0.1111(0.1167) Grad: 1.0261  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 43s (remain 13m 31s) Loss: 0.1049(0.1169) Grad: 4470.5605  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 11s (remain 13m 3s) Loss: 0.1167(0.1169) Grad: 278.6475  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 38s (remain 12m 36s) Loss: 0.1159(0.1170) Grad: 2.3665  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 5s (remain 12m 8s) Loss: 0.1427(0.1169) Grad: 3078.6914  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 32s (remain 11m 41s) Loss: 0.1173(0.1170) Grad: 1.2951  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 59s (remain 11m 13s) Loss: 0.1332(0.1171) Grad: 34.6135  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 27s (remain 10m 46s) Loss: 0.1166(0.1170) Grad: 44.4830  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 54s (remain 10m 19s) Loss: 0.1160(0.1172) Grad: 16268.4805  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 21s (remain 9m 51s) Loss: 0.1328(0.1173) Grad: 6289.3521  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 48s (remain 9m 24s) Loss: 0.1139(0.1172) Grad: 3.6955  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 15s (remain 8m 57s) Loss: 0.1118(0.1172) Grad: 5.8725  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 43s (remain 8m 30s) Loss: 0.0936(0.1172) Grad: 32.6191  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 10s (remain 8m 3s) Loss: 0.1166(0.1173) Grad: 25867.9395  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 37s (remain 7m 35s) Loss: 0.0940(0.1172) Grad: 31.3878  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 4s (remain 7m 8s) Loss: 0.1375(0.1172) Grad: 754.8199  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 31s (remain 6m 41s) Loss: 0.1246(0.1173) Grad: 21877.0801  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 9m 59s (remain 6m 14s) Loss: 0.1228(0.1173) Grad: 599.9441  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 26s (remain 5m 46s) Loss: 0.1194(0.1173) Grad: 34.3723  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 53s (remain 5m 19s) Loss: 0.1241(0.1173) Grad: 4.0389  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 20s (remain 4m 52s) Loss: 0.1254(0.1173) Grad: 131.4668  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 47s (remain 4m 25s) Loss: 0.1178(0.1173) Grad: 4.3177  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 15s (remain 3m 57s) Loss: 0.1050(0.1173) Grad: 1040.0321  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.1235(0.1172) Grad: 8079.2588  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 9s (remain 3m 3s) Loss: 0.1173(0.1172) Grad: 11.9078  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 36s (remain 2m 36s) Loss: 0.1143(0.1172) Grad: 4.4440  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 3s (remain 2m 8s) Loss: 0.1245(0.1172) Grad: 16831.8047  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 31s (remain 1m 41s) Loss: 0.0973(0.1171) Grad: 11.8803  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 14m 58s (remain 1m 14s) Loss: 0.0989(0.1171) Grad: 4303.8560  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 25s (remain 0m 47s) Loss: 0.1480(0.1172) Grad: 5700.3784  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 52s (remain 0m 20s) Loss: 0.1085(0.1172) Grad: 3.3778  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 12s (remain 0m 0s) Loss: 0.1100(0.1172) Grad: 5.9625  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 35s) Loss: 0.1124(0.1124) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1015(0.1246) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1100(0.1230) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1142(0.1225) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1359(0.1229) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1269(0.1234) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 24s) Loss: 0.1449(0.1225) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1242(0.1231) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.0976(0.1222) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1334(0.1225) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1273(0.1230) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1506(0.1225) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1105(0.1214) \n","Epoch 5 - avg_train_loss: 0.1172  avg_val_loss: 0.1214  time: 1153s\n","Epoch 5 - Score: 0.8855\n","Epoch 5 - Save Best Score: 0.8855 Model\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 47m 34s) Loss: 0.3799(0.3799) Grad: 108387.6484  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 29s (remain 16m 43s) Loss: 0.3628(0.3748) Grad: 49241.1484  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 56s (remain 15m 45s) Loss: 0.2408(0.3365) Grad: 17207.1875  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 23s (remain 15m 8s) Loss: 0.1493(0.2842) Grad: 908.4725  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 50s (remain 14m 36s) Loss: 0.1308(0.2489) Grad: 1520.2976  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 2m 17s (remain 14m 6s) Loss: 0.1596(0.2273) Grad: 2517.0779  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 45s (remain 13m 37s) Loss: 0.1220(0.2127) Grad: 1044.3407  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 3m 12s (remain 13m 8s) Loss: 0.1169(0.2013) Grad: 444.5212  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 39s (remain 12m 40s) Loss: 0.1135(0.1924) Grad: 9221.6787  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 4m 6s (remain 12m 12s) Loss: 0.1085(0.1850) Grad: 1052.7595  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 4m 33s (remain 11m 44s) Loss: 0.1214(0.1789) Grad: 1497.8997  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 5m 1s (remain 11m 16s) Loss: 0.1451(0.1743) Grad: 2433.4692  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 5m 28s (remain 10m 49s) Loss: 0.1260(0.1702) Grad: 3427.5823  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 5m 55s (remain 10m 21s) Loss: 0.1135(0.1665) Grad: 1382.3004  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 6m 22s (remain 9m 54s) Loss: 0.1169(0.1633) Grad: 857.5674  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 6m 50s (remain 9m 26s) Loss: 0.1450(0.1606) Grad: 15662.1836  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.1542(0.1583) Grad: 7676.0034  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 7m 44s (remain 8m 31s) Loss: 0.1349(0.1561) Grad: 13504.6191  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 8m 11s (remain 8m 4s) Loss: 0.1264(0.1542) Grad: 4355.9614  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.0977(0.1524) Grad: 1773.8260  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 9m 6s (remain 7m 9s) Loss: 0.1241(0.1507) Grad: 1646.0879  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 9m 33s (remain 6m 42s) Loss: 0.1125(0.1494) Grad: 28.3177  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 10m 0s (remain 6m 15s) Loss: 0.1068(0.1482) Grad: 436.6882  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 10m 27s (remain 5m 47s) Loss: 0.1244(0.1469) Grad: 4344.7988  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 10m 55s (remain 5m 20s) Loss: 0.1163(0.1457) Grad: 628.8427  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 11m 22s (remain 4m 53s) Loss: 0.1204(0.1447) Grad: 1006.3168  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 11m 49s (remain 4m 25s) Loss: 0.1136(0.1437) Grad: 1340.2778  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 12m 17s (remain 3m 58s) Loss: 0.1450(0.1428) Grad: 10764.2197  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 12m 44s (remain 3m 31s) Loss: 0.1208(0.1420) Grad: 2053.2976  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.1305(0.1414) Grad: 1787.5176  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 13m 39s (remain 2m 36s) Loss: 0.1427(0.1408) Grad: 3948.7375  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 14m 6s (remain 2m 9s) Loss: 0.1245(0.1401) Grad: 2832.1846  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 14m 33s (remain 1m 42s) Loss: 0.1232(0.1395) Grad: 44.1348  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 15m 0s (remain 1m 14s) Loss: 0.1223(0.1389) Grad: 3744.4780  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 15m 28s (remain 0m 47s) Loss: 0.1176(0.1384) Grad: 1031.3462  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 15m 55s (remain 0m 20s) Loss: 0.1144(0.1379) Grad: 1833.4430  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 16m 15s (remain 0m 0s) Loss: 0.1263(0.1376) Grad: 2397.1267  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 34s) Loss: 0.1311(0.1311) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1237(0.1210) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1343(0.1231) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1157(0.1244) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.1263(0.1251) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1360(0.1232) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1174(0.1222) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1354(0.1210) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1260(0.1205) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1364(0.1211) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1500(0.1216) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1380(0.1215) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1010(0.1200) \n","Epoch 1 - avg_train_loss: 0.1376  avg_val_loss: 0.1200  time: 1152s\n","Epoch 1 - Score: 0.8576\n","Epoch 1 - Save Best Score: 0.8576 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 38m 30s) Loss: 0.1222(0.1222) Grad: 14544.6064  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 30s (remain 17m 14s) Loss: 0.1245(0.1215) Grad: 30563.2520  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 57s (remain 16m 10s) Loss: 0.1141(0.1206) Grad: 1819.0841  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 25s (remain 15m 24s) Loss: 0.1220(0.1202) Grad: 5989.8325  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 52s (remain 14m 50s) Loss: 0.1200(0.1201) Grad: 8007.3198  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 2m 19s (remain 14m 17s) Loss: 0.1230(0.1202) Grad: 4847.8584  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 46s (remain 13m 46s) Loss: 0.1177(0.1200) Grad: 5838.4160  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 3m 14s (remain 13m 16s) Loss: 0.1272(0.1200) Grad: 4740.9185  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 41s (remain 12m 47s) Loss: 0.1257(0.1198) Grad: 7468.8125  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 4m 8s (remain 12m 18s) Loss: 0.1000(0.1197) Grad: 147.3825  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 4m 36s (remain 11m 49s) Loss: 0.1147(0.1195) Grad: 1748.3755  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 5m 3s (remain 11m 21s) Loss: 0.0979(0.1197) Grad: 134.0411  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 5m 30s (remain 10m 53s) Loss: 0.1140(0.1197) Grad: 7584.9009  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 57s (remain 10m 25s) Loss: 0.1247(0.1197) Grad: 7792.6841  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 6m 25s (remain 9m 57s) Loss: 0.1147(0.1195) Grad: 773.2920  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 6m 52s (remain 9m 29s) Loss: 0.1127(0.1195) Grad: 188.5820  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 7m 19s (remain 9m 1s) Loss: 0.1197(0.1196) Grad: 13519.2705  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 7m 46s (remain 8m 34s) Loss: 0.1266(0.1196) Grad: 2374.4128  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 8m 14s (remain 8m 6s) Loss: 0.1249(0.1198) Grad: 17.8934  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 8m 41s (remain 7m 39s) Loss: 0.1179(0.1197) Grad: 27.0239  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 9m 8s (remain 7m 11s) Loss: 0.1205(0.1198) Grad: 6192.8042  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 9m 36s (remain 6m 44s) Loss: 0.1143(0.1198) Grad: 38.2577  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 10m 3s (remain 6m 16s) Loss: 0.1196(0.1197) Grad: 2363.5854  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 10m 30s (remain 5m 49s) Loss: 0.1730(0.1198) Grad: 8040.8906  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 10m 57s (remain 5m 21s) Loss: 0.1268(0.1197) Grad: 30.8823  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 11m 24s (remain 4m 54s) Loss: 0.1278(0.1197) Grad: 39153.6055  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 11m 52s (remain 4m 26s) Loss: 0.1045(0.1196) Grad: 2275.7861  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 12m 19s (remain 3m 59s) Loss: 0.1205(0.1197) Grad: 4158.5669  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 12m 46s (remain 3m 31s) Loss: 0.1240(0.1196) Grad: 19586.2617  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 13m 13s (remain 3m 4s) Loss: 0.1361(0.1196) Grad: 20688.0898  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 13m 41s (remain 2m 37s) Loss: 0.1234(0.1196) Grad: 4971.9204  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 14m 8s (remain 2m 9s) Loss: 0.1050(0.1196) Grad: 4172.2969  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 14m 35s (remain 1m 42s) Loss: 0.1513(0.1196) Grad: 7686.8896  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 15m 3s (remain 1m 14s) Loss: 0.1108(0.1195) Grad: 10229.0791  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 15m 30s (remain 0m 47s) Loss: 0.1134(0.1195) Grad: 41733.8633  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 15m 57s (remain 0m 20s) Loss: 0.1236(0.1195) Grad: 4853.6821  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 16m 17s (remain 0m 0s) Loss: 0.1203(0.1194) Grad: 543.8035  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 9m 14s) Loss: 0.1304(0.1304) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1228(0.1202) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1330(0.1222) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1146(0.1235) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.1259(0.1243) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1326(0.1224) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1164(0.1214) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1354(0.1203) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1229(0.1198) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1362(0.1202) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.1494(0.1208) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1388(0.1206) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1003(0.1192) \n","Epoch 2 - avg_train_loss: 0.1194  avg_val_loss: 0.1192  time: 1155s\n","Epoch 2 - Score: 0.8834\n","Epoch 2 - Save Best Score: 0.8834 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 33m 42s) Loss: 0.1140(0.1140) Grad: 996.5680  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 28s (remain 16m 34s) Loss: 0.1210(0.1178) Grad: 424.3033  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 56s (remain 15m 52s) Loss: 0.1133(0.1178) Grad: 1961.4969  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 23s (remain 15m 13s) Loss: 0.1276(0.1175) Grad: 26883.8301  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 51s (remain 14m 39s) Loss: 0.1175(0.1178) Grad: 72674.1641  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 18s (remain 14m 8s) Loss: 0.1193(0.1180) Grad: 12690.6367  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 45s (remain 13m 39s) Loss: 0.1217(0.1181) Grad: 21.0854  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 3m 12s (remain 13m 9s) Loss: 0.1245(0.1181) Grad: 132.1283  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 39s (remain 12m 41s) Loss: 0.1216(0.1178) Grad: 3971.3718  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 4m 7s (remain 12m 13s) Loss: 0.1167(0.1181) Grad: 2477.1062  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 34s (remain 11m 45s) Loss: 0.1089(0.1181) Grad: 4937.8267  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 5m 1s (remain 11m 18s) Loss: 0.1240(0.1180) Grad: 19307.3418  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 5m 28s (remain 10m 50s) Loss: 0.0866(0.1181) Grad: 3439.7688  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 56s (remain 10m 22s) Loss: 0.1249(0.1182) Grad: 4204.3022  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 6m 23s (remain 9m 54s) Loss: 0.1063(0.1181) Grad: 11.5754  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 50s (remain 9m 27s) Loss: 0.1153(0.1180) Grad: 1175.4884  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.1371(0.1181) Grad: 52500.8945  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 7m 44s (remain 8m 32s) Loss: 0.1121(0.1180) Grad: 13852.4395  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 8m 12s (remain 8m 4s) Loss: 0.1182(0.1182) Grad: 13655.9824  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.1254(0.1183) Grad: 21336.0488  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 9m 6s (remain 7m 9s) Loss: 0.1222(0.1182) Grad: 2011.9884  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 9m 33s (remain 6m 42s) Loss: 0.1202(0.1181) Grad: 10.1704  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 10m 0s (remain 6m 15s) Loss: 0.1028(0.1181) Grad: 8497.5742  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 10m 28s (remain 5m 47s) Loss: 0.0992(0.1182) Grad: 20229.7402  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 10m 55s (remain 5m 20s) Loss: 0.1233(0.1182) Grad: 7394.0059  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 11m 22s (remain 4m 53s) Loss: 0.1065(0.1182) Grad: 1729.0365  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 11m 49s (remain 4m 25s) Loss: 0.1293(0.1182) Grad: 13087.4990  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 12m 16s (remain 3m 58s) Loss: 0.1157(0.1183) Grad: 65.7928  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 12m 43s (remain 3m 31s) Loss: 0.1257(0.1182) Grad: 47.8494  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.0988(0.1182) Grad: 1019.3952  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 13m 38s (remain 2m 36s) Loss: 0.1230(0.1182) Grad: 45.1263  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 14m 5s (remain 2m 9s) Loss: 0.1120(0.1183) Grad: 1537.5835  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 14m 32s (remain 1m 41s) Loss: 0.1005(0.1182) Grad: 4290.8999  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 15m 0s (remain 1m 14s) Loss: 0.1208(0.1182) Grad: 7654.5796  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 15m 27s (remain 0m 47s) Loss: 0.1091(0.1183) Grad: 7.4225  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 15m 54s (remain 0m 20s) Loss: 0.1213(0.1183) Grad: 28349.8379  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 16m 14s (remain 0m 0s) Loss: 0.1278(0.1183) Grad: 15930.1406  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 29s) Loss: 0.1302(0.1302) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1294(0.1210) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1342(0.1230) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1158(0.1244) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 53s) Loss: 0.1259(0.1250) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1385(0.1230) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1174(0.1220) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1346(0.1208) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1236(0.1203) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1363(0.1209) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1494(0.1214) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1383(0.1213) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1003(0.1198) \n","Epoch 3 - avg_train_loss: 0.1183  avg_val_loss: 0.1198  time: 1151s\n","Epoch 3 - Score: 0.8814\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 32m 57s) Loss: 0.1122(0.1122) Grad: 998.0564  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 27s (remain 15m 55s) Loss: 0.1131(0.1164) Grad: 16602.6035  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 54s (remain 15m 23s) Loss: 0.1295(0.1171) Grad: 20.2044  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 22s (remain 14m 54s) Loss: 0.1129(0.1175) Grad: 326.1930  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 49s (remain 14m 26s) Loss: 0.1433(0.1177) Grad: 36.8230  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 16s (remain 13m 58s) Loss: 0.1351(0.1181) Grad: 17.8117  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 44s (remain 13m 31s) Loss: 0.1554(0.1183) Grad: 4709.9263  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 3m 11s (remain 13m 4s) Loss: 0.1286(0.1182) Grad: 6897.4248  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 38s (remain 12m 36s) Loss: 0.1139(0.1182) Grad: 12723.2471  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 4m 5s (remain 12m 9s) Loss: 0.1295(0.1182) Grad: 164.5672  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 32s (remain 11m 41s) Loss: 0.1224(0.1182) Grad: 2761.4194  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 5m 0s (remain 11m 14s) Loss: 0.1256(0.1183) Grad: 379.5621  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 5m 27s (remain 10m 46s) Loss: 0.1138(0.1183) Grad: 6366.8115  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 54s (remain 10m 19s) Loss: 0.1111(0.1182) Grad: 9588.4365  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 6m 21s (remain 9m 52s) Loss: 0.1397(0.1180) Grad: 9925.6221  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 49s (remain 9m 25s) Loss: 0.1238(0.1180) Grad: 4041.7561  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 7m 16s (remain 8m 58s) Loss: 0.1317(0.1179) Grad: 85.8322  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 7m 43s (remain 8m 30s) Loss: 0.1206(0.1180) Grad: 43.8395  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 8m 10s (remain 8m 3s) Loss: 0.1168(0.1179) Grad: 403.1435  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 8m 37s (remain 7m 36s) Loss: 0.1162(0.1180) Grad: 342.1825  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 9m 5s (remain 7m 8s) Loss: 0.1282(0.1180) Grad: 10.0906  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 9m 32s (remain 6m 41s) Loss: 0.1049(0.1180) Grad: 79.3491  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 9m 59s (remain 6m 14s) Loss: 0.1385(0.1180) Grad: 74.1179  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 10m 26s (remain 5m 47s) Loss: 0.0989(0.1180) Grad: 22.1159  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 10m 54s (remain 5m 19s) Loss: 0.1194(0.1179) Grad: 1765.3955  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 11m 21s (remain 4m 52s) Loss: 0.1279(0.1179) Grad: 9.6654  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 11m 48s (remain 4m 25s) Loss: 0.1124(0.1178) Grad: 4654.6333  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 12m 15s (remain 3m 58s) Loss: 0.1103(0.1179) Grad: 921.6465  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 12m 42s (remain 3m 30s) Loss: 0.1168(0.1179) Grad: 18.5616  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 13m 10s (remain 3m 3s) Loss: 0.1229(0.1179) Grad: 8.6337  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 13m 37s (remain 2m 36s) Loss: 0.1288(0.1179) Grad: 1435.7919  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 14m 4s (remain 2m 9s) Loss: 0.1143(0.1179) Grad: 5403.6499  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 14m 31s (remain 1m 41s) Loss: 0.1153(0.1178) Grad: 364.3385  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 14m 59s (remain 1m 14s) Loss: 0.1137(0.1179) Grad: 101.9380  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 15m 26s (remain 0m 47s) Loss: 0.1214(0.1179) Grad: 36.9147  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 15m 53s (remain 0m 20s) Loss: 0.1308(0.1179) Grad: 15968.7031  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 16m 13s (remain 0m 0s) Loss: 0.1010(0.1179) Grad: 3653.8762  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 51s) Loss: 0.1301(0.1301) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 39s) Loss: 0.1295(0.1212) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1359(0.1230) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1161(0.1242) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.1259(0.1250) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1414(0.1231) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1171(0.1220) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1345(0.1208) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1232(0.1203) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1369(0.1208) \n","EVAL: [1000/1192] Elapsed 2m 23s (remain 0m 27s) Loss: 0.1494(0.1213) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1360(0.1211) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1003(0.1197) \n","Epoch 4 - avg_train_loss: 0.1179  avg_val_loss: 0.1197  time: 1150s\n","Epoch 4 - Score: 0.8876\n","Epoch 4 - Save Best Score: 0.8876 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 37m 51s) Loss: 0.1189(0.1189) Grad: 1011.2878  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 29s (remain 16m 48s) Loss: 0.1174(0.1174) Grad: 9510.5010  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 57s (remain 15m 58s) Loss: 0.1286(0.1175) Grad: 267.6565  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 24s (remain 15m 16s) Loss: 0.1117(0.1180) Grad: 9.7199  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 51s (remain 14m 44s) Loss: 0.1269(0.1179) Grad: 25.4252  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 18s (remain 14m 12s) Loss: 0.1221(0.1179) Grad: 9.0163  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 46s (remain 13m 42s) Loss: 0.1212(0.1180) Grad: 60911.9414  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 3m 13s (remain 13m 12s) Loss: 0.1167(0.1180) Grad: 12323.7070  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 40s (remain 12m 43s) Loss: 0.1406(0.1181) Grad: 8.3181  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 4m 7s (remain 12m 15s) Loss: 0.1269(0.1180) Grad: 11.9999  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 34s (remain 11m 46s) Loss: 0.0913(0.1181) Grad: 3029.3438  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 5m 2s (remain 11m 18s) Loss: 0.1020(0.1181) Grad: 5867.8965  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 5m 29s (remain 10m 50s) Loss: 0.1314(0.1180) Grad: 14536.6387  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 56s (remain 10m 22s) Loss: 0.1165(0.1180) Grad: 4116.5493  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 6m 23s (remain 9m 55s) Loss: 0.1062(0.1179) Grad: 2234.4565  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 50s (remain 9m 27s) Loss: 0.1100(0.1178) Grad: 72.1016  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 7m 17s (remain 8m 59s) Loss: 0.1126(0.1179) Grad: 7408.1172  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 7m 45s (remain 8m 32s) Loss: 0.1335(0.1178) Grad: 431.0500  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 8m 12s (remain 8m 5s) Loss: 0.1190(0.1177) Grad: 9663.3643  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 8m 39s (remain 7m 37s) Loss: 0.1039(0.1177) Grad: 156.9980  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 9m 6s (remain 7m 10s) Loss: 0.1200(0.1177) Grad: 23.3036  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 9m 34s (remain 6m 42s) Loss: 0.1145(0.1177) Grad: 15.5984  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 10m 1s (remain 6m 15s) Loss: 0.1141(0.1178) Grad: 91.3079  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 10m 28s (remain 5m 47s) Loss: 0.1284(0.1177) Grad: 3040.0793  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 10m 55s (remain 5m 20s) Loss: 0.1168(0.1177) Grad: 157.7301  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 11m 22s (remain 4m 53s) Loss: 0.1182(0.1177) Grad: 5531.6382  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 11m 49s (remain 4m 25s) Loss: 0.1208(0.1177) Grad: 97.7246  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 12m 17s (remain 3m 58s) Loss: 0.1009(0.1176) Grad: 11.9180  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 12m 44s (remain 3m 31s) Loss: 0.1230(0.1176) Grad: 1936.0830  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 13m 11s (remain 3m 3s) Loss: 0.1127(0.1176) Grad: 579.6935  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 13m 38s (remain 2m 36s) Loss: 0.1057(0.1175) Grad: 1.8917  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 14m 5s (remain 2m 9s) Loss: 0.1074(0.1176) Grad: 2009.9136  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 14m 33s (remain 1m 42s) Loss: 0.1015(0.1176) Grad: 7.1890  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 15m 0s (remain 1m 14s) Loss: 0.1000(0.1176) Grad: 14547.9883  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 15m 27s (remain 0m 47s) Loss: 0.1242(0.1175) Grad: 19.8823  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 15m 54s (remain 0m 20s) Loss: 0.1318(0.1176) Grad: 37.3627  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 16m 14s (remain 0m 0s) Loss: 0.0948(0.1175) Grad: 10841.4736  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 24s) Loss: 0.1300(0.1300) \n","EVAL: [100/1192] Elapsed 0m 14s (remain 2m 38s) Loss: 0.1334(0.1215) \n","EVAL: [200/1192] Elapsed 0m 29s (remain 2m 23s) Loss: 0.1341(0.1232) \n","EVAL: [300/1192] Elapsed 0m 43s (remain 2m 8s) Loss: 0.1173(0.1245) \n","EVAL: [400/1192] Elapsed 0m 57s (remain 1m 54s) Loss: 0.1259(0.1253) \n","EVAL: [500/1192] Elapsed 1m 12s (remain 1m 39s) Loss: 0.1438(0.1233) \n","EVAL: [600/1192] Elapsed 1m 26s (remain 1m 25s) Loss: 0.1170(0.1223) \n","EVAL: [700/1192] Elapsed 1m 40s (remain 1m 10s) Loss: 0.1347(0.1211) \n","EVAL: [800/1192] Elapsed 1m 55s (remain 0m 56s) Loss: 0.1249(0.1207) \n","EVAL: [900/1192] Elapsed 2m 9s (remain 0m 41s) Loss: 0.1377(0.1212) \n","EVAL: [1000/1192] Elapsed 2m 24s (remain 0m 27s) Loss: 0.1494(0.1217) \n","EVAL: [1100/1192] Elapsed 2m 38s (remain 0m 13s) Loss: 0.1355(0.1215) \n","EVAL: [1191/1192] Elapsed 2m 51s (remain 0m 0s) Loss: 0.1003(0.1200) \n","Epoch 5 - avg_train_loss: 0.1175  avg_val_loss: 0.1200  time: 1151s\n","Epoch 5 - Score: 0.8890\n","Epoch 5 - Save Best Score: 0.8890 Model\n","Best thres: 0.5, Score: 0.8842\n","Best thres: 0.4624999999999999, Score: 0.8844\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83bcf8b640694ea98c0bcee9ba680288"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32596053994d44e3b4a5b56588d897dc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"566b48c1e53d43b3a80f300aa1794515"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp061.ipynb","provenance":[{"file_id":"10yG4L3_nzpdL2CDwqxa9r-KWq6jYkWfl","timestamp":1647960989099}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e49e7d913b014b799bb6c430ea437050":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_846aed472ec1445c9821d997a160761b","IPY_MODEL_fe8a514f09f849d9a1202b114b81ca67","IPY_MODEL_afa41d99c01742fbb5a36f78d483688a"],"layout":"IPY_MODEL_83339685e60f4e269a7ce90195b0b835"}},"846aed472ec1445c9821d997a160761b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709941fbb4854281b034afe2a110eedf","placeholder":"​","style":"IPY_MODEL_f2c5fd44170943ed9728b67b4b141b58","value":"100%"}},"fe8a514f09f849d9a1202b114b81ca67":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42f270b69e8f4f7d9335b4d6812a231e","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa686274513846b0b5327f74cce07feb","value":42146}},"afa41d99c01742fbb5a36f78d483688a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f17f251ed64466795062c4c7aecd197","placeholder":"​","style":"IPY_MODEL_91bf0d41ddd749c4897cb9dae7142f9e","value":" 42146/42146 [00:36&lt;00:00, 1661.63it/s]"}},"83339685e60f4e269a7ce90195b0b835":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709941fbb4854281b034afe2a110eedf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c5fd44170943ed9728b67b4b141b58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42f270b69e8f4f7d9335b4d6812a231e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa686274513846b0b5327f74cce07feb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f17f251ed64466795062c4c7aecd197":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91bf0d41ddd749c4897cb9dae7142f9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e366494600f4459926de98f519c3c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6c5f982485147bdbb7a34bb579a556e","IPY_MODEL_adf4fd58487d46feb0075cbea4126202","IPY_MODEL_863ceb6b39164f3489f65608cffdc2c9"],"layout":"IPY_MODEL_dba83b2fb2344eeba1869222129ec79d"}},"d6c5f982485147bdbb7a34bb579a556e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4866556d6b78497eb91bd528dd47ac08","placeholder":"​","style":"IPY_MODEL_0ddc3908eaae406dae32f3e27b2d16cb","value":"100%"}},"adf4fd58487d46feb0075cbea4126202":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eae395eeef8640c68388946f1e6542ed","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5efcdb440400444a9da477697ba71e89","value":143}},"863ceb6b39164f3489f65608cffdc2c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96a28a87bf5d43339130946a25bfd0a8","placeholder":"​","style":"IPY_MODEL_75881f5d7f3f4022a805ce931dbb4535","value":" 143/143 [00:00&lt;00:00, 1985.67it/s]"}},"dba83b2fb2344eeba1869222129ec79d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4866556d6b78497eb91bd528dd47ac08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ddc3908eaae406dae32f3e27b2d16cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eae395eeef8640c68388946f1e6542ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5efcdb440400444a9da477697ba71e89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96a28a87bf5d43339130946a25bfd0a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75881f5d7f3f4022a805ce931dbb4535":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83bcf8b640694ea98c0bcee9ba680288":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d9b9dcf828c48a891a0bb1a6f652b85","IPY_MODEL_e83126322c654456a94546c66bcf2c3e","IPY_MODEL_50dfd5f5e1924076a8de2c3d658fee58"],"layout":"IPY_MODEL_bf0b99955aff4e4fa68aad7c70a8bc81"}},"8d9b9dcf828c48a891a0bb1a6f652b85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6432c1ee66384b8696107f34252cbe4f","placeholder":"​","style":"IPY_MODEL_73e22e85ec224fdc9b5d1944a72ad7ed","value":"Downloading: 100%"}},"e83126322c654456a94546c66bcf2c3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a237130fbe84224898ffb125cb33cd5","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_320ccd4613af4a76bc78a188b9c53ede","value":1627284589}},"50dfd5f5e1924076a8de2c3d658fee58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7ca9bb9646945cb9d89c26d68411f3b","placeholder":"​","style":"IPY_MODEL_dc1d1243e80c45ada8e44f1b121a8a97","value":" 1.52G/1.52G [00:31&lt;00:00, 54.0MB/s]"}},"bf0b99955aff4e4fa68aad7c70a8bc81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6432c1ee66384b8696107f34252cbe4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73e22e85ec224fdc9b5d1944a72ad7ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a237130fbe84224898ffb125cb33cd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"320ccd4613af4a76bc78a188b9c53ede":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7ca9bb9646945cb9d89c26d68411f3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc1d1243e80c45ada8e44f1b121a8a97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32596053994d44e3b4a5b56588d897dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a157fcb7ccbc47b5b44676f35eb51669","IPY_MODEL_1f5ff5dd342147c082768bea17a10526","IPY_MODEL_77b212337d5941bc818d630abd5327cf"],"layout":"IPY_MODEL_9e33ec7100024de8b87f74b338d7d094"}},"a157fcb7ccbc47b5b44676f35eb51669":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e7929d944b04bf398541bf24a731551","placeholder":"​","style":"IPY_MODEL_5d4d987dd6584503ae42baacc89bd753","value":"100%"}},"1f5ff5dd342147c082768bea17a10526":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_573e0247d8fc47af822c4a34f5abbf93","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_318de2fac1e64a48aacd8f2d6179c0ce","value":2}},"77b212337d5941bc818d630abd5327cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca217057537a45cfa33e80c77489cf34","placeholder":"​","style":"IPY_MODEL_ed186079846345abbed836f8751756f6","value":" 2/2 [00:01&lt;00:00,  1.64it/s]"}},"9e33ec7100024de8b87f74b338d7d094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e7929d944b04bf398541bf24a731551":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d4d987dd6584503ae42baacc89bd753":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"573e0247d8fc47af822c4a34f5abbf93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"318de2fac1e64a48aacd8f2d6179c0ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca217057537a45cfa33e80c77489cf34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed186079846345abbed836f8751756f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"566b48c1e53d43b3a80f300aa1794515":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2478baed65e426ca05e48663044a717","IPY_MODEL_8015c034288d4794a440dbd98d46a211","IPY_MODEL_89fb272a365e4e7287b60446d9984588"],"layout":"IPY_MODEL_952a68a0529b46e6af881624f7cf3b79"}},"d2478baed65e426ca05e48663044a717":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_884de52bbf8e42a59b702d98276e9a42","placeholder":"​","style":"IPY_MODEL_667ee42d99d148ab8c1046634cf69b76","value":"100%"}},"8015c034288d4794a440dbd98d46a211":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_682ab3900b2b43a6a56291216d6c6ef4","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aeb2010d7a354f5699c7e22c83711c2a","value":2}},"89fb272a365e4e7287b60446d9984588":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_128e0e6efbbc4f1f9586aa8e12770456","placeholder":"​","style":"IPY_MODEL_bd1e55a98c574326bbe26129be00c973","value":" 2/2 [00:02&lt;00:00,  1.46it/s]"}},"952a68a0529b46e6af881624f7cf3b79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"884de52bbf8e42a59b702d98276e9a42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667ee42d99d148ab8c1046634cf69b76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"682ab3900b2b43a6a56291216d6c6ef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aeb2010d7a354f5699c7e22c83711c2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"128e0e6efbbc4f1f9586aa8e12770456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd1e55a98c574326bbe26129be00c973":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}