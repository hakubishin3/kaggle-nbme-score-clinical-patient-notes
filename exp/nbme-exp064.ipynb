{"cells":[{"cell_type":"markdown","id":"colored-security","metadata":{"id":"colored-security"},"source":["## References"]},{"cell_type":"markdown","id":"educational-operator","metadata":{"id":"educational-operator"},"source":["- https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train"]},{"cell_type":"markdown","id":"incorrect-greek","metadata":{"id":"incorrect-greek"},"source":["## Configurations"]},{"cell_type":"code","execution_count":1,"id":"alive-granny","metadata":{"id":"alive-granny","executionInfo":{"status":"ok","timestamp":1648219759993,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["EXP_NAME = \"nbme-exp064\"\n","ENV = \"colab\"\n","DEBUG_MODE = False\n","SUBMISSION_MODE = False"]},{"cell_type":"code","execution_count":2,"id":"heavy-prophet","metadata":{"id":"heavy-prophet","executionInfo":{"status":"ok","timestamp":1648219759994,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CFG:\n","    env=ENV\n","    exp_name=EXP_NAME\n","    debug=DEBUG_MODE\n","    submission=SUBMISSION_MODE\n","    apex=True\n","    input_dir=None\n","    output_dir=None\n","    library=\"pytorch\"  # [\"tf\", \"pytorch\"]\n","    device=\"GPU\"  # [\"GPU\", \"TPU\"]\n","    competition_name=\"nbme-score-clinical-patient-notes\"\n","    id_col=\"id\"\n","    target_col=\"location\"\n","    pretrained_model_name=\"microsoft/deberta-large\"\n","    tokenizer=None\n","    max_len=None\n","    output_dim=1\n","    dropout=0.2\n","    num_workers=4\n","    batch_size=3\n","    lr=2e-5\n","    betas=(0.9, 0.98)\n","    weight_decay=0.1\n","    num_warmup_steps_rate=0.1\n","    batch_scheduler=True\n","    epochs=5\n","    n_fold=4\n","    train_fold=[0, 1, 2, 3]\n","    seed=71\n","    gradient_accumulation_steps=2\n","    max_grad_norm=1000\n","    print_freq=100\n","    train=True\n","    inference=True"]},{"cell_type":"code","execution_count":3,"id":"vocational-coating","metadata":{"id":"vocational-coating","executionInfo":{"status":"ok","timestamp":1648219759995,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.train_fold = [0, 1]\n","\n","if CFG.submission:\n","    CFG.train = False\n","    CFG.inference = True"]},{"cell_type":"markdown","id":"private-moderator","metadata":{"id":"private-moderator"},"source":["## Directory Settings"]},{"cell_type":"code","execution_count":4,"id":"married-tokyo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"married-tokyo","outputId":"89bf4e01-0a7d-45c0-e414-9f69264524f8","executionInfo":{"status":"ok","timestamp":1648219796306,"user_tz":-540,"elapsed":36317,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","Mounted at /content/drive\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 14.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 71.0 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.63.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","\n","print(CFG.env)\n","if CFG.env == \"colab\":\n","    # colab環境\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    CFG.input_dir = Path(\"./drive/MyDrive/00.kaggle/input\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","    # install packages\n","    !pip install transformers==4.16.2\n","\n","elif CFG.env == \"local\":\n","    # ローカルサーバ\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"../output/\") / CFG.competition_name / CFG.exp_name\n","    if not CFG.output_dir.exists():\n","        CFG.output_dir.mkdir()\n","\n","elif CFG.env == \"kaggle\":\n","    # kaggle環境\n","    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n","    CFG.output_dir = Path(\"./\")"]},{"cell_type":"code","execution_count":5,"id":"blank-pierre","metadata":{"id":"blank-pierre","executionInfo":{"status":"ok","timestamp":1648219807915,"user_tz":-540,"elapsed":11623,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["import gc\n","import os\n","import ast\n","import time\n","import math\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from scipy.optimize import minimize\n","from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoModelForMaskedLM\n","from transformers import BartModel,BertModel,BertTokenizer\n","from transformers import DebertaModel,DebertaTokenizer\n","from transformers import RobertaModel,RobertaTokenizer\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"sound-still","metadata":{"id":"sound-still"},"source":["## Utilities"]},{"cell_type":"code","execution_count":6,"id":"surprised-commercial","metadata":{"id":"surprised-commercial","executionInfo":{"status":"ok","timestamp":1648219807915,"user_tz":-540,"elapsed":8,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score"]},{"cell_type":"code","execution_count":7,"id":"interstate-accident","metadata":{"id":"interstate-accident","executionInfo":{"status":"ok","timestamp":1648219807916,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def create_labels_for_scoring(df):\n","    # example: ['48 61', '111 128'] -> [[48, 61], [111, 128]]\n","    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, \"location\"]\n","        if lst:\n","            new_lst = \";\".join(lst)\n","            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(f\"[['{new_lst}']]\")\n","\n","    # create labels\n","    truths = []\n","    for location_list in df[\"location_for_create_labels\"].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","\n","    return truths\n","\n","\n","def get_char_probs(texts, token_probs, tokenizer):\n","    res = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, token_probs)):\n","        encoded = tokenizer(\n","            text=text,\n","            max_length=CFG.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        for (offset_mapping, pred) in zip(encoded[\"offset_mapping\"], prediction):\n","            start, end = offset_mapping\n","            res[i][start:end] = pred\n","    return res\n","\n","\n","def get_predicted_location_str(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(\";\")]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","def scoring(df, th=0.5):\n","    labels = create_labels_for_scoring(df)\n","\n","    token_probs = df[[str(i) for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(df[\"pn_history\"].values, token_probs, CFG.tokenizer)\n","    predicted_location_str = get_predicted_location_str(char_probs, th=th)\n","    preds = get_predictions(predicted_location_str)\n","\n","    score = get_score(labels, preds)\n","    return score\n","\n","\n","def get_best_thres(oof_df):\n","    def f1_opt(x):\n","        return -1 * scoring(oof_df, th=x)\n","\n","    best_thres = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")[\"x\"].item()\n","    return best_thres"]},{"cell_type":"code","execution_count":8,"id":"coated-pioneer","metadata":{"id":"coated-pioneer","executionInfo":{"status":"ok","timestamp":1648219807916,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"id":"nervous-delaware","metadata":{"id":"nervous-delaware","executionInfo":{"status":"ok","timestamp":1648219807916,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"functioning-destruction","metadata":{"id":"functioning-destruction"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":10,"id":"global-monte","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"global-monte","outputId":"bcaf0752-127f-4b79-8c52-4f3b8ed78108","executionInfo":{"status":"ok","timestamp":1648219810902,"user_tz":-540,"elapsed":2991,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 6), (143, 3), (42146, 3), (5, 4))"]},"metadata":{},"execution_count":10}],"source":["train = pd.read_csv(CFG.input_dir / \"train.csv\")\n","features = pd.read_csv(CFG.input_dir / \"features.csv\")\n","patient_notes = pd.read_csv(CFG.input_dir / \"patient_notes.csv\")\n","test = pd.read_csv(CFG.input_dir / \"test.csv\")\n","\n","train.shape, features.shape, patient_notes.shape, test.shape"]},{"cell_type":"code","execution_count":11,"id":"independent-airfare","metadata":{"id":"independent-airfare","executionInfo":{"status":"ok","timestamp":1648219810903,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["if CFG.debug:\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    print(train.shape)"]},{"cell_type":"markdown","id":"silent-locator","metadata":{"id":"silent-locator"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":12,"id":"unusual-fifty","metadata":{"id":"unusual-fifty","executionInfo":{"status":"ok","timestamp":1648219810904,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def preprocess_features(features):\n","    features.loc[features[\"feature_text\"] == \"Last-Pap-smear-I-year-ago\", \"feature_text\"] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","\n","\n","features = preprocess_features(features)"]},{"cell_type":"code","source":["# lower case\n","features['feature_text'] = features['feature_text'].str.lower()\n","patient_notes['pn_history'] = patient_notes['pn_history'].str.lower()"],"metadata":{"id":"bAWBG0LKjTES","executionInfo":{"status":"ok","timestamp":1648219810904,"user_tz":-540,"elapsed":5,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"id":"bAWBG0LKjTES","execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"id":"decreased-mustang","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"decreased-mustang","outputId":"bab27b8b-7716-49fc-c953-deeaeec25746","executionInfo":{"status":"ok","timestamp":1648219811230,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((14300, 8), (5, 6))"]},"metadata":{},"execution_count":14}],"source":["train = train.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","train = train.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","test = test.merge(features, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","test = test.merge(patient_notes, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","train.shape, test.shape"]},{"cell_type":"code","execution_count":15,"id":"boolean-trade","metadata":{"id":"boolean-trade","executionInfo":{"status":"ok","timestamp":1648219811231,"user_tz":-540,"elapsed":10,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["train[\"annotation\"] = train[\"annotation\"].apply(ast.literal_eval)\n","train[\"location\"] = train[\"location\"].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":16,"id":"accomplished-dakota","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"accomplished-dakota","outputId":"a4bbed2a-4a8f-4c61-8761-be227243a7bc","executionInfo":{"status":"ok","timestamp":1648219811232,"user_tz":-540,"elapsed":11,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["0    4399\n","1    8181\n","2    1296\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{}}],"source":["train[\"annotation_length\"] = train[\"annotation\"].apply(len)\n","display(train['annotation_length'].value_counts().sort_index())"]},{"cell_type":"markdown","id":"funded-elizabeth","metadata":{"id":"funded-elizabeth"},"source":["## CV split"]},{"cell_type":"code","execution_count":17,"id":"unexpected-columbia","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"unexpected-columbia","outputId":"2dd7dd11-ba2d-4a4e-c769-44fa752f026f","executionInfo":{"status":"ok","timestamp":1648219811232,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3575\n","1    3575\n","2    3575\n","3    3575\n","dtype: int64"]},"metadata":{}}],"source":["Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"markdown","id":"critical-archive","metadata":{"id":"critical-archive"},"source":["## Setup tokenizer"]},{"cell_type":"code","execution_count":18,"id":"broken-generator","metadata":{"id":"broken-generator","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["40cb84a2ca2b48d5aebdb7c41e1edd89","93f6157a0c91436da57c03d3b31d7aa8","8179affb703b4c7dacee125d49de8e5f","24fb8ac2ffb3451e952cf4cb993c0600","11bc67030cce443c978a49e383146429","169d0af852bc46c4861b6f8a9310d28e","aad56fa4957248749ebecd00b903897f","8c76da5d96b447a592af3faa6f434338","1b5c5dded4874cb8813455f21e26e8d5","6ffe5f21175143f2be172191b03506e2","a787a271e3e14460873279d63475859c","ee2191179211460aa37b3a2c6d444e06","9ce07b570870428fa44bab0f9481d6af","cc3cfc9ae49a4bffb37a978118670e2c","4c68825decbd40ddb868a0f01a475d93","b0ee0830acb34818aad3e72c2071b72d","07a40a8350aa439585de58c837d32e91","946e89ded7b5490ebaac9c50577aa160","b83b30864ec049b0b5ad97d22f892332","d7b385705f874b72a3a58b088db069cb","859e8f1081614738aba96d83c515ccaa","1d87c4caf48a47c1a188294ecfc0d369","8691445cfb69497fbded79b24038d8d7","7228dfdc6a5b4fae979bd1248fa7f1f7","35a8d56b7d13448b95d90779b0a78f43","2c9cb10b8f9c4b59977db872049c1de8","9209904a12d642aa9ac52978113b8a53","977fd3adddd8440ca13922ddd99af66e","2e279a4386d046959c0fa7e26e922156","4f76b83795ea4a53baeab2d4dd0edc70","7a469f12c8a84f9599efbfd093fb0c66","50ad0a68447f4442b5cfb5e4ad2c7421","c7602959451d4830bdec8dd74c20b400","eddbb2a112fd4dce9beaaaece69662bb","c9d201912afb47c3b46f95a4ebbb2db7","608f63399d9d48f38658c7b48c8ab328","c915e397df4f49e7915e706bc227a509","50785d1b0efe4c36aaabedd4f3007a84","83e87f339587425db392a33f1ffaa1ff","ddc85ddd8e2647a1b48188060e6eafcf","e5c87d30bc1d4f4e9690cb456854fff0","fd0145d8162c4be0ac46acc9812145db","a7e5739c6788484d8cc66c325bf55f9c","b06a1518c3b84d8ebabe199b9d2a3958"]},"executionInfo":{"status":"ok","timestamp":1648219818790,"user_tz":-540,"elapsed":7565,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}},"outputId":"7a544203-4fa6-4b0d-a317-35a37e298d48"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40cb84a2ca2b48d5aebdb7c41e1edd89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee2191179211460aa37b3a2c6d444e06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8691445cfb69497fbded79b24038d8d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eddbb2a112fd4dce9beaaaece69662bb"}},"metadata":{}}],"source":["if CFG.submission:\n","    tokenizer = AutoTokenizer.from_pretrained(Path(\"../input/\") / CFG.exp_name / \"tokenizer/\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name)\n","    tokenizer.save_pretrained(CFG.output_dir / \"tokenizer/\")\n","\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","id":"compatible-lincoln","metadata":{"id":"compatible-lincoln"},"source":["## Create dataset"]},{"cell_type":"code","execution_count":19,"id":"fluid-nancy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["601689e1bf994cb28b6553e506b34f24","2a570bee8547428495612fb40d284109","1e6ed4bbee86471bb4eb88f3ec70bb61","ba822cb8afe54c769d529df793d8008e","01cac304ac114a919664a0dc3c8aa741","93555babf9584151b414e28ddb826010","c0c10324f8e349738da3a63d3733c473","9c3e9367d32044c4a314d7519897e48a","28116cf0d689496bb5abbadd7ecea374","07a754bbca864150a774868daf69651d","01f6f55acf3f41e0a67c640cdf5941b9"]},"id":"fluid-nancy","outputId":"aca8e00e-3b13-41a5-8a3f-9d36ee7701e5","executionInfo":{"status":"ok","timestamp":1648219849904,"user_tz":-540,"elapsed":31118,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/42146 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"601689e1bf994cb28b6553e506b34f24"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 325\n"]}],"source":["pn_history_lengths = []\n","tk0 = tqdm(patient_notes[\"pn_history\"].fillna(\"\").values, total=len(patient_notes))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    pn_history_lengths.append(length)\n","\n","print(\"max length:\", np.max(pn_history_lengths))"]},{"cell_type":"code","execution_count":20,"id":"posted-humidity","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["0e5099dedd284c8d98364fd8ba866a8e","c7db5dae1ec34e019b12924ef497c7ed","0216c31ea16544988227795263609fe4","4b011dd5d9fc47aea568aface56f7616","116ff02d546c457da0a752b09709a75b","eca2a14f315449d5a1325e8a6edfd8c5","fddf55357a134a5e85b4552d195e1c39","87cc3cbb14b34ac494af1a63849fcfcf","9e0e3bde94504329b89bd27eb8fa63ff","68dc286931194cc19952ec0af83f9740","687940667e3647ccad874a452b2c7c02"]},"id":"posted-humidity","outputId":"8679e079-deb1-4bc7-f27d-b7069296b40e","executionInfo":{"status":"ok","timestamp":1648219849905,"user_tz":-540,"elapsed":13,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5099dedd284c8d98364fd8ba866a8e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["max length: 30\n"]}],"source":["feature_text_lengths = []\n","tk0 = tqdm(features[\"feature_text\"].fillna(\"\").values, total=len(features))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n","    feature_text_lengths.append(length)\n","\n","print(\"max length:\", np.max(feature_text_lengths))"]},{"cell_type":"code","execution_count":21,"id":"resistant-amount","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"resistant-amount","outputId":"f2a3a48a-54a6-4e37-8b85-d89c686013a1","executionInfo":{"status":"ok","timestamp":1648219849905,"user_tz":-540,"elapsed":9,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["max length: 358\n"]}],"source":["CFG.max_len = max(pn_history_lengths) + max(feature_text_lengths) + 3   # cls & sep & sep\n","\n","print(\"max length:\", CFG.max_len)"]},{"cell_type":"code","execution_count":22,"id":"august-equity","metadata":{"id":"august-equity","executionInfo":{"status":"ok","timestamp":1648219849906,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TrainingDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","        self.annotation_lengths = self.df[\"annotation_length\"].values\n","        self.locations = self.df[\"location\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def _create_label(self, pn_history, annotation_length, location_list):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=True,\n","        )\n","        offset_mapping = encoded[\"offset_mapping\"]\n","        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","        label = np.zeros(len(offset_mapping))\n","        label[ignore_idxes] = -1\n","\n","        if annotation_length > 0:\n","            for location in location_list:\n","                for loc in [s.split() for s in location.split(\";\")]:\n","                    start, end = int(loc[0]), int(loc[1])\n","                    start_idx = -1\n","                    end_idx = -1\n","                    for idx in range(len(offset_mapping)):\n","                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                            start_idx = idx - 1\n","                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                            end_idx = idx + 1\n","                    if start_idx == -1:\n","                        start_idx = end_idx\n","                    if (start_idx != -1) & (end_idx != -1):\n","                        label[start_idx:end_idx] = 1\n","\n","        return torch.tensor(label, dtype=torch.float)\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        label = self._create_label(self.pn_historys[idx], self.annotation_lengths[idx], self.locations[idx])\n","        return input_, label"]},{"cell_type":"code","execution_count":23,"id":"weird-interaction","metadata":{"id":"weird-interaction","executionInfo":{"status":"ok","timestamp":1648219849906,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.df = df\n","        self.tokenizer = self.cfg.tokenizer\n","        self.max_len = self.cfg.max_len\n","        self.feature_texts = self.df[\"feature_text\"].values\n","        self.pn_historys = self.df[\"pn_history\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _create_input(self, pn_history, feature_text):\n","        encoded = self.tokenizer(\n","            text=pn_history,\n","            text_pair=feature_text,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False,\n","        )\n","        for k, v in encoded.items():\n","            encoded[k] = torch.tensor(v, dtype=torch.long)\n","        return encoded\n","\n","    def __getitem__(self, idx):\n","        input_ = self._create_input(self.pn_historys[idx], self.feature_texts[idx])\n","        return input_"]},{"cell_type":"markdown","id":"upper-mobility","metadata":{"id":"upper-mobility"},"source":["## Model"]},{"cell_type":"code","execution_count":24,"id":"spanish-destruction","metadata":{"id":"spanish-destruction","executionInfo":{"status":"ok","timestamp":1648219849906,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, cfg, model_config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        if model_config_path is None:\n","            self.model_config = AutoConfig.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                output_hidden_states=True,\n","            )\n","        else:\n","            self.model_config = torch.load(model_config_path)\n","\n","        if pretrained:\n","            self.backbone = AutoModel.from_pretrained(\n","                self.cfg.pretrained_model_name,\n","                config=self.model_config,\n","            )\n","            print(f\"Load weight from pretrained\")\n","        else:\n","            #self.backbone = AutoModel.from_config(self.model_config)\n","            itpt = AutoModelForMaskedLM.from_config(self.model_config)\n","            path = str(Path(\"./drive/MyDrive/00.kaggle/output\") / CFG.competition_name /  \"nbme-exp010/checkpoint-130170/pytorch_model.bin\")\n","            # path = \"../output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\"\n","            state_dict = torch.load(path)\n","            itpt.load_state_dict(state_dict)\n","            self.backbone = itpt.deberta\n","            print(f\"Load weight from {path}\")\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(self.cfg.dropout),\n","            nn.Linear(self.model_config.hidden_size, self.cfg.output_dim),\n","        )\n","\n","    def forward(self, inputs):\n","        h = self.backbone(**inputs)[\"last_hidden_state\"]\n","        output = self.fc(h)\n","        return output"]},{"cell_type":"markdown","id":"chronic-bullet","metadata":{"id":"chronic-bullet"},"source":["## Training"]},{"cell_type":"code","execution_count":25,"id":"biological-hunger","metadata":{"id":"biological-hunger","executionInfo":{"status":"ok","timestamp":1648219850487,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_fn(\n","    train_dataloader,\n","    model,\n","    criterion,\n","    optimizer,\n","    epoch,\n","    scheduler,\n","    device,\n","):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(train_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","\n","        if CFG.batch_scheduler:\n","            scheduler.step()\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"Grad: {grad_norm:.4f}  \"\n","                \"LR: {lr:.6f}  \"\n","                .format(\n","                    epoch+1,\n","                    step,\n","                    len(train_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(train_dataloader)),\n","                    loss=losses,\n","                     grad_norm=grad_norm,\n","                     lr=scheduler.get_lr()[0],\n","                )\n","            )\n","    return losses.avg"]},{"cell_type":"code","execution_count":26,"id":"satisfied-sterling","metadata":{"id":"satisfied-sterling","executionInfo":{"status":"ok","timestamp":1648219850488,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def valid_fn(\n","    val_dataloader,\n","    model,\n","    criterion,\n","    device,\n","):\n","    model.eval()\n","    preds = []\n","    losses = AverageMeter()\n","    start = time.time()\n","    for step, (inputs, labels) in enumerate(val_dataloader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        loss = criterion(output.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1)\n","        loss = loss.mean()\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(val_dataloader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                .format(\n","                    step, len(val_dataloader),\n","                    remain=timeSince(start, float(step+1) / len(val_dataloader)),\n","                    loss=losses,\n","                )\n","            )\n","    preds = np.concatenate(preds)\n","    return losses.avg, preds"]},{"cell_type":"code","execution_count":27,"id":"incorporate-viking","metadata":{"id":"incorporate-viking","executionInfo":{"status":"ok","timestamp":1648219850488,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def inference_fn(test_dataloader, model, device):\n","    model.eval()\n","    model.to(device)\n","    preds = []\n","    tk0 = tqdm(test_dataloader, total=len(test_dataloader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            output = model(inputs)\n","        preds.append(output.sigmoid().squeeze(2).detach().cpu().numpy())\n","    preds = np.concatenate(preds)\n","    return preds"]},{"cell_type":"code","execution_count":28,"id":"dental-sunset","metadata":{"id":"dental-sunset","executionInfo":{"status":"ok","timestamp":1648219850488,"user_tz":-540,"elapsed":6,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def train_loop(df, i_fold, device):\n","    print(f\"========== fold: {i_fold} training ==========\")\n","    train_idx = df[df[\"fold\"] != i_fold].index\n","    val_idx = df[df[\"fold\"] == i_fold].index\n","\n","    train_folds = df.loc[train_idx].reset_index(drop=True)\n","    val_folds = df.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainingDataset(CFG, train_folds)\n","    val_dataset = TrainingDataset(CFG, val_folds)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    val_dataloader = DataLoader(\n","        val_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","    model = CustomModel(CFG, model_config_path=None, pretrained=False)   # itptを使うため\n","    torch.save(model.model_config, CFG.output_dir / \"model_config.pth\")\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n","        {\"params\": [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n","    ]\n","    optimizer = AdamW(\n","        optimizer_grouped_parameters,\n","        lr=CFG.lr,\n","        betas=CFG.betas,\n","        weight_decay=CFG.weight_decay,\n","    )\n","    num_train_optimization_steps = int(len(train_dataloader) * CFG.epochs)\n","    num_warmup_steps = int(num_train_optimization_steps * CFG.num_warmup_steps_rate)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_warmup_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )\n","\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    best_score = -1 * np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","        avg_loss = train_fn(\n","            train_dataloader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","        avg_val_loss, val_preds = valid_fn(\n","            val_dataloader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","\n","        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_folds[[str(i) for i in range(CFG.max_len)]] = val_preds\n","        score = scoring(val_folds, th=0.5)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n","        print(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","        if score > best_score:\n","            best_score = score\n","            print(f\"Epoch {epoch+1} - Save Best Score: {score:.4f} Model\")\n","            torch.save({\n","                \"model\": model.state_dict(),\n","                \"predictions\": val_preds,\n","                },\n","                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","    val_folds[[str(i) for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return val_folds"]},{"cell_type":"markdown","id":"brazilian-graphics","metadata":{"id":"brazilian-graphics"},"source":["## Main"]},{"cell_type":"code","execution_count":29,"id":"connected-protein","metadata":{"id":"connected-protein","executionInfo":{"status":"ok","timestamp":1648219850489,"user_tz":-540,"elapsed":7,"user":{"displayName":"Shuhei Goda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08246931244224045522"}}},"outputs":[],"source":["def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for i_fold in range(CFG.n_fold):\n","            if i_fold in CFG.train_fold:\n","                _oof_df = train_loop(train, i_fold, device)\n","                oof_df = pd.concat([oof_df, _oof_df], axis=0, ignore_index=True)\n","        oof_df.to_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    if CFG.submission:\n","        oof_df = pd.read_pickle(Path(\"../input/\") / CFG.exp_name / \"oof_df.pkl\")\n","    else:\n","        oof_df = pd.read_pickle(CFG.output_dir / \"oof_df.pkl\")\n","\n","    score = scoring(oof_df, th=0.5)\n","    print(f\"Best thres: 0.5, Score: {score:.4f}\")\n","    best_thres = get_best_thres(oof_df)\n","    score = scoring(oof_df, th=best_thres)\n","    print(f\"Best thres: {best_thres}, Score: {score:.4f}\")\n","\n","    if CFG.inference:\n","        test_dataset = TestDataset(CFG, test)\n","        test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=False,\n","            num_workers=CFG.num_workers,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","        predictions = []\n","        for i_fold in CFG.train_fold:\n","            if CFG.submission:\n","                model = CustomModel(CFG, model_config_path=Path(\"../input/\") / CFG.exp_name / \"model_config.pth\", pretrained=False)\n","                path = Path(\"../input/\") / CFG.exp_name / f\"fold{i_fold}_best.pth\"\n","            else:\n","                model = CustomModel(CFG, model_config_path=None, pretrained=True)\n","                path = CFG.output_dir / f\"fold{i_fold}_best.pth\"\n","\n","            state = torch.load(path, map_location=torch.device(\"cpu\"))\n","            model.load_state_dict(state[\"model\"])\n","            test_token_probs = inference_fn(test_dataloader, model, device)\n","            test[[f\"fold{i_fold}_{i}\" for i in range(CFG.max_len)]] = test_token_probs\n","            test_char_probs = get_char_probs(test[\"pn_history\"].values, test_token_probs, CFG.tokenizer)\n","            predictions.append(test_char_probs)\n","\n","            del state, test_token_probs, model; gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        predictions = np.mean(predictions, axis=0)\n","        predicted_location_str = get_predicted_location_str(predictions, th=best_thres)\n","        test[CFG.target_col] = predicted_location_str\n","        test.to_csv(CFG.output_dir / \"raw_submission.csv\", index=False)\n","        test[[CFG.id_col, CFG.target_col]].to_csv(\n","            CFG.output_dir / \"submission.csv\", index=False\n","        )"]},{"cell_type":"code","execution_count":null,"id":"serious-bunny","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["46b0526921b843c5acd2ba088cf70d87","8f8d7ff16d774a31bcc474c1425fb37c","c0f37b8f907044ca862ad3584f889794","49e3a6ffe9d44c7f874c31dd6501b461","c61a5f5b7eda449084559df1818c8d15","7e827271638d48b9b0a97eda417f2a48","201733eb304646dba3733643fd242a03","784637e53a7a45eeb78948cb48ec26b0","f50a6775ffbe4986a57ae5e3b36beeeb","90efbc8b9a674ef6b37143907f5bf7ad","0ebab1b8a673424fa0aa783d45402a76","2205c256d19949309829b84941f91ba2","eff4f0909b1149f49f005f355605f172","5df3550872244457ae62a966b47f6f90","d213c6af9f4444808545126792be22bc","e1077cad5b9044c581a6a5d7417674a9","85ea4673500e4d85a357dcbea663185b","8666371077af4ee388b449e79a985310","d9989d6a84f24722a58844ea99d709d3","12ba6187a7424dce919376dbf8bad0b4","09969eb0cd134a2d81130df796b2498b","7b3cbe74d332405f89b02d5f363e92d8","b135c75a4b14404a95c71736efb071f5","512d97a1382244799b938e8280ca620d","0c5aca74fb534b75925dade7aae8d10a","3530324e6f4046d6bdffba337a7f069c","2750a8af76434058af836ac55aa8bb04","bd91079c15804ebdad3ca05b927b3614","1504c0b337c84d48a33bb97547daf248","df89172492874d61b1c04ba703a9b278","8c81fc4c9932434e9deb110f15cc008d","6b2ae0e9b2be4d188e460ea6100784b8","f00c1d57caad4da497dc1670efdea825"]},"id":"serious-bunny","outputId":"475505eb-84c5-49cb-efef-e404766e21f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== fold: 0 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 57m 13s) Loss: 0.3027(0.3027) Grad: 198029.6719  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 23s (remain 13m 27s) Loss: 0.2650(0.2861) Grad: 171483.6875  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 47s (remain 13m 15s) Loss: 0.1082(0.2425) Grad: 20524.4785  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 9s (remain 12m 39s) Loss: 0.0433(0.1810) Grad: 3325.2412  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 32s (remain 12m 9s) Loss: 0.0280(0.1453) Grad: 2987.5640  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 1m 54s (remain 11m 45s) Loss: 0.0376(0.1234) Grad: 3401.3213  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 17s (remain 11m 19s) Loss: 0.0059(0.1073) Grad: 2002.7188  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 2m 39s (remain 10m 55s) Loss: 0.0026(0.0947) Grad: 1259.0057  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 2s (remain 10m 31s) Loss: 0.0354(0.0848) Grad: 16178.8633  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 3m 24s (remain 10m 7s) Loss: 0.0122(0.0771) Grad: 8572.9180  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 3m 47s (remain 9m 44s) Loss: 0.0150(0.0706) Grad: 7156.3872  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 9s (remain 9m 20s) Loss: 0.0008(0.0653) Grad: 631.2597  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 4m 32s (remain 8m 57s) Loss: 0.0011(0.0607) Grad: 1676.4395  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 4m 54s (remain 8m 34s) Loss: 0.0082(0.0570) Grad: 4701.0591  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 5m 17s (remain 8m 12s) Loss: 0.0215(0.0537) Grad: 9820.0322  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 5m 39s (remain 7m 49s) Loss: 0.0065(0.0508) Grad: 12018.1475  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 6m 2s (remain 7m 26s) Loss: 0.0049(0.0482) Grad: 6334.4712  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 6m 24s (remain 7m 3s) Loss: 0.0026(0.0459) Grad: 1408.3198  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 6m 47s (remain 6m 40s) Loss: 0.0156(0.0439) Grad: 4076.2822  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 7m 9s (remain 6m 18s) Loss: 0.0050(0.0421) Grad: 1318.0729  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 7m 32s (remain 5m 55s) Loss: 0.0042(0.0403) Grad: 3017.5144  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 7m 54s (remain 5m 32s) Loss: 0.0019(0.0387) Grad: 1083.9587  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 8m 17s (remain 5m 10s) Loss: 0.0008(0.0373) Grad: 287.5874  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 8m 39s (remain 4m 47s) Loss: 0.0073(0.0360) Grad: 2127.0454  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 9m 2s (remain 4m 25s) Loss: 0.0005(0.0349) Grad: 352.1120  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 9m 24s (remain 4m 2s) Loss: 0.0002(0.0339) Grad: 64.3604  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 9m 46s (remain 3m 39s) Loss: 0.0004(0.0328) Grad: 153.5990  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 10m 9s (remain 3m 17s) Loss: 0.0419(0.0319) Grad: 3451.3889  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 10m 31s (remain 2m 54s) Loss: 0.0019(0.0310) Grad: 600.6406  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 10m 54s (remain 2m 32s) Loss: 0.0063(0.0302) Grad: 2310.2212  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 11m 16s (remain 2m 9s) Loss: 0.0009(0.0294) Grad: 204.1223  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 11m 39s (remain 1m 46s) Loss: 0.0003(0.0287) Grad: 108.7132  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 12m 1s (remain 1m 24s) Loss: 0.0405(0.0281) Grad: 4184.7656  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 12m 24s (remain 1m 1s) Loss: 0.0041(0.0274) Grad: 931.5646  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 12m 46s (remain 0m 39s) Loss: 0.0032(0.0269) Grad: 679.4755  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 13m 9s (remain 0m 16s) Loss: 0.0007(0.0263) Grad: 281.7607  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 13m 25s (remain 0m 0s) Loss: 0.0347(0.0258) Grad: 3183.0862  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 21s) Loss: 0.0007(0.0007) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0113(0.0043) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0227(0.0057) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0041(0.0064) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0027(0.0065) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0100(0.0060) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0125(0.0061) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0820(0.0073) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0021(0.0074) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0194(0.0075) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0012(0.0074) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0017(0.0070) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0002(0.0068) \n","Epoch 1 - avg_train_loss: 0.0258  avg_val_loss: 0.0068  time: 935s\n","Epoch 1 - Score: 0.8492\n","Epoch 1 - Save Best Score: 0.8492 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 34m 14s) Loss: 0.0020(0.0020) Grad: 7041.6099  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 26s (remain 15m 21s) Loss: 0.0106(0.0049) Grad: 13575.6182  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 51s (remain 14m 16s) Loss: 0.0004(0.0047) Grad: 8386.0127  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 13s (remain 13m 18s) Loss: 0.0048(0.0051) Grad: 8076.6328  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 35s (remain 12m 38s) Loss: 0.0265(0.0049) Grad: 7044.1216  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 1m 58s (remain 12m 6s) Loss: 0.0012(0.0052) Grad: 1588.4075  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 20s (remain 11m 37s) Loss: 0.0126(0.0056) Grad: 7931.7402  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 2m 43s (remain 11m 9s) Loss: 0.0042(0.0056) Grad: 6374.6040  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 5s (remain 10m 43s) Loss: 0.0044(0.0055) Grad: 5669.0015  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 3m 28s (remain 10m 18s) Loss: 0.0011(0.0054) Grad: 2101.0254  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 3m 50s (remain 9m 53s) Loss: 0.0002(0.0053) Grad: 684.7004  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 4m 13s (remain 9m 29s) Loss: 0.0113(0.0053) Grad: 13631.1738  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 4m 35s (remain 9m 5s) Loss: 0.0011(0.0053) Grad: 2329.3098  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 4m 58s (remain 8m 41s) Loss: 0.0020(0.0055) Grad: 3691.0969  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 5m 20s (remain 8m 17s) Loss: 0.0001(0.0054) Grad: 69.2198  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 5m 43s (remain 7m 54s) Loss: 0.0009(0.0054) Grad: 1823.2002  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 6m 5s (remain 7m 30s) Loss: 0.0002(0.0054) Grad: 414.9158  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 6m 28s (remain 7m 7s) Loss: 0.0095(0.0055) Grad: 4347.4561  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 6m 50s (remain 6m 44s) Loss: 0.0001(0.0054) Grad: 314.5248  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 7m 13s (remain 6m 21s) Loss: 0.0005(0.0054) Grad: 1739.2909  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 7m 35s (remain 5m 58s) Loss: 0.0019(0.0053) Grad: 3671.7720  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 7m 58s (remain 5m 35s) Loss: 0.0205(0.0053) Grad: 4243.5332  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 8m 20s (remain 5m 12s) Loss: 0.0073(0.0053) Grad: 5154.9165  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 8m 43s (remain 4m 49s) Loss: 0.0005(0.0053) Grad: 1598.3383  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 9m 6s (remain 4m 27s) Loss: 0.0029(0.0052) Grad: 5830.3921  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 9m 28s (remain 4m 4s) Loss: 0.0103(0.0052) Grad: 9257.8223  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 9m 51s (remain 3m 41s) Loss: 0.0000(0.0052) Grad: 48.0969  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 10m 13s (remain 3m 18s) Loss: 0.0030(0.0052) Grad: 6453.1064  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 10m 36s (remain 2m 55s) Loss: 0.0001(0.0053) Grad: 245.1656  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 10m 58s (remain 2m 33s) Loss: 0.0032(0.0053) Grad: 5594.1621  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 11m 21s (remain 2m 10s) Loss: 0.0001(0.0052) Grad: 176.1788  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 11m 43s (remain 1m 47s) Loss: 0.0011(0.0052) Grad: 3394.2178  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 12m 6s (remain 1m 24s) Loss: 0.0001(0.0052) Grad: 277.6033  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 12m 28s (remain 1m 2s) Loss: 0.0090(0.0053) Grad: 12247.4395  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 12m 51s (remain 0m 39s) Loss: 0.0000(0.0052) Grad: 10.2743  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 13m 13s (remain 0m 16s) Loss: 0.0008(0.0053) Grad: 1308.8403  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 13m 30s (remain 0m 0s) Loss: 0.0014(0.0053) Grad: 2443.4014  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 32s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0072(0.0040) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0047(0.0050) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0070(0.0051) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0048(0.0053) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0097(0.0048) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0136(0.0051) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0727(0.0060) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0019(0.0063) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0100(0.0063) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0061) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0010(0.0059) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0000(0.0057) \n","Epoch 2 - avg_train_loss: 0.0053  avg_val_loss: 0.0057  time: 940s\n","Epoch 2 - Score: 0.8776\n","Epoch 2 - Save Best Score: 0.8776 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 35m 15s) Loss: 0.0011(0.0011) Grad: 4096.0635  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 27s (remain 15m 48s) Loss: 0.0001(0.0033) Grad: 266.8348  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 51s (remain 14m 16s) Loss: 0.0033(0.0040) Grad: 5858.5215  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 13s (remain 13m 21s) Loss: 0.0003(0.0038) Grad: 2554.2083  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 36s (remain 12m 41s) Loss: 0.0067(0.0039) Grad: 20682.1270  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 1m 58s (remain 12m 7s) Loss: 0.0000(0.0040) Grad: 89.4495  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 20s (remain 11m 37s) Loss: 0.0424(0.0039) Grad: 58578.0508  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 2m 43s (remain 11m 9s) Loss: 0.0058(0.0040) Grad: 29584.7188  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 5s (remain 10m 44s) Loss: 0.0000(0.0041) Grad: 246.8411  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 3m 28s (remain 10m 18s) Loss: 0.0000(0.0041) Grad: 129.1068  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 3m 50s (remain 9m 53s) Loss: 0.0002(0.0041) Grad: 488.2639  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 13s (remain 9m 29s) Loss: 0.0000(0.0040) Grad: 148.6755  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 4m 35s (remain 9m 5s) Loss: 0.0105(0.0041) Grad: 9569.1113  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 4m 58s (remain 8m 41s) Loss: 0.0000(0.0041) Grad: 18.7705  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 5m 21s (remain 8m 18s) Loss: 0.0104(0.0041) Grad: 12822.2305  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 5m 43s (remain 7m 54s) Loss: 0.0000(0.0042) Grad: 21.8653  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 6m 5s (remain 7m 31s) Loss: 0.0001(0.0041) Grad: 291.8864  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 6m 28s (remain 7m 7s) Loss: 0.0002(0.0040) Grad: 756.9117  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 6m 50s (remain 6m 44s) Loss: 0.0034(0.0039) Grad: 13910.5771  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 7m 13s (remain 6m 21s) Loss: 0.0417(0.0040) Grad: 31793.6445  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 7m 35s (remain 5m 58s) Loss: 0.0045(0.0040) Grad: 18663.3730  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 7m 58s (remain 5m 35s) Loss: 0.0005(0.0040) Grad: 8085.8921  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 8m 20s (remain 5m 12s) Loss: 0.0058(0.0040) Grad: 12759.5664  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 8m 43s (remain 4m 49s) Loss: 0.0021(0.0040) Grad: 7413.2427  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 9m 5s (remain 4m 26s) Loss: 0.0016(0.0040) Grad: 6446.1060  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 9m 28s (remain 4m 4s) Loss: 0.0000(0.0040) Grad: 11.6831  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 9m 50s (remain 3m 41s) Loss: 0.0000(0.0040) Grad: 265.9180  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 10m 13s (remain 3m 18s) Loss: 0.0122(0.0039) Grad: 19720.4238  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 10m 36s (remain 2m 55s) Loss: 0.0049(0.0040) Grad: 8673.0557  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 10m 58s (remain 2m 33s) Loss: 0.0075(0.0040) Grad: 12373.5771  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 11m 21s (remain 2m 10s) Loss: 0.0000(0.0040) Grad: 109.1051  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 11m 43s (remain 1m 47s) Loss: 0.0001(0.0040) Grad: 283.5545  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 12m 6s (remain 1m 24s) Loss: 0.0015(0.0040) Grad: 10260.5518  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 12m 28s (remain 1m 2s) Loss: 0.0000(0.0040) Grad: 4.5729  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 12m 51s (remain 0m 39s) Loss: 0.0001(0.0040) Grad: 501.9148  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 13m 13s (remain 0m 16s) Loss: 0.0000(0.0040) Grad: 31.9409  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 13m 30s (remain 0m 0s) Loss: 0.0011(0.0040) Grad: 6311.5464  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 38s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0076(0.0052) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0080(0.0061) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0082(0.0064) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0040(0.0065) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0033(0.0059) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0023(0.0062) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0794(0.0075) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0011(0.0077) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0004(0.0076) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0075) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0012(0.0072) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0000(0.0071) \n","Epoch 3 - avg_train_loss: 0.0040  avg_val_loss: 0.0071  time: 943s\n","Epoch 3 - Score: 0.8794\n","Epoch 3 - Save Best Score: 0.8794 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 32m 52s) Loss: 0.0004(0.0004) Grad: 2354.6692  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 26s (remain 15m 5s) Loss: 0.0015(0.0038) Grad: 5945.6577  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 51s (remain 14m 16s) Loss: 0.0000(0.0039) Grad: 46.7350  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 13s (remain 13m 21s) Loss: 0.0000(0.0038) Grad: 50.9373  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 36s (remain 12m 43s) Loss: 0.0059(0.0036) Grad: 39863.4727  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 1m 59s (remain 12m 10s) Loss: 0.0035(0.0035) Grad: 43968.3281  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 21s (remain 11m 41s) Loss: 0.0049(0.0036) Grad: 23161.2402  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 2m 44s (remain 11m 13s) Loss: 0.0011(0.0035) Grad: 5753.8154  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 6s (remain 10m 46s) Loss: 0.0000(0.0034) Grad: 42.3504  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 3m 29s (remain 10m 21s) Loss: 0.0049(0.0032) Grad: 24838.0273  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 3m 52s (remain 9m 57s) Loss: 0.0000(0.0032) Grad: 142.1991  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 14s (remain 9m 32s) Loss: 0.0000(0.0032) Grad: 21.7559  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 4m 37s (remain 9m 8s) Loss: 0.0000(0.0031) Grad: 28.9656  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 0s (remain 8m 44s) Loss: 0.0002(0.0032) Grad: 1099.6644  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 5m 22s (remain 8m 20s) Loss: 0.0001(0.0032) Grad: 1982.8136  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 5m 45s (remain 7m 57s) Loss: 0.0002(0.0032) Grad: 1093.6013  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 6m 8s (remain 7m 33s) Loss: 0.0000(0.0032) Grad: 212.3740  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 6m 30s (remain 7m 10s) Loss: 0.0000(0.0033) Grad: 5.2138  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 6m 53s (remain 6m 47s) Loss: 0.0000(0.0032) Grad: 90.7061  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 7m 15s (remain 6m 23s) Loss: 0.0013(0.0033) Grad: 19890.5938  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 7m 38s (remain 6m 0s) Loss: 0.0010(0.0032) Grad: 5446.4121  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 8m 1s (remain 5m 37s) Loss: 0.0026(0.0032) Grad: 17770.4941  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 8m 23s (remain 5m 14s) Loss: 0.0044(0.0033) Grad: 10495.5684  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 8m 46s (remain 4m 51s) Loss: 0.0164(0.0033) Grad: 13477.4150  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 9m 9s (remain 4m 28s) Loss: 0.0000(0.0033) Grad: 13.5296  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 9m 31s (remain 4m 5s) Loss: 0.0000(0.0033) Grad: 172.7062  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 9m 54s (remain 3m 42s) Loss: 0.0000(0.0033) Grad: 23.6215  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 10m 17s (remain 3m 19s) Loss: 0.0167(0.0033) Grad: 40420.2812  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 10m 39s (remain 2m 56s) Loss: 0.0037(0.0033) Grad: 4774.3550  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 11m 2s (remain 2m 33s) Loss: 0.0055(0.0033) Grad: 36944.4375  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 11m 24s (remain 2m 10s) Loss: 0.0000(0.0033) Grad: 12.9032  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 11m 47s (remain 1m 48s) Loss: 0.0033(0.0034) Grad: 7253.3271  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 12m 10s (remain 1m 25s) Loss: 0.0000(0.0033) Grad: 41.5965  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 12m 32s (remain 1m 2s) Loss: 0.0000(0.0033) Grad: 9.8582  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 12m 55s (remain 0m 39s) Loss: 0.0026(0.0033) Grad: 16067.3398  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 13m 17s (remain 0m 16s) Loss: 0.0000(0.0032) Grad: 155.6129  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 13m 34s (remain 0m 0s) Loss: 0.0000(0.0032) Grad: 66.6372  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 9s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0156(0.0060) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0133(0.0072) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 32s) Loss: 0.0050(0.0075) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0077(0.0075) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0083(0.0068) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0008(0.0072) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0845(0.0087) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0002(0.0089) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0022(0.0088) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0087) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0007(0.0083) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0000(0.0081) \n","Epoch 4 - avg_train_loss: 0.0032  avg_val_loss: 0.0081  time: 947s\n","Epoch 4 - Score: 0.8817\n","Epoch 4 - Save Best Score: 0.8817 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 31m 8s) Loss: 0.0000(0.0000) Grad: 83.0906  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 26s (remain 15m 17s) Loss: 0.0000(0.0022) Grad: 43.8628  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 51s (remain 14m 18s) Loss: 0.0000(0.0022) Grad: 11.3415  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 13s (remain 13m 22s) Loss: 0.0000(0.0026) Grad: 2.6852  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 36s (remain 12m 41s) Loss: 0.0016(0.0023) Grad: 11533.3760  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 1m 58s (remain 12m 9s) Loss: 0.0000(0.0022) Grad: 227.8280  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 21s (remain 11m 39s) Loss: 0.0038(0.0023) Grad: 5292.3911  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 2m 43s (remain 11m 11s) Loss: 0.0000(0.0023) Grad: 5.7487  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 6s (remain 10m 46s) Loss: 0.0039(0.0024) Grad: 59857.9883  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 3m 29s (remain 10m 21s) Loss: 0.0000(0.0024) Grad: 11.3181  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 3m 52s (remain 9m 56s) Loss: 0.1159(0.0025) Grad: 85723.8828  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 14s (remain 9m 32s) Loss: 0.0039(0.0025) Grad: 34712.2734  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 4m 37s (remain 9m 8s) Loss: 0.0000(0.0025) Grad: 1.9056  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 4m 59s (remain 8m 44s) Loss: 0.0006(0.0024) Grad: 6870.9243  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 5m 22s (remain 8m 20s) Loss: 0.0001(0.0026) Grad: 303.7241  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 5m 45s (remain 7m 56s) Loss: 0.0000(0.0026) Grad: 114.3050  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 6m 7s (remain 7m 33s) Loss: 0.0000(0.0025) Grad: 48.0262  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 6m 30s (remain 7m 10s) Loss: 0.0000(0.0026) Grad: 25.8081  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 6m 52s (remain 6m 46s) Loss: 0.0038(0.0025) Grad: 4596.6245  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 7m 15s (remain 6m 23s) Loss: 0.0000(0.0025) Grad: 6.4998  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 7m 38s (remain 6m 0s) Loss: 0.0000(0.0025) Grad: 81.3192  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 8m 0s (remain 5m 37s) Loss: 0.0031(0.0026) Grad: 7847.4517  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 8m 23s (remain 5m 14s) Loss: 0.0016(0.0025) Grad: 9798.0361  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 8m 46s (remain 4m 51s) Loss: 0.0000(0.0026) Grad: 152.3656  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 9m 8s (remain 4m 28s) Loss: 0.0000(0.0026) Grad: 98.0254  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 9m 31s (remain 4m 5s) Loss: 0.0000(0.0026) Grad: 20.4614  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 9m 53s (remain 3m 42s) Loss: 0.0000(0.0026) Grad: 34.6990  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 10m 16s (remain 3m 19s) Loss: 0.0001(0.0026) Grad: 210.8947  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 10m 39s (remain 2m 56s) Loss: 0.0005(0.0026) Grad: 8952.9902  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 11m 1s (remain 2m 33s) Loss: 0.0089(0.0025) Grad: 19801.3086  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 11m 24s (remain 2m 10s) Loss: 0.0000(0.0025) Grad: 45.0333  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 11m 46s (remain 1m 48s) Loss: 0.0013(0.0025) Grad: 23641.9531  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 12m 9s (remain 1m 25s) Loss: 0.0028(0.0025) Grad: 4007.9209  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 12m 32s (remain 1m 2s) Loss: 0.0000(0.0025) Grad: 43.0436  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 12m 54s (remain 0m 39s) Loss: 0.0001(0.0025) Grad: 333.3161  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 13m 17s (remain 0m 16s) Loss: 0.0001(0.0025) Grad: 2365.2278  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 13m 33s (remain 0m 0s) Loss: 0.0032(0.0025) Grad: 5497.1543  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 6m 56s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0103(0.0064) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0132(0.0076) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0044(0.0077) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0087(0.0077) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0103(0.0071) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0016(0.0074) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0861(0.0087) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0001(0.0089) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0063(0.0088) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0087) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0002(0.0084) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0000(0.0082) \n","Epoch 5 - avg_train_loss: 0.0025  avg_val_loss: 0.0082  time: 946s\n","Epoch 5 - Score: 0.8832\n","Epoch 5 - Save Best Score: 0.8832 Model\n","========== fold: 1 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 40m 52s) Loss: 0.3820(0.3820) Grad: 235657.7969  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 26s (remain 15m 12s) Loss: 0.3317(0.3734) Grad: 206072.5469  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 49s (remain 13m 46s) Loss: 0.2127(0.3224) Grad: 128262.3125  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 11s (remain 13m 1s) Loss: 0.0452(0.2573) Grad: 9116.8516  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 34s (remain 12m 26s) Loss: 0.0236(0.2023) Grad: 1216.0879  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 1m 57s (remain 11m 58s) Loss: 0.0175(0.1683) Grad: 692.1767  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 19s (remain 11m 32s) Loss: 0.0332(0.1458) Grad: 1558.5590  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 2m 42s (remain 11m 6s) Loss: 0.0069(0.1290) Grad: 1217.3750  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 5s (remain 10m 42s) Loss: 0.1074(0.1158) Grad: 9607.3203  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 3m 28s (remain 10m 17s) Loss: 0.0280(0.1048) Grad: 11994.0156  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 3m 50s (remain 9m 53s) Loss: 0.0042(0.0956) Grad: 1801.1252  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 13s (remain 9m 30s) Loss: 0.0059(0.0882) Grad: 3019.8367  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 4m 36s (remain 9m 6s) Loss: 0.0118(0.0818) Grad: 1188.0121  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 4m 59s (remain 8m 43s) Loss: 0.0016(0.0763) Grad: 1372.4874  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 5m 22s (remain 8m 20s) Loss: 0.0017(0.0717) Grad: 941.4277  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 5m 45s (remain 7m 56s) Loss: 0.0001(0.0677) Grad: 67.6418  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 6m 7s (remain 7m 33s) Loss: 0.0040(0.0642) Grad: 1404.5758  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 6m 30s (remain 7m 10s) Loss: 0.0020(0.0609) Grad: 911.1181  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 6m 53s (remain 6m 47s) Loss: 0.0135(0.0580) Grad: 1716.5345  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 7m 15s (remain 6m 23s) Loss: 0.0017(0.0554) Grad: 779.9351  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 7m 38s (remain 6m 0s) Loss: 0.0032(0.0530) Grad: 1707.3391  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 8m 1s (remain 5m 37s) Loss: 0.0014(0.0509) Grad: 518.2341  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 8m 24s (remain 5m 14s) Loss: 0.0010(0.0490) Grad: 340.5412  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 8m 47s (remain 4m 52s) Loss: 0.0047(0.0471) Grad: 2592.1604  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 9m 10s (remain 4m 29s) Loss: 0.0027(0.0454) Grad: 970.1732  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 9m 34s (remain 4m 6s) Loss: 0.0310(0.0440) Grad: 5129.5078  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 9m 57s (remain 3m 43s) Loss: 0.0004(0.0425) Grad: 2809.0813  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 10m 19s (remain 3m 20s) Loss: 0.0114(0.0412) Grad: 1880.2319  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 10m 42s (remain 2m 57s) Loss: 0.0077(0.0400) Grad: 1214.5186  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 11m 5s (remain 2m 34s) Loss: 0.0116(0.0388) Grad: 6313.4375  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 11m 27s (remain 2m 11s) Loss: 0.0028(0.0378) Grad: 14472.2998  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 11m 50s (remain 1m 48s) Loss: 0.0000(0.0368) Grad: 13.5115  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 12m 13s (remain 1m 25s) Loss: 0.0047(0.0359) Grad: 1519.4370  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 12m 36s (remain 1m 2s) Loss: 0.0022(0.0350) Grad: 685.3589  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 12m 58s (remain 0m 39s) Loss: 0.0029(0.0341) Grad: 905.1769  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 13m 21s (remain 0m 16s) Loss: 0.0001(0.0333) Grad: 171.8339  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 13m 38s (remain 0m 0s) Loss: 0.0000(0.0327) Grad: 5.9300  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 4s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 56s) Loss: 0.0000(0.0049) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 44s) Loss: 0.0007(0.0062) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0052(0.0090) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0156(0.0094) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0088(0.0090) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.1248(0.0091) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0155(0.0102) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0028(0.0098) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0049(0.0097) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0094) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0033(0.0089) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0052(0.0085) \n","Epoch 1 - avg_train_loss: 0.0327  avg_val_loss: 0.0085  time: 947s\n","Epoch 1 - Score: 0.8531\n","Epoch 1 - Save Best Score: 0.8531 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 39m 50s) Loss: 0.0302(0.0302) Grad: 47591.7891  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 26s (remain 15m 20s) Loss: 0.0060(0.0072) Grad: 8932.4229  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 51s (remain 14m 18s) Loss: 0.0207(0.0066) Grad: 18207.4121  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 14s (remain 13m 28s) Loss: 0.0004(0.0062) Grad: 2447.7893  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 37s (remain 12m 48s) Loss: 0.0002(0.0062) Grad: 2811.2290  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 1m 59s (remain 12m 15s) Loss: 0.0152(0.0064) Grad: 34775.4609  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 22s (remain 11m 45s) Loss: 0.0001(0.0061) Grad: 396.2014  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 2m 45s (remain 11m 18s) Loss: 0.0000(0.0058) Grad: 82.7652  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 8s (remain 10m 52s) Loss: 0.0080(0.0057) Grad: 13136.2988  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 3m 31s (remain 10m 26s) Loss: 0.0042(0.0060) Grad: 5166.8301  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 3m 53s (remain 10m 1s) Loss: 0.0015(0.0059) Grad: 12656.2998  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 4m 16s (remain 9m 36s) Loss: 0.0064(0.0060) Grad: 11129.8037  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 4m 39s (remain 9m 11s) Loss: 0.0054(0.0060) Grad: 34745.7344  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 5m 1s (remain 8m 47s) Loss: 0.0001(0.0060) Grad: 270.1115  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 5m 24s (remain 8m 24s) Loss: 0.0000(0.0060) Grad: 87.1152  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 5m 47s (remain 8m 0s) Loss: 0.0001(0.0060) Grad: 184.6649  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 6m 10s (remain 7m 36s) Loss: 0.0005(0.0060) Grad: 1168.9772  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 6m 33s (remain 7m 12s) Loss: 0.0042(0.0059) Grad: 3115.5957  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 6m 55s (remain 6m 49s) Loss: 0.0000(0.0058) Grad: 54.9228  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 7m 18s (remain 6m 26s) Loss: 0.0006(0.0058) Grad: 1642.3315  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 7m 41s (remain 6m 2s) Loss: 0.0453(0.0058) Grad: 29179.0410  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 8m 4s (remain 5m 39s) Loss: 0.0009(0.0058) Grad: 6575.8145  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 8m 26s (remain 5m 16s) Loss: 0.0063(0.0057) Grad: 9495.5635  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 8m 49s (remain 4m 53s) Loss: 0.0000(0.0057) Grad: 35.5618  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 9m 12s (remain 4m 30s) Loss: 0.0070(0.0056) Grad: 21150.2344  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 9m 34s (remain 4m 6s) Loss: 0.0006(0.0056) Grad: 1423.0939  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 9m 57s (remain 3m 43s) Loss: 0.0086(0.0056) Grad: 7400.9341  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 10m 20s (remain 3m 20s) Loss: 0.0004(0.0055) Grad: 921.0771  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 10m 43s (remain 2m 57s) Loss: 0.0001(0.0055) Grad: 571.8083  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 11m 5s (remain 2m 34s) Loss: 0.0112(0.0054) Grad: 6836.0396  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 11m 28s (remain 2m 11s) Loss: 0.0024(0.0055) Grad: 4398.1216  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 11m 51s (remain 1m 48s) Loss: 0.0009(0.0054) Grad: 1972.8717  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 12m 14s (remain 1m 25s) Loss: 0.0061(0.0054) Grad: 23093.4785  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 12m 36s (remain 1m 2s) Loss: 0.0001(0.0053) Grad: 147.8839  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 12m 59s (remain 0m 39s) Loss: 0.0044(0.0054) Grad: 4687.2983  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 13m 22s (remain 0m 16s) Loss: 0.0218(0.0053) Grad: 33001.8984  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 13m 39s (remain 0m 0s) Loss: 0.0001(0.0053) Grad: 366.2549  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 5s) Loss: 0.0002(0.0002) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0001(0.0044) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0004(0.0045) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 32s) Loss: 0.0007(0.0071) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0154(0.0073) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0115(0.0071) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.1064(0.0072) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0094(0.0081) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0117(0.0077) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0037(0.0076) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0001(0.0073) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0038(0.0069) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0053(0.0065) \n","Epoch 2 - avg_train_loss: 0.0053  avg_val_loss: 0.0065  time: 955s\n","Epoch 2 - Score: 0.8724\n","Epoch 2 - Save Best Score: 0.8724 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 32m 12s) Loss: 0.0000(0.0000) Grad: 370.0852  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 26s (remain 15m 26s) Loss: 0.0092(0.0022) Grad: 42083.8672  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 51s (remain 14m 22s) Loss: 0.0000(0.0028) Grad: 56.4731  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 14s (remain 13m 25s) Loss: 0.0006(0.0038) Grad: 2013.3314  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 36s (remain 12m 46s) Loss: 0.0005(0.0038) Grad: 10252.7246  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 1m 59s (remain 12m 12s) Loss: 0.0032(0.0039) Grad: 7674.1396  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 22s (remain 11m 43s) Loss: 0.0000(0.0039) Grad: 84.2729  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 2m 45s (remain 11m 16s) Loss: 0.0002(0.0040) Grad: 1106.7070  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 7s (remain 10m 50s) Loss: 0.0002(0.0041) Grad: 1444.7478  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 3m 30s (remain 10m 26s) Loss: 0.0000(0.0040) Grad: 64.3540  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 3m 53s (remain 10m 0s) Loss: 0.0000(0.0040) Grad: 100.3870  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 16s (remain 9m 36s) Loss: 0.0033(0.0039) Grad: 6344.8062  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 4m 38s (remain 9m 11s) Loss: 0.0026(0.0039) Grad: 7282.1221  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 1s (remain 8m 47s) Loss: 0.0000(0.0039) Grad: 136.2710  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 5m 24s (remain 8m 23s) Loss: 0.0006(0.0039) Grad: 1950.0773  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 5m 47s (remain 7m 59s) Loss: 0.0120(0.0039) Grad: 24316.8242  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 6m 9s (remain 7m 35s) Loss: 0.0005(0.0039) Grad: 3455.5540  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 6m 32s (remain 7m 12s) Loss: 0.0001(0.0039) Grad: 2199.9070  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 6m 55s (remain 6m 48s) Loss: 0.0008(0.0039) Grad: 6302.3862  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 7m 17s (remain 6m 25s) Loss: 0.0000(0.0039) Grad: 35.3709  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 7m 40s (remain 6m 2s) Loss: 0.0000(0.0039) Grad: 30.7367  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 8m 3s (remain 5m 39s) Loss: 0.0065(0.0038) Grad: 28054.6973  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 8m 25s (remain 5m 15s) Loss: 0.0000(0.0039) Grad: 122.0722  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 8m 48s (remain 4m 52s) Loss: 0.0001(0.0039) Grad: 541.4294  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 9m 11s (remain 4m 29s) Loss: 0.0011(0.0040) Grad: 4249.5967  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 9m 34s (remain 4m 6s) Loss: 0.0024(0.0039) Grad: 7223.8931  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 9m 56s (remain 3m 43s) Loss: 0.0000(0.0039) Grad: 410.8927  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 10m 19s (remain 3m 20s) Loss: 0.0080(0.0039) Grad: 102976.1172  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 10m 42s (remain 2m 57s) Loss: 0.0014(0.0039) Grad: 3291.9043  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 11m 4s (remain 2m 34s) Loss: 0.0050(0.0039) Grad: 14744.8936  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 11m 27s (remain 2m 11s) Loss: 0.0000(0.0039) Grad: 333.3188  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 11m 50s (remain 1m 48s) Loss: 0.0105(0.0039) Grad: 13731.2119  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 12m 12s (remain 1m 25s) Loss: 0.0021(0.0039) Grad: 8612.2119  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 12m 35s (remain 1m 2s) Loss: 0.0000(0.0039) Grad: 16.5955  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 12m 58s (remain 0m 39s) Loss: 0.0001(0.0039) Grad: 811.1535  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 13m 21s (remain 0m 16s) Loss: 0.0001(0.0039) Grad: 343.0543  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 13m 37s (remain 0m 0s) Loss: 0.0015(0.0039) Grad: 5775.4902  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 20s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0001(0.0043) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0007(0.0048) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0007(0.0076) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0154(0.0079) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0150(0.0075) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.1111(0.0076) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0136(0.0085) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0186(0.0081) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0012(0.0079) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0077) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0062(0.0072) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0071(0.0068) \n","Epoch 3 - avg_train_loss: 0.0039  avg_val_loss: 0.0068  time: 959s\n","Epoch 3 - Score: 0.8759\n","Epoch 3 - Save Best Score: 0.8759 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 31m 36s) Loss: 0.0002(0.0002) Grad: 1113.6842  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 27s (remain 15m 43s) Loss: 0.0000(0.0035) Grad: 15.2249  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 51s (remain 14m 17s) Loss: 0.0035(0.0039) Grad: 9365.4072  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 13s (remain 13m 23s) Loss: 0.0083(0.0040) Grad: 34861.2617  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 36s (remain 12m 44s) Loss: 0.0000(0.0037) Grad: 88.2728  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 1m 59s (remain 12m 11s) Loss: 0.0143(0.0036) Grad: 12020.6582  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 21s (remain 11m 42s) Loss: 0.0000(0.0033) Grad: 4.3764  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 2m 44s (remain 11m 15s) Loss: 0.0001(0.0033) Grad: 747.0796  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 7s (remain 10m 49s) Loss: 0.0000(0.0032) Grad: 28.1031  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 3m 30s (remain 10m 23s) Loss: 0.0000(0.0031) Grad: 235.7476  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 3m 52s (remain 9m 58s) Loss: 0.0001(0.0030) Grad: 690.2414  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 15s (remain 9m 34s) Loss: 0.0022(0.0031) Grad: 17564.3926  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 4m 38s (remain 9m 9s) Loss: 0.0083(0.0031) Grad: 32802.9453  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 0s (remain 8m 45s) Loss: 0.0000(0.0031) Grad: 63.1366  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 5m 23s (remain 8m 21s) Loss: 0.0000(0.0031) Grad: 180.8756  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 5m 46s (remain 7m 58s) Loss: 0.0001(0.0031) Grad: 290.9006  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 6m 8s (remain 7m 34s) Loss: 0.0021(0.0032) Grad: 9044.9717  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 6m 31s (remain 7m 10s) Loss: 0.0016(0.0031) Grad: 9178.3740  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 6m 53s (remain 6m 47s) Loss: 0.0000(0.0031) Grad: 13.8756  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 7m 16s (remain 6m 24s) Loss: 0.0000(0.0031) Grad: 17.6797  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 7m 38s (remain 6m 0s) Loss: 0.0097(0.0031) Grad: 40218.3516  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 8m 1s (remain 5m 37s) Loss: 0.0045(0.0031) Grad: 14086.6318  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 8m 23s (remain 5m 14s) Loss: 0.0017(0.0031) Grad: 8025.6846  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 8m 45s (remain 4m 51s) Loss: 0.0011(0.0031) Grad: 14702.6328  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 9m 8s (remain 4m 27s) Loss: 0.0000(0.0031) Grad: 15.0723  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 9m 30s (remain 4m 5s) Loss: 0.0030(0.0031) Grad: 22135.2441  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 9m 53s (remain 3m 42s) Loss: 0.0026(0.0031) Grad: 10371.4883  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 10m 15s (remain 3m 19s) Loss: 0.0082(0.0031) Grad: 8809.4531  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 10m 37s (remain 2m 56s) Loss: 0.0010(0.0031) Grad: 4343.9434  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 11m 0s (remain 2m 33s) Loss: 0.0000(0.0031) Grad: 7.8577  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 11m 22s (remain 2m 10s) Loss: 0.0000(0.0031) Grad: 61.0724  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 11m 45s (remain 1m 47s) Loss: 0.0004(0.0031) Grad: 880.7837  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 12m 7s (remain 1m 25s) Loss: 0.0040(0.0031) Grad: 7381.4136  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 12m 30s (remain 1m 2s) Loss: 0.0033(0.0030) Grad: 5339.2944  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 12m 52s (remain 0m 39s) Loss: 0.0016(0.0030) Grad: 3644.4575  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 13m 15s (remain 0m 16s) Loss: 0.0635(0.0030) Grad: 29601.8027  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 13m 31s (remain 0m 0s) Loss: 0.0002(0.0030) Grad: 1123.8916  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 11s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0000(0.0051) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0000(0.0052) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0002(0.0085) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0205(0.0090) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0176(0.0085) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.1265(0.0085) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0192(0.0098) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0081(0.0093) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0004(0.0092) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0088) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0074(0.0083) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0075(0.0079) \n","Epoch 4 - avg_train_loss: 0.0030  avg_val_loss: 0.0079  time: 957s\n","Epoch 4 - Score: 0.8797\n","Epoch 4 - Save Best Score: 0.8797 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 33m 7s) Loss: 0.0000(0.0000) Grad: 1002.6313  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 26s (remain 15m 7s) Loss: 0.0000(0.0025) Grad: 11.7574  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 50s (remain 14m 11s) Loss: 0.0000(0.0022) Grad: 41.9682  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 13s (remain 13m 17s) Loss: 0.0000(0.0020) Grad: 614.3577  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 35s (remain 12m 39s) Loss: 0.0000(0.0022) Grad: 172.5697  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 1m 58s (remain 12m 7s) Loss: 0.0237(0.0024) Grad: 38227.1641  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 21s (remain 11m 39s) Loss: 0.0000(0.0023) Grad: 143.8719  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 2m 43s (remain 11m 12s) Loss: 0.0000(0.0025) Grad: 14.0916  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 6s (remain 10m 46s) Loss: 0.0240(0.0024) Grad: 52101.7734  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 3m 29s (remain 10m 20s) Loss: 0.0012(0.0024) Grad: 18757.4688  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 3m 51s (remain 9m 55s) Loss: 0.0588(0.0026) Grad: 50464.2344  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 14s (remain 9m 31s) Loss: 0.0000(0.0026) Grad: 151.2215  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 4m 37s (remain 9m 7s) Loss: 0.0045(0.0026) Grad: 10785.7197  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 4m 59s (remain 8m 43s) Loss: 0.0000(0.0026) Grad: 2.8242  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 5m 22s (remain 8m 19s) Loss: 0.0016(0.0026) Grad: 11736.6426  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 5m 44s (remain 7m 56s) Loss: 0.0037(0.0025) Grad: 5003.7080  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 6m 7s (remain 7m 33s) Loss: 0.0000(0.0025) Grad: 13.4836  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 6m 30s (remain 7m 9s) Loss: 0.0000(0.0026) Grad: 41.1597  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 6m 52s (remain 6m 46s) Loss: 0.0000(0.0026) Grad: 110.3569  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 7m 15s (remain 6m 23s) Loss: 0.0000(0.0025) Grad: 52.7036  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 7m 38s (remain 6m 0s) Loss: 0.0000(0.0025) Grad: 158.0105  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 8m 0s (remain 5m 37s) Loss: 0.0008(0.0025) Grad: 12017.4756  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 8m 23s (remain 5m 14s) Loss: 0.0000(0.0025) Grad: 31.3605  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 8m 45s (remain 4m 51s) Loss: 0.0302(0.0025) Grad: 12105.4541  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 9m 8s (remain 4m 28s) Loss: 0.0029(0.0024) Grad: 12336.2959  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 9m 31s (remain 4m 5s) Loss: 0.0009(0.0024) Grad: 8544.7344  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 9m 53s (remain 3m 42s) Loss: 0.0002(0.0024) Grad: 2192.4048  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 10m 16s (remain 3m 19s) Loss: 0.0000(0.0024) Grad: 17.0766  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 10m 39s (remain 2m 56s) Loss: 0.0000(0.0024) Grad: 18.6812  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 11m 2s (remain 2m 33s) Loss: 0.0002(0.0024) Grad: 1166.2511  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 11m 24s (remain 2m 10s) Loss: 0.0000(0.0024) Grad: 72.5963  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 11m 47s (remain 1m 48s) Loss: 0.0000(0.0024) Grad: 37.3419  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 12m 10s (remain 1m 25s) Loss: 0.0000(0.0024) Grad: 32.7086  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 12m 32s (remain 1m 2s) Loss: 0.0001(0.0024) Grad: 982.9774  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 12m 55s (remain 0m 39s) Loss: 0.0065(0.0024) Grad: 12904.0156  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 13m 18s (remain 0m 16s) Loss: 0.0000(0.0024) Grad: 234.4815  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 13m 35s (remain 0m 0s) Loss: 0.0000(0.0025) Grad: 48.7308  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 24s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0000(0.0061) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0000(0.0059) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0001(0.0096) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0228(0.0101) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0196(0.0095) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.1318(0.0095) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0204(0.0108) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0043(0.0103) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0003(0.0100) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0097) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0086(0.0092) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0080(0.0087) \n","Epoch 5 - avg_train_loss: 0.0025  avg_val_loss: 0.0087  time: 953s\n","Epoch 5 - Score: 0.8799\n","Epoch 5 - Save Best Score: 0.8799 Model\n","========== fold: 2 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 43m 26s) Loss: 0.2898(0.2898) Grad: 191369.0000  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 25s (remain 14m 52s) Loss: 0.2587(0.2923) Grad: 86189.7188  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 48s (remain 13m 35s) Loss: 0.1192(0.2414) Grad: 19075.3906  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 11s (remain 12m 54s) Loss: 0.0354(0.1814) Grad: 2072.9700  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 33s (remain 12m 20s) Loss: 0.0740(0.1446) Grad: 6140.2305  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 1m 56s (remain 11m 52s) Loss: 0.0450(0.1228) Grad: 4178.3081  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 18s (remain 11m 26s) Loss: 0.0138(0.1075) Grad: 2533.2505  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 2m 41s (remain 11m 1s) Loss: 0.0018(0.0953) Grad: 1162.7322  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 3m 4s (remain 10m 37s) Loss: 0.0124(0.0855) Grad: 2332.5486  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 3m 26s (remain 10m 14s) Loss: 0.0055(0.0777) Grad: 2970.4612  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 3m 49s (remain 9m 50s) Loss: 0.0231(0.0713) Grad: 3997.7517  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 12s (remain 9m 26s) Loss: 0.0063(0.0658) Grad: 3441.4973  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 4m 34s (remain 9m 3s) Loss: 0.0041(0.0612) Grad: 3063.3860  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 4m 57s (remain 8m 40s) Loss: 0.0012(0.0574) Grad: 955.5955  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 5m 20s (remain 8m 16s) Loss: 0.0044(0.0540) Grad: 4605.9077  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 5m 42s (remain 7m 53s) Loss: 0.0007(0.0510) Grad: 482.0027  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 6m 4s (remain 7m 29s) Loss: 0.0065(0.0485) Grad: 3154.6946  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 6m 27s (remain 7m 6s) Loss: 0.0061(0.0461) Grad: 4665.0640  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 6m 49s (remain 6m 43s) Loss: 0.0089(0.0442) Grad: 5890.0488  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 7m 12s (remain 6m 20s) Loss: 0.0083(0.0423) Grad: 6763.1353  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 7m 34s (remain 5m 57s) Loss: 0.0131(0.0406) Grad: 4627.0825  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 7m 57s (remain 5m 34s) Loss: 0.0051(0.0391) Grad: 8939.1582  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 8m 19s (remain 5m 12s) Loss: 0.0111(0.0378) Grad: 11541.0762  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 8m 42s (remain 4m 49s) Loss: 0.0001(0.0365) Grad: 764.7301  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 9m 4s (remain 4m 26s) Loss: 0.0059(0.0353) Grad: 4304.9312  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 9m 27s (remain 4m 3s) Loss: 0.0132(0.0342) Grad: 3535.4390  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 9m 50s (remain 3m 41s) Loss: 0.0002(0.0332) Grad: 278.3297  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 10m 12s (remain 3m 18s) Loss: 0.0975(0.0323) Grad: 34208.4883  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 10m 35s (remain 2m 55s) Loss: 0.0010(0.0314) Grad: 942.6363  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 10m 57s (remain 2m 32s) Loss: 0.0040(0.0306) Grad: 2513.1033  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 11m 19s (remain 2m 10s) Loss: 0.0026(0.0298) Grad: 2375.1321  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 11m 42s (remain 1m 47s) Loss: 0.0228(0.0291) Grad: 6036.8188  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 12m 4s (remain 1m 24s) Loss: 0.0001(0.0284) Grad: 93.5174  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 12m 27s (remain 1m 2s) Loss: 0.0014(0.0278) Grad: 1833.6075  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 12m 49s (remain 0m 39s) Loss: 0.0125(0.0271) Grad: 5128.4712  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 13m 11s (remain 0m 16s) Loss: 0.0049(0.0266) Grad: 5746.0767  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 13m 28s (remain 0m 0s) Loss: 0.0015(0.0262) Grad: 899.4294  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 12s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 56s) Loss: 0.0196(0.0066) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 44s) Loss: 0.0099(0.0067) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0193(0.0062) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0037(0.0071) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0000(0.0071) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0094(0.0074) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0046(0.0084) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0000(0.0083) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0083(0.0087) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0110(0.0088) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0493(0.0085) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0000(0.0081) \n","Epoch 1 - avg_train_loss: 0.0262  avg_val_loss: 0.0081  time: 937s\n","Epoch 1 - Score: 0.8488\n","Epoch 1 - Save Best Score: 0.8488 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 33m 42s) Loss: 0.0000(0.0000) Grad: 913.8618  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 26s (remain 15m 14s) Loss: 0.0072(0.0054) Grad: 12759.5322  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 50s (remain 14m 8s) Loss: 0.0026(0.0052) Grad: 4858.4634  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 12s (remain 13m 12s) Loss: 0.0060(0.0050) Grad: 17872.8613  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 35s (remain 12m 35s) Loss: 0.0001(0.0054) Grad: 343.5033  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 1m 57s (remain 12m 3s) Loss: 0.0004(0.0056) Grad: 3752.6301  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 20s (remain 11m 34s) Loss: 0.0000(0.0056) Grad: 31.0006  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 2m 42s (remain 11m 6s) Loss: 0.0006(0.0056) Grad: 6476.7324  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 5s (remain 10m 40s) Loss: 0.0161(0.0056) Grad: 45874.8242  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 3m 27s (remain 10m 15s) Loss: 0.0008(0.0057) Grad: 8928.0488  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 3m 49s (remain 9m 50s) Loss: 0.0003(0.0057) Grad: 1089.4760  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 4m 12s (remain 9m 26s) Loss: 0.0011(0.0057) Grad: 5318.0654  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 4m 34s (remain 9m 2s) Loss: 0.0067(0.0057) Grad: 11236.3428  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 4m 56s (remain 8m 38s) Loss: 0.0000(0.0057) Grad: 36.9169  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 5m 19s (remain 8m 15s) Loss: 0.0181(0.0057) Grad: 27621.6465  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 5m 41s (remain 7m 51s) Loss: 0.0000(0.0056) Grad: 835.3832  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 6m 3s (remain 7m 28s) Loss: 0.0042(0.0056) Grad: 22716.5059  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 6m 26s (remain 7m 5s) Loss: 0.0009(0.0056) Grad: 4242.9956  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 6m 48s (remain 6m 42s) Loss: 0.0000(0.0056) Grad: 41.1638  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 7m 10s (remain 6m 19s) Loss: 0.0002(0.0057) Grad: 1244.6776  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 7m 33s (remain 5m 56s) Loss: 0.0001(0.0056) Grad: 146.9568  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 7m 55s (remain 5m 33s) Loss: 0.0098(0.0055) Grad: 10258.7773  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 8m 17s (remain 5m 10s) Loss: 0.0003(0.0055) Grad: 532.3564  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 8m 39s (remain 4m 47s) Loss: 0.0008(0.0056) Grad: 822.0558  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 9m 2s (remain 4m 25s) Loss: 0.0007(0.0056) Grad: 1119.8740  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 9m 24s (remain 4m 2s) Loss: 0.0068(0.0056) Grad: 6041.6484  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 9m 46s (remain 3m 39s) Loss: 0.0004(0.0056) Grad: 1305.7175  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 10m 9s (remain 3m 17s) Loss: 0.0755(0.0056) Grad: 29076.0703  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 10m 31s (remain 2m 54s) Loss: 0.0002(0.0056) Grad: 209.8422  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 10m 53s (remain 2m 31s) Loss: 0.0118(0.0056) Grad: 4196.3862  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 11m 16s (remain 2m 9s) Loss: 0.0012(0.0056) Grad: 1738.6156  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 11m 38s (remain 1m 46s) Loss: 0.0060(0.0056) Grad: 8917.7461  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 12m 0s (remain 1m 24s) Loss: 0.0006(0.0055) Grad: 828.8796  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 12m 23s (remain 1m 1s) Loss: 0.0003(0.0055) Grad: 242.4039  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 12m 45s (remain 0m 39s) Loss: 0.0174(0.0055) Grad: 4910.5991  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 13m 8s (remain 0m 16s) Loss: 0.0017(0.0055) Grad: 2118.0156  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 13m 24s (remain 0m 0s) Loss: 0.0002(0.0055) Grad: 283.2918  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 16s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0312(0.0062) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0086(0.0059) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0137(0.0057) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0003(0.0061) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0001(0.0056) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0075(0.0058) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0029(0.0062) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0001(0.0061) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0011(0.0062) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0148(0.0060) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0303(0.0057) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0003(0.0056) \n","Epoch 2 - avg_train_loss: 0.0055  avg_val_loss: 0.0056  time: 944s\n","Epoch 2 - Score: 0.8731\n","Epoch 2 - Save Best Score: 0.8731 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 32m 39s) Loss: 0.0003(0.0003) Grad: 900.4348  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 26s (remain 14m 54s) Loss: 0.0123(0.0038) Grad: 14719.3936  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 50s (remain 14m 1s) Loss: 0.0126(0.0034) Grad: 32212.6680  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 12s (remain 13m 7s) Loss: 0.0034(0.0036) Grad: 10049.8057  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 34s (remain 12m 29s) Loss: 0.0006(0.0036) Grad: 2867.1709  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 1m 56s (remain 11m 56s) Loss: 0.0002(0.0040) Grad: 658.5660  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 19s (remain 11m 28s) Loss: 0.0001(0.0040) Grad: 288.7008  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 2m 41s (remain 11m 1s) Loss: 0.0076(0.0041) Grad: 10716.0283  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 3s (remain 10m 36s) Loss: 0.0000(0.0041) Grad: 34.1646  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 3m 25s (remain 10m 10s) Loss: 0.0011(0.0042) Grad: 3458.3455  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 3m 47s (remain 9m 46s) Loss: 0.0001(0.0041) Grad: 354.6604  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 10s (remain 9m 22s) Loss: 0.0007(0.0041) Grad: 2678.6125  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 4m 32s (remain 8m 58s) Loss: 0.0001(0.0040) Grad: 206.3695  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 4m 54s (remain 8m 34s) Loss: 0.0024(0.0040) Grad: 9377.1826  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 5m 16s (remain 8m 11s) Loss: 0.0018(0.0040) Grad: 2366.5278  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 5m 38s (remain 7m 47s) Loss: 0.0034(0.0040) Grad: 5022.6006  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 6m 0s (remain 7m 24s) Loss: 0.0106(0.0041) Grad: 81183.7188  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 6m 22s (remain 7m 1s) Loss: 0.0023(0.0040) Grad: 7687.6963  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 6m 45s (remain 6m 39s) Loss: 0.0000(0.0040) Grad: 17.9824  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 7m 7s (remain 6m 16s) Loss: 0.0150(0.0040) Grad: 11756.9102  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 7m 29s (remain 5m 53s) Loss: 0.0002(0.0040) Grad: 701.9904  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 7m 51s (remain 5m 30s) Loss: 0.0118(0.0040) Grad: 7129.2231  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 8m 13s (remain 5m 8s) Loss: 0.0088(0.0040) Grad: 14877.7109  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 8m 35s (remain 4m 45s) Loss: 0.0099(0.0040) Grad: 17670.9629  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 8m 58s (remain 4m 23s) Loss: 0.0001(0.0040) Grad: 320.8752  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 9m 20s (remain 4m 0s) Loss: 0.0014(0.0040) Grad: 5583.6680  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 9m 42s (remain 3m 38s) Loss: 0.0066(0.0040) Grad: 40812.2188  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 10m 4s (remain 3m 15s) Loss: 0.0001(0.0040) Grad: 147.1139  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 10m 26s (remain 2m 53s) Loss: 0.0135(0.0041) Grad: 10927.4834  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 10m 48s (remain 2m 30s) Loss: 0.0025(0.0041) Grad: 1981.5076  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 11m 11s (remain 2m 8s) Loss: 0.0000(0.0041) Grad: 3.0735  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 11m 33s (remain 1m 45s) Loss: 0.0045(0.0041) Grad: 3144.9517  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 11m 55s (remain 1m 23s) Loss: 0.0292(0.0041) Grad: 9813.2158  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 12m 17s (remain 1m 1s) Loss: 0.0000(0.0041) Grad: 63.9438  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 12m 39s (remain 0m 38s) Loss: 0.0005(0.0041) Grad: 2021.9977  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 13m 2s (remain 0m 16s) Loss: 0.0002(0.0041) Grad: 948.4675  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 13m 18s (remain 0m 0s) Loss: 0.0027(0.0041) Grad: 1901.7307  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 7s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0314(0.0065) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0066(0.0060) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0029(0.0056) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0002(0.0060) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0024(0.0055) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0036(0.0056) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0035(0.0063) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0000(0.0063) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0120(0.0064) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0147(0.0063) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0441(0.0060) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0000(0.0059) \n","Epoch 3 - avg_train_loss: 0.0041  avg_val_loss: 0.0059  time: 944s\n","Epoch 3 - Score: 0.8832\n","Epoch 3 - Save Best Score: 0.8832 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 30m 1s) Loss: 0.0051(0.0051) Grad: 23437.7734  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 25s (remain 14m 39s) Loss: 0.0000(0.0027) Grad: 140.9684  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 49s (remain 13m 57s) Loss: 0.0028(0.0028) Grad: 6735.2925  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 12s (remain 13m 4s) Loss: 0.0000(0.0027) Grad: 135.7279  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 34s (remain 12m 26s) Loss: 0.0005(0.0026) Grad: 2667.8608  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 1m 56s (remain 11m 54s) Loss: 0.0030(0.0028) Grad: 16561.4336  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 19s (remain 11m 28s) Loss: 0.0002(0.0027) Grad: 709.7558  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 2m 41s (remain 11m 4s) Loss: 0.0030(0.0029) Grad: 5760.0591  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 4s (remain 10m 40s) Loss: 0.0042(0.0030) Grad: 8067.1841  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 3m 27s (remain 10m 16s) Loss: 0.0000(0.0029) Grad: 10.8894  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 3m 50s (remain 9m 52s) Loss: 0.0001(0.0029) Grad: 458.4802  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 12s (remain 9m 27s) Loss: 0.0001(0.0030) Grad: 424.6995  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 4m 34s (remain 9m 3s) Loss: 0.0106(0.0030) Grad: 23449.5742  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 4m 57s (remain 8m 39s) Loss: 0.0001(0.0030) Grad: 585.8212  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 5m 19s (remain 8m 15s) Loss: 0.0011(0.0031) Grad: 5399.1133  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 5m 41s (remain 7m 52s) Loss: 0.0066(0.0031) Grad: 29660.7402  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 6m 3s (remain 7m 28s) Loss: 0.0017(0.0030) Grad: 14116.1982  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 6m 25s (remain 7m 5s) Loss: 0.0000(0.0031) Grad: 2.8399  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 6m 47s (remain 6m 41s) Loss: 0.0282(0.0031) Grad: 26625.1465  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 7m 9s (remain 6m 18s) Loss: 0.0040(0.0031) Grad: 10446.7998  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 7m 31s (remain 5m 55s) Loss: 0.0048(0.0031) Grad: 4247.9253  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 7m 53s (remain 5m 32s) Loss: 0.0001(0.0031) Grad: 360.3803  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 8m 16s (remain 5m 9s) Loss: 0.0011(0.0032) Grad: 3324.1521  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 8m 38s (remain 4m 46s) Loss: 0.0025(0.0032) Grad: 7006.7754  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 9m 0s (remain 4m 24s) Loss: 0.0025(0.0032) Grad: 13525.2529  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 9m 22s (remain 4m 1s) Loss: 0.0000(0.0032) Grad: 294.5819  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 9m 44s (remain 3m 38s) Loss: 0.0000(0.0032) Grad: 4.1163  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 10m 6s (remain 3m 16s) Loss: 0.0003(0.0032) Grad: 6002.5942  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 10m 28s (remain 2m 53s) Loss: 0.0255(0.0032) Grad: 39537.7695  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 10m 50s (remain 2m 31s) Loss: 0.0044(0.0032) Grad: 11065.0332  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 11m 12s (remain 2m 8s) Loss: 0.0031(0.0032) Grad: 17685.1367  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 11m 34s (remain 1m 46s) Loss: 0.0002(0.0033) Grad: 2661.4846  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 11m 56s (remain 1m 23s) Loss: 0.0000(0.0032) Grad: 167.7788  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 12m 18s (remain 1m 1s) Loss: 0.0001(0.0032) Grad: 531.1711  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 12m 40s (remain 0m 38s) Loss: 0.0068(0.0032) Grad: 18267.0098  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 13m 2s (remain 0m 16s) Loss: 0.0140(0.0032) Grad: 64827.4023  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 13m 18s (remain 0m 0s) Loss: 0.0067(0.0032) Grad: 12393.6035  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 11s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0478(0.0077) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0129(0.0077) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 32s) Loss: 0.0099(0.0073) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0001(0.0075) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0011(0.0069) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0065(0.0070) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0045(0.0076) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0000(0.0076) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0047(0.0077) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0240(0.0076) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0543(0.0072) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0000(0.0070) \n","Epoch 4 - avg_train_loss: 0.0032  avg_val_loss: 0.0070  time: 938s\n","Epoch 4 - Score: 0.8870\n","Epoch 4 - Save Best Score: 0.8870 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 31m 2s) Loss: 0.0124(0.0124) Grad: 23114.7461  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 25s (remain 14m 48s) Loss: 0.0008(0.0024) Grad: 4517.3115  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 49s (remain 13m 52s) Loss: 0.0011(0.0024) Grad: 2986.3701  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 11s (remain 12m 59s) Loss: 0.0157(0.0024) Grad: 73478.4844  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 33s (remain 12m 21s) Loss: 0.0000(0.0024) Grad: 195.8718  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 1m 55s (remain 11m 49s) Loss: 0.0000(0.0024) Grad: 1.1446  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 17s (remain 11m 21s) Loss: 0.0001(0.0024) Grad: 456.0834  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 2m 39s (remain 10m 54s) Loss: 0.0001(0.0024) Grad: 1952.0315  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 1s (remain 10m 28s) Loss: 0.0000(0.0024) Grad: 3.4362  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 3m 23s (remain 10m 4s) Loss: 0.0010(0.0023) Grad: 5022.0962  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 3m 45s (remain 9m 39s) Loss: 0.0000(0.0026) Grad: 1.6752  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 7s (remain 9m 16s) Loss: 0.0000(0.0025) Grad: 11.1738  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 4m 29s (remain 8m 53s) Loss: 0.0000(0.0025) Grad: 31.3686  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 4m 52s (remain 8m 31s) Loss: 0.0008(0.0026) Grad: 12896.0576  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 5m 15s (remain 8m 8s) Loss: 0.0098(0.0025) Grad: 15692.9912  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 5m 37s (remain 7m 45s) Loss: 0.0000(0.0025) Grad: 4.7771  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 5m 59s (remain 7m 23s) Loss: 0.0000(0.0025) Grad: 1.1276  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 6m 21s (remain 7m 0s) Loss: 0.0000(0.0026) Grad: 5.3592  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 6m 43s (remain 6m 37s) Loss: 0.0157(0.0025) Grad: 77508.2812  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 7m 5s (remain 6m 14s) Loss: 0.0000(0.0025) Grad: 39.7770  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 7m 27s (remain 5m 52s) Loss: 0.0012(0.0025) Grad: 24667.0508  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 7m 49s (remain 5m 29s) Loss: 0.0125(0.0024) Grad: 32512.6113  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 8m 11s (remain 5m 6s) Loss: 0.0002(0.0024) Grad: 1158.9625  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 8m 33s (remain 4m 44s) Loss: 0.0004(0.0024) Grad: 7977.5991  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 8m 55s (remain 4m 21s) Loss: 0.0000(0.0024) Grad: 5.8424  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 9m 17s (remain 3m 59s) Loss: 0.0000(0.0024) Grad: 140.8797  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 9m 39s (remain 3m 37s) Loss: 0.0000(0.0024) Grad: 2.6312  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 10m 1s (remain 3m 14s) Loss: 0.0004(0.0024) Grad: 6548.7124  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 10m 24s (remain 2m 52s) Loss: 0.0003(0.0024) Grad: 10000.2812  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 10m 46s (remain 2m 30s) Loss: 0.0000(0.0024) Grad: 4.2712  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 11m 8s (remain 2m 7s) Loss: 0.0000(0.0024) Grad: 1.7420  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 11m 30s (remain 1m 45s) Loss: 0.0002(0.0024) Grad: 3779.0771  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 11m 52s (remain 1m 23s) Loss: 0.0000(0.0024) Grad: 4.3725  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 12m 14s (remain 1m 0s) Loss: 0.0047(0.0025) Grad: 6779.2700  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 12m 36s (remain 0m 38s) Loss: 0.0019(0.0025) Grad: 3912.4937  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 12m 59s (remain 0m 16s) Loss: 0.0000(0.0025) Grad: 33.1564  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 13m 15s (remain 0m 0s) Loss: 0.0000(0.0025) Grad: 6.1180  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 1s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 55s) Loss: 0.0470(0.0088) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0111(0.0082) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 32s) Loss: 0.0038(0.0078) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0000(0.0082) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0004(0.0075) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0089(0.0076) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 51s) Loss: 0.0042(0.0083) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0000(0.0083) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0051(0.0084) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0280(0.0083) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0583(0.0079) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0000(0.0076) \n","Epoch 5 - avg_train_loss: 0.0025  avg_val_loss: 0.0076  time: 935s\n","Epoch 5 - Score: 0.8859\n","========== fold: 3 training ==========\n","Load weight from drive/MyDrive/00.kaggle/output/nbme-score-clinical-patient-notes/nbme-exp010/checkpoint-130170/pytorch_model.bin\n","Epoch: [1][0/3575] Elapsed 0m 0s (remain 39m 26s) Loss: 0.4564(0.4564) Grad: 255000.8125  LR: 0.000000  \n","Epoch: [1][100/3575] Elapsed 0m 22s (remain 13m 11s) Loss: 0.4012(0.4426) Grad: 58702.3945  LR: 0.000001  \n","Epoch: [1][200/3575] Elapsed 0m 45s (remain 12m 46s) Loss: 0.1636(0.3619) Grad: 27888.6348  LR: 0.000002  \n","Epoch: [1][300/3575] Elapsed 1m 8s (remain 12m 20s) Loss: 0.0285(0.2680) Grad: 1926.1106  LR: 0.000003  \n","Epoch: [1][400/3575] Elapsed 1m 30s (remain 11m 55s) Loss: 0.0190(0.2108) Grad: 2184.1230  LR: 0.000004  \n","Epoch: [1][500/3575] Elapsed 1m 52s (remain 11m 30s) Loss: 0.0624(0.1758) Grad: 5651.6997  LR: 0.000006  \n","Epoch: [1][600/3575] Elapsed 2m 14s (remain 11m 5s) Loss: 0.0134(0.1522) Grad: 1938.3398  LR: 0.000007  \n","Epoch: [1][700/3575] Elapsed 2m 36s (remain 10m 41s) Loss: 0.0045(0.1342) Grad: 671.2077  LR: 0.000008  \n","Epoch: [1][800/3575] Elapsed 2m 58s (remain 10m 18s) Loss: 0.0086(0.1198) Grad: 4356.4468  LR: 0.000009  \n","Epoch: [1][900/3575] Elapsed 3m 20s (remain 9m 55s) Loss: 0.0051(0.1080) Grad: 1252.5045  LR: 0.000010  \n","Epoch: [1][1000/3575] Elapsed 3m 42s (remain 9m 32s) Loss: 0.0010(0.0984) Grad: 725.4888  LR: 0.000011  \n","Epoch: [1][1100/3575] Elapsed 4m 4s (remain 9m 9s) Loss: 0.0116(0.0910) Grad: 3552.1628  LR: 0.000012  \n","Epoch: [1][1200/3575] Elapsed 4m 26s (remain 8m 47s) Loss: 0.0011(0.0844) Grad: 570.5518  LR: 0.000013  \n","Epoch: [1][1300/3575] Elapsed 4m 48s (remain 8m 25s) Loss: 0.0011(0.0788) Grad: 420.4547  LR: 0.000015  \n","Epoch: [1][1400/3575] Elapsed 5m 10s (remain 8m 2s) Loss: 0.0019(0.0738) Grad: 1703.5015  LR: 0.000016  \n","Epoch: [1][1500/3575] Elapsed 5m 32s (remain 7m 40s) Loss: 0.0471(0.0695) Grad: 15692.1396  LR: 0.000017  \n","Epoch: [1][1600/3575] Elapsed 5m 54s (remain 7m 17s) Loss: 0.0372(0.0658) Grad: 3681.3994  LR: 0.000018  \n","Epoch: [1][1700/3575] Elapsed 6m 17s (remain 6m 55s) Loss: 0.0577(0.0625) Grad: 18070.7773  LR: 0.000019  \n","Epoch: [1][1800/3575] Elapsed 6m 39s (remain 6m 33s) Loss: 0.0089(0.0596) Grad: 4135.1807  LR: 0.000020  \n","Epoch: [1][1900/3575] Elapsed 7m 1s (remain 6m 10s) Loss: 0.0033(0.0569) Grad: 1199.3071  LR: 0.000020  \n","Epoch: [1][2000/3575] Elapsed 7m 23s (remain 5m 48s) Loss: 0.0007(0.0544) Grad: 618.8143  LR: 0.000020  \n","Epoch: [1][2100/3575] Elapsed 7m 45s (remain 5m 26s) Loss: 0.0000(0.0523) Grad: 31.6887  LR: 0.000020  \n","Epoch: [1][2200/3575] Elapsed 8m 7s (remain 5m 4s) Loss: 0.0002(0.0503) Grad: 79.8717  LR: 0.000019  \n","Epoch: [1][2300/3575] Elapsed 8m 29s (remain 4m 42s) Loss: 0.0033(0.0485) Grad: 1718.8457  LR: 0.000019  \n","Epoch: [1][2400/3575] Elapsed 8m 51s (remain 4m 19s) Loss: 0.0022(0.0468) Grad: 502.3448  LR: 0.000019  \n","Epoch: [1][2500/3575] Elapsed 9m 13s (remain 3m 57s) Loss: 0.0001(0.0452) Grad: 28.3308  LR: 0.000019  \n","Epoch: [1][2600/3575] Elapsed 9m 35s (remain 3m 35s) Loss: 0.0076(0.0438) Grad: 852.1745  LR: 0.000019  \n","Epoch: [1][2700/3575] Elapsed 9m 57s (remain 3m 13s) Loss: 0.0294(0.0425) Grad: 8566.6768  LR: 0.000019  \n","Epoch: [1][2800/3575] Elapsed 10m 20s (remain 2m 51s) Loss: 0.0114(0.0412) Grad: 1144.6179  LR: 0.000019  \n","Epoch: [1][2900/3575] Elapsed 10m 41s (remain 2m 29s) Loss: 0.0020(0.0401) Grad: 842.8021  LR: 0.000019  \n","Epoch: [1][3000/3575] Elapsed 11m 4s (remain 2m 7s) Loss: 0.0310(0.0390) Grad: 4514.6436  LR: 0.000018  \n","Epoch: [1][3100/3575] Elapsed 11m 26s (remain 1m 44s) Loss: 0.0023(0.0380) Grad: 2225.3591  LR: 0.000018  \n","Epoch: [1][3200/3575] Elapsed 11m 48s (remain 1m 22s) Loss: 0.0000(0.0370) Grad: 11.4828  LR: 0.000018  \n","Epoch: [1][3300/3575] Elapsed 12m 10s (remain 1m 0s) Loss: 0.0015(0.0361) Grad: 1073.1008  LR: 0.000018  \n","Epoch: [1][3400/3575] Elapsed 12m 32s (remain 0m 38s) Loss: 0.0018(0.0352) Grad: 653.0560  LR: 0.000018  \n","Epoch: [1][3500/3575] Elapsed 12m 54s (remain 0m 16s) Loss: 0.0010(0.0343) Grad: 385.0436  LR: 0.000018  \n","Epoch: [1][3574/3575] Elapsed 13m 10s (remain 0m 0s) Loss: 0.0033(0.0338) Grad: 787.6115  LR: 0.000018  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 10s) Loss: 0.0008(0.0008) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 56s) Loss: 0.0288(0.0046) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 43s) Loss: 0.0084(0.0049) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 32s) Loss: 0.0032(0.0051) \n","EVAL: [400/1192] Elapsed 0m 41s (remain 1m 22s) Loss: 0.0001(0.0050) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 11s) Loss: 0.0234(0.0049) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0039(0.0051) \n","EVAL: [700/1192] Elapsed 1m 12s (remain 0m 50s) Loss: 0.0023(0.0057) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0130(0.0057) \n","EVAL: [900/1192] Elapsed 1m 33s (remain 0m 30s) Loss: 0.0067(0.0062) \n","EVAL: [1000/1192] Elapsed 1m 43s (remain 0m 19s) Loss: 0.0008(0.0060) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0128(0.0058) \n","EVAL: [1191/1192] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0003(0.0057) \n","Epoch 1 - avg_train_loss: 0.0338  avg_val_loss: 0.0057  time: 920s\n","Epoch 1 - Score: 0.8617\n","Epoch 1 - Save Best Score: 0.8617 Model\n","Epoch: [2][0/3575] Elapsed 0m 0s (remain 35m 1s) Loss: 0.0062(0.0062) Grad: 12068.7979  LR: 0.000018  \n","Epoch: [2][100/3575] Elapsed 0m 26s (remain 15m 6s) Loss: 0.0062(0.0060) Grad: 19664.3711  LR: 0.000018  \n","Epoch: [2][200/3575] Elapsed 0m 50s (remain 14m 4s) Loss: 0.0002(0.0055) Grad: 709.3712  LR: 0.000018  \n","Epoch: [2][300/3575] Elapsed 1m 12s (remain 13m 8s) Loss: 0.0070(0.0057) Grad: 22755.2344  LR: 0.000017  \n","Epoch: [2][400/3575] Elapsed 1m 34s (remain 12m 31s) Loss: 0.0071(0.0055) Grad: 16712.1172  LR: 0.000017  \n","Epoch: [2][500/3575] Elapsed 1m 57s (remain 11m 58s) Loss: 0.0014(0.0054) Grad: 4670.6182  LR: 0.000017  \n","Epoch: [2][600/3575] Elapsed 2m 19s (remain 11m 28s) Loss: 0.0059(0.0053) Grad: 12894.7510  LR: 0.000017  \n","Epoch: [2][700/3575] Elapsed 2m 41s (remain 11m 1s) Loss: 0.0048(0.0051) Grad: 9146.6729  LR: 0.000017  \n","Epoch: [2][800/3575] Elapsed 3m 3s (remain 10m 35s) Loss: 0.0545(0.0053) Grad: 159455.9531  LR: 0.000017  \n","Epoch: [2][900/3575] Elapsed 3m 25s (remain 10m 10s) Loss: 0.0000(0.0053) Grad: 19.4481  LR: 0.000017  \n","Epoch: [2][1000/3575] Elapsed 3m 47s (remain 9m 45s) Loss: 0.0020(0.0053) Grad: 4753.9531  LR: 0.000017  \n","Epoch: [2][1100/3575] Elapsed 4m 9s (remain 9m 21s) Loss: 0.0000(0.0053) Grad: 155.2938  LR: 0.000016  \n","Epoch: [2][1200/3575] Elapsed 4m 31s (remain 8m 57s) Loss: 0.0129(0.0051) Grad: 18009.0645  LR: 0.000016  \n","Epoch: [2][1300/3575] Elapsed 4m 53s (remain 8m 33s) Loss: 0.0021(0.0052) Grad: 9213.3262  LR: 0.000016  \n","Epoch: [2][1400/3575] Elapsed 5m 16s (remain 8m 10s) Loss: 0.0004(0.0052) Grad: 1590.0515  LR: 0.000016  \n","Epoch: [2][1500/3575] Elapsed 5m 38s (remain 7m 47s) Loss: 0.0001(0.0052) Grad: 317.1921  LR: 0.000016  \n","Epoch: [2][1600/3575] Elapsed 6m 0s (remain 7m 24s) Loss: 0.0212(0.0051) Grad: 23967.4043  LR: 0.000016  \n","Epoch: [2][1700/3575] Elapsed 6m 22s (remain 7m 1s) Loss: 0.0031(0.0052) Grad: 11229.2598  LR: 0.000016  \n","Epoch: [2][1800/3575] Elapsed 6m 44s (remain 6m 38s) Loss: 0.0000(0.0052) Grad: 33.1874  LR: 0.000016  \n","Epoch: [2][1900/3575] Elapsed 7m 6s (remain 6m 15s) Loss: 0.0000(0.0051) Grad: 48.4085  LR: 0.000015  \n","Epoch: [2][2000/3575] Elapsed 7m 29s (remain 5m 53s) Loss: 0.0113(0.0052) Grad: 13554.6943  LR: 0.000015  \n","Epoch: [2][2100/3575] Elapsed 7m 51s (remain 5m 30s) Loss: 0.0000(0.0051) Grad: 45.0462  LR: 0.000015  \n","Epoch: [2][2200/3575] Elapsed 8m 13s (remain 5m 8s) Loss: 0.0005(0.0051) Grad: 2305.9185  LR: 0.000015  \n","Epoch: [2][2300/3575] Elapsed 8m 36s (remain 4m 46s) Loss: 0.0031(0.0051) Grad: 15416.2227  LR: 0.000015  \n","Epoch: [2][2400/3575] Elapsed 9m 0s (remain 4m 24s) Loss: 0.0000(0.0051) Grad: 21.7816  LR: 0.000015  \n","Epoch: [2][2500/3575] Elapsed 9m 23s (remain 4m 2s) Loss: 0.0424(0.0052) Grad: 47827.0977  LR: 0.000015  \n","Epoch: [2][2600/3575] Elapsed 9m 47s (remain 3m 39s) Loss: 0.0001(0.0052) Grad: 257.0591  LR: 0.000015  \n","Epoch: [2][2700/3575] Elapsed 10m 11s (remain 3m 17s) Loss: 0.0012(0.0053) Grad: 7122.2461  LR: 0.000014  \n","Epoch: [2][2800/3575] Elapsed 10m 34s (remain 2m 55s) Loss: 0.0619(0.0054) Grad: 68697.8750  LR: 0.000014  \n","Epoch: [2][2900/3575] Elapsed 10m 57s (remain 2m 32s) Loss: 0.0449(0.0054) Grad: 46306.1133  LR: 0.000014  \n","Epoch: [2][3000/3575] Elapsed 11m 19s (remain 2m 10s) Loss: 0.0071(0.0054) Grad: 8917.9512  LR: 0.000014  \n","Epoch: [2][3100/3575] Elapsed 11m 42s (remain 1m 47s) Loss: 0.0074(0.0054) Grad: 17620.2070  LR: 0.000014  \n","Epoch: [2][3200/3575] Elapsed 12m 5s (remain 1m 24s) Loss: 0.0052(0.0054) Grad: 8600.7061  LR: 0.000014  \n","Epoch: [2][3300/3575] Elapsed 12m 28s (remain 1m 2s) Loss: 0.0253(0.0053) Grad: 17424.8320  LR: 0.000014  \n","Epoch: [2][3400/3575] Elapsed 12m 50s (remain 0m 39s) Loss: 0.0001(0.0054) Grad: 1575.4639  LR: 0.000014  \n","Epoch: [2][3500/3575] Elapsed 13m 14s (remain 0m 16s) Loss: 0.0018(0.0053) Grad: 10174.3291  LR: 0.000013  \n","Epoch: [2][3574/3575] Elapsed 13m 32s (remain 0m 0s) Loss: 0.0005(0.0053) Grad: 3888.7234  LR: 0.000013  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 49s) Loss: 0.0004(0.0004) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 56s) Loss: 0.0283(0.0051) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 44s) Loss: 0.0063(0.0049) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0032(0.0057) \n","EVAL: [400/1192] Elapsed 0m 42s (remain 1m 23s) Loss: 0.0000(0.0055) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0184(0.0052) \n","EVAL: [600/1192] Elapsed 1m 3s (remain 1m 1s) Loss: 0.0039(0.0056) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0024(0.0062) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0044(0.0062) \n","EVAL: [900/1192] Elapsed 1m 34s (remain 0m 30s) Loss: 0.0056(0.0063) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0008(0.0062) \n","EVAL: [1100/1192] Elapsed 1m 55s (remain 0m 9s) Loss: 0.0287(0.0060) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0000(0.0059) \n","Epoch 2 - avg_train_loss: 0.0053  avg_val_loss: 0.0059  time: 943s\n","Epoch 2 - Score: 0.8792\n","Epoch 2 - Save Best Score: 0.8792 Model\n","Epoch: [3][0/3575] Elapsed 0m 0s (remain 35m 17s) Loss: 0.0004(0.0004) Grad: 1904.5389  LR: 0.000013  \n","Epoch: [3][100/3575] Elapsed 0m 29s (remain 16m 40s) Loss: 0.0013(0.0045) Grad: 9905.9258  LR: 0.000013  \n","Epoch: [3][200/3575] Elapsed 0m 54s (remain 15m 19s) Loss: 0.0001(0.0040) Grad: 703.9172  LR: 0.000013  \n","Epoch: [3][300/3575] Elapsed 1m 19s (remain 14m 20s) Loss: 0.0293(0.0043) Grad: 29478.7109  LR: 0.000013  \n","Epoch: [3][400/3575] Elapsed 1m 43s (remain 13m 38s) Loss: 0.0062(0.0043) Grad: 36058.7773  LR: 0.000013  \n","Epoch: [3][500/3575] Elapsed 2m 7s (remain 12m 59s) Loss: 0.0089(0.0041) Grad: 72959.8203  LR: 0.000013  \n","Epoch: [3][600/3575] Elapsed 2m 31s (remain 12m 30s) Loss: 0.0000(0.0042) Grad: 33.4565  LR: 0.000013  \n","Epoch: [3][700/3575] Elapsed 2m 55s (remain 12m 0s) Loss: 0.0000(0.0041) Grad: 64.6464  LR: 0.000012  \n","Epoch: [3][800/3575] Elapsed 3m 19s (remain 11m 31s) Loss: 0.0004(0.0041) Grad: 2563.6299  LR: 0.000012  \n","Epoch: [3][900/3575] Elapsed 3m 43s (remain 11m 2s) Loss: 0.0013(0.0043) Grad: 5219.9424  LR: 0.000012  \n","Epoch: [3][1000/3575] Elapsed 4m 7s (remain 10m 37s) Loss: 0.0007(0.0041) Grad: 5194.8765  LR: 0.000012  \n","Epoch: [3][1100/3575] Elapsed 4m 32s (remain 10m 11s) Loss: 0.0262(0.0040) Grad: 134024.3594  LR: 0.000012  \n","Epoch: [3][1200/3575] Elapsed 4m 56s (remain 9m 46s) Loss: 0.0045(0.0040) Grad: 5824.4678  LR: 0.000012  \n","Epoch: [3][1300/3575] Elapsed 5m 20s (remain 9m 20s) Loss: 0.0023(0.0041) Grad: 4156.5513  LR: 0.000012  \n","Epoch: [3][1400/3575] Elapsed 5m 45s (remain 8m 55s) Loss: 0.0000(0.0040) Grad: 7.7037  LR: 0.000012  \n","Epoch: [3][1500/3575] Elapsed 6m 8s (remain 8m 29s) Loss: 0.0015(0.0039) Grad: 3005.5747  LR: 0.000011  \n","Epoch: [3][1600/3575] Elapsed 6m 32s (remain 8m 4s) Loss: 0.0057(0.0040) Grad: 7069.9131  LR: 0.000011  \n","Epoch: [3][1700/3575] Elapsed 6m 56s (remain 7m 39s) Loss: 0.0104(0.0040) Grad: 6835.6030  LR: 0.000011  \n","Epoch: [3][1800/3575] Elapsed 7m 21s (remain 7m 14s) Loss: 0.0001(0.0040) Grad: 549.8965  LR: 0.000011  \n","Epoch: [3][1900/3575] Elapsed 7m 45s (remain 6m 49s) Loss: 0.0048(0.0041) Grad: 4112.2222  LR: 0.000011  \n","Epoch: [3][2000/3575] Elapsed 8m 8s (remain 6m 24s) Loss: 0.0058(0.0041) Grad: 20708.6387  LR: 0.000011  \n","Epoch: [3][2100/3575] Elapsed 8m 33s (remain 5m 59s) Loss: 0.0000(0.0041) Grad: 7.6454  LR: 0.000011  \n","Epoch: [3][2200/3575] Elapsed 8m 56s (remain 5m 35s) Loss: 0.0017(0.0041) Grad: 3549.6030  LR: 0.000011  \n","Epoch: [3][2300/3575] Elapsed 9m 20s (remain 5m 10s) Loss: 0.0042(0.0041) Grad: 8232.0449  LR: 0.000010  \n","Epoch: [3][2400/3575] Elapsed 9m 44s (remain 4m 45s) Loss: 0.0011(0.0041) Grad: 4137.0171  LR: 0.000010  \n","Epoch: [3][2500/3575] Elapsed 10m 8s (remain 4m 21s) Loss: 0.0004(0.0041) Grad: 744.5929  LR: 0.000010  \n","Epoch: [3][2600/3575] Elapsed 10m 32s (remain 3m 56s) Loss: 0.0015(0.0041) Grad: 3353.1375  LR: 0.000010  \n","Epoch: [3][2700/3575] Elapsed 10m 56s (remain 3m 32s) Loss: 0.0001(0.0041) Grad: 88.0489  LR: 0.000010  \n","Epoch: [3][2800/3575] Elapsed 11m 20s (remain 3m 7s) Loss: 0.0000(0.0041) Grad: 33.8439  LR: 0.000010  \n","Epoch: [3][2900/3575] Elapsed 11m 44s (remain 2m 43s) Loss: 0.0001(0.0041) Grad: 178.4260  LR: 0.000010  \n","Epoch: [3][3000/3575] Elapsed 12m 8s (remain 2m 19s) Loss: 0.0000(0.0042) Grad: 114.8656  LR: 0.000010  \n","Epoch: [3][3100/3575] Elapsed 12m 32s (remain 1m 55s) Loss: 0.0010(0.0042) Grad: 1101.7520  LR: 0.000009  \n","Epoch: [3][3200/3575] Elapsed 12m 56s (remain 1m 30s) Loss: 0.0019(0.0042) Grad: 3454.4570  LR: 0.000009  \n","Epoch: [3][3300/3575] Elapsed 13m 21s (remain 1m 6s) Loss: 0.0021(0.0042) Grad: 4531.7998  LR: 0.000009  \n","Epoch: [3][3400/3575] Elapsed 13m 45s (remain 0m 42s) Loss: 0.0000(0.0042) Grad: 13.8848  LR: 0.000009  \n","Epoch: [3][3500/3575] Elapsed 14m 9s (remain 0m 17s) Loss: 0.0094(0.0042) Grad: 26743.3438  LR: 0.000009  \n","Epoch: [3][3574/3575] Elapsed 14m 27s (remain 0m 0s) Loss: 0.0017(0.0041) Grad: 12081.8818  LR: 0.000009  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 8m 10s) Loss: 0.0003(0.0003) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 56s) Loss: 0.0475(0.0058) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 44s) Loss: 0.0088(0.0054) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0063(0.0057) \n","EVAL: [400/1192] Elapsed 0m 42s (remain 1m 23s) Loss: 0.0000(0.0054) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0401(0.0053) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0051(0.0056) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0023(0.0061) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0056(0.0061) \n","EVAL: [900/1192] Elapsed 1m 34s (remain 0m 30s) Loss: 0.0030(0.0065) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0064) \n","EVAL: [1100/1192] Elapsed 1m 55s (remain 0m 9s) Loss: 0.0184(0.0062) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0000(0.0061) \n","Epoch 3 - avg_train_loss: 0.0041  avg_val_loss: 0.0061  time: 997s\n","Epoch 3 - Score: 0.8881\n","Epoch 3 - Save Best Score: 0.8881 Model\n","Epoch: [4][0/3575] Elapsed 0m 0s (remain 33m 37s) Loss: 0.0000(0.0000) Grad: 1003.8192  LR: 0.000009  \n","Epoch: [4][100/3575] Elapsed 0m 30s (remain 17m 27s) Loss: 0.0005(0.0037) Grad: 4737.4927  LR: 0.000009  \n","Epoch: [4][200/3575] Elapsed 0m 55s (remain 15m 28s) Loss: 0.0000(0.0033) Grad: 17.4063  LR: 0.000009  \n","Epoch: [4][300/3575] Elapsed 1m 19s (remain 14m 26s) Loss: 0.0001(0.0032) Grad: 946.7341  LR: 0.000009  \n","Epoch: [4][400/3575] Elapsed 1m 44s (remain 13m 43s) Loss: 0.0000(0.0031) Grad: 27.0588  LR: 0.000008  \n","Epoch: [4][500/3575] Elapsed 2m 8s (remain 13m 7s) Loss: 0.0000(0.0031) Grad: 41.0175  LR: 0.000008  \n","Epoch: [4][600/3575] Elapsed 2m 32s (remain 12m 35s) Loss: 0.0015(0.0033) Grad: 6816.1128  LR: 0.000008  \n","Epoch: [4][700/3575] Elapsed 2m 56s (remain 12m 4s) Loss: 0.0023(0.0032) Grad: 6717.4282  LR: 0.000008  \n","Epoch: [4][800/3575] Elapsed 3m 21s (remain 11m 36s) Loss: 0.0034(0.0033) Grad: 10677.5078  LR: 0.000008  \n","Epoch: [4][900/3575] Elapsed 3m 45s (remain 11m 8s) Loss: 0.0001(0.0035) Grad: 336.7156  LR: 0.000008  \n","Epoch: [4][1000/3575] Elapsed 4m 9s (remain 10m 41s) Loss: 0.0004(0.0034) Grad: 5234.5708  LR: 0.000008  \n","Epoch: [4][1100/3575] Elapsed 4m 33s (remain 10m 14s) Loss: 0.0002(0.0033) Grad: 995.9315  LR: 0.000008  \n","Epoch: [4][1200/3575] Elapsed 4m 57s (remain 9m 48s) Loss: 0.0081(0.0033) Grad: 29757.3691  LR: 0.000007  \n","Epoch: [4][1300/3575] Elapsed 5m 22s (remain 9m 23s) Loss: 0.0548(0.0034) Grad: 522327.4688  LR: 0.000007  \n","Epoch: [4][1400/3575] Elapsed 5m 46s (remain 8m 57s) Loss: 0.0169(0.0033) Grad: 27550.7207  LR: 0.000007  \n","Epoch: [4][1500/3575] Elapsed 6m 10s (remain 8m 32s) Loss: 0.0000(0.0032) Grad: 467.3620  LR: 0.000007  \n","Epoch: [4][1600/3575] Elapsed 6m 35s (remain 8m 7s) Loss: 0.0000(0.0032) Grad: 299.7426  LR: 0.000007  \n","Epoch: [4][1700/3575] Elapsed 6m 59s (remain 7m 41s) Loss: 0.0000(0.0032) Grad: 516.4633  LR: 0.000007  \n","Epoch: [4][1800/3575] Elapsed 7m 23s (remain 7m 16s) Loss: 0.0001(0.0032) Grad: 681.8254  LR: 0.000007  \n","Epoch: [4][1900/3575] Elapsed 7m 47s (remain 6m 51s) Loss: 0.0004(0.0032) Grad: 9729.9629  LR: 0.000007  \n","Epoch: [4][2000/3575] Elapsed 8m 11s (remain 6m 26s) Loss: 0.0000(0.0033) Grad: 5.8662  LR: 0.000006  \n","Epoch: [4][2100/3575] Elapsed 8m 35s (remain 6m 1s) Loss: 0.0001(0.0033) Grad: 347.9149  LR: 0.000006  \n","Epoch: [4][2200/3575] Elapsed 8m 59s (remain 5m 36s) Loss: 0.0000(0.0033) Grad: 48.9570  LR: 0.000006  \n","Epoch: [4][2300/3575] Elapsed 9m 23s (remain 5m 12s) Loss: 0.0000(0.0033) Grad: 42.6676  LR: 0.000006  \n","Epoch: [4][2400/3575] Elapsed 9m 47s (remain 4m 47s) Loss: 0.0000(0.0033) Grad: 318.8290  LR: 0.000006  \n","Epoch: [4][2500/3575] Elapsed 10m 11s (remain 4m 22s) Loss: 0.0000(0.0032) Grad: 11.6453  LR: 0.000006  \n","Epoch: [4][2600/3575] Elapsed 10m 35s (remain 3m 57s) Loss: 0.0020(0.0033) Grad: 8069.3809  LR: 0.000006  \n","Epoch: [4][2700/3575] Elapsed 10m 59s (remain 3m 33s) Loss: 0.0001(0.0033) Grad: 573.3132  LR: 0.000006  \n","Epoch: [4][2800/3575] Elapsed 11m 23s (remain 3m 8s) Loss: 0.0000(0.0033) Grad: 20.0690  LR: 0.000005  \n","Epoch: [4][2900/3575] Elapsed 11m 46s (remain 2m 44s) Loss: 0.0000(0.0033) Grad: 14.3561  LR: 0.000005  \n","Epoch: [4][3000/3575] Elapsed 12m 10s (remain 2m 19s) Loss: 0.0001(0.0033) Grad: 967.1534  LR: 0.000005  \n","Epoch: [4][3100/3575] Elapsed 12m 34s (remain 1m 55s) Loss: 0.0116(0.0033) Grad: 8101.3521  LR: 0.000005  \n","Epoch: [4][3200/3575] Elapsed 12m 58s (remain 1m 30s) Loss: 0.0000(0.0034) Grad: 166.4953  LR: 0.000005  \n","Epoch: [4][3300/3575] Elapsed 13m 22s (remain 1m 6s) Loss: 0.0000(0.0034) Grad: 42.0688  LR: 0.000005  \n","Epoch: [4][3400/3575] Elapsed 13m 46s (remain 0m 42s) Loss: 0.0000(0.0034) Grad: 48.0726  LR: 0.000005  \n","Epoch: [4][3500/3575] Elapsed 14m 10s (remain 0m 17s) Loss: 0.0006(0.0033) Grad: 5934.6147  LR: 0.000005  \n","Epoch: [4][3574/3575] Elapsed 14m 28s (remain 0m 0s) Loss: 0.0037(0.0033) Grad: 7642.1494  LR: 0.000004  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 54s) Loss: 0.0001(0.0001) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 56s) Loss: 0.0432(0.0066) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 44s) Loss: 0.0126(0.0060) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0088(0.0062) \n","EVAL: [400/1192] Elapsed 0m 42s (remain 1m 23s) Loss: 0.0000(0.0061) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0373(0.0060) \n","EVAL: [600/1192] Elapsed 1m 3s (remain 1m 1s) Loss: 0.0056(0.0063) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0028(0.0068) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0064(0.0068) \n","EVAL: [900/1192] Elapsed 1m 34s (remain 0m 30s) Loss: 0.0047(0.0071) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0069) \n","EVAL: [1100/1192] Elapsed 1m 55s (remain 0m 9s) Loss: 0.0184(0.0067) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0000(0.0066) \n","Epoch 4 - avg_train_loss: 0.0033  avg_val_loss: 0.0066  time: 999s\n","Epoch 4 - Score: 0.8892\n","Epoch 4 - Save Best Score: 0.8892 Model\n","Epoch: [5][0/3575] Elapsed 0m 0s (remain 34m 42s) Loss: 0.0002(0.0002) Grad: 2303.8271  LR: 0.000004  \n","Epoch: [5][100/3575] Elapsed 0m 29s (remain 17m 1s) Loss: 0.0013(0.0023) Grad: 17101.8418  LR: 0.000004  \n","Epoch: [5][200/3575] Elapsed 0m 54s (remain 15m 16s) Loss: 0.0001(0.0027) Grad: 861.8970  LR: 0.000004  \n","Epoch: [5][300/3575] Elapsed 1m 18s (remain 14m 15s) Loss: 0.0000(0.0026) Grad: 26.5124  LR: 0.000004  \n","Epoch: [5][400/3575] Elapsed 1m 41s (remain 13m 25s) Loss: 0.0003(0.0027) Grad: 11948.0918  LR: 0.000004  \n","Epoch: [5][500/3575] Elapsed 2m 5s (remain 12m 52s) Loss: 0.0000(0.0029) Grad: 19.7152  LR: 0.000004  \n","Epoch: [5][600/3575] Elapsed 2m 30s (remain 12m 22s) Loss: 0.0016(0.0028) Grad: 17348.5332  LR: 0.000004  \n","Epoch: [5][700/3575] Elapsed 2m 54s (remain 11m 54s) Loss: 0.0049(0.0028) Grad: 19060.6328  LR: 0.000004  \n","Epoch: [5][800/3575] Elapsed 3m 18s (remain 11m 26s) Loss: 0.0000(0.0027) Grad: 7.2179  LR: 0.000003  \n","Epoch: [5][900/3575] Elapsed 3m 42s (remain 10m 59s) Loss: 0.0000(0.0027) Grad: 188.4200  LR: 0.000003  \n","Epoch: [5][1000/3575] Elapsed 4m 6s (remain 10m 33s) Loss: 0.0091(0.0026) Grad: 27569.1230  LR: 0.000003  \n","Epoch: [5][1100/3575] Elapsed 4m 29s (remain 10m 6s) Loss: 0.0001(0.0026) Grad: 321.7552  LR: 0.000003  \n","Epoch: [5][1200/3575] Elapsed 4m 53s (remain 9m 40s) Loss: 0.0001(0.0025) Grad: 319.0205  LR: 0.000003  \n","Epoch: [5][1300/3575] Elapsed 5m 17s (remain 9m 15s) Loss: 0.0033(0.0026) Grad: 34663.8086  LR: 0.000003  \n","Epoch: [5][1400/3575] Elapsed 5m 41s (remain 8m 50s) Loss: 0.0024(0.0026) Grad: 48971.8359  LR: 0.000003  \n","Epoch: [5][1500/3575] Elapsed 6m 5s (remain 8m 25s) Loss: 0.0000(0.0025) Grad: 68.6529  LR: 0.000003  \n","Epoch: [5][1600/3575] Elapsed 6m 29s (remain 8m 0s) Loss: 0.0000(0.0027) Grad: 485.3216  LR: 0.000002  \n","Epoch: [5][1700/3575] Elapsed 6m 53s (remain 7m 35s) Loss: 0.0001(0.0027) Grad: 715.8087  LR: 0.000002  \n","Epoch: [5][1800/3575] Elapsed 7m 17s (remain 7m 11s) Loss: 0.0195(0.0027) Grad: 21775.3555  LR: 0.000002  \n","Epoch: [5][1900/3575] Elapsed 7m 41s (remain 6m 46s) Loss: 0.0000(0.0026) Grad: 73.8441  LR: 0.000002  \n","Epoch: [5][2000/3575] Elapsed 8m 4s (remain 6m 21s) Loss: 0.0001(0.0026) Grad: 1524.6044  LR: 0.000002  \n","Epoch: [5][2100/3575] Elapsed 8m 27s (remain 5m 56s) Loss: 0.0000(0.0027) Grad: 39.1980  LR: 0.000002  \n","Epoch: [5][2200/3575] Elapsed 8m 51s (remain 5m 31s) Loss: 0.0002(0.0027) Grad: 3081.5664  LR: 0.000002  \n","Epoch: [5][2300/3575] Elapsed 9m 14s (remain 5m 6s) Loss: 0.0001(0.0027) Grad: 860.0244  LR: 0.000002  \n","Epoch: [5][2400/3575] Elapsed 9m 37s (remain 4m 42s) Loss: 0.0000(0.0027) Grad: 60.7300  LR: 0.000001  \n","Epoch: [5][2500/3575] Elapsed 10m 1s (remain 4m 18s) Loss: 0.0006(0.0027) Grad: 5344.1196  LR: 0.000001  \n","Epoch: [5][2600/3575] Elapsed 10m 25s (remain 3m 54s) Loss: 0.0000(0.0027) Grad: 156.0460  LR: 0.000001  \n","Epoch: [5][2700/3575] Elapsed 10m 49s (remain 3m 30s) Loss: 0.0000(0.0027) Grad: 15.2135  LR: 0.000001  \n","Epoch: [5][2800/3575] Elapsed 11m 12s (remain 3m 5s) Loss: 0.0001(0.0027) Grad: 570.1804  LR: 0.000001  \n","Epoch: [5][2900/3575] Elapsed 11m 37s (remain 2m 41s) Loss: 0.0000(0.0026) Grad: 59.5518  LR: 0.000001  \n","Epoch: [5][3000/3575] Elapsed 12m 1s (remain 2m 17s) Loss: 0.0000(0.0026) Grad: 1.5981  LR: 0.000001  \n","Epoch: [5][3100/3575] Elapsed 12m 25s (remain 1m 53s) Loss: 0.0002(0.0026) Grad: 720.3626  LR: 0.000001  \n","Epoch: [5][3200/3575] Elapsed 12m 49s (remain 1m 29s) Loss: 0.0000(0.0027) Grad: 4.0772  LR: 0.000000  \n","Epoch: [5][3300/3575] Elapsed 13m 12s (remain 1m 5s) Loss: 0.0000(0.0027) Grad: 529.6226  LR: 0.000000  \n","Epoch: [5][3400/3575] Elapsed 13m 35s (remain 0m 41s) Loss: 0.0000(0.0027) Grad: 17.5255  LR: 0.000000  \n","Epoch: [5][3500/3575] Elapsed 13m 59s (remain 0m 17s) Loss: 0.0000(0.0027) Grad: 71.0971  LR: 0.000000  \n","Epoch: [5][3574/3575] Elapsed 14m 17s (remain 0m 0s) Loss: 0.0093(0.0027) Grad: 29280.2969  LR: 0.000000  \n","EVAL: [0/1192] Elapsed 0m 0s (remain 7m 47s) Loss: 0.0000(0.0000) \n","EVAL: [100/1192] Elapsed 0m 10s (remain 1m 56s) Loss: 0.0583(0.0076) \n","EVAL: [200/1192] Elapsed 0m 21s (remain 1m 44s) Loss: 0.0102(0.0067) \n","EVAL: [300/1192] Elapsed 0m 31s (remain 1m 33s) Loss: 0.0104(0.0072) \n","EVAL: [400/1192] Elapsed 0m 42s (remain 1m 23s) Loss: 0.0000(0.0070) \n","EVAL: [500/1192] Elapsed 0m 52s (remain 1m 12s) Loss: 0.0479(0.0069) \n","EVAL: [600/1192] Elapsed 1m 2s (remain 1m 1s) Loss: 0.0058(0.0073) \n","EVAL: [700/1192] Elapsed 1m 13s (remain 0m 51s) Loss: 0.0029(0.0079) \n","EVAL: [800/1192] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0050(0.0079) \n","EVAL: [900/1192] Elapsed 1m 34s (remain 0m 30s) Loss: 0.0029(0.0083) \n","EVAL: [1000/1192] Elapsed 1m 44s (remain 0m 19s) Loss: 0.0000(0.0080) \n","EVAL: [1100/1192] Elapsed 1m 54s (remain 0m 9s) Loss: 0.0168(0.0078) \n","EVAL: [1191/1192] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0000(0.0077) \n","Epoch 5 - avg_train_loss: 0.0027  avg_val_loss: 0.0077  time: 987s\n","Epoch 5 - Score: 0.8887\n","Best thres: 0.5, Score: 0.8848\n","Best thres: 0.51953125, Score: 0.8849\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b0526921b843c5acd2ba088cf70d87"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2205c256d19949309829b84941f91ba2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b135c75a4b14404a95c71736efb071f5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n","    close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Load weight from pretrained\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"nbme-exp064.ipynb","provenance":[{"file_id":"10yG4L3_nzpdL2CDwqxa9r-KWq6jYkWfl","timestamp":1648219695953}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":641.572862,"end_time":"2022-02-27T11:39:50.972497","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-02-27T11:29:09.399635","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"40cb84a2ca2b48d5aebdb7c41e1edd89":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93f6157a0c91436da57c03d3b31d7aa8","IPY_MODEL_8179affb703b4c7dacee125d49de8e5f","IPY_MODEL_24fb8ac2ffb3451e952cf4cb993c0600"],"layout":"IPY_MODEL_11bc67030cce443c978a49e383146429"}},"93f6157a0c91436da57c03d3b31d7aa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_169d0af852bc46c4861b6f8a9310d28e","placeholder":"​","style":"IPY_MODEL_aad56fa4957248749ebecd00b903897f","value":"Downloading: 100%"}},"8179affb703b4c7dacee125d49de8e5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c76da5d96b447a592af3faa6f434338","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b5c5dded4874cb8813455f21e26e8d5","value":52}},"24fb8ac2ffb3451e952cf4cb993c0600":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ffe5f21175143f2be172191b03506e2","placeholder":"​","style":"IPY_MODEL_a787a271e3e14460873279d63475859c","value":" 52.0/52.0 [00:00&lt;00:00, 1.42kB/s]"}},"11bc67030cce443c978a49e383146429":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"169d0af852bc46c4861b6f8a9310d28e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad56fa4957248749ebecd00b903897f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c76da5d96b447a592af3faa6f434338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b5c5dded4874cb8813455f21e26e8d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ffe5f21175143f2be172191b03506e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a787a271e3e14460873279d63475859c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee2191179211460aa37b3a2c6d444e06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ce07b570870428fa44bab0f9481d6af","IPY_MODEL_cc3cfc9ae49a4bffb37a978118670e2c","IPY_MODEL_4c68825decbd40ddb868a0f01a475d93"],"layout":"IPY_MODEL_b0ee0830acb34818aad3e72c2071b72d"}},"9ce07b570870428fa44bab0f9481d6af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07a40a8350aa439585de58c837d32e91","placeholder":"​","style":"IPY_MODEL_946e89ded7b5490ebaac9c50577aa160","value":"Downloading: 100%"}},"cc3cfc9ae49a4bffb37a978118670e2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b83b30864ec049b0b5ad97d22f892332","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7b385705f874b72a3a58b088db069cb","value":475}},"4c68825decbd40ddb868a0f01a475d93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_859e8f1081614738aba96d83c515ccaa","placeholder":"​","style":"IPY_MODEL_1d87c4caf48a47c1a188294ecfc0d369","value":" 475/475 [00:00&lt;00:00, 13.4kB/s]"}},"b0ee0830acb34818aad3e72c2071b72d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07a40a8350aa439585de58c837d32e91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"946e89ded7b5490ebaac9c50577aa160":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b83b30864ec049b0b5ad97d22f892332":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7b385705f874b72a3a58b088db069cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"859e8f1081614738aba96d83c515ccaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d87c4caf48a47c1a188294ecfc0d369":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8691445cfb69497fbded79b24038d8d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7228dfdc6a5b4fae979bd1248fa7f1f7","IPY_MODEL_35a8d56b7d13448b95d90779b0a78f43","IPY_MODEL_2c9cb10b8f9c4b59977db872049c1de8"],"layout":"IPY_MODEL_9209904a12d642aa9ac52978113b8a53"}},"7228dfdc6a5b4fae979bd1248fa7f1f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_977fd3adddd8440ca13922ddd99af66e","placeholder":"​","style":"IPY_MODEL_2e279a4386d046959c0fa7e26e922156","value":"Downloading: 100%"}},"35a8d56b7d13448b95d90779b0a78f43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f76b83795ea4a53baeab2d4dd0edc70","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a469f12c8a84f9599efbfd093fb0c66","value":898825}},"2c9cb10b8f9c4b59977db872049c1de8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ad0a68447f4442b5cfb5e4ad2c7421","placeholder":"​","style":"IPY_MODEL_c7602959451d4830bdec8dd74c20b400","value":" 878k/878k [00:00&lt;00:00, 1.94MB/s]"}},"9209904a12d642aa9ac52978113b8a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"977fd3adddd8440ca13922ddd99af66e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e279a4386d046959c0fa7e26e922156":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f76b83795ea4a53baeab2d4dd0edc70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a469f12c8a84f9599efbfd093fb0c66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50ad0a68447f4442b5cfb5e4ad2c7421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7602959451d4830bdec8dd74c20b400":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eddbb2a112fd4dce9beaaaece69662bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9d201912afb47c3b46f95a4ebbb2db7","IPY_MODEL_608f63399d9d48f38658c7b48c8ab328","IPY_MODEL_c915e397df4f49e7915e706bc227a509"],"layout":"IPY_MODEL_50785d1b0efe4c36aaabedd4f3007a84"}},"c9d201912afb47c3b46f95a4ebbb2db7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83e87f339587425db392a33f1ffaa1ff","placeholder":"​","style":"IPY_MODEL_ddc85ddd8e2647a1b48188060e6eafcf","value":"Downloading: 100%"}},"608f63399d9d48f38658c7b48c8ab328":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5c87d30bc1d4f4e9690cb456854fff0","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd0145d8162c4be0ac46acc9812145db","value":456318}},"c915e397df4f49e7915e706bc227a509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7e5739c6788484d8cc66c325bf55f9c","placeholder":"​","style":"IPY_MODEL_b06a1518c3b84d8ebabe199b9d2a3958","value":" 446k/446k [00:00&lt;00:00, 633kB/s]"}},"50785d1b0efe4c36aaabedd4f3007a84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83e87f339587425db392a33f1ffaa1ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddc85ddd8e2647a1b48188060e6eafcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5c87d30bc1d4f4e9690cb456854fff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd0145d8162c4be0ac46acc9812145db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7e5739c6788484d8cc66c325bf55f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b06a1518c3b84d8ebabe199b9d2a3958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"601689e1bf994cb28b6553e506b34f24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a570bee8547428495612fb40d284109","IPY_MODEL_1e6ed4bbee86471bb4eb88f3ec70bb61","IPY_MODEL_ba822cb8afe54c769d529df793d8008e"],"layout":"IPY_MODEL_01cac304ac114a919664a0dc3c8aa741"}},"2a570bee8547428495612fb40d284109":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93555babf9584151b414e28ddb826010","placeholder":"​","style":"IPY_MODEL_c0c10324f8e349738da3a63d3733c473","value":"100%"}},"1e6ed4bbee86471bb4eb88f3ec70bb61":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c3e9367d32044c4a314d7519897e48a","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28116cf0d689496bb5abbadd7ecea374","value":42146}},"ba822cb8afe54c769d529df793d8008e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07a754bbca864150a774868daf69651d","placeholder":"​","style":"IPY_MODEL_01f6f55acf3f41e0a67c640cdf5941b9","value":" 42146/42146 [00:30&lt;00:00, 2106.78it/s]"}},"01cac304ac114a919664a0dc3c8aa741":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93555babf9584151b414e28ddb826010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c10324f8e349738da3a63d3733c473":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c3e9367d32044c4a314d7519897e48a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28116cf0d689496bb5abbadd7ecea374":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07a754bbca864150a774868daf69651d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01f6f55acf3f41e0a67c640cdf5941b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e5099dedd284c8d98364fd8ba866a8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7db5dae1ec34e019b12924ef497c7ed","IPY_MODEL_0216c31ea16544988227795263609fe4","IPY_MODEL_4b011dd5d9fc47aea568aface56f7616"],"layout":"IPY_MODEL_116ff02d546c457da0a752b09709a75b"}},"c7db5dae1ec34e019b12924ef497c7ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eca2a14f315449d5a1325e8a6edfd8c5","placeholder":"​","style":"IPY_MODEL_fddf55357a134a5e85b4552d195e1c39","value":"100%"}},"0216c31ea16544988227795263609fe4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87cc3cbb14b34ac494af1a63849fcfcf","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e0e3bde94504329b89bd27eb8fa63ff","value":143}},"4b011dd5d9fc47aea568aface56f7616":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68dc286931194cc19952ec0af83f9740","placeholder":"​","style":"IPY_MODEL_687940667e3647ccad874a452b2c7c02","value":" 143/143 [00:00&lt;00:00, 2244.03it/s]"}},"116ff02d546c457da0a752b09709a75b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eca2a14f315449d5a1325e8a6edfd8c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fddf55357a134a5e85b4552d195e1c39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87cc3cbb14b34ac494af1a63849fcfcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e0e3bde94504329b89bd27eb8fa63ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68dc286931194cc19952ec0af83f9740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"687940667e3647ccad874a452b2c7c02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46b0526921b843c5acd2ba088cf70d87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f8d7ff16d774a31bcc474c1425fb37c","IPY_MODEL_c0f37b8f907044ca862ad3584f889794","IPY_MODEL_49e3a6ffe9d44c7f874c31dd6501b461"],"layout":"IPY_MODEL_c61a5f5b7eda449084559df1818c8d15"}},"8f8d7ff16d774a31bcc474c1425fb37c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e827271638d48b9b0a97eda417f2a48","placeholder":"​","style":"IPY_MODEL_201733eb304646dba3733643fd242a03","value":"Downloading: 100%"}},"c0f37b8f907044ca862ad3584f889794":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_784637e53a7a45eeb78948cb48ec26b0","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f50a6775ffbe4986a57ae5e3b36beeeb","value":1627284589}},"49e3a6ffe9d44c7f874c31dd6501b461":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90efbc8b9a674ef6b37143907f5bf7ad","placeholder":"​","style":"IPY_MODEL_0ebab1b8a673424fa0aa783d45402a76","value":" 1.52G/1.52G [00:33&lt;00:00, 53.7MB/s]"}},"c61a5f5b7eda449084559df1818c8d15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e827271638d48b9b0a97eda417f2a48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"201733eb304646dba3733643fd242a03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"784637e53a7a45eeb78948cb48ec26b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f50a6775ffbe4986a57ae5e3b36beeeb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90efbc8b9a674ef6b37143907f5bf7ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ebab1b8a673424fa0aa783d45402a76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2205c256d19949309829b84941f91ba2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eff4f0909b1149f49f005f355605f172","IPY_MODEL_5df3550872244457ae62a966b47f6f90","IPY_MODEL_d213c6af9f4444808545126792be22bc"],"layout":"IPY_MODEL_e1077cad5b9044c581a6a5d7417674a9"}},"eff4f0909b1149f49f005f355605f172":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85ea4673500e4d85a357dcbea663185b","placeholder":"​","style":"IPY_MODEL_8666371077af4ee388b449e79a985310","value":"100%"}},"5df3550872244457ae62a966b47f6f90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9989d6a84f24722a58844ea99d709d3","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12ba6187a7424dce919376dbf8bad0b4","value":2}},"d213c6af9f4444808545126792be22bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09969eb0cd134a2d81130df796b2498b","placeholder":"​","style":"IPY_MODEL_7b3cbe74d332405f89b02d5f363e92d8","value":" 2/2 [00:01&lt;00:00,  1.24s/it]"}},"e1077cad5b9044c581a6a5d7417674a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85ea4673500e4d85a357dcbea663185b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8666371077af4ee388b449e79a985310":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9989d6a84f24722a58844ea99d709d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12ba6187a7424dce919376dbf8bad0b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09969eb0cd134a2d81130df796b2498b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b3cbe74d332405f89b02d5f363e92d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b135c75a4b14404a95c71736efb071f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_512d97a1382244799b938e8280ca620d","IPY_MODEL_0c5aca74fb534b75925dade7aae8d10a","IPY_MODEL_3530324e6f4046d6bdffba337a7f069c"],"layout":"IPY_MODEL_2750a8af76434058af836ac55aa8bb04"}},"512d97a1382244799b938e8280ca620d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd91079c15804ebdad3ca05b927b3614","placeholder":"​","style":"IPY_MODEL_1504c0b337c84d48a33bb97547daf248","value":"100%"}},"0c5aca74fb534b75925dade7aae8d10a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df89172492874d61b1c04ba703a9b278","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c81fc4c9932434e9deb110f15cc008d","value":2}},"3530324e6f4046d6bdffba337a7f069c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b2ae0e9b2be4d188e460ea6100784b8","placeholder":"​","style":"IPY_MODEL_f00c1d57caad4da497dc1670efdea825","value":" 2/2 [00:01&lt;00:00,  1.43s/it]"}},"2750a8af76434058af836ac55aa8bb04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd91079c15804ebdad3ca05b927b3614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1504c0b337c84d48a33bb97547daf248":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df89172492874d61b1c04ba703a9b278":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c81fc4c9932434e9deb110f15cc008d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b2ae0e9b2be4d188e460ea6100784b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f00c1d57caad4da497dc1670efdea825":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}